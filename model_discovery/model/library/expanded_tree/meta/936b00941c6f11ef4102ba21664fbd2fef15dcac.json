{"paperId": "936b00941c6f11ef4102ba21664fbd2fef15dcac", "abstract": "Transformer, a new type of neural network based on the self-attention mechanism, has revolutionized the field of natural language processing. Since Transformer has a more powerful representation ability than Convolutional Neural Networks (CNN), researchers are trying to apply it to computer vision tasks. In the past, most of the review papers summarized Transformers in the field of computer vision and natural language processing, respectively, which isolates the relationship between the two fields and fails to show the correlations and differences between the two fields. In order to better demonstrate the mutual promotion between the two fields, this paper will combine the development of Transformer in the two fields to provide a comprehensive review. Furthermore, we will review these Transformer models by their application scenarios and analyze their advantages and disadvantages. Finally, we discuss the challenges and some future research directions for Transformer.", "venue": "2022 5th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)", "year": 2022, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper will combine the development of Transformer in the two fields to provide a comprehensive review and review these Transformer models by their application scenarios and analyze their advantages and disadvantages."}, "embedding": {"model": "specter_v2", "vector": [0.22442691028118134, 0.8524084091186523, -0.24908064305782318, 0.29401901364326477, -0.1829000562429428, -0.54590904712677, 0.6905431747436523, -0.11490979790687561, -0.2559559643268585, -0.294584184885025, 0.3183612823486328, 0.01738530397415161, 0.7469597458839417, -0.30231809616088867, -0.2576162815093994, 0.03783687576651573, -0.08749346435070038, 0.326667457818985, 0.2961446940898895, -0.31413933634757996, -0.33675509691238403, -0.7404051423072815, -0.8579932451248169, 0.12736228108406067, 0.4719710350036621, 0.8355153203010559, 0.2560746967792511, 0.2925311326980591, -0.8693581223487854, 0.8657442331314087, 0.47358065843582153, -0.7625733613967896, 0.2284555584192276, 0.1736878901720047, -0.43973222374916077, -0.2543404698371887, 0.7581799626350403, 0.021078862249851227, -0.5445731282234192, 1.2288556098937988, -0.4098464250564575, 0.06499319523572922, 0.36970239877700806, -1.0792862176895142, -0.6539847254753113, 0.7053908109664917, 1.0712090730667114, 0.907225489616394, -0.395204097032547, -0.40246450901031494, 1.6011650562286377, -0.9943444728851318, 0.13155467808246613, 1.3137379884719849, 0.5266363620758057, 0.3418331742286682, -0.1605740487575531, -0.7374795079231262, 0.4883033335208893, 0.09798700362443924, -0.6089339852333069, -0.34983351826667786, 0.4941578209400177, -0.21601036190986633, 1.9166796207427979, -0.5616747736930847, 0.0938616469502449, 0.6096419095993042, 0.05361838638782501, 1.4255560636520386, 0.23761257529258728, -0.7064266800880432, -0.4455077052116394, -0.03549277037382126, 0.10756225138902664, 1.2115193605422974, -0.5371723175048828, 0.05608542636036873, -0.7535098195075989, -0.22039858996868134, 0.9184018969535828, -0.25401344895362854, -0.21414075791835785, -0.40130752325057983, -0.1440030187368393, 0.9451654553413391, 0.3640855550765991, 0.8628411293029785, -0.261224627494812, 0.41017162799835205, 0.7852662205696106, 0.2592029869556427, -0.2587445378303528, 0.45649299025535583, 0.07726450264453888, 0.5277377367019653, -0.8017701506614685, -0.031834736466407776, -0.15599456429481506, 1.153391718864441, -0.21134863793849945, 0.6517537832260132, -0.8781397342681885, 0.3266485035419464, 1.4092342853546143, 0.3226354718208313, 0.3719215393066406, -0.843474805355072, 0.2804378867149353, -0.33992183208465576, -0.20998512208461761, -0.7846638560295105, 0.3666553795337677, -0.30757275223731995, -0.8491764068603516, -1.2756695747375488, -0.23574358224868774, 0.4950008988380432, -1.0689167976379395, 0.6722198724746704, -0.7600138187408447, -0.26645737886428833, 0.08004266768693924, 0.21860961616039276, 0.7132250666618347, 0.437655508518219, 0.6476076245307922, 0.1570470631122589, 1.1545403003692627, -0.8134640455245972, -0.9212958216667175, -1.129642128944397, 0.09412772208452225, -0.28029555082321167, 0.5108441710472107, -0.2735036313533783, -0.7411059141159058, -0.7369148135185242, -0.7295010089874268, 0.04903154820203781, -0.43690425157546997, 0.08583741635084152, 0.7978572845458984, 0.17527151107788086, -1.342509388923645, 0.6538509726524353, 0.08062388002872467, -0.6267867088317871, 0.697479248046875, 0.026084091514348984, 0.2862655818462372, -0.1495373696088791, -1.53495192527771, 0.4337318539619446, 0.11416598409414291, -0.5107250809669495, -0.46502137184143066, -0.1973169595003128, -1.52549409866333, 0.20463016629219055, 0.3822997212409973, -0.6075409650802612, 1.2440167665481567, -0.4568651020526886, -0.8913854360580444, 0.829990565776825, -0.6591270565986633, -0.11067737638950348, -0.08259045332670212, 0.01121413055807352, -0.38586482405662537, -0.4490015506744385, 0.4827583432197571, 0.18106327950954437, 0.566238284111023, -0.21210934221744537, -0.36479002237319946, 0.20098471641540527, -0.17347554862499237, -0.3181530833244324, -0.1832055300474167, 0.883560836315155, -0.3923274874687195, -0.17919036746025085, 0.23454561829566956, 1.015112042427063, 0.3316030204296112, -0.06709069758653641, -0.225563645362854, -1.7064156532287598, 0.7251120805740356, 0.09801431745290756, 0.9119649529457092, -0.8428499698638916, -1.099135160446167, -0.28659695386886597, -0.0538976788520813, 0.06952337920665741, -0.7757290601730347, 0.5639059543609619, -0.48711028695106506, 0.3782890737056732, 0.16139377653598785, -0.5344632267951965, -0.24939219653606415, 0.14316602051258087, -0.9782419800758362, -0.15454450249671936, 0.31513088941574097, 1.1446123123168945, -1.0585694313049316, -0.4050617814064026, -0.05267548933625221, 0.14899292588233948, -0.3007543087005615, 1.2358300685882568, -0.14353978633880615, -0.4805716276168823, -0.19327066838741302, 0.09915142506361008, 0.022578371688723564, -0.4034196734428406, 0.19429059326648712, -0.5885816812515259, -0.10569608211517334, 0.6301981806755066, 0.11364647001028061, 0.9901255965232849, -0.15090569853782654, 0.9816243648529053, -0.2655946612358093, -0.841159462928772, 0.3936496078968048, 0.8148521184921265, -0.44913607835769653, -0.7515924572944641, 0.44919103384017944, -0.031811296939849854, -0.7283586263656616, 0.24141238629817963, 0.42164918780326843, 0.7212873697280884, -0.0463140532374382, 0.016515977680683136, 0.6785030364990234, -0.2980012893676758, 0.23611833155155182, 0.41493016481399536, 0.6396845579147339, 0.09454497694969177, 0.4620697498321533, -0.18626680970191956, 0.4730702042579651, -0.40128031373023987, 0.11675874143838882, 0.5664878487586975, 0.20312733948230743, 0.6707154512405396, 0.7142552733421326, -0.47711601853370667, -0.2861478924751282, -0.25639697909355164, 0.8332912921905518, 1.3511321544647217, -0.2588661015033722, -0.35686030983924866, -0.5904056429862976, -0.4388284683227539, -0.6814978718757629, 0.1676313579082489, -0.24421656131744385, 0.04515984654426575, -0.273759663105011, -0.6851921677589417, 1.0503126382827759, 0.2958278954029083, 1.1400337219238281, -0.9548484683036804, -0.14581537246704102, -0.18896125257015228, -0.13713665306568146, -0.9152022004127502, -0.5651642084121704, 0.4051385521888733, -0.6788212060928345, -0.6819303035736084, 0.08958878368139267, -0.5505968332290649, 0.15390802919864655, -0.510924756526947, 0.9236955642700195, -0.816709041595459, 0.19098158180713654, 0.35067301988601685, 0.687674880027771, -0.8809940218925476, -0.7306888103485107, -0.007850845344364643, -0.035208288580179214, -0.17315201461315155, 0.8123649954795837, 0.6157695055007935, 0.34896451234817505, -0.20575425028800964, -0.27671778202056885, -0.45072874426841736, -0.03278631344437599, 0.3542770445346832, 0.8751298785209656, -0.05427977442741394, -0.39418351650238037, -1.049501657485962, 1.3558053970336914, 0.44547557830810547, -0.5899232625961304, 0.3346838057041168, -0.9568325877189636, -0.12285389751195908, 0.3644920289516449, -0.6782478094100952, -0.20675769448280334, -0.40094810724258423, 0.6234135031700134, -0.5685742497444153, -0.10339134186506271, 0.2588784396648407, 0.02069135755300522, 0.21661368012428284, 0.09944266825914383, 0.9100358486175537, 0.4643491208553314, 0.08931375294923782, 0.46159154176712036, -0.6730563640594482, 0.6012510061264038, 0.3811599612236023, 0.25178948044776917, -0.12012290954589844, -0.5243297815322876, -0.5929161310195923, -0.5090886950492859, -0.38687264919281006, 0.17433036863803864, -0.14821985363960266, -0.04076363518834114, -0.7908376455307007, -0.8116335272789001, 0.1480131894350052, -1.261205792427063, 0.01532646082341671, -0.18238428235054016, -0.8074888586997986, 0.0004599257663358003, -0.8414602875709534, -0.9884518384933472, -0.45828306674957275, -0.7560526132583618, -0.6099615693092346, 0.011912708170711994, 0.30788907408714294, 0.09090762585401535, -0.49845704436302185, -0.09415476769208908, -0.47166505455970764, 1.3012890815734863, -0.7267207503318787, 1.139212727546692, -0.3197939693927765, -0.2464975118637085, -0.12462832778692245, -0.1992129683494568, 0.6508183479309082, 0.161050483584404, -0.07905135303735733, -0.9493176341056824, 0.588976263999939, 0.22973090410232544, 0.038044583052396774, 0.2470073103904724, 0.33669716119766235, 0.45778894424438477, -0.0371527299284935, -0.5551844239234924, 0.21076032519340515, 1.6220064163208008, -0.4139143228530884, 0.24637694656848907, 0.4702201187610626, 0.9687782526016235, 0.199214369058609, -0.3330281674861908, -0.20683158934116364, 0.6765517592430115, 0.07009122520685196, 0.6671246886253357, -0.06672986596822739, 0.00503202760592103, -0.6468536853790283, 0.3363509178161621, 1.3490864038467407, -0.010881341062486172, -0.1361890733242035, -1.142364263534546, 1.0898094177246094, -1.1935712099075317, -0.816734254360199, 0.46845775842666626, 0.3102158308029175, 0.4392477869987488, -0.3644160330295563, -0.6625940203666687, -0.10914520174264908, 0.705228328704834, 0.5773525834083557, -0.05967406928539276, -0.689895749092102, -0.2521401643753052, 0.4620382487773895, 0.4528767764568329, 0.6159810423851013, -0.6549286842346191, 1.217585802078247, 14.640716552734375, 0.8755690455436707, -0.24057814478874207, 0.7075579762458801, 0.22089757025241852, 0.8652023673057556, -0.4919656813144684, 0.14248542487621307, -1.170985221862793, -0.3747153878211975, 0.5175524353981018, -0.06569308042526245, 0.48041436076164246, 0.3134729266166687, -0.25948068499565125, 0.2875516414642334, -0.2909071147441864, 0.9131466150283813, 0.8128283619880676, -0.9522013664245605, 0.7029291987419128, 0.14332546293735504, -0.29497915506362915, 0.7121610641479492, 0.5088622570037842, 0.6571340560913086, 0.7579410076141357, -0.4118010699748993, 0.46001407504081726, -0.15187780559062958, 0.8296801447868347, 0.32814037799835205, 0.6748502254486084, 0.3380764126777649, -1.0646510124206543, -0.16774451732635498, -0.8067198991775513, -0.938772439956665, 0.08741093426942825, 0.18353495001792908, -0.29050934314727783, -0.6110724806785583, 0.05407514050602913, 0.6537367105484009, 0.11236061155796051, 0.41222816705703735, -0.8438423871994019, 0.6644588112831116, -0.08491862565279007, -0.003554882714524865, 0.2790868580341339, 0.7119470834732056, 0.4388854503631592, -0.21929693222045898, 0.10223614424467087, 0.0911678820848465, 0.009993300773203373, 0.6529355645179749, -0.487238347530365, 0.017440903931856155, -0.4408299922943115, -0.5935483574867249, -0.16601039469242096, 0.7534542083740234, 0.3498695194721222, 0.35172924399375916, -0.2818555533885956, 0.4495539665222168, 0.5807574391365051, 0.40616923570632935, -0.2666996121406555, -0.48039644956588745, 0.1804630607366562, 0.10349083691835403, 0.44045108556747437, 0.6704803109169006, 0.06685010343790054, -0.5327085852622986, -0.6160849928855896, 0.006273964419960976, 0.3784739077091217, -0.9963585734367371, -0.9156390428543091, 1.552965760231018, -0.6138759255409241, -0.5470260977745056, 0.5285221338272095, -0.8436551690101624, -0.4296402633190155, 0.3882768154144287, -1.829392433166504, -0.9629911184310913, -0.04579290747642517, 0.3668527901172638, -0.3292103111743927, -0.34524768590927124, 1.2132598161697388, -0.13536086678504944, 0.003117440501227975, -0.0547867976129055, -0.4814107418060303, 0.6386381983757019, -0.2483678013086319, -0.7335583567619324, 0.5682685971260071, 0.3238361179828644, 0.2097131460905075, 0.2223161906003952, 0.08545832335948944, 0.1635410487651825, -0.11672290414571762, -0.17452731728553772, 1.2226629257202148, -0.7504985332489014, -0.23666329681873322, -0.6030820608139038, -0.9052198529243469, 0.37798330187797546, 0.9768048524856567, -0.24097731709480286, -0.08982294797897339, -0.06148453801870346, -0.8329789638519287, -0.0547773502767086, -0.8664209842681885, -0.10610118508338928, 0.4658185839653015, -1.0914698839187622, -0.7956286072731018, -0.21093282103538513, 0.24871943891048431, -0.7331482172012329, -0.21574905514717102, -0.3814101219177246, -0.07011941820383072, 0.14300799369812012, 0.8601510524749756, -0.40874284505844116, 0.3385944962501526, 0.5598782896995544, -0.10519586503505707, -0.8238075971603394, -0.33078083395957947, -0.7262818217277527, 0.29469773173332214, 0.6312626600265503, 0.7292240262031555, -0.8126565217971802, 0.35852667689323425, 0.7503223419189453, 0.4483276605606079, -0.2936171889305115, -0.9285207390785217, -0.5099722146987915, 0.010630542412400246, -0.43947532773017883, 0.4421444833278656, 0.021658940240740776, -0.1880861520767212, 0.31580641865730286, 0.8006457090377808, 0.35372108221054077, 0.0176245030015707, -0.7083304524421692, -0.2966062128543854, -0.8138206601142883, 0.5527380704879761, -0.317315012216568, -0.3043048679828644, -1.1947996616363525, 0.3127022981643677, -1.027877926826477, 0.01841888390481472, -1.5774991512298584, -0.4343061149120331, 0.04114154353737831, -0.49094158411026, 0.5574638843536377, 0.6711264252662659, -0.6238179802894592, -0.19358307123184204, -0.21430820226669312, -0.2678435146808624, 0.8280050158500671, 0.9283756017684937, -1.2259588241577148, 0.02756798267364502, 0.020078107714653015, -0.2149282991886139, 0.35435888171195984, 0.5275013446807861, -0.7837013006210327, -0.7401291131973267, -1.4666388034820557, 0.40913230180740356, -0.4545742869377136, -0.09010697901248932, -0.22743873298168182, 1.0779627561569214, 0.488190233707428, -0.4171889126300812, 0.2077713906764984, 0.30423983931541443, -1.1604626178741455, -0.8840558528900146, 0.23679295182228088, -0.3492128849029541, 0.30457010865211487, -0.009724418632686138, -0.3640815019607544, -0.8191325664520264, 0.5984936952590942, -0.1332404911518097, -1.472322702407837, -0.6392105221748352, 0.5596888661384583, -0.9974389672279358, 0.439849853515625, -0.0446670725941658, -0.24293144047260284, -1.3337215185165405, -0.444234162569046, -0.09191339462995529, 0.40330132842063904, -0.5296633839607239, 1.1006371974945068, 0.5814998149871826, -1.2068160772323608, 0.42515644431114197, 0.4981631636619568, 0.013625230640172958, 0.004508995451033115, -0.06428739428520203, 0.08735548704862595, -0.48031502962112427, 0.7191205620765686, 0.14677996933460236, 0.18989622592926025, -0.9074541926383972, 0.113712377846241, 1.001554250717163, -0.46286725997924805, -0.17959295213222504, 0.9175304770469666, -0.3728429675102234, -0.8911377191543579, 0.21834349632263184, -1.198805570602417, -1.1033172607421875, -0.1687050759792328, 0.18312321603298187, -0.11270900070667267, -0.47451430559158325, -0.4931826591491699, -0.5945377349853516, 0.2671337425708771, 0.22798988223075867, -0.27484723925590515, 0.5239070057868958, 0.01090534869581461, -0.7379178404808044, 0.39222678542137146, 0.2226048707962036, -0.9155789017677307, -0.5743452310562134, -0.897754967212677, -0.3933584988117218, -0.03750896826386452, 0.3690393567085266, -0.15997281670570374, -0.9596749544143677, 1.0588716268539429, 0.6063063740730286, 0.48141205310821533, 0.12897264957427979, -0.014225149527192116, 0.23479348421096802, 0.32458338141441345, 0.24103595316410065, -0.6740067005157471, -0.7711867094039917, 1.5836310386657715, 1.1681413650512695, -0.8305542469024658, -0.12985806167125702, -0.7800931334495544, -0.6589643359184265, 0.9236211180686951, 0.39409950375556946, -0.17474645376205444, 1.0970841646194458, -0.231650248169899, 0.3744695484638214, -0.1738446056842804, -0.8888657093048096, -0.5006040334701538, 0.3798055350780487, 1.4948171377182007, 0.6144760251045227, -0.0447046235203743, 0.2786025106906891, 0.9694857001304626, 0.2119295299053192, 0.28173828125, 0.6899078488349915, 0.14980259537696838, -0.06610983610153198, -0.08332028239965439, 0.2198268473148346, 0.5986760258674622, -0.743150532245636, -0.949677050113678, -0.07696393132209778, 0.7794950604438782, 0.12112795561552048, 0.6438485383987427, 0.9360063672065735, -0.01312414649873972, 0.8366860747337341, 0.38914424180984497, 0.31167781352996826, -0.6904239654541016, -0.3993885815143585, -0.30121102929115295, -0.7503702044487, -0.21387578547000885, -0.6651943922042847, -0.5732086896896362, -0.012543367221951485, 0.10866450518369675, 0.0806904137134552, 0.03763175010681152, 0.1046900823712349, 0.8871797919273376, 0.3074142038822174, 0.3652762472629547, -0.7333518862724304, 0.2871282398700714, -0.1625857800245285, -1.0465577840805054, -0.07062117010354996, -0.7447487115859985, -0.03468788415193558, -0.11189405620098114, -0.337613970041275, -0.25888675451278687]}, "authors": [{"authorId": "2187004330", "name": "Jiaru Jia"}, {"authorId": "2187146972", "name": "Xin Chen"}, {"authorId": "13607382", "name": "Aiqing Yang"}, {"authorId": "2186998909", "name": "Qiulin He"}, {"authorId": "2124127567", "name": "Pengyu Dai"}, {"authorId": "2112345119", "name": "Mingzhe Liu"}], "references": [{"paperId": "9dc481ec44178e797466bbad968071917842156b", "title": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection"}, {"paperId": "78d02f2909a582c624eca2d0f67c91ee91974180", "title": "DN-DETR: Accelerate DETR Training by Introducing Query DeNoising"}, {"paperId": "c2df109689819d6f456c771874208840c98a7a9f", "title": "Lawin Transformer: Improving Semantic Segmentation Transformer with Multi-Scale Representations via Large Window Attention"}, {"paperId": "9137efc758f80dd22bb56f82cca5c94f78a5db3e", "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and Detection"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "520bd2331cca8d5a9c032c186a2a0f7704ead6ff", "title": "R-Drop: Regularized Dropout for Neural Networks"}, {"paperId": "1fb10189c500e4902cd1b5afd406f57323d21be8", "title": "VOLO: Vision Outlooker for Visual Recognition"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "2a805d0e1b067444a554c5169d189fa1f649f411", "title": "Scaling Vision Transformers"}, {"paperId": "3d4b1c580c4df032549a84ee1a5114a09863ce18", "title": "SOLQ: Segmenting Objects by Learning Queries"}, {"paperId": "1ee1160b8c7c70ded02e786c184a6da651e88bed", "title": "Dynamic Head: Unifying Object Detection Heads with Attentions"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "816b977342fd291fc4f200a9642fa6df9eb601e9", "title": "ISTR: End-to-End Instance Segmentation with Transformers"}, {"paperId": "f0524b3005720bcff886bcb0227f7f0dd924ff07", "title": "VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "3456c1e95d8d2f985a0701232dd55171b3cbd5e0", "title": "Lessons on Parameter Sharing across Layers in Transformers"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0", "title": "Incorporating Convolution Designs into Visual Transformers"}, {"paperId": "610b302950a19acef1c45456111dcd495f638c18", "title": "ConViT: improving vision transformers with soft convolutional inductive biases"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "6e8f35c6d54acb14109c9b792a62609eac8a7b5e", "title": "TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "6d5f423164cd5ef9324281652987c8a65009e98e", "title": "Sparse R-CNN: End-to-End Object Detection with Learnable Proposals"}, {"paperId": "75bcdf04827cd230d88b70c622dce8868eb50a3b", "title": "Revisiting Stereo Depth Estimation From a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "eedf2748a9a1ba2779cde95fd8bad9c2260d5317", "title": "LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention"}, {"paperId": "f7f89feee68b6856c0a980a5888b42d18231be07", "title": "Learning Joint Spatial-Temporal Transformations for Video Inpainting"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "1c8aea2bfb61f4661b6907018a5a8bca390900dd", "title": "PALM: Pre-training an Autoencoding&autoregressive Language Model for Context-conditioned Generation"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "e6a8a243aba31adc038ae513f6ceafcff4c3636c", "title": "Speaker-Aware BERT for Multi-Turn Response Selection in Retrieval-Based Chatbots"}, {"paperId": "be90ac37997fdf3a0e261dc0fc6be18d20170bb0", "title": "4D Light Field Segmentation From Light Field Super-Pixel Hypergraph Representation"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "b03cf6324ecf7a295a4aeae5970c88d1a1c3f336", "title": "Explicit Sparse Transformer: Concentrated Attention Through Explicit Selection"}, {"paperId": "841d43cf4015042a4ee45745c5b6f2c59c184da5", "title": "DeFINE: Deep Factorized Input Token Embeddings for Neural Sequence Modeling"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "a88c914f5a738d38f02790bb5de41453bf17bde1", "title": "Object-Contextual Representations for Semantic Segmentation"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "d56c1fc337fb07ec004dc846f80582c327af717c", "title": "StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "81f5810fbbab9b7203b9556f4ce3c741875407bc", "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "145b8b5d99a2beba6029418ca043585b90138d12", "title": "MASS: Masked Sequence to Sequence Pre-training for Language Generation"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "81b99bc2eea674a205f2f3dbf4d19f2ece55def6", "title": "TransCut2: Transparent Object Segmentation From a Light-Field Image"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "fa0beb3f4d7f6e7e49b153af7e8a7c30f2937b60", "title": "Sparse Attentive Backtracking: Temporal CreditAssignment Through Reminding"}, {"paperId": "ad655c25e052fa4eeed53421344aca6f239c4c9d", "title": "Dual Attention Network for Scene Segmentation"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "2a94c84383ee3de5e6211d43d16e7de387f68878", "title": "Feature Pyramid Networks for Object Detection"}, {"paperId": "1031a69923b80ad01cf3fbb703d10757a80e699b", "title": "Pyramid Scene Parsing Network"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "13497bd108d4412d02050e646235f456568cf822", "title": "Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin"}, {"paperId": "993a1e7d592a2bcb1f3e8db34c026c3227a1d091", "title": "TransCut: Transparent Object Segmentation from a Light-Field Image"}, {"paperId": "4aa9f5150b46320f534de4747a2dd0cd7f3fe292", "title": "Semi-supervised Sequence Learning"}, {"paperId": "f8e79ac0ea341056ef20f2616628b3e964764cfd", "title": "You Only Look Once: Unified, Real-Time Object Detection"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "6364fdaa0a0eccd823a779fcdd489173f938e91a", "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation"}, {"paperId": "39ad6c911f3351a3b390130a6e4265355b4d593b", "title": "Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "161ffb54a3fdf0715b198bb57bd22f910242eb49", "title": "Multitask Learning"}, {"paperId": "b08c360ddf899923aebf25913706b4f03e54eccd", "title": "DeLighT: Deep and Light-weight Transformer"}, {"paperId": "cee1cf016d7bcb97df1caebfa53f3b77bebdd14a", "title": "Semantic Segmentation With Light Field Imaging and Convolutional Neural Networks"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Peters , Mark Neumann , Mohit Iyyer , Matt Gardner , Christopher Clark , Kenton Lee , Luke Zettlemoyer . Deep contextualized word representations . CoRR abs / 1802 . 05365 ( 2018 )"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}]}