{"paperId": "9a13a0bfa8e2d15cbc30cde868f03238d583b950", "abstract": "Each new generation of English-oriented Large Language Models (LLMs) exhibits enhanced cross-lingual transfer capabilities and significantly outperforms older LLMs on low-resource languages. This prompts the question: Is there a need for LLMs dedicated to a particular low-resource language? We aim to explore this question for Bengali, a low-to-moderate resource Indo-Aryan language native to the Bengal region of South Asia. We compare the performance of open-weight and closed-source LLMs such as LLaMA-3 and GPT-4 against fine-tuned encoder-decoder models across a diverse set of Bengali downstream tasks, including translation, summarization, paraphrasing, question-answering, and natural language inference. Our findings reveal that while LLMs generally excel in reasoning tasks, their performance in tasks requiring Bengali script generation is inconsistent. Key challenges include inefficient tokenization of Bengali script by existing LLMs, leading to increased computational costs and potential performance degradation. Additionally, we highlight biases in machine-translated datasets commonly used for Bengali NLP tasks. We conclude that there is a significant need for a Bengali-oriented LLM, but the field currently lacks the high-quality pretraining and instruction-tuning datasets necessary to develop a highly effective model.", "venue": "", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "There is a significant need for a Bengali-oriented Large Language Models, but the field currently lacks the high-quality pretraining and instruction-tuning datasets necessary to develop a highly effective model."}, "embedding": {"model": "specter_v2", "vector": [0.011054208502173424, 0.6089547872543335, -0.10762697458267212, 0.1198316216468811, -0.7727457880973816, -0.6489297151565552, 0.6191413402557373, -0.23135420680046082, -0.28121036291122437, -0.009976739063858986, 0.4087410569190979, -0.4207734763622284, 0.3572238087654114, -0.023680532351136208, -0.2425028383731842, 0.012166363187134266, -0.8282983303070068, 0.4371134638786316, -0.36050400137901306, -0.23453772068023682, -0.31974852085113525, -0.4450855851173401, -0.6279637813568115, 0.05576419085264206, 0.5515499711036682, 0.2235313206911087, 0.258048951625824, 1.2705533504486084, -0.42027291655540466, 0.7165836095809937, 0.03255145996809006, -0.4221982955932617, 0.0012407297035679221, -0.6649227738380432, -0.6225594878196716, -0.19748805463314056, 0.2963561713695526, -0.8373422622680664, -0.45313769578933716, 0.5194340944290161, 0.047729939222335815, 0.02958829142153263, 0.442799836397171, -0.5487022399902344, -0.8344307541847229, 1.1631498336791992, 1.0770478248596191, 0.8600198030471802, -0.30470871925354004, -0.6007826924324036, 1.080933690071106, -1.197420597076416, 0.1834864467382431, 1.3556222915649414, 0.6550232768058777, 0.3467124104499817, 0.07257223129272461, -0.4530857503414154, 0.24980203807353973, 0.2185690850019455, -0.9211509823799133, -0.73575359582901, -0.13436803221702576, 0.23668251931667328, 1.712154507637024, -0.14067701995372772, -0.23568803071975708, 0.16312846541404724, -0.36847376823425293, 1.5407888889312744, 0.273951917886734, -0.6417505145072937, -0.1878529042005539, 0.19410759210586548, 0.09591003507375717, 0.5108524560928345, -0.5697601437568665, -0.6641400456428528, -0.8500971794128418, -0.08307906240224838, 0.45823362469673157, -0.4793037176132202, -0.34702068567276, 0.4637909531593323, -0.36380961537361145, 0.756298840045929, 0.3534812033176422, 0.6374733448028564, -0.25513535737991333, 0.05147431790828705, 0.31645655632019043, 0.5116395354270935, 0.2530041038990021, 0.3395296335220337, -0.432866632938385, 0.3522912859916687, -1.042190670967102, 0.235850527882576, 0.48096176981925964, 0.9970957636833191, -0.22551286220550537, 0.26186811923980713, -0.9890953898429871, 0.2775653898715973, 0.9982976913452148, -0.007038033567368984, 0.6284801363945007, -0.7366043925285339, 0.3369385600090027, -0.7667344212532043, 0.134019136428833, -0.460719496011734, -0.27239394187927246, -0.10843029618263245, -0.8284865617752075, -1.788637399673462, -0.2745416760444641, -0.25739508867263794, -0.8953052759170532, 0.7048161625862122, -0.19527271389961243, -0.18413858115673065, 0.589272141456604, 0.6002418994903564, 1.025371789932251, 1.1873259544372559, 0.04470769688487053, -0.35047757625579834, 0.82682204246521, -0.6350476741790771, -0.7600568532943726, -0.8929235339164734, 0.5969859957695007, -0.41077977418899536, 0.3513191342353821, -0.37135109305381775, -1.3644160032272339, -0.7971470952033997, -0.6391584277153015, -0.3305952250957489, -0.3764340877532959, 0.62578946352005, 0.7397653460502625, 0.28956466913223267, -0.8498998284339905, 0.4288421869277954, 0.14293448626995087, -0.6156700849533081, 0.28727585077285767, -0.014912296086549759, 0.4960823059082031, -0.3995346128940582, -1.318329930305481, 0.4900743067264557, 0.43828320503234863, -0.43232378363609314, -0.09209417551755905, -0.46666112542152405, -0.8411011695861816, -0.028682876378297806, 0.022522682324051857, -0.2681750953197479, 1.22225022315979, 0.012697521597146988, -1.50479257106781, 0.5064380168914795, -0.46244731545448303, 0.08021705597639084, 0.2554658353328705, -0.052701435983181, -0.2690485417842865, -0.0977175161242485, -0.10939179360866547, 0.3481960892677307, 0.3705928325653076, -0.1581917554140091, -0.07428384572267532, 0.33419501781463623, -0.3889228105545044, 0.19460651278495789, -0.07880627363920212, 1.061596155166626, -0.8812949061393738, -0.437283992767334, 0.4962761402130127, 0.46784907579421997, 0.4101773798465729, -0.6371356844902039, -0.7315662503242493, -1.0383764505386353, 0.6325426697731018, -0.8245925903320312, 1.2131118774414062, -0.4911838471889496, -0.30901995301246643, -0.35510826110839844, -0.5881029963493347, 0.0602322593331337, -0.3985251784324646, 0.600606381893158, -0.03350886330008507, 0.5989385843276978, -0.4723547399044037, -0.5459818840026855, 0.13347965478897095, -0.06491012126207352, -0.8464243412017822, -0.03945959359407425, 0.5120576024055481, 1.2235718965530396, -0.3849388062953949, 0.11575746536254883, -0.2811180353164673, 0.06425198912620544, -0.7243995070457458, 1.3028948307037354, -0.22209355235099792, 0.43938860297203064, -0.2969905734062195, 0.007773533929139376, 0.1709558218717575, -0.21194912493228912, 0.5233433842658997, -0.573893129825592, -0.33673882484436035, 0.5057188272476196, -0.43370646238327026, 1.310166835784912, -0.026669232174754143, 0.356134295463562, -0.03872235119342804, -0.7117707133293152, -0.2017247974872589, 0.49193042516708374, -0.533039927482605, -0.482653945684433, 0.30129924416542053, 0.584363579750061, -0.34546682238578796, 0.4642264246940613, 0.6712173819541931, 0.724371612071991, -0.6505476832389832, 0.4848169982433319, 0.8434138298034668, -0.4138069748878479, 0.43392083048820496, 0.542223334312439, 0.4429144561290741, 0.4403989017009735, 0.17399555444717407, -0.16685524582862854, 0.4776332676410675, -0.29487258195877075, -0.05044367536902428, 0.7025154232978821, 0.6586401462554932, 1.0566105842590332, 0.540107250213623, -0.4244571924209595, -0.4687269330024719, 0.1212933287024498, 0.4612908363342285, 1.6898845434188843, -0.2837982773780823, -0.070445716381073, -1.2825486660003662, -0.18669778108596802, -0.5692561864852905, 0.21817632019519806, -0.03494895622134209, 0.3275946378707886, -0.8077983260154724, -1.199556589126587, 1.2025786638259888, -0.030746860429644585, 1.0642644166946411, -0.6120579242706299, 0.00047820189502090216, -0.14931493997573853, -0.09518791735172272, -0.7728992104530334, -0.43935006856918335, 0.1309119015932083, -0.42119407653808594, 0.0838778167963028, -0.416432648897171, -0.4440597593784332, -0.14193952083587646, -0.8995164632797241, 0.8406673073768616, -0.6057074666023254, -0.20201314985752106, 0.16562986373901367, 0.6850826740264893, -0.8104474544525146, -1.1857913732528687, 0.1413852423429489, 0.21657414734363556, -0.40395835041999817, 0.14995841681957245, 0.5526029467582703, 0.35926586389541626, -0.009413392283022404, -0.11544900387525558, 0.3633085787296295, 0.17214959859848022, -0.12249670177698135, 0.8056970834732056, -0.20407292246818542, 0.32717210054397583, -1.0137532949447632, 0.9971972107887268, 0.23765721917152405, -0.2071128934621811, 0.6276119351387024, -0.1782766431570053, -0.5550561547279358, 0.6648598909378052, -0.38224971294403076, -0.41605570912361145, -1.3969461917877197, 0.08471102267503738, 0.23608005046844482, -0.34776511788368225, 0.4395493268966675, -0.10306296497583389, 0.28700703382492065, -0.01693335734307766, 0.8533341884613037, 0.32554247975349426, -0.49739494919776917, 0.7790746092796326, -0.38338589668273926, 0.6658401489257812, 0.2947360575199127, 0.019787795841693878, -0.4311021864414215, -0.5543739199638367, -0.8657861351966858, -0.34428009390830994, 0.07747301459312439, -0.29231691360473633, -0.05741279199719429, 0.244245246052742, -0.9148703217506409, -0.09227564930915833, 0.3712845742702484, -0.9445227980613708, -0.3170567452907562, 0.37713053822517395, -0.321325421333313, -0.18600429594516754, -1.1454031467437744, -1.5909128189086914, -0.057276651263237, -0.879429817199707, -0.814932644367218, 0.2146044224500656, 0.2914089858531952, -0.24499672651290894, -0.13137494027614594, -0.16822902858257294, -0.26973599195480347, 0.9476743936538696, -0.8392360210418701, 1.204899549484253, -0.06184014678001404, 0.07426313310861588, -0.0999751091003418, 0.12163300067186356, 0.7263419032096863, -0.14309866726398468, 0.1647445261478424, -0.7204657793045044, 0.29629772901535034, -0.13151180744171143, -0.40498486161231995, -0.2614729702472687, 0.42585209012031555, 0.5011727809906006, -0.2655201554298401, 0.07052125036716461, 0.42748746275901794, 1.0052725076675415, -1.0055363178253174, -0.25845885276794434, 0.11843819916248322, 1.3136494159698486, 0.32201087474823, -0.3584887683391571, 0.18503308296203613, 0.6949158906936646, 0.0808626040816307, -0.37972286343574524, -0.15427158772945404, -0.22232197225093842, -0.5462889671325684, 0.6104868054389954, 2.2278189659118652, -0.024007486179471016, -0.2820185720920563, -0.9791213870048523, 0.45876654982566833, -1.1915695667266846, -0.34897294640541077, 0.36653995513916016, 0.5571308135986328, 0.7652927041053772, -0.6976624131202698, -0.47887343168258667, -0.37987762689590454, 0.3800853192806244, 0.067346952855587, -0.3742350935935974, -0.8633338809013367, -0.18440920114517212, 0.3918776214122772, 0.2563200891017914, 0.21416720747947693, -0.5492876768112183, 0.8215452432632446, 14.90121841430664, 0.8716383576393127, -0.01785668544471264, 0.9193019270896912, 0.6657767295837402, 0.3602592945098877, -0.15151061117649078, -0.4359103739261627, -1.0421695709228516, -0.27567365765571594, 1.5666093826293945, -0.038584500551223755, 0.7851887941360474, 0.21889609098434448, 0.23653526604175568, 0.3448982238769531, -0.2292119562625885, 0.5238410830497742, 0.6549869775772095, -1.4918416738510132, 0.7678577899932861, 0.09387851506471634, 0.45704835653305054, 0.8202926516532898, 0.29642781615257263, 0.9698856472969055, 0.1263880878686905, -0.4629385769367218, 0.4062771201133728, -0.07677283138036728, 0.48901262879371643, -0.5607537627220154, 0.5373731255531311, 0.6630508303642273, -0.4220753610134125, -0.11400599777698517, -0.8207558989524841, -1.081777572631836, 0.11791792511940002, -0.38428714871406555, -0.5030928254127502, -0.2605384886264801, -0.12252344936132431, 0.3033559024333954, -0.1084819957613945, 0.0891733318567276, -0.41460299491882324, 1.318637490272522, -0.17958225309848785, 0.08084187656641006, 0.3474879860877991, 0.20402465760707855, 0.3147147297859192, 0.20582710206508636, 0.10034414380788803, 0.2899794280529022, 0.1574219912290573, 0.28358232975006104, -0.8839329481124878, 0.25948503613471985, -0.09715709835290909, -0.25348973274230957, -0.2004261165857315, 0.6240665912628174, 0.18690715730190277, 0.036477841436862946, -0.4486812949180603, 0.7832136750221252, 0.5294128656387329, 0.32903507351875305, -0.28312796354293823, -0.15963344275951385, 0.31424301862716675, -0.6775417923927307, 0.28472837805747986, 0.37929198145866394, -0.0075175566598773, -0.5490823984146118, -0.7148696184158325, -0.46963635087013245, 0.12310557812452316, -0.817151665687561, -0.604306161403656, 0.8139201402664185, -0.1503988355398178, -0.040647976100444794, 0.225574791431427, -0.5685436129570007, -0.3178386092185974, 0.9539715647697449, -1.3787899017333984, -1.1437358856201172, 0.6061664819717407, -0.2279968410730362, 0.0001981990790227428, -0.031575705856084824, 1.5689153671264648, -0.27564537525177, -0.6838539242744446, -0.033013880252838135, 0.47504955530166626, 0.44770801067352295, -0.3558677136898041, -0.6843376755714417, 0.8727740049362183, 0.5878366231918335, -0.11214720457792282, 0.02347676455974579, -0.10310574620962143, 0.2817418873310089, -1.4069123268127441, -0.27951574325561523, 0.8504772186279297, -0.9418337345123291, -0.4735611379146576, -0.625790536403656, -1.2167805433273315, 0.14755426347255707, 0.7893847227096558, -0.358950138092041, 0.3253234624862671, -0.08315445482730865, 0.04321100935339928, -0.07454743981361389, -0.7159315347671509, -0.06841585785150528, 0.16968710720539093, -0.8078888058662415, -0.53791743516922, 0.17664049565792084, 0.4143854081630707, -0.998773992061615, -0.8373507261276245, -0.3189031481742859, 0.012993773445487022, 0.1924075484275818, 0.6976851224899292, -0.5311498045921326, 0.4711805284023285, 0.7133423686027527, -0.277981162071228, -0.9401094913482666, -0.22509077191352844, -0.7714734673500061, -0.04272574931383133, 0.5790225267410278, 0.629030168056488, -0.13690824806690216, -0.3538743853569031, 0.8223811984062195, 0.27441754937171936, -0.20543839037418365, -0.6811690330505371, 0.03342048451304436, 0.4483335018157959, -0.46859458088874817, 0.2177802324295044, -0.048044417053461075, -0.4830453395843506, 0.15222856402397156, 0.46615543961524963, 1.1208698749542236, -0.1320163458585739, -0.4981604218482971, 0.5386854410171509, 0.2017202228307724, 0.0223860926926136, -0.41724392771720886, -0.12179724127054214, -1.0172570943832397, 0.0390656515955925, -0.9760395884513855, 0.23006507754325867, -1.4382981061935425, -0.5345836281776428, 0.18897537887096405, 0.11181140691041946, 0.016457155346870422, 0.24202050268650055, 0.3084687888622284, -0.2284853458404541, -0.11820869147777557, -0.38443076610565186, 0.4227679967880249, 0.7209823131561279, -0.5952892303466797, -0.1003737673163414, -0.11867453157901764, -0.0480654314160347, 0.5397744178771973, 0.6767488718032837, -0.3320121169090271, -0.7998054623603821, -1.6134511232376099, 0.017489172518253326, -0.2557644546031952, -0.3658544719219208, -0.3982146084308624, 0.48504847288131714, 0.3870839476585388, 0.04284732788801193, -0.1764831691980362, -0.1309504508972168, -0.09380500763654709, -0.49922579526901245, -0.033048298209905624, -0.3532702922821045, 0.03892082720994949, 0.29599612951278687, -0.8167757987976074, -0.29588988423347473, 0.6795068383216858, -0.05185790732502937, -1.3519712686538696, -0.9760621786117554, 0.17460018396377563, -0.8936364054679871, 0.29098859429359436, -0.3730870485305786, 0.16093064844608307, -0.802821934223175, -0.3402000367641449, 0.014553959481418133, 0.11994561553001404, -0.3555440306663513, 0.8325695395469666, 0.07631029188632965, -0.6858093738555908, -0.7167619466781616, 0.43108096718788147, -0.315771222114563, -0.0988323986530304, 0.2787263095378876, 0.32977718114852905, -0.7955277562141418, 0.5605151057243347, 0.4221172630786896, 0.32337549328804016, -0.7002317309379578, -0.6005586981773376, 0.3741512894630432, -0.10303464531898499, -0.4698202908039093, 1.2824088335037231, -0.46941301226615906, -1.50668466091156, 0.05378805100917816, -1.1018048524856567, -0.5448199510574341, -0.23211117088794708, 0.832663893699646, 0.16726617515087128, 0.3567506968975067, -0.5052440762519836, -0.5493075847625732, -0.13910119235515594, 0.05856605991721153, -0.3106369078159332, 0.7469781041145325, -0.624584972858429, -0.7047755122184753, 0.6559969782829285, 0.5665135979652405, -0.709475040435791, -0.42544376850128174, -0.39512985944747925, -0.4979964792728424, 0.4372718632221222, 0.526746392250061, -0.6943365335464478, -0.06180039420723915, 0.5231834053993225, 0.10922267287969589, 0.385570764541626, 0.2604857385158539, -0.07987038791179657, 0.22672046720981598, 0.8769820928573608, -0.04944048449397087, -0.8165009617805481, -1.210553765296936, 1.3813925981521606, 1.123722791671753, -1.0209931135177612, 0.3657546639442444, 0.1218007430434227, -0.9540367126464844, 0.8470587730407715, -0.0784187912940979, 0.22670327126979828, 0.7160676121711731, -0.320731520652771, 0.27633848786354065, 0.5150015950202942, -0.6350944638252258, -0.2841958999633789, 0.762794554233551, 0.8137101531028748, 0.8813195824623108, 0.4574718177318573, -0.1567372828722, 1.1386710405349731, -0.1686014086008072, 0.036255575716495514, 0.7189252972602844, 0.7844968438148499, -0.15669043362140656, 0.32243868708610535, -0.0626654326915741, 0.6972630620002747, -0.9533605575561523, -0.6796346306800842, -0.023788804188370705, 0.5343489646911621, 0.026871511712670326, 0.6086838245391846, 0.8404765129089355, 0.5966699123382568, 0.5314626097679138, 0.4098011255264282, 0.6510642766952515, -0.4901675283908844, -0.14830908179283142, 0.00749962730333209, -0.4620363414287567, 0.14881768822669983, -0.2478667050600052, -0.1736980378627777, -0.4304126799106598, -0.41690489649772644, 0.37815171480178833, 0.08694827556610107, 0.7077227830886841, 1.5119787454605103, 0.6543159484863281, 0.3481416404247284, -0.2915423810482025, -0.705854594707489, -0.3424084782600403, -1.1727619171142578, -0.05740128085017204, -0.6798248887062073, -0.4001668095588684, 0.4919079542160034, 0.09449460357427597, -0.1941865235567093]}, "authors": [{"authorId": "2309177612", "name": "Tamzeed Mahfuz"}, {"authorId": "2309179435", "name": "Satak Kumar Dey"}, {"authorId": "2309177577", "name": "Ruwad Naswan"}, {"authorId": "2309179134", "name": "Hasnaen Adil"}, {"authorId": "2184774573", "name": "Khondker Salman Sayeed"}, {"authorId": "2184775655", "name": "Haz Sameen Shahgir"}], "references": [{"paperId": "53a803388e83ae89261624099d7be4287ace67cb", "title": "DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model"}, {"paperId": "4bfc97e8e2533669d1ff58955583759adb7476fc", "title": "Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study"}, {"paperId": "ef62f95c16f668f031d649799cbd79081c6d2b0f", "title": "A Careful Examination of Large Language Model Performance on Grade School Arithmetic"}, {"paperId": "abdceff7d7983cdede9a5aabe6a476d4c72e41a3", "title": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"}, {"paperId": "09d75de9475a516e0d24ca09931b4269480a9453", "title": "BEnQA: A Question Answering and Reasoning Benchmark for Bengali and English"}, {"paperId": "53f4fb0e9972989194368faf288ff8e3cba5bd60", "title": "Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference"}, {"paperId": "10a491a5cc5855ed58a26b2763814a6310233bdf", "title": "A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bangla Texts"}, {"paperId": "1e0caa706e9d9fdad82d6713fa20b52975a1703b", "title": "At Which Training Stage Does Code Data Help LLMs Reasoning?"}, {"paperId": "dd41f3d40f89c93ba866ba482c3c8c617a0b0bad", "title": "BenLLM-Eval: A Comprehensive Evaluation into the Potentials and Pitfalls of Large Language Models on Bengali NLP"}, {"paperId": "5b30e6cc9095a659ab62e458db49fd8da685bdbd", "title": "BanglaGPT: A Generative Pretrained Transformer-Based Model for Bangla Language"}, {"paperId": "c96297261467b5daa2d01227496a70d444602434", "title": "Baichuan 2: Open Large-scale Language Models"}, {"paperId": "cb587eaea753ee38013afb7e5b6bc8fba1248d04", "title": "RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback"}, {"paperId": "47030369e97cc44d4b2e3cf1be85da0fd134904a", "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "bb9a44c94a89dbe00f0061d05c70a45064ff6ea6", "title": "CMMLU: Measuring massive multitask language understanding in Chinese"}, {"paperId": "c1c98ef93fb6474837961ef300cf3d8e7d3a0cd0", "title": "BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer"}, {"paperId": "32ac52069e562d4f900afee70bdca63f53461481", "title": "QLoRA: Efficient Finetuning of Quantized LLMs"}, {"paperId": "28085f480ce456a376ebace9b899e3bc93dbc048", "title": "TinyStories: How Small Can Language Models Be and Still Speak Coherent English?"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "a87576ff578ec1781f9cb48934c3e837144afdcb", "title": "Towards Leaving No Indic Language Behind: Building Monolingual Corpora, Benchmark and Models for Indic Languages"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "8b284502ce1baf68a0c60a1b3fadd20a1fb76300", "title": "BanglaParaphrase: A High-Quality Bangla Paraphrase Dataset"}, {"paperId": "e19b54ad4c1c8af045069e9cac350ffc2ce60e1a", "title": "No Language Left Behind: Scaling Human-Centered Machine Translation"}, {"paperId": "8ce8d0a34759f0d94abfc11b4478cc97ad6ed162", "title": "BanglaNLG and BanglaT5: Benchmarks and Resources for Evaluating Low-Resource Natural Language Generation in Bangla"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "f17b380a684d369850533c423c83f20a3fc3f3f0", "title": "IndicBART: A Pre-trained Model for Indic Natural Language Generation"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "ecf5618b513aa5c4d5bf62ca251923a188251117", "title": "XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages"}, {"paperId": "789b8487da7188442085983caba3ffaae05531e9", "title": "The Flores-101 Evaluation Benchmark for Low-Resource and Multilingual Machine Translation"}, {"paperId": "96afd5a4bcf814fc9db32b1fd0324c3dbb63ed61", "title": "MuRIL: Multilingual Representations for Indian Languages"}, {"paperId": "e77c8f93bf92bc9198c3b8b981d223bf56aa707f", "title": "BanglaBERT: Language Model Pretraining and Benchmarks for Low-Resource Language Understanding Evaluation in Bangla"}, {"paperId": "ba62052b2c85f6ab6963f9e9247780ae38926a8a", "title": "Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New Datasets for Bengali-English Machine Translation"}, {"paperId": "053b1d7b97eb2c91fc3921d589c160b0923c70b1", "title": "Learning to summarize from human feedback"}, {"paperId": "b896b846ae180d804c7290d8b9ae9ffc55325866", "title": "Language-agnostic BERT Sentence Embedding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "c1601b8b7a60fe4e8fa121a7cf2acd9ec4a8043c", "title": "Processing South Asian Languages Written in the Latin Script: the Dakshina Dataset"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "bb669de2fce407df2f5cb2f8c51dedee3f467e04", "title": "The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "b89ef853319e2cef3d2bffca9a155d34c16cb596", "title": "BaTEClaCor: A Novel Dataset for Bangla Text Error Classification and Correction"}, {"paperId": "155f9a7bc82cc2e05d5064c903632c4ec15e6875", "title": "CrossSum: Beyond English-Centric Cross-Lingual Abstractive Text Summarization for 1500+ Language Pairs"}, {"paperId": "013abd0a9ce671a98dc659679b3a1e49988e5c45", "title": "SentNoB: A Dataset for Analysing Sentiment on Noisy Bangla Texts"}, {"paperId": null, "title": "2023. Mistral 7b"}, {"paperId": null, "title": "2024. Jetmoe: Reaching llama2 performance with 0.1 m dollars"}, {"paperId": null, "title": "2023 How multilingual is multilingual llm?"}, {"paperId": null, "title": "2022. Crosslingual generalization through multitask finetuning"}, {"paperId": null, "title": "2024. Scaling instruction-finetuned language models"}, {"paperId": null, "title": "2024. Aya 23: Open weight re-leases to further multilingual progress"}, {"paperId": null, "title": "2023. Apurba presents bhashabhrom: Eee day 2023 datathon"}, {"paperId": null, "title": "2023. Gemini: a family of highly capable multimodal models"}, {"paperId": null, "title": "2023. Bangla grammatical error detection using t5 trans-former model"}]}