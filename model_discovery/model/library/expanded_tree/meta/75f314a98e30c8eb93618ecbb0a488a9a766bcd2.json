{"paperId": "75f314a98e30c8eb93618ecbb0a488a9a766bcd2", "abstract": "Large Language Models (LLMs) have demonstrated great potential as generalist assistants, showcasing powerful task understanding and problem-solving capabilities. To deploy LLMs as AI assistants, it is crucial that these models exhibit desirable behavioral traits, such as non-toxicity and resilience against jailbreak attempts. Current methods for detoxification or preventing jailbreaking usually involve Supervised Fine-Tuning (SFT) or Reinforcement Learning from Human Feedback (RLHF), which requires finetuning billions of parameters through gradient descent with substantial computation cost. Furthermore, models modified through SFT and RLHF may deviate from the pretrained models, potentially leading to a degradation in foundational LLM capabilities. In this paper, we observe that surprisingly, directly editing a small subset of parameters can effectively modulate specific behaviors of LLMs, such as detoxification and resistance to jailbreaking. Specifically, for a behavior that we aim to avoid, we employ a linear classifier, which we term the behavior probe, to classify binary behavior labels within the hidden state space of the LLM. Using this probe, we introduce an algorithm to identify a critical subset of LLM parameters that significantly influence this targeted behavior. Then we directly edit these selected parameters by shifting them towards the behavior probe. Such a direct parameter editing method necessitates only inference-level computational resources. Experiments demonstrate that in the representative detoxification task, our approach achieves reductions of up to 90.0\\% in toxicity on the RealToxicityPrompts dataset and 49.2\\% on ToxiGen, while maintaining the LLM's general capabilities in areas such as common sense, question answering, and mathematics. Our code is available at https://github.com/lucywang720/model-surgery.", "venue": "", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "It is observed that surprisingly, directly editing a small subset of parameters can effectively modulate specific behaviors of LLMs, such as detoxification and resistance to jailbreaking."}, "embedding": {"model": "specter_v2", "vector": [0.23887263238430023, 0.6228306889533997, -0.2239019125699997, 0.025718629360198975, -0.2574845850467682, -0.3426549434661865, 0.6928033828735352, -0.036410603672266006, -0.29214417934417725, -0.08754005283117294, -0.13412907719612122, 0.01947788894176483, 0.05594271421432495, 0.37865307927131653, -0.44762107729911804, -0.10884866118431091, -0.7330262064933777, 0.5267817378044128, -0.4275602698326111, -0.3296814262866974, 0.03527309000492096, -0.15491683781147003, -0.5035390257835388, 0.20196354389190674, 0.7354774475097656, 0.20033489167690277, -0.08486104756593704, 0.7312353849411011, 0.1380906105041504, 0.6153216361999512, 0.23624636232852936, -0.1258777678012848, -0.07902666926383972, -0.02189357951283455, -0.3516026735305786, 0.33892881870269775, 0.16438136994838715, -0.29847148060798645, -0.3702387809753418, 0.8417763710021973, -0.4721553921699524, 0.17015676200389862, 0.6753472685813904, -0.7763048410415649, -0.6944743990898132, 0.6712023615837097, 0.7170031666755676, 0.5992603898048401, 0.15246792137622833, -0.07373927533626556, 1.0170700550079346, -1.033194899559021, 0.24540948867797852, 1.2609779834747314, 0.42711907625198364, 0.6278718113899231, -0.36355987191200256, -0.7371610403060913, 0.7257064580917358, 0.01698051020503044, -1.0272808074951172, -0.06536809355020523, -0.2026333063840866, -0.2690623104572296, 1.6414525508880615, -0.370544970035553, -0.3428206741809845, 0.7385385036468506, -0.021648092195391655, 1.3669451475143433, 0.18041545152664185, -0.5376814007759094, -0.16412955522537231, 0.6813156008720398, 0.07472790032625198, 1.0537302494049072, -0.269516259431839, 0.3086566925048828, -0.5619051456451416, -0.4687732756137848, 0.3721069395542145, -0.13899512588977814, -0.3380846679210663, -0.08027784526348114, -0.12023618072271347, 0.6867334246635437, 0.5845097303390503, 0.8250492811203003, -0.20217536389827728, 0.5469154715538025, -0.013527224771678448, 0.6585392951965332, -0.3024657666683197, 1.2552051544189453, -0.2734256982803345, 0.6320895552635193, -0.341625839471817, 0.5553719997406006, 0.07430462539196014, 0.6398935317993164, -0.1184127926826477, 0.151152566075325, -0.8855555057525635, 0.18290315568447113, 1.3369578123092651, 0.08564981818199158, 0.6834908723831177, -0.7698889374732971, 0.02018304541707039, -0.13878919184207916, 0.7857206463813782, -0.47983115911483765, -0.49398481845855713, -0.11806496977806091, -0.5133817195892334, -1.199116587638855, -0.3310321271419525, 0.19191724061965942, -0.7511013746261597, 0.9460251927375793, -0.2877950966358185, -0.09836994111537933, -0.24343359470367432, 0.3689938485622406, 0.39302027225494385, 0.49391111731529236, 0.6283665299415588, 0.083652064204216, 0.4999909996986389, -0.6403878927230835, -0.4760798513889313, -1.0820029973983765, 1.145194411277771, 0.15530182421207428, 0.5083991289138794, 0.24386686086654663, -1.2855026721954346, -0.6367499828338623, -0.9432916045188904, 0.24461640417575836, -0.7307350039482117, 0.4817124605178833, 1.0446078777313232, 0.1870398074388504, -0.48384734988212585, 0.7298647165298462, 0.01501517090946436, -0.2742733955383301, 0.015156475827097893, 0.5237330198287964, 0.013103528879582882, -0.6556219458580017, -1.172468662261963, 0.543677806854248, 0.30448779463768005, -0.5293285250663757, -0.6966270208358765, -0.6231476068496704, -1.2465929985046387, -0.163800910115242, 0.5755009055137634, -0.5277640223503113, 1.5360817909240723, 0.21342720091342926, -1.0674021244049072, 0.7879276275634766, 0.04479161649942398, 0.23825867474079132, 0.4945908188819885, 0.015418934635818005, -0.5521394610404968, -0.3914496600627899, -0.22409237921237946, 0.4298625588417053, 0.43296030163764954, -0.7297168374061584, 0.2657054364681244, 0.45611339807510376, 0.4061560332775116, -0.3606482744216919, 0.019993754103779793, 0.5607556700706482, -0.044070299714803696, -0.09588007628917694, -0.08717633783817291, 0.2818477749824524, -0.15307095646858215, 0.04214107245206833, -0.4750327467918396, -1.206204891204834, 0.403495728969574, 0.20539002120494843, 1.2818621397018433, -0.9305325746536255, -0.3905782103538513, -0.34357914328575134, 0.011490315198898315, -0.11645306646823883, -0.7057220339775085, 0.8062983155250549, -0.48297563195228577, 0.5925842523574829, -0.9829725623130798, -1.1974661350250244, 0.18662957847118378, -0.12385280430316925, -0.39080846309661865, -0.040849361568689346, 0.2897058427333832, 1.1441364288330078, -0.8440324664115906, 0.3403097093105316, -0.005510818213224411, -0.05479014664888382, -1.414697527885437, 1.3834304809570312, -0.6145211458206177, 0.6103655695915222, -0.11272731423377991, -0.08574259281158447, -0.14155109226703644, -0.5362895131111145, 0.0830320417881012, -0.4313508868217468, 0.20307070016860962, 0.13281966745853424, -0.3030875027179718, 1.2845147848129272, -0.3652700185775757, -0.2617577612400055, -0.025346830487251282, -0.47797173261642456, -0.07587521523237228, 0.39205873012542725, -0.48882368206977844, -0.30282554030418396, 0.09050644934177399, 0.41462990641593933, -0.4126272201538086, -0.3276621699333191, 0.28634750843048096, 0.373818576335907, -0.609237015247345, 0.14706183969974518, 0.2345423698425293, -0.920181393623352, 0.5592073202133179, 0.38442903757095337, 0.7530573010444641, -0.037126097828149796, 0.8556169271469116, 0.1607521027326584, 0.59197598695755, -0.7317072749137878, -0.19736799597740173, 0.6493885517120361, 0.6679204106330872, 0.5028894543647766, -0.058464761823415756, -0.7060138583183289, -0.1061072126030922, -0.025214776396751404, 0.4337407350540161, 1.379088282585144, -0.05534375086426735, -0.31584152579307556, -0.6879810094833374, -0.2869850993156433, -0.2452368289232254, 0.5046793222427368, -0.6565762162208557, -0.7660166025161743, -0.3717400133609772, -1.234186053276062, 0.8009077310562134, 0.19269132614135742, 1.0706532001495361, -0.8471391201019287, -0.06693044304847717, -0.21821917593479156, 0.39241376519203186, -0.6640672087669373, -0.5952646732330322, 0.1788749396800995, -0.25215989351272583, -0.2559317350387573, 0.28971442580223083, -0.08632808178663254, 0.48509681224823, -0.6369030475616455, 0.7558914422988892, 0.012474858202040195, -0.4546814560890198, 0.3920803666114807, 0.782067060470581, -0.41295188665390015, -1.0685573816299438, 0.010952460579574108, 0.15893080830574036, -0.1373026818037033, -0.031545888632535934, 0.42785322666168213, 0.22692807018756866, -0.05585359409451485, -0.9218248128890991, -0.12217698991298676, 0.027497295290231705, 0.2608676850795746, 0.16793295741081238, -0.5398151874542236, -0.061087701469659805, -1.5173531770706177, 1.3140679597854614, -0.04759130999445915, -0.1370648890733719, 0.45951950550079346, -0.8911083936691284, -0.3937675654888153, 0.7815410494804382, -0.9326995611190796, -0.06547795981168747, -0.8764214515686035, 0.6396209001541138, 0.2447309046983719, -0.4844546616077423, 0.5629064440727234, 0.19249525666236877, -0.0013313983799889684, 0.7170814275741577, 0.614532470703125, -0.10045702755451202, -0.3904057443141937, 0.47945642471313477, -0.6797816753387451, 0.47806316614151, -0.1110117956995964, 0.43559715151786804, -0.36250826716423035, -0.27564579248428345, -0.41947340965270996, -0.7288157939910889, -0.05223628506064415, 0.06402011215686798, 0.2283782809972763, 0.018940292298793793, -0.537168025970459, -1.0178381204605103, 0.16325706243515015, -0.8578661680221558, -0.7336411476135254, 0.1107521578669548, -0.555142879486084, -0.13471876084804535, -0.8930070996284485, -1.120206594467163, -0.3910093307495117, -0.04878190532326698, -1.060291051864624, 0.4527372121810913, 0.030048690736293793, -0.7656686305999756, -0.6439705491065979, 0.2603852450847626, -0.03424248844385147, 0.7456319332122803, -0.4641835391521454, 1.3468257188796997, 0.21164576709270477, -0.15984496474266052, -0.38286373019218445, 0.3796803653240204, 0.32904577255249023, -0.12762309610843658, 0.0031767634209245443, -0.868420422077179, -0.18515492975711823, -0.1925145834684372, -0.6183586120605469, -0.15611328184604645, -0.16848108172416687, 0.9219446182250977, -0.2811805307865143, -0.44848281145095825, 0.281020849943161, 0.9311351180076599, -0.46476665139198303, -0.053065136075019836, 0.25370362401008606, 0.9005378484725952, 0.14965450763702393, -0.41849470138549805, 0.7295305132865906, 0.6150547862052917, 0.39382582902908325, -0.02960340306162834, 0.008872793056070805, 0.30513837933540344, -0.7019399404525757, 0.9113011360168457, 1.0450935363769531, 0.5608896017074585, -0.1307351142168045, -1.033737063407898, 0.41591715812683105, -1.1381020545959473, -0.169821098446846, 0.8505595922470093, 0.592369794845581, 0.7641816139221191, -0.539981484413147, -0.4958035349845886, -0.18206043541431427, -0.06999711692333221, -0.1370154619216919, -0.6681250929832458, -0.6882633566856384, 0.23461414873600006, 0.030897360295057297, -0.23791854083538055, 0.8483108878135681, -0.5161728858947754, 0.6071349382400513, 15.091374397277832, 0.4992043375968933, -0.05186433717608452, 0.5374576449394226, 0.41421592235565186, 0.562263548374176, -0.395111620426178, -0.29890936613082886, -0.83646559715271, -0.34924399852752686, 0.9040781855583191, 0.11468285322189331, 1.0823167562484741, 0.06678064912557602, 0.05202070623636246, 0.08524458855390549, -0.715179443359375, 0.7151255011558533, 0.6481380462646484, -0.9828890562057495, 0.6501414775848389, 0.06030074134469032, 0.5797368884086609, 0.1656295210123062, 1.0479964017868042, 0.9302703142166138, 0.41808778047561646, -0.8708493709564209, 0.6293345093727112, 0.3952670991420746, 0.8207063674926758, 0.1845472753047943, 0.053809501230716705, 1.0377089977264404, -0.46463724970817566, -0.6530697345733643, -0.452904611825943, -1.1242798566818237, -0.13216105103492737, -0.3687191605567932, -0.7785990834236145, -0.6786788702011108, -0.3913969099521637, 0.6529309153556824, -0.3492026925086975, 0.4882592260837555, -0.530565619468689, 0.5311813354492188, 0.04863124340772629, 0.2756136357784271, 0.3087727129459381, 0.5195692181587219, 0.23911237716674805, -0.20040535926818848, -0.09141156822443008, 0.12477554380893707, 0.581885814666748, 0.8853462934494019, -0.7800207138061523, -0.22294731438159943, -0.4598449766635895, -0.4165104627609253, 0.08257639408111572, 0.6756594777107239, 0.8834076523780823, 0.07910389453172684, 0.019865892827510834, 0.2761349678039551, 0.6825617551803589, 0.37221387028694153, -0.005058710929006338, 0.18114466965198517, 0.1475382149219513, -0.3021266758441925, -0.342765212059021, 0.4899405241012573, -0.1710876077413559, -0.6824994683265686, -0.6807799935340881, -0.8078646659851074, 0.23668788373470306, -1.0138438940048218, -0.9196223616600037, 0.5753147006034851, -0.01297466829419136, -0.2952648401260376, 0.06184771656990051, -0.7484516501426697, -0.271578848361969, 0.056710418313741684, -1.2877458333969116, -0.8501653671264648, 0.18305154144763947, -0.1450536698102951, -0.4703644812107086, 0.02440192550420761, 1.7258049249649048, -0.03829948976635933, -0.7341402173042297, 0.42668402194976807, -0.08378289639949799, -0.4217354655265808, -0.014326426200568676, -1.0675283670425415, 0.5874621868133545, -0.08780285716056824, -0.17715910077095032, 0.8003975749015808, 0.3233705163002014, 0.054503194987773895, -0.7343270182609558, -0.0757099911570549, 0.6169692277908325, -1.4721202850341797, -0.29814252257347107, -0.6797810196876526, -1.0944699048995972, 0.3628592789173126, 0.16934162378311157, -0.4580455720424652, 0.29273951053619385, -0.2757602334022522, -0.826384425163269, 0.08129456639289856, -1.2239793539047241, 0.19368594884872437, 0.412418395280838, -0.941119372844696, -0.5025506019592285, 0.3796457052230835, 0.032422732561826706, -0.9660025238990784, -0.4606693685054779, -0.07079275697469711, -0.41712310910224915, 0.3336099088191986, 0.810397744178772, -0.8363333940505981, 0.37347063422203064, 0.3968147337436676, 0.17346319556236267, -1.1857587099075317, -0.40459346771240234, -0.9540577530860901, -0.04701623320579529, -0.23933789134025574, 0.9048945307731628, -0.4903186857700348, -0.24730661511421204, 1.3396531343460083, 0.28609901666641235, -0.1624906212091446, -0.25940603017807007, -0.11269966512918472, 0.4191667437553406, -0.23751389980316162, 0.15683315694332123, 0.23108288645744324, 0.10382462292909622, 0.1725514978170395, 0.16467881202697754, 0.9240588545799255, -0.43296322226524353, -0.45720118284225464, 0.509646475315094, -0.10163772106170654, -0.3880046010017395, -0.296305388212204, 0.072884701192379, -1.205480694770813, -0.04016746208071709, -1.2862753868103027, 0.18975165486335754, -0.6958853006362915, -0.3382962942123413, 0.3742749094963074, -0.16043365001678467, 0.22327478229999542, 0.16521641612052917, -0.32813429832458496, -0.4260823130607605, -0.2557194232940674, -0.47606655955314636, 0.5812249183654785, 0.9697822332382202, -0.9958555698394775, 0.1391301304101944, -0.25685039162635803, -0.4287380576133728, 0.3013466000556946, 0.31266558170318604, -0.7298809289932251, -0.6742905974388123, -1.0538885593414307, 0.5179843902587891, -0.33501264452934265, 0.2169121354818344, -0.6141722798347473, 0.7077111005783081, 0.15342994034290314, -0.17826037108898163, 0.7398183941841125, 0.4437917172908783, -0.8707061409950256, -0.41372889280319214, 0.5775538682937622, -0.9942057728767395, 0.3729766607284546, 0.2441064417362213, -0.5648949146270752, -0.15410956740379333, 0.3209952116012573, 0.0007780211744830012, -1.1706867218017578, -0.25637951493263245, 0.32222649455070496, -0.9750336408615112, -0.11319217085838318, -0.30071359872817993, 0.39528322219848633, -1.0469177961349487, -0.2818942070007324, -0.14555029571056366, 0.4880177974700928, -0.02769404463469982, 0.7153877019882202, 0.16024494171142578, -0.9435917735099792, 0.1914224773645401, 0.29513391852378845, 0.30601203441619873, -0.062133073806762695, 0.4716755449771881, 0.3767208158969879, -0.19859452545642853, 0.4729008674621582, 0.6125349998474121, 0.6484233736991882, -0.4897301197052002, 0.035721879452466965, 1.0661119222640991, -0.7134466171264648, 0.04616690054535866, 1.0535017251968384, 0.18089990317821503, -1.3753587007522583, 0.3491033613681793, -1.3220525979995728, -0.4282996952533722, -0.903335452079773, 0.6963081359863281, -0.2639288604259491, -0.20740826427936554, 0.17044170200824738, -0.4579813480377197, 0.254846453666687, -0.519119381904602, 0.0762559175491333, 0.580676257610321, -0.06651018559932709, -0.35899391770362854, 0.6069566011428833, 0.4062117040157318, -0.6765673756599426, -0.5026820302009583, -0.4180773198604584, -0.12131934612989426, 0.24016515910625458, 0.1486995667219162, -0.9935511350631714, -0.10384222865104675, 0.6662201881408691, 0.2770761251449585, 0.10654790699481964, -0.08699540793895721, -0.06193011254072189, -0.05681173503398895, 1.390212893486023, -0.10064180940389633, -0.5023913979530334, -0.2339007705450058, 0.916968584060669, 1.7727465629577637, -0.9555943608283997, 0.3194103538990021, -0.19548997282981873, -1.0163428783416748, 0.6110978722572327, 0.5888039469718933, -0.26490628719329834, 0.7513778805732727, -0.42771539092063904, 0.2217620611190796, -0.30049410462379456, -1.0016151666641235, 0.18351972103118896, 0.7460166215896606, 0.9251137375831604, 0.6689102053642273, 0.4917922914028168, 0.1765005886554718, 1.0417624711990356, 0.1535404473543167, 0.30143141746520996, 1.0672705173492432, 0.48533469438552856, -0.019506916403770447, -0.25364741683006287, -0.06100790202617645, 0.3124958574771881, -0.31379786133766174, -0.29936647415161133, -0.42488226294517517, 0.6190473437309265, 0.2699779272079468, 0.5377359390258789, 0.09662798047065735, 0.22551482915878296, 0.7871456742286682, 0.42717140913009644, 0.5388845205307007, -0.9275509715080261, -0.5601110458374023, -0.5846181511878967, -0.7524521350860596, -0.11128894984722137, -0.12817806005477905, -0.18700727820396423, -0.31043922901153564, 0.009924850426614285, 0.442746102809906, -0.05702350288629532, -0.11261198669672012, 1.2850176095962524, 0.5669072866439819, 0.05156010016798973, -0.22345133125782013, -0.3563968241214752, -0.7532528042793274, -1.088942289352417, -0.04636159911751747, -0.09941182285547256, -0.2518022358417511, -0.6955227255821228, -0.5498151779174805, -0.40236109495162964]}, "authors": [{"authorId": "2238105242", "name": "Huanqian Wang"}, {"authorId": "2256993684", "name": "Yang Yue"}, {"authorId": "2301205439", "name": "Rui Lu"}, {"authorId": "2311303932", "name": "Jingxin Shi"}, {"authorId": "2136104377", "name": "Andrew Zhao"}, {"authorId": "2219056193", "name": "Shenzhi Wang"}, {"authorId": "2235964292", "name": "Shiji Song"}, {"authorId": "2258319611", "name": "Gao Huang"}], "references": [{"paperId": "ce4fcd755402762f8f1fa08164061b8766405130", "title": "Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks"}, {"paperId": "b6b050477c32a493ef4becb23d7d19835203c064", "title": "DiveR-CT: Diversity-enhanced Red Teaming with Relaxing Constraints"}, {"paperId": "9c9ca3a8320c0babd9fc331cc376ffff32fe1f67", "title": "Online Merging Optimizers for Boosting Rewards and Mitigating Tax in Alignment"}, {"paperId": "5dd7c7654811a45f364ceca9fdbc2b4116e49eda", "title": "Towards Safer Large Language Models through Machine Unlearning"}, {"paperId": "f9863e1cb5ab60b0ad2892b0d003ffb2308ff187", "title": "Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning"}, {"paperId": "ecb7964c96e94bf362aae90aecd457401e07da27", "title": "Parameter-Efficient Detoxification with Contrastive Decoding"}, {"paperId": "26b2adbe089ea36617c3ec0aa009319929da0550", "title": "A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity"}, {"paperId": "6f9dbae279fa0c3a90d12f3b0f271dc8e6274817", "title": "A Survey of Reinforcement Learning from Human Feedback"}, {"paperId": "edd1dc1e8d7989f36c0e54f69f4aeb5e597edc8b", "title": "Steering Llama 2 via Contrastive Activation Addition"}, {"paperId": "15b8b6a8028b2b6e75b67dfb6aebaede36826cf8", "title": "Language Model Alignment with Elastic Reset"}, {"paperId": "37680e5cb6030e01f1a44a5abe2257972196ae26", "title": "Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2"}, {"paperId": "d030be820dd5e4739461f246ce248fba2df33f0a", "title": "Backdoor Activation Attack: Attack Large Language Models using Activation Steering for Safety-Alignment"}, {"paperId": "0f7308fbcae43d22813f70c334c2425df0b1cce1", "title": "Safe RLHF: Safe Reinforcement Learning from Human Feedback"}, {"paperId": "ac27dd71af3ee93e1129482ceececbae7dd0d0e8", "title": "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation"}, {"paperId": "d59523889679aee15992c4bf6e52b134186d07d3", "title": "The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets"}, {"paperId": "53e42ca0c344a0c87a7e4943aaba46762cb311bb", "title": "Chat Vector: A Simple Approach to Equip LLMs with Instruction Following and Model Alignment in New Languages"}, {"paperId": "9f923edcb6b8281d178c398b72f22190ba8247bf", "title": "Understanding, Predicting and Better Resolving Q-Value Divergence in Offline-RL"}, {"paperId": "a4c921bdef167ae54cc3a40643e6e3ed13d49a61", "title": "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions"}, {"paperId": "0b0debb710366cdff461938c80763eace1651af6", "title": "Code Llama: Open Foundation Models for Code"}, {"paperId": "965d15261b682fd3fd766311b99a11257322ac4c", "title": "Activation Addition: Steering Language Models Without Optimization"}, {"paperId": "9f859726b3d8dffd96a1f55de4122617751cc1b4", "title": "Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment"}, {"paperId": "838cd69a0b6c9c244a6eebb0f4742c0625132de6", "title": "An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning"}, {"paperId": "47030369e97cc44d4b2e3cf1be85da0fd134904a", "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "fbd2c8089870814449f9254a711041bbae145a82", "title": "How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources"}, {"paperId": "0d1c76d45afa012ded7ab741194baf142117c495", "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"}, {"paperId": "546d0624adfc6e18fb87d8cc77e7705bb9ea7445", "title": "LIMA: Less Is More for Alignment"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "e65b346d442e9962a4276dc1c1af2956d9d5f1eb", "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions"}, {"paperId": "2fe1ac0b09cc0f50eb83eef6c7c6b45ac8b12413", "title": "Mass-Editing Memory in a Transformer"}, {"paperId": "74eae12620bd1c1393e268bddcb6f129a5025166", "title": "Improving alignment of dialogue agents via targeted human judgements"}, {"paperId": "0286b2736a114198b25fb5553c671c33aed5d477", "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"}, {"paperId": "cf36236015c9f93f15bfafbf282f69e08bdc9c16", "title": "Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "996445d847f06e99b0bd259345408a0cf1bce87e", "title": "Locating and Editing Factual Associations in GPT"}, {"paperId": "5d49c7401c5f2337c4cc88d243ae39ed659afe64", "title": "Red Teaming Language Models with Language Models"}, {"paperId": "3dc7dc1bea9a4f70c02b6759a0bda7aca0005a9e", "title": "A General Language Assistant as a Laboratory for Alignment"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "399e7d8129c60818ee208f236c8dda17e876d21f", "title": "RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "4450493ecb806cb889b341ae8e430886f2549a61", "title": "GoEmotions: A Dataset of Fine-Grained Emotions"}, {"paperId": "83a820fe19944a7621238b8cfcc0b8a0cbc0f4b6", "title": "TyDi QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages"}, {"paperId": "38e69f83eb63e806c5db26b296d27e8d2a8f04c7", "title": "Challenges for Toxic Comment Classification: An In-Depth Error Analysis"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": null, "title": "2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"}, {"paperId": "fe5b2664159211f7a1a6cd959ef20dacae7175d8", "title": "CARER: Contextualized Affect Representations for Emotion Recognition"}, {"paperId": null, "title": "2022. Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned"}, {"paperId": null, "title": "2023. Resolving interference when merging models"}, {"paperId": null, "title": "2024. Countering reward over-optimization in llm with demonstration-guided reinforcement"}, {"paperId": null, "title": "2022. Toxigen: A large-scale machine-generated dataset for adversarial and implicit hate speech detection"}, {"paperId": null, "title": "2023. Editing models with task arithmetic"}, {"paperId": null, "title": "2023. The linear representation hypothesis and the geometry of large language models"}, {"paperId": null, "title": "2024. Mitigating the alignment tax of rlhf. 2"}, {"paperId": null, "title": "2024a. Negative preference optimization: From catastrophic collapse to effective unlearning. 2"}]}