{"paperId": "ca57cad707e340db0ea1168d2e1e925ec8b59387", "abstract": "Language models are essential for natural language processing (NLP) tasks, such as machine translation and text summarization. Remarkable performance has been demonstrated recently across many NLP domains via a Transformer-based language model with over a billion parameters, verifying the benefits of model size. Model parallelism is required if a model is too large to fit in a single computing device. Current methods for model parallelism either suffer from backward locking in backpropagation or are not applicable to language models. We propose the first model-parallel algorithm that speeds the training of Transformer-based language models. We also prove that our proposed algorithm is guaranteed to converge to critical points for non-convex problems. Extensive experiments on Transformer and Transformer-XL language models demonstrate that the proposed algorithm obtains a much faster speedup beyond data parallelism, with comparable or better accuracy. Code to reproduce experiments is to be found at \\url{this https URL}.", "venue": "Neural Information Processing Systems", "year": 2019, "citationCount": 8, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes the first model-parallel algorithm that speeds the training of Transformer-based language models, and proves that the proposed algorithm is guaranteed to converge to critical points for non-convex problems."}, "embedding": {"model": "specter_v2", "vector": [0.1284443885087967, 0.23410773277282715, -0.46197181940078735, -0.03342690318822861, -0.5989791750907898, -0.17140363156795502, 0.5331240892410278, -0.0031312524806708097, -0.7895276546478271, -0.24301685392856598, 0.45350581407546997, -0.6487416625022888, 0.082297183573246, 0.06796415895223618, -0.2637978196144104, 0.08845138549804688, -0.7408645153045654, 0.8436465263366699, -0.45337849855422974, -0.4483330547809601, -0.33556169271469116, -0.39458057284355164, -0.5749199986457825, 0.11499296873807907, 0.7058097720146179, 0.1844705194234848, 0.19861584901809692, 0.9450617432594299, -0.5497678518295288, 0.13661085069179535, 0.7152835726737976, -0.14545023441314697, 0.4686542749404907, 0.2709304094314575, -0.3346956670284271, -0.08774205297231674, 0.2646779716014862, -0.4063468873500824, -0.29904836416244507, 0.9503406286239624, -0.49564677476882935, 0.20665161311626434, 0.3050093352794647, -0.9613619446754456, -0.1318199336528778, 0.8055883049964905, 0.3317580223083496, 1.0163108110427856, -0.24617210030555725, -0.5499134063720703, 1.1017040014266968, -1.3374300003051758, 0.2331031709909439, 1.275896430015564, 0.8562959432601929, 0.383128821849823, -0.28499361872673035, -0.5821297764778137, 0.3436245918273926, -0.07858419418334961, -0.7769629955291748, -0.4044436812400818, -0.3722194731235504, 0.08998902887105942, 2.0266871452331543, -0.3484688401222229, 0.46355509757995605, 0.010119407437741756, -0.07040458172559738, 1.4801337718963623, 0.08084242045879364, -0.8484520316123962, -0.3203268051147461, -0.029635757207870483, 0.12469002604484558, 1.1671191453933716, -0.4077202379703522, 0.021425604820251465, -1.1419435739517212, -0.449603796005249, -0.07258761674165726, -0.02057093195617199, -0.3109669089317322, -0.2364208996295929, -0.2651229202747345, 0.821820080280304, 0.2547253966331482, 0.5367811918258667, -0.2651662826538086, 0.617189347743988, 0.4895840883255005, 0.6038537621498108, 0.4046122133731842, 0.29144468903541565, -0.17432253062725067, 0.47274965047836304, -1.1956629753112793, 0.26433029770851135, 0.20039968192577362, 0.7364610433578491, -0.2508050501346588, 0.07713466137647629, -0.4978424608707428, 0.017155099660158157, 1.4336066246032715, 0.4472246766090393, 0.3995266854763031, -0.3122079074382782, 0.5296025276184082, -0.5588207840919495, 0.26039817929267883, -0.36611655354499817, -0.7713346481323242, -0.2350456565618515, -0.7728236317634583, -1.4042632579803467, -0.5250906348228455, 0.083384208381176, -0.7899566888809204, 0.538206934928894, -0.07096898555755615, 0.07786038517951965, 0.43417122960090637, 0.6216458082199097, 0.22266776859760284, 1.1112864017486572, 0.11382415145635605, -0.3559560775756836, 1.1734504699707031, -0.768365204334259, -0.8300753831863403, -0.9815995097160339, 0.9673463106155396, -0.28708675503730774, 0.3101854920387268, -0.07499486207962036, -1.465187668800354, -0.398876428604126, -0.6434289813041687, -0.03665313869714737, -0.39710843563079834, 0.2468409538269043, 0.9557260274887085, 0.23463737964630127, -1.1497275829315186, 0.8040909171104431, -0.2855650782585144, -0.32153454422950745, 0.3713160455226898, 0.4427552819252014, 0.1563553661108017, -0.3408355116844177, -1.1256103515625, 0.6534691452980042, 0.3501169681549072, -0.4398994445800781, -0.09465720504522324, -0.9385645389556885, -0.8232279419898987, 0.14735111594200134, 0.21251362562179565, -0.8241264820098877, 1.3871499300003052, 0.08239106088876724, -1.2504748106002808, 0.46272602677345276, -0.7643225789070129, -0.2988300323486328, 0.42995956540107727, -0.27535542845726013, -0.28289932012557983, -0.3013921082019806, -0.08098624646663666, 0.31200993061065674, 0.3109469711780548, -0.04925725609064102, -0.3362213373184204, 0.19330370426177979, -0.4846579432487488, 0.10094692558050156, -0.6110848188400269, 0.9130064845085144, -0.39293554425239563, -0.14388848841190338, 0.40923213958740234, 0.7388326525688171, -0.5236123204231262, -0.2916000485420227, -0.37887099385261536, -1.008285403251648, 0.5811282992362976, -0.18932446837425232, 0.8007319569587708, -0.794434130191803, -0.45568177103996277, -0.171944260597229, 0.13756407797336578, 0.047035250812768936, -0.7791640162467957, 0.7770563960075378, -0.26840946078300476, 0.5457340478897095, -0.39252418279647827, -1.0336875915527344, 0.0955125167965889, -0.21314993500709534, -0.8378722071647644, 0.008528835140168667, 0.18501664698123932, 1.2264094352722168, -1.0275427103042603, 0.19744442403316498, -0.04599050059914589, 0.2738909125328064, -0.9090788960456848, 0.948567807674408, -0.46322232484817505, 0.04784620553255081, 0.26207512617111206, -0.452929824590683, 0.359069287776947, -0.32521307468414307, 0.5078012943267822, -0.3536233603954315, -0.253196656703949, 0.31983548402786255, -0.3907814025878906, 1.2388665676116943, -0.2836551368236542, 0.41607141494750977, 0.03880755230784416, -0.7299179434776306, -0.006901340093463659, 0.5110187530517578, -0.015249923802912235, -0.48974695801734924, 0.34448960423469543, 0.5268305540084839, -0.5635362863540649, 0.2774388790130615, 0.6224831938743591, 0.42725610733032227, -0.08763433992862701, 0.5679944753646851, 0.5360345244407654, -0.3588544726371765, 0.8287108540534973, 0.2955963611602783, 0.31712472438812256, 0.21597357094287872, 0.25649118423461914, -0.18649069964885712, 0.2754804193973541, -0.4810813367366791, -0.09288492798805237, 0.20259183645248413, 0.6149896383285522, 0.27577629685401917, 0.3908863663673401, -0.9213823080062866, -0.4773775339126587, -0.1327904462814331, 0.7857850193977356, 1.4490963220596313, -0.42735370993614197, -0.36052581667900085, -0.6910374164581299, -0.16270337998867035, -0.5332627892494202, -0.021377241238951683, 0.021420439705252647, 0.14005182683467865, -0.6828056573867798, -1.5463095903396606, 0.9459882378578186, 0.20885208249092102, 0.7632359266281128, 0.07623612135648727, -0.23036213219165802, -0.43555232882499695, -0.04532937332987785, -0.9239738583564758, -0.44328638911247253, 0.41732242703437805, -1.022217035293579, -0.14117486774921417, -0.0442599318921566, -0.03693228214979172, 0.2918992042541504, -0.4261396527290344, 0.733170747756958, -0.6124577522277832, 0.1557760387659073, -0.17257855832576752, 0.9206515550613403, -0.9743762612342834, -0.8927184343338013, -0.016412926837801933, 0.4733956754207611, -0.23527589440345764, 0.28903618454933167, 0.45038121938705444, 0.4856485426425934, -0.3759927451610565, -0.36572879552841187, 0.5064083933830261, -0.20571881532669067, 0.287479043006897, 0.3898772597312927, -0.21583080291748047, -0.26878827810287476, -0.954605221748352, 1.253043293952942, 0.3756088316440582, -0.8435294032096863, 0.5592087507247925, -0.6167441010475159, -0.01997525431215763, 0.5597414374351501, -0.5617796182632446, 0.013893007300794125, -0.7736106514930725, 0.3165300190448761, -0.38680437207221985, 0.2830659747123718, 0.43289458751678467, 0.511437714099884, 0.34092453122138977, 0.12338444590568542, 0.5304374694824219, 0.44330552220344543, -0.05015240237116814, 0.6683712601661682, -0.7872321009635925, 0.13720183074474335, 0.5406634211540222, 0.27412062883377075, -0.08136100322008133, 0.026131151244044304, -0.7466661334037781, -0.39730721712112427, -0.46418148279190063, 0.0243579912930727, -0.1163732036948204, 0.0049128346145153046, -0.542782723903656, -0.9057897329330444, -0.1031184121966362, -1.2952808141708374, -0.1492341160774231, 0.2575177550315857, -0.011777188628911972, -0.13291002810001373, -0.8973249793052673, -1.3627249002456665, -0.6302546262741089, -1.0525683164596558, -0.9539965987205505, 0.5014231204986572, 0.055908918380737305, 0.05349891632795334, -0.692103922367096, -0.01645555905997753, -0.16467848420143127, 0.756549596786499, -0.8187196254730225, 1.0374761819839478, -0.14143814146518707, -0.023721134290099144, -0.017143238335847855, 0.1106191948056221, 0.2643151879310608, -0.5999472141265869, 0.11313479393720627, -0.6193082332611084, 0.11951181292533875, -0.4073695242404938, -0.14352580904960632, 0.07696038484573364, 0.5879475474357605, 0.053789664059877396, -0.099932961165905, -0.6230992078781128, 0.34634286165237427, 1.439922571182251, -1.1433827877044678, -0.19406865537166595, 0.15197740495204926, 1.040358543395996, 0.01883365586400032, -0.4082052707672119, 0.41223934292793274, 0.39844971895217896, 0.3729354441165924, 0.06075410544872284, -0.49631139636039734, 0.42067134380340576, -0.3401200771331787, 0.4713936746120453, 1.792265772819519, 0.355447381734848, -0.2715931832790375, -1.447176456451416, 0.37604212760925293, -1.1964447498321533, -0.48384568095207214, 0.3056763708591461, 0.5531535148620605, 0.2936418950557709, -0.558570146560669, -0.01745297946035862, -0.05173247680068016, 0.4809558689594269, 0.08081904798746109, -0.05974573269486427, -0.8191276788711548, 0.09052903950214386, 0.22730432450771332, 0.5620886087417603, 0.7364153861999512, -0.27283385396003723, 0.9762082695960999, 15.032052993774414, 0.8076955676078796, -0.11999253183603287, 0.8983173370361328, 0.2720135748386383, 0.12183806300163269, -0.44083139300346375, -0.23889069259166718, -1.0243703126907349, -0.3427635133266449, 1.3427140712738037, -0.21054986119270325, 0.8374582529067993, -0.18014110624790192, 0.48031988739967346, 0.24024149775505066, -0.22997617721557617, 0.7208709716796875, 0.49622735381126404, -1.430167317390442, 0.6284750699996948, 0.4303341805934906, 0.4437882900238037, 0.9985005259513855, 0.4103128910064697, 0.5202480554580688, 0.4697103500366211, -0.6582506895065308, 0.4408916234970093, 0.20091110467910767, 0.6183539032936096, -0.3827960789203644, 0.5454140305519104, 1.147037148475647, -0.8404595851898193, -0.411868691444397, -0.6101606488227844, -1.1855967044830322, 0.5373110175132751, 0.37778952717781067, -1.0085136890411377, 0.04435647279024124, -0.22307907044887543, 0.8796494603157043, 0.7197762131690979, 0.19276092946529388, -0.021078506484627724, 0.7076249718666077, -0.6585023999214172, 0.09923763573169708, 0.42342954874038696, 0.2033158391714096, 0.2243777960538864, -0.0010529457358643413, 0.28882527351379395, -0.16626247763633728, 0.29666319489479065, 0.17767179012298584, -0.7024213075637817, 0.12823039293289185, -0.36868417263031006, -0.3491000831127167, -0.02580430544912815, 0.6557173132896423, 0.37142741680145264, 0.21253080666065216, -0.221588134765625, 0.13006459176540375, 0.6642391681671143, -0.0026531375478953123, -0.31746602058410645, 0.3602084219455719, 0.130590558052063, -0.4801900088787079, -0.15338611602783203, 0.35246944427490234, -0.10313461720943451, -0.6524132490158081, -0.6455042958259583, -0.6567419767379761, 0.3653046488761902, -0.5478699803352356, -0.5206295251846313, 0.7532583475112915, -0.18663445115089417, -0.4619840979576111, 0.5972136855125427, -0.875386118888855, 0.07553538680076599, 0.6157696843147278, -1.5140454769134521, -0.8938090205192566, 0.8359100222587585, -0.3277096152305603, -0.44516563415527344, 0.06589332967996597, 1.284837007522583, 0.151705801486969, -0.27309900522232056, -0.20637083053588867, 0.30539560317993164, -0.23327869176864624, -0.7428149580955505, -0.7305481433868408, 1.0639371871948242, 0.4134649932384491, 0.12730731070041656, 0.08724156022071838, 0.09363450855016708, 0.36659160256385803, -1.0354515314102173, 0.11923732608556747, 1.1621835231781006, -0.7335805892944336, -0.18258409202098846, -0.9274168014526367, -0.5605369806289673, 0.18421471118927002, 0.35342150926589966, -0.6623984575271606, 0.325064092874527, 0.07920508831739426, -0.3244790732860565, -0.0844765231013298, -0.8046008944511414, 0.27399492263793945, 0.5774851441383362, -0.6729092001914978, -0.32136300206184387, 0.409210205078125, 0.19724535942077637, -0.9994753003120422, -0.32158392667770386, -0.012181020341813564, 0.1764293760061264, 0.20071884989738464, 0.876306414604187, -0.48661285638809204, 0.40874040126800537, 0.6966988444328308, 0.04493113234639168, -0.8091036677360535, 0.1929704248905182, -0.9844953417778015, -0.09226899594068527, -0.2525133192539215, 0.503049910068512, -0.4444029629230499, 0.09517662227153778, 0.5358233451843262, 0.3381612002849579, -0.46937885880470276, -0.8603811860084534, -0.32761603593826294, 0.13262148201465607, -0.6916435360908508, 0.4811609387397766, -0.14593634009361267, -0.06790545582771301, 0.12213771790266037, 0.16839070618152618, 0.8669688105583191, -0.46761733293533325, -0.8111215233802795, 0.49151068925857544, -0.06898859143257141, 0.20370742678642273, -0.7187075614929199, -0.30158179998397827, -1.4257768392562866, 0.2319348305463791, -1.4130851030349731, -0.01274537481367588, -1.3780527114868164, -0.22656585276126862, 0.23737972974777222, 0.22127245366573334, 0.24698147177696228, 0.30931517481803894, -0.35979264974594116, -0.23939374089241028, -0.46266698837280273, -0.2691640555858612, 0.8023273944854736, 0.8740909099578857, -0.8906213045120239, 0.02613525651395321, -0.210409015417099, 0.2636745274066925, 0.3768309950828552, 0.48078110814094543, -0.5653022527694702, -0.9045863747596741, -1.5272496938705444, 0.6677419543266296, -0.008229999803006649, -0.07439573109149933, -0.530570387840271, 0.7063519358634949, 0.40365153551101685, -0.4665014445781708, -0.0017208211356773973, 0.3702009320259094, -0.8857974410057068, -0.42768406867980957, 0.8178876042366028, -0.5739595890045166, 0.6559252142906189, 0.4570079445838928, -0.6459127068519592, -0.1193142905831337, 0.6247602105140686, -0.3697964549064636, -0.920670211315155, -0.36855584383010864, 0.33094796538352966, -0.7432796955108643, 0.28321748971939087, -0.27562060952186584, -0.1449577361345291, -0.7921554446220398, -0.020637771114706993, 0.2687820792198181, 0.5899898409843445, -0.3403925895690918, 0.5463091731071472, 0.2751360237598419, -0.7349320650100708, -0.1373877227306366, 0.26556333899497986, -0.48448777198791504, -0.10755384713411331, 0.32778048515319824, 0.5985819101333618, -0.47873350977897644, 0.7205942869186401, 0.3927309811115265, -0.1363760530948639, -1.0912518501281738, -0.07408084720373154, 0.8689113855361938, -1.0388540029525757, -0.5329639315605164, 0.939990758895874, -0.502923309803009, -1.5071661472320557, -0.04146213084459305, -1.1506998538970947, -0.3991718292236328, -0.48392966389656067, 0.6420581340789795, 0.33693185448646545, 0.06632880121469498, 0.14701420068740845, -0.6171518564224243, 0.2476012259721756, 0.12667015194892883, -0.713909924030304, 0.6506670117378235, 0.06946572661399841, -0.7176793813705444, 0.5446913242340088, 0.3020658493041992, -0.6231456995010376, -0.24274371564388275, -0.6711301207542419, -0.17995710670948029, 0.11135593056678772, 0.577124297618866, -0.21600830554962158, -0.15570130944252014, 0.8813575506210327, 0.5553311705589294, 0.3546854555606842, 0.3530247211456299, -0.5202815532684326, 0.3946296274662018, 0.6775141954421997, 0.12323164194822311, -0.7025870084762573, -0.9860057830810547, 1.567463994026184, 0.9510461091995239, -0.7900112271308899, 0.4621414840221405, -0.3255426287651062, -0.7399791479110718, 0.8855880498886108, -0.2551971971988678, 0.1122591570019722, 0.8256798386573792, 0.07234418392181396, 0.31681206822395325, 0.0359208881855011, -0.9743548035621643, -0.2507435381412506, 0.8496326804161072, 0.862223207950592, 0.5349458456039429, 0.2359076738357544, -0.12073929607868195, 0.7726135849952698, 0.04879468306899071, 0.5726457238197327, 0.40044885873794556, 0.5510900616645813, -0.0939810499548912, -0.01571556180715561, -0.1576213836669922, 0.42288702726364136, -0.5977707505226135, -1.0310149192810059, 0.3015155494213104, 0.5755464434623718, -0.05307760089635849, 0.7652614712715149, 0.6512126922607422, 0.3653241991996765, 0.46366673707962036, 0.15067893266677856, 0.5974575877189636, -0.29089099168777466, -0.49008768796920776, -0.056370072066783905, -0.5825017690658569, 0.19095492362976074, -0.31864315271377563, -0.29834210872650146, -0.7495321035385132, -0.698103129863739, 0.16911101341247559, 0.36145952343940735, 0.5157997608184814, 1.3460887670516968, 0.5218799710273743, 0.37077951431274414, -0.3386956751346588, -0.40905117988586426, -0.73564213514328, -0.8478764295578003, 0.06933724135160446, -0.8308734893798828, -0.28256383538246155, 0.1526331901550293, 0.016413312405347824, -0.44351503252983093]}, "authors": [{"authorId": "144286907", "name": "Qian Yang"}, {"authorId": "3382735", "name": "Zhouyuan Huo"}, {"authorId": "2900282", "name": "Wenlin Wang"}, {"authorId": "145114933", "name": "Heng Huang"}, {"authorId": "145006560", "name": "L. Carin"}], "references": [{"paperId": "56d41f91193994eb80884ec83c1c1e74b7cc3058", "title": "An End-to-End Generative Architecture for Paraphrase Generation"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "b9de9599d7241459db9213b5cdd7059696f5ef8d", "title": "Character-Level Language Modeling with Deeper Self-Attention"}, {"paperId": "1a717046a5ef236718dcbcf1b7fa52bf925f5633", "title": "Training Neural Networks Using Features Replay"}, {"paperId": "7f2406aba47ac90dcc92f890dca3d9b647d11894", "title": "Decoupled Parallel Backpropagation with Convergence Guarantee"}, {"paperId": "dc6da6e53e5954159f8fd30b67f6c9a5e51c9662", "title": "Wise Crowd Content Assessment and Educational Rubrics"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "45dfef0cc1ed96558c1c650432ce39d6a1050b6a", "title": "Fixing Weight Decay Regularization in Adam"}, {"paperId": "a3be639d7e915b5f4e1499e52e1fcfd0940a31e5", "title": "Paraphrase Generation with Deep Reinforcement Learning"}, {"paperId": "5a5a1076c3a3d4f7cbcc48a1e3f14307deec6b7a", "title": "A Deep Generative Framework for Paraphrase Generation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "0d57ba12a6d958e178d83be4c84513f7e42b24e5", "title": "Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour"}, {"paperId": "527113e8ec7a38ce58198af738516ed7c7313135", "title": "HiText: Text Reading with Dynamic Salience Marking"}, {"paperId": "629975fc3a5cc35cf7001d067354507f422bef5a", "title": "Joint Training for Pivot-based Neural Machine Translation"}, {"paperId": "5d0604d2b78bb44db4cd3d94f776b15f0e8a30ab", "title": "Neural Machine Translation with Pivot Languages"}, {"paperId": "424aef7340ee618132cc3314669400e23ad910ba", "title": "Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "63e39cdf1ad884da6bc69096bb3413b5b1100559", "title": "Using the Output Embedding to Improve Language Models"}, {"paperId": "27760cc69be4ce445962ccb270a02d1944a9d4c9", "title": "Decoupled Neural Interfaces using Synthetic Gradients"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "d21703674ae562bae4a849a75847cdd9ead417df", "title": "Optimization Methods for Large-Scale Machine Learning"}, {"paperId": "7a67159fc7bc76d0b37930b55005a69b51241635", "title": "Abstractive Sentence Summarization with Attentive Recurrent Neural Networks"}, {"paperId": "942deb7d865b7782c03176d95e3a0d56cb71009e", "title": "Training Deep Nets with Sublinear Memory Cost"}, {"paperId": "f37076f426023241f19cdc2fb0a0fd733a6fa7fa", "title": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond"}, {"paperId": "59f8fbc0903158aab28a34230d9243ea5e81e422", "title": "PEAK: Pyramid Evaluation via Automated Knowledge Extraction"}, {"paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0", "title": "Effective Approaches to Attention-based Neural Machine Translation"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "4ce50b6d21e299d60e3ae2f46408ef2b6f29cdd4", "title": "Multi-GPU Training of ConvNets"}, {"paperId": "413c1142de9d91804d6d11c67ff3fed59c9fc279", "title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"}, {"paperId": "052b1d8ce63b07fec3de9dbb583772d860b7c769", "title": "Learning representations by back-propagating errors"}, {"paperId": "34ddd8865569c2c32dec9bf7ffc817ff42faaa01", "title": "A Stochastic Approximation Method"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": null, "title": "Lecture 6a overview of mini\u2013 batch gradient descent"}, {"paperId": null, "title": "Large text compression benchmark"}, {"paperId": null, "title": "Proof: When \u03b3 t is constant and \u03b3 t = \u03b3, we have \u03c3 = 1. Because of the definition of M K and taking total expectation of (15) in Lemma 1"}]}