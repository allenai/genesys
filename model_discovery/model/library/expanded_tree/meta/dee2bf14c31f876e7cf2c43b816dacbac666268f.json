{"paperId": "dee2bf14c31f876e7cf2c43b816dacbac666268f", "abstract": "Interacting with humans through multi-turn conversations is a fundamental feature of large language models (LLMs). However, existing LLM serving engines executing multi-turn conversations are inefficient due to the need to repeatedly compute the key-value (KV) caches of historical tokens, incurring high serving costs. To address the problem, this paper proposes CachedAttention, a new attention mechanism that enables reuse of KV caches across multi-turn conversations, significantly reducing the repetitive computation overheads. CachedAttention maintains a hierarchical KV caching system that leverages cost-effective memory/storage mediums to save KV caches for all requests. To reduce KV cache access overheads from slow mediums, CachedAttention employs layer-wise pre-loading and asynchronous saving schemes to overlap the KV cache access with the GPU computation. To ensure that the KV caches to be accessed are placed in the fastest hierarchy, CachedAttention employs scheduler-aware fetching and eviction schemes to consciously place the KV caches in different layers based on the hints from the inference job scheduler. To avoid the invalidation of the saved KV caches incurred by context window overflow, CachedAttention enables the saved KV caches to remain valid via decoupling the positional encoding and effectively truncating the KV caches. Extensive experimental results demonstrate that CachedAttention significantly decreases the time to the first token (TTFT) by up to 87%, improves the prompt prefilling throughput by up to 7.8$\\times$ for multi-turn conversations, and reduces the end-to-end inference cost by up to 70%.", "venue": "USENIX Annual Technical Conference", "year": 2024, "citationCount": 4, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "CachedAttention is proposed, a new attention mechanism that enables reuse of KV caches across multi-turn conversations, significantly reducing the repetitive computation overheads and reducing the end-to-end inference cost."}, "embedding": {"model": "specter_v2", "vector": [-0.17710870504379272, 0.5042309165000916, -0.6223214268684387, -0.20262585580348969, -0.5222009420394897, 0.015756206586956978, 0.7151932120323181, -0.22009888291358948, -0.46062469482421875, -0.262355238199234, 0.5186085104942322, -0.3509732782840729, 0.4951282739639282, 0.2570708096027374, -0.20199991762638092, -0.02146950550377369, -0.8969504833221436, 0.20934219658374786, 0.18788033723831177, -0.06128094717860222, -0.16186155378818512, -0.5617918968200684, -1.3889957666397095, 0.47667986154556274, 0.5518385171890259, 0.2090601921081543, 0.31024500727653503, 1.2882263660430908, -0.4607033133506775, 0.650375247001648, 0.6288784742355347, -0.011525214649736881, -0.11418589949607849, 0.114042267203331, -0.18826882541179657, -0.30651941895484924, 0.08846752345561981, -0.6281519532203674, -0.2568857967853546, 0.2764994502067566, -0.11999895423650742, 0.25352743268013, 0.09309803694486618, -1.1328552961349487, 0.22452011704444885, 0.636155366897583, 0.39854899048805237, 0.7291911840438843, -0.3459434509277344, -0.5895258188247681, 1.0718574523925781, -1.657908320426941, 0.0005784113891422749, 1.5626270771026611, 0.5072991251945496, 0.12555211782455444, 0.13764697313308716, -0.3833867013454437, 0.9583821296691895, -0.10590089857578278, -0.5913020968437195, -0.7357234358787537, -0.2440197467803955, 0.10447537899017334, 1.6909080743789673, -0.018586479127407074, 0.3980185091495514, 0.3148414194583893, 0.10889697819948196, 1.6702334880828857, -0.0912979394197464, -0.9918311834335327, -0.22511737048625946, 0.30543971061706543, 0.7329341173171997, 0.869102954864502, -0.4418063163757324, 0.029987681657075882, -0.8986021280288696, -0.5012782216072083, 0.4910188615322113, -0.04918519780039787, 0.19513119757175446, -0.18452098965644836, -0.35794585943222046, 0.5707302689552307, -0.2354261875152588, 0.6124982237815857, -0.14901411533355713, 0.49426764249801636, 0.8525092005729675, 0.13576869666576385, 0.34202849864959717, -0.424245685338974, 0.13921499252319336, -0.21664942800998688, -0.7661835551261902, 0.4352354407310486, 0.44574230909347534, 0.9772412776947021, -0.7967345118522644, -0.12510034441947937, -0.9355630278587341, 0.1291331648826599, 1.4229323863983154, 0.18788078427314758, 0.20420101284980774, -0.6457493305206299, 0.14140628278255463, -1.0793638229370117, 0.5366698503494263, -0.31998923420906067, -0.08661893755197525, 0.19178183376789093, -0.5901182889938354, -0.9475078582763672, -0.3740893006324768, 0.4269970953464508, -0.46121746301651, 0.3024757504463196, 0.2990553379058838, 0.33229997754096985, 0.11117614805698395, 0.2753336429595947, 0.5881630778312683, 0.7209246158599854, 0.2769787609577179, -0.12134052067995071, 1.2094024419784546, -1.2741979360580444, -0.5919076800346375, -0.9177355170249939, 0.8333454728126526, -0.28310564160346985, 0.5099889636039734, -0.28626322746276855, -1.2482722997665405, -0.7465299367904663, -0.6294307112693787, -0.15210570394992828, -0.5639617443084717, 0.20458056032657623, 1.139701247215271, 0.03567026928067207, -1.2307125329971313, 0.23719748854637146, -0.34866049885749817, -0.14660297334194183, -0.24554504454135895, -0.21462351083755493, 0.6402994990348816, -0.25374913215637207, -1.5022192001342773, 0.22848571836948395, -0.22544941306114197, -0.6441843509674072, 0.15095405280590057, -0.5055402517318726, -0.9966357946395874, -0.10498425364494324, 0.13350915908813477, -0.2450571209192276, 1.6656031608581543, 0.39798879623413086, -1.3400917053222656, 0.5093740820884705, -0.5584583282470703, 0.4710739850997925, 0.34623396396636963, -0.30525699257850647, -0.6320807337760925, -0.24444931745529175, -0.2124389261007309, 0.374926894903183, 0.5780201554298401, -0.4657376706600189, -0.6195083260536194, 0.26810264587402344, -0.13561223447322845, 0.22844015061855316, 0.11875581741333008, 0.9963064789772034, -0.6334527730941772, 0.28803011775016785, 0.1078416258096695, 0.6442166566848755, 0.06958223879337311, 0.061865419149398804, -0.2968176007270813, -0.8424847722053528, 0.9800428748130798, -0.12413565814495087, 1.4341862201690674, -0.6528552770614624, -1.113547444343567, -0.2671458125114441, -0.023503417149186134, -0.0001578790252096951, -0.43668195605278015, 0.777530312538147, 0.06784673780202866, 0.037355802953243256, 0.30668747425079346, -0.9362682104110718, 0.16976681351661682, -0.4026213586330414, -0.9837394952774048, -0.3704890310764313, -0.6526517271995544, 0.9388716220855713, -0.9377068281173706, -0.22446492314338684, -0.11143894493579865, 0.2744452655315399, -0.639917254447937, 1.4636112451553345, -0.40406155586242676, 0.27149152755737305, -0.3760393261909485, -0.4325679540634155, 0.12332545965909958, -0.3179149329662323, 0.44617509841918945, -0.6063777804374695, -0.46791255474090576, 0.41322651505470276, 0.09522034227848053, 0.7544772028923035, -0.44361793994903564, 0.15978184342384338, 0.17335990071296692, 0.007789269555360079, -0.3474760353565216, 0.7383705973625183, -0.3729279935359955, -0.4614616334438324, 0.2767000198364258, 0.4933830201625824, -0.6551917195320129, 0.05762087553739548, 1.1929775476455688, 1.0844324827194214, -0.6489806175231934, 0.7031118273735046, -0.2621033787727356, 0.023652561008930206, 0.21945898234844208, 0.6031858325004578, 0.2053559124469757, 0.4333556890487671, 0.4787102937698364, -0.2789148986339569, 0.4409732222557068, -1.0012588500976562, -0.39690452814102173, 0.6540215611457825, 0.26373007893562317, 0.16953343152999878, 0.4549524486064911, -0.8964197039604187, -0.4485808312892914, 0.4563947319984436, 0.618522584438324, 1.7774189710617065, 0.060040511190891266, -0.06930747628211975, -1.14859139919281, -0.4055110812187195, -0.1707042008638382, 0.4597281515598297, 0.1669309437274933, -0.08246555179357529, -0.5839418172836304, -0.5318994522094727, 1.1308889389038086, 0.26653996109962463, 0.949482262134552, -0.8155555129051208, -0.608896017074585, -0.2092415690422058, 0.034646857529878616, -0.9540852904319763, -0.7842667102813721, -0.1362435519695282, -0.42111316323280334, 0.08319701999425888, 0.10944725573062897, -0.2224484086036682, -0.003913621883839369, -0.046584926545619965, 0.9206271171569824, -0.16020320355892181, -0.186479851603508, 0.527499794960022, 0.6910703182220459, -0.5924661755561829, -1.2365587949752808, 0.05997633934020996, 0.2591744661331177, -0.2866368293762207, 0.38325124979019165, 0.6111833453178406, 0.20237061381340027, -0.06763409078121185, -0.1096721738576889, 0.6613439321517944, -0.016709690913558006, -0.4973571002483368, 0.3020878732204437, -0.9467620849609375, 0.03716852515935898, -1.0600560903549194, 1.2419418096542358, 0.24250416457653046, -0.34759920835494995, 0.6659963130950928, -0.6062634587287903, -0.3961167633533478, 0.2749907374382019, -0.7527300119400024, -0.358197420835495, -1.500259518623352, 0.44163647294044495, -0.04449404403567314, -0.16681155562400818, -0.19845837354660034, 0.23830996453762054, 0.17953838407993317, -0.4299231469631195, 1.0189732313156128, 0.4400264024734497, -0.29198822379112244, 0.664877712726593, -0.10282119363546371, 0.16048355400562286, -0.06712491810321808, -0.4809880554676056, -0.05017344281077385, -0.5664064288139343, -0.7864921689033508, -0.3270076513290405, -0.38563084602355957, -0.2547394335269928, -0.6645842790603638, -0.06345974653959274, -0.5381388068199158, -1.0290595293045044, 0.2962436079978943, -1.5472276210784912, -0.3433189392089844, 0.6984779834747314, -0.2472241222858429, -0.2961706817150116, -1.0315072536468506, -1.4505096673965454, -0.9308540225028992, -0.9634277820587158, -1.0496174097061157, 0.49235621094703674, -0.3851069211959839, -0.5616447925567627, -0.380330353975296, 0.05935968458652496, -0.3889662027359009, 0.9574574828147888, -0.9510892629623413, 0.9734641909599304, 0.056363049894571304, -0.36187615990638733, -0.22976650297641754, 0.07492216676473618, -0.0541265606880188, -0.2343500703573227, 0.015597336925566196, -0.7317844033241272, 0.005237689707428217, -0.1332836002111435, 0.07938719540834427, -0.1960826814174652, 0.20942848920822144, 0.6385123133659363, -0.10938313603401184, -0.8819475173950195, -0.16397158801555634, 0.8590155839920044, -0.6020916700363159, -0.169732928276062, -0.17634838819503784, 1.094018816947937, -0.007321635726839304, 0.10746869444847107, 0.6525377035140991, 0.663817822933197, 0.6111174821853638, -0.1289433389902115, -0.45292094349861145, 0.11395109444856644, -0.21424426138401031, 0.79537433385849, 2.101916551589966, 0.24854303896427155, -0.18544210493564606, -0.6682538986206055, 0.48017066717147827, -1.5803290605545044, -0.534776508808136, 0.49524199962615967, 0.8786052465438843, -0.08937869966030121, -0.5066975951194763, 0.029313281178474426, -0.5948922038078308, 0.9053499102592468, 0.5957558751106262, -0.18880996108055115, -1.119508981704712, 0.5527554154396057, -0.40291929244995117, -0.23337984085083008, 0.8113085031509399, -0.1290237158536911, 0.7647327184677124, 14.607504844665527, 0.7880474328994751, 0.057907383888959885, 0.6954379081726074, 0.7697822451591492, 0.12408466637134552, -0.3722118139266968, -0.3195926249027252, -1.351487159729004, 0.017672643065452576, 1.6755657196044922, -0.061511002480983734, 0.5554845929145813, 0.009080218151211739, 0.551586925983429, -0.0857866182923317, -0.22962868213653564, 0.43025442957878113, 0.5650935173034668, -0.9311074614524841, 0.4956173300743103, 0.24033448100090027, -0.19172097742557526, 0.5360702276229858, 0.6303228139877319, 0.9544533491134644, 0.6630831956863403, -0.10437517613172531, 0.853175938129425, 0.3863804042339325, 0.9323711395263672, -0.6642745137214661, 0.1396765410900116, 0.9121843576431274, -1.1242247819900513, 0.1984887272119522, -0.3708692789077759, -1.1018539667129517, 0.45378270745277405, 0.3408720791339874, -0.39331933856010437, -0.7697314620018005, -0.49685534834861755, 0.22793477773666382, 0.6841663718223572, 0.15388518571853638, 0.11201094835996628, 0.5306298136711121, -0.08687076717615128, -0.1458221822977066, 0.4194090962409973, 0.3565663695335388, 0.2500878572463989, 0.00760902464389801, 0.10008787363767624, 0.13020175695419312, 0.23350179195404053, 0.18480625748634338, -0.25653988122940063, -0.221110999584198, -0.48794618248939514, -0.024492165073752403, 0.21771647036075592, 0.704526960849762, 0.39776214957237244, -0.07782141864299774, -0.6243881583213806, 0.48137009143829346, 0.7713727355003357, 0.13598385453224182, -0.6271939277648926, 0.3094967305660248, 0.6773196458816528, -0.3234850764274597, 0.08680466562509537, 0.44786337018013, 0.20615547895431519, -0.4716099500656128, -0.5553684234619141, -0.421391099691391, -0.11246362328529358, -0.7223404049873352, -0.42482200264930725, 0.9294232726097107, 0.11797073483467102, -0.33379051089286804, 0.03747255355119705, -0.15764570236206055, -0.4715757966041565, 0.1866949498653412, -1.1525787115097046, -1.072380781173706, 0.7673649787902832, -0.46920621395111084, -0.27370744943618774, 0.6083172559738159, 1.3268752098083496, 0.11118502914905548, -0.3801279664039612, 0.13305184245109558, 0.3045734465122223, -0.2865298390388489, -0.35386019945144653, -0.3912808299064636, 1.2606407403945923, 0.08287278562784195, -0.4058294892311096, 0.26886609196662903, 0.03689679130911827, 0.0579889640212059, -0.8844656348228455, -0.21200008690357208, 0.9624736309051514, -0.7719695568084717, -0.575456976890564, -1.1655257940292358, -1.0861494541168213, 0.19345195591449738, 0.5263583064079285, 0.15063691139221191, 0.10270743072032928, 0.04151013121008873, -0.38136088848114014, 0.04587966948747635, -0.8205616474151611, 0.34185710549354553, 0.34363672137260437, -1.0401597023010254, 0.2540924549102783, -0.21998025476932526, 0.6334932446479797, -1.3736990690231323, -0.3836975395679474, -0.6350966095924377, 0.5344178080558777, -0.24413910508155823, 0.7433817982673645, -0.2451426386833191, 0.2025706022977829, 1.0297131538391113, 0.06000556796789169, -0.6686587929725647, -0.024474244564771652, -0.9591326713562012, -0.4101276099681854, 0.19840610027313232, 0.5828931927680969, -0.44521504640579224, -0.2940245270729065, 1.3230352401733398, 0.6565538048744202, -0.7812169194221497, -0.4981662333011627, 0.06857937574386597, 0.3027856945991516, -0.7938147783279419, 0.6872024536132812, -0.3130449652671814, 0.46334728598594666, -0.08337201923131943, 0.13598087430000305, 0.8408140540122986, 0.09758855402469635, -0.5306390523910522, 0.42835476994514465, 0.07099536061286926, 0.22848987579345703, -0.2903003692626953, -0.021435339003801346, -1.523688793182373, -0.11860569566488266, -0.8871579766273499, 0.26722460985183716, -0.7098058462142944, -0.06455928087234497, -0.003724907524883747, -0.085419200360775, -0.058462586253881454, 0.15169395506381989, -0.6941884160041809, -0.4584485590457916, -0.36911264061927795, -1.0431296825408936, 0.789454460144043, 1.1111096143722534, -0.18201129138469696, 0.18584993481636047, 0.044617533683776855, 0.2773066461086273, 0.22978167235851288, 0.25255918502807617, -0.22233183681964874, -0.7242035865783691, -1.0260188579559326, -0.0380496047437191, 0.283145934343338, 0.19302615523338318, -0.5390613079071045, 0.6776793599128723, 0.3287293612957001, -0.5310201048851013, -0.2211502343416214, 0.3378395438194275, -0.673204779624939, -0.6018074750900269, 0.28868499398231506, -0.812595784664154, 0.295245498418808, 0.4181184470653534, -0.5513980984687805, -0.03119039349257946, 1.0985887050628662, -0.37262362241744995, -1.0871632099151611, -0.8396982550621033, 0.4256250858306885, -0.9658435583114624, -0.02929365634918213, -0.12355411052703857, 0.17359839379787445, -0.6472479701042175, -0.6078399419784546, 0.20123505592346191, 0.130032017827034, -0.1579248458147049, 1.2457859516143799, 0.4348638653755188, -1.177309513092041, 0.12014768272638321, 0.5167571902275085, -0.26233384013175964, -0.18430431187152863, 0.6873556971549988, 0.6606981158256531, -0.09076190739870071, 0.6992096900939941, 0.8197301626205444, 0.22371172904968262, -1.365895390510559, -0.12370087206363678, 0.5838620066642761, -0.6731587648391724, -0.5764210224151611, 0.7777040004730225, -0.3581443727016449, -1.2037720680236816, -0.0346180684864521, -1.3885446786880493, -0.42885395884513855, -0.8117297291755676, 1.1401984691619873, 0.25163668394088745, -0.08931839466094971, -0.2694016993045807, -0.5520418286323547, -0.15742410719394684, -0.48905470967292786, -0.8045110702514648, 0.15904392302036285, -0.5246691107749939, -0.5391885042190552, 0.8281739354133606, 0.7764474153518677, -0.4666735529899597, -0.79637211561203, -0.3829830586910248, -0.6799455881118774, 0.18760168552398682, 0.5877177119255066, -0.3150377869606018, -0.11200176179409027, 0.6958934664726257, 0.4798230230808258, 0.33538737893104553, -0.5393484830856323, -0.13958640396595, 0.8617649078369141, 0.4183533787727356, 0.7002049684524536, -0.4900114834308624, -1.1173224449157715, 1.2916327714920044, 1.1128588914871216, -0.641360342502594, 0.10477583110332489, -0.1387249231338501, -0.8580330014228821, 0.8126367330551147, 0.4176061153411865, 0.42094865441322327, 0.9644964337348938, 0.22698599100112915, 0.5785005688667297, 0.06105963885784149, -1.249586820602417, 0.27390632033348083, 0.5145061016082764, 0.6414282917976379, 0.7141943573951721, 0.810400664806366, 0.11267096549272537, 0.793624758720398, 0.6291525959968567, 0.5514570474624634, 0.46505916118621826, 0.8598313331604004, -0.36651307344436646, -0.21916262805461884, -0.16023322939872742, 0.7569039463996887, -0.25507277250289917, -0.9368252158164978, 0.3999553918838501, 0.5986732840538025, -0.2973075807094574, 0.41027334332466125, 0.9502444863319397, 0.21985746920108795, 0.1298537254333496, 0.4348524808883667, 0.45489007234573364, -0.3770502805709839, -0.23689265549182892, -0.26665380597114563, -0.3855569660663605, -0.13954387605190277, 0.14940091967582703, -0.30407899618148804, -0.7122002840042114, -0.5418405532836914, 0.5131084322929382, 0.21769651770591736, 0.007706560660153627, 1.3440319299697876, 0.9725003242492676, 0.3372161090373993, -0.502640426158905, -0.7495083212852478, -0.5008750557899475, -0.7458773851394653, -0.16859053075313568, -0.8634588122367859, -0.13177600502967834, 0.09492950141429901, -0.036021288484334946, -0.7867088317871094]}, "authors": [{"authorId": "2281750844", "name": "Bin Gao"}, {"authorId": "2294207767", "name": "Zhuomin He"}, {"authorId": "145882675", "name": "Puru Sharma"}, {"authorId": "2281747746", "name": "Qingxuan Kang"}, {"authorId": "2217840", "name": "Djordje Jevdjic"}, {"authorId": "2294321883", "name": "Junbo Deng"}, {"authorId": "2294393706", "name": "Xingkun Yang"}, {"authorId": "2294305212", "name": "Zhou Yu"}, {"authorId": "2294173655", "name": "Pengfei Zuo"}], "references": [{"paperId": "c8a744a1f47ba30db89e2b7102971fafbd6118c1", "title": "ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition"}, {"paperId": "411114f989a3d1083d90afd265103132fee94ebe", "title": "Mixtral of Experts"}, {"paperId": "ddacee7382548fd9976e846c92500cfa3b6741db", "title": "PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU"}, {"paperId": "00e18c603e60d861c4e99c541e4d65ef442d5945", "title": "LLM in a flash: Efficient Large Language Model Inference with Limited Memory"}, {"paperId": "9f5b740169b1557852e945ba745a7a2c05c56dcc", "title": "Stateful Large Language Model Serving with Pensieve"}, {"paperId": "ad9146d98ae95bbeeef460abe083ecc2c4798672", "title": "Splitwise: Efficient generative LLM inference using phase splitting"}, {"paperId": "db633c6b1c286c0386f0078d8a2e6224e03a6227", "title": "Mistral 7B"}, {"paperId": "188336f606e76fda9e219b954d1750ad26646fdb", "title": "ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models"}, {"paperId": "6c323c535365e1c7cbfd9703cbec3b5650a3346b", "title": "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "12b233752c7097ea6525622bed238ae2d2193c5a", "title": "MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "43e624ddeed82df944a6cae0dedec3372438e243", "title": "Accelerating LLM Inference with Staged Speculative Decoding"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "ce9435c82dc9b576f2037aa2f4357a520be9b2aa", "title": "SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "7a1e71cb1310c4a873e7a4e54d1a6dab0553adce", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"}, {"paperId": "d6eeb2898bd9bd34744194ef543062dda6c4531a", "title": "Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time"}, {"paperId": "1fbaf2d8b69ef6e42a38c233f5d01bea70bad5b7", "title": "Fast Distributed Inference Serving for Large Language Models"}, {"paperId": "d50f023fe0921cabdd6d053c377cdd26c715994c", "title": "Tabi: An Efficient Multi-Level Inference System for Large Language Models"}, {"paperId": "42a14d824caa3348046eb34c37e2ab7985faa7a3", "title": "High-throughput Generative Inference of Large Language Models with a Single GPU"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "d03a9b2a0e090cc9fd2ba0a457ecea35372f1018", "title": "Demystifying Prompts in Language Models via Perplexity Estimation"}, {"paperId": "379e42895f6d40ab9e9559609f505aba89145a5d", "title": "Efficiently Scaling Transformer Inference"}, {"paperId": "6d088e8d785a57b50c2b0e465e2460e09ced48d7", "title": "Accelerating Distributed MoE Training and Inference with Lina"}, {"paperId": "c022f75b00d795c6297d6a9ea948856ea4d365a1", "title": "DeepSpeed- Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "7d1e512888a2fa4e838c12a02ae7fce867d322a8", "title": "DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "72dd63d67588a42fc817bbb8d655b397f67425df", "title": "ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep learning"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "74276a37bfa50f90dfae37f767b2b67784bd402a", "title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "5f994dc8cae24ca9d1ed629e517fcc652660ddde", "title": "ERNIE: Enhanced Language Representation with Informative Entities"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "56e0088592222ab9316cd6bcf0a5849b7c82d8aa", "title": "Fast and exact analysis for LRU caches"}, {"paperId": "a9a5d671271fff45429084e184a788f611b6f194", "title": "FRAGE: Frequency-Agnostic Word Representation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "0b44fcbeea9415d400c5f5789d6b892b6f98daff", "title": "Building a Large Annotated Corpus of English: The Penn Treebank"}, {"paperId": "c5d954d13c1c620d78ebaba9afa120733e90ed09", "title": "An approximate analysis of the LRU and FIFO buffer replacement schemes"}, {"paperId": "1a4c6856292b8c64d19a812a77f0aa6fd47cb96c", "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework"}, {"paperId": "e3aa232577bb427b1f3a34acbdef84bd85734042", "title": "LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models"}, {"paperId": "b8b45b14df9029562b8995c6ab7fd90a8810f312", "title": "GPT3.int8(): 8-bit Matrix Multiplication for Transformers at Scale"}, {"paperId": "9d7a75601e0e50dd68d40cfb8ef0e891dad797a6", "title": "Orca: A Distributed Serving System for Transformer-Based Generative Models"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "InternLM"}, {"paperId": null, "title": "How long can context length of open-source llms truly promise?"}, {"paperId": null, "title": "vllm: Easy, fast, and cheap llm serving with pagedattention"}, {"paperId": null, "title": "NVIDIA"}, {"paperId": null, "title": "Efficient llm inference by piggy-backing decodes with chunked prefills"}, {"paperId": null, "title": "Gemini: a family of highly capable multimodal models"}, {"paperId": null, "title": "ShareGPT"}, {"paperId": null, "title": "p4d pricing"}]}