{"paperId": "189fde3f4dfa105bb51472a8945618f395919560", "abstract": "Transformers are the dominant architecture for sequence modeling, but there is growing interest in models that use a fixed-size latent state that does not depend on the sequence length, which we refer to as\"generalized state space models\"(GSSMs). In this paper we show that while GSSMs are promising in terms of inference-time efficiency, they are limited compared to transformer models on tasks that require copying from the input context. We start with a theoretical analysis of the simple task of string copying and prove that a two layer transformer can copy strings of exponential length while GSSMs are fundamentally limited by their fixed-size latent state. Empirically, we find that transformers outperform GSSMs in terms of efficiency and generalization on synthetic tasks that require copying the context. Finally, we evaluate pretrained large language models and find that transformer models dramatically outperform state space models at copying and retrieving information from context. Taken together, these results suggest a fundamental gap between transformers and GSSMs on tasks of practical interest.", "venue": "arXiv.org", "year": 2024, "citationCount": 25, "influentialCitationCount": 4, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "It is proved that a two layer transformer can copy strings of exponential length while GSSMs are fundamentally limited by their fixed-size latent state, and a fundamental gap between transformers and GSSMs on tasks of practical interest is suggested."}, "embedding": {"model": "specter_v2", "vector": [0.7239600419998169, 0.6993688941001892, -0.32327181100845337, -0.01127705816179514, -0.2364538311958313, -0.4676787555217743, 0.9915751218795776, -0.13129468262195587, -0.3769374489784241, -0.2677620053291321, 0.5776199102401733, -0.3537207841873169, 0.327908992767334, 0.06352940201759338, -0.5962169766426086, 0.037666331976652145, -0.7112658023834229, 0.39241254329681396, 0.331770122051239, -0.15879102051258087, 0.2512454390525818, -0.3578685224056244, -1.1323199272155762, 0.0390000194311142, 0.11639098823070526, 0.38501718640327454, 0.349372535943985, 0.6573061943054199, -0.6881707310676575, 0.7205737233161926, 0.4153980314731598, -0.6769987344741821, 0.28741228580474854, -0.3211743235588074, -0.5463010668754578, -0.28539013862609863, 0.3105626404285431, -0.49153998494148254, -0.7746286392211914, 0.6838143467903137, -0.5146386623382568, 0.3155944049358368, 0.17069140076637268, -0.7557122707366943, -0.1436246782541275, 0.9672569036483765, 0.8796729445457458, 0.5887275338172913, 0.19111746549606323, -0.4390915036201477, 1.3807896375656128, -0.5583427548408508, 0.6752372980117798, 1.4676849842071533, 0.5164509415626526, 0.46080923080444336, -0.3460704982280731, -0.6378899812698364, 0.975271999835968, 0.11149679869413376, -0.7372686266899109, -0.2265562117099762, 0.011296423152089119, 0.06342652440071106, 2.1152806282043457, -0.23781685531139374, 0.26131680607795715, 0.5651751756668091, 0.1488800197839737, 1.4817155599594116, 0.1450314074754715, -0.6346947550773621, -0.09580279886722565, -0.05929026007652283, 0.131694033741951, 0.9532403349876404, -0.47651609778404236, 0.46611833572387695, -0.9724658131599426, -0.17301207780838013, 0.6720250844955444, 0.16178251802921295, 0.08793189376592636, -0.4661250114440918, -0.2408490926027298, 0.36676421761512756, 0.3244521915912628, 0.8262333869934082, 0.052492473274469376, 0.8672839403152466, 0.22976835072040558, 0.21221338212490082, -0.0353618748486042, 0.30588921904563904, 0.18181411921977997, 0.27136898040771484, -0.9396660923957825, 0.20794689655303955, 0.0421949066221714, 1.036980390548706, -0.22802530229091644, -0.07131341099739075, -0.8303979635238647, 0.041913192719221115, 1.2232840061187744, -0.41464826464653015, 0.6277570128440857, -0.9020096659660339, 0.2981778681278229, -0.4713341295719147, 0.3566525876522064, -0.46139463782310486, -0.08169789612293243, -0.31383633613586426, -0.5293677449226379, -1.5694247484207153, -0.3942549526691437, 0.6738717555999756, -0.6468730568885803, 0.8876258730888367, -0.4840339124202728, 0.7002761363983154, -0.39126530289649963, 0.10583555698394775, 0.21815118193626404, 0.8379177451133728, 0.5582075715065002, -0.08412912487983704, 0.5783704519271851, -0.4317336976528168, -0.7330021262168884, -1.319460153579712, 0.6276450753211975, 0.23214243352413177, 0.11841528862714767, 0.0029072382021695375, -1.3351739645004272, -0.9854616522789001, -0.9188055992126465, -0.05962049216032028, -0.6910526752471924, 0.07270604372024536, 1.174461841583252, 0.3834766447544098, -0.7840320467948914, 1.2861007452011108, -0.6428565979003906, -0.36987242102622986, 0.5073269605636597, -0.01854878105223179, 0.08966279029846191, -0.5966260433197021, -0.97869873046875, 0.37746620178222656, 0.4876367449760437, -0.5135107040405273, -0.4071149528026581, -0.4611092209815979, -0.9834633469581604, 0.19342395663261414, 0.5756601095199585, -0.43164587020874023, 1.083357810974121, 0.33197641372680664, -1.2062407732009888, 0.704723596572876, -0.6134926676750183, -0.056624703109264374, 0.3570424020290375, -0.11696653813123703, -0.26571953296661377, -0.5630883574485779, -0.3209426999092102, 0.11069565266370773, 0.20836853981018066, -0.35032662749290466, -0.29489633440971375, -0.09863801300525665, -0.3145396411418915, -0.4071022868156433, 0.1617850363254547, 0.8414417505264282, -0.4287298321723938, -0.30442795157432556, 0.5715510845184326, 0.35613808035850525, -0.022433729842305183, -0.08815252035856247, -0.3946390748023987, -1.3759632110595703, 0.23639656603336334, -0.2051626592874527, 1.0412744283676147, -0.6451170444488525, -0.2781907320022583, -0.5399949550628662, -0.2502008378505707, -0.19523000717163086, -0.8838772177696228, 0.939262330532074, -0.4963034391403198, 0.4470522701740265, -0.5491296052932739, -1.0921720266342163, 0.1177682876586914, -0.07567281275987625, -0.7373225092887878, -0.1407170444726944, -0.045413561165332794, 1.2193714380264282, -1.008049488067627, 0.27596375346183777, -0.17358450591564178, -0.054921817034482956, -0.840783417224884, 1.3737554550170898, -0.30356842279434204, -0.07485335320234299, -0.08181243389844894, -0.8369103670120239, -0.08626802265644073, -0.50874924659729, 0.5780142545700073, -0.18314523994922638, 0.18470582365989685, 1.0062187910079956, -0.5342300534248352, 1.7304733991622925, -0.30843713879585266, 0.40453192591667175, -0.4781285524368286, -0.9527437686920166, 0.3424566388130188, 0.05640556663274765, -0.23503901064395905, -0.011463819071650505, 0.04538552090525627, -0.15028516948223114, -0.6676777005195618, 0.25027191638946533, 0.31527256965637207, 0.38458600640296936, -0.23693035542964935, 0.5750864148139954, 0.36537641286849976, -0.5438711047172546, 0.39886540174484253, 0.7306534051895142, 0.9396676421165466, 0.6844887733459473, 0.494616836309433, 0.4039701521396637, -0.057462383061647415, -1.0045970678329468, 0.10996980220079422, 0.4644556939601898, 0.9223335981369019, 0.5325931906700134, 0.42388394474983215, -0.6838886737823486, -0.44376009702682495, -0.22774909436702728, 0.6369595527648926, 1.3047295808792114, -0.15766620635986328, -0.5514617562294006, -0.7074582576751709, -0.013802164234220982, -0.45962783694267273, 0.6281932592391968, -0.6534618139266968, -0.7109986543655396, -0.5765327215194702, -0.8176604509353638, 0.6705916523933411, 0.647602915763855, 1.131263256072998, -0.3808780908584595, -0.18576961755752563, 0.05723012611269951, -0.02462243288755417, -0.6365470886230469, -0.36901986598968506, 0.21157872676849365, -0.9310923218727112, 0.011844063177704811, 0.1327040046453476, -0.03719543665647507, -0.08132872730493546, -0.8450937271118164, 0.6882677674293518, -0.22771309316158295, -0.40928685665130615, 0.18920719623565674, 0.7559938430786133, -0.5496749877929688, -1.0427403450012207, 0.3521774709224701, -0.13733968138694763, -0.2258426696062088, 0.3703102171421051, 0.27072563767433167, 0.1552712321281433, 0.06512149423360825, -0.5048996210098267, 0.44612252712249756, 0.08547628670930862, -0.0209689699113369, 0.3190317451953888, -0.464200496673584, -0.349399596452713, -1.202837586402893, 0.6419574022293091, 0.30187493562698364, -0.5706391930580139, 0.6233508586883545, -0.7859461307525635, -0.12527626752853394, 0.11028669774532318, -0.8257028460502625, -0.37540924549102783, -0.682209849357605, 0.42742934823036194, -0.24018144607543945, -0.16256791353225708, -0.037668392062187195, 0.3793143332004547, 0.7339486479759216, -0.1004461795091629, 0.9009906649589539, 0.4772953987121582, -0.4161062240600586, 0.4544380009174347, -0.9200060367584229, 0.49148789048194885, 0.33249378204345703, 0.2727135121822357, -0.06572001427412033, 0.005010557360947132, -0.3393418490886688, -0.2368353307247162, -0.14094123244285583, -0.2702963948249817, 0.024312341585755348, 0.16251619160175323, -0.3430465757846832, -0.8690493106842041, 0.22318856418132782, -1.0568033456802368, -0.5724380612373352, 0.24457091093063354, -0.5130053758621216, -0.42865535616874695, -0.6853308081626892, -1.4639613628387451, -0.5827862024307251, 0.14145098626613617, -0.9207653999328613, 0.4150102734565735, -0.1689767837524414, -0.30012187361717224, -0.3638289272785187, 0.04496892914175987, -0.19201545417308807, 0.8461500406265259, -0.8196501135826111, 0.8851972222328186, 0.08376511186361313, -0.9186839461326599, -0.35126686096191406, 0.473200261592865, 0.15208004415035248, -0.15405844151973724, 0.029259704053401947, -0.7949760556221008, -0.21150606870651245, -0.6496403813362122, 0.1614055335521698, 0.1632550060749054, 0.10176844894886017, 1.0181612968444824, -0.2447306364774704, -1.1112531423568726, 0.21286636590957642, 1.2554115056991577, -0.3593243360519409, 0.3872377574443817, 0.06546352058649063, 0.5634421110153198, 0.3066626787185669, -0.2796257734298706, 0.4454631507396698, 0.2158341258764267, 0.6742744445800781, 0.05437973141670227, 0.5510385036468506, 0.12098671495914459, -1.1103992462158203, 0.5219475030899048, 1.140406608581543, 0.018837278708815575, -0.03980977460741997, -0.8861281275749207, 0.6807894110679626, -1.0380710363388062, -0.9813701510429382, 1.164023756980896, 0.8760117888450623, 0.4864157736301422, -0.49436238408088684, -0.20976996421813965, -0.16220340132713318, 0.31963157653808594, 0.17340169847011566, -0.6055415868759155, -0.24341851472854614, 0.20101113617420197, 0.4313063621520996, 0.27008286118507385, 0.5727444887161255, 0.07604029774665833, 0.6383509039878845, 15.055110931396484, 0.7973719835281372, 0.12130539119243622, 0.46177878975868225, 0.30624663829803467, -0.10853415727615356, -0.4729292094707489, 0.21846510469913483, -1.200629711151123, 0.09417008608579636, 1.1493600606918335, 0.0927632749080658, 0.9494092464447021, -0.20704469084739685, -0.1882181465625763, 0.28495222330093384, -0.8552138209342957, 0.524220883846283, 0.35016927123069763, -1.548936128616333, 0.4733189642429352, 0.2934165298938751, -0.11830569058656693, 0.3082845211029053, 0.6234820485115051, 0.6996778249740601, 0.644836962223053, -0.6672220826148987, 0.598504900932312, 0.5122676491737366, 0.8737492561340332, 0.3258816599845886, 0.0771915391087532, 0.7174530029296875, -0.7803632616996765, -0.32591724395751953, -0.6878300905227661, -0.9858928322792053, 0.4781557321548462, -0.29049035906791687, -0.3856535255908966, -0.4992574155330658, -0.026201356202363968, 1.0097239017486572, 0.03579806536436081, 0.260353684425354, -0.16836372017860413, 0.7842054963111877, -0.16645340621471405, -0.05058153346180916, 0.09280230104923248, 0.11266003549098969, 0.04182020574808121, -0.2243158221244812, 0.14658701419830322, 0.2434319108724594, -0.1728591024875641, 0.6216893792152405, -0.30861687660217285, -0.3082987368106842, -0.5166319012641907, -0.4303379952907562, 0.36842548847198486, 0.17299608886241913, 0.46077001094818115, 0.05978744849562645, -0.15947765111923218, 0.44595202803611755, 0.6620227098464966, 0.25387224555015564, -0.12993164360523224, -0.09954337775707245, 0.2605515718460083, -0.14168386161327362, 0.2869751751422882, 0.5555769205093384, 0.014809148386120796, -0.3670293390750885, -0.7312029004096985, -0.29392194747924805, 0.43362587690353394, -1.0768364667892456, -0.610450029373169, 0.5314211845397949, 0.05564311891794205, -0.5235379338264465, 0.01919253170490265, -0.7533134818077087, -0.21553301811218262, 0.23661279678344727, -1.1563843488693237, -0.46932005882263184, 0.059548839926719666, -0.2515297830104828, -0.2782209515571594, 0.07173308730125427, 1.061790943145752, -0.266888290643692, -0.42191082239151, 0.19398611783981323, 0.07280880957841873, 0.22352199256420135, -0.4535001814365387, -0.7176368236541748, 1.0168395042419434, 0.1840616762638092, 0.19415073096752167, 1.038920521736145, 0.023210197687149048, -0.06899882107973099, -0.7061792016029358, 0.1059364378452301, 0.6759527921676636, -1.1490199565887451, -0.5345290303230286, -0.7489168047904968, -1.0953409671783447, 1.040081262588501, 0.32919803261756897, -0.5240918397903442, 0.31128165125846863, -0.13725289702415466, -0.8358535170555115, -0.09101647883653641, -0.5280023217201233, 0.10220114141702652, 1.3441208600997925, -0.7968181371688843, -0.5723572373390198, -0.25624191761016846, 0.327704519033432, -0.7687063813209534, -0.7947564721107483, -0.5170116424560547, 0.16675478219985962, -0.02352582849562168, 0.9326532483100891, -0.9389697909355164, 0.5575796365737915, 0.8211305141448975, 0.10897279530763626, -0.8248531222343445, -0.40292346477508545, -1.1589170694351196, 0.28060200810432434, 0.14959470927715302, 0.5263696908950806, -0.8339037895202637, 0.30811139941215515, 0.9415802359580994, 0.5197781920433044, -0.02930237352848053, -0.7611504793167114, -0.6920265555381775, 0.3760252296924591, -0.4433659315109253, 0.7423776388168335, -0.06522087752819061, -0.0864642783999443, 0.10647009313106537, 0.5385836958885193, 0.5472656488418579, -0.10460542142391205, -0.5689250826835632, 0.4105660617351532, -0.3292379379272461, -0.27998384833335876, -0.5816249847412109, -0.4133530855178833, -1.7522562742233276, 0.02486584521830082, -1.3234074115753174, 0.07112658768892288, -1.2858937978744507, -0.18604688346385956, 0.042595259845256805, -0.12288372963666916, 0.08438318222761154, 0.35631030797958374, -0.7214882969856262, -0.32952266931533813, -0.5614250302314758, -0.269603967666626, 0.5857654213905334, 0.7067724466323853, -0.8279121518135071, 0.6736770272254944, -0.07853357493877411, 0.23773041367530823, -0.23081077635288239, 0.31725144386291504, -0.5890836715698242, -0.8539876341819763, -1.2015048265457153, 0.620957612991333, 0.15835444629192352, 0.04765336960554123, -0.34248143434524536, 0.5962314605712891, 0.20931269228458405, -0.36285024881362915, 0.0039513492956757545, 0.5981047749519348, -0.8508821129798889, 0.16490280628204346, 0.5689722299575806, -1.2551100254058838, 0.08139972388744354, 0.13497813045978546, 0.03607713803648949, 0.11840792000293732, 0.358737975358963, -0.18426088988780975, -1.2548288106918335, -0.4450325667858124, 0.33713746070861816, -0.9495197534561157, -0.1548549234867096, -0.18761835992336273, -0.26827749609947205, -1.116422414779663, -0.5404350757598877, 0.022837359458208084, 0.08955692499876022, -0.0558919683098793, 1.0791938304901123, 0.1963888704776764, -0.874001145362854, 0.20662862062454224, 0.00016916212916839868, 0.15407699346542358, 0.03365496173501015, 0.3108503222465515, 0.013751816935837269, -0.042476337403059006, 0.5799881815910339, 0.20949296653270721, 0.4490365982055664, -0.9033138751983643, 0.21900252997875214, 0.7463145852088928, -0.38349246978759766, -0.24095730483531952, 0.9142181873321533, -0.5341132283210754, -1.0258793830871582, 0.23736810684204102, -1.3643641471862793, -0.2659553289413452, -0.5951802134513855, 0.48539260029792786, 0.434606671333313, -0.17326734960079193, 0.3542935252189636, -0.3277229368686676, 0.43428367376327515, 0.0027055577374994755, -0.3158769905567169, 0.8994776606559753, -0.03364589810371399, -0.46824783086776733, 0.8566372990608215, 0.7755351066589355, -1.0525391101837158, -0.7474641799926758, -0.9420584440231323, -0.18762309849262238, -0.3945363461971283, 0.2612655460834503, -0.40972891449928284, -0.288082480430603, 0.8604120016098022, 0.5807293057441711, 0.1798507124185562, -0.12864623963832855, 0.14728960394859314, 0.009446481242775917, 0.6658045053482056, 0.4083418548107147, -0.3542677164077759, -0.4947887659072876, 0.6024059057235718, 1.2852520942687988, -0.49980831146240234, 0.4837765693664551, -0.3480561673641205, -0.42414915561676025, 0.4568631649017334, 0.10782598704099655, -0.04755585640668869, 0.5759400725364685, -0.07393566519021988, -0.12695515155792236, 0.1591486781835556, -1.1724640130996704, 0.13187342882156372, 0.6268614530563354, 1.10554039478302, 0.5741912126541138, -0.025444714352488518, 0.22074203193187714, 0.7032367587089539, 0.05714414641261101, 0.43896177411079407, 0.6631326675415039, 0.7004120349884033, -0.040214113891124725, -0.04399411007761955, 0.40216588973999023, 0.8257369995117188, -0.4228338897228241, -0.47718530893325806, 0.08856038749217987, 0.4178505837917328, -0.274833083152771, 0.49077561497688293, 1.0764447450637817, 0.4286297857761383, 0.5195064544677734, 0.5228452682495117, 0.8587199449539185, -0.46085888147354126, -0.05620863661170006, -0.5329070091247559, -0.6057012677192688, -0.42681416869163513, -0.23737671971321106, -0.8390752077102661, -0.13968560099601746, -0.15535123646259308, 0.1368638277053833, 0.06697625666856766, 0.2464461326599121, 1.1322873830795288, 0.5880621075630188, 0.25095343589782715, -0.40209490060806274, -0.1506250649690628, -0.7048625946044922, -1.1630265712738037, 0.11509836465120316, -0.36735960841178894, -0.39691561460494995, -0.2986067831516266, -0.1633095145225525, -0.056965116411447525]}, "authors": [{"authorId": "47009988", "name": "Samy Jelassi"}, {"authorId": "35402876", "name": "David Brandfonbrener"}, {"authorId": "144695232", "name": "S. Kakade"}, {"authorId": "19201820", "name": "Eran Malach"}], "references": [{"paperId": "9da427202cc48370fd66359f5d72ff5ff3bc8b57", "title": "Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks"}, {"paperId": "57a6c75ebb987ea29a1f904de23f72451e095032", "title": "Is Mamba Capable of In-Context Learning?"}, {"paperId": "85447eeb6e5276e713957835125a2273f9ac0694", "title": "In-Context Language Learning: Architectures and Algorithms"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "4726d1dc54851db99c29180127d840bd19f20afc", "title": "Positional Description Matters for Transformers Arithmetic"}, {"paperId": "1ec3a3ff77cb4b424499b3805ecc90182ecd8f8b", "title": "What Algorithms can Transformers Learn? A Study in Length Generalization"}, {"paperId": "240103933ffe3dac2179cc160a2bd91299357a53", "title": "Retentive Network: A Successor to Transformer for Large Language Models"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "fc1ffc7df07cc9b665deca4a94b871732e1f0b4d", "title": "Length Generalization in Arithmetic Transformers"}, {"paperId": "bfd2b76998a0521c12903ef5ced517adf70ad2ba", "title": "HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution"}, {"paperId": "42cf52baff90952944da0409ec52ff7611ed55dc", "title": "Representational Strengths and Limitations of Transformers"}, {"paperId": "d40dbe668d5b68419e934dfa4c5851ffa1c24aa2", "title": "Exposing Attention Glitches with Flip-Flop Language Modeling"}, {"paperId": "6f6e2e0311589a9af045f6acd00b7dee6d19fce4", "title": "The Impact of Positional Encoding on Length Generalization in Transformers"}, {"paperId": "af385c0fdd0eda2bbf429bea6fedffc327c8a180", "title": "Randomized Positional Encodings Boost Length Generalization of Transformers"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "114b733f6fff0c2b4f2b149d2265bc1c7496a3c9", "title": "Tighter Bounds on the Expressivity of Transformer Encoders"}, {"paperId": "c90a99eeb57019732a6cc996bb9eaf13faedf00f", "title": "In-context Learning and Induction Heads"}, {"paperId": "c6d38add1b7bbc10f0da37a90e3f1b51ee5fb617", "title": "Neural Networks and the Chomsky Hierarchy"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "28c7e583d90ccfc5c3078dfc1d6b80a9ad90248d", "title": "Quantifying Memorization Across Neural Language Models"}, {"paperId": "04db9b694280134f09af5fa787a306907edba29d", "title": "How Much Do Language Models Copy From Their Training Data? Evaluating Linguistic Novelty in Text Generation Using RAVEN"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "1cbb3d96242c3f47c3f40aada33616d0f5c07737", "title": "Inductive Biases and Variable Creation in Self-Attention Mechanisms"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "349eb17c5b61924db8ccc5816c863c6674c8b565", "title": "Saturated Transformers are Constant-Depth Threshold Circuits"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "45e5d7637a585a87d967a4a357d17c5d89aecea2", "title": "A Formal Hierarchy of RNN Architectures"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "c44120f765fc43994c5cfb4e12e4f62999efeae6", "title": "How Context Affects Language Models' Factual Predictions"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "1d6848a71d441226f8b9cef06e7b74339dc374cf", "title": "The Ingenious Gentleman Don Quixote De La Mancha"}, {"paperId": "a1b35b15a548819cc133e3e0e4cf9b01af80e35d", "title": "Sequential Neural Networks as Automata"}, {"paperId": "4d1c856275744c0284312a3a50efb6ca9dc4cd4c", "title": "Know What You Don\u2019t Know: Unanswerable Questions for SQuAD"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "2d876ed1dd2c58058d7197b734a8e4d349b8f231", "title": "Quasi-Recurrent Neural Networks"}, {"paperId": "84069287da0a6b488b8c933f3cb5be759cb6237e", "title": "On the difficulty of training recurrent neural networks"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "a15174ed603bae1b101c4655111bb511787b95b4", "title": "The magical number seven plus or minus two: some limits on our capacity for processing information."}, {"paperId": null, "title": "Statistically meaningful approximation: a case study on approximating turing 11"}, {"paperId": null, "title": "An incremental large language model for long text processing in the brain"}, {"paperId": null, "title": "than State Space Models at Copying machines with transformers"}, {"paperId": null, "title": "Transformers as recognizers of formal languages: A survey on expressivity"}]}