{"paperId": "9af3c1be7a4cfd38f10b9373e4623f4b64d467cd", "abstract": "Identifying important neurons for final predictions is essential for understanding the mechanisms of large language models. Due to computational constraints, current attribution techniques struggle to operate at neuron level. In this paper, we propose a static method for pinpointing significant neurons for different outputs. Compared to seven other methods, our approach demonstrates superior performance across three metrics. Additionally, since most static methods typically only identify\"value neurons\"directly contributing to the final prediction, we introduce a static method for identifying\"query neurons\"which activate these\"value neurons\". Finally, we apply our methods to analyze the localization of six distinct types of knowledge across both attention and feed-forward network (FFN) layers. Our method and analysis are helpful for understanding the mechanisms of knowledge storage and set the stage for future research in knowledge editing. We will release our data and code on github.", "venue": "", "year": 2023, "citationCount": 2, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A static method for pinpointing significant neurons for different outputs and applies its methods to analyze the localization of six distinct types of knowledge across both attention and feed-forward network layers."}, "embedding": {"model": "specter_v2", "vector": [0.06498580425977707, 0.7758205533027649, -0.1188887432217598, 0.07642757892608643, 0.07258224487304688, -0.023559769615530968, 0.827255368232727, -0.24327877163887024, -0.5578345656394958, -0.10308851301670074, 0.7152044177055359, 0.22338923811912537, 0.45401352643966675, 0.002999932738021016, -0.36507079005241394, -0.0664660632610321, -0.6217986941337585, 0.14225158095359802, 0.18988358974456787, -0.06267258524894714, 0.16350170969963074, -0.4933978319168091, -1.2156212329864502, 0.46024248003959656, -0.3235078752040863, 0.6843978762626648, 0.5702391862869263, 0.7986792922019958, -0.6139314770698547, 0.6653993129730225, 0.34130433201789856, -0.17359469830989838, -0.04914001747965813, 0.21758374571800232, -0.589694082736969, -0.5446431040763855, 0.21742059290409088, -0.3391466736793518, -0.5934644937515259, 0.9118996858596802, -0.36067965626716614, 0.08618549257516861, 0.5925830602645874, -0.851880669593811, -0.34598857164382935, 1.3376410007476807, 0.9822664260864258, 0.9795653223991394, -0.42636534571647644, -0.3454509973526001, 1.1015737056732178, -1.2969999313354492, 0.49624109268188477, 1.6978944540023804, 0.3990029990673065, 0.3349071145057678, -0.04011474922299385, -0.6641696691513062, 1.1185334920883179, 0.15362265706062317, -1.0110784769058228, -0.511091947555542, -0.021981537342071533, -0.07431942969560623, 2.0939202308654785, -0.7135524749755859, 0.010187719948589802, 0.8539156913757324, 0.1744750589132309, 1.4954657554626465, -0.07482589781284332, -0.9680463671684265, -0.29397517442703247, 0.4118576645851135, 0.15134109556674957, 0.8409647345542908, -0.513401210308075, 0.11949355900287628, -1.0337176322937012, -0.1790454238653183, 0.977213978767395, -0.218534916639328, -0.1510123312473297, 0.2737116515636444, -0.8546072840690613, 0.43729910254478455, 0.3830147981643677, 0.711780309677124, -0.6225400567054749, 0.8789321184158325, 0.11347085982561111, 0.4171474277973175, -0.5917807221412659, 0.6045653820037842, -0.23090356588363647, 0.5326815247535706, -0.6319580078125, 0.09581795334815979, 0.17497192323207855, 0.7260737419128418, -0.004514739383012056, 0.4540414810180664, -0.839509129524231, 0.19948330521583557, 1.6113615036010742, -0.07491219788789749, 0.7903282642364502, -1.3944361209869385, -0.05486433953046799, -0.7070013284683228, 0.3967398405075073, -0.9849960207939148, 0.11530426889657974, -0.4552258849143982, -0.2000662386417389, -0.9809423089027405, -0.2365226298570633, 0.14380893111228943, -0.6086297631263733, 0.9894745349884033, -0.6130123734474182, 0.03687772527337074, 0.1322440207004547, 0.4752201437950134, 0.4479176998138428, 0.5265179872512817, 0.37888893485069275, 0.4209243059158325, 0.9208328127861023, -0.8232060074806213, -0.6401956677436829, -0.8552916646003723, 0.18740509450435638, -0.13284233212471008, -0.030381500720977783, -0.34564709663391113, -1.2024520635604858, -0.850669801235199, -0.7146186232566833, 0.010714617557823658, -0.6390489339828491, 0.15127968788146973, 1.003970980644226, -0.27765989303588867, -1.290942907333374, 1.1114462614059448, 0.14076589047908783, -0.12532079219818115, 0.5006471872329712, 0.5521664619445801, 0.5043529868125916, 0.1595963090658188, -1.5912096500396729, 0.44139808416366577, 0.29284659028053284, -0.4647214114665985, -0.3723677694797516, -0.16885073482990265, -0.7364655137062073, 0.40521085262298584, 0.37508854269981384, -0.8843645453453064, 1.4301340579986572, -0.636611819267273, -1.078644871711731, 0.5301584601402283, -0.6888529062271118, 0.00886504165828228, -0.1510271430015564, 0.17524731159210205, -0.7297453880310059, -0.1588994264602661, -0.3001006543636322, 1.3113740682601929, 0.5779513120651245, -0.6280543804168701, -0.3280114531517029, 0.3286396563053131, -0.10160930454730988, -0.02233932353556156, -0.5172077417373657, 1.0099396705627441, -0.3926774561405182, -0.16201460361480713, 0.2876001000404358, 0.71778404712677, 0.2700948715209961, 0.015962375327944756, -0.2515868544578552, -1.145306944847107, 0.1685027927160263, 0.037808556109666824, 0.8105495572090149, -0.7587946653366089, -0.6546622514724731, -0.1227249801158905, 0.18072901666164398, -0.36848679184913635, -0.8816014528274536, 0.21562613546848297, -0.17342810332775116, 0.6023672819137573, -0.037670381367206573, -0.8466300964355469, -0.055926647037267685, -0.16432559490203857, -0.7530844211578369, -0.624866247177124, -0.04124096781015396, 1.2219321727752686, -0.8669043779373169, -0.26084819436073303, -0.24808719754219055, 0.23777170479297638, -0.523288905620575, 0.9664312601089478, -0.49645161628723145, -0.3536096513271332, -0.021364204585552216, -0.2521088421344757, -0.29983842372894287, -0.42754435539245605, 0.22558531165122986, -0.5091805458068848, -0.23354016244411469, 0.35507625341415405, -0.5331692099571228, 1.074790120124817, -0.1704348474740982, 0.9382058382034302, -0.04394847899675369, -0.2850189507007599, -0.01812828704714775, 0.6748780608177185, -0.49658849835395813, -0.23303186893463135, 0.4745061695575714, 0.3676672577857971, -0.43306228518486023, 0.2501080334186554, 0.4525182843208313, 1.0277215242385864, -0.1416192501783371, 0.18317624926567078, 0.8050060868263245, 0.16276690363883972, 0.16000357270240784, 0.39041998982429504, 0.4099924564361572, 0.23787669837474823, 0.45836642384529114, -0.07899235188961029, 0.050683725625276566, -0.7950536608695984, -0.04583844915032387, 0.6909277439117432, 0.6264952421188354, 0.8349703550338745, 0.6310418844223022, -0.707131028175354, -0.12092496454715729, 0.2259918451309204, 0.6096792221069336, 1.2410818338394165, -0.24119111895561218, 0.0175075214356184, -0.677105724811554, 0.39034515619277954, -0.08837290108203888, 0.5661756992340088, -0.6951670050621033, -0.07865317165851593, -0.26612505316734314, -0.7413327097892761, 0.899092972278595, 0.5052387714385986, 0.7641282677650452, -1.1450566053390503, -0.18111388385295868, -0.29896479845046997, 0.3423701524734497, -0.6113450527191162, -0.28849533200263977, 0.5258181691169739, -0.6223269104957581, 0.011068209074437618, 0.17297665774822235, -0.3774589002132416, 0.16991429030895233, -0.6461012363433838, 0.8619089722633362, -0.369351863861084, 0.0007879004697315395, -0.000731937529053539, 1.2089619636535645, -0.9403744339942932, -0.6884169578552246, 0.21517230570316315, 0.22532762587070465, -0.027910569682717323, 0.31986862421035767, 0.6857771277427673, -0.1916007250547409, 0.024036772549152374, -0.3114819824695587, 0.24492870271205902, 0.27217742800712585, -0.1731293797492981, 0.9959135055541992, -0.362899512052536, 0.3495321571826935, -1.0804461240768433, 0.8239718079566956, -0.2860700190067291, -0.43322044610977173, 0.2580387592315674, -0.8331558108329773, -0.09929779917001724, 0.5099955797195435, -0.45681965351104736, -0.4127197265625, -0.8964128494262695, 0.5427355766296387, -0.6793211698532104, -0.6149613261222839, 0.40205809473991394, 0.5536175966262817, 0.1003018394112587, 0.18933404982089996, 0.479779988527298, 0.2693060338497162, -0.08923424780368805, 0.2786083519458771, -0.8297764658927917, 0.7795439958572388, 0.46720317006111145, -0.33159324526786804, -0.16609856486320496, -0.35445624589920044, -0.6372273564338684, -0.5021096467971802, -0.39453378319740295, -0.24859343469142914, -0.16667616367340088, 0.07388325780630112, -0.7047372460365295, -0.9131970405578613, 0.18157550692558289, -1.2802786827087402, -0.4003469944000244, 0.22647060453891754, -0.23097245395183563, -0.0395873598754406, -1.2124296426773071, -1.1218246221542358, -0.5171266794204712, -0.2061026245355606, -0.6731724739074707, -0.22274968028068542, 0.23152123391628265, -0.6955206990242004, -0.8510060906410217, -0.3082965910434723, -0.5791884660720825, 1.3656021356582642, -0.8870512247085571, 1.0399752855300903, -0.017056703567504883, -0.2689579725265503, -0.17509660124778748, 0.1525464802980423, 0.2654072344303131, -0.5086774826049805, 0.03395911306142807, -1.2526038885116577, 0.6917038559913635, -0.2656741142272949, -0.277556449174881, 0.6571584343910217, 0.46763694286346436, 1.3184654712677002, -0.06502945721149445, -0.6902470588684082, 0.1938534379005432, 1.4457350969314575, -0.7922031283378601, -0.06962477415800095, 0.35934725403785706, 0.8787612915039062, 0.31237733364105225, -0.7870538830757141, 0.35276326537132263, 0.4088081419467926, 0.4925094544887543, 0.47821131348609924, 0.07477949559688568, -0.46222856640815735, -0.6832279562950134, 0.369405597448349, 1.1355891227722168, -0.13394895195960999, -0.02044066973030567, -0.7948607206344604, 0.7412351965904236, -1.3243720531463623, -0.8714587092399597, 0.6838242411613464, 0.8927006125450134, 0.5805055499076843, -0.35747095942497253, -0.7998529672622681, -0.49941736459732056, 0.6376111507415771, 0.18277183175086975, -0.5605481863021851, -0.686306357383728, -0.2615633010864258, -0.11808275431394577, 0.22030521929264069, 0.7523620128631592, -0.3178471028804779, 0.6485477089881897, 14.500129699707031, 0.4569229483604431, -0.15053978562355042, 0.6750032305717468, 0.46102413535118103, 0.33383291959762573, -0.6028852462768555, -0.3240729570388794, -1.5558581352233887, -0.20507271587848663, 1.5516289472579956, 0.31382712721824646, 0.9308363795280457, -0.029524395242333412, -0.18110178411006927, 0.22305846214294434, -0.28246405720710754, 0.6485856175422668, 0.704584538936615, -1.4711910486221313, 0.5818136930465698, 0.0027276116888970137, 0.3566332459449768, 0.7857500910758972, 0.6508554816246033, 0.7690330147743225, 0.3327847719192505, -0.5581660866737366, 0.7488245964050293, 0.8112390637397766, 0.6379426121711731, 0.19518762826919556, 0.37598633766174316, 0.5630850791931152, -0.6566190123558044, -0.49753427505493164, -0.8849458694458008, -1.0753687620162964, 0.06468919664621353, -0.17893017828464508, -0.6899787187576294, -1.1387218236923218, -0.33299174904823303, 0.467854380607605, -0.06913413852453232, 0.2916707992553711, -0.43257537484169006, 0.7935659289360046, -0.12729820609092712, -0.08577526360750198, 0.19271579384803772, 0.977939784526825, 0.2687441110610962, -0.09667171537876129, 0.03524932637810707, -0.05250615254044533, -0.2604844272136688, 0.9997231364250183, -0.8673213124275208, -0.14762812852859497, -0.048663824796676636, -0.4042603671550751, 0.24046581983566284, 0.8193780183792114, 0.24558880925178528, 0.22667932510375977, -0.32639822363853455, 0.5868956446647644, 0.837344765663147, 0.5315744876861572, 0.12585875391960144, 0.07148335874080658, 0.4720492959022522, -0.3185703754425049, 0.3721516728401184, 0.8482293486595154, -0.1500614732503891, -0.41268911957740784, -0.9323025345802307, 0.16910715401172638, 0.16766561567783356, -1.272003173828125, -0.4988756775856018, 0.9455508589744568, -0.2527749836444855, 0.18556581437587738, 0.14593955874443054, -1.0564253330230713, -0.25678330659866333, 0.610958456993103, -1.5425316095352173, -0.5902433395385742, 0.2006998360157013, 0.042802561074495316, -0.3798179030418396, -0.33715057373046875, 1.7660865783691406, -0.3058362901210785, -0.32848095893859863, -0.04789780080318451, 0.15963426232337952, -0.06301941722631454, -0.07893451303243637, -0.8624730110168457, 0.49930331110954285, 0.007953779771924019, 0.15711194276809692, 0.6005892157554626, -0.27508044242858887, 0.048721253871917725, -0.4609282314777374, -0.1302342712879181, 1.291654109954834, -1.024200201034546, -0.6479448080062866, -0.4547499120235443, -1.0113704204559326, 0.5065274238586426, 0.8895851969718933, -0.40697169303894043, 0.21205741167068481, 0.3038693070411682, -0.7033876776695251, 0.17907939851284027, -0.47365567088127136, 0.17870891094207764, 0.3419729471206665, -0.6310011744499207, -0.566196084022522, -0.1374286264181137, 0.23788270354270935, -0.629483699798584, -0.44441208243370056, -0.6047549247741699, 0.046910956501960754, 0.20266160368919373, 0.9817979335784912, -0.7329286932945251, 0.6080463528633118, 0.41778358817100525, -0.2574508786201477, -0.9031461477279663, -0.5763899087905884, -0.605644941329956, -0.267202764749527, -0.006412578746676445, 1.1071053743362427, -0.6395035982131958, -0.35785529017448425, 0.8844703435897827, 0.06001095101237297, -0.4455624222755432, -0.4243381917476654, 0.014528180472552776, -0.033850137144327164, -0.43403398990631104, 0.32597827911376953, -0.10522154718637466, -0.37007617950439453, 0.14331017434597015, 0.6619466543197632, 0.5917761325836182, -0.4824798107147217, -0.5900976061820984, -0.3681953251361847, -0.2932286560535431, -0.0723210796713829, -0.7412970662117004, -0.0998058170080185, -1.2113372087478638, 0.20225627720355988, -1.4417256116867065, -0.07078002393245697, -1.4584298133850098, -0.259743332862854, 0.07493583112955093, -0.9145230054855347, 0.7221147418022156, 0.48334309458732605, -0.3596915006637573, -0.46584585309028625, 0.12856987118721008, -0.6800179481506348, 0.3082921504974365, 0.6682838201522827, -0.3652370572090149, 0.11306875199079514, -0.19121213257312775, -0.2656297981739044, 0.4859845042228699, 0.5790389776229858, -0.531385064125061, -0.6632039546966553, -1.5724574327468872, 0.7552880644798279, -0.5148684978485107, 0.10657308995723724, -0.773152232170105, 1.0725940465927124, 0.4524882435798645, 0.3058274984359741, 0.2526914179325104, 0.49551230669021606, -0.6982675194740295, -0.4765060544013977, 0.13988050818443298, -1.0143985748291016, -0.06666623055934906, 0.26726624369621277, -0.45596078038215637, -0.22913190722465515, 0.46977725625038147, -0.21827435493469238, -1.4175139665603638, -1.1532248258590698, 0.21393617987632751, -0.6627159714698792, -0.06074637919664383, -0.407612681388855, -0.29725518822669983, -1.157138705253601, -0.22785162925720215, -0.12533500790596008, 0.23381364345550537, -0.3809300661087036, 0.9536669254302979, 0.7298995852470398, -0.9206764698028564, 0.13415475189685822, 0.36392319202423096, -0.03904084488749504, -0.361785352230072, 0.25905245542526245, 0.3037542998790741, 0.12223253399133682, 0.7823765277862549, 0.0294181015342474, 0.6379411816596985, -0.46407240629196167, -0.12850137054920197, 0.9515058994293213, 0.22293294966220856, -0.16448546946048737, 1.2804464101791382, -0.3160388469696045, -1.045784592628479, 0.3324688673019409, -1.3853850364685059, -1.0228452682495117, -0.04389915242791176, 0.5511278510093689, -0.119756318628788, -0.148241326212883, -0.1823626309633255, -0.2886245548725128, -0.04097207635641098, 0.1620265692472458, -0.5525544285774231, 0.0901150181889534, -0.3098198175430298, -0.3182469606399536, 1.107793927192688, 0.7284281849861145, -0.8033172488212585, -0.7484098672866821, -0.6253023147583008, -0.5606919527053833, 0.16366074979305267, 0.6871832013130188, -0.7291191816329956, -0.6262152194976807, 1.0260392427444458, 0.4351225197315216, -0.04130135476589203, -0.4038994014263153, 0.14402620494365692, 0.021240366622805595, 0.8870925903320312, -0.027759108692407608, -0.7300336956977844, -0.6049558520317078, 1.4493149518966675, 1.4926921129226685, -0.7828968167304993, -0.19138561189174652, -0.12475045025348663, -0.7390245795249939, 1.128781795501709, 0.4941152036190033, 0.17102888226509094, 0.7870123982429504, -0.3325827121734619, 0.1549667865037918, 0.016053691506385803, -1.4192806482315063, 0.05361223593354225, 0.4111872613430023, 0.7277352809906006, 0.6890931725502014, 0.4615863859653473, 0.48584017157554626, 0.9805401563644409, 0.06977617740631104, 0.2979249060153961, 0.4566601812839508, 0.24346299469470978, -0.5960759520530701, 0.4641910195350647, 0.07162003219127655, 0.9443594813346863, -0.412212610244751, -0.8639531135559082, 0.05612233281135559, 0.28685590624809265, 0.28538835048675537, 0.34434932470321655, 0.8382527232170105, 0.2802248001098633, 0.39652112126350403, 0.7032954692840576, 0.5292046070098877, -0.548460066318512, -0.3989867866039276, -0.2699151635169983, -0.5320413112640381, -0.07814649492502213, -0.1581207662820816, -0.6671898365020752, -0.9358298778533936, 0.05218609794974327, 0.3952975571155548, -0.3789956867694855, 0.432721883058548, 1.1022167205810547, 0.9422487616539001, 0.6111133098602295, -0.7100353837013245, -0.2869220972061157, -0.4518139362335205, -0.9732577800750732, 0.14419612288475037, -0.789649248123169, -0.4584153890609741, -0.4509207010269165, -0.3672756254673004, -0.04435518756508827]}, "authors": [{"authorId": "2263692531", "name": "Zeping Yu"}, {"authorId": "2240623492", "name": "Sophia Ananiadou"}], "references": [{"paperId": "44c5c804442b635a745390d7d17b1ecb5e3ca89a", "title": "Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era"}, {"paperId": "1301ed763095097ff424c668e16a265b3ae2f231", "title": "Dictionary Learning Improves Patch-Free Circuit Discovery in Mechanistic Interpretability: A Case Study on Othello-GPT"}, {"paperId": "26b2adbe089ea36617c3ec0aa009319929da0550", "title": "A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity"}, {"paperId": "07c2c3b4af7e4ff1577f36f47f1c93398a6df648", "title": "Successor Heads: Recurring, Interpretable Attention Heads In The Wild"}, {"paperId": "49a02664e552320a43cea541c07ca312e45350b5", "title": "Future Lens: Anticipating Subsequent Tokens from a Single Hidden State"}, {"paperId": "c16c05ca0a3d24519405849fd24604fc1ce47751", "title": "Towards Best Practices of Activation Patching in Language Models: Metrics and Methods"}, {"paperId": "26089bdfdbca1e6eaaceca71e3116b715bec6d47", "title": "Explainability for Large Language Models: A Survey"}, {"paperId": "628b131f8f309d583ccf1da268f520c051169ddd", "title": "Journey to the Center of the Knowledge Neurons: Discoveries of Language-Independent Knowledge Neurons and Degenerate Knowledge Neurons"}, {"paperId": "77f02ff24909896856fec410968aef7999c29440", "title": "Does Circuit Analysis Interpretability Scale? Evidence from Multiple Choice Capabilities in Chinchilla"}, {"paperId": "9806cac2d36feda043dcdfe0f4de2608127da27c", "title": "Towards Understanding In-Context Learning with Contrastive Demonstrations and Saliency Maps"}, {"paperId": "7bd4ca8706a79983d31ab74e6c79bfdfd949602e", "title": "Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning"}, {"paperId": "12910786da7a34c9ee26798fd81b0ed7b0e38789", "title": "Finding Neurons in a Haystack: Case Studies with Sparse Probing"}, {"paperId": "133b97e40017a9bbbadd10bcd7f13088a97ca3cc", "title": "Dissecting Recall of Factual Associations in Auto-Regressive Language Models"}, {"paperId": "eefbd8b384a58f464827b19e30a6920ba976def9", "title": "Towards Automated Circuit Discovery for Mechanistic Interpretability"}, {"paperId": "8d8fc878bf4c7005546c866824a72d0c46ca91a3", "title": "Localizing Model Behavior with Path Patching"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "f680d47a51a0e470fcb228bf0110c026535ead1b", "title": "Progress measures for grokking via mechanistic interpretability"}, {"paperId": "9c0a434b240299cec0029a1be93ab263d7ec9963", "title": "Does Localization Inform Editing? Surprising Differences in Causality-Based Localization vs. Knowledge Editing in Language Models"}, {"paperId": "6edd112383ad494f5f2eba72b6f4ffae122ce61f", "title": "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small"}, {"paperId": "9d125f45b1d2dea01f05281470bc08e12b6c7cba", "title": "Toy Models of Superposition"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "cf36236015c9f93f15bfafbf282f69e08bdc9c16", "title": "Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "b0ceba96db8b7b71beb2f0906568ffc143fddbf9", "title": "A Rigorous Study of Integrated Gradients Method and Extensions to Internal Neuron Attributions"}, {"paperId": "996445d847f06e99b0bd259345408a0cf1bce87e", "title": "Locating and Editing Factual Associations in GPT"}, {"paperId": "da130d6538eeeacfb3a0da4cff106c098f74cdd4", "title": "Attention Flows are Shapley Value Explanations"}, {"paperId": "2c871df72c52b58f05447fcb3afc838168d94505", "title": "Knowledge Neurons in Pretrained Transformers"}, {"paperId": "e1872cbe03dd45b5323f9c30facca5e3d6d95f14", "title": "VisQA: X-raying Vision and Language Reasoning in Transformers"}, {"paperId": "4a54d58a4b20e4f3af25cea3c188a12082a95e02", "title": "Transformer Feed-Forward Layers Are Key-Value Memories"}, {"paperId": "33422275fbb9958f55419620697faf531482699b", "title": "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering"}, {"paperId": "6936f7e97ed4a587fcb347d0636f1e5cbcadf227", "title": "Investigating Saturation Effects in Integrated Gradients"}, {"paperId": "5a5cb1d36d3ab64fc1941d05ec4387c4e62feac7", "title": "Why Attentions May Not Be Interpretable?"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "3d61a34611c6171f203286119f76ec52f8016580", "title": "Towards Transparent and Explainable Attention Models"}, {"paperId": "ce177672b00ddf46e4906157a7e997ca9338b8b9", "title": "Attention is not not Explanation"}, {"paperId": "874e9318c09c711ecd48a903b3824a3a03e2cd62", "title": "Explain Yourself! Leveraging Language Models for Commonsense Reasoning"}, {"paperId": "135112c7ba1762d65f39b1a61777f26ae4dfd8ad", "title": "Is Attention Interpretable?"}, {"paperId": "1e83c20def5c84efa6d4a0d80aa3159f55cb9c3f", "title": "Attention is not Explanation"}, {"paperId": "62e39c6dbcead1fe4d29017914591d929aa6ac4c", "title": "The (Un)reliability of saliency methods"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "f302e136c41db5de1d624412f68c9174cf7ae8be", "title": "Axiomatic Attribution for Deep Networks"}, {"paperId": "d8574a62874312b81347438b1566cdb1c6d5abe5", "title": "Direct and Indirect Effects"}, {"paperId": "78d08b8ab4132defffe98ec7f80a51452203f70d", "title": "Investigating Gender Bias in Language Models Using Causal Mediation Analysis"}, {"paperId": null, "title": "gpt: the logit lens"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Bertviz: A tool for visualizing mul-tihead self-attention in the bert model"}, {"paperId": null, "title": "2022. Analyzing transformers in embedding space"}, {"paperId": null, "title": "2023. At-tentionviz: A global view of transformer attention"}, {"paperId": null, "title": "A mathematical framework for transformer circuits"}, {"paperId": null, "title": "2023. How does gpt-2 compute greater-than?: In-terpreting mathematical abilities in a pre-trained language model"}, {"paperId": null, "title": "2023. Char-acterizing mechanisms for factual recall in language models"}, {"paperId": null, "title": "2023. Towards monosemanticity: Decom-posing language models with dictionary learning"}, {"paperId": null, "title": "2022. Mechanistic interpretability, variables, and the importance of interpretable bases"}, {"paperId": null, "title": "2023b. Fact finding: Attempting to reverse-engineer factual recall on the neuron level"}, {"paperId": null, "title": "2022. In-context"}, {"paperId": null, "title": "2024b. Interpretabil-ity at scale: Identifying causal mechanisms in alpaca"}]}