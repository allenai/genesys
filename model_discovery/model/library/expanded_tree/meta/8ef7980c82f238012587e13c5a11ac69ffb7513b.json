{"paperId": "8ef7980c82f238012587e13c5a11ac69ffb7513b", "abstract": "The capacity of Large Language Models (LLMs) to comprehend and reason over long contexts is pivotal for advancements in diverse fields. Yet, they still stuggle with capturing long-distance dependencies within sequences to deeply understand semantics. To address this issue, we introduce Query-aware Inference for LLMs (Q-LLM), a system designed to process extensive sequences akin to human cognition. By focusing on memory data relevant to a given query, Q-LLM can accurately capture pertinent information within a fixed window size and provide precise answers to queries. It doesn't require extra training and can be seamlessly integrated with any LLMs. Q-LLM using LLaMA3 (QuickLLaMA) can read Harry Potter within 30s and accurately answer the questions. Q-LLM improved by 7.17% compared to the current state-of-the-art on LLaMA3, and by 3.26% on Mistral on the $\\infty$-bench. In the Needle-in-a-Haystack task, On widely recognized benchmarks, Q-LLM improved upon the current SOTA by 7.0% on Mistral and achieves 100% on LLaMA3. Our code can be found in https://github.com/dvlab-research/Q-LLM.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Query-aware Inference for LLMs (Q-LLM), a system designed to process extensive sequences akin to human cognition, can accurately capture pertinent information within a fixed window size and provide precise answers to queries by focusing on memory data relevant to a given query."}, "embedding": {"model": "specter_v2", "vector": [-0.13329514861106873, 0.13682128489017487, -0.513871967792511, -0.4686831533908844, -0.3485656678676605, -0.305899441242218, 0.5669936537742615, 0.3227859139442444, -0.7756390571594238, -0.08902034163475037, 0.525814414024353, -0.20512807369232178, 0.42402228713035583, 0.023510046303272247, -0.11045198887586594, 0.4564612805843353, -1.0428025722503662, 0.6245136260986328, 0.3174326717853546, -0.37721288204193115, 0.1392749398946762, -0.4055560529232025, -1.1057653427124023, 0.47342413663864136, 0.2736961841583252, 0.4140535295009613, 0.30101972818374634, 1.0345808267593384, -0.3498653173446655, 0.5357613563537598, 0.38431259989738464, -0.10992385447025299, -0.4075767993927002, 0.4118863344192505, -0.741946280002594, -0.5177217721939087, -0.038579683750867844, -0.48527345061302185, -0.33083656430244446, 0.4077140986919403, -0.18459120392799377, 0.4356115460395813, 0.42524319887161255, -0.5373436212539673, -0.19099949300289154, 0.6914417147636414, 0.6655054688453674, 0.8418217301368713, 0.02193102240562439, -0.6515151858329773, 1.685086965560913, -1.5644968748092651, 0.3102048337459564, 1.7044939994812012, 0.27902695536613464, 0.25839099287986755, -0.22623610496520996, -0.2542002499103546, 0.7247933149337769, 0.43101802468299866, -0.9104931354522705, -0.3173251152038574, -0.6786620020866394, 0.2661428153514862, 2.264767646789551, -0.030104542151093483, -0.1876019984483719, 0.506991982460022, -0.09159546345472336, 1.5523314476013184, -0.17803721129894257, -0.8175116181373596, 0.02370774745941162, -0.06929652392864227, 0.5660690069198608, 0.8261501789093018, -0.42706093192100525, 0.0359659269452095, -1.0400832891464233, -0.4445536732673645, 0.14332744479179382, 0.11324034631252289, 0.18317599594593048, -0.052631307393312454, -0.5465468168258667, 0.802189826965332, 0.3527277410030365, 0.7353321313858032, -0.25298452377319336, 0.40717869997024536, 0.1579907089471817, 0.17170579731464386, -0.1960965245962143, 0.5310620069503784, -0.3942790627479553, 0.008665061555802822, -0.8216031193733215, 0.6346056461334229, 0.5003578662872314, 0.7875394821166992, -0.1599370837211609, -0.4398634433746338, -0.6513657569885254, 0.11019298434257507, 1.3976010084152222, 0.16737088561058044, 0.330308735370636, -0.8776291608810425, 0.23186826705932617, -0.5873861312866211, 0.43999430537223816, -0.4445367753505707, -0.5344232320785522, -0.0975879579782486, -0.19109447300434113, -1.4688618183135986, -0.3253386616706848, 0.12289576232433319, -0.27219510078430176, 0.596049427986145, -0.051788028329610825, -0.13542360067367554, -0.024326397106051445, 0.5436782836914062, 0.544256329536438, 0.8111463189125061, 0.3305903673171997, -0.056293901056051254, 1.229898452758789, -0.929887056350708, -0.47202223539352417, -1.3587180376052856, 1.2424579858779907, 0.05793851986527443, 0.37804877758026123, -0.26256322860717773, -1.1122422218322754, -0.8541674613952637, -0.821796715259552, -0.32686305046081543, -0.8294771909713745, 0.029967566952109337, 1.0441503524780273, 0.0384858101606369, -0.8875279426574707, 0.5412144064903259, -0.3523256480693817, -0.3464123010635376, 0.06634712219238281, -0.04347037523984909, 0.35219186544418335, -0.644517719745636, -1.492475152015686, 0.3990819752216339, 0.2539968490600586, -0.6014953851699829, -0.23126257956027985, -0.5962764620780945, -1.2171710729599, -0.07753886282444, 0.6326245665550232, -0.4292003810405731, 1.4635151624679565, 0.5475648641586304, -0.83702152967453, 0.6457141637802124, -0.7688243985176086, 0.0023738679010421038, 0.10816363990306854, -0.32450300455093384, -0.7389782667160034, -0.45616671442985535, -0.17307765781879425, 0.5830581784248352, 0.08563462644815445, -0.0138495909050107, -0.4295244812965393, -0.09305015206336975, -0.13402265310287476, -0.25604528188705444, 0.1330462247133255, 1.0618194341659546, -0.49053338170051575, -0.1092558279633522, 0.333016574382782, 0.6141392588615417, -0.1780116856098175, 0.07899802923202515, -0.41051965951919556, -1.2662043571472168, 0.6191668510437012, 0.1443750560283661, 1.2252241373062134, -0.827826201915741, -0.5864622592926025, -0.36147886514663696, -0.018398327752947807, -0.07336011528968811, -0.7234929203987122, 0.9522516131401062, -0.08362741768360138, 0.47826623916625977, -0.6150755882263184, -1.105611801147461, 0.09381872415542603, 0.17483682930469513, -0.7843335270881653, -0.4277575612068176, 0.08969847112894058, 1.126476526260376, -1.0975487232208252, -0.2242439091205597, -0.2701247036457062, 0.053338438272476196, -1.1588644981384277, 1.4455821514129639, -1.1317510604858398, 0.0025433998089283705, -0.34115317463874817, -0.07337421923875809, -0.0021820301190018654, -0.42754894495010376, 0.367880254983902, -0.2580609917640686, -0.3114083409309387, 0.4133199453353882, -0.3296136260032654, 1.5543863773345947, -0.36661455035209656, 0.1709623485803604, -0.3440297842025757, -0.3807990550994873, -0.1422801911830902, 0.135450541973114, -0.4968556761741638, -0.4353936016559601, -0.13938619196414948, 0.39421331882476807, -0.5479113459587097, -0.31138479709625244, 0.7002445459365845, 0.8728319406509399, -0.4649440050125122, 0.445953905582428, 0.06053251400589943, -0.3424014747142792, 0.5216264724731445, 0.5324901342391968, 0.6476669311523438, 0.2986385226249695, 0.7033920288085938, -0.01860108971595764, 0.5251553058624268, -0.7143162488937378, -0.20947861671447754, 0.8116576075553894, 0.9676515460014343, 0.5242413878440857, 0.3701172173023224, -0.9651080965995789, -0.13977627456188202, 0.2632104158401489, 0.4926707148551941, 1.787251591682434, 0.05026339367032051, -0.4837947189807892, -0.5452478528022766, -0.3785797655582428, -0.06256565451622009, 0.5603587031364441, -0.45175376534461975, 0.18456046283245087, -0.3860538601875305, -0.9204334020614624, 0.8910266757011414, 0.6031481027603149, 0.8448436260223389, -0.6906400322914124, -0.5537808537483215, -0.28863200545310974, 0.021151956170797348, -0.8003664016723633, -0.41487959027290344, 0.27602729201316833, -0.5418647527694702, -0.07589512318372726, 0.5770073533058167, 0.0342811718583107, 0.03624579310417175, -0.7093836069107056, 1.099103331565857, -0.31478244066238403, -0.40268978476524353, -0.0201518964022398, 0.5945653915405273, -0.46517279744148254, -0.6250951290130615, 0.22423604130744934, -0.04004179313778877, -0.43609386682510376, 0.5529330968856812, 0.4943646192550659, 0.0010687652975320816, 0.24711111187934875, -0.6198339462280273, 0.2067740112543106, 0.24048198759555817, -0.16325882077217102, 0.6221815347671509, -0.4602760970592499, 0.22318683564662933, -1.3521490097045898, 0.5858790278434753, -0.3082299828529358, -0.3020016551017761, 0.42731794714927673, -0.8868281245231628, 0.08906318992376328, 0.49332964420318604, -0.554343581199646, -0.16381920874118805, -1.0839970111846924, 0.12955127656459808, 0.14139415323734283, -0.5400146842002869, 0.5766350030899048, 0.15284253656864166, 0.6510659456253052, 0.3480965495109558, 0.5296311974525452, 0.2656020224094391, -0.4905892610549927, 0.7592117786407471, -0.6389824748039246, 0.4027453064918518, 0.13568063080310822, -0.175857812166214, -0.25234702229499817, -0.03118935599923134, -0.9049410820007324, -0.5593221783638, -0.6613358855247498, -0.41958215832710266, 0.2315765619277954, 0.1399015486240387, -0.25310954451560974, -0.9660003781318665, -0.2859075963497162, -1.4048354625701904, -0.2965494990348816, 0.5022099018096924, -0.24083232879638672, 0.0031446933280676603, -0.8200839161872864, -1.2135401964187622, -0.6545883417129517, -0.3144885003566742, -0.5347104072570801, 0.49509555101394653, -0.19178232550621033, -0.814683198928833, -0.6603726744651794, 0.07915574312210083, -0.16934534907341003, 1.031768798828125, -0.7039333581924438, 1.1159543991088867, -0.12084155529737473, -0.36238351464271545, -0.390481173992157, 0.10777193307876587, 0.04818257316946983, -0.2841945290565491, -0.04507024958729744, -0.7918680906295776, 0.27204376459121704, -0.31999629735946655, -0.4676257073879242, 0.15222683548927307, -0.09431736171245575, 0.960549533367157, -0.04174574464559555, -0.7291975021362305, -0.0783739984035492, 1.2232468128204346, -0.6074438691139221, -0.11527830362319946, -0.15834106504917145, 0.8049069046974182, 0.12957341969013214, 0.1569792479276657, 0.9344620108604431, 0.39772677421569824, 0.3832149803638458, 0.1811070442199707, 0.1309380680322647, 0.4125376045703888, -0.46673330664634705, 0.4101947247982025, 1.126121163368225, 0.4686971604824066, -0.21379414200782776, -1.1262669563293457, 0.5472499132156372, -1.2890620231628418, -0.3441494107246399, 0.590284526348114, 0.8001452088356018, 0.6599157452583313, -0.5009766817092896, -0.26789090037345886, -0.47341376543045044, 0.051778655499219894, 0.562411367893219, -0.6840728521347046, -0.7075692415237427, -0.04067521542310715, 0.3491796553134918, -0.1380823850631714, 0.6853951811790466, -0.20545406639575958, 0.454704225063324, 14.699254989624023, 0.7840394377708435, 0.2686684727668762, 0.35409218072891235, 0.49744632840156555, 0.18735602498054504, -0.4707633852958679, -0.14323745667934418, -1.207281231880188, -0.387345552444458, 1.5153398513793945, 0.2804196774959564, 0.3081693947315216, 0.02829371578991413, 0.14813122153282166, -0.08436760306358337, -1.0189628601074219, 0.5659887790679932, 0.3785247504711151, -1.1560006141662598, 0.42242467403411865, 0.0964023545384407, -0.28192105889320374, 0.4519253671169281, 0.6179801225662231, 0.840286135673523, 0.47787976264953613, -0.7178947925567627, 0.538981020450592, 0.5125783085823059, 0.6313563585281372, -0.07915579527616501, 0.3892710506916046, 1.034616231918335, -0.8203926086425781, -0.2637457549571991, -0.59804368019104, -1.2404195070266724, 0.1329563856124878, -0.05227680131793022, -0.8455315232276917, -0.6685194969177246, -0.44168031215667725, 0.761925458908081, -0.04576729238033295, 0.2152581810951233, -0.03775813430547714, 0.5440992712974548, 0.18453499674797058, -0.34332218766212463, 0.21927472949028015, 0.6183163523674011, 0.20191043615341187, 0.053795330226421356, -0.11580200493335724, 0.10892836004495621, 0.07911364734172821, 0.6943889260292053, -0.35848769545555115, 0.10360810905694962, -0.43308576941490173, -0.2440129965543747, 0.20737969875335693, 0.5880990624427795, 0.8250429034233093, 0.23976357281208038, -0.5395150184631348, 0.34953320026397705, 0.5959360003471375, 0.013157356530427933, -0.2881620228290558, 0.27200689911842346, 0.36920011043548584, -0.4248281419277191, 0.05766928568482399, 0.6081788539886475, 0.09211531281471252, -0.23216122388839722, -0.7316496968269348, -0.36931824684143066, 0.959175705909729, -0.6881022453308105, -0.7587884664535522, 0.7278949022293091, -0.11891967803239822, -0.27035653591156006, -0.21249529719352722, -0.708187997341156, 0.012952050194144249, 0.5285215973854065, -1.1489876508712769, -0.6011135578155518, 0.5033379793167114, -0.38772517442703247, -0.15593136847019196, 0.7453843355178833, 1.8957502841949463, 0.004354135133326054, -0.37240272760391235, -0.329606831073761, -0.09947438538074493, -0.2948947250843048, -0.19241146743297577, -0.9253167510032654, 0.9147470593452454, 0.20259279012680054, 0.014852565713226795, 0.6576732993125916, 0.012617679312825203, 0.04036938399076462, -0.8644696474075317, -0.14748916029930115, 1.023714303970337, -1.3601306676864624, -0.5401760339736938, -0.8393412232398987, -1.161948323249817, 0.4426395893096924, 0.33595654368400574, -0.231876403093338, 0.5777649879455566, 0.19681453704833984, -0.7557548880577087, -0.08650040626525879, -0.6668517589569092, 0.16399246454238892, 0.543569028377533, -0.7276607155799866, -0.5202136635780334, -0.07282917946577072, 0.6692391037940979, -0.8130270838737488, -0.6242315769195557, -0.3240381181240082, 0.22496359050273895, 0.11338792741298676, 1.0242421627044678, -0.6897895932197571, 0.6713550686836243, 0.7414016723632812, -0.3910577893257141, -0.5460219979286194, 0.0977684035897255, -0.6299737691879272, -0.4329908490180969, -0.31493568420410156, 1.1363842487335205, -0.3525201678276062, -0.05031044781208038, 1.1341948509216309, 0.6359832286834717, -0.6927399039268494, -0.4290110766887665, -0.11975821852684021, 0.07007327675819397, -0.59209144115448, 0.4191449284553528, -0.0995413064956665, -0.07218437641859055, 0.1792866587638855, 0.5296643376350403, 1.0700314044952393, -0.3056902289390564, -0.3698347508907318, 0.3421211242675781, -0.18074442446231842, -0.2783774137496948, -0.27223554253578186, -0.2616110146045685, -1.578062891960144, -0.17234322428703308, -0.8939308524131775, 0.05174441635608673, -0.9892750382423401, -0.4563494026660919, 0.19902309775352478, -0.08584894239902496, -0.04871964454650879, 0.19066664576530457, -0.8682736754417419, -0.8565571308135986, -0.6945122480392456, -0.8672071695327759, 0.49517232179641724, 0.7477286458015442, -0.31308144330978394, 0.46892473101615906, 0.07191979140043259, 0.07202930003404617, 0.037748269736766815, 0.2528916597366333, -0.30581778287887573, -0.8098978996276855, -1.3555102348327637, 0.5454810261726379, 0.14230792224407196, -0.12606769800186157, -0.33777129650115967, 0.8446915149688721, 0.04879474639892578, -0.18569345772266388, -0.28561127185821533, 0.46835216879844666, -0.6567562222480774, -0.6565267443656921, 0.6507188081741333, -1.1449321508407593, 0.3110538125038147, 0.20284222066402435, -0.4712247848510742, -0.27783870697021484, 0.7285929322242737, -0.1693604588508606, -1.083304762840271, -0.939970076084137, 0.3777877986431122, -0.6922606229782104, 0.2100425511598587, -0.4967591464519501, 0.2149226814508438, -1.1701457500457764, -0.3658093810081482, 0.0713655948638916, 0.7000275254249573, -0.3111468553543091, 0.9593546390533447, 0.5656335353851318, -0.7209484577178955, 0.13235177099704742, 0.3225153982639313, 0.24760755896568298, 0.42812612652778625, 0.6320756077766418, 0.30381473898887634, -0.22919835150241852, 0.778038501739502, 0.5450682640075684, 0.24117659032344818, -0.8973103165626526, 0.2918968200683594, 0.688004195690155, -0.42414161562919617, -0.07862162590026855, 1.20999014377594, -0.3587817847728729, -0.9672594666481018, 0.2438874989748001, -1.7442659139633179, -0.629300057888031, -0.47225502133369446, 0.9705471396446228, 0.23420444130897522, 0.07172425836324692, 0.2221546173095703, -1.002384066581726, -0.03762366622686386, -0.10835794359445572, -0.48291996121406555, 0.5554582476615906, -0.1918143481016159, -0.8594664931297302, 1.0153993368148804, 0.8883100152015686, -0.3480492830276489, -0.25360506772994995, -0.9007192850112915, 0.18363183736801147, -0.0859355553984642, 0.12492834776639938, -0.6298069953918457, 0.15886905789375305, 0.6967599391937256, 0.10296650230884552, 0.4169418215751648, -0.17443129420280457, 0.1274232417345047, 0.3872189521789551, 1.176628828048706, 0.015506302937865257, -0.2862788438796997, -0.48755449056625366, 1.2380200624465942, 1.4372328519821167, -1.000906229019165, 0.12610790133476257, -0.10098202526569366, -0.6619148254394531, 0.9294739365577698, 0.3743899166584015, 0.3665654957294464, 0.8795311450958252, -0.2711995542049408, 0.07116906344890594, -0.12009380012750626, -1.5363872051239014, 0.05164876952767372, 0.839513897895813, 0.752594530582428, 0.6902467608451843, 0.552986741065979, 0.3122183084487915, 0.8259479999542236, 0.1778136044740677, 0.17997026443481445, 0.3849514424800873, 0.7446433305740356, -0.34697213768959045, -0.08330369740724564, 0.2740963399410248, 0.5434627532958984, -0.3700966238975525, -0.8281537890434265, 0.1585565209388733, 0.562919020652771, 0.11605744063854218, 0.7452977299690247, 0.8011420369148254, 0.5051401257514954, 0.439730167388916, 0.46429646015167236, 0.3020949065685272, -0.8438973426818848, 0.19664666056632996, -0.8250343799591064, -0.423544317483902, -0.2705695927143097, -0.18425977230072021, -0.5008612871170044, -0.7225844860076904, -0.28864172101020813, 0.6425783634185791, 0.14551037549972534, 0.0675235241651535, 1.2814884185791016, 0.6716809272766113, 0.1446138620376587, -0.2723236680030823, 0.28740087151527405, -0.6723437905311584, -1.1353392601013184, -0.16512101888656616, -0.8709658980369568, -0.054514169692993164, -0.056448936462402344, -0.015393957495689392, -0.6356076598167419]}, "authors": [{"authorId": "2302794180", "name": "Jingyao Li"}, {"authorId": "2285182555", "name": "Han Shi"}, {"authorId": "2302886882", "name": "Xin Jiang"}, {"authorId": "2302853377", "name": "Zhenguo Li"}, {"authorId": "2286297079", "name": "Hong Xu"}, {"authorId": "2273012826", "name": "Jiaya Jia"}], "references": [{"paperId": "1784c987e681d60c634765fe64c8d9c26f73d5ff", "title": "SnapKV: LLM Knows What You are Looking for Before Generation"}, {"paperId": "f05e84702562cb693dd68d3d1c88072519a7bd71", "title": "\u221eBench: Extending Long Context Evaluation Beyond 100K Tokens"}, {"paperId": "ee802ccb7fc3a322b824310ae6f29fc6a1e4314b", "title": "Infinite-LLM: Efficient LLM Service for Long Context with DistAttention and Distributed KVCache"}, {"paperId": "6cea8d0fa51ad72f4f07b154cbf8c2c7214294cd", "title": "MoTCoder: Elevating Large Language Models with Modular of Thought for Challenging Programming Tasks"}, {"paperId": "801935217ef90357cf4a9220de9d46aafd819190", "title": "BAL: Balancing Diversity and Novelty for Active Learning"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "4ea5ca620122e6a9a2b000444d36491cebf49c7c", "title": "Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey"}, {"paperId": "4d76206515d6b33903937474273885476fc2771e", "title": "FlashDecoding++: Faster Large Language Model Inference on GPUs"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "b31a5884a8ebe96b6300839b28608b97f8f8ef76", "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "b069c32fcd77160f944ab3ba71ab6f0cfb782c68", "title": "Focused Transformer: Contrastive Training for Context Scaling"}, {"paperId": "dbc368bc8b49347dd27679894524fa62f88492c9", "title": "Unlimiformer: Long-Range Transformers with Unlimited Length Input"}, {"paperId": "db0c03a5adff4d16ce501e6fb2f37717e42ea093", "title": "TagCLIP: Improving Discrimination Ability of Open-Vocabulary Semantic Segmentation"}, {"paperId": "68adb03744692247fb834406798894db9fe77010", "title": "A Survey on Long Text Modeling with Transformers"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "b03cf6324ecf7a295a4aeae5970c88d1a1c3f336", "title": "Explicit Sparse Transformer: Concentrated Attention Through Explicit Selection"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "dc52b09089704ebd6f471177474bc29741c50023", "title": "Fast Transformer Decoding: One Write-Head is All You Need"}, {"paperId": "7be8c119dbe065c52125ee7716601751f3116844", "title": "Generalization through Memorization: Nearest Neighbor Language Models"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "bba5f2852b1db8a18004eb7328efa5e1d57cc62a", "title": "Key-Value Memory Networks for Directly Reading Documents"}, {"paperId": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e", "title": "End-To-End Memory Networks"}, {"paperId": "c1126fbffd6b8547a44c58b192b36b08b18299de", "title": "Neural Turing Machines"}, {"paperId": "71ae756c75ac89e2d731c9c79649562b5768ff39", "title": "Memory Networks"}, {"paperId": "94b26fafcaf03e3468b27010276c520b39303281", "title": "Strengths and Weaknesses"}, {"paperId": "3689b7ca7b07924b6135b8a71b9f1b7937b0a3d5", "title": "Length Extrapolation of Transformers: A Survey from the Perspective of Position Encoding"}, {"paperId": null, "title": "2023. Needle in a haystack - pressure testing"}, {"paperId": null, "title": "intrinsic capacity of llms for understanding extremely long sequences with training-free memory"}, {"paperId": null, "title": "2022. Effi-ciently modeling long sequences with structured state spaces"}, {"paperId": null, "title": "encodings to all tokens exceeding the local window size."}, {"paperId": null, "title": "2024c. Moodv2: Masked image modeling for out-of-distribution detection"}, {"paperId": null, "title": "2023b. Rethinking out-of-distribution (ood) detection: Masked image modeling is all you need"}, {"paperId": null, "title": "difficulties with out-of-domain distribution when extended to process longer sequences (Xiao et al., 2024a)."}, {"paperId": null, "title": "are kept in GPU memory"}, {"paperId": null, "title": "The prompts for Needle-in-a-Haystack Bench are"}, {"paperId": null, "title": "2024b. Robocoder: Robotic learning from basic skills to general tasks with large language models"}, {"paperId": null, "title": "stage. Given that most units are seldom used, we adopt an offloading strategy, which stores most memory units in CPU memory. Only the tokens and memory units essential for current operations"}, {"paperId": null, "title": "2023. Exploring the limits of transfer learning with a unified text-to-text trans-former"}, {"paperId": null, "title": "2023. Metamath: Bootstrap your own mathematical questions for large language models"}, {"paperId": null, "title": "2023. Yarn: Efficient context window extension of large language models"}, {"paperId": null, "title": "2022. Memorizing transformers"}]}