{"paperId": "f87c1345cb5a10d8fea30580ba0bdf593472c004", "abstract": "Dynamic attention mechanism and global modeling ability make Transformer show strong feature learning ability. In recent years, Transformer has become comparable to CNNs methods in computer vision. This review mainly investigates the current research progress of Transformer in image and video applications, which makes a comprehensive overview of Transformer in visual learning understanding. First, the attention mechanism is reviewed, which plays an essential part in Transformer. And then, the visual Transformer model and the principle of each module are introduced. Thirdly, the existing Transformer-based models are investigated, and their performance is compared in visual learning understanding applications. Three image tasks and two video tasks of computer vision are investigated. The former mainly includes image classification, object detection, and image segmentation. The latter contains object tracking and video classification. It is significant for comparing different models' performance in various tasks on several public benchmark data sets. Finally, ten general problems are summarized, and the developing prospects of the visual Transformer are given in this review.", "venue": "arXiv.org", "year": 2022, "citationCount": 22, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2203.12944", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This review mainly investigates the current research progress of Transformer in image and video applications, which makes a comprehensive overview of Trans transformer in visual learning understanding."}, "embedding": {"model": "specter_v2", "vector": [0.23588447272777557, 0.47095954418182373, -0.33802565932273865, 0.36872440576553345, -0.201394185423851, 0.17491872608661652, 0.33017346262931824, -0.39030590653419495, -0.28596869111061096, -0.6666936278343201, -0.03574033081531525, 0.6106418371200562, 0.6020244359970093, -0.2616296708583832, -0.1924533247947693, -0.24003978073596954, -0.40993261337280273, 0.10979624092578888, 0.9224250912666321, 0.12463725358247757, -0.1290537565946579, -0.3097676634788513, -1.3460402488708496, 0.28479883074760437, 0.09734117239713669, 1.1922798156738281, 0.5469900369644165, 0.9146081209182739, -0.26220703125, 0.8002398014068604, 0.7520400285720825, -0.233359694480896, 0.4078594148159027, 0.08703143894672394, -0.26762884855270386, 0.4725894331932068, 0.9283694624900818, -0.40950265526771545, -0.8665568828582764, 0.919450044631958, -0.1591775268316269, 0.3290617763996124, 0.41571861505508423, -1.203749179840088, -0.19579973816871643, -0.19171200692653656, 0.40486833453178406, 1.0982701778411865, -0.8011272549629211, -0.31712043285369873, 1.388761043548584, -1.1622296571731567, -0.053518012166023254, 1.4948054552078247, 0.5825089812278748, 0.33406367897987366, 0.1640423834323883, -0.6619377732276917, 0.6385722756385803, 0.16804267466068268, -0.29795095324516296, -0.16817457973957062, 0.17326489090919495, -0.5871549844741821, 1.4274797439575195, -0.7802250385284424, 0.3088492453098297, 0.4988873600959778, 0.6312784552574158, 1.6003236770629883, 0.07797783613204956, -0.5610483884811401, -0.45429885387420654, -0.17505614459514618, 0.1939307302236557, 1.3123130798339844, -0.13195806741714478, 0.4465830624103546, -1.1863664388656616, 0.38438332080841064, 1.0449907779693604, 0.1268540769815445, 0.056846778839826584, -0.44340431690216064, 0.02423333190381527, 0.5992814302444458, 0.8155531287193298, 0.3208436071872711, -0.08186256885528564, 0.9736357927322388, 0.6032088398933411, -0.11727052927017212, -0.2970452904701233, -0.1678590029478073, 0.24011769890785217, 0.9579570889472961, -0.4838421046733856, -0.1630088835954666, -0.7130132913589478, 0.892877459526062, -0.2357078194618225, 0.6761596202850342, -0.6021577715873718, 0.26657533645629883, 1.6193729639053345, 0.19956769049167633, 0.2645998001098633, -0.7044051289558411, 0.0318511538207531, -0.4286409914493561, -0.09785718470811844, -0.8007645010948181, 0.06362029165029526, -0.8094519972801208, -0.6852167248725891, -0.2749740183353424, -0.014571317471563816, 0.7984828352928162, -1.5804476737976074, 0.2350112348794937, -0.6127185821533203, 0.05201507359743118, -0.1287936568260193, 0.23903098702430725, 0.7198912501335144, 0.4955776631832123, 0.7076478600502014, 0.16919730603694916, 1.2491220235824585, -1.3163295984268188, -0.5971829891204834, -0.9022799134254456, -0.36638274788856506, -0.4568270146846771, 0.304442822933197, -0.04139547049999237, -0.8705618977546692, -1.5307012796401978, -0.856631875038147, -0.02040066197514534, -0.4422675371170044, 0.12552060186862946, 1.0701950788497925, 0.2093082070350647, -1.293799638748169, 0.45134851336479187, -0.33807626366615295, -0.7826332449913025, 0.7599499225616455, 0.05585798993706703, 0.5070317983627319, -0.10493975132703781, -0.8154533505439758, 0.4158703088760376, 0.05885545164346695, -0.5744580030441284, -0.9845568537712097, -0.23742437362670898, -1.1298733949661255, 0.18096628785133362, 0.21448636054992676, -0.8792840242385864, 1.0477219820022583, -0.6615114808082581, -0.6962089538574219, 0.6709055304527283, -0.3123917877674103, -0.004466296173632145, 0.16876429319381714, -0.12026569992303848, -0.09775152802467346, -0.1781436949968338, 0.037195682525634766, 0.42191842198371887, 0.8090744018554688, -0.5980294942855835, -0.7584006786346436, 0.011747386306524277, -0.34782809019088745, 0.030064672231674194, -0.41873782873153687, 0.9860678315162659, -0.7683894634246826, -0.42220139503479004, 0.4508257806301117, 0.8815350532531738, 0.03753981739282608, 0.3292848765850067, 0.36806952953338623, -1.1699188947677612, 1.4972506761550903, -0.016502004116773605, 0.4997808337211609, -0.7225362062454224, -1.0060030221939087, -0.32543548941612244, 0.1394210308790207, -0.10045842081308365, -0.771733820438385, 0.14713813364505768, -0.1725895255804062, -0.20931027829647064, 0.3242122232913971, -0.675857424736023, -0.31153446435928345, 0.005187435075640678, -0.8499438762664795, 0.09510276466608047, 0.2891436815261841, 1.3630390167236328, -0.7229698896408081, -0.2766202986240387, 0.31938666105270386, -0.010910565964877605, -0.41042670607566833, 1.2413157224655151, -0.1749165654182434, -0.30281177163124084, -0.314876914024353, 0.43202465772628784, -0.05844489857554436, -0.44324612617492676, 0.34339484572410583, -0.9380354285240173, 0.21438704431056976, -0.04071345180273056, -0.3308730125427246, 0.8614894151687622, 0.04927727207541466, 1.1616162061691284, -0.38216206431388855, -0.9184794425964355, 0.3939581513404846, 0.5140356421470642, -0.15645214915275574, -0.6921677589416504, 0.6080111861228943, -0.2402765452861786, -0.7599503397941589, 0.07400162518024445, 0.3313625752925873, 0.7332680225372314, 0.08629453927278519, 0.06033645570278168, 1.0704419612884521, -0.1253891885280609, -0.22873929142951965, 0.3687133491039276, 0.20312973856925964, 0.3951818346977234, 0.24570760130882263, -0.19465506076812744, -0.06160033494234085, -0.9506167769432068, 0.1910819411277771, 0.7762576341629028, -0.05456695705652237, 1.0430902242660522, 0.2948608100414276, -0.9503947496414185, -0.4765835106372833, -0.4420967698097229, 0.8180567026138306, 1.4748356342315674, 0.36767199635505676, -0.11190546303987503, -0.5350946187973022, -0.599812388420105, -0.45138078927993774, -0.5067660808563232, -0.6405438184738159, -0.27332502603530884, -0.07626714557409286, -0.9084147214889526, 0.8875524401664734, 0.8676385283470154, 1.4684070348739624, -0.810411810874939, -0.4309295415878296, -0.37026238441467285, 0.18170000612735748, -0.894973635673523, -0.5314409136772156, 0.4182138741016388, -0.7622771859169006, -0.5287275314331055, 0.2092847228050232, -0.5539406538009644, 0.34202951192855835, -0.15802569687366486, 0.6872618198394775, -0.34227877855300903, -0.40605586767196655, 0.6533938646316528, 1.0083777904510498, -1.0290820598602295, -0.17725931107997894, -0.26654860377311707, -0.055437132716178894, 0.048916108906269073, 0.49699175357818604, 0.591439425945282, 0.2267254889011383, 0.5701261162757874, -0.4409501850605011, -0.11973685771226883, 0.2546623647212982, 0.0735660195350647, 0.976970911026001, 0.006530751008540392, 0.15404096245765686, -0.5726192593574524, 0.6524816751480103, 0.7560910582542419, -0.6594576239585876, 0.46685752272605896, -0.5287613272666931, -0.37865734100341797, 0.18590213358402252, -0.6775213479995728, -0.4382685422897339, -0.25062796473503113, 0.7909172773361206, -0.9236887097358704, -0.21517328917980194, -0.3861347436904907, 0.16755545139312744, -0.5693686008453369, 0.1826891452074051, 0.5991891622543335, 0.353313148021698, 0.3529137074947357, -0.07750396430492401, -0.7663764357566833, 0.59343022108078, 0.20695017278194427, 0.22005921602249146, 0.15820911526679993, -0.2543033957481384, -0.6585243940353394, -0.8367382884025574, -0.8188296556472778, -0.3750673830509186, -0.972212553024292, 0.3851047456264496, -0.677341639995575, -0.8993978500366211, 0.5297306776046753, -0.7051960825920105, -0.061139658093452454, -0.020303355529904366, -0.18000160157680511, -0.5949367880821228, -1.1960718631744385, -0.8234429359436035, -0.4464810788631439, -0.46750959753990173, -1.0525161027908325, 0.21987906098365784, 0.6372091174125671, 0.42218512296676636, -0.7180375456809998, -0.3776998817920685, -0.17021559178829193, 1.0682352781295776, -0.2484584003686905, 0.5054739713668823, -0.19090598821640015, -0.9365067481994629, 0.25218191742897034, -0.028989499434828758, 0.8049806952476501, -0.07020722329616547, 0.23296158015727997, -1.3366155624389648, 0.08616482466459274, 0.19298595190048218, -0.1351698338985443, 0.8790426850318909, 0.6307879686355591, 0.7761527299880981, 0.6035273671150208, -0.7150818109512329, 0.342308908700943, 1.5275059938430786, -0.25176551938056946, 0.22688111662864685, 0.20209231972694397, 1.1486377716064453, 0.011731046251952648, -0.11526422202587128, -0.19796407222747803, 0.0732136145234108, 0.2854040861129761, 0.6435778737068176, -0.5258527398109436, -0.8899972438812256, -0.5382459759712219, 0.4808419942855835, 0.9128101468086243, -0.13333284854888916, 0.17034217715263367, -1.223879098892212, 1.0845222473144531, -1.2249056100845337, -0.9794526696205139, 0.79720538854599, 0.6288490295410156, -0.22146153450012207, 0.11190614849328995, -0.13647644221782684, -0.3023141622543335, 1.086799144744873, 0.36741259694099426, -0.38188278675079346, -0.07516654580831528, -0.036627158522605896, 0.4126032590866089, 0.46171027421951294, 0.6411879658699036, -0.5281807780265808, 0.5598090291023254, 14.454324722290039, 0.9122014045715332, -0.3349520266056061, 0.4838304817676544, 0.6241349577903748, 0.7674189209938049, 0.01417316123843193, -0.05394722521305084, -1.1105914115905762, -0.38379064202308655, 0.23570619523525238, 0.1957264095544815, 0.06887376308441162, 0.43265026807785034, -0.39912453293800354, 0.3296094238758087, -0.295884907245636, 1.1624573469161987, 0.7777799963951111, -1.1464840173721313, 0.8111726641654968, 0.1778881847858429, 0.00055780413094908, 0.610668957233429, 0.806063711643219, 0.4503423273563385, 0.19333185255527496, -0.5972814559936523, 0.5236415266990662, 0.029804738238453865, 0.5971341729164124, 0.022727658972144127, 0.34404322504997253, -0.04968849569559097, -1.738517165184021, -0.4527776837348938, -0.7850808501243591, -0.7796980142593384, 0.014332550577819347, -0.2150103598833084, -0.5551683306694031, -0.3136691451072693, 0.22542746365070343, 0.9725657105445862, -0.20412373542785645, 0.6905553936958313, -0.38871118426322937, 0.6270067095756531, -0.030795326456427574, 0.19367173314094543, 0.23056498169898987, 0.7236192226409912, 0.32451331615448, -0.21162670850753784, -0.18822143971920013, 0.3089047372341156, 0.5437305569648743, 0.15507511794567108, -0.3822767734527588, -0.5761846303939819, -0.2693862020969391, -0.06960044801235199, -0.48426711559295654, 1.06294584274292, -0.28394678235054016, 0.2879045009613037, -0.1828605681657791, -0.13152046501636505, 0.13126835227012634, 0.32217368483543396, -0.641177773475647, -0.11120902746915817, 0.11717694252729416, 0.04545140266418457, 0.5178860425949097, 0.625000536441803, -0.2569398581981659, -0.4883272647857666, -0.8565958142280579, -0.08039787411689758, 0.6604651212692261, -1.1179492473602295, -0.7129759192466736, 1.150708556175232, -0.38883498311042786, -0.22150813043117523, 1.0399101972579956, -1.0503584146499634, -0.6056421995162964, -0.06182257458567619, -1.4865334033966064, -1.2751561403274536, -0.5657813549041748, 0.34395235776901245, 0.1936553716659546, -0.29584580659866333, 0.3449227213859558, -0.1321178823709488, 0.07270928472280502, 0.0530536025762558, -0.5870277285575867, 0.3661964237689972, -0.21552886068820953, -0.6689777374267578, 0.5302614569664001, 0.6117528080940247, 0.3550235331058502, -0.21581022441387177, -0.057901956140995026, 0.24908386170864105, -0.33631426095962524, -0.2332969456911087, 0.19734570384025574, -0.774219810962677, -0.500131368637085, -0.7163074612617493, -1.2629221677780151, 0.6383773684501648, 0.7473118305206299, 0.08148325979709625, -0.19650375843048096, -0.08930712193250656, -0.4643869996070862, -0.40510326623916626, -0.7381905913352966, -0.253804475069046, 0.3650396764278412, -0.753915548324585, -0.7614191770553589, -0.11012572050094604, 0.06963424384593964, -0.7855437994003296, -0.17142075300216675, -0.15643882751464844, 0.19698165357112885, -0.14620569348335266, 1.2333515882492065, -0.5289413332939148, 0.017346426844596863, 0.24293193221092224, -0.14275000989437103, -0.46980714797973633, -0.40733858942985535, -0.64663165807724, 0.4421519935131073, 0.3202962875366211, -0.010838979855179787, -0.6269285678863525, 0.15068387985229492, 0.22277505695819855, 0.43908455967903137, -0.4939853549003601, -0.5903854370117188, -0.021083153784275055, -0.22011956572532654, -0.46520212292671204, -0.18185797333717346, -0.27772071957588196, -0.5428147315979004, 0.1974097043275833, 0.5773879289627075, 0.5597891807556152, 0.2852429151535034, -0.46182993054389954, 0.3272266387939453, -0.513349711894989, 0.06132955849170685, -0.39405080676078796, -0.8550631403923035, -1.5519719123840332, -0.2463575303554535, -0.9851992726325989, 0.02061777003109455, -1.3387792110443115, -0.11804065108299255, 0.3547568619251251, -0.808864176273346, 0.36844006180763245, 0.3322056531906128, -0.04486668109893799, 0.0438484288752079, -0.3370266854763031, -0.7629240155220032, 0.7404486536979675, 1.2207220792770386, -0.8992092609405518, 0.324076384305954, 0.07170626521110535, 0.08361437916755676, 0.7948929667472839, 0.2467748075723648, -0.5676596760749817, -0.8627232909202576, -0.8234063982963562, -0.1386415660381317, -0.4502941966056824, -0.016757944598793983, -1.1387087106704712, 1.3458905220031738, 0.25270339846611023, 0.5440914034843445, 0.002749448176473379, 0.4378589689731598, -1.003767490386963, -0.5818408131599426, 0.47677767276763916, -0.44632938504219055, -0.04567360505461693, 0.46432217955589294, -0.2169276624917984, -0.6345426440238953, 1.0287861824035645, 0.8088025450706482, -1.0541592836380005, -1.342054843902588, 0.7134717106819153, -0.7197226285934448, 0.13227052986621857, 0.5011809468269348, -0.39570754766464233, -1.2511937618255615, -0.2731846570968628, -0.41198042035102844, 0.46164268255233765, -0.43309229612350464, 1.1414906978607178, 1.2192203998565674, -1.335105061531067, 0.3007746934890747, 0.6497671008110046, -0.2697668969631195, -0.09736839681863785, 0.345817893743515, 0.5019311904907227, -0.08095013350248337, 0.346090704202652, -0.42861881852149963, -0.2389179915189743, -1.0897142887115479, 0.22231389582157135, 1.3526692390441895, -0.22631648182868958, -0.25067204236984253, 1.037239670753479, 0.43214988708496094, -0.6405510902404785, 0.43693023920059204, -0.981792688369751, -0.6977844834327698, -0.12061335146427155, 0.5324801206588745, -0.019422225654125214, -0.1830367147922516, -0.1109657883644104, -0.5599733591079712, 0.7741277813911438, -0.18523195385932922, -0.19573497772216797, 0.22469456493854523, -0.003200868610292673, -0.05175914987921715, 0.6398736238479614, 0.2734162211418152, -0.9310163855552673, -1.3247346878051758, -0.7392644286155701, -0.5850354433059692, -0.6128135919570923, 0.08867961913347244, -0.09814167767763138, -1.3721388578414917, 0.8180153369903564, 1.1007153987884521, 0.4067092835903168, 0.6492913961410522, 0.09699563682079315, 0.006764272693544626, 0.3582327365875244, 0.05431791767477989, -0.5463194847106934, 0.09403731673955917, 1.1863425970077515, 1.0142128467559814, -0.7844929695129395, 0.19095353782176971, -0.42066526412963867, -0.7674753069877625, 1.1080759763717651, 0.8348236680030823, -0.4088969826698303, 0.7710191011428833, -0.5579763054847717, 0.4694489538669586, 0.011019433848559856, -0.9523838758468628, -0.4938511550426483, 0.9928696751594543, 1.5336334705352783, 0.21062292158603668, -0.33322152495384216, 0.7749795913696289, 0.5165401101112366, 0.7291911244392395, 0.12673768401145935, 0.5758761167526245, 0.07624080777168274, -0.7160404324531555, 0.4669792354106903, -0.15893146395683289, 0.6530323028564453, -0.7077344655990601, 0.02507391944527626, 0.13896609842777252, 1.1099921464920044, 0.07958241552114487, 0.44955822825431824, 0.8092527389526367, 0.04049453139305115, 0.6494011878967285, 0.03417627513408661, 0.694019615650177, -0.5161342024803162, -0.25340723991394043, -0.025898395106196404, -1.2251789569854736, -0.16957741975784302, -0.8515716791152954, -0.48730364441871643, -0.2006247490644455, 0.34040576219558716, -0.011316213756799698, -0.07226350903511047, -0.13985656201839447, 0.8707885146141052, 0.12522681057453156, 0.7181551456451416, -0.8702492713928223, -0.3104126453399658, -0.007194002624601126, -0.78154456615448, -0.012016759254038334, -0.6461681723594666, 0.2387528419494629, -0.9611031413078308, -0.07004515826702118, 0.21520785987377167]}, "authors": [{"authorId": "2243308092", "name": "Yuting Yang"}, {"authorId": "2143819911", "name": "Licheng Jiao"}, {"authorId": "40913460", "name": "X. Liu"}, {"authorId": "70448703", "name": "F. Liu"}, {"authorId": "1702138", "name": "Shuyuan Yang"}, {"authorId": "1897949", "name": "Zhixi Feng"}, {"authorId": "144474380", "name": "Xu Tang"}], "references": [{"paperId": "c7fc852d19accc342d9e82b3221d7805168a4c25", "title": "ViTBIS: Vision Transformer for Biomedical Image Segmentation"}, {"paperId": "9137efc758f80dd22bb56f82cca5c94f78a5db3e", "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and Detection"}, {"paperId": "91a4cbae6553e975ddc3b2f6850ed725ff475307", "title": "SwinTrack: A Simple and Strong Baseline for Transformer Tracking"}, {"paperId": "45f686be3b96302ede327645227134e1c304dbab", "title": "Attention mechanisms in computer vision: A survey"}, {"paperId": "7b4125cced6db9b14af663de1c593416f314e0da", "title": "AFTer-UNet: Axial Fusion Transformer UNet for Medical Image Segmentation"}, {"paperId": "eb36750a31af99baf22ed01d0b8c24d9ff550b40", "title": "EAPT: Efficient Attention Pyramid Transformer for Image Processing"}, {"paperId": "19b3b074d38b250d024920732ae51a8ffa0996dd", "title": "Pix2seq: A Language Modeling Framework for Object Detection"}, {"paperId": "03a2befad038a9f29859295fdfcdbfa52c564622", "title": "An End-to-End Transformer Model for 3D Object Detection"}, {"paperId": "f7e449d7695fbbf43081cc820a81fe0ccb11c3db", "title": "PnP-DETR: Towards Efficient Visual Analysis with Transformers"}, {"paperId": "813b03e123d448d53d93a087a2d34a04dfe70c5c", "title": "Voxel Transformer for 3D Object Detection"}, {"paperId": "203b965e5c9eb1e1c521ec66f82b036335c7cd4d", "title": "Shifted Chunk Transformer for Spatio-Temporal Representational Learning"}, {"paperId": "ebf221bf7260e2d27b243b15909d89196f62f39b", "title": "TransFER: Learning Relation-aware Facial Expression Representations with Transformers"}, {"paperId": "312160aa805e1c9936b26359c7c2e0acef81b936", "title": "Improving 3D Object Detection with Channel-wise Transformer"}, {"paperId": "1cd6b0f41d62aca38ba5a69db10e79c05e618c21", "title": "Conditional DETR for Fast Training Convergence"}, {"paperId": "e92cd9b7bf810a5097b3a7365b8aa56b67fea74b", "title": "PSViT: Better Vision Transformer via Token Pooling and Attention Sharing"}, {"paperId": "2c4d5b1278125d84c9e66ebe1032af888d9211f3", "title": "Token Shift Transformer for Video Classification"}, {"paperId": "c945efdeefaacb8ca679298720f4b0b054dc84bd", "title": "Vision Transformer with Progressive Sampling"}, {"paperId": "c3d2014bbdb03892d5db653a25e28952f07bfcc3", "title": "Transformer3D-Det: Improving 3D Object Detection by Vote Refinement"}, {"paperId": "1b892411abfce6b6864d0daf96b92771149c35ca", "title": "ViTT: Vision Transformer Tracker"}, {"paperId": "a9c214e846188adb645021cd7b1964b8ea1fef6f", "title": "Rethinking and Improving Relative Position Encoding for Vision Transformer"}, {"paperId": "faa30dfcb1531df4e4d5c219bad06d65f6c860fa", "title": "LeViT-UNet: Make Faster Encoders with Transformer for Medical Image Segmentation"}, {"paperId": "260ad39a1dac4b451019e2bf17925f4df8e3b69a", "title": "Per-Pixel Classification is Not All You Need for Semantic Segmentation"}, {"paperId": "0739e0dce6671cef8752655610347dbf5d5dda8d", "title": "Transclaw U-Net: Claw U-Net With Transformers for Medical Image Segmentation"}, {"paperId": "f4064793439109140b1385e4e0ef9dc50eea9a22", "title": "Learning Disentangled Representation Implicitly Via Transformer for Occluded Person Re-Identification"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "157530e815652b7e864a9f7885977c7ae8214b6f", "title": "ResViT: Residual Vision Transformers for Multimodal Medical Image Synthesis"}, {"paperId": "1fb10189c500e4902cd1b5afd406f57323d21be8", "title": "VOLO: Vision Outlooker for Visual Recognition"}, {"paperId": "94eae578e6af3382f6449506965639f18aab3fa0", "title": "Video Swin Transformer"}, {"paperId": "d8d2e574965fe733eb1416e03df2b5c2914fc530", "title": "A Survey of Transformers"}, {"paperId": "9d1934ea1bd69d928d17e05d44495d42edf8601d", "title": "You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection"}, {"paperId": "41ba014710b4d86dfd01560b73b7fe0b6af210b0", "title": "To the Point: Efficient 3D Object Detection in the Range Image with Graph Convolution Kernels"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "ea7cfe7f2340584cbe653da6077ee7c213e49b92", "title": "Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation"}, {"paperId": "68f080e0ac836ea230cb5316fbed273c70422d75", "title": "Segmenter: Transformer for Semantic Segmentation"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "8d3ddc27dce9c6c0fe110e4f9cb45d3b59feb04b", "title": "Visformer: The Vision-friendly Transformer"}, {"paperId": "8754533bead3996f20440e4a1d0220d4971d00d7", "title": "VidTr: Video Transformer Without Convolutions"}, {"paperId": "37b66aefc502b205da52a0a811fd9a3bafb399f3", "title": "Efficient DETR: Improving End-to-End Object Detector with Dense Prior"}, {"paperId": "75a98b6ce3279848c806fc1ad18100bf666b4933", "title": "TransMOT: Spatial-Temporal Graph Transformer for Multiple Object Tracking"}, {"paperId": "44930df2a3186edb58c4d6f6e5ed828c5d6a0089", "title": "Attention, please! A survey of neural attention models in deep learning"}, {"paperId": "72af9b2e03d3668e09edd0ec413b0b20cbce8f9c", "title": "Learning Spatio-Temporal Transformer for Visual Tracking"}, {"paperId": "7c3ce1b3ad598a282546e03e2dc8b52c338caed6", "title": "Transformer Tracking"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "b6382a7351c0c595f91472ac71d3b2d87b3c4844", "title": "ViViT: A Video Vision Transformer"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "0eff37167876356da2163b2e396df2719adf7de9", "title": "CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification"}, {"paperId": "8e33914d6051dd031a5e096962b9398fc1d16067", "title": "Vision Transformers for Dense Prediction"}, {"paperId": "96da196d6f8c947db03d13759f030642f8234abf", "title": "DeepViT: Towards Deeper Vision Transformer"}, {"paperId": "75284d5e4dfe1cd8a9ce69085210319e14fcfa3d", "title": "Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking"}, {"paperId": "7519a1e9e7371df79bd8a21cee871feb0ec597a5", "title": "UNETR: Transformers for 3D Medical Image Segmentation"}, {"paperId": "147164a3905f41a7a5a10f732d086a621c9c5862", "title": "TransBTS: Multimodal Brain Tumor Segmentation Using Transformer"}, {"paperId": "8356d155d730e374f4db6dfd03d19a7b66c348a8", "title": "CoTr: Efficiently Bridging CNN and Transformer for 3D Medical Image Segmentation"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "63812f583caac3ac32bbfb64f66ba69e57c1e90a", "title": "Conditional Positional Encodings for Vision Transformers"}, {"paperId": "367f7f64ded5d18528c1013db9dfa01b075db484", "title": "Medical Transformer: Gated Axial-Attention for Medical Image Segmentation"}, {"paperId": "fa08b41ccdfc5d8771adfbc34c176fa237d4646c", "title": "Is Space-Time Attention All You Need for Video Understanding?"}, {"paperId": "24b8a0b02bcb7934967757fc59d273a71ba67e30", "title": "TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation"}, {"paperId": "94b69cf199fa0b6c842e17fe5d6174a9d161c3df", "title": "Video Transformer Network"}, {"paperId": "16a7a491bb9194d38bfe3b2f6ce7a68b404fcf7d", "title": "Spatial-Spectral Transformer for Hyperspectral Image Classification"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78", "title": "Bottleneck Transformers for Visual Recognition"}, {"paperId": "69621df0df837d345d764525696899e0570194b6", "title": "Fast Convergence of DETR with Spatially Modulated Co-Attention"}, {"paperId": "0357156aef567fb5b709222894ddea1ce5d4e721", "title": "TrackFormer: Multi-Object Tracking with Transformers"}, {"paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b", "title": "Transformers in Vision: A Survey"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "1020da59ab3db2b3051fb558559d7fdcd2c7e57b", "title": "TransTrack: Multiple-Object Tracking with Transformer"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "1834a1ff37052895c42906ceb163d9306badc00b", "title": "FcaNet: Frequency Channel Attention Networks"}, {"paperId": "16ecba2d6e6907dce95560e5d3448d8bc7559b39", "title": "3D Object Detection with Pointformer"}, {"paperId": "d2e54b3a596a1dce0def9d035dfe1fb7c0c6142a", "title": "Toward Transformer-Based Object Detection"}, {"paperId": "787119e3c3f819244c82b7d97779473773e60696", "title": "MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers"}, {"paperId": "ddf7dfd1d9096f4a58f33b575bd1b4630309e7b2", "title": "Temporal-Channel Transformer for 3D Lidar-Based Video Object Detection for Autonomous Driving"}, {"paperId": "234763381de73a18f49430b0238310a6853d184e", "title": "Rethinking Transformer-based Set Prediction for Object Detection"}, {"paperId": "2e1db8cb373f4d4a51d44308b7a457886d855fbb", "title": "End-to-End Object Detection with Adaptive Clustering Transformer"}, {"paperId": "c13a8f9edb933e60c7a989244aee56283a54ce37", "title": "UP-DETR: Unsupervised Pre-training for Object Detection with Transformers"}, {"paperId": "35248e4b63c96067ccf1bc3f3fa0f2e27a0e6cee", "title": "RelationNet++: Bridging Visual Representations for Object Detection via Transformer Decoder"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "f0f81bda8974900a46d19ac9882cdeaa3dccf458", "title": "Visualizing Transformers for NLP: A Brief Survey"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "6e1efe22d5696269aff7addcb438f77ff6cc2508", "title": "A Universal Representation Transformer Layer for Few-Shot Image Classification"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb", "title": "TAM: Temporal Adaptive Module for Video Recognition"}, {"paperId": "f26f24bc6a515647b2867cbc8236a03177e8a2bd", "title": "Oriented Spatial Transformer Network for Pedestrian Detection Using Fish-Eye Camera"}, {"paperId": "f1b9a9a2498a594b46dd840877d25dbe03420b82", "title": "PolyTransform: Deep Polygon Transformer for Instance Segmentation"}, {"paperId": "a4cc0701170331a1fd0e58bad962bd7f39f5efc9", "title": "GhostNet: More Features From Cheap Operations"}, {"paperId": "42ebefbd9f3843aced4854e09fe83b9d99074939", "title": "Gated Channel Transformation for Visual Recognition"}, {"paperId": "173d31ea3ec9db19870fcf2710841b4a3e864c6d", "title": "Global-Local Temporal Representations for Video Person Re-Identification"}, {"paperId": "441555b5cd09703e55c03e70bd2c9f82c0ffcf9b", "title": "Deep High-Resolution Representation Learning for Visual Recognition"}, {"paperId": "dfbeb3ca7a01fe80c49b76baa50bf092f71eef4a", "title": "A Survey of Deep Learning-Based Object Detection"}, {"paperId": "d6dccb5d71fbb6f5765f89633ba3a8e6809a720d", "title": "Stand-Alone Self-Attention in Vision Models"}, {"paperId": "3e70bbe6c4cd98d66599db709e32b748f184a2d4", "title": "CondConv: Conditionally Parameterized Convolutions for Efficient Inference"}, {"paperId": "a8427ce5aee6d62800c725588e89940ed4910e0d", "title": "An Attentive Survey of Attention Models"}, {"paperId": "deb956b70eb93bb08eaabc18fb11aed9bd20d08f", "title": "SRM: A Style-Based Recalibration Module for Convolutional Neural Networks"}, {"paperId": "2be79623e328f1af6f1d557d402af816061df045", "title": "STNReID: Deep Convolutional Networks With Pairwise Spatial Transformer Networks for Partial Person Re-Identification"}, {"paperId": "fb8cf663a71bf31f59557a35d36aaf8c465b50af", "title": "Selective Kernel Networks"}, {"paperId": "9bd25f99bfc73af7e6d76f83d92f8270eab7be1d", "title": "Video Action Transformer Network"}, {"paperId": "a5f782f08ae8df9b9926200fdc5adbe99565513a", "title": "Global Second-Order Pooling Convolutional Networks"}, {"paperId": "cd8ddaaf56e38dddafdeac3f9643b9b5e9d35d54", "title": "Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks"}, {"paperId": "4eee87d960754f755fdec073a160af3e2e31672f", "title": "PSANet: Point-wise Spatial Attention Network for Scene Parsing"}, {"paperId": "62dccab9ab715f33761a5315746ed02e48eed2a0", "title": "A Short Note about Kinetics-600"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "7998468d99ab07bb982294d1c9b53a3bf3934fa6", "title": "Object Detection With Deep Learning: A Review"}, {"paperId": "39f1cbef12f64dcdb3a7683f9e70f436a7742328", "title": "Applications of Deep Learning and Reinforcement Learning to Biological Data"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "8760bc7631c0cb04e7138254e9fd6451b7def8ca", "title": "Revisiting Unreasonable Effectiveness of Data in Deep Learning Era"}, {"paperId": "ac574f981394aaea3d472607e84f4f793650e84b", "title": "Partitioned-cooperative quantum-behaved particle swarm optimization based on multilevel thresholding applied to medical image segmentation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6", "title": "The Kinetics Human Action Video Dataset"}, {"paperId": "4a73a1840945e87583d89ca0216a2c449d50a4a3", "title": "Deformable Convolutional Networks"}, {"paperId": "a437b2e8a092f73d019eb91282a60c29b98789d9", "title": "A Survey of Visual Attention Models"}, {"paperId": "dbb6ded623159c867fbeca0772db7b2eb9489523", "title": "Spatial Transformer Networks"}, {"paperId": "6364fdaa0a0eccd823a779fcdd489173f938e91a", "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation"}, {"paperId": "e0945081b5b87187a53d4329cf77cd8bff635795", "title": "Highway Networks"}, {"paperId": "4d8f2d14af5991d4f0d050d22216825cac3157bd", "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "8a756d4d25511d92a45d0f4545fa819de993851d", "title": "Recurrent Models of Visual Attention"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "adea2a2bd6237aa0c0386def787a2365da142108", "title": "Rough-granular approach for impulse fault classification of transformers using cross-wavelet transform"}, {"paperId": "fedd6b25ddff046d0f1edb6d807f9f22fa923307", "title": "Exploiting Multi-View Part-Wise Correlation via an Efficient Transformer for Vehicle Re-Identification"}, {"paperId": "9f7f81b1c82828a45a52df8f0c6a92636af76c7e", "title": "CrossFormer: A Versatile Vision Transformer Based on Cross-scale Attention"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "03b537c948a9711cf2a7b324e02e030874df8f73", "title": "HRViT: Multi-Scale High-Resolution Vision Transformer"}, {"paperId": "5dab5b00bd902f408d2688c3cfd7bb43861ada3d", "title": "LiteTrans: Reconstruct Transformer with Convolution for Medical Image Segmentation"}, {"paperId": "083ca4bd4d5b231a1d7a0715ec55cc57a0f44b13", "title": "Aggregating Nested Transformers"}, {"paperId": "d0277df2d090a63940c9deb569f195dbf5da4e99", "title": "TransCenter: Transformers with Dense Queries for Multiple-Object Tracking"}, {"paperId": "9c54d3a7ae4ba332ca98ae1a1c844ca4650392cb", "title": "GasHis-Transformer: A Multi-scale Visual Transformer Approach for Gastric Histopathology Image Classification"}, {"paperId": "50fadb9e46139af8e84d9d50478430d1bbe4e081", "title": "Spectral-Spatial Transformer Network for Hyperspectral Image Classification: A Factorized Architecture Search Framework"}, {"paperId": "31444a27bb09e64cf252be9fa2349a5178307012", "title": "nnFormer: Interleaved Transformer for Volumetric Segmentation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": null, "title": "TRANSFORMERS MEET VISUAL LEARNING UNDERSTANDING: A COMPREHENSIVE REVIEW"}]}