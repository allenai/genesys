{"paperId": "1566d3de5321a27483f8dd26a2294634d43492e5", "abstract": "Transformer has brought great success to a wide range of natural language processing tasks. Nevertheless, the computational overhead of the vanilla transformer scales quadratically with sequence length. Many efforts have been made to develop more ef\ufb01cient transformer variants. A line of work (e.g., Linformer) projects the input sequence into a low-rank space, achieving linear time complexity. However, Linformer does not suit well for text generation tasks as the sequence length must be pre-speci\ufb01ed. We propose MemSizer, an approach also projects the source sequence into lower dimension representation but can take input with dynamic length, with a different perspective of the attention mechanism. MemSizer not only achieves the same linear time complexity but also enjoys ef\ufb01cient recurrent-style autoregressive generation, which yields constant memory complexity and reduced computation at inference. We demonstrate that MemSizer provides an improved tradeoff between ef\ufb01ciency and accuracy over the vanilla transformer and other linear variants in language modeling and machine translation tasks, revealing a viable direction to-wards further inference ef\ufb01ciency improve-ment.", "venue": "arXiv.org", "year": 2022, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2203.12644", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is demonstrated that MemSizer provides an improved tradeoff between ef\ufb01ciency and accuracy over the vanilla transformer and other linear variants in language modeling and machine translation tasks, revealing a viable direction to-wards further inference ef-ciency improve-ment."}, "embedding": {"model": "specter_v2", "vector": [0.22200274467468262, 0.7472693920135498, -0.2924865782260895, 0.12348129600286484, -0.71224445104599, -0.6338133215904236, 0.8848665356636047, -0.10964522510766983, -0.4347374737262726, -0.2566401958465576, 0.927460253238678, -0.21575786173343658, 0.5282740592956543, -0.29684051871299744, -0.38301801681518555, -0.1465074121952057, -0.5558022856712341, 0.42319539189338684, -0.384181410074234, -0.13315263390541077, -0.02220788598060608, -0.6096223592758179, -0.5462227463722229, 0.34364932775497437, 0.13174548745155334, 0.37056809663772583, 0.34612327814102173, 0.8131418228149414, -0.7054175734519958, 0.43225306272506714, 0.5194193720817566, -0.6047079563140869, 0.3902561366558075, -0.13433241844177246, -0.2932151257991791, -0.1759803742170334, 0.3503475785255432, -0.4759405553340912, -0.3726901710033417, 0.8000458478927612, -0.14394544064998627, 0.2543008625507355, 0.36416754126548767, -0.43707022070884705, -0.5656237602233887, 1.361188292503357, 0.589012861251831, 0.7629188299179077, -0.18408483266830444, -0.6869996786117554, 1.3161484003067017, -1.8229193687438965, 0.24164749681949615, 1.6831603050231934, 0.3350681960582733, 0.2639962136745453, -0.22579678893089294, -0.5758785605430603, 0.6399022340774536, 0.2924683392047882, -0.8090456128120422, -0.5482634902000427, 0.06483890116214752, -0.15007589757442474, 1.677951693534851, -0.26782166957855225, 0.12683695554733276, 0.5078836679458618, 0.007884801365435123, 1.366059422492981, -0.0006260161753743887, -0.7307956218719482, -0.28821665048599243, 0.11579097807407379, -0.05784223601222038, 0.9657905101776123, -0.5606042742729187, 0.20425722002983093, -1.0343961715698242, -0.2766202390193939, 0.3609165847301483, -0.4937712252140045, -0.08899590373039246, -0.1378035694360733, -0.44888538122177124, 0.8364973664283752, 0.2252931445837021, 0.8502215147018433, -0.05197553336620331, 0.7407616376876831, 0.39676809310913086, 0.1818496733903885, 0.3287391662597656, 0.48386242985725403, -0.03819718584418297, 0.3993091285228729, -1.1357954740524292, 0.18304358422756195, -0.26645347476005554, 0.7257782220840454, -0.3091002404689789, 0.6273919939994812, -1.0025215148925781, 0.13485956192016602, 1.249332070350647, 0.2604466378688812, 0.8369637727737427, -0.6495620012283325, 0.262325257062912, -0.9607437252998352, -0.18203498423099518, -0.8158259391784668, -0.08398307114839554, -0.34091755747795105, -1.0540845394134521, -1.6144633293151855, -0.4340861439704895, 0.20674388110637665, -0.7523304224014282, 0.8214132785797119, -0.39434704184532166, 0.3413493037223816, 0.2186182588338852, 0.19199058413505554, 0.36782267689704895, 1.0498056411743164, -0.2643369734287262, -0.18687400221824646, 1.045820951461792, -0.8970586061477661, -0.6972023248672485, -1.06598699092865, 0.6264822483062744, -0.28000062704086304, 0.17488506436347961, -0.14700140058994293, -1.3658092021942139, -0.8388846516609192, -0.5659233331680298, -0.06024250015616417, -0.44387921690940857, 0.6076556444168091, 0.8882129788398743, 0.44318994879722595, -1.2521169185638428, 0.5508285760879517, -0.1674058884382248, -0.012882430106401443, 0.2828584611415863, 0.06696873903274536, 0.17018108069896698, -0.2609533369541168, -1.1021971702575684, 0.30624911189079285, 0.08330168575048447, -0.3334062099456787, -0.058397985994815826, -0.8202979564666748, -1.0993868112564087, -0.0005037381197325885, 0.145084410905838, -0.6133241057395935, 1.0991038084030151, 0.2582976818084717, -1.5719118118286133, 0.36519235372543335, -0.6795616149902344, -0.07495114952325821, -0.02894989773631096, -0.3572792410850525, 0.05637659132480621, -0.7096520066261292, 0.0460236519575119, 0.15985658764839172, 0.5764201879501343, 0.07863155007362366, 0.01500387117266655, 0.1852029263973236, -0.4999754726886749, -0.17842088639736176, -0.036623209714889526, 0.7528418302536011, -0.2671049237251282, -0.56080162525177, 0.5270825624465942, 0.46777981519699097, -0.32001352310180664, -0.5754369497299194, -0.6496824026107788, -0.9069995880126953, 0.33595776557922363, -0.08229522407054901, 0.9929883480072021, -0.6199452877044678, -0.3626619875431061, -0.15732961893081665, -0.19436946511268616, -0.3454338312149048, -0.9479910135269165, 0.8177940249443054, -0.7145764231681824, 0.4965462386608124, -0.08046267181634903, -0.7650911808013916, -0.034910302609205246, -0.47578248381614685, -1.2847083806991577, -0.09832777827978134, 0.30930283665657043, 1.2012816667556763, -0.9148750305175781, 0.22088001668453217, -0.0368068553507328, 0.08826526999473572, -1.0306395292282104, 1.2597122192382812, -0.07995720952749252, 0.15266110002994537, -0.07886075228452682, -0.5001466274261475, 0.134366974234581, -0.32932230830192566, 0.456879198551178, -0.5144819021224976, -0.014189903624355793, 0.5020933151245117, -0.5776501893997192, 1.1830830574035645, -0.4357167184352875, 0.613994300365448, -0.23288363218307495, -0.8471285104751587, 0.1545952707529068, 0.31891244649887085, -0.19392041862010956, -0.15217165648937225, 0.1732710599899292, 0.32956209778785706, -0.6652899384498596, 0.5222776532173157, 0.6587901711463928, 0.5195044279098511, -0.1824253350496292, 0.15413394570350647, 0.6390103101730347, -0.29763689637184143, 0.41849634051322937, 0.4864751398563385, 0.6928612589836121, 0.23771753907203674, 0.47426000237464905, -0.025932425633072853, 0.4209115207195282, -0.9254146218299866, -0.18068791925907135, 0.5160896182060242, 1.3444194793701172, 0.8222803473472595, 0.30018889904022217, -0.5092988610267639, -0.4007088243961334, -0.2588457763195038, 0.8092158436775208, 1.2437385320663452, -0.630351185798645, -0.651245653629303, -0.5325911641120911, 0.17741039395332336, -0.5410298705101013, 0.22305768728256226, -0.26660364866256714, -0.17853471636772156, -0.7785928249359131, -1.0406725406646729, 0.8546265363693237, 0.4175134599208832, 0.7952821850776672, -0.037565309554338455, 0.05096907541155815, -0.1821662038564682, -0.11124634742736816, -0.85071861743927, -0.5528392195701599, 0.02360495924949646, -0.5673537850379944, 0.1288035660982132, -0.11985720694065094, 0.15461286902427673, 0.2315085381269455, -0.6621761918067932, 0.9427146911621094, -0.7850701808929443, 0.020957784727215767, -0.04106098413467407, 0.4537649154663086, -0.5965238213539124, -0.6739368438720703, 0.10961870104074478, 0.3366716206073761, -0.11700493097305298, -0.018840836361050606, 0.35460102558135986, 0.11637569218873978, -0.4677826762199402, -0.23906420171260834, 0.43145138025283813, 0.15413853526115417, 0.33558279275894165, 0.5023201107978821, -0.34117984771728516, -0.4385906159877777, -1.1013977527618408, 0.9833125472068787, 0.2713875472545624, -0.5761415958404541, 0.22882159054279327, -0.7016745209693909, -0.09345509111881256, 0.48236021399497986, -0.6443346738815308, 0.0783727616071701, -0.9002195000648499, 0.10535646229982376, -0.31915390491485596, 0.31726953387260437, 0.295840322971344, 0.27712076902389526, 0.7213847041130066, -0.08152875304222107, 0.7283633947372437, 0.26732948422431946, -0.12304577231407166, 1.1962871551513672, -0.9967772364616394, 0.4609090983867645, 0.3478487432003021, 0.6892669796943665, -0.19322404265403748, -0.17728832364082336, -0.6964650750160217, -0.4077126979827881, -0.032736096531152725, -0.08144500106573105, -0.054305993020534515, 0.2697041630744934, -0.7587189078330994, -0.8331964015960693, -0.07231393456459045, -1.4241688251495361, 0.1770407259464264, -0.029431840404868126, -0.20717686414718628, -0.23754802346229553, -1.1630380153656006, -1.4941284656524658, -0.6026559472084045, -0.9081801772117615, -0.9585487246513367, 0.6092854738235474, -0.3396230936050415, -0.3122376799583435, -0.328029066324234, 0.07304222881793976, -0.3758887052536011, 1.1494109630584717, -0.9301905632019043, 1.1035584211349487, -0.03726208955049515, -0.5799033641815186, -0.06051651015877724, 0.20942169427871704, 0.4427724778652191, -0.3496535122394562, -0.06501249969005585, -0.6584017872810364, 0.061364397406578064, -0.29532110691070557, 0.09880850464105606, 0.1867923140525818, 0.5963644981384277, 0.4554663896560669, -0.5031457543373108, -0.5373906493186951, 0.422460675239563, 1.3515751361846924, -0.5748143196105957, -0.03423044830560684, 0.10469922423362732, 1.00264573097229, 0.13679225742816925, -0.22507427632808685, 0.5596527457237244, 0.23507146537303925, 0.4634692370891571, -0.07329458743333817, 0.06608084589242935, 0.20039014518260956, -0.6698551774024963, 0.7861394882202148, 1.9855351448059082, 0.3462626039981842, -0.16560830175876617, -0.7863194346427917, 0.476773202419281, -1.2723388671875, -1.1183758974075317, 0.7047324180603027, 0.6250637173652649, 0.2603204548358917, -0.7916494607925415, -0.4249815046787262, -0.15577659010887146, 0.21992795169353485, 0.47573596239089966, -0.012703614309430122, -0.6476659178733826, 0.059256233274936676, 0.6416978240013123, 0.43523216247558594, 0.762981653213501, -0.009945732541382313, 0.8286502361297607, 14.920648574829102, 0.7166216969490051, -0.1328149139881134, 0.7116779088973999, 0.4706529974937439, -0.12277540564537048, -0.46690860390663147, 0.09935791045427322, -1.1748881340026855, -0.08469174057245255, 1.0056324005126953, -0.4427798390388489, 0.39754870533943176, 0.19493402540683746, 0.2585563361644745, 0.4662804901599884, -0.4544811546802521, 0.967758059501648, 0.6247344613075256, -1.652823805809021, 0.7593500018119812, 0.2311856746673584, -0.045245494693517685, 0.38983529806137085, 0.766761839389801, 0.6181299686431885, 0.37910225987434387, -0.5230769515037537, 0.43109825253486633, 0.37926918268203735, 0.6252758502960205, -0.060284573584795, 0.3288673758506775, 0.4566356837749481, -1.2502591609954834, -0.364331990480423, -0.7363243103027344, -1.059553623199463, 0.4856930673122406, 0.5437425971031189, -0.5842010378837585, -0.35219404101371765, -0.23780106008052826, 0.6298303008079529, 0.23584169149398804, -0.011955354362726212, -0.021071990951895714, 0.7835157513618469, -0.0285341814160347, 0.18490754067897797, 0.18276335299015045, -0.10142618417739868, 0.2701074182987213, -0.1433703899383545, 0.6903769969940186, 0.11366049945354462, 0.12291911244392395, 0.4628307521343231, -0.4719216227531433, 0.10460023581981659, -0.6221249103546143, -0.4584352672100067, 0.10394452512264252, 0.7769951224327087, 0.4127180874347687, 0.16236987709999084, -0.1989753246307373, 0.42753827571868896, 0.7685735821723938, -0.05206679180264473, -0.17373056709766388, 0.3143256902694702, 0.29966166615486145, -0.1184908002614975, 0.12404858320951462, 0.20831997692584991, 0.10765045136213303, -0.6166654825210571, -0.7386108040809631, -0.5233443975448608, 0.06584307551383972, -0.733578622341156, -0.5810676217079163, 0.9207916259765625, -0.19599252939224243, -0.5488907694816589, -0.05808964744210243, -0.817837655544281, -0.2001463621854782, 0.5658215284347534, -0.9312952160835266, -0.6658530831336975, 0.7184796929359436, -0.5203772187232971, -0.10262422263622284, -0.08852878957986832, 1.1669801473617554, -0.13878343999385834, -0.32605668902397156, 0.07809017598628998, 0.11117511987686157, 0.18399417400360107, -0.3698084354400635, -0.7583839297294617, 1.149725079536438, 0.6780468821525574, 0.26950666308403015, 0.6043498516082764, -0.041886020451784134, 0.18623921275138855, -1.1374320983886719, -0.04720751941204071, 0.8851660490036011, -1.170654058456421, -0.33605995774269104, -1.0798397064208984, -0.5425623059272766, 0.23427927494049072, 0.48327144980430603, -0.5947417616844177, 0.38677066564559937, 0.03805389627814293, -0.48563286662101746, -0.2156517207622528, -0.23145923018455505, 0.11287882179021835, 0.6217347979545593, -0.8001985549926758, -0.22654198110103607, 0.08391644060611725, 0.4668593108654022, -0.9919648170471191, -0.3791804015636444, -0.26676440238952637, 0.140070840716362, 0.3071618378162384, 1.1177552938461304, -0.5240652561187744, 0.7887178063392639, 0.7812351584434509, -0.1261075735092163, -0.9311553239822388, -0.644682765007019, -0.7911419868469238, -0.02962963655591011, 0.4634459912776947, 0.6330527663230896, -0.13201409578323364, 0.3255363702774048, 0.5313006639480591, 0.5139377117156982, -0.5445020198822021, -0.7270106077194214, -0.21124981343746185, 0.196905717253685, -0.6854591369628906, 0.18312780559062958, -0.2451781928539276, -0.12179051339626312, 0.6883603930473328, 0.009309526532888412, 0.4624854326248169, -0.27522948384284973, -0.6538487672805786, 0.5705607533454895, 0.11498701572418213, -0.013286808505654335, -0.5037655830383301, -0.3766392469406128, -1.5479179620742798, 0.17630212008953094, -1.4977707862854004, 0.005983809940516949, -1.2844712734222412, -0.310842901468277, 0.3844946324825287, 0.09240582585334778, 0.047867849469184875, 0.3024381101131439, -0.22062155604362488, -0.25348415970802307, -0.7082866430282593, 0.08632482588291168, 0.7701711654663086, 0.48458704352378845, -0.9690006971359253, 0.22216464579105377, -0.09597547352313995, -0.045459698885679245, 0.05099564790725708, 0.22316282987594604, -0.36127564311027527, -0.996401846408844, -1.4649112224578857, 0.5730650424957275, 0.08554177731275558, -0.13552752137184143, -0.3728232681751251, 0.7459202408790588, 0.3036022484302521, -0.06634583324193954, -0.058857839554548264, 0.47109201550483704, -0.47297412157058716, -0.09262920916080475, 0.30458441376686096, -0.8819071650505066, 0.6836922764778137, -0.11622939258813858, -0.5965447425842285, -0.061288658529520035, 0.8140231966972351, -0.11821652948856354, -1.2696647644042969, -0.30973106622695923, 0.4776640832424164, -0.8005845546722412, 0.1102297455072403, -0.5945208072662354, -0.11591921746730804, -0.8849664926528931, -0.476627379655838, 0.38716888427734375, -0.02869546227157116, -0.3076440691947937, 1.1635059118270874, 0.6428664922714233, -1.2112845182418823, -0.043401721864938736, 0.39927223324775696, -0.3201277554035187, -0.35791775584220886, 0.2520447075366974, 0.2894503176212311, 0.17579910159111023, 0.5848093032836914, 0.5877062678337097, 0.34833064675331116, -0.9314063787460327, 0.07842367142438889, 0.40815821290016174, -0.6527948379516602, -0.33822521567344666, 1.292254090309143, -0.41683366894721985, -1.033522129058838, -0.23157234489917755, -1.1945897340774536, -0.4176463186740875, -0.1679842174053192, 0.7734705209732056, 0.20130479335784912, -0.10948020964860916, -0.11083097010850906, -0.6411222815513611, 0.29192835092544556, 0.07627612352371216, -0.8627610206604004, 0.442077100276947, -0.12533973157405853, -0.7834450602531433, 0.7292776107788086, 1.0095393657684326, -0.3872842788696289, 0.2096179723739624, -0.661959171295166, -0.3864305913448334, -0.298429399728775, 0.3482731580734253, 0.07483983784914017, -0.598672091960907, 0.6275681257247925, 0.49255216121673584, 0.014181247912347317, 0.1041538417339325, -0.1861105114221573, 0.2367296814918518, 0.579156219959259, 0.24976018071174622, -0.41954904794692993, -0.5557395219802856, 1.5562725067138672, 1.2525960206985474, -0.367996484041214, 0.4419150650501251, -0.32798001170158386, -0.5680400133132935, 0.8266052007675171, 0.00900866836309433, -0.025290384888648987, 0.9070802927017212, 0.13528069853782654, 0.18092387914657593, 0.3357357382774353, -1.2771353721618652, -0.3753339350223541, 0.8857566714286804, 0.980362057685852, 1.0016556978225708, 0.005584364756941795, 0.008773783221840858, 0.7992943525314331, -0.2887866795063019, -0.0061323014087975025, 0.6021813750267029, 0.33087101578712463, -0.051056597381830215, -0.27907514572143555, -0.12367440015077591, 1.0143826007843018, -0.6323807239532471, -1.078887939453125, 0.23163087666034698, 0.2014031559228897, -0.07542046904563904, 0.7996344566345215, 0.8629043698310852, -0.09421920031309128, 0.5534055829048157, 0.13113616406917572, 0.5415387153625488, -0.5827175974845886, -0.09581499546766281, -0.19998440146446228, -0.7401235103607178, -0.31847232580184937, -0.019580697640776634, -0.2652256190776825, -0.3146817088127136, -0.16560280323028564, 0.20072883367538452, 0.31775152683258057, 0.2517564594745636, 1.0057899951934814, 0.5136752724647522, 0.31121546030044556, -0.0711735337972641, -0.5399672389030457, -0.5164283514022827, -0.9551144242286682, 0.22458185255527496, -0.6032090783119202, -0.3006620705127716, -0.027430769056081772, 0.04965205118060112, -0.07400014251470566]}, "authors": [{"authorId": "48378494", "name": "Yizhe Zhang"}, {"authorId": "2053327987", "name": "Deng Cai"}], "references": [{"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "title": "Luna: Linear Unified Nested Attention"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "054e307c1edf4b28137ffcbce980fe81f0647d20", "title": "Finetuning Pretrained Transformers into RNNs"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "0822f8d7e6a72a65e65f147d3a8d8fccd485da40", "title": "Shortformer: Better Language Modeling using Shorter Inputs"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "168fc3525f7b97695a97b04e257ee9bd1e832acb", "title": "Memory Transformer"}, {"paperId": "ac6535d096fc79dde2d9ce0329e0626b79ede7f0", "title": "Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "a238109c3969ae681eee0d4f1bf2012f28850593", "title": "Synthesizer: Rethinking Self-Attention in Transformer Models"}, {"paperId": "8905f3dcd215fbc3d56839b6f52a43d77ac59fe8", "title": "Augmenting Transformers with KNN-Based Composite Memory for Dialog"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "ce106590145e89ea4b621c99665862967ccf5dac", "title": "Q8BERT: Quantized 8Bit BERT"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1", "title": "Reducing Transformer Depth on Demand with Structured Dropout"}, {"paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"}, {"paperId": "3c5f1ab37f70db503636075e15b3173f86eea00b", "title": "Green AI"}, {"paperId": "bf442ab269074665a68e4dbbe19e4efc97862541", "title": "Large Memory Layers with Product Keys"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "b03c7ff961822183bab66b2e594415e585d3fd09", "title": "Are Sixteen Heads Really Better than One?"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "bf8fe437f779f2098f9af82b534aa51dc9edb06f", "title": "Scaling Neural Machine Translation"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "424aef7340ee618132cc3314669400e23ad910ba", "title": "Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling"}, {"paperId": "32e934094c4d17fe4d734b2e169ba5e3cd0ee05e", "title": "Orthogonal Random Features"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "63e39cdf1ad884da6bc69096bb3413b5b1100559", "title": "Using the Output Embedding to Improve Language Models"}, {"paperId": "1a327709cc53ff9e52454e50a643abf4a0ac92af", "title": "Findings of the 2016 Conference on Machine Translation"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e", "title": "End-To-End Memory Networks"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "c1126fbffd6b8547a44c58b192b36b08b18299de", "title": "Neural Turing Machines"}, {"paperId": "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649", "title": "Understanding the difficulty of training deep feedforward neural networks"}, {"paperId": "7a59fde27461a3ef4a21a249cc403d0d96e4a0d7", "title": "Random Features for Large-Scale Kernel Machines"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "ce9a21b93ba29d4145a8ef6bf401e77f261848de", "title": "A Learning Algorithm for Continually Running Fully Recurrent Neural Networks"}, {"paperId": null, "title": ". Ef\ufb01cient"}, {"paperId": null, "title": "Lucia Specia, Marco Turchi, Karin Verspoor, and Marcos Zampieri"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}]}