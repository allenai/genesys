{"paperId": "a20e7e5e4338644d24145e71a9b89100af87e5d0", "abstract": "Large-scale pre-trained multi-modal models (e.g., CLIP) demonstrate strong zero-shot transfer capability in many discriminative tasks. Their adaptation to zero-shot image-conditioned text generation tasks has drawn increasing interest. Prior arts approach to zero-shot captioning by either utilizing the existing large language models (e.g., GPT-2) or pre-training the encoder-decoder network in an end-to-end manner. In this work, we propose a simple framework, named DeCap, for zero-shot captioning. We introduce a lightweight visual-aware language decoder. This decoder is both data-efficient and computation-efficient: 1) it only requires the text data for training, easing the burden on the collection of paired data. 2) it does not require end-to-end training. When trained with text-only data, the decoder takes the text embedding extracted from the off-the-shelf CLIP encoder as a prefix embedding. The challenge is that the decoder is trained on the text corpus but at the inference stage, it needs to generate captions based on visual inputs. The modality gap issue is widely observed in multi-modal contrastive models that prevents us from directly taking the visual embedding as the prefix embedding. We propose a training-free mechanism to reduce the modality gap. We project the visual embedding into the CLIP text embedding space, while the projected embedding retains the information of the visual input. Taking the projected embedding as the prefix embedding, the decoder generates high-quality descriptions that match the visual input. The experiments show that DeCap outperforms other zero-shot captioning methods and unpaired captioning methods on the typical image captioning benchmarks, i.e., MSCOCO and NoCaps.", "venue": "International Conference on Learning Representations", "year": 2023, "citationCount": 45, "influentialCitationCount": 8, "openAccessPdf": {"url": "http://arxiv.org/pdf/2303.03032", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces a lightweight visual-aware language decoder that only requires the text data for training, easing the burden on the collection of paired data, and proposes a training-free mechanism to reduce the modality gap."}, "embedding": {"model": "specter_v2", "vector": [0.3458770513534546, 0.6274972558021545, -0.3036826252937317, 0.07693268358707428, -0.7814464569091797, -0.18240445852279663, 1.0195555686950684, -0.4987470209598541, -0.12225805222988129, -0.3628249764442444, 0.9100790023803711, 0.3987555205821991, 0.4161320626735687, 0.25657859444618225, -0.22540690004825592, -0.04704313352704048, -0.5767992734909058, 0.2931106388568878, 0.39102306962013245, -0.8216108083724976, -0.2765616178512573, -1.2455862760543823, -1.3083068132400513, 0.711383581161499, 0.40230029821395874, 0.28342750668525696, 0.463070273399353, 1.3262159824371338, -0.07743547111749649, 0.1154373437166214, 0.5662934184074402, -0.6923489570617676, 0.08541657775640488, -0.3792575001716614, -0.048687729984521866, 0.14182886481285095, 0.3472217321395874, -0.9940003156661987, -0.3666444718837738, 0.511512279510498, -0.07620768994092941, 0.1457156240940094, 1.0267325639724731, -0.8056113719940186, -0.7477145195007324, 0.5508254766464233, 0.5409988164901733, 0.05944228544831276, 0.03122527152299881, -0.7097060084342957, 1.4335708618164062, -1.5676344633102417, 0.7552270889282227, 1.538500428199768, -0.048574257642030716, 1.097951889038086, -0.26794278621673584, -0.056403327733278275, 0.9796391725540161, -0.026441391557455063, -0.6061453819274902, -0.25837934017181396, 0.09659521281719208, -0.3115270137786865, 1.028120517730713, -0.4714934825897217, -0.2272801250219345, 1.260288953781128, -0.10023240000009537, 1.1902740001678467, -0.6016882061958313, -1.0705150365829468, -0.21042704582214355, 0.04528941586613655, -0.33737289905548096, 0.5899040102958679, -0.8055872917175293, 0.24159446358680725, -0.7425929307937622, 0.48904696106910706, 0.14893393218517303, 0.07202394306659698, -0.23684696853160858, -0.28273600339889526, -0.490858256816864, 0.5683298110961914, 0.43543729186058044, 0.3258107900619507, 0.33739805221557617, 0.5025756359100342, 0.7651962041854858, 0.14494693279266357, 0.10031703114509583, -0.3223096430301666, 0.3694564998149872, 0.4512387812137604, -0.8088417053222656, 0.4079437553882599, 0.23061023652553558, 1.1864356994628906, -0.6708235144615173, -0.3730202317237854, -1.4555010795593262, 0.11867953091859818, 1.0767226219177246, -0.039546120911836624, 0.3981095254421234, -0.8176255822181702, 0.49029138684272766, -1.2341184616088867, 0.4221227765083313, -1.0159564018249512, 0.3085131049156189, 0.2056398093700409, -0.6133611798286438, -1.093947410583496, -0.4831676781177521, 0.26078295707702637, -1.3690024614334106, 0.9706921577453613, -0.5556437373161316, -0.08510778099298477, 0.2092730700969696, 0.6457580924034119, 0.7543286681175232, 1.1855015754699707, 0.3313131332397461, 0.20792582631111145, 0.9287721514701843, -1.1803945302963257, -0.8450106382369995, -1.0674294233322144, 0.5190281271934509, -0.18726502358913422, 0.6674599647521973, -0.5342431664466858, -0.8568970561027527, -0.8649201393127441, -1.2155951261520386, -0.4228041470050812, -0.8545135259628296, 0.5644160509109497, 0.675066351890564, 0.3568419814109802, -0.9258121252059937, 0.4088055491447449, -0.08133646100759506, -0.4775538146495819, 0.29074519872665405, -0.26929450035095215, 0.02521207183599472, -0.8951298594474792, -1.2293424606323242, 0.1571691781282425, 0.009150859899818897, -0.7069898843765259, -0.5904956459999084, -0.44201424717903137, -1.4258906841278076, -0.2625613808631897, 0.5451216101646423, -0.34684208035469055, 1.2245097160339355, -0.40683308243751526, -1.0391745567321777, 0.7840607762336731, -0.565284013748169, 0.4804321229457855, 0.49632394313812256, -0.38169410824775696, -0.3550821542739868, 0.16361582279205322, 0.23685355484485626, 1.2254117727279663, 0.7330945730209351, -0.6009914875030518, 0.13878010213375092, 0.7154427766799927, -0.13467317819595337, -0.02660263516008854, -0.3742741644382477, 0.6375702023506165, -1.0754427909851074, -0.2763899862766266, 0.05599717050790787, 0.7282497882843018, 0.38865166902542114, 0.38965317606925964, -0.44579359889030457, -0.5187209248542786, 0.9370604157447815, -0.07193608582019806, 0.38647621870040894, -1.1546567678451538, -0.31871458888053894, -0.6921376585960388, -0.306270569562912, -0.489663690328598, -1.0474437475204468, 0.7476162910461426, -0.2208619862794876, 0.390548437833786, -0.2554249167442322, -1.8117364645004272, 0.338898628950119, -0.2368769496679306, -0.8468753695487976, -0.4618273675441742, 0.3468646705150604, 1.375130534172058, -0.8035117387771606, -0.4375232756137848, -0.07050832360982895, 0.3678847551345825, -0.9261670708656311, 1.0610792636871338, -0.951133131980896, 0.08271383494138718, -0.25738024711608887, -0.12205782532691956, -0.05991048738360405, -0.2616766095161438, 0.33201679587364197, -0.6768304705619812, 0.14304649829864502, -0.051015716046094894, 0.083350770175457, 1.7412619590759277, 0.27094078063964844, 0.8458490967750549, -0.4695834517478943, -0.5113111138343811, 0.19668203592300415, 0.8572315573692322, -0.39725059270858765, -0.5617309212684631, 0.6200228333473206, 0.07686042040586472, -0.9216923117637634, -0.16928431391716003, 0.7203291058540344, 0.433483749628067, -0.6189048290252686, -0.026089627295732498, 0.5272807478904724, -0.23968985676765442, 0.8233224153518677, 1.0610722303390503, 0.35538747906684875, 0.765428364276886, -0.41404855251312256, 0.19600650668144226, 0.23472721874713898, -0.6683844327926636, -0.811061680316925, 0.29185181856155396, 0.6227068901062012, 1.9994943141937256, 0.9804272651672363, -0.4234107732772827, -0.8599632382392883, -0.19296807050704956, 1.0190258026123047, 1.6451667547225952, 0.18958427011966705, -0.31046152114868164, -0.946067750453949, -0.14047515392303467, -0.7238330245018005, -0.056060947477817535, -0.6984813213348389, -0.2068660706281662, -0.001509333262220025, -0.6679772734642029, 0.2887294888496399, 0.44658172130584717, 0.8666539788246155, -0.3799213171005249, 0.00986791867762804, -0.47958993911743164, -0.4159727692604065, -1.0299957990646362, -0.827919602394104, -0.04291520267724991, 0.27204206585884094, 0.22084985673427582, -0.7559868097305298, -0.6884974241256714, 0.5993566513061523, -0.7295026779174805, 0.8953440189361572, -0.6773908138275146, -0.6472134590148926, 0.470595121383667, -0.11753564327955246, -0.2941908836364746, -0.6690552234649658, 0.13591323792934418, 0.022442054003477097, -0.07108774781227112, 0.25596052408218384, 0.5150370001792908, 0.25304967164993286, 0.19483695924282074, -0.5966043472290039, 0.8976104259490967, -0.04063388705253601, -0.14497552812099457, 0.7709493041038513, -0.7931635975837708, 0.28105977177619934, -0.49494946002960205, 0.7675567269325256, -0.019678199663758278, -0.009501736611127853, 0.3314562439918518, 0.16645781695842743, -0.6721399426460266, 0.4893507659435272, -0.970528781414032, -0.5092887282371521, -0.6750194430351257, 0.5588279366493225, -0.49856045842170715, -0.21014611423015594, 0.18063560128211975, -0.13077232241630554, 0.7911893129348755, 0.31240376830101013, 0.4073677659034729, 0.42043760418891907, -0.0847783237695694, 1.009122610092163, -1.037099838256836, 1.1018191576004028, -0.022670280188322067, 0.32000860571861267, 0.4173378348350525, -0.01655815728008747, -0.19323591887950897, -0.639539897441864, -0.10741086304187775, -0.6855672001838684, -1.1600430011749268, 0.953617513179779, -0.6485804319381714, -0.5084327459335327, -0.26374247670173645, -1.2217928171157837, 0.0441640242934227, 0.27669641375541687, -0.696458637714386, -0.43256717920303345, -0.8453090190887451, -0.8366489410400391, -0.08036349713802338, -0.44420936703681946, -0.6884968280792236, 0.5228822231292725, 0.13661709427833557, -0.2710646390914917, -0.3376648724079132, 0.1469976305961609, -0.2925691306591034, 0.5568007826805115, -0.071782685816288, 0.7381102442741394, 0.17485252022743225, -0.4301750957965851, -0.8500486016273499, 0.08310443162918091, 0.7288140058517456, -0.38855114579200745, 0.3853468596935272, -0.6781818270683289, 0.04993162676692009, -0.7166791558265686, -0.5884243845939636, 0.13114053010940552, 0.3624730706214905, 0.046129677444696426, 0.48659905791282654, -0.6343569755554199, 0.26634758710861206, 1.7150835990905762, -0.7098410725593567, 0.5325352549552917, -0.2550926208496094, 0.7750620245933533, 0.657170295715332, -0.02599859982728958, 0.42226460576057434, 0.28861159086227417, 0.13730019330978394, 0.3333447575569153, -0.22290214896202087, -0.3857240676879883, -1.1645689010620117, 0.7604403495788574, 1.4491779804229736, 0.2832280993461609, -0.45112308859825134, -0.9630182385444641, 1.2763053178787231, -1.3304502964019775, -0.7622928023338318, 0.5295397043228149, 0.42499569058418274, -0.31764698028564453, -0.5801824331283569, -0.452990859746933, -0.8101019263267517, 0.758868932723999, 0.36200058460235596, -0.13616156578063965, -0.5286523103713989, 0.008262401446700096, -0.21160706877708435, -0.32498738169670105, 0.4625678062438965, -0.4659927487373352, 0.26158225536346436, 13.95173454284668, 0.882534921169281, 0.4183887839317322, 0.3357844054698944, 0.7783454060554504, -0.0916743129491806, -0.4887612760066986, -0.14506536722183228, -1.0452985763549805, -0.09984809160232544, 1.1793402433395386, 0.21692121028900146, 0.016503749415278435, 0.20370502769947052, 0.07388035207986832, 0.23419100046157837, -0.7458931803703308, 0.6089591383934021, 1.374312162399292, -1.208138108253479, 0.6531574726104736, -0.04349664971232414, 0.7224108576774597, 0.18497571349143982, 1.1550241708755493, 1.0068488121032715, -0.15081922709941864, -0.30149635672569275, 0.47166430950164795, 0.38418057560920715, 1.231528639793396, -0.21971894800662994, 0.17862766981124878, 0.31989118456840515, -0.6976308822631836, -0.21181729435920715, -0.6480141878128052, -0.822656512260437, 0.7331027388572693, -0.4572172462940216, 0.07516752928495407, -0.2934231460094452, -0.11165030300617218, 0.620575487613678, 0.005421342793852091, 0.2127223014831543, 0.005544453859329224, 0.22497335076332092, 0.19874975085258484, -0.09463623911142349, 0.6061943769454956, 0.514418363571167, 0.4634685218334198, -0.14227986335754395, 0.24568957090377808, 0.13812480866909027, -0.05862584337592125, 0.8704654574394226, -0.5874902606010437, -0.18732450902462006, -0.5334784984588623, -0.07002179324626923, -0.6377375721931458, 0.582518994808197, 0.131599560379982, 0.18556258082389832, -0.7152525782585144, 0.7829443216323853, 0.27881619334220886, 0.3214907646179199, -0.47368234395980835, -0.25002795457839966, -0.18845203518867493, -0.08808503299951553, 0.5028194189071655, 0.6413980722427368, 0.22738705575466156, -0.5914117097854614, -0.3230966329574585, 0.2819243371486664, -0.09254216402769089, -1.4649347066879272, -1.0022677183151245, 0.9175004363059998, 0.10333658009767532, -1.1929097175598145, -0.10904309153556824, -0.6855873465538025, -0.6449050903320312, 0.09791933000087738, -0.9644060134887695, -0.9451351761817932, -0.039248544722795486, -0.2834923565387726, -0.14860233664512634, 0.0921933501958847, 1.2370679378509521, 0.3002256751060486, 0.04443487152457237, 0.18830759823322296, 0.48643970489501953, 0.2208607792854309, 0.07588235288858414, -0.38014090061187744, 0.473467081785202, 0.18599538505077362, -0.5653433799743652, -0.39045149087905884, 0.3919859230518341, 0.09763967990875244, -0.5604718923568726, 0.014763589017093182, 0.6657569408416748, -0.9337770342826843, -0.6023042798042297, -0.8728212714195251, -0.6962945461273193, -0.14228442311286926, 0.9322690963745117, -0.23072980344295502, 0.44346800446510315, 0.0013415224384516478, -0.6428442001342773, 0.0022031590342521667, -0.748773455619812, 0.550275981426239, 0.03284671530127525, -0.6744017601013184, -0.4243563413619995, 0.25183719396591187, 0.8691875338554382, -0.8580989837646484, -0.11536388099193573, -0.5960389971733093, 0.2876310348510742, -0.0030237953178584576, 0.9063661694526672, -0.23160333931446075, 1.5707719326019287, 0.7130895853042603, -0.3480413556098938, -0.4867064952850342, 0.23804765939712524, -0.8337255716323853, 0.19146904349327087, 0.6646624207496643, 0.6449401378631592, 0.437229186296463, 0.12219295650720596, 1.11605703830719, 0.30942630767822266, -0.34959036111831665, -0.3250423073768616, -0.4928204119205475, 0.5835740566253662, -0.4912347197532654, -0.23281800746917725, -0.37570539116859436, 0.18248414993286133, 0.274689257144928, -0.2662307620048523, 0.38473251461982727, 0.10699760913848877, -0.9878108501434326, 0.4519418179988861, 0.14075398445129395, 0.03314005956053734, 0.23826143145561218, -0.49984756112098694, -1.5149905681610107, -0.028919095173478127, -1.0406564474105835, 0.5050750374794006, -1.1598501205444336, 0.15525180101394653, 1.1112290620803833, 0.07166530936956406, -0.10320685058832169, 0.6372478008270264, 0.23881085216999054, 0.27169814705848694, -0.8102676868438721, -0.9170046448707581, 0.9415190815925598, 1.4340468645095825, -0.7718304991722107, 0.128753200173378, -0.5740066170692444, -0.007181271910667419, 0.11746896058320999, 0.20106932520866394, -0.08286052942276001, -1.0358349084854126, -1.3484827280044556, 0.5111101865768433, 0.053216494619846344, 0.4514564275741577, -1.113257646560669, 0.5671334862709045, 0.9446480870246887, -0.268076092004776, -0.5911062359809875, 0.9008281826972961, -0.9089133143424988, -0.8473397493362427, -0.20469239354133606, -0.9816395044326782, -0.06068621203303337, 0.23142488300800323, -0.132072314620018, -0.5502512454986572, 0.6664950251579285, -0.07884146273136139, -0.9530325531959534, -0.6925333738327026, 0.4841725528240204, -0.6748666167259216, 0.10540572553873062, -0.02980645000934601, -0.04412904381752014, -1.3217389583587646, -0.9936082363128662, -0.4770810008049011, 0.28133320808410645, -0.4517804682254791, 1.4025479555130005, 0.8392030000686646, -1.5473166704177856, -0.3687668740749359, 0.12437881529331207, 0.39217934012413025, -0.09363853186368942, 1.2105242013931274, 0.2432461529970169, -0.10313832014799118, 0.5619614720344543, 0.047415249049663544, 0.42253682017326355, -0.6506273746490479, 0.33339330554008484, 0.6098591089248657, -0.02399599738419056, -0.34178096055984497, 0.8662872910499573, -0.056638117879629135, -0.8507633209228516, 0.21323162317276, -0.659982442855835, -0.4140322208404541, -0.03792225942015648, 1.0014528036117554, -0.2584192156791687, -0.6304771900177002, -0.5761082768440247, -0.25161632895469666, 0.7135970592498779, -0.5140732526779175, -1.0436509847640991, 0.5661497116088867, -0.5058780908584595, -0.12267596274614334, 0.44892939925193787, 1.4149090051651, -1.2969365119934082, -0.9928994178771973, -0.3321799635887146, -1.2559657096862793, -0.04382787644863129, -0.05193668231368065, -0.759799599647522, -0.11522132903337479, 1.0320240259170532, 0.7922757863998413, 0.3317223787307739, 0.30614620447158813, 0.3884144425392151, 0.1502772718667984, 0.39136743545532227, -0.4637075662612915, -1.0175729990005493, -0.01238991692662239, 1.0414512157440186, 1.5094647407531738, -0.810680627822876, 0.1645929217338562, -0.28950363397598267, -1.1671066284179688, 0.5465237498283386, 0.4632757902145386, 0.14004069566726685, 1.0277718305587769, -0.40426987409591675, -0.14387191832065582, 0.4593125879764557, -1.4693487882614136, -0.212239608168602, 1.0250071287155151, 1.7741447687149048, 0.18926386535167694, 0.18158556520938873, 0.020530231297016144, 0.9225133657455444, 0.30261746048927307, 0.18138620257377625, 0.8480223417282104, 0.12918871641159058, -0.4737427532672882, -0.09051305055618286, 0.05663933977484703, 0.5450752377510071, -0.5045707821846008, -0.5847808122634888, 0.09359649568796158, 0.27603772282600403, 0.115267813205719, 0.7990537285804749, 1.1508233547210693, 0.022131089121103287, 0.30432793498039246, 0.37116673588752747, 0.2388489544391632, -0.38456660509109497, 0.5432568788528442, -0.13044695556163788, -0.9211021065711975, 0.29588064551353455, -0.30318522453308105, -0.5250880718231201, -0.2867737412452698, -0.26104140281677246, 0.7016122341156006, -0.7571242451667786, 0.21096543967723846, 1.3520300388336182, 0.486721932888031, 0.5222480297088623, -0.5209357142448425, -1.032597541809082, 0.2620917558670044, -0.5970301628112793, 0.1411008983850479, -0.174423485994339, -0.14905177056789398, -0.2514910101890564, -0.36227700114250183, 0.4661087691783905]}, "authors": [{"authorId": "153021098", "name": "Wei Li"}, {"authorId": "2948393", "name": "Linchao Zhu"}, {"authorId": "39774417", "name": "Longyin Wen"}, {"authorId": "2143684866", "name": "Yi Yang"}], "references": [{"paperId": "440b698bd341c7a44f407fa64f954ec06604e80b", "title": "V2L: Leveraging Vision and Vision-language Models into Large-scale Product Retrieval"}, {"paperId": "3cf5995209f1531669615fc25b098ce8ce3768d0", "title": "Zero-Shot Video Captioning with Evolving Pseudo-Tokens"}, {"paperId": "959e1ff94f7775f02a53a54a9939b28006882084", "title": "The Unreasonable Effectiveness of CLIP Features for Image Captioning: An Experimental Analysis"}, {"paperId": "43c81cd19ffd3170be14407e10e0229f879a8647", "title": "Multimodal Knowledge Alignment with Reinforcement Learning"}, {"paperId": "05bcf9999525656cfaa59bc71f8572d771ff3776", "title": "Language Models Can See: Plugging Visual Controls in Text Generation"}, {"paperId": "a26a7a74f1e5fd562be95c3611a0680759fbdf84", "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "c57293882b2561e1ba03017902df9fc2f289dea2", "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"}, {"paperId": "5e76879aaea118b532fb24a50b721076d4c6ae93", "title": "Unified Contrastive Learning in Image-Text-Label Space"}, {"paperId": "ada81a4de88a6ce474df2e2446ad11fea480616e", "title": "Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language"}, {"paperId": "838a2297b94f7bad96c4f8370a5f58487f194f44", "title": "Visual Abductive Reasoning"}, {"paperId": "32e89d4d1225f3e02ac38ec93efc39fb61ccdde8", "title": "Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning"}, {"paperId": "97f00be0f3a92ccb4c5f14b6d068a217718fa4a1", "title": "Aligning Source Visual and Target Language Domains for Unpaired Video Captioning"}, {"paperId": "a2502d2cd7144c5e2bc1d0d7ec37d2c84b37d381", "title": "ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic"}, {"paperId": "a7aa150b55d64d339b1c154d6d88455fc3cbc44f", "title": "ClipCap: CLIP Prefix for Image Captioning"}, {"paperId": "1a707ab4c53049f508548f080583c1817c7e2454", "title": "Auto-Encoding Knowledge Graph for Unsupervised Medical Report Generation"}, {"paperId": "50f6dd2aa07074d2904f153a0e489285499436c1", "title": "Unifying Multimodal Transformer for Bi-directional Image and Text Generation"}, {"paperId": "5e00596fa946670d894b1bdaeff5a98e3867ef13", "title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision"}, {"paperId": "76e64bb7cd283d448740dc1dafb9be69cc34765b", "title": "End-to-End Dense Video Captioning with Parallel Decoding"}, {"paperId": "b82c5f9efdb2ae56baa084ca41aeddd8a665c1d1", "title": "Align before Fuse: Vision and Language Representation Learning with Momentum Distillation"}, {"paperId": "8f167ec1149921fac63b1ea855443de109bb013a", "title": "How Much Can CLIP Benefit Vision-and-Language Tasks?"}, {"paperId": "afa76fedf8701e057b2bf7a228bf41980ac2d1c9", "title": "RSTNet: Captioning with Adaptive Attention on Visual and Non-Visual Words"}, {"paperId": "cf9b8da26d9b92e75ba49616ed2a1033f59fce14", "title": "Open-vocabulary Object Detection via Vision and Language Knowledge Distillation"}, {"paperId": "38b0567e83386ddc294d6c81b541deacbd8e3c2a", "title": "CLIPScore: A Reference-free Evaluation Metric for Image Captioning"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "394be105b87e9bfe72c20efe6338de10604e1a11", "title": "Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "cba8f7e9c9d153189e61f0e39bb56d52da5e0956", "title": "Improving Video Captioning with Temporal Composition of a Visual-Syntactic Embedding*"}, {"paperId": "bf2f223b2f4c425275f6b31f9e0111af32b41882", "title": "Cross-Domain Image Captioning via Cross-Modal Retrieval and Model Adaptation"}, {"paperId": "8cda672bd5487ec2c67d5c217dc84ed8fb786640", "title": "ActBERT: Learning Global-Local Video-Text Representations"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "70557ea6b65846fc30729ceed224acd4ac64ca5d", "title": "MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "68a154d4fb82fde011037021b1ae280e30857040", "title": "Delving Deeper into the Decoder for Video Captioning"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be", "title": "Towards Unsupervised Image Captioning With Shared Multimodal Embeddings"}, {"paperId": "094159beb3a83f506b532b287c03c2215018f63a", "title": "Large-Scale Datasets for Going Deeper in Image Understanding"}, {"paperId": "28b74bb7c8b08cceb2430ec2d54dfa0f3225d796", "title": "VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research"}, {"paperId": "580fd9a601314ea32dc85ec98267b411dd3465cf", "title": "Unsupervised Image Captioning"}, {"paperId": "b4df354db88a70183a64dbc9e56cf14e7669a6c0", "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"}, {"paperId": "d64f52b94977b71976327eeb3db702b246ee39ce", "title": "Decoupled Novel Object Captioner"}, {"paperId": "afc2850945a871e72c245818f9bc141bd659b453", "title": "Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8", "title": "Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering"}, {"paperId": "96dd1fc39a368d23291816d57763bc6eb4f7b8d6", "title": "Dense-Captioning Events in Videos"}, {"paperId": "2dfeb5a90abc49ab2a80a492a01a4e2c8e92ec22", "title": "In-datacenter performance analysis of a tensor processing unit"}, {"paperId": "9f4d7d622d1f7319cc511bfef661cd973e881a4c", "title": "Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning"}, {"paperId": "086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c", "title": "Guided Open Vocabulary Image Captioning with Constrained Beam Search"}, {"paperId": "6c8353697cdbb98dfba4f493875778c4286d3e3a", "title": "Self-Critical Sequence Training for Image Captioning"}, {"paperId": "f90d9c5615f4a0e3f9a1ce2a0075269b9bab6b5f", "title": "SPICE: Semantic Propositional Image Caption Evaluation"}, {"paperId": "18f1143c64e6557c933b206fb8b2a7bd1f389afd", "title": "Rich Image Captioning in the Wild"}, {"paperId": "b8e2e9f3ba008e28257195ec69a00e07f260131d", "title": "MSR-VTT: A Large Video Description Dataset for Bridging Video and Language"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "0a28efacb92d16e6e0dd4d87b5aca91b28be8853", "title": "ActivityNet: A large-scale video benchmark for human activity understanding"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "696ca58d93f6404fea0fc75c62d1d7b378f47628", "title": "Microsoft COCO Captions: Data Collection and Evaluation Server"}, {"paperId": "258986132bf17755fe8263e42429fe73218c1534", "title": "CIDEr: Consensus-based image description evaluation"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "8b55402ffee2734bfc7d5d7595500916e1ef04e8", "title": "nocaps: novel object captioning at scale"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "1c46943103bd7b7a2c7be86859995a4144d1938b", "title": "Visualizing Data using t-SNE"}, {"paperId": "4774432f02ef4c5285952dd8c7daff0852c3a601", "title": "Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization"}]}