{"paperId": "b07112533752dd3cbb2a4613e0f7c2a967af5b9f", "abstract": "The tremendous success of Stack Overflow has accumulated an extensive corpus of software engineering knowledge, thus motivating researchers to propose various solutions for analyzing its content. The performance of such solutions hinges significantly on the selection of representation models for Stack Overflow posts. As the volume of literature on Stack Overflow continues to burgeon, it highlights the need for a powerful Stack Overflow post representation model and drives researchers\u2019 interest in developing specialized representation models that can adeptly capture the intricacies of Stack Overflow posts. The state-of-the-art (SOTA) Stack Overflow post representation models are Post2Vec and BERTOverflow, which are built upon neural networks such as convolutional neural network and transformer architecture (e.g., BERT). Despite their promising results, these representation methods have not been evaluated in the same experimental setting. To fill the research gap, we first empirically compare the performance of the representation models designed specifically for Stack Overflow posts (Post2Vec and BERTOverflow) in a wide range of related tasks (i.e., tag recommendation, relatedness prediction, and API recommendation). The results show that Post2Vec cannot further improve the SOTA techniques of the considered downstream tasks, and BERTOverflow shows surprisingly poor performance. To find more suitable representation models for the posts, we further explore a diverse set of transformer-based models, including (1) general domain language models (RoBERTa, Longformer, and GPT2) and (2) language models built with software engineering related textual artifacts (CodeBERT, GraphCodeBERT, seBERT, CodeT5, PLBart, and CodeGen). This exploration shows that models like CodeBERT and RoBERTa are suitable for representing Stack Overflow posts. However, it also illustrates the \u201cNo Silver Bullet\u201d concept, as none of the models consistently wins against all the others. Inspired by the findings, we propose SOBERT, which employs a simple yet effective strategy to improve the representation models of Stack Overflow posts by continuing the pre-training phase with the textual artifact from Stack Overflow. The overall experimental results demonstrate that SOBERT can consistently outperform the considered models and increase the SOTA performance significantly for all the downstream tasks.", "venue": "ACM Transactions on Software Engineering and Methodology", "year": 2023, "citationCount": 12, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3635711", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "Inspired by the findings, SOBERT is proposed, which employs a simple yet effective strategy to improve the representation models of Stack Overflow posts by continuing the pre-training phase with the textual artifact from Stack Overflow."}, "embedding": {"model": "specter_v2", "vector": [-0.07269684225320816, 0.6270516514778137, -0.3471168875694275, 0.24019746482372284, -0.19594717025756836, -0.6905890703201294, 0.4654425084590912, 0.05541219562292099, 0.40387338399887085, -0.2642762064933777, 1.0409470796585083, -0.6863133907318115, 0.4613649845123291, -0.05280616506934166, -0.21360374987125397, 0.18467146158218384, -0.27613911032676697, 0.08692656457424164, -0.04865230619907379, -0.2731720507144928, 0.6986835598945618, -0.7950968742370605, -1.1562366485595703, 0.6026230454444885, 0.44957682490348816, 0.5919209122657776, -0.058046258985996246, 0.5458393096923828, -1.1863317489624023, 0.9254255294799805, 0.414662629365921, -0.741535484790802, 0.3174581527709961, 0.24764376878738403, -0.3093397617340088, 0.036692067980766296, 0.6725503206253052, -0.3221515715122223, -0.2813216745853424, 1.106888771057129, -0.2372829169034958, -0.04310062155127525, 0.10639133304357529, -0.5583682656288147, -0.27409517765045166, 1.1399682760238647, 0.7515588998794556, 0.6613898873329163, -0.2590867280960083, -0.5452518463134766, 1.4857001304626465, -1.209501028060913, 0.27950340509414673, 0.9067897796630859, 0.5977172255516052, 0.014281533658504486, -0.029347453266382217, -0.6712477803230286, 0.5539643168449402, -0.2612464427947998, -0.6489944458007812, -0.1822204738855362, 0.02211143635213375, -1.0279126167297363, 1.5714287757873535, -0.46678170561790466, -0.35539913177490234, 0.11234313249588013, -0.215165913105011, 1.2351405620574951, -0.10334649682044983, -0.46213993430137634, 0.01654239185154438, 0.006641356740146875, 0.6467626094818115, 1.0061548948287964, 0.12741754949092865, 0.15844358503818512, -0.3287545442581177, -0.4913536608219147, 0.2984524965286255, 0.4437553286552429, -0.12072047591209412, -0.11315762996673584, 0.2677500247955322, 0.19039392471313477, -0.0496562160551548, 0.9934012293815613, -0.3357715308666229, 0.9069404602050781, 0.6810623407363892, 0.45991289615631104, -0.10469246655702591, 0.8943648338317871, -0.5082927346229553, 0.4723460376262665, -0.7940710186958313, 0.2615211308002472, 0.1686394065618515, 0.7586778998374939, 0.004203916061669588, 0.27112066745758057, -1.0844892263412476, -0.1394805908203125, 1.3320659399032593, -0.7737153768539429, 0.653837263584137, -0.9124384522438049, 0.335191935300827, 0.29816699028015137, 0.416157066822052, -0.5064709782600403, 0.49475350975990295, -0.40049681067466736, 0.06714097410440445, -1.0025484561920166, -0.3115454316139221, 0.2599402368068695, -0.6609653830528259, 0.354780375957489, -1.0752536058425903, 0.46302568912506104, 0.1956396847963333, 0.15428662300109863, 0.5844992995262146, 0.20936432480812073, -0.05712917819619179, 0.22087298333644867, 0.48448446393013, -1.0128549337387085, -0.6500065922737122, -1.3655681610107422, 1.077968716621399, -0.5330596566200256, -0.29211416840553284, -0.3560984432697296, -1.332110047340393, -0.5745530724525452, -0.7936868667602539, 0.4847528040409088, -0.4965949058532715, -0.04896548017859459, 0.8220260143280029, 0.5404374003410339, -0.9411798715591431, 1.0564374923706055, -0.12451350688934326, -0.1725432127714157, 0.1948828250169754, -0.27707648277282715, 0.6637175679206848, -0.34036698937416077, -0.7889738082885742, 0.1621343046426773, 0.07536442577838898, -0.8781254291534424, -0.18001781404018402, -0.634465754032135, -1.274082899093628, 0.20907925069332123, 0.5450726747512817, -0.07031741738319397, 1.474030613899231, -0.12500417232513428, -0.7713432312011719, 0.47338923811912537, -0.14143560826778412, 0.4141630232334137, 0.0731581449508667, -0.0433955080807209, -0.3543436527252197, -0.9582360982894897, 0.1508675068616867, -0.8606618046760559, 0.13604941964149475, -0.4531289041042328, 0.2023913562297821, 0.29530468583106995, -0.16479451954364777, -0.6216632723808289, -0.31154322624206543, 1.103592872619629, -0.30358970165252686, 0.23526592552661896, 0.4881080985069275, 1.3198838233947754, -0.2572779655456543, -0.0029059769585728645, -0.137076273560524, -0.6158145070075989, 0.3168468773365021, -0.3136627674102783, 1.6742594242095947, -0.8507080674171448, -0.8886538743972778, -0.3452759385108948, -0.2691327631473541, 0.14769922196865082, -0.5759872198104858, 0.774479866027832, -0.674340546131134, 1.092087984085083, -0.07015630602836609, -0.8281195759773254, 0.12833206355571747, -0.4246147871017456, -0.913738489151001, -0.2699114978313446, 0.01079014502465725, 0.8009980320930481, -0.966942310333252, 0.3921470642089844, -0.16124333441257477, 0.06434164941310883, -0.9136673212051392, 1.1973692178726196, -0.3217502534389496, -0.4054257273674011, -0.4558762013912201, 0.29575905203819275, 0.5452176928520203, -0.607891321182251, 0.6550527215003967, -0.21138963103294373, -0.6939211487770081, 0.7818151712417603, -0.49190753698349, 1.0605731010437012, -0.06616535782814026, 0.042735353112220764, 0.15363888442516327, -0.5571821928024292, 0.6890618801116943, 0.7970351576805115, -0.11271017789840698, -0.3640536069869995, 0.25800779461860657, 0.7020965814590454, -0.8678838014602661, -0.04853156954050064, 0.796471118927002, 0.6748678088188171, -0.44189387559890747, 0.34902840852737427, 0.3392844498157501, 0.024159220978617668, 0.5403316617012024, 0.01494817528873682, 1.3686203956604004, 0.3337000608444214, 0.37268736958503723, 0.044029559940099716, 0.5404841899871826, -0.8350021243095398, 0.45821595191955566, 0.22326423227787018, 0.40712466835975647, 1.2011995315551758, 0.9550355076789856, -0.6848764419555664, -0.26851004362106323, 0.2835277020931244, 0.959761381149292, 1.2158291339874268, 0.0225495807826519, -0.5608862638473511, -0.37983405590057373, -0.7697538137435913, 0.10335157066583633, 0.4701038897037506, -0.0673629567027092, -0.35004186630249023, -0.5178660750389099, -0.8238822817802429, 0.4749802350997925, 0.28509023785591125, 0.42229098081588745, -0.5655579566955566, 0.12819133698940277, -0.013259387575089931, 0.11895839869976044, -0.6962159276008606, -0.5263410806655884, 0.2365395724773407, -0.4064541757106781, -0.30301886796951294, 0.1414385885000229, -0.3494204878807068, 0.5244094729423523, -0.7434042692184448, 1.2176485061645508, 0.24079644680023193, -0.15856066346168518, 0.07703655958175659, 0.24832065403461456, -0.31678393483161926, -0.6899853944778442, -0.17397421598434448, -0.3639011085033417, -0.5862166285514832, 0.8952637910842896, 0.5759305357933044, 0.15748512744903564, 0.14630180597305298, -0.5207860469818115, -0.29482510685920715, 0.09195594489574432, -0.00802088063210249, 0.2185623049736023, -0.0056770876981318, -0.26341402530670166, -0.6312236785888672, 0.9747099876403809, -0.3090042173862457, -0.8942674994468689, 0.35336562991142273, -0.9142566323280334, -0.31742191314697266, 0.5964214205741882, 0.03416657820343971, -0.13177485764026642, -1.420047402381897, 0.7150747776031494, -0.14911940693855286, 0.01081849541515112, 0.7701813578605652, 0.6361462473869324, 0.3444410264492035, -0.03696437552571297, 0.15465793013572693, 0.3070257604122162, -0.512998104095459, -0.08901818096637726, -0.6687143445014954, 0.10685712844133377, 0.13936486840248108, 0.16062568128108978, -0.444765567779541, -0.47063466906547546, 0.1011078879237175, -0.6114345192909241, -0.32024890184402466, 0.33422282338142395, -0.060530707240104675, -0.2624342143535614, -0.5336223244667053, -0.3583050072193146, -0.4004005491733551, -1.1292425394058228, 0.015603055246174335, 0.1262718290090561, -0.7809906005859375, -0.00968860648572445, -0.8167855739593506, -0.8514014482498169, -0.9591228365898132, -0.3696829676628113, -1.281501054763794, 0.3642609119415283, -0.3169691264629364, -0.40320920944213867, -0.2949249744415283, 0.1626904010772705, -0.3873588740825653, 0.7776120901107788, -0.4648968577384949, 0.9424732327461243, -0.2752254009246826, -0.39366447925567627, -0.38589784502983093, -0.009576388634741306, 0.7758606672286987, -0.12249207496643066, 0.5062082409858704, -0.04257681220769882, 0.3899213373661041, -0.1365985870361328, 0.0881141871213913, -0.13855351507663727, 0.023725362494587898, 0.9295512437820435, 0.14954873919487, -0.42697909474372864, 0.019988948479294777, 1.600438117980957, -0.8247767686843872, 0.30459219217300415, 0.5762739181518555, 0.561532199382782, 0.6659263372421265, -0.26648634672164917, 0.7269240021705627, 0.07230253517627716, -0.03777235373854637, 0.5204710960388184, 0.439433753490448, -0.06199011951684952, -0.5027801990509033, 0.9176589846611023, 1.5567772388458252, 0.35454919934272766, 0.08241630345582962, -1.3764758110046387, 0.9699588418006897, -1.5002474784851074, -0.22762331366539001, 0.16150015592575073, 0.8626417517662048, 0.3577731251716614, -0.47671735286712646, -0.9504613876342773, -0.06164516136050224, 1.0087943077087402, 0.10775221139192581, 0.07400518655776978, -0.7799801826477051, 0.5868917107582092, 0.3898998200893402, 0.5813137888908386, 0.41042062640190125, -0.12088626623153687, 0.41238242387771606, 14.722245216369629, -0.005882309749722481, 0.13818274438381195, 0.15514884889125824, 0.20732389390468597, 0.6726996898651123, -0.5403468012809753, 0.09408150613307953, -1.3205708265304565, 0.09149497002363205, 0.9411965012550354, -0.2840348780155182, 0.13325725495815277, 0.31648918986320496, -0.3331652581691742, 0.5329049825668335, -0.38504135608673096, 0.34117910265922546, 0.48208561539649963, -1.3738453388214111, 0.2791074514389038, 0.25835686922073364, 0.6274438500404358, 0.43963193893432617, 0.9276116490364075, 0.8467591404914856, 0.7196260094642639, -0.5538974404335022, 0.44100090861320496, 0.002288008341565728, 0.561490535736084, 0.2659842371940613, 1.2977739572525024, 0.3251916468143463, -0.6157909035682678, -0.5951715707778931, -0.8629090189933777, -1.5582424402236938, 0.35025307536125183, 0.27297091484069824, -0.7063404321670532, -0.42897599935531616, -0.3131997883319855, 0.7509181499481201, 0.3862673044204712, 0.6425703763961792, -0.44599875807762146, 0.4028593897819519, 0.279930979013443, 0.31193339824676514, 0.17461563646793365, 0.47115620970726013, 0.13119199872016907, -0.2800352871417999, 0.7285540103912354, -0.3663460314273834, 0.5274789333343506, 0.5641506910324097, -0.6879276037216187, 0.0346253477036953, -0.5233856439590454, -0.9599607586860657, -0.09340863674879074, 0.5073969960212708, 0.5271928310394287, -0.19360262155532837, -0.7794435620307922, 0.041698478162288666, 0.3269890248775482, 0.2918911278247833, 0.015994708985090256, -0.1815933883190155, 0.9645373225212097, 0.39330294728279114, 0.23272015154361725, 0.7488035559654236, -0.4016587436199188, -0.7230640649795532, -0.7029175758361816, -0.11690765619277954, 0.1683596968650818, -0.583544135093689, -0.9682902097702026, 0.7448030114173889, -0.8715482354164124, -0.8793180584907532, -0.044785141944885254, -0.9810401201248169, -0.3119824528694153, 0.18939843773841858, -1.8107726573944092, -0.005206947680562735, -0.13662269711494446, -0.6225581765174866, -0.7784703969955444, -0.43364080786705017, 1.2040083408355713, 0.40007925033569336, -0.5861420631408691, -0.4063882529735565, 0.1717785745859146, 0.012274778448045254, 0.21869313716888428, -1.2695326805114746, 0.8819355964660645, 0.11797811090946198, -0.8319941759109497, 0.3921302855014801, 0.3697609305381775, -0.32078927755355835, -0.44620048999786377, -0.6308481693267822, 0.9494602680206299, -1.0394699573516846, 0.05958850681781769, -0.2856801152229309, -0.9136922359466553, 0.5336631536483765, 0.4248282015323639, -0.0363566055893898, 0.347896933555603, 0.13596026599407196, -0.8378772139549255, 0.2765975892543793, -0.9504789710044861, 0.15648572146892548, 0.5897154808044434, -0.6601591110229492, -0.6657555103302002, 0.0807369202375412, 0.4040141999721527, -0.5453903675079346, -0.5868890881538391, 0.1210249587893486, -0.2869492173194885, -0.5283936262130737, 0.6649172902107239, -0.5442231297492981, 1.368359923362732, 0.5617080926895142, -0.4679187536239624, -0.4403427839279175, -0.45531946420669556, -1.2630120515823364, 0.029182521626353264, 0.14730428159236908, 0.7659325003623962, -0.3455447852611542, 0.7206659913063049, 1.3652257919311523, -0.03302837163209915, 0.14830632507801056, 0.11435116827487946, -0.4731597900390625, 0.4395415782928467, -0.29169952869415283, 0.7597364783287048, 0.1210089847445488, 0.1343606412410736, -0.598834216594696, 0.8215982913970947, 0.4689309597015381, -0.15792155265808105, -0.43521422147750854, 0.3213343322277069, -0.42489302158355713, 0.10610858350992203, -0.744554877281189, -0.35799771547317505, -1.1171042919158936, 0.3894301950931549, -1.4039223194122314, 0.12297961860895157, -1.0243000984191895, -0.5132777690887451, 0.7534353137016296, -0.8559959530830383, 0.004241004586219788, 0.5267509818077087, -0.6608573198318481, -0.7727882862091064, -0.7028137445449829, -0.5980411171913147, 0.6224514842033386, 0.6453285217285156, -0.48416900634765625, 0.18918168544769287, -0.330983430147171, -0.4891132116317749, 0.43222859501838684, 0.2706266939640045, -0.44452205300331116, -0.1891108900308609, -1.27553129196167, 0.4125436842441559, -0.1586374044418335, -0.4597131311893463, -0.07132411003112793, 0.637528657913208, 0.5878763794898987, -0.6625706553459167, 0.33542174100875854, -0.3306523859500885, -0.9346421957015991, -0.5941310524940491, 0.2922824025154114, -0.5349739193916321, 0.204588383436203, 0.08596418797969818, -0.7653639316558838, -0.7085189819335938, -0.09127978980541229, -0.4573518633842468, -1.2046446800231934, -0.7226166725158691, 0.26491278409957886, -0.8184464573860168, -0.25379490852355957, -0.15610261261463165, -0.05838385596871376, -1.0493710041046143, -0.1232842206954956, 0.19643329083919525, 0.33904948830604553, 0.1474461853504181, 1.0801854133605957, 0.16053611040115356, -1.1682993173599243, 0.05634767562150955, 0.38069358468055725, 0.2644556164741516, -0.45316579937934875, -0.33120739459991455, 0.036071259528398514, -0.5219972133636475, 0.17453134059906006, 0.32842352986335754, 0.6442956924438477, -0.7297337055206299, -0.06062640994787216, 0.2690366208553314, -0.4387523829936981, -0.09006655961275101, 0.8788174390792847, -0.23254945874214172, -1.2441999912261963, 0.12098824232816696, -1.2576746940612793, -0.5093031525611877, -0.36280909180641174, 0.850023090839386, 0.42492741346359253, 0.08565964549779892, 0.03650019317865372, -0.2224372923374176, 0.13932979106903076, -0.16968680918216705, 0.039937082678079605, 0.684870719909668, 0.09388349205255508, -1.040879249572754, 0.47482192516326904, 0.8428944945335388, -0.6217002868652344, -0.24887055158615112, -0.4866294860839844, 0.33933141827583313, -0.6108799576759338, 0.6109783053398132, -0.2700175642967224, -0.8260523080825806, 0.5634739995002747, 0.13032729923725128, 0.3542967736721039, -0.23317411541938782, -0.32999059557914734, 0.10337726771831512, 0.3560967743396759, 0.18347562849521637, -0.4696437418460846, -0.3953770399093628, 1.3934625387191772, 1.0655065774917603, -0.7695125341415405, 0.1741223782300949, -0.27288949489593506, -0.3719775378704071, 1.1499512195587158, 0.5202993154525757, -0.24306590855121613, 0.762053370475769, 0.11043723672628403, 0.09798537194728851, 0.025020167231559753, -1.033462643623352, -0.20601435005664825, 0.05522756278514862, 0.5115442872047424, 1.3102120161056519, -0.041905563324689865, 0.040079712867736816, 1.180714726448059, 0.2328760027885437, 0.38693079352378845, 1.2314951419830322, 0.841966986656189, -0.2728812098503113, -0.45961302518844604, -0.1685829758644104, 0.6981840133666992, -1.1316181421279907, -0.7080267667770386, -0.1464630514383316, -0.08164023607969284, 0.09689018875360489, 0.3131251335144043, 0.7629929780960083, -0.1265522539615631, 0.7397595643997192, 0.8378346562385559, -0.2294968068599701, -0.8809230327606201, -0.771889865398407, -0.19372916221618652, -0.26676708459854126, -0.3069562017917633, 0.19202959537506104, -0.8225909471511841, -0.4658677577972412, -0.19795335829257965, 0.2376912236213684, 0.20743657648563385, 0.37081849575042725, 0.6574106216430664, 0.6886150240898132, 0.8085734248161316, -0.5587209463119507, -0.02381356991827488, -0.6183507442474365, -0.4834221303462982, -0.31977295875549316, -0.3517914414405823, -0.03176388889551163, -0.2064146101474762, -0.694007933139801, -0.5035141110420227]}, "authors": [{"authorId": "2158107537", "name": "Junda He"}, {"authorId": "2211431558", "name": "Zhou Xin"}, {"authorId": "2203459", "name": "Bowen Xu"}, {"authorId": "2146322053", "name": "Ting Zhang"}, {"authorId": "35276441", "name": "Kisub Kim"}, {"authorId": "2139059234", "name": "Zhou Yang"}, {"authorId": "2121315", "name": "Ferdian Thung"}, {"authorId": "9223952", "name": "I. Irsan"}, {"authorId": "2150912791", "name": "David Lo"}], "references": [{"paperId": "dbd5628305135ea148243985165f8f189aefc170", "title": "Post2Vec: Learning Distributed Representations of Stack Overflow Posts"}, {"paperId": "ed5702c457d9f6cadfb07e16f7f8094ce45d095e", "title": "CLEAR: Contrastive Learning for API Recommendation"}, {"paperId": "38115e80d805fb0fb8f090dc88ced4b24be07878", "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis"}, {"paperId": "3c876033cf83c9b40156aa8f8ff7f044abf188d9", "title": "PTM4Tag: Sharpening Tag Recommendation of Stack Overflow Posts with Pre-trained Models"}, {"paperId": "6c05127d198de1f11d5af696b9f207fff2d8e41a", "title": "Aspect-Based API Review Classification: How Far Can Pre-Trained Transformer Model Go?"}, {"paperId": "c7cbbbdba2c942180675c2a69035e506d9378679", "title": "Using Pre-Trained Models to Boost Code Review Automation"}, {"paperId": "13d710314ea8bdeafdbb91bf4d3cb2839484a1c3", "title": "Using Deep Learning to Generate Complete Log Statements"}, {"paperId": "11907f691e9b7fc32a492e1de676a4b788add155", "title": "On the Validity of Pre-Trained Transformers for Natural Language Processing in the Software Engineering Domain"}, {"paperId": "a30f912f8c5e2a2bfb06351d4578e1ba3fa37896", "title": "CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation"}, {"paperId": "009ff661c78438e9430604b6ae3b86f392d4ad81", "title": "An Empirical Study on the Usage of Transformer Models for Code Completion"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "04887ace250540da57c73fb759ee5edbadf74301", "title": "Attention-based model for predicting question relatedness on Stack Overflow"}, {"paperId": "0646bb09db4d1ba24150e69b71edcd4aff691b3c", "title": "Unified Pre-training for Program Understanding and Generation"}, {"paperId": "69a72ff5b30642d11c96635e99aadad3140d33a7", "title": "CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation"}, {"paperId": "2aef78b2ba39bb2268966d336eee80d425e78ff4", "title": "Traceability Transformed: Generating More Accurate Links with Pre-Trained BERT Models"}, {"paperId": "c2c7233293d55f201fe5b496234bed1914eea70e", "title": "Studying the Usage of Text-To-Text Transfer Transformer to Support Code-Related Tasks"}, {"paperId": "b632564a92885a9a1acbba027239b819d0858df1", "title": "TagDC: A tag recommendation method for software information sites with a combination of deep learning and collaborative filtering"}, {"paperId": "435f5037346e3e7b5af93e25bcbd271ecfdccfc0", "title": "PostFinder: Mining Stack Overflow posts to support software developers"}, {"paperId": "4083958684292f6fa2f5c7fd4f9be975e80145b6", "title": "GraphCodeBERT: Pre-training Code Representations with Data Flow"}, {"paperId": "b252328704c5a7d9cebd8e29b0210f3bc2f214a2", "title": "Sentiment Analysis for Software Engineering: How Far Can Pre-trained Transformer Models Go?"}, {"paperId": "021bbcefc993c389bad6c1daefd8ff92d0fc2441", "title": "Contrastive Code Representation Learning"}, {"paperId": "3a2b241ef190d433e24ea2e643de2a9e8336863f", "title": "Code and Named Entity Recognition in StackOverflow"}, {"paperId": "e816f788767eec6a8ef0ea9eddd0e902435d4271", "title": "Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "0fe2636446cd686830da3d971b31a004d6094b3c", "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages"}, {"paperId": "592843debcee8160a2473be2f57a56c6c30666da", "title": "Discovering, Explaining and Summarizing Controversial Discussions in Community Q&A Sites"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "fbe25e4f069a19dc63daca27b7c98cff338663b9", "title": "CodeSearchNet Challenge: Evaluating the State of Semantic Code Search"}, {"paperId": "2f9d4887d0022400fc40c774c4c78350c3bc5390", "title": "Small and Practical BERT Models for Sequence Labeling"}, {"paperId": "b2c2eae45a365e6e3beb6dc97da2105729e28e16", "title": "BIKER: a tool for Bi-information source based API method recommendation"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "8495c1722e1f5107733c842839c2d298b9116921", "title": "BERT with History Answer Embedding for Conversational Question Answering"}, {"paperId": "3f6f7a738b73b2c58b3117ca350ce99172d3a402", "title": "Question Relatedness on Stack Overflow: The Task, Dataset, and Corpus-inspired Models"}, {"paperId": "8c84c26e9af9d679ef470d423c5e10d81545c2b3", "title": "Is deep learning better than traditional approaches in tag recommendation for software information sites?"}, {"paperId": "0de47f354468283efc7765ec0b3588b2ae483c77", "title": "Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence"}, {"paperId": "516497e7fc39ebb126bed28dcc5c6129e500acb8", "title": "An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation"}, {"paperId": "2d7cd527303f8f515cd282be0243c38e24d2e11d", "title": "Prediction of relatedness in stack overflow: deep learning vs. SVM: a reproducibility study"}, {"paperId": "3627975313cd18f479e263cb40f33d5ff9e80da6", "title": "API Method Recommendation without Worrying about the Task-API Knowledge Gap"}, {"paperId": "6071c5ce80b11ffa45a65dc8023aa5438ef5c4c7", "title": "Automatically Classifying Posts Into Question Categories on Stack Overflow"}, {"paperId": "727e60430527dc10c806177373e2dda9bf8d72b9", "title": "Classifying stack overflow posts on API issues"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "6c6170ffb39cdc8cfffbeda9c7a2259eda5875f2", "title": "Tree-to-tree Neural Networks for Program Translation"}, {"paperId": "8c604cdea0411c77d1c9edef944045bba8b77024", "title": "AnswerBot: Automated generation of answer summary to developers' technical questions"}, {"paperId": "29d2ec9b25e5a0844d156a0e7bc19df24a2c3a48", "title": "Supervised Deep Features for Software Functional Clone Detection by Exploiting Lexical and Syntactical Information in Source Code"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "294be1a0a18aa158fb99836c68b8cd0b25dbc562", "title": "What do developers search for on the web?"}, {"paperId": "e4a323a3a1ca5ff4cc2dd74ede65f48fd62b897b", "title": "Deep API learning"}, {"paperId": "f0f95dcdda7d33b2db70e86aaae87467697147f1", "title": "Improving Low Quality Stack Overflow Post Detection"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "e23c34414e66118ecd9b08cf0cd4d016f59b0b85", "title": "Bidirectional recurrent neural networks"}, {"paperId": null, "title": "Transactions on Software Engineering and Methodology,"}, {"paperId": "8ea6733cfb4a19b7f632afc41c4eb94979e6678a", "title": "Representation Learning"}, {"paperId": null, "title": "ELECTRA: Pre-training Text En-coders as Discriminators Rather Than Generators"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": "7899ad5265e6b9a0fbada8a388b57127f754779a", "title": "Ordinal methods for behavioral data analysis"}, {"paperId": null, "title": "Continued pre-training based on Stack Overflow textual artifact develops a consistently better representation model"}, {"paperId": null, "title": "Received 8 March 2023; revised 20 September 2023; accepted 30 October 2023"}, {"paperId": null, "title": "24 He et al."}, {"paperId": null, "title": "for Stack Overflow Posts"}, {"paperId": null, "title": "we summarize the contributions of our empirical study"}, {"paperId": null, "title": "We derive several insightful lessons from the experimental results to the software engineering community"}, {"paperId": null, "title": "Existing Stack Over\ufb02ow post representation techniques fail to improve the SOTA performance of considered tasks"}, {"paperId": null, "title": "We comprehensively evaluate the effectiveness of seven representation models for Stack Over-flow posts in three downstream tasks"}, {"paperId": null, "title": "We propose SOBERT by pre-training based on posts from Stack Over\ufb02ow and show that SOBERT consistently outperforms other representation models in multiple downstream tasks"}, {"paperId": null, "title": "all the considered"}]}