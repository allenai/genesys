{"paperId": "da18398274bec87d3568acfd6aba6977be7ba6b8", "abstract": "The success of deep learning algorithms generally depends on large-scale data, while humans appear to have inherent ability of knowledge transfer, by recognizing and applying relevant knowledge from previous learning experiences when encountering and solving unseen tasks. Such an ability to acquire and reuse knowledge is known as transferability in deep learning. It has formed the long-term quest towards making deep learning as data-efficient as human learning, and has been motivating fruitful design of more powerful deep learning algorithms. We present this survey to connect different isolated areas in deep learning with their relation to transferability, and to provide a unified and complete view to investigating transferability through the whole lifecycle of deep learning. The survey elaborates the fundamental goals and challenges in parallel with the core principles and methods, covering recent cornerstones in deep architectures, pre-training, task adaptation and domain adaptation. This highlights unanswered questions on the appropriate objectives for learning transferable knowledge and for adapting the knowledge to new tasks and domains, avoiding catastrophic forgetting and negative transfer. Finally, we implement a benchmark and an open-source library, enabling a fair evaluation of deep learning methods in terms of transferability.", "venue": "arXiv.org", "year": 2022, "citationCount": 78, "influentialCitationCount": 5, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This survey connects different isolated areas in deep learning with their relation to transferability, and provides a unified and complete view to investigating transferability through the whole lifecycle of deep learning."}, "embedding": {"model": "specter_v2", "vector": [0.19011783599853516, 0.4104687571525574, 0.027080275118350983, -0.16107487678527832, 0.021409757435321808, -0.04086960107088089, 0.7793446779251099, -0.33473604917526245, -0.7787021398544312, 0.3867371678352356, -0.12302150577306747, 0.382548063993454, 0.34698712825775146, -0.03233666345477104, -0.6219322681427002, 0.21887150406837463, -0.7777428030967712, 0.2982097268104553, 0.6472075581550598, -0.6191415190696716, -0.39941295981407166, -0.20819003880023956, -1.1488525867462158, 0.13760031759738922, -0.006607742514461279, 0.9310311675071716, 0.25845012068748474, 0.7919848561286926, -0.29585716128349304, 0.397451251745224, 0.3898262679576874, -0.5652272701263428, 0.5415352582931519, -0.11006217449903488, -0.8801635503768921, -0.3681303560733795, 0.5500344634056091, -0.8610691428184509, -0.5414113402366638, 0.7406489253044128, -0.37757378816604614, 0.41897574067115784, 0.5611388087272644, -0.6758784055709839, -0.3546145558357239, 0.15999636054039001, 1.059032917022705, 0.8289487957954407, -0.42663902044296265, -0.5923477411270142, 0.7519316077232361, -1.3636585474014282, 0.2783268690109253, 1.0837316513061523, 0.7938565015792847, 0.8474734425544739, -0.32096946239471436, -0.76958829164505, 0.3855421245098114, -0.16220982372760773, -0.29359039664268494, -0.06865083426237106, 0.12347821146249771, -0.36592352390289307, 1.8359534740447998, -0.6474453210830688, -0.12057902663946152, 0.7252801060676575, 0.48955175280570984, 1.359209656715393, 0.20454303920269012, -0.7813971638679504, -0.27302443981170654, 0.40351995825767517, 0.19932198524475098, 0.8027632236480713, -0.35607561469078064, 0.3234887719154358, -0.9803159236907959, 0.1899890899658203, 0.810638427734375, 0.12762629985809326, 0.09240338206291199, -0.4088638424873352, -0.35641714930534363, 0.34368544816970825, 0.7718703746795654, 0.5662820935249329, -0.6884180307388306, 0.6235947012901306, 0.5008558034896851, 0.9792385101318359, -0.1251099407672882, 0.4283466041088104, -0.24163736402988434, 0.6048452854156494, -0.4289308190345764, -0.13257654011249542, 0.09894535690546036, 1.0320703983306885, 0.5650200247764587, 0.0018285914557054639, -0.3423443138599396, 0.35692042112350464, 0.6757228970527649, -0.3419979214668274, 0.6826231479644775, -0.4606192708015442, 0.4760410487651825, -0.5743340253829956, 0.05024908483028412, -0.693555474281311, -0.07030723989009857, -0.4250146448612213, -0.829098641872406, -0.6161869764328003, -0.6707056760787964, 0.012920771725475788, -0.5856136679649353, 0.8941270112991333, -0.5864855647087097, 0.0010611569741740823, 0.2828027009963989, 0.7265474796295166, 0.3957763910293579, 0.30470752716064453, 0.5022716522216797, 0.3146386444568634, 0.48365411162376404, -0.5023831725120544, -0.2568817436695099, -1.0555964708328247, 0.18021948635578156, -0.1783597767353058, 0.2714211046695709, -0.3701045513153076, -1.3753844499588013, -1.2753697633743286, -1.1547147035598755, -0.02613961324095726, -0.8566191792488098, -0.1671586036682129, 1.2690355777740479, -0.10211098194122314, -0.880652904510498, 1.3236180543899536, -0.11556509137153625, -0.4078279435634613, 0.5346654653549194, 0.7746171355247498, -0.11351218074560165, -0.3037095367908478, -1.257177472114563, 0.48565372824668884, 0.7757871747016907, -0.869070827960968, -0.6471391916275024, -0.6426079273223877, -0.4714548885822296, -0.24484485387802124, 0.024049721658229828, -1.2488021850585938, 1.2515631914138794, -1.0393859148025513, -1.1290103197097778, 0.831068217754364, 0.019832877442240715, 0.10187976807355881, 0.7784342169761658, -0.18222101032733917, -0.45207029581069946, -0.47801902890205383, -0.43640050292015076, 0.730214536190033, 0.5648056864738464, -0.30121031403541565, -0.35494136810302734, 0.20947135984897614, -0.30286359786987305, -0.16463494300842285, -0.9663450717926025, 0.20950931310653687, -0.4831092059612274, -0.5325481295585632, 0.4927075505256653, 0.6358247399330139, 0.3325703740119934, -0.14582780003547668, 0.25335484743118286, -0.8933822512626648, 0.68424391746521, 0.06716420501470566, 0.1782827228307724, -1.0767641067504883, -0.41029229760169983, -0.10698998719453812, -0.07832306623458862, -0.19512209296226501, -1.101501703262329, 0.6797105669975281, -0.13306264579296112, 0.030719315633177757, -0.12437525391578674, -0.8479717373847961, -0.1978374421596527, -0.16982577741146088, -0.607903242111206, -0.38519933819770813, 0.34151706099510193, 1.3494620323181152, -1.0849723815917969, 0.6703721284866333, -0.23520855605602264, 0.14911092817783356, -0.7926387786865234, 1.466009259223938, -0.1490294337272644, 0.06032034382224083, -0.02835482731461525, -0.25141698122024536, 0.29916295409202576, -0.3360195755958557, 0.24784843623638153, -0.5188776850700378, 0.5152873992919922, 0.3547884225845337, -0.07162858545780182, 1.8173786401748657, -0.7250319123268127, 0.9649809002876282, -0.19792059063911438, -0.7741683125495911, 0.34058892726898193, 0.528195321559906, -0.19208070635795593, -0.5512747764587402, 0.38962915539741516, 0.3598102331161499, -0.7261949777603149, 0.26203837990760803, 0.9030565023422241, 0.3855896592140198, -0.25735199451446533, 0.12130635976791382, 1.22185480594635, -0.2695465087890625, -0.071406789124012, 0.22255662083625793, 0.5353254675865173, 0.21086324751377106, 0.2021266222000122, -0.10738606005907059, 0.10123497247695923, -0.8586797714233398, -0.3023819327354431, 0.5219060182571411, 0.6337930560112, 0.7949895858764648, -0.03964756429195404, -0.8110598921775818, -0.024624481797218323, -0.4142526686191559, 0.9241823554039001, 1.835695505142212, 0.06359007209539413, 0.5835435390472412, -0.6512358784675598, -0.8787875771522522, -0.10102484375238419, 0.0262505691498518, -0.9474548697471619, -0.7056340575218201, -0.2991044223308563, -0.8889980316162109, 0.43931883573532104, 0.5592229962348938, 1.432745099067688, -0.6158057451248169, -0.36341580748558044, 0.16412431001663208, 0.5046979188919067, -0.4168887734413147, -0.46123436093330383, 0.43599608540534973, -1.1606411933898926, -0.03372034803032875, -0.02445710264146328, -0.3462482988834381, 0.3712523877620697, -0.4695303738117218, 1.220201849937439, -0.35062456130981445, -0.13434283435344696, 0.45007237792015076, 0.9493809342384338, -0.8618965744972229, -0.7351517081260681, 0.3687177002429962, 0.23992934823036194, -0.008357742801308632, 0.2716912031173706, 0.17175786197185516, -0.15250152349472046, 0.7454666495323181, -0.7157139182090759, -0.07755425572395325, 0.3175428807735443, 0.24687284231185913, 0.9178310036659241, -0.4167921245098114, 0.8527381420135498, -1.2318947315216064, 0.9904434680938721, -0.10025715082883835, -0.3733592927455902, 0.3204074501991272, -0.5612634420394897, -0.25654348731040955, 0.4968334436416626, -0.764057993888855, -0.5242781639099121, -0.7567275166511536, 0.3368518650531769, -0.3532732129096985, -0.24661853909492493, 0.1138942688703537, 0.5717058777809143, -0.3800967335700989, 0.5236690640449524, 0.2971580922603607, 0.5274524688720703, -0.1633109748363495, 0.43084558844566345, -0.8769402503967285, 0.6377321481704712, 0.3235858678817749, 0.1292971521615982, -0.08512140810489655, -0.2535085082054138, -0.11184551566839218, -0.6691727638244629, -0.26029840111732483, -0.6224753260612488, -0.3089381754398346, -0.06115438789129257, -0.5234037637710571, -0.49757522344589233, 0.11622420698404312, -0.6714548468589783, -0.6227366924285889, 0.011659245938062668, -0.03620277717709541, -0.2346429079771042, -1.521151065826416, -0.9137480854988098, 0.046174418181180954, -0.29850316047668457, -0.9411332011222839, -0.3325415253639221, 0.26683756709098816, -0.2522614002227783, -1.152290940284729, -0.38439902663230896, -0.6905176043510437, 1.2649585008621216, -0.3890158236026764, 0.8951004147529602, -0.11275956779718399, -0.2005550116300583, -0.197892427444458, -0.03867805004119873, 1.0075128078460693, -0.03756273165345192, -0.48006266355514526, -1.4295657873153687, -0.14551936089992523, -0.30733415484428406, -0.8356034755706787, 0.46934574842453003, -0.11811628937721252, 0.6187145709991455, 0.144318625330925, -0.2524067163467407, 0.4403994083404541, 1.635445475578308, -0.6900023818016052, -0.15181678533554077, 0.5890166759490967, 0.6079282760620117, 0.3084426522254944, -0.4447888135910034, 0.1446302980184555, 0.11781632155179977, 0.08786160498857498, 0.17929083108901978, -0.357472687959671, -0.8029988408088684, -0.7721453905105591, 0.1361100673675537, 1.3242043256759644, -0.06568355858325958, 0.2966795861721039, -1.0236973762512207, 0.5730258822441101, -1.1428331136703491, -0.33651676774024963, 1.206737995147705, 0.9134547114372253, 0.6059258580207825, -0.21948814392089844, -0.665880560874939, -0.5190390348434448, 0.2621607482433319, -0.22742633521556854, -0.6553006172180176, -0.3451470136642456, 0.09713658690452576, 0.37191250920295715, 0.1927127093076706, 0.5683555603027344, -0.23636621236801147, 0.5732466578483582, 14.481280326843262, 0.7644544839859009, -0.25383833050727844, 0.9961983561515808, 0.3413764536380768, 0.35411059856414795, -0.3412727117538452, -0.5374638438224792, -0.8956063389778137, -0.38950029015541077, 0.6773583292961121, 0.11104853451251984, 0.7614893317222595, 0.06955782324075699, -0.6531791090965271, 0.3377685844898224, -1.1529170274734497, 0.6787530779838562, 0.45976153016090393, -1.3753321170806885, 0.6542290449142456, 0.020608535036444664, 0.8502591252326965, 0.7169762253761292, 0.7544601559638977, 1.1846283674240112, 0.28277191519737244, -0.30665427446365356, 0.5589919686317444, 0.5695866942405701, 0.701516330242157, 0.03363851085305214, 0.7301519513130188, 0.5249506235122681, -0.5256913900375366, -0.28895634412765503, -0.726982831954956, -0.9318463206291199, -0.20453420281410217, -0.04854315146803856, -0.8102828860282898, -0.24030709266662598, -0.0436975322663784, 0.949959397315979, -0.12667216360569, 0.09545360505580902, -0.32837164402008057, 0.4446200132369995, -0.05833807587623596, 0.14376983046531677, -0.050350893288850784, 0.576135516166687, 0.08338499069213867, 0.04360806196928024, 0.026864349842071533, -0.2381262332201004, -0.10225838422775269, 0.3588702082633972, -1.0574676990509033, -0.08039013296365738, -0.2829599380493164, 0.3959043323993683, -0.1362047791481018, 0.26509252190589905, 0.694525420665741, 0.32526272535324097, -0.2600654661655426, 0.8265560865402222, 0.8554360270500183, 0.5997494459152222, 0.13165324926376343, -0.31148722767829895, 0.2911664545536041, -0.3842689096927643, -0.13123728334903717, 0.7488506436347961, -0.3298056423664093, -0.43361297249794006, -0.4673464596271515, -0.013862461782991886, 0.5019023418426514, -0.8977189064025879, -1.2325708866119385, 1.1672760248184204, -0.2286709100008011, -0.551155686378479, 0.4095315933227539, -0.8138840794563293, -0.134649395942688, 0.7534272074699402, -1.7244118452072144, -0.5673888921737671, -0.2935521900653839, 0.23805445432662964, -0.46213120222091675, -0.7285585403442383, 1.1228909492492676, 0.19697469472885132, -0.1372421532869339, 0.1951470524072647, -0.10260520875453949, -0.11983844637870789, 0.14344388246536255, -0.6152071952819824, 0.5467397570610046, -0.08258765935897827, -0.3591618239879608, 0.2631477415561676, -0.49446016550064087, 0.31294506788253784, -0.4758642017841339, -0.5398045778274536, 0.39701375365257263, -0.8555065393447876, -0.38158008456230164, -0.5548590421676636, -1.296892523765564, 0.611499011516571, 0.6668446660041809, -0.3888711631298065, 0.3344205617904663, 0.25415095686912537, -0.704641580581665, -0.4034018814563751, -0.9941640496253967, 0.02108629234135151, 0.4184575080871582, -0.6643794178962708, -0.9154558181762695, -0.14865322411060333, 0.11490785330533981, -0.6813144087791443, -0.522736132144928, -0.2764279842376709, -0.016671951860189438, -0.4463198184967041, 1.1417226791381836, -0.7570900917053223, 0.12983360886573792, 0.9631878733634949, -0.16679708659648895, -0.9203826785087585, -0.10264475643634796, -0.633118212223053, 0.5601216554641724, 0.17880189418792725, 0.5687978267669678, -0.9295632839202881, 0.05219673737883568, 0.6883809566497803, 0.20597797632217407, -0.022538091987371445, -0.5413169264793396, -0.4968031644821167, 0.2775707542896271, -0.4294280707836151, 0.47210943698883057, 0.15483425557613373, -0.6757234930992126, -0.028859557583928108, 0.7486123442649841, 0.4814338982105255, -0.11387894302606583, -0.7387639284133911, 0.39444610476493835, -0.5690942406654358, -0.022410742938518524, -0.667025625705719, -0.45351144671440125, -1.5399842262268066, 0.2257014960050583, -1.722985029220581, -0.23122696578502655, -1.1242536306381226, -0.661116361618042, -0.054458945989608765, -0.8342803120613098, 0.1972164809703827, 0.4768991768360138, -0.10869834572076797, -0.13717208802700043, 0.12948331236839294, -0.2844180166721344, 0.6350096464157104, 1.003480076789856, -0.4291037917137146, -0.06584727019071579, -0.14953608810901642, 0.22129499912261963, 0.5283235311508179, 0.7479538321495056, -0.7101076245307922, -1.0374394655227661, -1.6917955875396729, 0.38863709568977356, -0.42331182956695557, 0.1330692619085312, -0.9715692400932312, 0.8162782788276672, 0.3836705684661865, 0.34532657265663147, 0.5192705392837524, 0.6824829578399658, -1.3117573261260986, -0.38784897327423096, 0.33979150652885437, -0.6489318013191223, -0.13378256559371948, 1.050808310508728, -0.17113138735294342, -0.4815559685230255, 0.44807079434394836, -0.021144188940525055, -0.7363945841789246, -1.3347834348678589, 0.4834367632865906, -0.4830215275287628, 0.1702069342136383, 0.10524097830057144, -0.333403080701828, -1.2346082925796509, -0.14150971174240112, -0.4669021964073181, 0.23763681948184967, -0.3446684181690216, 0.9092003107070923, 0.6013760566711426, -1.3925375938415527, 0.02604285068809986, 0.7292783260345459, 0.051455240696668625, -0.30335733294487, 0.5802159905433655, 0.30463916063308716, -0.39757147431373596, 0.1125689372420311, -0.4957433342933655, 0.3083771765232086, -0.2551723122596741, -0.1470434069633484, 1.0603309869766235, 0.01805165968835354, -0.061953384429216385, 1.1762843132019043, 0.03528108447790146, -1.1301747560501099, 0.21409451961517334, -0.6789005398750305, -0.28446707129478455, -0.02101478911936283, 0.41067636013031006, -0.038463007658720016, 0.3514482378959656, 0.3624623417854309, -0.20324477553367615, 0.2608417272567749, -0.15153250098228455, -0.4339146912097931, 0.37276706099510193, -0.26503732800483704, -0.241333469748497, 0.888641893863678, 0.9286700487136841, -1.1065086126327515, -1.1595618724822998, -0.99828040599823, -0.25756222009658813, -0.2560608386993408, 0.37526559829711914, -0.5709474086761475, -0.9196221232414246, 0.8786780834197998, 0.7170027494430542, 0.05216832831501961, 0.5440680384635925, -0.06959804892539978, -0.0796765387058258, 1.060895562171936, 0.2618948221206665, -0.3971773684024811, -0.03020147606730461, 1.175014615058899, 1.6418708562850952, -1.281646966934204, -0.11694575846195221, -0.19499234855175018, -0.4769938886165619, 1.0032672882080078, 0.4431285262107849, -0.20346011221408844, 1.1919325590133667, -0.7810858488082886, 0.1268899142742157, 0.5568196773529053, -0.9994863867759705, 0.06626833975315094, 1.0343890190124512, 1.2668217420578003, 0.49319007992744446, 0.069837287068367, 0.3507870137691498, 1.0427699089050293, -0.1326967179775238, 0.41756781935691833, 0.659233033657074, 0.48007169365882874, -0.3665757477283478, 0.3200635612010956, 0.2171011120080948, 0.22306567430496216, -0.4284588396549225, -0.1941048800945282, -0.009476607665419579, 1.049296498298645, 0.34578320384025574, 0.4346045255661011, 0.703394889831543, 0.04149990156292915, 0.9910821914672852, 0.25473105907440186, 0.6690384745597839, -0.46570321917533875, -0.547605037689209, -0.5688769221305847, -0.8115202188491821, 0.011109425686299801, -0.47620323300361633, -0.2164783924818039, -0.17897780239582062, -0.2526717185974121, 0.6379610896110535, -0.14565423130989075, 0.45612600445747375, 0.7982974648475647, 0.574108362197876, 0.7928058505058289, -0.47072815895080566, -0.3283168375492096, -0.46600741147994995, -1.0057942867279053, 0.20174337923526764, -0.13287962973117828, -0.014621675945818424, -0.398800253868103, -0.036219894886016846, 0.17382536828517914]}, "authors": [{"authorId": "2116325864", "name": "Junguang Jiang"}, {"authorId": "2066476988", "name": "Yang Shu"}, {"authorId": "2144499343", "name": "Jianmin Wang"}, {"authorId": "2054275000", "name": "Mingsheng Long"}], "references": [{"paperId": "6296aa7cab06eaf058f7291040b320b5a83c0091", "title": "Generative Adversarial Networks"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "6f54d34b472c0f88fc062787d377a32244d9651e", "title": "Decoupled Adaptation for Cross-Domain Object Detection"}, {"paperId": "c206a6e7f51f5e1b6bfc479a174b66ad88ada2db", "title": "Exploring the Limits of Large Scale Pre-training"}, {"paperId": "f45261b7b53043c316f45f613cb735907b93fb5a", "title": "Raise a Child in Large Language Model: Towards Effective and Generalizable Fine-tuning"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "f07b2e5b0c0f0f52f44a2926f17a27de3db0b780", "title": "Zoo-Tuning: Adaptive Transfer from a Zoo of Models"}, {"paperId": "87d5b61f5b6fdb0a57fc66b5c5bb428c398eaa86", "title": "Deep learning for AI"}, {"paperId": "529edafa160a77901bec123cf8858e6c08f6cd06", "title": "When does pretraining help?: assessing self-supervised learning for law and the CaseHOLD dataset of 53,000+ legal holdings"}, {"paperId": "739ceacfafb1c4eaa17509351b647c773270b3ae", "title": "An Empirical Study of Training Self-Supervised Vision Transformers"}, {"paperId": "3961acb8c63a46ab5fa54e79cb59b37288a8d8ad", "title": "Regressive Domain Adaptation for Unsupervised Keypoint Detection"}, {"paperId": "e602ce17a993d33d114381be4dc54e7c19d01bce", "title": "Cycle Self-Training for Domain Adaptation"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "54a0d678fa5cacc4fe033d70b86ca8b89977142e", "title": "LogME: Practical Assessment of Pre-trained Models for Transfer Learning"}, {"paperId": "8f566001453bc6be0a935bf69ffd90d9db3af32b", "title": "Towards Causal Representation Learning"}, {"paperId": "e54ffc76d805c48660bb0fd20019ca82ac94ba0d", "title": "Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning"}, {"paperId": "d22e4cc3a501c17881b9478621f29760e429e76e", "title": "Parameter-Efficient Transfer Learning with Diff Pruning"}, {"paperId": "0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d", "title": "Exploring Simple Siamese Representation Learning"}, {"paperId": "1c1a69d5b4aba343515c69464e4fc8da969ac61e", "title": "Bi-tuning of Pre-trained Representations"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "17293cd36ee5e7ec37dcec1d5ab85f9b77ad65d5", "title": "Do Adversarially Robust ImageNet Models Transfer Better?"}, {"paperId": "6a5efb990b6558c21d9fdded4884c00ba152cb7c", "title": "In Search of Lost Domain Generalization"}, {"paperId": "022622e024890d6e044ac50e2da6b44c59bdf418", "title": "The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization"}, {"paperId": "38f93092ece8eee9771e61c1edaf11b1293cae1b", "title": "Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning"}, {"paperId": "199d88fb9ec7430ca653f4c066b02aa7c3b4dd98", "title": "What makes instance discrimination good for transfer learning?"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "082d70e93af82d3ad289795312c717e7f1858e5f", "title": "A survey on domain adaptation theory"}, {"paperId": "e816f788767eec6a8ef0ea9eddd0e902435d4271", "title": "Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks"}, {"paperId": "43f5124d50b5b148c71cb2e56970e4a386be055a", "title": "LEEP: A New Measure to Evaluate Transferability of Learned Representations"}, {"paperId": "6e1bb490ae54b42f13d14d69b2012edda4664949", "title": "Do We Really Need to Access the Source Data? Source Hypothesis Transfer for Unsupervised Domain Adaptation"}, {"paperId": "7af72a461ed7cda180e7eab878efd5f35d79bbf4", "title": "A Simple Framework for Contrastive Learning of Visual Representations"}, {"paperId": "8ae9a17c87a4518b513e860683a0ef7824be994d", "title": "Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference"}, {"paperId": "22b52d3f18eaf43993a3a91053f5efe6267144e7", "title": "Mutual Mean-Teaching: Pseudo Label Refinery for Unsupervised Domain Adaptation on Person Re-identification"}, {"paperId": "3a083d843f891b3574494c385699c21766ce8b7a", "title": "Improved protein structure prediction using potentials from deep learning"}, {"paperId": "bc51622358d8eea83248ef29402fe10640d07ba6", "title": "Big Transfer (BiT): General Visual Representation Learning"}, {"paperId": "ee66b3c5dc6347b3cdfd3e7ef8dd4968163e93b4", "title": "Minimum Class Confusion for Versatile Domain Adaptation"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "83d410601e3d55fab285926882828a48e23b97e4", "title": "Transferable Representation Learning with Deep Adaptation Networks"}, {"paperId": "add2f205338d70e10ce5e686df4a690e2851bdfc", "title": "Momentum Contrast for Unsupervised Visual Representation Learning"}, {"paperId": "ab70853cd5912c470f6ff95e95481980f0a2a41b", "title": "SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization"}, {"paperId": "18d026ec5d0eebd17ee2c762da89540c0b3d7bde", "title": "A Comprehensive Survey on Transfer Learning"}, {"paperId": "361c00b22e29d0816ca896513d2c165e26399821", "title": "Grandmaster level in StarCraft II using multi-agent reinforcement learning"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "222b9a7b8038120671a1610e857d3edbc7ac5550", "title": "Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models"}, {"paperId": "b3d60b4a1622807986efff92fa58e150b9c40567", "title": "Side-Tuning: Network Adaptation via Additive Side Networks"}, {"paperId": "67a9dde04f367efc903b6d06097df9bdd9887ae7", "title": "Recurrent Independent Mechanisms"}, {"paperId": "abf5478c24664a1380b7e213a3ab1c4af54775d0", "title": "Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML"}, {"paperId": "90e04f3ae23ca7df5f59b11453341e3db943b6f4", "title": "A Continual Learning Survey: Defying Forgetting in Classification Tasks"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "81f5810fbbab9b7203b9556f4ce3c741875407bc", "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans"}, {"paperId": "753b7a701adc1b6072378bd048cfa8567885d9c7", "title": "Invariant Risk Minimization"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "97f4d09175705be4677d675fa27e55defac44800", "title": "Contrastive Multiview Coding"}, {"paperId": "809cc93921e4698bde891475254ad6dfba33d03b", "title": "How Multilingual is Multilingual BERT?"}, {"paperId": "600fcb58fb81cfb3d72b2c7e55ebb363a2f191e5", "title": "Pre-training Graph Neural Networks"}, {"paperId": "0ddada21984cd7e1a8aa9af41bddbd2660865f1a", "title": "Transferability vs. Discriminability: Batch Spectral Penalization for Adversarial Domain Adaptation"}, {"paperId": "290357314d0c339bcce31cfbe6b29aa50f89b026", "title": "Learning What and Where to Transfer"}, {"paperId": "c58a3c67f34b83146acab4cee21c062f08b02475", "title": "Diversify and Match: A Domain Adaptive Representation Learning Paradigm for Object Detection"}, {"paperId": "88ee291cf1f57fd0f4914a80b986a08a90d887f1", "title": "Billion-scale semi-supervised learning for image classification"}, {"paperId": "4ae0c4a511697e960c477ea3e37b3e11bf3e0e02", "title": "Learning Robust Global Representations by Penalizing Local Predictive Power"}, {"paperId": "031e4e43aaffd7a479738dcea69a2d5be7957aa3", "title": "ERNIE: Enhanced Representation through Knowledge Integration"}, {"paperId": "868c1e3037d2e212e9181d731d811a1c24fe05a2", "title": "Bridging Theory and Algorithm for Domain Adaptation"}, {"paperId": "9d5ec23154fb278a765f47ba5ee5150bd441d0de", "title": "A Closer Look at Few-shot Classification"}, {"paperId": "865100f1b248723f48fc5d2c68be0421fd24ff48", "title": "Sliced Wasserstein Discrepancy for Unsupervised Domain Adaptation"}, {"paperId": "156d217b0a911af97fa1b5a71dc909ccef7a8028", "title": "SciBERT: A Pretrained Language Model for Scientific Text"}, {"paperId": "578e050d6e007797d032a07e712142035f2666dc", "title": "An Embarrassingly Simple Approach for Transfer Learning from Pretrained Language Models"}, {"paperId": "cff4cb74f4466bd0407977e40ef0be9f444c63ea", "title": "Transfusion: Understanding Transfer Learning for Medical Imaging"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "658721bc13b0fa97366d38c05a96bf0a9f4bb0ac", "title": "Multi-Task Deep Neural Networks for Natural Language Understanding"}, {"paperId": "98627a34761bad5bd0582a7b03988de780b2d06b", "title": "DELTA: DEep Learning Transfer using Feature Map with Attention for Convolutional Networks"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "6c405d4b5dc41a86be05acd59c06ed19daf01d14", "title": "Theoretically Principled Trade-off between Robustness and Accuracy"}, {"paperId": "ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc", "title": "Cross-lingual Language Model Pretraining"}, {"paperId": "675b96a38f37f92043189d7e90377a6b41a2a9cd", "title": "Contrastive Adaptation Network for Unsupervised Domain Adaptation"}, {"paperId": "5ca9b18448a2ef8a2443445269ccb151aa100de9", "title": "Strong-Weak Distribution Alignment for Adaptive Object Detection"}, {"paperId": "d8d680aea59295c020b9d53d78dd8d954a876845", "title": "Meta-Transfer Learning for Few-Shot Learning"}, {"paperId": "3217278e346fefbd34f0727321059c7ea5792612", "title": "Moment Matching for Multi-Source Domain Adaptation"}, {"paperId": "1365b4a286e607a4902ef11c84a1f309719d946c", "title": "ADVENT: Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation"}, {"paperId": "57eedf785fd9e3ea28b4cd30539cb0fa374f9e74", "title": "Characterizing and Avoiding Negative Transfer"}, {"paperId": "e87b5f4c64056431dfc62ebff0f23d9c94252598", "title": "SpotTune: Transfer Learning Through Adaptive Fine-Tuning"}, {"paperId": "4152d2c8585f7e3f85d3b3d84036171de104cbd7", "title": "Rethinking ImageNet Pre-Training"}, {"paperId": "a42eb9e4c2506640446f07df3a9a0134752b00da", "title": "Domain Adaptive Transfer Learning with Specialist Models"}, {"paperId": "0f50b7483f1b200ebf88c4dd7698de986399a0f3", "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness"}, {"paperId": "967a21a111757d6af7f7a25ca7ea2bdf6d505098", "title": "Deep Graph Infomax"}, {"paperId": "1c3112ef8a346b9817382ed34a8c146c53d5bcf5", "title": "XNLI: Evaluating Cross-lingual Sentence Representations"}, {"paperId": "9b15362b9a025071aa170f7ed81a761bc057c859", "title": "Unsupervised Domain Adaptation for Semantic Segmentation via Class-Balanced Self-training"}, {"paperId": "af3825437b627db1a99f946f7aa773ba8b03befd", "title": "Learning deep representations by mutual information estimation and maximization"}, {"paperId": "04f739a0c29b75877243731aeead512bf0ed1dff", "title": "Meta-Learning with Latent Embedding Optimization"}, {"paperId": "b227f3e4c0dc96e5ac5426b85485a70f2175a205", "title": "Representation Learning with Contrastive Predictive Coding"}, {"paperId": "89c3355f5bc7130ae4ed090c8accc52dd885d558", "title": "Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning"}, {"paperId": "8a8cfa45b4c0d071fbffa091c02670b19c94b693", "title": "Do Better ImageNet Models Transfer Better?"}, {"paperId": "1e1855ca80e8ac3de0e169871f320416902e9ad1", "title": "Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels"}, {"paperId": "155b7782dbd713982a4133df3aee7adfd0b6b304", "title": "Unsupervised Feature Learning via Non-parametric Instance Discrimination"}, {"paperId": "0f885fd46064d271d4404cf9bb3d758e1a6f8d55", "title": "Exploring the Limits of Weakly Supervised Pretraining"}, {"paperId": "2fe2cfd98e232f1396f01881853ed6b3d5e37d65", "title": "Taskonomy: Disentangling Task Transfer Learning"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "d70dc8f866ab04e207c2c144cc337b421bc762e0", "title": "DeepJDOT: Deep Joint distribution optimal transport for unsupervised domain adaptation"}, {"paperId": "d08b35243edc5be07387a9ed218070b31e502901", "title": "Group Normalization"}, {"paperId": "04a7cab83c5b1b5dd13dcb8632fae3f24150f873", "title": "Domain Adaptive Faster R-CNN for Object Detection in the Wild"}, {"paperId": "193b518bc3025804c6d587c74cbc154d91478417", "title": "Learning to Adapt Structured Output Space for Semantic Segmentation"}, {"paperId": "d55d1d035e91220335edff0fe8f5d249d8c4a00b", "title": "Measuring the Intrinsic Dimension of Objective Landscapes"}, {"paperId": "008c901b3fd9e46ee8d3bddb616121e2887b7e67", "title": "A DIRT-T Approach to Unsupervised Domain Adaptation"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "97883f37c62b4b0e52cdc31dea1a375597db3804", "title": "Piggyback: Adding Multiple Tasks to a Single, Fixed Network by Learning to Mask"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "0d725e4fea8bbaf332d6a8d424ebecbd547a3851", "title": "Maximum Classifier Discrepancy for Unsupervised Domain Adaptation"}, {"paperId": "2ec7156913117949ab933f27f492d0149bc0031f", "title": "Learning Sparse Neural Networks through L0 Regularization"}, {"paperId": "46f6a90fcf0ecc4b60470a1f35cd95d65d5f8d9b", "title": "Elements of Causal Inference: Foundations and Learning Algorithms"}, {"paperId": "7002d8c61be9f1ea210f88059df6955c88db62b7", "title": "Person Transfer GAN to Bridge Domain Gap for Person Re-identification"}, {"paperId": "572a1f77306e160c3893299c18f3ed862fb5f6d9", "title": "Few-Shot Learning with Graph Neural Networks"}, {"paperId": "907a90967f68da4311802247408e0515e363f930", "title": "CyCADA: Cycle-Consistent Adversarial Domain Adaptation"}, {"paperId": "e3d772986d176057aca2f5e3eb783da53b559134", "title": "Unsupervised Machine Translation Using Monolingual Corpora Only"}, {"paperId": "cbf7521d6f73d49bbdfeea92de6f7f89ce71cd65", "title": "Open Set Domain Adaptation"}, {"paperId": "1fefc1d288a87fe218ba25024c4b2b6ef345738e", "title": "Self-ensembling for domain adaptation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "9171e83fb98299e14cbb3673437a0495a213767a", "title": "Conditional Adversarial Domain Adaptation"}, {"paperId": "ceeaca3bfb24a559590893843977aa930a7ac531", "title": "Joint distribution optimal transportation for domain adaptation"}, {"paperId": "d89ee98810039d2061ed42ee8026da49c503d16b", "title": "Learning multiple visual domains with residual adapters"}, {"paperId": "15168665f4b8eb11466086e69780ed98e5280059", "title": "Generate to Adapt: Aligning Domains Using Generative Adversarial Networks"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "c269858a7bb34e8350f2442ccf37797856ae9bca", "title": "Prototypical Networks for Few-shot Learning"}, {"paperId": "c889d6f98e6d79b89c3a6adf8a921f88fa6ba518", "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"}, {"paperId": "470d11b8ca4586c930adbbfc3f60bff08f2a0161", "title": "Meta Networks"}, {"paperId": "641165c959554d8f03314778bd6dfb581d9a469e", "title": "Generalization and Equilibrium in Generative Adversarial Nets (GANs)"}, {"paperId": "345afa0e85cb2f5cb438ae44027499ff2c392409", "title": "Adversarial Discriminative Domain Adaptation"}, {"paperId": "01dc0a157e355ddc34a426f121fc871601fda567", "title": "Central Moment Discrepancy (CMD) for Domain-Invariant Representation Learning"}, {"paperId": "68cb9fce1e6af2740377494350b650533c9a29e1", "title": "Learning from Simulated and Unsupervised Images through Adversarial Training"}, {"paperId": "220ac48a22547a455d05f416e1fd22bbd0b0788d", "title": "Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks"}, {"paperId": "762a75cc06ff35ce026182d1907300e75f9d24c6", "title": "FCNs in the Wild: Pixel-level Adversarial and Constraint-based Adaptation"}, {"paperId": "54ddb00fa691728944fd8becea90a373d21597cf", "title": "Understanding deep learning requires rethinking generalization"}, {"paperId": "04bd2907111855b9fde9413bb25b9788a4c03f26", "title": "Unsupervised Cross-Domain Image Generation"}, {"paperId": "01cb4071a0a43aeef63e5d568ad5afe1fb8b2411", "title": "Domain Separation Networks"}, {"paperId": "12d0cf8ae5ffe1b89345e1dcead22be592d844b2", "title": "Deep CORAL: Correlation Alignment for Deep Domain Adaptation"}, {"paperId": "8f3b80ddc0dd62e6c3369fabb1715990c29e9b9a", "title": "Learning without Forgetting"}, {"paperId": "372bc106c61e7eb004835e85bbfee997409f176a", "title": "Coupled Generative Adversarial Networks"}, {"paperId": "3904315e2eca50d0086e4b7273f7fd707c652230", "title": "Meta-Learning with Memory-Augmented Neural Networks"}, {"paperId": "be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6", "title": "Matching Networks for One Shot Learning"}, {"paperId": "ae9e5e72aefd19b81c1fe75d7baf6c0bedad75e5", "title": "Deep Transfer Learning with Joint Adaptation Networks"}, {"paperId": "24da6180db314619060d7b8fc798390f0c7a139a", "title": "Revisiting Batch Normalization For Practical Domain Adaptation"}, {"paperId": "b4929ef46d86b92753362bdd1aa7b6e3e03e6214", "title": "Unsupervised Domain Adaptation with Residual Transfer Networks"}, {"paperId": "846aedd869a00c09b40f1f1f35673cb22bc87490", "title": "Mastering the game of Go with deep neural networks and tree search"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "13497bd108d4412d02050e646235f456568cf822", "title": "Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin"}, {"paperId": "83f200fdef3f1b1778a3b46eabd44d5e2b305e2e", "title": "Simultaneous Deep Transfer Across Domains and Tasks"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "1d5972b32a9b5a455a6eef389de5b7fca25771ad", "title": "Domain-Adversarial Training of Neural Networks"}, {"paperId": "fc1b1c9364c58ec406f494dd944b609a6a038ba6", "title": "Unsupervised Visual Representation Learning by Context Prediction"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "7340f090f8a0df5b109682e9f6d57e4b8ca1a2f7", "title": "Learning Transferable Features with Deep Adaptation Networks"}, {"paperId": "8e12047bb8ed40c3266459ce8370a9f9594397bb", "title": "Transfer of Learning"}, {"paperId": "a2bf2e83df0c8b3257a8a809cb96c3ea58ec04b3", "title": "Causal inference by using invariant prediction: identification and confidence intervals"}, {"paperId": "bee044c8e8903fb67523c1f8c105ab4718600cdb", "title": "Explaining and Harnessing Adversarial Examples"}, {"paperId": "1c734a14c2325cb76783ca0431862c7f04a69268", "title": "Deep Domain Confusion: Maximizing for Domain Invariance"}, {"paperId": "081651b38ff7533550a3adfc1c00da333a8fe86c", "title": "How transferable are features in deep neural networks?"}, {"paperId": "2530cfc7764bda1330c48c0c8e2cd0e0c671d7e1", "title": "Unsupervised Domain Adaptation by Backpropagation"}, {"paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e", "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"}, {"paperId": "1109b663453e78a59e4f66446d71720ac58cec25", "title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks"}, {"paperId": "9c495a9b835f7803746fce1f711dad0eeb411112", "title": "Transfer Feature Learning with Joint Distribution Adaptation"}, {"paperId": "2f4df08d9072fc2ac181b7fced6a245315ce05c8", "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation"}, {"paperId": "b8de958fead0d8a9619b55c7299df3257c624a96", "title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition"}, {"paperId": "cea9cfa21060a1a34a337abae81c75e7370f084c", "title": "Connecting the Dots with Landmarks: Discriminatively Learning Domain-Invariant Features for Unsupervised Domain Adaptation"}, {"paperId": "7151066eb54f4e6b43bdd12aec566a9a912d744e", "title": "Optimal kernel choice for large-scale two-sample tests"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "f1bb50162b731dfd41bdd3648ba5239579420ac0", "title": "On causal and anticausal learning"}, {"paperId": "184ac0766262312ba76bbdece4e7ffad0aa8180b", "title": "Representation Learning: A Review and New Perspectives"}, {"paperId": "8db26a22942404bd435909a16bb3a50cd67b4318", "title": "Marginalized Denoising Autoencoders for Domain Adaptation"}, {"paperId": "7de1d1612debcbde32cd588fa607a408df79c717", "title": "Geodesic flow kernel for unsupervised domain adaptation"}, {"paperId": "225f78ae8a44723c136646044fd5c5d7f1d3d15a", "title": "A Kernel Two-Sample Test"}, {"paperId": "a6c1a120f6c84eff4fb0facf404094f840105b9f", "title": "Deep Learning of Representations for Unsupervised and Transfer Learning"}, {"paperId": "6f4065f0cc99a0839b0248ffb4457e5f0277b30d", "title": "Domain Adaptation for Large-Scale Sentiment Classification: A Deep Learning Approach"}, {"paperId": "a25fbcbbae1e8f79c4360d26aa11a3abf1a11972", "title": "A Survey on Transfer Learning"}, {"paperId": "66d398aeaeb7ec24ededb1adaa4b4f09a6c1bcde", "title": "A theory of learning from different domains"}, {"paperId": "80b895a6e8d73a2a8ada6c0e31fb434f9a83cc86", "title": "Impossibility Theorems for Domain Adaptation"}, {"paperId": "f2fdb43f594b9ae0c32e1d52cf2d6b82dfe46dc3", "title": "Hilbert Space Embeddings and Metrics on Probability Measures"}, {"paperId": "1dae4d61cd74cc919ecc638bde6b7125728ea97b", "title": "Domain Adaptation via Transfer Component Analysis"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "c62043a7d2537bbf40a84b9913957452a47fdb83", "title": "Dataset Shift in Machine Learning"}, {"paperId": "a9606fe31a66df53cd36ceffbcb44a68e3b52d67", "title": "Domain Adaptation: Learning Bounds and Algorithms"}, {"paperId": "843959ffdccf31c6694d135fad07425924f785b1", "title": "Extracting and composing robust features with denoising autoencoders"}, {"paperId": "1fc971fc394fd7a00922b082973568850e77a163", "title": "Direct Importance Estimation with Model Selection and Its Application to Covariate Shift Adaptation"}, {"paperId": "424c3ab98f1ae2d9e9ecf892e15a12c09f4e9ffe", "title": "Covariate Shift Adaptation by Importance Weighted Cross Validation"}, {"paperId": "96c6bc559b79d8fd518f431c707e8b44ce3bc4de", "title": "Analysis of Representations for Domain Adaptation"}, {"paperId": "af8835c8960e539cc33f5375861efaedec1fb0b2", "title": "Correcting Sample Selection Bias by Unlabeled Data"}, {"paperId": "355d44f53428b1ac4fb2ab468d593c720640e5bd", "title": "Greedy Layer-Wise Training of Deep Networks"}, {"paperId": "463565c30b7a9c12c2ef0558a51cfc7b05055737", "title": "Semi-Supervised Learning (Adaptive Computation and Machine Learning)"}, {"paperId": "009f35c0e453f2435efd8d8ef8086b76b294967a", "title": "Rademacher and Gaussian Complexities: Risk Bounds and Structural Results"}, {"paperId": "161ffb54a3fdf0715b198bb57bd22f910242eb49", "title": "Multitask Learning"}, {"paperId": "a68cdde72e058fac58228e293cf27bd18d7357d7", "title": "Representation Subspace Distance for Domain Adaptation Regression"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "c63096546d654475ed5ada7e221db1efd84d6dea", "title": "Adapting ImageNet-scale models to complex distribution shifts with self-learning"}, {"paperId": "f5d9fd9db048042fbd1f1175c45f59535d34b84c", "title": "Omni-Training for Data-E\ufb03cient Deep Learning"}, {"paperId": "74e7e36a3e7d52aee4d332945956e904a27466e1", "title": "Stochastic Normalization"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "e7c642fbbe31fea90cf3c643c380e354c20d9aa4", "title": "Transferable Normalization: Towards Improving Transferability of Deep Neural Networks"}, {"paperId": "62086fbddce3bafa052232742bc047eccb184d1d", "title": "Catastrophic Forgetting Meets Negative Transfer: Batch Spectral Shrinkage for Safe Transfer Learning"}, {"paperId": null, "title": "Hierarchically structured metalearning"}, {"paperId": "44b6da0cd36c0fa2f7d3485c6dc0b6d2fbe379bb", "title": "Learning how to learn"}, {"paperId": null, "title": "Pytorch image models"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "6ebdf55cade577979515dc5d09620204a07e7c92", "title": "Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping"}, {"paperId": null, "title": "Unpaired image-to-image translation using cycle-consistent adversarial networks"}, {"paperId": "885dec9bb60d27b4a60e80b3ea401d0f4bdf5c44", "title": "Overcoming catastrophic forgetting in neural networks"}, {"paperId": "2913c2bf3f92b5ae369400a42b2d27cc5bc05ecb", "title": "Deep Learning"}, {"paperId": "db8dbe07af7eebc1eed662be268592f00f4882e0", "title": "To transfer or not to transfer"}, {"paperId": "bdaec1b3eb9a8f7a2b296be009a148c35236f3ce", "title": "Evolutionary principles in self-referential learning, or on learning how to learn: The meta-meta-. hook"}]}