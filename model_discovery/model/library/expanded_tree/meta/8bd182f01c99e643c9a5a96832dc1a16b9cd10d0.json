{"paperId": "8bd182f01c99e643c9a5a96832dc1a16b9cd10d0", "abstract": "Preservation of domain knowledge from the source to target is crucial in any translation workflow. It is common in the translation industry to receive highly-specialized projects, where there is hardly any parallel in-domain data. In such scenarios where there is insufficient in-domain data to fine-tune Machine Translation (MT) models, producing translations that are consistent with the relevant context is challenging. In this work, we propose leveraging state-of-the-art pretrained language models (LMs) for domain-specific data augmentation for MT, simulating the domain characteristics of either (a) a small bilingual dataset, or (b) the monolingual source text to be translated. Combining this idea with back-translation, we can generate huge amounts of synthetic bilingual in-domain data for both use cases. For our investigation, we used the state-of-the-art MT architecture, Transformer. We employed mixed fine-tuning to train models that significantly improve translation of in-domain texts. More specifically, our proposed methods achieved improvements of approximately 5-6 BLEU and 2-3 BLEU, respectively, on Arabic-to-English and English-to-Arabic language pairs. Furthermore, the outcome of human evaluation corroborates the automatic evaluation results.", "venue": "Conference of the Association for Machine Translation in the Americas", "year": 2022, "citationCount": 7, "influentialCitationCount": 1, "openAccessPdf": {"url": "http://arxiv.org/pdf/2208.05909", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes leveraging state-of-the-art pretrained language models (LMs) for domain-specific data augmentation for MT, simulating the domain characteristics of either a small bilingual dataset, or the monolingual source text to be translated, to generate huge amounts of synthetic bilingual in-domain data."}, "embedding": {"model": "specter_v2", "vector": [0.30881643295288086, 0.3417893350124359, -0.4491046667098999, 0.08892206102609634, -0.8197227120399475, -0.587945282459259, 1.05868661403656, -0.5031031966209412, -0.30189257860183716, 0.41245388984680176, 0.74543696641922, -0.7005426287651062, 0.04528146982192993, -0.23175837099552155, -0.29603704810142517, -0.10145615041255951, -0.633651077747345, 0.9230021834373474, -0.5545834898948669, -1.252922534942627, -0.48442813754081726, -0.5653481483459473, 0.19634877145290375, 0.15988865494728088, 0.9630492925643921, -0.0192798413336277, 0.40648725628852844, 0.5843675136566162, -0.40172645449638367, 0.22743095457553864, 0.28137415647506714, -0.506245493888855, 0.4440724551677704, -0.6417138576507568, -0.2806773781776428, 0.664239227771759, 0.18152429163455963, -0.5665213465690613, -0.3438372313976288, 0.5376452803611755, -0.14522358775138855, 0.04023343697190285, 0.4645243287086487, -0.8327174782752991, -0.6946525573730469, 1.1895910501480103, 0.711245596408844, 0.8289560079574585, -0.04170870780944824, -0.4598486125469208, 0.7889474630355835, -1.0645593404769897, 0.5295959115028381, 1.06890869140625, 0.36685115098953247, 0.7210674285888672, -0.18663324415683746, -0.521761953830719, -0.058483101427555084, -0.029308805242180824, -0.6211830973625183, -0.3096029460430145, 0.44582399725914, -0.2541150450706482, 1.3546926975250244, -0.6500217914581299, -0.09888653457164764, 0.703828752040863, -0.1344860941171646, 1.0412323474884033, 0.004698958247900009, -1.0776885747909546, -0.4937850832939148, 0.24203801155090332, -0.49826279282569885, 0.673598051071167, -0.4521542191505432, -0.07675337791442871, -0.8494362235069275, 0.29464927315711975, 0.5206100344657898, -0.26869845390319824, -0.4253016710281372, -0.20759044587612152, -0.9657073020935059, 0.6192529201507568, 0.2247186154127121, 1.0238302946090698, -0.21270155906677246, 0.030656227841973305, 0.4587162733078003, 1.0043509006500244, 0.24023295938968658, 0.5158272385597229, -0.3826931118965149, 0.987139880657196, -1.0562548637390137, 0.2002873420715332, -0.13305452466011047, 0.7525323629379272, -0.012381990440189838, 0.17428483068943024, -0.7463503479957581, 0.32241860032081604, 1.0865956544876099, 0.43256810307502747, 0.993854820728302, -0.1899210512638092, 0.9177573323249817, -0.2763971984386444, 0.3605654537677765, -0.4172351062297821, -0.48199304938316345, -0.32489579916000366, -0.648411214351654, -1.425595760345459, -0.15483902394771576, 0.08647825568914413, -0.910964846611023, 0.9925989508628845, 0.059869617223739624, -0.4254419505596161, 0.52326500415802, 0.3821858763694763, 0.34983503818511963, 0.6081814169883728, -0.36448848247528076, -0.5500190854072571, 0.8260531425476074, -0.7933218479156494, -0.535634458065033, -1.1836233139038086, 0.5144747495651245, -0.6060230135917664, 0.6478530168533325, -0.4053700864315033, -1.1843743324279785, -0.699949324131012, -0.9340118765830994, 0.08348626643419266, -0.5264125466346741, 0.4830514192581177, 0.4553573727607727, 0.490583598613739, -1.2707605361938477, 0.47978144884109497, 0.020395008847117424, -0.5235087871551514, 0.2949667274951935, -0.08265379816293716, -0.004287322983145714, -0.9515053033828735, -1.5208734273910522, 0.7446871995925903, 0.019683565944433212, -0.9019707441329956, -0.8858769536018372, -0.5317572355270386, -1.0952153205871582, -0.9161196351051331, -0.031296346336603165, -0.5461269617080688, 1.2838776111602783, -0.26025575399398804, -1.2864724397659302, 0.7817026376724243, -0.08260057121515274, -0.11344876885414124, 0.4397360384464264, 0.18116772174835205, -0.8384200930595398, -0.29903697967529297, 0.3520210087299347, 0.27112871408462524, 0.5042340159416199, 0.10427230596542358, 0.27638182044029236, 0.23104524612426758, 0.06064325198531151, 0.10981568694114685, -0.7853200435638428, 1.031129240989685, -0.46715810894966125, -0.9195191264152527, 0.38406088948249817, 0.8249498605728149, -0.31786203384399414, -0.5589529275894165, -0.25790247321128845, -0.3820685148239136, 0.950661838054657, -0.649978518486023, 0.6442422866821289, -0.5993435382843018, -0.29009953141212463, -0.427127867937088, -0.6074476838111877, -0.4062829911708832, -1.0646017789840698, 1.0153343677520752, -0.567331850528717, -0.054302189499139786, -0.16360917687416077, -0.6242173910140991, -0.12079619616270065, -0.5925663709640503, -1.131711721420288, 0.058480873703956604, 0.4513659179210663, 0.9688944220542908, -0.7618558406829834, 0.3645961582660675, -0.04345451667904854, 0.316466361284256, -0.6965547204017639, 0.8144062757492065, -0.749929666519165, 1.0450953245162964, -0.27689921855926514, -0.09430819004774094, 0.29071903228759766, -0.530780553817749, 0.6965674757957458, -0.7547643184661865, 0.09578710794448853, 0.7674554586410522, -0.019347917288541794, 1.8773200511932373, -0.39961501955986023, 0.6115597486495972, -0.1317121833562851, -0.973699688911438, 0.3667195439338684, 0.7002078890800476, 0.12846875190734863, -0.5873808264732361, 0.4648025631904602, 0.636512815952301, -0.6112079620361328, 0.4368937909603119, 0.7980879545211792, 0.13213877379894257, -0.41181430220603943, 0.5823074579238892, 0.7837685346603394, -0.313922643661499, 1.1231783628463745, 0.5729047656059265, 0.5177643299102783, 0.562593400478363, 0.020675091072916985, -0.0866791233420372, 0.8032006621360779, 0.011969653889536858, -0.3808271884918213, -0.2149544656276703, 0.7035906910896301, 0.7241629362106323, -0.06777974963188171, -0.6788439154624939, -0.45127370953559875, -0.04344000667333603, 0.8090401291847229, 1.1059328317642212, -0.2217399626970291, -0.23025822639465332, -1.1661971807479858, -0.6383219361305237, -0.7271159291267395, 0.23736335337162018, -0.20088699460029602, -0.07205485552549362, -0.551868736743927, -1.2919487953186035, 0.8951435685157776, 0.008311078883707523, 1.1610944271087646, 0.03546375036239624, 0.13428230583667755, -0.23523768782615662, -0.7015585899353027, -0.8983836770057678, -0.902736246585846, -0.11210648715496063, -0.8000296950340271, -0.06922514736652374, -0.6007099151611328, -0.4735669493675232, 0.21618476510047913, -0.39547988772392273, 1.2324926853179932, -0.7671863436698914, -0.06710883229970932, -0.0444575771689415, 0.5112358331680298, -0.17179778218269348, -1.279846429824829, -0.13704577088356018, 0.33392128348350525, -0.18909619748592377, 0.22739529609680176, 0.3060794174671173, 0.1680939942598343, 0.4638824760913849, -0.42822083830833435, 0.21450579166412354, -0.1892680823802948, 0.18102382123470306, 0.452362596988678, -0.14224094152450562, -0.03440138325095177, -0.8461625576019287, 0.935583233833313, 0.2907864451408386, -0.5230618119239807, 0.45989781618118286, -0.17014797031879425, -0.44265490770339966, 0.7328283786773682, -0.6659140586853027, -0.33529937267303467, -1.3227171897888184, 0.6172037124633789, 0.22081027925014496, 0.05698087438941002, 0.3437023460865021, -0.2215907871723175, 0.40308088064193726, 0.9620463848114014, 0.5905987024307251, 0.2763269543647766, -0.36294835805892944, 0.7601229548454285, -0.7591495513916016, 0.26723453402519226, 0.38225480914115906, 0.5797999501228333, -0.18547029793262482, -0.21860705316066742, -0.15902948379516602, 0.038368646055459976, 0.5130056142807007, -0.2813727855682373, -0.4527518153190613, 0.016945885494351387, -1.1664884090423584, 0.2597309350967407, -0.029044387862086296, -0.7224931716918945, -0.5570375919342041, 0.1908871829509735, -0.2674369812011719, -0.47939953207969666, -0.9547460675239563, -1.1505461931228638, -0.04235828295350075, -0.5322440266609192, -1.3402377367019653, 0.4517253637313843, -0.15707089006900787, -0.1588527411222458, -0.6804143786430359, 0.1271689534187317, 0.10835400968790054, 0.9180612564086914, -0.5577032566070557, 0.8738037347793579, -0.09877583384513855, -0.17795410752296448, -0.11176047474145889, 0.5954967737197876, 0.18529446423053741, 0.05397360771894455, 0.05593632534146309, -0.354449599981308, -0.015772512182593346, -0.16300882399082184, -0.48220518231391907, -0.31177541613578796, 0.3225047290325165, -0.17217044532299042, 0.08955064415931702, -0.4915086030960083, 0.27446407079696655, 1.2277179956436157, -0.7276638150215149, -0.06155659630894661, 0.4056509733200073, 0.6129588484764099, 0.2423262596130371, 0.30889084935188293, 0.4516284763813019, 0.38581523299217224, 0.5577749609947205, -0.3622782230377197, -0.543750524520874, -0.3392006754875183, -0.6285180449485779, 0.8878321051597595, 1.3970474004745483, 0.44449058175086975, -0.21160098910331726, -1.4741712808609009, 0.7489032745361328, -0.664095401763916, -0.26406964659690857, 0.5857588052749634, 0.48696115612983704, 0.8744797706604004, -0.7605142593383789, -0.13077720999717712, 0.17418406903743744, 0.7574741840362549, -0.07892448455095291, 0.1617552787065506, -0.26522988080978394, -0.16250771284103394, 0.4803246855735779, 0.2557419240474701, 0.5286948084831238, -0.27561211585998535, 0.781126856803894, 14.61829948425293, 0.9918065667152405, -0.11283431202173233, 1.0477209091186523, 0.4710928797721863, 0.11441195011138916, -0.3634170591831207, -0.09917352348566055, -0.866857647895813, -0.16332346200942993, 1.2916988134384155, -0.047563280910253525, 1.1960173845291138, 0.044440530240535736, 0.2708689868450165, 0.5228796005249023, -0.32899418473243713, 0.4353264570236206, 0.7233204245567322, -1.639741063117981, 0.892949104309082, 0.4245665371417999, 0.7152327299118042, 0.5278979539871216, 0.8016523122787476, 0.6723737716674805, 0.33247271180152893, -0.22688253223896027, 0.37020379304885864, -0.2677184045314789, 1.1101975440979004, -0.23703953623771667, 0.2219868153333664, 0.5525838136672974, -0.5585899353027344, -0.08091957867145538, -0.5647050738334656, -0.7476791143417358, 0.37624460458755493, 0.3035007119178772, -0.8393632173538208, -0.05572499334812164, -0.22609423100948334, 0.7648423314094543, 0.26657578349113464, -0.21707801520824432, -0.45418423414230347, 0.6198261380195618, 0.26366472244262695, 0.40219196677207947, 0.04255072772502899, 0.05872416868805885, 0.22709491848945618, -0.38148555159568787, 0.4342471659183502, -0.579208254814148, -0.10374054312705994, 0.19293175637722015, -0.7481212019920349, -0.02385764569044113, -0.7878147959709167, -0.44919639825820923, -0.1444983333349228, 0.6033805012702942, 0.2313721477985382, 0.26741570234298706, -0.3611736297607422, 0.44512221217155457, 0.3543912470340729, 0.2690359055995941, -0.673458456993103, -0.1252533346414566, 0.15931673347949982, -0.17863593995571136, -0.0960342288017273, 0.2676708996295929, -0.14596472680568695, -0.5794479846954346, -0.7855613827705383, -0.9653953909873962, 0.46869808435440063, -0.9755561947822571, -0.690493643283844, 1.3002241849899292, -0.17659837007522583, -1.1782861948013306, 0.24250349402427673, -1.0153555870056152, 0.133495032787323, 0.5531323552131653, -1.3581116199493408, -1.027129054069519, 0.42447274923324585, 0.06744075566530228, -0.3488066494464874, -0.6925002336502075, 1.0551856756210327, 0.29976311326026917, -0.19555586576461792, 0.08559111505746841, 0.405991792678833, 0.11039210110902786, 0.16840504109859467, -0.44152769446372986, 0.8499477505683899, 0.4354473650455475, 0.15353615581989288, 0.21533256769180298, 0.03368312492966652, 0.12490621209144592, -1.2388380765914917, -0.2416074275970459, 0.9279792308807373, -1.1103583574295044, -0.14571067690849304, -0.8735819458961487, -0.27596038579940796, 0.1974600851535797, 0.9647825360298157, -0.6726287007331848, 0.6769936680793762, -0.18758395314216614, -0.19741083681583405, -0.35827288031578064, -1.4789725542068481, 0.4403945207595825, 0.4169211685657501, -0.5264241099357605, -0.3687911927700043, 0.7171916961669922, 0.3337368369102478, -0.9734963178634644, -0.6313961148262024, -0.3073716461658478, -0.6286416053771973, 0.2580586075782776, 1.1739705801010132, -0.49531736969947815, 0.9851283431053162, 0.4948350191116333, -0.4135867953300476, -0.9838972091674805, 0.20982515811920166, -1.0735126733779907, 0.5795590877532959, 0.5382754802703857, 0.7662531733512878, -0.36554116010665894, -0.032453518360853195, 0.6174165606498718, 0.4647318124771118, 0.15924349427223206, -0.37451404333114624, -0.20744143426418304, 0.3007732033729553, -0.3888051509857178, 0.6504901051521301, 0.23436689376831055, 0.13295957446098328, 0.3650490343570709, 0.2822914719581604, 0.7313966155052185, -0.1678701639175415, -0.5523818731307983, 1.0383853912353516, 0.6915859580039978, 0.07384281605482101, -0.43354588747024536, -0.39190244674682617, -1.4485334157943726, -0.09032027423381805, -1.3255218267440796, 0.004206083249300718, -1.2472200393676758, -0.5294510126113892, 0.30382055044174194, 0.20959913730621338, -0.1798093318939209, 0.5352424383163452, 0.334367036819458, -0.6637831330299377, -0.7409354448318481, 0.040803320705890656, 1.0182571411132812, 1.1994584798812866, -0.8103073835372925, 0.13600286841392517, -0.5824599266052246, -0.03380009904503822, 0.3801112174987793, 0.4330461025238037, -0.1260220855474472, -1.222344160079956, -1.6351840496063232, 0.19203439354896545, -0.11176688224077225, -0.20457610487937927, -0.5263523459434509, 0.13003572821617126, 0.12505656480789185, -0.061118319630622864, -0.16753973066806793, 0.23565959930419922, -0.6969987750053406, -0.3042893707752228, 0.13224665820598602, -0.3826275169849396, 0.39289677143096924, 0.377334326505661, -0.7941206097602844, -0.3852749764919281, 0.9670414328575134, 0.06493549793958664, -1.0755259990692139, -0.48317673802375793, 0.16960392892360687, -0.8317099809646606, 0.526731014251709, -0.25868359208106995, 0.021310774609446526, -0.9937135577201843, -0.6385406851768494, 0.3615294098854065, 0.2992626428604126, -0.10270410031080246, 0.5695408582687378, 0.1890655905008316, -1.3087742328643799, -0.4284343719482422, 0.3806992471218109, -0.272541344165802, -0.6281540989875793, 0.34969252347946167, 0.693988561630249, -0.5821888446807861, 0.47712188959121704, 0.10290896892547607, 0.21646837890148163, -0.3326755166053772, 0.13160189986228943, 0.6679934859275818, -0.6308104991912842, 0.00548868253827095, 1.0130419731140137, -0.6183338165283203, -1.445747971534729, -0.2899761199951172, -0.6943649053573608, -0.3605745732784271, -0.4731796383857727, 1.0239723920822144, -0.06435251981019974, 0.12304139882326126, -0.21109835803508759, -0.6335639357566833, 0.3258301317691803, 0.37994542717933655, -1.0396075248718262, 0.645902693271637, -0.35566434264183044, -0.5850628614425659, 0.20300841331481934, 0.08185745775699615, -0.07216238975524902, -0.19815996289253235, -0.5749219655990601, -0.668292224407196, -0.2960016429424286, 0.22201929986476898, -0.8284348845481873, -0.6984832286834717, 0.7625059485435486, 0.3144606649875641, 0.08771105110645294, 0.8966363668441772, -0.2725259065628052, 0.34427177906036377, 0.27761200070381165, 0.37986254692077637, -0.5101250410079956, -0.43283775448799133, 1.2305961847305298, 1.3183211088180542, -1.0254734754562378, 0.26976215839385986, -0.0006760277319699526, -0.9930375814437866, 0.8015277981758118, 0.14673735201358795, 0.28610193729400635, 0.5439749360084534, -0.3361819088459015, 0.6542494297027588, 0.5787420868873596, -0.7388085722923279, -0.1920556128025055, 0.8299531936645508, 1.47089684009552, 0.9422730207443237, 0.07352761924266815, -0.19831417500972748, 0.9011144042015076, 0.0784967690706253, 0.24948057532310486, 0.5516084432601929, 0.32434093952178955, -0.19310882687568665, -0.7396503686904907, -0.5166035294532776, -0.019231347367167473, -0.4195382595062256, -0.6717568635940552, -0.2884185016155243, 0.9422966241836548, 0.21696050465106964, 1.070694088935852, 0.570353090763092, -0.29202866554260254, 0.4693676233291626, 0.26592543721199036, 0.8576923608779907, -0.45307353138923645, -0.19400815665721893, -0.00575955118983984, -0.5133615732192993, 0.36876198649406433, -0.2486480474472046, -0.3824768364429474, -0.15513980388641357, -0.44937410950660706, 0.30706337094306946, 0.018230289220809937, 0.5776671767234802, 1.125535011291504, 0.30675193667411804, 0.2069086730480194, -0.09134651720523834, -0.4645215570926666, -0.4009787142276764, -1.1277810335159302, 0.40964367985725403, -0.3731798827648163, -0.20002837479114532, -0.22461950778961182, 0.39546412229537964, -0.12691961228847504]}, "authors": [{"authorId": "9400076", "name": "Yasmin Moslem"}, {"authorId": "1748844", "name": "Rejwanul Haque"}, {"authorId": "1380281888", "name": "John D. Kelleher"}, {"authorId": "144315616", "name": "Andy Way"}], "references": [{"paperId": "8b3a67c7e5289eed160d2acfd04d71cfb552c67d", "title": "Branch-Train-Merge: Embarrassingly Parallel Training of Expert Language Models"}, {"paperId": "daa3af99c6421a60e4dc06cb27fc97a60a1aa54b", "title": "Alexa Teacher Model: Pretraining and Distilling Multi-Billion-Parameter Encoders for Natural Language Understanding Systems"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "7a25155364476839b6d1fc0653cd8611327ab9ba", "title": "mGPT: Few-Shot Learners Go Multilingual"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "55b9a2ade0a49e9cf10b71528d69dfee4e826025", "title": "Cedille: A large autoregressive French language model"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "de068215c44e2a9cd40e0d52e851666cda29ee6a", "title": "Sentence Augmentation for Language Translation Using GPT-2"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "972706306f85b1bfb40c7d35c796ad5174eb0c9c", "title": "DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing"}, {"paperId": "7798c3759a1284ccfd0d44eb38ec80d08be254db", "title": "Recent advances of low-resource neural machine translation"}, {"paperId": "4c5f4ddc68be643fb34ea969bf2c105ff7538995", "title": "Can Language Models be Biomedical Knowledge Bases?"}, {"paperId": "0857bff865fd772d34566f62e0ff698e7d0717aa", "title": "Survey of Low-Resource Machine Translation"}, {"paperId": "3631f9a372bfaee6d5448780548fccc9e6e81d87", "title": "Facebook AI\u2019s WMT21 News Translation Task Submission"}, {"paperId": "36de6b3b18ea763619bdca2d39035a8adf1582d2", "title": "Language Models are Good Translators"}, {"paperId": "789b8487da7188442085983caba3ffaae05531e9", "title": "The Flores-101 Evaluation Benchmark for Low-Resource and Multilingual Machine Translation"}, {"paperId": "368ba3d484c93d60408352eef87358790d2cef94", "title": "Improving the Lexical Ability of Pretrained Language Models for Unsupervised Neural Machine Translation"}, {"paperId": "75ee15ddebceb3313bd6fa95fa72325bf64b5363", "title": "Multi-Domain Adaptation in Neural Machine Translation Through Multidimensional Tagging"}, {"paperId": "c7ab9761a25f730de840e9b140bd77551746314a", "title": "Neural Data-to-Text Generation with LM-based Text Augmentation"}, {"paperId": "c342798bafc1eaaa60c652fc90fd738941542133", "title": "AraGPT2: Pre-Trained Transformer for Arabic Language Generation"}, {"paperId": "cc50f846ed7222698d130cddbc58ed4d547914ed", "title": "CPM: A Large-scale Generative Chinese Pre-trained Language Model"}, {"paperId": "c204d40384d39c59cd7249bde4cd8615972acaac", "title": "Findings of the WMT 2020 Shared Task on Machine Translation Robustness"}, {"paperId": "02436c658df06542a13432eba260777a299f245c", "title": "The OpenNMT Neural Machine Translation Toolkit: 2020 Edition"}, {"paperId": "9e67b9758520e49016ab66bafb974d2e1ed762d1", "title": "COMET: A Neural Framework for MT Evaluation"}, {"paperId": "5431098723db5858c4553f0259921cbbdd6492d5", "title": "TICO-19: the Translation Initiative for Covid-19"}, {"paperId": "b390df1a35c2a493ad2a796a6ac68f49be8a43d2", "title": "Boosting Neural Machine Translation with Similar Translations"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "dc373d5e108a90a70f55285a852a32706adbeb45", "title": "Incorporating BERT into Neural Machine Translation"}, {"paperId": "1628974fa1f1481d4d5f735009b75daedec9d877", "title": "Domain, Translationese and Noise in Synthetic Data for Neural Machine Translation"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "d0086b86103a620a86bc918746df0aa642e2a8a3", "title": "Language Models as Knowledge Bases?"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "4ba55448a9a978e01a33638f5b294a9db1d5920b", "title": "Neural Fuzzy Repair: Integrating Fuzzy Matches into Neural Machine Translation"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "6e722ac4d386489aa47703887881835ec0e1331d", "title": "Tagged Back-Translation"}, {"paperId": "d0248b1ddf76b125b5c0b6006e93be636e0a4d90", "title": "Adaptation of Machine Translation Models with Back-translated Data using Transductive Data Selection Methods"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc", "title": "Cross-lingual Language Model Pretraining"}, {"paperId": "e6deb7f451931b28bc6936d5fa703bc392c4cf4c", "title": "Using Monolingual Data in Neural Machine Translation: a Systematic Study"}, {"paperId": "08170cde0cdeef674a78bdff5680adeb365844d4", "title": "Back-Translation Sampling by Targeting Difficult Words in Neural Machine Translation"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "0669f0a031cfaada55841e5962eb6796d4e94971", "title": "Iterative Back-Translation for Neural Machine Translation"}, {"paperId": "29de7c0fb3c09eaf55b20619bceaeafe72fd87a6", "title": "Hierarchical Neural Story Generation"}, {"paperId": "6db2b93a2d4007371030644173f1001c959214d2", "title": "Learning to Write with Cooperative Discriminators"}, {"paperId": "e73bd7f9bdc262b9b7fb60ca0d5230d3ab0fad5e", "title": "Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates"}, {"paperId": "b4bfadfca9742bb3ee98a0cd322d5ce4e59a3ceb", "title": "A Call for Clarity in Reporting BLEU Scores"}, {"paperId": "a5ae9a23a587dee02aedeb3ec271de0da95eabe4", "title": "Effective Domain Mixing for Neural Machine Translation"}, {"paperId": "0b1317a42760d4de86d721a867e340db4d6b0810", "title": "Multi-Domain Neural Machine Translation through Unsupervised Adaptation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "106d5e0cf44ea08500adc91c4d5bb3e6c8a4d627", "title": "Six Challenges for Neural Machine Translation"}, {"paperId": "b67fd687df7d4f5a6fe889dda778c485c729a6ce", "title": "Domain Control for Neural Machine Translation"}, {"paperId": "2e55ba6c97ce5eb55abd959909403fe8da7e9fe9", "title": "Overcoming catastrophic forgetting in neural networks"}, {"paperId": "f3b96ef2dc1fc5e14982f1b963db8db6a54183bb", "title": "Improving Neural Machine Translation Models with Monolingual Data"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "25ca4a36df2955b345634b5f8a6b6bb66a774b3c", "title": "Parallel Data, Tools and Interfaces in OPUS"}, {"paperId": "f493b8a1f05fd788b1bcaecf18eb87a3f5965b35", "title": "Correlating automated and human assessments of machine translation quality"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "6924cef6e203834bc2533d1f8c30179182736ba1", "title": "Motivations"}, {"paperId": "70f8e3c72e9178b408667e3619a87a153fd853e6", "title": "Foundation Models of Scientific Knowledge for Chemistry: Opportunities, Challenges and Lessons Learned"}, {"paperId": "354baa59362da14e2d6f50d5ebaa76f672d0f7af", "title": "Improving the Quality Trade-Off for Neural Machine Translation Multi-Domain Adaptation"}, {"paperId": "d64d09c6d72a92b8dda87eca50513a9ba2bc8542", "title": "Findings of the WMT 2021 Shared Task on Large-Scale Multilingual Machine Translation"}, {"paperId": "1ab0511020509a4953107da42a5ce96f8470cda0", "title": "Findings of the WMT 2020 Biomedical Translation Shared Task: Basque, Italian and Russian as New Additional Languages"}, {"paperId": null, "title": "ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Understanding Back-Translation at Scale"}, {"paperId": "256365e6007b2aa1e4356f9979a1ba83b9041d1e", "title": "An Empirical Comparison of Domain Adaptation Methods for Neural Machine Translation"}, {"paperId": "4a30e0193889fca9c34cbf4e4e42ac2fe3db9f79", "title": "chrF++: words helping character n-grams"}, {"paperId": "024a7cf98b5498ac181054cb6d0543b33a7f6c40", "title": "Adapting Neural Machine Translation with Parallel Synthetic Data"}, {"paperId": null, "title": "We apply mixed \ufb01ne-tuning proposed by Chu et al."}, {"paperId": "2826f9dccdcceb113b33ccf2841d488f1419bb30", "title": "Stanford Neural Machine Translation Systems for Spoken Language Domains"}, {"paperId": null, "title": "BigScience Language Open-science Open-access Multilingual (BLOOM) Language Model"}]}