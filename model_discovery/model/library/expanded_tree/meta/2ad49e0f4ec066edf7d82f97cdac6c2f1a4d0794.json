{"paperId": "2ad49e0f4ec066edf7d82f97cdac6c2f1a4d0794", "abstract": "Fine-tuning a pre-trained language model (PLM) emerges as the predominant strategy in many natural language processing applications. However, even fine-tuning the PLMs and doing inference are expensive, especially on edge devices with low computing power. Some general approaches (e.g. quantization and distillation) have been widely studied to reduce the compute/memory of PLM fine-tuning, while very few one-shot compression techniques are explored. In this paper, we investigate the neural tangent kernel (NTK)--which reveals the gradient descent dynamics of neural networks--of the multilayer perceptrons (MLP) modules in a PLM and propose to coin a lightweight PLM through NTK-approximating MLP fusion. To achieve this, we reconsider the MLP as a bundle of sub-MLPs, and cluster them into a given number of centroids, which can then be restored as a compressed MLP and surprisingly shown to well approximate the NTK of the original PLM. Extensive experiments of PLM fine-tuning on both natural language understanding (NLU) and generation (NLG) tasks are provided to verify the effectiveness of the proposed method MLP fusion. Our code is available at https://github.com/weitianxin/MLP_Fusion.", "venue": "International Conference on Machine Learning", "year": 2023, "citationCount": 5, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2307.08941", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "The neural tangent kernel (NTK)--which reveals the gradient descent dynamics of neural networks--of the multilayer perceptrons (MLP) modules in a PLM is investigated and proposed to coin a lightweight PLM through NTK-approximating MLP fusion, which is surprisingly shown to well approximate the NTK of the original PLM."}, "embedding": {"model": "specter_v2", "vector": [0.010692410171031952, 0.5793493390083313, -0.42933234572410583, -0.1250319927930832, -0.4337277114391327, -0.024185366928577423, 0.7234618067741394, 0.029404545202851295, -0.5510332584381104, -0.42976564168930054, 0.8316811323165894, 0.046217843890190125, 0.3991219401359558, 0.18051685392856598, -0.1748175472021103, 0.1264367699623108, -0.4106287658214569, 0.09378010034561157, -0.491569459438324, -0.2914140224456787, -0.14263781905174255, -0.8171789050102234, -1.0279638767242432, 0.17300835251808167, 0.5839561223983765, 0.7424917221069336, 0.0909666195511818, 1.1908657550811768, -0.5459269881248474, -0.006916937418282032, 0.6300405859947205, -0.6265330910682678, 0.23280830681324005, 0.08660333603620529, -0.3255273401737213, 0.05713367089629173, 0.08348750323057175, -0.5237971544265747, -0.2728450894355774, 1.0523818731307983, -0.17980046570301056, 0.43832066655158997, 0.615257978439331, -0.42300519347190857, -0.42947790026664734, 0.8073119521141052, 0.5379729866981506, 0.36067116260528564, -0.43922847509384155, -0.5984524488449097, 1.0584666728973389, -1.303537130355835, -0.21306362748146057, 1.657073736190796, 0.5179581046104431, 0.2351873517036438, -0.1852598488330841, -0.42394688725471497, 0.41093355417251587, 0.007190894801169634, -0.8479719758033752, -0.5484486222267151, -0.05827844515442848, -0.03823321312665939, 1.7756785154342651, -0.34111952781677246, -0.16890589892864227, 0.361473023891449, 0.013467027805745602, 1.384759783744812, -0.2012334018945694, -0.9309828877449036, -0.1364818662405014, 0.02666155993938446, 0.293400377035141, 0.6847003102302551, -0.4390380382537842, 0.46350449323654175, -0.9498344659805298, -0.25898441672325134, 0.15096110105514526, 0.034102071076631546, 0.039602041244506836, 0.19911418855190277, -0.17080993950366974, 0.8803993463516235, 0.4592346251010895, 0.6633583307266235, -0.11363887041807175, 1.045850396156311, 0.9259304404258728, 0.23461031913757324, 0.37698113918304443, 0.2524676024913788, -0.08948784321546555, 0.09729283303022385, -1.1959197521209717, 0.20880505442619324, 0.07250043749809265, 0.508819580078125, 0.041154347360134125, 0.1995624303817749, -0.8878668546676636, 0.477822482585907, 1.4017231464385986, -0.05290159583091736, 0.6075950264930725, -0.9876900315284729, 0.37860235571861267, -0.9436532855033875, -0.18656466901302338, -0.5460143685340881, -0.010790372267365456, -0.020731959491968155, -1.1413679122924805, -1.1871261596679688, -0.6188720464706421, -0.1870688945055008, -0.96617591381073, 0.6123528480529785, -0.5236787796020508, 0.26827821135520935, 0.4442494809627533, 0.5334843993186951, 0.14835494756698608, 0.9491214156150818, 0.2769036591053009, 0.05292128771543503, 1.1157386302947998, -1.0634682178497314, -0.8828200697898865, -0.7752828001976013, 0.934634268283844, -0.5167211294174194, 0.244107186794281, -0.2580055296421051, -1.2287837266921997, -1.2029169797897339, -0.842976450920105, -0.2508913278579712, -0.46088576316833496, 0.7988330125808716, 1.1336030960083008, 0.5885568857192993, -0.893689751625061, 1.194589614868164, -0.1805517077445984, -0.3353116512298584, 0.38936057686805725, 0.028374873101711273, 0.2832276523113251, -0.3542385995388031, -1.3374578952789307, 0.26697424054145813, 0.6915128231048584, -0.37525489926338196, 0.0863608717918396, -0.5424656867980957, -0.9625120759010315, 0.092691570520401, 0.2714230716228485, -0.8829324245452881, 1.514356255531311, 0.2816700041294098, -1.7825101613998413, 0.2048014998435974, -0.2781563699245453, -0.050017040222883224, 0.15348047018051147, -0.34419819712638855, -0.6061139702796936, -0.5515409708023071, -0.31410640478134155, 0.8388434052467346, 0.6618444919586182, 0.24679133296012878, -0.4090834856033325, 0.2616041302680969, -0.4987274408340454, 0.4141463339328766, -0.4719751179218292, 0.5936300158500671, -0.41035109758377075, -0.45683377981185913, 0.37602025270462036, 0.8333012461662292, 0.03489117696881294, -0.4071809947490692, -0.6906952261924744, -1.074492335319519, 0.8478970527648926, -0.10560636967420578, 0.8267403244972229, -1.0273290872573853, -0.8593788743019104, -0.3079324960708618, -0.03727811574935913, 0.15311254560947418, -0.8358851075172424, 0.6770637631416321, -0.01000304240733385, 0.4355529248714447, 0.10195761919021606, -1.526835560798645, 0.6007251739501953, -0.21890883147716522, -0.9659696221351624, -0.26722225546836853, 0.18250496685504913, 1.330074667930603, -0.8467245697975159, 0.27358588576316833, -0.07384578138589859, 0.3926335871219635, -0.8358281850814819, 1.125740885734558, -0.40109696984291077, -0.07142960280179977, 0.22585728764533997, -0.08688890933990479, 0.11886951327323914, 0.007618775125592947, -0.025526007637381554, -0.6082768440246582, 0.040461134165525436, 0.5045148134231567, -0.5637670755386353, 1.8256670236587524, -0.15435920655727386, 0.7012656331062317, -0.2571604251861572, -0.44265708327293396, 0.27672603726387024, 0.6128922700881958, -0.7024866938591003, -0.06657492369413376, 0.3848714530467987, 0.6963932514190674, -0.7455359697341919, 0.47557899355888367, 1.0883023738861084, 0.5971112251281738, -0.527868390083313, 0.2741539478302002, 0.8129889369010925, -0.6124956607818604, 0.580088198184967, 0.28904449939727783, 0.40439876914024353, 0.12522301077842712, 0.4204801619052887, 0.18562200665473938, 0.2084575742483139, -1.0493924617767334, -0.35808491706848145, 0.8237085342407227, 0.5570656657218933, 0.9581864476203918, 0.15979498624801636, -0.598983645439148, -0.43044963479042053, -0.07195238769054413, 0.7342211604118347, 1.6627980470657349, -0.3170250952243805, -0.10955759137868881, -0.9189261794090271, -0.10382061451673508, -0.20560133457183838, 0.08324752002954483, -0.1825319528579712, -0.3116855025291443, -0.16014982759952545, -1.1785814762115479, 1.244220495223999, -0.004336575511842966, 1.1415656805038452, -0.3452102541923523, 0.14322449266910553, -0.12921567261219025, 0.31071341037750244, -0.6720743179321289, -0.9586334228515625, 0.3019064962863922, -0.4318850636482239, 0.2501533329486847, -0.23713667690753937, 0.11506057530641556, -0.14151589572429657, -0.8252450823783875, 0.6141309142112732, -0.7346384525299072, -0.06464404612779617, -0.2162122279405594, 0.46434953808784485, -0.7288476228713989, -0.8687753677368164, 0.5933132171630859, 0.5240834355354309, 0.05220156908035278, 0.40232834219932556, 0.6038345098495483, 0.15107934176921844, -0.6982530355453491, -0.2979968786239624, 0.13585937023162842, 0.08606582134962082, -0.22936195135116577, 0.6874183416366577, -0.2516237795352936, 0.09330812841653824, -1.0162391662597656, 1.5693830251693726, 0.35201314091682434, -0.3101005554199219, 0.2764418125152588, -0.6360700130462646, -0.06832469254732132, 0.5865032076835632, -0.6133307218551636, -0.5174609422683716, -0.95943284034729, 0.20268669724464417, -0.40043747425079346, -0.503594696521759, 0.2113676816225052, 0.4706950783729553, 0.23028802871704102, 0.2263273149728775, 0.4285397529602051, 0.2555963099002838, -0.40653195977211, 1.2208399772644043, -0.46545127034187317, 1.0089353322982788, 0.33405032753944397, 0.08686168491840363, -0.2589547634124756, -0.583665668964386, -0.5640230774879456, -0.47728967666625977, -0.5347967147827148, -0.27450188994407654, -0.018934153020381927, 0.31460899114608765, -0.62137371301651, -0.8510128259658813, -0.18527273833751678, -1.3292332887649536, 0.3238614499568939, -0.23939110338687897, 0.07991166412830353, -0.4426896572113037, -0.8614011406898499, -1.5808429718017578, -0.5667415261268616, -0.9738273620605469, -0.8510239124298096, 0.368673175573349, 0.2854539155960083, -0.22793401777744293, -0.4807828366756439, 0.20715992152690887, -0.48702603578567505, 1.1291873455047607, -0.9568434953689575, 0.7531041502952576, -0.1214321106672287, 0.18134662508964539, -0.055920276790857315, -0.129596546292305, 0.9636067152023315, -0.20257049798965454, 0.07552403211593628, -1.2127859592437744, 0.13611964881420135, -0.12420109659433365, -0.2812577784061432, 0.4737149477005005, 0.4489079415798187, 0.45273542404174805, -0.05595214664936066, -0.41095077991485596, 0.8295196890830994, 1.3315850496292114, -0.8601046204566956, -0.14602845907211304, -0.32964104413986206, 0.9990662932395935, 0.017286861315369606, -0.5508811473846436, 0.5160889625549316, 0.21401473879814148, 0.2708296477794647, -0.07572250813245773, -0.13331112265586853, -0.335940420627594, -0.5619012713432312, 0.5784454941749573, 2.164524555206299, 0.4591834843158722, 0.026891300454735756, -0.8843106627464294, 0.42257022857666016, -1.3840277194976807, -0.5102088451385498, 0.8667564988136292, 0.40810874104499817, 0.31799009442329407, -0.3980764150619507, -0.5811145901679993, -0.14321334660053253, 0.2844353914260864, 0.57867830991745, -0.38653454184532166, -1.2963696718215942, 0.13179443776607513, -0.10145948082208633, 0.19244511425495148, 0.5885235667228699, -0.5820542573928833, 0.6000822186470032, 14.429450988769531, 1.338779330253601, -0.07336928695440292, 0.5656904578208923, 0.7124354839324951, 0.39212098717689514, -0.12512123584747314, -0.2352689504623413, -1.33819580078125, -0.19854432344436646, 1.12398362159729, -0.09633908420801163, 0.8218022584915161, 0.14106179773807526, -0.035734474658966064, 0.4123171865940094, -0.5938917994499207, 1.0951989889144897, 0.37364140152931213, -1.8166413307189941, 0.5248151421546936, 0.16050514578819275, 0.8317208290100098, 0.8922953605651855, 0.6751779913902283, 0.9594754576683044, 0.34593358635902405, -0.22752490639686584, 0.42506805062294006, 0.4770432412624359, 0.8263683319091797, -0.14917537569999695, 0.6405453681945801, 0.7980639338493347, -0.9145134687423706, -0.2869911193847656, -0.7931601405143738, -1.16660737991333, 0.41210904717445374, 0.4187640845775604, -0.5116766095161438, -0.27353334426879883, -0.34918665885925293, 0.5744370818138123, 0.14543119072914124, 0.34685781598091125, -0.05262597277760506, 0.4832487106323242, -0.26227420568466187, 0.18277966976165771, 0.5795472860336304, 0.12853503227233887, 0.3107048571109772, 0.34366920590400696, 0.21991509199142456, -0.18222948908805847, 0.1423729807138443, 0.652286946773529, -0.9861406087875366, -0.031680360436439514, -0.10974328219890594, -0.29920831322669983, -0.07020393013954163, 0.7387546896934509, 0.6679834127426147, -0.05242067947983742, -0.1819630116224289, 0.6467218399047852, 0.8750293850898743, 0.45719337463378906, -0.01746431551873684, -0.41642671823501587, 0.45366808772087097, -0.7105485796928406, 0.11402146518230438, 0.6217117309570312, -0.4334629774093628, -0.6385127902030945, -0.6761376261711121, -0.22346913814544678, -0.05241582542657852, -0.668960690498352, -0.956356406211853, 0.7304478883743286, -0.3783959448337555, 0.05077024921774864, -0.08710477501153946, -0.4389619529247284, -0.4403701424598694, 0.7051711678504944, -1.4931608438491821, -0.4955654442310333, 0.7891554832458496, -0.8095494508743286, -0.36165720224380493, -0.22292262315750122, 1.3935787677764893, 0.13512392342090607, -0.48377665877342224, -0.06026464328169823, 0.4058269262313843, -0.12046857178211212, -0.34234195947647095, -0.6105049252510071, 1.0890381336212158, 0.4006851315498352, -0.056715331971645355, 0.025153927505016327, -0.334110289812088, 0.3331095278263092, -0.35863661766052246, -0.3197181224822998, 0.7462432980537415, -0.2871139347553253, -0.586784303188324, -0.7825296521186829, -0.935016930103302, -0.1349131017923355, 0.7053107619285583, -0.21433258056640625, 0.18118560314178467, 0.03380244970321655, -0.6051861643791199, -0.053687091916799545, -0.6725025773048401, 0.21338601410388947, -0.045124150812625885, -1.1931401491165161, -0.40872669219970703, 0.05870755761861801, 0.6700870394706726, -0.8010400533676147, -0.6556013226509094, -0.13722148537635803, -0.13137920200824738, 0.01326522696763277, 1.036389708518982, -0.20058922469615936, 0.4756819009780884, 0.7765430212020874, -0.3014114499092102, -0.749154806137085, 0.1605612337589264, -0.9939736127853394, -0.19989414513111115, 0.3647322654724121, 0.43530118465423584, -0.08607441186904907, 0.39400386810302734, 0.7899483442306519, 0.1974741369485855, -0.7409796714782715, -0.6580491662025452, -0.23146675527095795, -0.0921861082315445, -1.0377659797668457, 0.5160830616950989, -0.36959806084632874, 0.11263760179281235, 0.09035281091928482, 0.4325467348098755, 0.5984399914741516, -0.11838740855455399, -0.7473515272140503, 0.061963729560375214, 0.190085768699646, -0.21450817584991455, -0.7356917262077332, -0.273903489112854, -1.5649276971817017, -0.08702151477336884, -1.40188729763031, -0.04833308979868889, -0.9008549451828003, -0.5410715937614441, 0.34396588802337646, -0.1092422604560852, -0.04154786467552185, 0.25201576948165894, -0.17902223765850067, 0.1233743205666542, -0.26520705223083496, -0.4352242052555084, 1.1580673456192017, 0.7385624051094055, -0.8033525347709656, -0.17671671509742737, 0.025394750759005547, 0.08832821995019913, 0.5708754658699036, 0.5324857234954834, -0.45459404587745667, -0.7322630882263184, -1.2908596992492676, 0.06815202534198761, -0.12747736275196075, -0.22851064801216125, -0.9204340577125549, 1.0255039930343628, 0.6955831050872803, -0.21666385233402252, -0.06858237087726593, 0.3803442120552063, -0.4376065731048584, -0.6166624426841736, 0.29554304480552673, -0.9960678815841675, -0.2082848995923996, -0.057857394218444824, -0.4370158910751343, -0.49923574924468994, 0.4252879023551941, -0.24621427059173584, -0.7190008163452148, -0.7289295196533203, 0.48771947622299194, -0.26147347688674927, 0.02794264815747738, -0.7233647704124451, -0.04035313054919243, -1.0481898784637451, -0.34238800406455994, -0.009458391927182674, 0.046227578073740005, -0.5188398957252502, 0.7844870686531067, 0.46312251687049866, -1.3716429471969604, -0.04652225598692894, 0.516322910785675, -0.10595287382602692, -0.20744743943214417, 0.4746800363063812, 0.39889758825302124, -0.08317835628986359, 0.6653098464012146, 0.6772447228431702, 0.3297026753425598, -0.5011789202690125, -0.07676736265420914, 0.6701537370681763, -0.7519669532775879, -0.20912884175777435, 1.1084092855453491, -0.5404983162879944, -1.3691121339797974, 0.1924157291650772, -1.4814585447311401, -0.31107261776924133, -0.3024318814277649, 0.6961219310760498, 0.2254244089126587, 0.1782955527305603, 0.06026197969913483, -0.17520210146903992, 0.06290596723556519, -0.2413366287946701, -0.718865692615509, 0.29011133313179016, -0.4111553430557251, -0.4204908609390259, 0.632544994354248, 1.2658987045288086, -1.1006113290786743, -0.9493370056152344, -0.9027801752090454, -0.14623384177684784, 0.014948568306863308, 0.37864530086517334, -0.18885932862758636, -0.314972460269928, 0.8969607949256897, 0.4741056263446808, 0.281178742647171, 0.07502128928899765, -0.2826066315174103, 0.5718406438827515, 0.9367785453796387, -0.22036020457744598, -0.9044737219810486, -0.6347195506095886, 1.4585875272750854, 1.1758123636245728, -0.9839066863059998, 0.0671282559633255, -0.1277933567762375, -0.7958463430404663, 1.0613672733306885, -0.23863951861858368, 0.008163942955434322, 1.0480033159255981, -0.3336901366710663, 0.18190407752990723, 0.2745392322540283, -1.0969974994659424, -0.33445197343826294, 1.0005801916122437, 0.8957656025886536, 0.4931851327419281, 0.4668126702308655, 0.3432493805885315, 0.8280541300773621, -0.07070733606815338, 0.17086559534072876, 0.42649850249290466, 0.2054455578327179, -0.357885479927063, -0.07882978767156601, -0.2553708851337433, 0.9455490708351135, -0.5119215250015259, -0.596173107624054, 0.703208863735199, 0.2217956930398941, 0.42122504115104675, 0.6776577234268188, 0.6433138847351074, -0.10074050724506378, 0.45847389101982117, 0.33218473196029663, 0.13972590863704681, -0.5109297037124634, -0.21208271384239197, -0.013583107851445675, -0.7722094058990479, -0.041474249213933945, -0.0811881422996521, -0.4360453188419342, -0.48807293176651, -0.42390838265419006, 0.3301927447319031, -0.1391678899526596, 0.6589379906654358, 1.3782563209533691, 0.6904837489128113, 0.3098466694355011, -0.47866734862327576, -0.7727140188217163, -0.7531362175941467, -0.9105635285377502, -0.3205777406692505, -0.2933526337146759, -0.13144421577453613, 0.29436835646629333, -0.10799787938594818, -0.2016763985157013]}, "authors": [{"authorId": "2068207615", "name": "Tianxin Wei"}, {"authorId": "120731124", "name": "Zeming Guo"}, {"authorId": "2109142009", "name": "Yifan Chen"}, {"authorId": "31108652", "name": "Jingrui He"}], "references": [{"paperId": "b935c81a7d4c706d311f8ec518e740575b6b0102", "title": "\"Lossless\" Compression of Deep Neural Networks: A High-dimensional Neural Tangent Kernel Approach"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "289700f4570733b612147883ad29b963bbffe31a", "title": "Inducer-tuning: Connecting Prefix-tuning and Adapter-tuning"}, {"paperId": "9a1d94a930168918a1a1e1939b089d16d58d7865", "title": "A Kernel-Based View of Language Model Fine-Tuning"}, {"paperId": "ea528a93a4413cbfdb3062fbc28ce216d9aebabb", "title": "Augmentations in Hypergraph Contrastive Learning: Fabricated and Generative"}, {"paperId": "38cc471221bcebe9ebae75268001b268b507ca0e", "title": "Comprehensive Fair Meta-learned Recommender System"}, {"paperId": "05d70085d1b580b2369942410ae77c48d1eeacca", "title": "Exploring Extreme Parameter Compression for Pre-trained Language Models"}, {"paperId": "2190519a4c695b5d57a5b1e37e91c570f81cc4f1", "title": "Empowering parameter-efficient transfer learning by recognizing the kernel structure in self-attention"}, {"paperId": "8326dba15f6b8ee6e43c23eea3265a05e59e8135", "title": "Monarch: Expressive Structured Matrices for Efficient and Accurate Training"}, {"paperId": "df602516e28a9ef0ef665ed0aef551984d8d770d", "title": "Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5)"}, {"paperId": "ad9effaa6c12330f24e34bd3fa5d1496acc113af", "title": "More Than a Toy: Random Matrix Models Predict How Real-World Neural Representations Generalize"}, {"paperId": "c7b09b6c523298af7da994d6ede75f1f25b04afe", "title": "Rare Gems: Finding Lottery Tickets at Initialization"}, {"paperId": "a68ab49816d5729435c3d994b434c75c6f162da0", "title": "Sketching as a Tool for Understanding and Accelerating Self-attention for Long Sequences"}, {"paperId": "4b0541eccd8f98852d6807a14fbac17f775c7b40", "title": "Skyformer: Remodel Self-Attention with Gaussian Kernel and Nystr\u00f6m Method"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "6cf9e18bff20eca4ddfeb50ae069f8cc994f9d27", "title": "Model Compression Using Optimal Transport"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "389036b1366b64579725457993c1f63a4f3370ba", "title": "The Lottery Ticket Hypothesis for Pre-trained BERT Networks"}, {"paperId": "056935031bc5cf0aeeaa0946320de26e14a1817e", "title": "Revisiting Few-sample BERT Fine-tuning"}, {"paperId": "3b0fb765716ef6861a84abffcbe40643857c613b", "title": "Pruning neural networks without any data by iteratively conserving synaptic flow"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "d7c4b8f15f82825de9edcf57e499b05256c7885d", "title": "Text-to-Text Pre-Training for Data-to-Text Tasks"}, {"paperId": "90a1491ac32e732c93773354e4e665794ed4d490", "title": "DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference"}, {"paperId": "5d34881ff68bd203ff790187e7e5c9e034389cfa", "title": "FastBERT: a Self-distilling BERT with Adaptive Inference Time"}, {"paperId": "c6c734e16f66fbfcefac7625cc64599e83292c1e", "title": "MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers"}, {"paperId": "c114ce10c4a315d92c3815f54bc9893e7e6ef182", "title": "Picking Winning Tickets Before Training by Preserving Gradient Flow"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "261004890f902acd810ac4e9b1025ca5981ceedf", "title": "Model Fusion via Optimal Transport"}, {"paperId": "83b8108014e3db4f46354a28ae68193f143c4e7e", "title": "Structured Pruning of Large Language Models"}, {"paperId": "51ea1137e418a0e0042388e2b899727c69a4a365", "title": "Distributed Learning of Fully Connected Neural Networks using Independent Subnet Training"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "1029daa28aa772e441470e61bdd610c222e92932", "title": "On Exact Computation with an Infinitely Wide Neural Net"}, {"paperId": "cf440ccce4a7a8681e238b4f26d5b95109add55d", "title": "SNIP: Single-shot Network Pruning based on Connection Sensitivity"}, {"paperId": "7a84a692327534fd227fa1e07fcb3816b633c591", "title": "Neural Tangent Kernel: Convergence and Generalization in Neural Networks"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "41a78e2885b5dc8c719495a33985b5f4880f5b48", "title": "Speech-Transformer: A No-Recurrence Sequence-to-Sequence Model for Speech Recognition"}, {"paperId": "21937ecd9d66567184b83eca3d3e09eb4e6fbd60", "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "90a16f34d109b63d95ab4da2d491cbe3a1c8b656", "title": "Learning Efficient Convolutional Networks through Network Slimming"}, {"paperId": "e4da4fb310df2bfa5b9aab217982723634bda4bc", "title": "Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff", "title": "Learning both Weights and Connections for Efficient Neural Network"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "ecbea3b74deb06657a2d0100a717501f7d1a252a", "title": "Sketching as a Tool for Numerical Linear Algebra"}, {"paperId": "e5ae8ab688051931b4814f6d32b18391f8d1fa8d", "title": "Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "2a941e7c5f374f8f8dba0daf6ffc6504a2779473", "title": "The Fast Johnson--Lindenstrauss Transform and Approximate Nearest Neighbors"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "9241ea3d8cb85633d314ecb74b31567b8e73f6af", "title": "Least squares quantization in PCM"}, {"paperId": "03b4a233b19cf202ba9117d501a82a48ef3ed6e9", "title": "Cognitron: A self-organizing multilayered neural network"}, {"paperId": "34ddd8865569c2c32dec9bf7ffc817ff42faaa01", "title": "A Stochastic Approximation Method"}, {"paperId": "8c4e2a1c421d91a75961e1a91a378cbaf4289b0f", "title": ": Conditional Computation of Transformer Models for Ef\ufb01cient Inference"}, {"paperId": "acf87283fa8ae426f1a4987b345b401bf2913f61", "title": "Do Transformers Really Perform Badly for Graph Representation?"}, {"paperId": "08ee34a64247c0fe3c22b9f3c0848eb921041a8d", "title": "Supplementary Material: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Computational optimal transport: With applications to data science. Foundations and Trends\u00ae in Machine Learning"}, {"paperId": null, "title": "Universal language model \ufb01ne-tuning for text classi\ufb01cation"}, {"paperId": null, "title": "Like what you like: Knowledge distill via neuron selectivity transfer"}, {"paperId": "3d07b5087e53c6f7c228b3c7e769494527be228e", "title": "A Study of Translation Edit Rate with Targeted Human Annotation"}, {"paperId": "4774432f02ef4c5285952dd8c7daff0852c3a601", "title": "Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization"}, {"paperId": "6a106d66cc79632e661ed47070edbe6233a30177", "title": "Poor Man's Monte Carlo"}, {"paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5", "title": "of the Association for Computational Linguistics"}]}