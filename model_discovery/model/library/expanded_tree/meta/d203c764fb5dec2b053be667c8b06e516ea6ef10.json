{"paperId": "d203c764fb5dec2b053be667c8b06e516ea6ef10", "abstract": "Transformer-based language models have found many diverse applications requiring them to process sequences of increasing length. For these applications, the causal self-attention -- which is the only component scaling quadratically w.r.t. the sequence length -- becomes a central concern. While many works have proposed schemes to sparsify the attention patterns and reduce the computational overhead of self-attention, those are often limited by implementations concerns and end up imposing a simple and static structure over the attention matrix. Conversely, implementing more dynamic sparse attentions often results in runtimes significantly slower than computing the full attention using the Flash implementation from Dao et al. (2022). We extend FlashAttention to accommodate a large class of attention sparsity patterns that, in particular, encompass key/query dropping and hashing-based attention. This leads to implementations with no computational complexity overhead and a multi-fold runtime speedup on top of FlashAttention. Even with relatively low degrees of sparsity, our method improves visibly upon FlashAttention as the sequence length increases. Without sacrificing perplexity, we increase the training speed of a transformer language model by $2.0\\times$ and $3.3\\times$ for sequences of respectively $8k$ and $16k$ tokens.", "venue": "arXiv.org", "year": 2023, "citationCount": 11, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2306.01160", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work extends FlashAttention to accommodate a large class of attention sparsity patterns that, in particular, encompass key/query dropping and hashing-based attention, leading to implementations with no computational complexity overhead and a multi-fold runtime speedup on top of FlashAtt attention."}, "embedding": {"model": "specter_v2", "vector": [0.13235752284526825, 0.5590221881866455, -0.1419016718864441, 0.14536678791046143, -0.3432871997356415, -0.3099564015865326, 0.7955765724182129, -0.09041883796453476, -0.3279736638069153, 0.005415010266005993, 0.7419222593307495, 0.10414981096982956, 0.5495352745056152, 0.13427546620368958, -0.14841428399085999, 0.13380730152130127, -0.8586890697479248, 0.22816744446754456, 0.1504579484462738, -0.07605358958244324, 0.18792016804218292, -0.9035423994064331, -1.2796432971954346, -0.007288267835974693, 0.4979593753814697, 0.2818431556224823, 0.45060664415359497, 0.5869296789169312, -0.3330187499523163, 0.36744025349617004, 0.5346243381500244, -0.25662875175476074, 0.19228476285934448, -0.13213729858398438, -0.5194292664527893, -0.670961320400238, 0.650067925453186, -0.060902856290340424, -0.7354334592819214, 0.6976699233055115, -0.24463973939418793, 0.30938729643821716, -0.03531678393483162, -0.4428074061870575, -0.7167341113090515, 1.0117579698562622, 0.5013821125030518, 0.9799091219902039, 0.3880615532398224, -0.4410367012023926, 1.3408628702163696, -1.1196391582489014, 0.07251526415348053, 1.5254969596862793, 0.43640315532684326, 0.21672682464122772, 0.04653212055563927, -0.586762547492981, 0.7313393354415894, 0.5361122488975525, -0.8072242736816406, -0.04149229824542999, -0.18622072041034698, 0.14008192718029022, 1.8193391561508179, -0.26987919211387634, 0.3873652517795563, 0.7237478494644165, -0.04955783113837242, 1.4208627939224243, 0.008606243878602982, -0.5141426920890808, -0.3966347873210907, 0.21286870539188385, 0.2608986794948578, 0.6362220644950867, -0.571244478225708, 0.24168460071086884, -1.0481940507888794, -0.27082207798957825, 0.11712130159139633, 0.2961108386516571, 0.20333808660507202, -0.10367750376462936, -0.009653921239078045, 0.7690235376358032, 0.06078400835394859, 0.9467287063598633, -0.1068815290927887, 0.8401165008544922, 0.5905739665031433, 0.2790053188800812, -0.08523674309253693, 0.32384437322616577, 0.3256257474422455, 0.0057255057618021965, -0.8824610710144043, 0.3434341847896576, -0.041116584092378616, 1.3207764625549316, -0.1985049694776535, 0.6451566815376282, -0.3780609667301178, 0.00484119076281786, 0.9871055483818054, 0.6241735816001892, 0.5107753872871399, -0.5085693001747131, -0.34713679552078247, -0.6483627557754517, -0.25359201431274414, -0.750036895275116, 0.0108287762850523, -0.2937754690647125, -0.8881601095199585, -1.5881576538085938, -0.6145597100257874, 0.5089870691299438, -0.40673962235450745, 0.6316485404968262, -0.2942223846912384, 0.2402525097131729, -0.5131698250770569, 0.3486771285533905, 0.5378592610359192, 0.5572754740715027, 0.4681059420108795, 0.07027000933885574, 1.0152549743652344, -0.3658987283706665, -0.6972901225090027, -1.092081069946289, 0.5782757997512817, -0.12136782705783844, 0.45528075098991394, 0.06769471615552902, -1.4665589332580566, -0.9378907084465027, -0.4066956043243408, 0.07773220539093018, -0.443520724773407, -0.18847322463989258, 1.2124013900756836, 0.03102412074804306, -1.0646930932998657, 0.4870830774307251, -0.3471783399581909, -0.5947945713996887, 0.2929076552391052, -0.05456659197807312, 0.1190454512834549, -0.3609452545642853, -1.717609167098999, 0.5404292345046997, -0.09976394474506378, -0.6780434846878052, -0.47535809874534607, -1.0532026290893555, -1.2921613454818726, 0.19958005845546722, 0.28754115104675293, -0.36539265513420105, 1.283311128616333, -0.22812098264694214, -0.7337043881416321, 0.6843885183334351, -0.5794209241867065, -0.08157098293304443, 0.33192747831344604, -0.5793095231056213, -0.3286326825618744, -0.3950243592262268, 0.11080219596624374, 0.3129130005836487, 0.4073173701763153, 0.04883256182074547, -0.5988318920135498, 0.24204441905021667, -0.3015119731426239, -0.37930190563201904, -0.4938579201698303, 0.8420153260231018, -0.39953508973121643, -0.07452414184808731, -0.3375513255596161, 0.45851337909698486, -0.020267875865101814, -0.7573364973068237, -0.223006471991539, -1.422113060951233, 0.8793481588363647, -0.018913907930254936, 1.3424681425094604, -1.0120855569839478, -0.6114691495895386, -0.2941865921020508, 0.06489194929599762, -0.0376456081867218, -0.6828439235687256, 0.9147166609764099, -0.7753685712814331, 0.3748200535774231, -0.2026635706424713, -0.5337216258049011, -0.005296753253787756, -0.3576614260673523, -0.7525427341461182, -0.12424968183040619, -0.13413117825984955, 0.9796271920204163, -1.192796230316162, 0.03694680705666542, 0.019215278327465057, 0.39460936188697815, -1.0199666023254395, 1.213951826095581, -0.1226268857717514, -0.010309872217476368, -0.13259653747081757, -0.32378995418548584, 0.17918463051319122, -0.3334076404571533, 0.3166673183441162, -0.3183739483356476, -0.3604179322719574, 0.3817332983016968, -0.0005697741289623082, 1.2226089239120483, -0.43541038036346436, 0.8463045358657837, -0.36560195684432983, -0.651397705078125, 0.32480937242507935, 0.2192002236843109, 0.006337213329970837, -0.9640296101570129, -0.1327345073223114, 0.11674635857343674, -0.8288976550102234, -0.18254312872886658, 0.5159181356430054, 0.9502097368240356, -0.4884612262248993, 0.07388380914926529, 0.33322811126708984, 0.006079366896301508, 0.4272509515285492, 1.0118224620819092, 0.9357446432113647, 0.33616793155670166, 0.712920069694519, -0.419424444437027, 0.21369409561157227, -0.7753689289093018, -0.191835418343544, 0.7134383320808411, 0.8106982707977295, 0.2626349627971649, 0.5120217204093933, -1.0328246355056763, -0.9849994778633118, 0.33629029989242554, 0.5862419605255127, 1.3972307443618774, -0.18731839954853058, -0.39568883180618286, -0.6177173256874084, -0.11937233805656433, -0.05172004923224449, 0.3228938579559326, -0.6056186556816101, -0.501941442489624, -0.8803418874740601, -0.6962243318557739, 0.6832523941993713, 0.5042077302932739, 0.8644589781761169, -0.827383279800415, -0.774120569229126, -0.3450763523578644, 0.28961142897605896, -0.691595196723938, -0.6572883129119873, 0.25369128584861755, -0.06540323793888092, -0.060716643929481506, 0.17131437361240387, 0.17622332274913788, -0.18871751427650452, -0.22019743919372559, 1.1192113161087036, -0.4079337418079376, -0.4742293953895569, 0.41618895530700684, 0.21952015161514282, -0.5971255302429199, -0.38023126125335693, 0.43522167205810547, 0.41798561811447144, -0.32719919085502625, 0.43461474776268005, 0.34943464398384094, -0.14793607592582703, -0.13711567223072052, -0.5527697801589966, -0.13082213699817657, 0.08866015076637268, 0.10276954621076584, 0.09266975522041321, -0.43374139070510864, -0.09818172454833984, -1.3123129606246948, 0.44981759786605835, -0.17032894492149353, -0.5877276659011841, -0.024151386693120003, -0.7713133692741394, -0.3614650368690491, 0.5279330611228943, -0.6047051548957825, -0.35425400733947754, -0.4435398578643799, 0.29123491048812866, -0.42365774512290955, -0.25821852684020996, 0.04141518846154213, 0.36048516631126404, 0.19988960027694702, 0.01699717529118061, 0.7472286224365234, -0.012525302357971668, -0.009989350102841854, 0.29831984639167786, -0.8365539312362671, 0.4703572988510132, 0.4289515018463135, 0.4431266188621521, 0.0510970763862133, -0.08706910163164139, -1.0666420459747314, -0.6451848745346069, -0.26200178265571594, -0.21864962577819824, -0.08889361470937729, 0.1508241593837738, -0.5218245387077332, -1.6640827655792236, -0.23006683588027954, -1.1145230531692505, -0.5182979106903076, 0.2928389310836792, -0.36478081345558167, -0.12542884051799774, -0.7869297862052917, -0.858497679233551, -0.9436076283454895, -0.6374019980430603, -0.4198600649833679, 0.4075816869735718, 0.17640838027000427, -0.8948643207550049, -0.6190072298049927, 0.0936272144317627, -0.5545276403427124, 0.9270452857017517, -0.797407329082489, 0.4528335928916931, 0.03119778260588646, -0.6133812069892883, -0.30854228138923645, 0.3505939841270447, -0.042507994920015335, -0.14471812546253204, 0.23156151175498962, -0.7458496689796448, 0.08691803365945816, -0.6216983199119568, -0.1906612515449524, 0.36240801215171814, 0.3799957036972046, 0.6632670164108276, -0.08841592073440552, -0.6383820176124573, 0.2525179088115692, 1.3840811252593994, -0.4302250146865845, 0.4862537086009979, 0.33461543917655945, 1.3495701551437378, 0.3630285859107971, 0.08785242587327957, 0.867520809173584, 0.64339679479599, 0.4684663414955139, 0.10986709594726562, -0.3333233892917633, 0.20886284112930298, -0.6447455883026123, 0.6305338144302368, 1.3528823852539062, 0.3183993399143219, 0.13700878620147705, -1.025551676750183, 0.8272579908370972, -0.9372637271881104, -1.4113489389419556, 0.367154985666275, 0.5786052942276001, 0.18500104546546936, -0.7961087822914124, -0.009476729668676853, -0.20489023625850677, 0.2061695158481598, 0.11880408972501755, -0.48518508672714233, -0.6594411730766296, -0.10594654828310013, 0.41172370314598083, 0.37312230467796326, 0.7598636150360107, -0.2839027941226959, 1.0220680236816406, 15.244179725646973, 0.6969072818756104, -0.07422691583633423, 0.5054723620414734, 0.4951428472995758, 0.0752440020442009, -0.6342355012893677, 0.10972372442483902, -1.2020424604415894, -0.13942012190818787, 1.0209299325942993, -0.12404583394527435, 0.5174993872642517, 0.2274632602930069, 0.30324697494506836, 0.041205745190382004, -0.47341427206993103, 0.7777859568595886, 0.6135505437850952, -0.9589327573776245, 0.32291045784950256, 0.044538095593452454, -0.008163385093212128, 0.17668995261192322, 0.8553047776222229, 0.745572566986084, 0.8442076444625854, -0.2667061984539032, 0.8203220367431641, 0.5364205241203308, 1.2604860067367554, 0.03998879715800285, 0.12943819165229797, 0.2554377019405365, -0.9423559904098511, -0.43259409070014954, -0.5329844355583191, -0.9400370121002197, 0.3409545421600342, 0.014796908013522625, -0.4290587604045868, -0.4952974021434784, 0.2434379905462265, 0.7824982404708862, 0.07261962443590164, 0.3573041558265686, -0.14018292725086212, 0.6761215925216675, 0.12412522733211517, -0.11264432966709137, 0.2811513841152191, 0.8563463687896729, -0.0012504991609603167, 0.4337407946586609, 0.08014893531799316, 0.459771990776062, -0.08924310654401779, 0.44806286692619324, -0.13098731637001038, -0.18376123905181885, -0.5290599465370178, -0.2378881722688675, 0.32237154245376587, 0.8928971290588379, 0.6885533928871155, 0.03252284973859787, -0.37746888399124146, 0.2662026882171631, 0.47177621722221375, -0.04481616988778114, -0.4704274535179138, -0.1690593957901001, 0.4333782196044922, -0.26280996203422546, -0.060603320598602295, 0.6349618434906006, -0.025095274671912193, -0.49633610248565674, -1.1112385988235474, -0.8920101523399353, 0.7037581205368042, -1.0416438579559326, -0.7480190992355347, 0.9885550141334534, -0.32093238830566406, -0.08910230547189713, 0.21692699193954468, -0.4609796702861786, -0.1427452713251114, 0.27542978525161743, -0.9484297037124634, -0.4808926284313202, 0.07279419898986816, -0.1990540474653244, -0.11310786753892899, 0.21745452284812927, 1.12353515625, 0.23003582656383514, -0.04741927981376648, 0.12076002359390259, -0.37955406308174133, -0.30196669697761536, -0.02456456795334816, -0.9499617218971252, 0.7563486695289612, 0.1749429553747177, -0.20642542839050293, 0.5291112661361694, 0.49246302247047424, -0.039832595735788345, -1.0519700050354004, 0.32313913106918335, 0.8078964948654175, -1.2123401165008545, -0.24068281054496765, -0.9893064498901367, -1.0286701917648315, 0.3417583405971527, 0.7240343689918518, -0.32453832030296326, -0.022677000612020493, 0.1570092737674713, -0.6777482628822327, -0.33836251497268677, -0.34211114048957825, -0.15231721103191376, 0.5022217631340027, -1.0214524269104004, -0.18603384494781494, -0.46597450971603394, 0.48540371656417847, -0.6931723356246948, -0.3248293399810791, -0.2530200481414795, 0.34389638900756836, -0.005525687709450722, 0.8542208671569824, -0.4811457097530365, 0.6361031532287598, 0.8780592679977417, 0.2837776839733124, -0.40731626749038696, -0.7030563950538635, -1.0234054327011108, 0.014974375255405903, 0.4305265247821808, 0.1627686470746994, -0.032461922615766525, 0.17257142066955566, 0.5996495485305786, 0.16980503499507904, -0.20047149062156677, -0.5129271149635315, -0.15306000411510468, -0.12169497460126877, -0.46521276235580444, 0.1603415608406067, 0.3432106673717499, 0.2609045207500458, 0.17096109688282013, -0.018400317057967186, 0.5088428854942322, 0.02898767963051796, -0.7631776928901672, 0.17130877077579498, -0.16654062271118164, 0.3496007025241852, -0.42302563786506653, -0.5689266324043274, -1.2278691530227661, 0.08521212637424469, -0.8000417351722717, -0.16787250339984894, -0.6373417377471924, -0.09326344728469849, 0.21775110065937042, -0.14237940311431885, 0.17878878116607666, 0.13720755279064178, -0.4163217842578888, -0.39975637197494507, -0.6479089856147766, -0.7282534837722778, 0.8166563510894775, 0.6834728121757507, -0.7169399857521057, 0.3878578543663025, -0.5030016899108887, -0.15727724134922028, 0.14903578162193298, 0.038337234407663345, -0.7034621238708496, -0.3456844687461853, -1.0842779874801636, 0.5312414169311523, 0.06608515977859497, 0.1513882875442505, -0.42777565121650696, 0.6876773238182068, 0.35192182660102844, -0.212502583861351, 0.016613822430372238, -0.06756222248077393, -0.5877249240875244, -0.40017205476760864, 0.4857150912284851, -0.9715473055839539, 0.6705233454704285, 0.37462282180786133, -0.5991124510765076, -0.06132141500711441, 1.09848952293396, -0.17307281494140625, -1.0772693157196045, -0.5903487801551819, 0.5929790139198303, -0.7930630445480347, 0.44437021017074585, -0.376579612493515, -0.07680431753396988, -0.9651269316673279, -0.6645872592926025, 0.04431244730949402, 0.16630037128925323, -0.5197725892066956, 1.2151292562484741, 0.2367263287305832, -1.1490075588226318, -0.054862216114997864, 0.22926363348960876, 0.05694074556231499, -0.2763133645057678, 0.7815085053443909, 0.3471370041370392, 0.1284649670124054, 0.9354261159896851, 0.3078863024711609, 0.2769143283367157, -1.055545449256897, 0.5525490641593933, 0.607092022895813, -0.15618827939033508, -0.32104727625846863, 0.9259624481201172, 0.17495067417621613, -0.46851488947868347, 0.03866789489984512, -0.7679787874221802, -0.5392307043075562, -0.15449203550815582, 0.6418968439102173, 0.29566407203674316, -0.589043140411377, 0.008288009092211723, -0.7516850829124451, 0.16615459322929382, -0.03777873143553734, -0.21943379938602448, 0.786184549331665, -0.26383253931999207, -0.40678638219833374, 0.40469080209732056, 0.5249093174934387, -0.36528778076171875, -0.5782174468040466, -0.9219444394111633, -0.07388380914926529, -0.12988625466823578, 0.2369273453950882, -0.1761011928319931, -0.5021737813949585, 0.8380194306373596, 0.6023411750793457, 0.7863706350326538, 0.11588659882545471, 0.3242397904396057, 0.2760229706764221, 0.4177889823913574, 0.10431423038244247, -0.30356550216674805, -0.4891796112060547, 1.2531753778457642, 1.2984422445297241, -0.33367976546287537, -0.07594411820173264, -0.25777286291122437, -0.7598622441291809, 0.6081727743148804, 0.36805611848831177, -0.0890231654047966, 0.40289032459259033, 0.03837422654032707, -0.08496472984552383, 0.07505743950605392, -1.2853111028671265, -0.3337968587875366, 0.6505102515220642, 0.922981321811676, 0.988665759563446, -0.04393085092306137, 0.1631467491388321, 0.7341878414154053, -0.010487443767488003, 0.23845133185386658, 0.17283515632152557, 0.0025747460313141346, -0.002772281179204583, -0.10132934898138046, 0.11990606039762497, 0.19403712451457977, -0.6568447947502136, -1.068515419960022, -0.009596931748092175, 0.3308998644351959, 0.030958838760852814, 0.3546103239059448, 0.9967175126075745, 0.12737952172756195, 0.5916213989257812, -0.07551632076501846, 0.4858323335647583, -0.2827586233615875, -0.2051146775484085, -0.04762791097164154, -0.6995795965194702, -0.5205013751983643, -0.13385672867298126, -1.0575307607650757, -0.26614314317703247, -0.6140652894973755, 0.4088204503059387, 0.2223895788192749, -0.20016348361968994, 1.0411713123321533, 0.6691166758537292, 0.414178729057312, -0.2591641843318939, -0.25915002822875977, -0.046694785356521606, -0.8437182903289795, 0.1926448941230774, -0.23245075345039368, -0.044765654951334, -0.21640615165233612, -0.09446734935045242, -0.02901344932615757]}, "authors": [{"authorId": "2435537", "name": "Matteo Pagliardini"}, {"authorId": "50552613", "name": "Daniele Paliotta"}, {"authorId": "2456863", "name": "Martin Jaggi"}, {"authorId": "116272138", "name": "Franccois Fleuret"}], "references": [{"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "1944cebf4e41a10ea7bd02ce30404c18c9c4e04f", "title": "Linear Complexity Randomized Self-attention Mechanism"}, {"paperId": "9e82736043eebe3f71eb86cbef6e2ac45306ece5", "title": "Structured Pruning Learns Compact and Accurate Models"}, {"paperId": "c49ac1f916d6d2edeb187e6619c8d23acd95eb21", "title": "cosFormer: Rethinking Softmax in Attention"}, {"paperId": "002c256d30d6be4b23d365a8de8ae0e67e4c9641", "title": "Improving language models by retrieving from trillions of tokens"}, {"paperId": "fd1b829261ba04bb92e0ab60c4f6e7cea0d99fbf", "title": "Ethical and social risks of harm from Language Models"}, {"paperId": "7a27cc0cc37931e85315ed41333f01cb6de18c02", "title": "Differentiable Subset Pruning of Transformer Heads"}, {"paperId": "c156b1b30e3dd9284615e5304f2fb2826c09d0ff", "title": "Learned Token Pruning for Transformers"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "ca2f1088d3e581b2c6c75cf0ebc96506d620f64d", "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "73e0f38ab49b19b86321016b773e15f1d02e3a72", "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "6346222f4d308dad8e716e0fd33be470f6e94cbb", "title": "Losing Heads in the Lottery: Pruning Transformer Attention in Neural Machine Translation"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "d97cd476bef990352ae921e4c7c5ae1222e9b8da", "title": "A Mixture of h - 1 Heads is Better than h Heads"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "5c27f7106d2f0c95fc51fb98ece672e00185ffa1", "title": "Scheduled DropHead: A Regularization Method for Transformer Models"}, {"paperId": "57f123c95ecf9d901be3a53291f53302740451e2", "title": "Fixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation"}, {"paperId": "94f94e8892261d0377159379ca5a166ceae19a14", "title": "PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector Elimination"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "661d142c23cb2a3207d5f1ba2ac7ff61f2d4fb2f", "title": "Triton: an intermediate language and compiler for tiled neural network computations"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "b03c7ff961822183bab66b2e594415e585d3fd09", "title": "Are Sixteen Heads Really Better than One?"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "50645e3dc912d597e89d59bffb96ccc0f8e1aefa", "title": "Practical and Optimal LSH for Angular Distance"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "The human knowledge compression contest"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}]}