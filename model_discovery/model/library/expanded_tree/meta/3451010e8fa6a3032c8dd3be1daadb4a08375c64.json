{"paperId": "3451010e8fa6a3032c8dd3be1daadb4a08375c64", "abstract": "The increasing computational requirements of deep neural networks (DNNs) have led to significant interest in obtaining DNN models that are sparse, yet accurate. Recent work has investigated the even harder case of sparse training, where the DNN weights are, for as much as possible, already sparse to reduce computational costs during training. Existing sparse training methods are often empirical and can have lower accuracy relative to the dense baseline. In this paper, we present a general approach called Alternating Compressed/DeCompressed (AC/DC) training of DNNs, demonstrate convergence for a variant of the algorithm, and show that AC/DC outperforms existing sparse training methods in accuracy at similar computational budgets; at high sparsity levels, AC/DC even outperforms existing methods that rely on accurate pre-trained dense models. An important property of AC/DC is that it allows co-training of dense and sparse models, yielding accurate sparse-dense model pairs at the end of the training process. This is useful in practice, where compressed variants may be desirable for deployment in resource-constrained settings without re-doing the entire training flow, and also provides us with insights into the accuracy gap between dense and compressed models. The code is available at: https://github.com/IST-DASLab/ACDC .", "venue": "Neural Information Processing Systems", "year": 2021, "citationCount": 55, "influentialCitationCount": 5, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper presents a general approach called Alternating Compressed/DeCompressed (AC/DC) training of DNNs, demonstrates convergence for a variant of the algorithm, and shows that AC/DC outperforms existing sparse training methods in accuracy at similar computational budgets; at high sparsity levels, AC/ DC even outperformsexisting methods that rely on accurate pre-trained dense models."}, "embedding": {"model": "specter_v2", "vector": [0.42762598395347595, 0.6797946691513062, -0.45599719882011414, 0.06954076141119003, -0.2681896388530731, 0.19882749021053314, 0.33540505170822144, -0.4296543002128601, -0.36030763387680054, -0.07546693086624146, 0.47494837641716003, -0.00403053592890501, 0.5653684735298157, 0.04614691808819771, -0.13464558124542236, -0.05915205553174019, -0.7791456580162048, -0.09424279630184174, -0.06560859084129333, -0.044430796056985855, -0.2763451635837555, -0.38845983147621155, -1.1987336874008179, 0.18646448850631714, 0.45550963282585144, 1.2724051475524902, 0.18013298511505127, 1.0327091217041016, -0.2720705568790436, 0.5352755188941956, 0.8903322219848633, -0.29266899824142456, 1.041631817817688, -0.2376490831375122, -0.07711005955934525, -0.027774715796113014, 0.3704909682273865, -0.8948673605918884, -0.8417150378227234, 1.1761677265167236, -0.3920871615409851, 0.2756933867931366, 0.019028929993510246, -0.6976103782653809, 0.14739356935024261, 0.25830745697021484, 0.5826135873794556, 1.123922348022461, -0.4618939459323883, -0.39385131001472473, 1.1239032745361328, -1.0291041135787964, -0.08821509033441544, 1.271634817123413, 0.9942459464073181, 0.46535035967826843, -0.42572274804115295, -0.7258127927780151, 0.5685932636260986, -0.2109319418668747, -0.4506341516971588, -0.4104216694831848, -0.020772660151124, -0.14299194514751434, 1.5735127925872803, -0.48602524399757385, 0.44783881306648254, 1.2091375589370728, -0.341768354177475, 1.1142964363098145, -0.14569340646266937, -0.6921676993370056, 0.006723674479871988, 0.03214571997523308, 0.25965067744255066, 0.5506706237792969, 0.007172431796789169, 0.5541011095046997, -0.9768368601799011, 0.019918855279684067, 0.2793866693973541, 0.6893434524536133, -0.02639266662299633, -0.22230903804302216, 0.3020629286766052, 0.8948975205421448, 0.6249127984046936, 0.5784807801246643, -0.4948658347129822, 0.9811806678771973, 0.5283286571502686, 0.3204869031906128, 0.18557849526405334, 0.3750712275505066, 0.0460352748632431, 0.030705368146300316, -1.192819356918335, -0.15490205585956573, 0.2643069326877594, 0.7306114435195923, -0.42240065336227417, 0.3625834584236145, -0.07028225064277649, 0.4762730300426483, 1.1738735437393188, -0.30967414379119873, 0.49834370613098145, -0.9164408445358276, 0.29284927248954773, -0.8845316767692566, -0.47974881529808044, -0.880933403968811, 0.33029454946517944, -0.668718695640564, -1.2252368927001953, -1.0148082971572876, -0.8876942992210388, -0.03970622271299362, -0.814076840877533, 0.6179205179214478, -0.5872874855995178, 0.9020532965660095, 0.2451454997062683, 0.7285226583480835, 0.18933118879795074, 1.0182147026062012, -0.17790722846984863, 0.14399854838848114, 0.6337217092514038, -1.1608532667160034, -0.7126502394676208, -1.182161808013916, 0.05895933508872986, -0.0674428939819336, -0.27511557936668396, 0.05768447741866112, -1.3256099224090576, -0.8927274346351624, -0.9310585260391235, -0.04873429983854294, -0.40284717082977295, 0.05707946792244911, 1.0874300003051758, 0.11600502580404282, -0.8176708817481995, 1.4312658309936523, -0.6239140629768372, -0.13913942873477936, 1.0193095207214355, 0.23893991112709045, 0.4175865352153778, -0.30353790521621704, -0.7786412239074707, 0.09624361246824265, 0.10800281167030334, -0.23726288974285126, -0.3682352304458618, -0.6721321940422058, -0.6355918645858765, 0.2321997731924057, -0.21558083593845367, -0.5371101498603821, 1.294226050376892, -0.450266569852829, -0.8334502577781677, 0.6269920468330383, -0.07918078452348709, -0.4965517818927765, 0.4759810268878937, -0.4341621696949005, -0.5327960252761841, 0.5858602523803711, -0.2499663531780243, 0.6280685663223267, 0.4302287697792053, -0.23968425393104553, 0.19178451597690582, 0.24668677151203156, -0.5803130269050598, -0.6681564450263977, -0.7449397444725037, 0.3327256441116333, -0.5627124309539795, -0.5037813186645508, 0.33953505754470825, 0.7544160485267639, -0.1451059728860855, 0.45255908370018005, -0.5217030048370361, -0.3807411789894104, 1.1575732231140137, -0.21122035384178162, 0.7234273552894592, -1.0842359066009521, -0.9315351843833923, 0.21330863237380981, 0.19050569832324982, 0.0721212774515152, -0.8477100133895874, 0.17360945045948029, -0.6257416009902954, 0.18549562990665436, -0.14892111718654633, -1.3046010732650757, -0.20771008729934692, 0.23756442964076996, -0.6693732142448425, -0.3142634332180023, 0.30248168110847473, 0.7256890535354614, -0.8818463683128357, 0.032017141580581665, -0.1723703145980835, 0.7323047518730164, -1.4916229248046875, 1.2012332677841187, -0.2535179555416107, -0.18443597853183746, 0.060268960893154144, 0.054402612149715424, 0.14116880297660828, -0.4598753750324249, 0.6682115793228149, -0.6967337727546692, 0.3573942482471466, 0.6880298256874084, -0.4257282018661499, 1.1140133142471313, -0.4480731785297394, 0.885305643081665, 0.22912423312664032, -1.1021050214767456, 0.28056082129478455, 0.3632517457008362, 0.290614515542984, -0.5662185549736023, 0.638572096824646, 0.648292601108551, -0.5699228048324585, 0.44746318459510803, 0.519709050655365, 0.6474495530128479, 0.12863889336585999, 0.31165871024131775, 0.9140404462814331, -0.11129043996334076, 0.3084530830383301, 0.6890736818313599, 0.5880329608917236, 0.06233113631606102, 0.07516203820705414, 0.30592697858810425, -0.34987935423851013, -1.1928009986877441, 0.11270752549171448, 0.48114609718322754, 0.5184435844421387, 1.2378813028335571, 0.7101402282714844, -0.5780148506164551, -0.9104422330856323, 0.2790781557559967, 0.5044265389442444, 0.8066345453262329, -0.2759261131286621, 0.2699955105781555, -0.6380789875984192, -0.42612239718437195, -0.1600484549999237, -0.35079658031463623, -0.05865410342812538, -0.4127572476863861, -0.18616947531700134, -0.9671746492385864, 0.8439125418663025, 0.21290168166160583, 1.6156625747680664, -0.02422633394598961, -0.16539715230464935, -0.6446529030799866, 0.3039553165435791, -1.2605223655700684, -0.39709338545799255, 0.847515881061554, -1.0432347059249878, -0.5348675847053528, 8.65268666530028e-05, -0.0972723588347435, 0.2715650498867035, -0.42360177636146545, 0.9619582295417786, -0.005384238436818123, -0.13531441986560822, 0.09964493662118912, 0.540745198726654, -0.1674404740333557, -0.3850598633289337, -0.06268203258514404, 0.18941374123096466, 0.1287405639886856, 0.20259273052215576, -0.34399572014808655, -0.1836366057395935, -0.3424745202064514, -0.4108497202396393, 0.07367576658725739, 0.01105841901153326, -0.048596080392599106, 1.0571057796478271, -0.5288610458374023, 0.2554379105567932, -1.4094784259796143, 0.4394848346710205, -0.4686676561832428, -0.21359677612781525, -0.37947502732276917, -0.8160885572433472, 0.03699545934796333, 0.7295289635658264, -0.6134389042854309, -0.04445086792111397, -0.915423572063446, -0.14953413605690002, -1.3156890869140625, -0.30373960733413696, -0.10865598917007446, 0.7590546011924744, -0.14626474678516388, 0.36684495210647583, -0.07764914631843567, 0.6367652416229248, -0.3597843050956726, -0.08690925687551498, -0.8521929979324341, 0.8327257633209229, 0.35964441299438477, 0.1773344725370407, -0.1835944503545761, -0.039150457829236984, -0.2974814474582672, -1.1297423839569092, -0.39657241106033325, -0.28063592314720154, -0.1893080174922943, -0.008027349598705769, -0.7608873844146729, -0.09489083290100098, -0.5150635242462158, -0.6409865617752075, -0.3152608871459961, -0.2202540636062622, 0.13860981166362762, -0.15782012045383453, -0.92127525806427, -1.3266034126281738, -0.38502663373947144, -0.8522229790687561, -0.8884016275405884, 0.17141836881637573, 0.37828579545021057, -0.32760560512542725, -0.7760220170021057, -0.3410171568393707, -0.45347359776496887, 0.9618653655052185, -0.27880609035491943, 0.7085849642753601, -0.43887245655059814, 0.14371156692504883, -0.43946290016174316, -0.21948698163032532, 1.1142672300338745, -0.71892911195755, 0.337094783782959, -1.1153745651245117, 0.3051656484603882, -0.33919140696525574, -0.6179563999176025, 0.5440261363983154, 0.33602333068847656, 0.9079751372337341, -0.09911490231752396, -0.2216995805501938, 1.2569817304611206, 1.5595170259475708, -0.9320508241653442, 0.4249533712863922, -0.13969896733760834, 0.650375485420227, -0.5729417204856873, -0.6712260246276855, 0.7017976641654968, -0.5207768082618713, -0.11008214205503464, 0.6456378698348999, -0.1247677356004715, -0.7652056217193604, -1.0027436017990112, 0.10841366648674011, 1.4148167371749878, 0.6559455990791321, 0.24652019143104553, -0.7227649092674255, 0.5563585162162781, -0.9102892875671387, -0.8174139261245728, 0.9044305682182312, 0.5442632436752319, 0.4454965591430664, -0.38849595189094543, -0.4562859535217285, 0.1052301749587059, 0.4013670086860657, 0.6483516693115234, -0.6220210194587708, -0.6044720411300659, -0.04823918268084526, 0.8216221332550049, 0.29789477586746216, 0.4542478621006012, -0.22449864447116852, -0.2917841672897339, 14.403141975402832, 0.5257980823516846, -0.06234736368060112, 0.6856814622879028, 0.8720263838768005, -0.3969380557537079, -0.2667238712310791, -0.2795804738998413, -1.0795804262161255, 0.38483357429504395, 1.3228857517242432, 0.6423347592353821, 0.7288604378700256, 0.5506388545036316, -0.24888208508491516, 0.02741115912795067, -0.5872951745986938, 1.1605030298233032, 0.38086000084877014, -1.5778800249099731, 0.0789029449224472, 0.3247869312763214, 0.8579499125480652, 0.8114529252052307, 0.8250387907028198, 0.8462141752243042, 0.3427980840206146, -0.28215670585632324, 0.369174063205719, 0.41317740082740784, 1.2474840879440308, 0.17048631608486176, 0.824392557144165, 0.5959801077842712, -0.6070895195007324, -0.32342225313186646, -0.5467243790626526, -1.1299917697906494, -0.09071783721446991, 0.4184052348136902, 0.012165798805654049, -0.6946764588356018, 0.32695871591567993, 1.3743064403533936, -0.08217716962099075, 0.4670942425727844, 0.07055069506168365, 0.5184297561645508, -0.47913309931755066, 0.2837889492511749, 0.470041424036026, 0.1955280303955078, 0.072534941136837, 0.037663623690605164, 0.007281376514583826, 0.19793778657913208, 0.03779250755906105, 0.7996175289154053, -0.8919011950492859, -0.8248159289360046, -0.5924578309059143, -0.5983115434646606, -0.04647908732295036, 0.8056091070175171, 0.5994817614555359, 0.24559740722179413, -0.4630851447582245, 0.4249163568019867, 0.4310010075569153, 0.07981995493173599, -0.03559761866927147, -0.16426007449626923, 0.39417001605033875, -0.3960817754268646, 0.19194167852401733, 0.6154455542564392, -0.55544513463974, -0.7442156672477722, -0.7652752995491028, -0.6135169863700867, 0.473089337348938, -1.1051019430160522, -0.8096634745597839, 0.6766548752784729, -0.47712838649749756, -0.40313655138015747, 0.2926363945007324, -0.7947571277618408, -0.3202435374259949, 0.3135102689266205, -1.4879660606384277, 0.29918330907821655, 0.008897554129362106, -0.09782082587480545, -0.36999252438545227, -0.37846797704696655, 1.017753005027771, 0.5330262184143066, -0.4962514340877533, 0.01303889136761427, -0.05084509402513504, 0.21947230398654938, -0.6036921143531799, -0.46241727471351624, 0.5120128393173218, 0.7950237393379211, -0.11237384378910065, -0.06754593551158905, -0.25317296385765076, 0.3583035171031952, -0.6166972517967224, -0.3561602532863617, 0.26603254675865173, 0.09855670481920242, -0.03386954590678215, -0.46642717719078064, -0.5741565823554993, 0.5372459888458252, 0.4328296184539795, 0.46096739172935486, 0.5414090156555176, -0.016790512949228287, -0.7788523435592651, -0.4147191345691681, -1.162798285484314, -0.046318043023347855, 0.49553585052490234, -1.01798677444458, -0.15018725395202637, 0.11059681326150894, 0.36935216188430786, -0.8009071350097656, -0.48909270763397217, -0.1774483621120453, 0.0011742693604901433, -0.6966061592102051, 1.0571314096450806, -0.18223395943641663, 1.054247498512268, 1.3993650674819946, -0.6441493034362793, -0.5792717337608337, 0.5706273913383484, -0.83760666847229, -0.6599827408790588, -0.17159955203533173, 0.12846912443637848, -0.4219737946987152, 0.6747705936431885, 0.5840181112289429, -0.011003977619111538, -0.5217486619949341, -0.699120044708252, -0.1222383975982666, -0.45387738943099976, -0.5566394925117493, -0.11711284518241882, 0.11520030349493027, -0.3998282849788666, -0.16845978796482086, 0.49022629857063293, 0.3161598742008209, -0.10161234438419342, -0.7492218613624573, -0.07388931512832642, -0.16417449712753296, -0.5250750184059143, -0.3028625547885895, -0.6997507810592651, -1.7926207780838013, 0.07756919413805008, -1.4311615228652954, -0.48599445819854736, -0.49006757140159607, -0.6134395599365234, 0.06348574906587601, -0.17111709713935852, 0.1084723100066185, 0.8533964157104492, 0.1431395560503006, 0.07850761711597443, -0.40876448154449463, -0.4776657521724701, 0.8735041618347168, 0.6756195425987244, -0.44158974289894104, 0.21640075743198395, 0.021442897617816925, 0.06847120076417923, 0.6544727683067322, 0.4107930064201355, -0.38395845890045166, -0.5803934931755066, -1.3474775552749634, 0.3603748381137848, -0.17507225275039673, 0.4858838617801666, -1.304042935371399, 0.8012181520462036, 0.6836694478988647, 0.023605583235621452, 0.06158800795674324, 0.4748465120792389, -1.4332586526870728, -0.5074787735939026, 0.5787985324859619, -0.7326565980911255, 0.10670772939920425, 0.04351118206977844, -0.20173019170761108, -0.5120447278022766, 0.48376092314720154, 0.4698624610900879, -0.6358279585838318, -0.7526487112045288, 0.6755122542381287, -0.2075072079896927, 0.24005651473999023, -0.15674495697021484, -0.44721460342407227, -1.2497191429138184, -0.3935922384262085, -0.4841713607311249, 0.24961161613464355, -0.7106866240501404, 0.2708047032356262, 0.624141275882721, -1.3809196949005127, 0.7351104617118835, 0.5440589785575867, -0.5602554082870483, 0.2683667540550232, 0.40120217204093933, 0.7096084952354431, -0.7058464884757996, 0.08839929103851318, 0.15716376900672913, 0.2613184154033661, -0.37948885560035706, -0.027650564908981323, 1.4759111404418945, -0.3133702874183655, -0.4773150086402893, 0.976219654083252, -0.924944281578064, -0.8597191572189331, 0.676991879940033, -0.9837650656700134, -0.21514466404914856, -0.1992715448141098, 0.5463876724243164, 0.10609932243824005, 0.08322329819202423, 0.4938247799873352, -0.28779399394989014, 0.09835170954465866, 0.08536145836114883, -0.04061592370271683, 0.946596086025238, -0.0385948121547699, -0.2095845341682434, 0.5170593857765198, 1.4034430980682373, -0.9665957689285278, -1.4813190698623657, -1.0914846658706665, -0.848405659198761, -0.40171313285827637, 0.7083665132522583, -0.26448020339012146, -1.6429164409637451, 0.9154467582702637, 0.7232478260993958, 0.43732938170433044, 0.6657008528709412, -0.17013849318027496, 0.6419209837913513, 0.8579684495925903, -0.3818511366844177, -0.6552698016166687, 0.06376359611749649, 1.2100377082824707, 0.9494506120681763, -0.7272385358810425, 0.5181254148483276, -0.24164268374443054, -0.4374391734600067, 0.908187985420227, 0.3604917824268341, -0.5812471508979797, 1.0954896211624146, 0.020192626863718033, -0.49952706694602966, 0.3027956187725067, -1.212432861328125, -0.23679384589195251, 0.4384770691394806, 1.0355786085128784, 0.10749778896570206, -0.32232731580734253, 0.4875739812850952, 1.0145683288574219, 0.07771943509578705, -0.11406795680522919, 0.2634902596473694, 0.39258697628974915, -0.2034008651971817, 0.524408221244812, 0.16648368537425995, 1.1284979581832886, -0.8875452280044556, -0.7927213311195374, 0.296517014503479, 0.6669920682907104, 0.49263978004455566, 0.5272860527038574, 1.2132271528244019, -0.18910738825798035, 0.5380414724349976, -0.008807206526398659, 0.3622267544269562, -0.517100989818573, -0.41322287917137146, -0.13077948987483978, -0.5870286822319031, -0.47156262397766113, -0.3602905571460724, -0.3888331949710846, -0.17226144671440125, -0.737281084060669, 0.6593456268310547, -0.12814795970916748, 0.28164568543434143, 0.926960825920105, 0.5708882212638855, 0.7982693314552307, 0.22365456819534302, -0.8648218512535095, -0.43520423769950867, -0.575339138507843, -0.19741855561733246, -0.5186210870742798, 0.12466216832399368, 0.01174487080425024, -0.7856945991516113, -0.23196619749069214]}, "authors": [{"authorId": "3341722", "name": "Alexandra Peste"}, {"authorId": "2082370867", "name": "Eugenia Iofinova"}, {"authorId": "2869958", "name": "Adrian Vladu"}, {"authorId": "3311387", "name": "Dan Alistarh"}], "references": [{"paperId": "4ac782a4d5db8ef988d2e6f4a24dda0db027c4d5", "title": "Graphcore"}, {"paperId": "9c4dd36ad206ca8be96ae4000568e899f4acfa91", "title": "Top-KAST: Top-K Always Sparse Training"}, {"paperId": "90d5e6f8d3b9f2617b3a3cf00fb02e730eb011cb", "title": "Accelerating Sparse Deep Neural Networks"}, {"paperId": "04e283adccf66742130bde4a4dedcda8f549dd7e", "title": "A Survey of Quantization Methods for Efficient Neural Network Inference"}, {"paperId": "5e38dc1ccf33ac1df09b8eb6476f110cb3d1966f", "title": "Learning N: M Fine-grained Structured Sparse Neural Networks From Scratch"}, {"paperId": "9d6acac70b2d1fdb861a08b00766ef263109cd7f", "title": "Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks"}, {"paperId": "9fd1684e6d163c89bd2b2887ab1b21b89ad10137", "title": "TensorFlow Lite Micro: Embedded Machine Learning on TinyML Systems"}, {"paperId": "a0be3cc21ffe87fa5d7d37d688b548e096a8f720", "title": "Sparse Convex Optimization via Adaptively Regularized Hard Thresholding"}, {"paperId": "3b0fb765716ef6861a84abffcbe40643857c613b", "title": "Pruning neural networks without any data by iteratively conserving synaptic flow"}, {"paperId": "c71da533053d79ad267b1d74814a43dda7c584fb", "title": "Dynamic Model Pruning with Feedback"}, {"paperId": "6701ae0675f344b14705c7b9dec14273a87e310e", "title": "WoodFisher: Efficient Second-Order Approximation for Neural Network Compression"}, {"paperId": "5f2c083f80073c56c41c4ea66ae48312513c55aa", "title": "Energy and Policy Considerations for Modern Deep Learning Research"}, {"paperId": "8f03e529dc7ce4dd036864045013223bcd133ec3", "title": "Toward a theory of optimization for over-parameterized systems of non-linear equations: the lessons of deep learning"}, {"paperId": "8eb599d5d7f1821b205e3b56fef5340b1622ba52", "title": "Soft Threshold Weight Reparameterization for Learnable Sparsity"}, {"paperId": "e3916a3ba640e216d909d741542b7dbcff069d73", "title": "Landscape Connectivity and Dropout Stability of SGD Solutions for Over-parameterized Neural Networks"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "2e3002f131e1815bda7a10303eff97f79dea01ec", "title": "Rigging the Lottery: Making All Tickets Winners"}, {"paperId": "db2d3dc613169b519f1a2dd35e0473dc2e848025", "title": "Fast Sparse ConvNets"}, {"paperId": "9b07ecad383a426ec5f5d110329f0c04d4e9cf0b", "title": "Understanding Top-k Sparsification in Distributed Deep Learning"}, {"paperId": "60ed82ca3ec8fbfef4d52e98e49ab687ce501a0c", "title": "Sparse Networks from Scratch: Faster Training without Losing Performance"}, {"paperId": "bc789aef715498e79a74f857fa090ece9e383bf1", "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes"}, {"paperId": "075da5ebbb890924267b4b163292ad21d0b100a0", "title": "Stabilizing the Lottery Ticket Hypothesis"}, {"paperId": "26384278cf5d575fc32cb92c303fb648fa0d5217", "title": "The State of Sparsity in Deep Neural Networks"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "cf440ccce4a7a8681e238b4f26d5b95109add55d", "title": "SNIP: Single-shot Network Pruning based on Connection Sensitivity"}, {"paperId": "2d8c43aa050203e2b49cd8021d0f65c7d2cca00e", "title": "The Convergence of Sparsified Gradient Methods"}, {"paperId": "42ec3db12a2e4628885451b13035c2e975220a25", "title": "A Convergence Theory for Deep Learning via Over-Parameterization"}, {"paperId": "21937ecd9d66567184b83eca3d3e09eb4e6fbd60", "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"}, {"paperId": "df013a17ab84d5403361da4538a04d574f58be83", "title": "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning"}, {"paperId": "ccee800244908d2960830967e70ead7dd8266f7a", "title": "Deep Rewiring: Training very sparse deep networks"}, {"paperId": "3b4d671a8c7018c0b42673ba581e5ff3ae762d6c", "title": "To prune, or not to prune: exploring the efficacy of pruning for model compression"}, {"paperId": "6dbb9e4b2e3b67dc4e1634989511f67d41373dd0", "title": "Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "773d5ddc414424a8948446ddaa5275b944f50891", "title": "Learning to Prune Deep Neural Networks via Layer-wise Optimal Brain Surgeon"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "34cc3ceae5c3f7c8acbb89f2bff63f9d452b00d5", "title": "Variational Dropout Sparsifies Deep Neural Networks"}, {"paperId": "54ddb00fa691728944fd8becea90a373d21597cf", "title": "Understanding deep learning requires rethinking generalization"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "07f5bae91cd45eafe82f3548a43268eb5c84df7a", "title": "Linear Convergence of Gradient and Proximal-Gradient Methods Under the Polyak-\u0141ojasiewicz Condition"}, {"paperId": "64ade6c659f6deeed5527bdd81619cdba90af29a", "title": "Training Skinny Deep Neural Networks with Iterative Hard Thresholding Methods"}, {"paperId": "950619635df80e87c6f25b486cc5eaad4d71d0b0", "title": "DSD: Dense-Sparse-Dense Training for Deep Neural Networks"}, {"paperId": "1c4e9156ca07705531e45960b7a919dc473abb51", "title": "Wide Residual Networks"}, {"paperId": "6eecc808d4c74e7d0d7ef6b8a4112c985ced104d", "title": "Binarized Neural Networks"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff", "title": "Learning both Weights and Connections for Efficient Neural Network"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "4e0261775559aede577c4a0d6cf4e3995de02467", "title": "On Iterative Hard Thresholding Methods for High-dimensional M-Estimation"}, {"paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd", "title": "ImageNet Large Scale Visual Recognition Challenge"}, {"paperId": "94b4197d59404f685419ee8b84bacc4bfa533f45", "title": "Gradient Hard Thresholding Pursuit for Sparsity-Constrained Optimization"}, {"paperId": "e10a650f8c557c64b0a4554c529eead94ad431ed", "title": "Hard Thresholding Pursuit: An Algorithm for Compressive Sensing"}, {"paperId": "0da75214f4d1f636355bb0212262c5c5e55b746c", "title": "Iterative Thresholding for Sparse Approximations"}, {"paperId": "a898ad13c96e5c068a2e4fc88227278e646b712e", "title": "Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?"}, {"paperId": "95382aab883166330fd4e8193132579e97444dbc", "title": "A simple and effective method for removal of hidden units and weights"}, {"paperId": "e8eaf8aedb495b6ae0e174eea11e3cfcdf4a3724", "title": "Optimal Brain Surgeon and general network pruning"}, {"paperId": "8c62b78dad367bfb38ba5c7f8d0906d18d7cf629", "title": "Simultaneous Training of Partially Masked Neural Networks"}, {"paperId": null, "title": "NeuralMagic DeepSparse Inference Engine"}, {"paperId": null, "title": "Experiment tracking with weights and biases, 2020. Software available from wandb.com"}, {"paperId": null, "title": "Efficient inference with TensorRT"}, {"paperId": null, "title": "Ran El-Yaniv, and Yoshua Bengio"}, {"paperId": "2002ac9bbffa3c0970ecd442bd7bf9f44bf5f2f7", "title": "Sparse Recovery Algorithms: Sufficient Conditions in Terms of RestrictedIsometry Constants"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "735d4220d5579cc6afe956d9f6ea501a96ae99e2", "title": "On the momentum term in gradient descent learning algorithms"}, {"paperId": "e7297db245c3feb1897720b173a59fe7e36babb7", "title": "Optimal Brain Damage"}, {"paperId": null, "title": "Finding a Sparse Nearly-Stationary Point Here we prove Theorem 3. For simplicity, we first prove the deterministic version of the theorem"}]}