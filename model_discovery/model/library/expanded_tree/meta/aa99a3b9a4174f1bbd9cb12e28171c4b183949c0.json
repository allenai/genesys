{"paperId": "aa99a3b9a4174f1bbd9cb12e28171c4b183949c0", "abstract": "Large Language Models (LLMs) have recently emerged as a focal point of research and application, driven by their unprecedented ability to understand and generate text with human-like quality. Even more recently, LLMs have been extended into multi-modal large language models (MM-LLMs) which extends their capabilities to deal with image, video and audio information, in addition to text. This opens up applications like text-to-video generation, image captioning, text-to-speech, and more and is achieved either by retro-fitting an LLM with multi-modal capabilities, or building a MM-LLM from scratch. This paper provides an extensive review of the current state of those LLMs with multi-modal capabilities as well as the very recent MM-LLMs. It covers the historical development of LLMs especially the advances enabled by transformer-based architectures like OpenAI's GPT series and Google's BERT, as well as the role of attention mechanisms in enhancing model performance. The paper includes coverage of the major and most important of the LLMs and MM-LLMs and also covers the techniques of model tuning, including fine-tuning and prompt engineering, which tailor pre-trained models to specific tasks or domains. Ethical considerations and challenges, such as data bias and model misuse, are also analysed to underscore the importance of responsible AI development and deployment. Finally, we discuss the implications of open-source versus proprietary models in AI research. Through this review, we provide insights into the transformative potential of MM-LLMs in various applications.", "venue": "arXiv.org", "year": 2024, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper provides an extensive review of the current state of those LLMs with multi-modal capabilities as well as the very recent MM-LLMs and also covers the techniques of model tuning, including fine-tuning and prompt engineering, which tailor pre-trained models to specific tasks or domains."}, "embedding": {"model": "specter_v2", "vector": [0.33729031682014465, 0.7424524426460266, 0.148768812417984, 0.09408774971961975, -0.7096500396728516, -0.3110445439815521, 0.9009532928466797, -0.3914869725704193, -0.29331377148628235, -0.4681689739227295, 0.5153352618217468, 0.25227871537208557, 0.3257838785648346, 0.17154690623283386, -0.5177252888679504, 0.3448517322540283, -0.7779446244239807, 0.8794119358062744, 0.1509019136428833, -0.39484861493110657, -0.3816344141960144, -0.8480364084243774, -1.1950923204421997, 0.4808993339538574, 0.3360523283481598, 0.3960646092891693, 0.48377352952957153, 1.281504511833191, -0.23474760353565216, 0.5595436096191406, 0.47053223848342896, -0.2938430607318878, 0.15373022854328156, 0.06257569044828415, -0.28560400009155273, 0.07288232445716858, 0.49658113718032837, -0.37780722975730896, -0.5347338914871216, 0.2689451575279236, -0.203217014670372, 0.11273011565208435, 0.6902896761894226, -0.864220380783081, -0.6348525881767273, 0.8124428391456604, 0.7632129788398743, 0.5471066236495972, 0.04463140293955803, -0.23488712310791016, 1.3932485580444336, -1.1754796504974365, 0.25870615243911743, 2.059433937072754, 0.24895820021629333, 0.6793630719184875, -0.3049684166908264, -0.6250319480895996, 0.5748998522758484, -0.20692984759807587, -0.7016693949699402, -0.4526137709617615, 0.1236550360918045, -0.27519920468330383, 1.6716917753219604, -0.2935313880443573, 0.04451598972082138, 0.7398423552513123, -0.01765759289264679, 1.7851355075836182, -0.23987223207950592, -1.210431456565857, -0.43028441071510315, 0.13372142612934113, -0.3086775541305542, 0.7951750159263611, -0.7224251627922058, 0.39822667837142944, -1.008929967880249, -0.10006647557020187, 0.6143492460250854, -0.4944725036621094, -0.0576448030769825, -0.14142067730426788, -0.8766506910324097, 1.0079748630523682, 0.28144577145576477, 0.7090017795562744, -0.05023114010691643, 0.6212975382804871, 0.22320590913295746, 0.26648756861686707, -0.17249912023544312, 0.35851341485977173, -0.0675245001912117, 0.5109636783599854, -0.7917180061340332, 0.33422186970710754, -0.0612858422100544, 1.1574630737304688, -0.389232337474823, 0.16175176203250885, -1.0518475770950317, 0.2916378378868103, 1.6926618814468384, 0.2152768075466156, 0.6056729555130005, -0.9018744230270386, 0.6293356418609619, -0.8032912015914917, 0.2828887403011322, -0.5332205295562744, -0.15721918642520905, 0.2165440171957016, -0.47574904561042786, -1.2094393968582153, -0.12412041425704956, 0.14163270592689514, -1.1295727491378784, 0.7789322733879089, -0.4321647882461548, -0.4028412699699402, 0.427537739276886, 0.34742283821105957, 0.4786766767501831, 0.9390912652015686, 0.5629011392593384, 0.37508153915405273, 1.0606567859649658, -0.8541796803474426, -0.5370818972587585, -1.5463745594024658, 0.41937771439552307, -0.24934539198875427, 0.3617705702781677, -0.33451002836227417, -1.4257253408432007, -0.8674406409263611, -0.5470160841941833, -0.26802486181259155, -0.33868682384490967, 0.7235538363456726, 1.0213353633880615, -0.061440713703632355, -1.1920557022094727, 0.3545570373535156, -0.030276892706751823, -0.37707459926605225, 0.31427428126335144, 0.1759912073612213, 0.04888882860541344, -0.4772007167339325, -1.2794278860092163, -0.028808671981096268, 0.13592791557312012, -0.5403180122375488, -0.35264310240745544, 0.14789484441280365, -1.418033242225647, -0.4785544276237488, -0.07324399054050446, -0.6487331986427307, 1.3650319576263428, -0.22606472671031952, -1.0224146842956543, 0.6877514719963074, -0.5532310605049133, -0.0999743640422821, 0.06454473733901978, -0.16045066714286804, -0.5134215950965881, -0.14422176778316498, -0.1496007740497589, 1.3552918434143066, 0.9136353135108948, -0.09138141572475433, -0.3305259048938751, 0.254893958568573, -0.06496810913085938, -0.00989422108978033, -0.1478685587644577, 1.2383332252502441, -0.5720051527023315, -0.28635695576667786, 0.23587395250797272, 0.4072440266609192, -0.044516049325466156, -0.09530570358037949, -0.3397526443004608, -0.9887309074401855, 0.5719102621078491, 0.12433251738548279, 0.7222580313682556, -0.8785760402679443, -0.5249449014663696, -0.6076721549034119, -0.20679879188537598, -0.3531051576137543, -1.1145448684692383, 0.808448851108551, -0.28130438923835754, 0.24123559892177582, -0.1852513998746872, -1.2475168704986572, 0.023871805518865585, -0.2834608852863312, -0.5120300650596619, -0.33272069692611694, 0.5624464750289917, 1.348305583000183, -0.5696200132369995, -0.35105660557746887, -0.021579429507255554, 0.10899590700864792, -0.8672988414764404, 1.1325650215148926, -0.9367696642875671, 0.2216249406337738, -0.1863335520029068, -0.3371795415878296, -0.448408842086792, -0.3740874230861664, -0.15792614221572876, -0.4283883571624756, -0.16046974062919617, 0.12412676960229874, -0.1602131873369217, 1.8012568950653076, 0.057334329932928085, 0.6139438152313232, -0.48072290420532227, -0.25246545672416687, -0.04987079277634621, 0.8431911468505859, -0.51195228099823, -0.439815491437912, 0.38960322737693787, 0.4049912989139557, -0.5854722857475281, 0.13244439661502838, 0.7059269547462463, 0.6676323413848877, -0.23806041479110718, 0.41135039925575256, 0.4586567282676697, -0.6004452705383301, 0.7416002750396729, 0.590764582157135, 0.38611310720443726, 0.33122918009757996, -0.06074707210063934, 0.0995895192027092, 0.41453924775123596, -0.6370433568954468, -0.5866039395332336, 0.3972131311893463, 0.6319333910942078, 1.4608696699142456, 0.07329323142766953, -0.7973576784133911, -0.36121076345443726, 0.16524161398410797, 0.9439589381217957, 1.405843734741211, -0.24792605638504028, -0.13299869000911713, -0.7300390005111694, 0.05055581405758858, -0.5627402663230896, 0.26609963178634644, -0.4500669240951538, -0.046599388122558594, -0.5096204876899719, -0.6492874026298523, 0.7568305730819702, 0.29857349395751953, 0.5420675873756409, -1.026109218597412, -0.5304458737373352, -0.2997813820838928, -0.024322422221302986, -0.7885299324989319, -0.9297378063201904, -0.10821337252855301, -0.437706857919693, -0.08323507010936737, -0.39270538091659546, -0.5131470561027527, 0.1623196005821228, -0.6934897899627686, 0.8015219569206238, -0.869614839553833, -0.34885329008102417, 0.4454435408115387, 0.7749074101448059, -0.9731694459915161, -1.1304552555084229, -0.14806398749351501, -0.10555844753980637, -0.0971146747469902, 0.1451505422592163, 0.7646521925926208, 0.25308868288993835, -0.03214656561613083, -0.709820568561554, 0.6515243053436279, 0.18569447100162506, -0.25797295570373535, 0.8319032788276672, -0.6267040371894836, -0.22807163000106812, -0.8909041881561279, 0.9648362994194031, 0.45664748549461365, -0.4840935170650482, 0.5209019184112549, -0.21941536664962769, -0.11098036170005798, 0.2319670170545578, -0.7893023490905762, -0.44359034299850464, -0.4912191331386566, 0.5825658440589905, -0.44328054785728455, -0.6560104489326477, 0.17393967509269714, 0.43332579731941223, 0.46480831503868103, 0.30105575919151306, 0.5120741724967957, 0.46955716609954834, -0.07698716968297958, 0.8238557577133179, -0.794415295124054, 0.6130075454711914, 0.35952329635620117, 0.26327669620513916, -0.009446565061807632, -0.40508830547332764, -0.425030380487442, -0.3689348101615906, -0.13435949385166168, -0.29978498816490173, -0.5819331407546997, 0.5406343340873718, -0.8115273714065552, -0.4802934229373932, 0.2519151270389557, -1.4175851345062256, -0.03764637932181358, 0.2343457043170929, -0.26710301637649536, -0.4938183128833771, -1.0033737421035767, -1.147672176361084, -0.4903034567832947, -0.657910943031311, -1.0190249681472778, 0.6334814429283142, 0.23049546778202057, -0.5078279376029968, -0.4027276337146759, 0.25271129608154297, 0.021216843277215958, 0.8137384653091431, -0.7129780650138855, 1.0863908529281616, -0.08648718893527985, -0.24034708738327026, -0.5435353517532349, 0.3529576361179352, 0.14831151068210602, -0.45882925391197205, 0.4248639643192291, -0.8776195049285889, 0.1722455471754074, -0.5171225070953369, -0.5502257943153381, -0.06307527422904968, 0.49362409114837646, 0.1435965895652771, 0.19798575341701508, -0.38736024498939514, -0.007521619088947773, 1.1779134273529053, -0.4633910357952118, -0.11508232355117798, 0.013446923345327377, 1.0951403379440308, 0.46639350056648254, -0.29970648884773254, 0.45482948422431946, 0.6621465086936951, 0.18898075819015503, 0.32234832644462585, -0.10666171461343765, -0.214371919631958, -0.716895580291748, 0.7059963941574097, 1.4462532997131348, 0.3018968403339386, -0.3683255612850189, -0.9887968897819519, 0.7162342667579651, -1.217113971710205, -0.5475143194198608, 0.6512486338615417, 0.5443194508552551, 0.3734736740589142, -0.5526471138000488, -0.26780056953430176, -0.3448907434940338, 0.6692497730255127, 0.32679465413093567, -0.19094088673591614, -0.5664238333702087, -0.3175928294658661, -0.14345115423202515, -0.2512317895889282, 0.3941483795642853, -0.6694132685661316, 0.5787976980209351, 14.50255298614502, 0.7390540242195129, 0.207320436835289, 0.3193362355232239, 0.5105130076408386, 0.26428738236427307, -0.48860105872154236, -0.2927238643169403, -1.0674655437469482, -0.5393199920654297, 1.3778023719787598, 0.07172541320323944, 0.8993809223175049, -0.08982627093791962, -0.07299786061048508, 0.14641539752483368, -0.7980782985687256, 0.868929386138916, 0.8204443454742432, -1.1526604890823364, 0.8012561202049255, 0.04976547881960869, 0.2515345513820648, 0.8157791495323181, 0.6923748850822449, 0.678065836429596, 0.3645785450935364, -0.37908393144607544, 1.031754732131958, 0.46177515387535095, 0.8621987104415894, 0.19290947914123535, -0.18936434388160706, 0.8216976523399353, -1.022040605545044, -0.44480881094932556, -0.35066497325897217, -0.9882045984268188, 0.33360549807548523, -0.43328869342803955, -0.1656275987625122, -0.6437598466873169, -0.12962420284748077, 0.6626985669136047, -0.2547783851623535, 0.527830958366394, -0.023695874959230423, 0.3382784426212311, -0.2738081216812134, 0.15953989326953888, 0.37000948190689087, 0.43770721554756165, 0.6343903541564941, -0.41237038373947144, 0.2701660394668579, -0.19126476347446442, -0.037520743906497955, 0.7072694301605225, -0.309833288192749, 0.003269920125603676, -0.6220186948776245, -0.6353206634521484, -0.29217982292175293, 0.5434191823005676, 0.41782084107398987, 0.5506501197814941, -0.598257303237915, 0.2956148684024811, 0.4824720323085785, 0.1740192323923111, -0.25096452236175537, 0.17653390765190125, -0.21357713639736176, -0.5253151655197144, 0.23506194353103638, 0.732487142086029, 0.420101135969162, -0.3870648145675659, -0.5958353877067566, -0.41943204402923584, 0.4153473973274231, -1.1481261253356934, -0.8204077482223511, 1.3292577266693115, -0.08855343610048294, -0.5916079878807068, -0.1745101660490036, -0.6696648001670837, -0.05778976157307625, 0.4915968179702759, -1.2988815307617188, -1.2035108804702759, 0.6428263187408447, -0.09217852354049683, 0.2144191563129425, -0.36583077907562256, 1.3275235891342163, -0.14650891721248627, -0.3187730312347412, -0.1345621645450592, -0.09033224731683731, 0.08816945552825928, -0.3116384446620941, -0.4278460741043091, 0.8087584376335144, 0.28210219740867615, 0.3899810314178467, -0.2156812697649002, 0.021059896796941757, 0.19877609610557556, -0.7606368064880371, 0.1623912900686264, 1.1051636934280396, -0.9645915627479553, -0.46645379066467285, -0.709679365158081, -0.5030189156532288, 0.29390281438827515, 0.8867666721343994, -0.39076805114746094, -0.0994374006986618, -0.3670591711997986, -0.4661923050880432, 0.1828605979681015, -0.6552861928939819, 0.08458803594112396, 0.035574305802583694, -0.8688942193984985, -0.3608410656452179, 0.3325989246368408, 0.7980515956878662, -0.8128089904785156, -0.16615255177021027, -0.43691572546958923, 0.13158835470676422, 0.1322861611843109, 0.8757801055908203, -0.4689427316188812, 0.6417385935783386, 0.8055375218391418, -0.12407804280519485, -0.7067623138427734, -0.21637465059757233, -1.0970789194107056, 0.1152409091591835, 0.2442234754562378, 0.9417018890380859, -0.28007808327674866, -0.18829183280467987, 1.1963979005813599, 0.4275357723236084, -0.17108935117721558, -0.5394219756126404, -0.08284792304039001, 0.034962091594934464, -0.8345632553100586, 0.19495375454425812, -0.8457511067390442, -0.2148856818675995, 0.39231252670288086, 0.32518401741981506, 0.6987872123718262, -0.29727253317832947, -0.5831539034843445, 0.3024967610836029, -0.26815977692604065, -0.01956145092844963, -0.28732892870903015, -0.21096163988113403, -1.2388101816177368, -0.08227131515741348, -1.0259801149368286, 0.27475106716156006, -1.3076659440994263, -0.3929523527622223, 0.20569494366645813, 0.0828561931848526, 0.18758215010166168, 0.7700409889221191, -0.25493329763412476, 0.02401970699429512, -0.15250752866268158, -0.5660858154296875, 0.8396204710006714, 1.0331770181655884, -0.8994019031524658, 0.0419527143239975, -0.035401351749897, 0.24568936228752136, 0.3670467436313629, 0.3045455813407898, -0.4859786033630371, -1.0639513731002808, -1.8035482168197632, 0.5581932067871094, 0.14775213599205017, 0.02104039117693901, -1.2402511835098267, 0.6916261315345764, 0.6157086491584778, -0.4072127044200897, -0.05013037100434303, 0.6314637064933777, -0.9363685250282288, -0.37023356556892395, 0.10977967083454132, -1.0641827583312988, 0.3550720810890198, 0.5676160454750061, -0.5001292824745178, -0.48101744055747986, 0.764300525188446, -0.22280000150203705, -1.1982331275939941, -0.5706766247749329, 0.499399334192276, -0.696643590927124, 0.14274992048740387, -0.01786203496158123, -0.15395322442054749, -0.992669403553009, -0.5694749355316162, -0.08265707641839981, 0.27179667353630066, -0.6125229001045227, 1.3133525848388672, 0.8427846431732178, -1.1238651275634766, -0.2546190321445465, 0.5587174892425537, 0.3669714033603668, 0.06822654604911804, 0.5195325016975403, 0.28043031692504883, -0.14028602838516235, 0.9203261137008667, 0.388230562210083, 0.2543799877166748, -0.9017478227615356, -0.05892284959554672, 0.7244563698768616, -0.18333987891674042, -0.14961689710617065, 1.3917970657348633, -0.10398265719413757, -1.0677525997161865, 0.21379892528057098, -0.9452043771743774, -0.9716553092002869, -0.4527393579483032, 0.7727668881416321, -0.31806638836860657, -0.4709288775920868, -0.7134922742843628, -0.2587912380695343, 0.37841206789016724, -0.049638427793979645, -0.872313916683197, 0.381163626909256, -0.5055127143859863, -0.21543477475643158, 0.9312021136283875, 0.7002395987510681, -0.784680187702179, -0.8014155626296997, -0.5030005574226379, -0.782832145690918, 0.29953083395957947, 0.16793128848075867, -0.554989218711853, -0.7224205136299133, 1.0019675493240356, 0.6104831099510193, 0.2439488172531128, -0.006030043587088585, 0.2994588017463684, 0.3782791793346405, 0.4686770737171173, -0.03637868911027908, -0.6004235148429871, -0.5159109830856323, 1.3788819313049316, 1.5402153730392456, -0.8965921401977539, -0.256216824054718, -0.15662123262882233, -1.0934160947799683, 0.8625761270523071, 0.14503487944602966, 0.24027490615844727, 0.6959488391876221, -0.4193863272666931, 0.14208172261714935, 0.20390509068965912, -1.36497962474823, -0.12479027360677719, 1.1790727376937866, 1.1316494941711426, 0.7437281012535095, 0.3362291157245636, 0.2798052430152893, 0.6373676061630249, 0.13411960005760193, 0.49631568789482117, 0.2962428629398346, 0.46799758076667786, -0.1836145669221878, -0.028359340503811836, -0.1675405353307724, 0.672196090221405, -0.3235120177268982, -0.6927751898765564, 0.1449652910232544, 0.31187644600868225, 0.25892773270606995, 0.9536454081535339, 0.7991045117378235, 0.3032069802284241, 0.5226394534111023, 0.34242013096809387, 0.5678578019142151, -0.4937976896762848, 0.046791937202215195, 0.03660860285162926, -0.6938826441764832, 0.10236679017543793, -0.3168080747127533, -0.7678987979888916, -0.3806770443916321, 0.39072778820991516, 0.32092294096946716, -0.24631905555725098, 0.22604110836982727, 1.2149016857147217, 0.6381034255027771, 0.2862347364425659, -0.7346572875976562, -0.6218745708465576, 0.008351007476449013, -0.9634897708892822, 0.11312320083379745, -0.5016953349113464, -0.20110370218753815, -0.09557893872261047, -0.06982101500034332, 0.022883210331201553]}, "authors": [{"authorId": "2294568988", "name": "Kilian Carolan"}, {"authorId": "2294568855", "name": "Laura Fennelly"}, {"authorId": "1680223", "name": "A. Smeaton"}], "references": [{"paperId": "5aa35e2d7b2ab889ca003f6a2c09f5d6f25d8896", "title": "Generative AI: A systematic review using topic modelling techniques"}, {"paperId": "83de13bd492b9e72c314e308f0d77014154a6a74", "title": "Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment"}, {"paperId": "2c0312c604f9f7638bb4533b39e0ae81e7f6ab12", "title": "The Falcon Series of Open Language Models"}, {"paperId": "b50d19c5c298f6562c3b3c6c3822a351bdc89260", "title": "MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI"}, {"paperId": "451539c0d0f5f5785ff58d09ca5e67a5f129f9de", "title": "A Survey on Multimodal Large Language Models for Autonomous Driving"}, {"paperId": "673abda2b3d94c100c4b5341bddab8850c194aa7", "title": "Prompt Prototype Learning Based on Ranking Instruction For Few-Shot Visual Tasks"}, {"paperId": "124d4d374fbef2016fa9880489871a58a7450644", "title": "Improved Baselines with Visual Instruction Tuning"}, {"paperId": "87bf66eb6d22df17f70170a0e575b4f12c4813ef", "title": "LLM-grounded Video Diffusion Models"}, {"paperId": "4ea8e22236681a09225ee3f8ff5fffd934ec9bae", "title": "From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference"}, {"paperId": "658cd67a91da86cf451e6f1b015f762b56015172", "title": "Detecting and Preventing Hallucinations in Large Vision Language Models"}, {"paperId": "7d78238a9bad60433d616abdd93c735087d99670", "title": "LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation"}, {"paperId": "4f03688df8997e1f4b5aeaf81f44242390ea5c27", "title": "Information Retrieval Meets Large Language Models: A Strategic Report from Chinese IR Community"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "3b6179c293df29e31d31cea46476f104ab6950f2", "title": "Kosmos-2: Grounding Multimodal Large Language Models to the World"}, {"paperId": "21029921a9a0e13efc9ab7b5c98a3412a9be7ab4", "title": "Large language model applications for evaluation: Opportunities and ethical implications"}, {"paperId": "ca5a44251f35897659157f020f212f617c919170", "title": "RA-CLIP: Retrieval Augmented Contrastive Language-Image Pre-Training"}, {"paperId": "7a1e71cb1310c4a873e7a4e54d1a6dab0553adce", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"}, {"paperId": "32ac52069e562d4f900afee70bdca63f53461481", "title": "QLoRA: Efficient Finetuning of Quantized LLMs"}, {"paperId": "5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200", "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints"}, {"paperId": "206400aba5f12f734cdd2e4ab48ef6014ea60773", "title": "Evaluating Object Hallucination in Large Vision-Language Models"}, {"paperId": "7e32aac43e9f1df49e116add03327ee6f365dbf3", "title": "mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality"}, {"paperId": "131c6f328c11706de2c43cd16e0b7c5d5e610b6a", "title": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond"}, {"paperId": "ca6a2bc279be5a3349a22bfd6866ed633d18734b", "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "38a9609a5bd874534527df9b00f2897927e57be9", "title": "MedAlpaca - An Open-Source Collection of Medical Conversational AI Models and Training Data"}, {"paperId": "4651e2cff4e4f20bf6039c4719dbbe8cbe05b278", "title": "ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "fbfef4723d8c8467d7bd523e1d0b703cce0e0f9c", "title": "Language Is Not All You Need: Aligning Perception with Language Models"}, {"paperId": "59bed3776e211726755238eabd2e63283ba743ff", "title": "Risks and Benefits of Large Language Models for the Environment."}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "9689acb6cb760e8bc21c16f368368b37dee977f9", "title": "Adaptive Machine Translation with Large Language Models"}, {"paperId": "de32da8f5c6a50a6c311e9357ba16aa7d05a1bc9", "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "7016eb4f34611f97fe8c99176246e314678e03f4", "title": "A New Generation of Perspective API: Efficient Multilingual Character-level Transformers"}, {"paperId": "a37bf9d65a4d1ebf95c79b3ab973bb7a8019ac3e", "title": "Deep Learning Approaches on Image Captioning: A Review"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "77d956cdab4508d569ae5741549b78e715fd0749", "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "ac3cdb50606f7770eef8e4cd951840a4f71287a0", "title": "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "399e7d8129c60818ee208f236c8dda17e876d21f", "title": "RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "9770fff7379a7ab9006b48939462354dda9a2053", "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca", "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "722b2330a1d08e1c2d71a8d708c2b9f200e74f25", "title": "Is Neural Machine Translation the New State of the Art?"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "5d4a6ce39cfe7bfc6305cba86464efff8bc20c97", "title": "A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges"}, {"paperId": "9159408884cbe7f5f7a79d90c9f91ba5cee0d932", "title": "A Survey of Text Representation and Embedding Techniques in NLP"}, {"paperId": "80527ed02db8fe7574f676ed2aa573eb1ae252a0", "title": "EU AI Act: first regulation on artificial intelligence"}, {"paperId": null, "title": "Understanding Rotary Position Embedding: A Key Concept in Transformer Models"}, {"paperId": "10baebea116e3f618d514a0d68a4cc3e482db73c", "title": "Review on Usage of Hidden Markov Model in Natural Language Processing"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Improving language understanding with unsupervised learning"}, {"paperId": null, "title": "\u201cGemini: a family of highly capable multimodal mod-els\u201d"}, {"paperId": null, "title": "Open Source or Proprietary LLMs \u2014 indukishen"}, {"paperId": null, "title": "Choosing Neural Networks over N-Gram Models for Natural Language Processing \u2014 towardsdatascience."}, {"paperId": null, "title": "The case for and against open-source large language models for use in newsrooms \u2014 digiday.com"}, {"paperId": null, "title": "LLM Benchmarks (Introduction to Benchmarks Techniques)"}, {"paperId": null, "title": "The Falcon has landed in the Hugging Face ecosystem \u2014 huggingface"}, {"paperId": null, "title": "Navigating the Attention Landscape: MHA, MQA, and GQA Decoded \u2014 iamshobhitagarwal"}, {"paperId": null, "title": "This question-answering dataset modelled after open book exams used for assessing human understanding of various subjects"}, {"paperId": null, "title": "Introducing Falcon 180b: A Comprehensive Guide with a Hands-On Demo of the Falcon 40B \u2014 blog"}, {"paperId": null, "title": "Google \u201dWe Have No Moat, And Neither Does OpenAI\u201d \u2014 semianalysis"}, {"paperId": null, "title": "Large language models (LLMs): A brief History, applications & challenges \u2014 blog"}, {"paperId": null, "title": "What is Grouped Query Attention (GQA)?"}, {"paperId": null, "title": "A brief history of language models \u2014 towardsdatascience"}, {"paperId": null, "title": "IBM Data and AI Team"}, {"paperId": null, "title": "Introducing Claude"}, {"paperId": null, "title": "What Is Language Modeling? \u2014 Definition from TechTarget \u2014 techtarget.com"}, {"paperId": null, "title": "What is RLHF: Reinforcement Learning from Human Feedback \u2014 medium.com"}, {"paperId": null, "title": "A Short History Of ChatGPT: How We Got To Where We Are Today \u2014 forbes.com"}, {"paperId": null, "title": "\u201cEthical implications of large language models a multidimensional exploration of societal, economic, and technical concerns\u201d"}, {"paperId": null, "title": "Game-Changer 2024: Meta\u2019s LLAMA 2.0 \u2014 sebas-tianstreng96"}, {"paperId": null, "title": "BLIP-2: A Breakthrough Approach in Vision-Language Pre-training \u2014 femiloyeseun"}, {"paperId": null, "title": "LLaMA 1 vs LLaMA 2: A Deep Dive into Meta\u2019s LLMs \u2014 ankursnewsletter.com"}, {"paperId": null, "title": "The Future of LLMs: Proprietary versus Open-Source \u2014 linkedin.com"}, {"paperId": null, "title": "UAE\u2019s Technology Innovation Institute Launches Open-Source \u201dFalcon 40B\u201d Large Language Model for Research & Commercial Utilization \u2014 tii.ae"}, {"paperId": null, "title": "Llama 2: The Next Revolution in AI Language Models - Complete 2024 Guide - viso"}, {"paperId": null, "title": "2: a guide to Anthropic\u2019s AI model and Chatbot"}, {"paperId": null, "title": "The Ultimate Guide to LLM Fine Tuning: Best Practices & Tools \u2014 Lakera \u2013 Protecting AI teams that disrupt the world"}, {"paperId": null, "title": "Full Fine-Tuning, PEFT, Prompt Engineering, or RAG? \u2014 deci"}, {"paperId": null, "title": "Exploring the Falcon LLM: The New King of The Jun-gle \u2014 minh"}, {"paperId": null, "title": "Supervised Fine-tuning: customizing LLMs \u2014 medium"}, {"paperId": null, "title": "This task evaluates common-sense reasoning by requiring models to complete sentences based on everyday events"}, {"paperId": null, "title": "This benchmark consists of real yes/no questions from Google searches paired with Wikipedia passages. It challenges models to infer answers from context that may be implied but not stated"}, {"paperId": null, "title": "What I learned from Bloomberg\u2019s experience of building their own LLM \u2014 linkedin.com"}, {"paperId": null, "title": "Common Crawl"}, {"paperId": null, "title": "Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90% ChatGPT Quality"}]}