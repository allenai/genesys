{"paperId": "6f5ebf4e64714edab506daf1823096fe2ba89fab", "abstract": "Efficient Transformer models typically employ local and global attention methods, or utilize hierarchical or recurrent architectures, to process long text inputs in natural language processing tasks. However, these models face challenges in terms of sacrificing either efficiency, accuracy, or compatibility to develop their application in longer sequences. To maintain both the accuracy of global attention and the efficiency of local attention, while keeping a good compatibility to be easily applied to an existing pre-trained model, in this paper, we propose multi-level local attention (Mulla attention), which is a hierarchical local attention that acts on both the input sequence and multiple pooling sequences of different granularity simultaneously, thus performing long-range modeling while maintaining linear or log-linear complexity. We apply Mulla attention to LongT5 and implement our LongT5-Mulla sequence-to-sequence model, without introducing new parameters except for positional embeddings. Experiments show that our model can surpass all baseline models, including two original variants of LongT5, in the 8~16k-input long text summarization task on the Multi-News, arXiv and WCEP-10 datasets, with improvements of at least +0.22, +0.01, +0.52 percentage points (pp) averaged Rouge scores respectively, while at the meantime being able to effectively process longer sequences that have 16~48k tokens with at least 52.6% lower memory consumption than LongT5-tglobal, and +0.56~1.62 pp averaged Rouge scores higher than LongT5-local. These results demonstrate that our proposed LongT5-Mulla model can effectively process long sequences and extend the maximum input length for long text tasks from 16k to 48k while maintaining accuracy and efficiency.", "venue": "IEEE Access", "year": 2023, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10348571.pdf", "status": "GOLD"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes multi-level local attention (Mulla attention), which is a hierarchical local attention that acts on both the input sequence and multiple pooling sequences of different granularity simultaneously, thus performing long-range modeling while maintaining linear or log-linear complexity."}, "embedding": {"model": "specter_v2", "vector": [0.13951890170574188, 0.21139906346797943, -0.37560027837753296, -0.07751587778329849, -0.7582207322120667, -0.1316799372434616, 0.72411048412323, 0.1621101200580597, -0.2587987780570984, -0.023974018171429634, 1.2841598987579346, 0.3846852481365204, 0.2037779837846756, 0.15164482593536377, -0.0003909013175871223, 0.07743377238512039, -0.8993374705314636, 0.06251437962055206, -0.015537385828793049, -0.38261523842811584, 0.34762319922447205, -0.8438209295272827, -0.7103957533836365, 0.47907695174217224, 0.5357105731964111, 0.24785740673542023, 0.3803212344646454, 1.1662858724594116, -0.41640010476112366, 0.5765076279640198, 0.1927156001329422, -0.3696359097957611, -0.07859289646148682, -0.3703731596469879, -0.7692907452583313, -0.14291442930698395, 0.5262347459793091, -0.38873350620269775, -0.17931225895881653, 0.5728957056999207, -0.023089274764060974, 0.33796364068984985, 0.26132169365882874, -0.21541078388690948, -0.22891642153263092, 1.217224359512329, 0.43158963322639465, 0.6029635667800903, 0.05783718079328537, -0.6687020063400269, 1.6953543424606323, -1.3854737281799316, 0.04891970381140709, 1.6757547855377197, 0.6319436430931091, 0.07543566823005676, -0.04338913410902023, -0.22005760669708252, 0.6425756812095642, 0.15606677532196045, -0.46441712975502014, -0.4652463495731354, -0.11862591654062271, -0.10359493643045425, 1.8750317096710205, -0.3593997657299042, -0.049719858914613724, 0.3009665608406067, 0.1965966522693634, 1.5327198505401611, -0.5981683731079102, -0.4903712868690491, -0.6984180808067322, -0.6429031491279602, 0.8954226970672607, 0.4454715847969055, -0.5396227240562439, -0.2574231028556824, -0.8486306071281433, 0.025501741096377373, 0.14811822772026062, 0.29058119654655457, -0.029908156022429466, 0.4088198244571686, -0.4803890883922577, 0.683474600315094, 0.4446611702442169, 0.9782729744911194, -0.6899020075798035, 0.7754059433937073, 0.7819963097572327, 0.4571634531021118, 0.32235702872276306, 0.4628070592880249, -0.036313675343990326, 0.2762133777141571, -0.9600456953048706, 0.27852505445480347, -0.43050438165664673, 0.710524320602417, -0.14422675967216492, 0.12325932830572128, -0.9931865930557251, 0.26915982365608215, 0.8276556730270386, -0.040810126811265945, 0.4695465862751007, -0.6310774683952332, 0.18270789086818695, -0.40311700105667114, 0.10970023274421692, -0.7926812171936035, -0.16655875742435455, -0.30324047803878784, -0.868720531463623, -1.419878602027893, -0.233568474650383, 0.23469039797782898, -0.3034823536872864, 0.5220593214035034, -0.6556132435798645, 0.18174776434898376, 0.2287464588880539, 0.1301412731409073, 0.762121319770813, 1.1640490293502808, 0.1603066474199295, -0.21624082326889038, 1.0341670513153076, -1.0446698665618896, -0.7872099876403809, -1.0392521619796753, 1.01981782913208, -0.5209029316902161, 0.33585402369499207, -0.2296770215034485, -1.2047603130340576, -0.8254722952842712, -0.8764373660087585, -0.3360684812068939, -0.4367227256298065, 0.343453586101532, 0.631696879863739, -0.2711620330810547, -0.8622315526008606, 0.7644385695457458, -0.11379719525575638, -0.5290332436561584, 0.07030775398015976, -0.3881148099899292, 0.29626500606536865, -0.4671742618083954, -1.518436074256897, 0.5340942740440369, 0.07807183265686035, -0.3504510223865509, 0.03452810272574425, -0.720276415348053, -1.1452181339263916, 0.1683364063501358, 0.04485972225666046, -0.5095536112785339, 1.277937650680542, 0.36224061250686646, -1.2014843225479126, 0.25959283113479614, -0.55274498462677, -0.249679833650589, 0.05041395127773285, -0.6540614366531372, -0.07505019754171371, -0.4967789351940155, -0.08772487938404083, 0.20459306240081787, 0.05724024027585983, 0.5236701369285583, -0.24763223528862, 0.2646837830543518, -0.39566943049430847, -0.14570419490337372, -0.2739197015762329, 1.1822350025177002, -0.34886088967323303, -0.26607367396354675, -0.023294590413570404, 1.0746891498565674, 0.13368374109268188, -0.831985354423523, -0.2477884143590927, -1.296162724494934, 0.8898253440856934, -0.2673241198062897, 1.2971856594085693, -0.7576518058776855, -0.6473002433776855, -0.7516642212867737, -0.2396753579378128, 0.06686151772737503, -0.9069403409957886, 0.8802821636199951, -0.16714955866336823, 0.3134296238422394, 0.1638631969690323, -1.1442838907241821, 0.04447343945503235, -0.5141471028327942, -0.795579731464386, -0.18962004780769348, 0.21134738624095917, 1.2111897468566895, -1.1396335363388062, 0.08069182187318802, 0.00508978171274066, 0.18739722669124603, -0.8135154247283936, 1.0652883052825928, -0.49669721722602844, -0.07593493908643723, -0.38300821185112, -0.5341264605522156, 0.04733826220035553, -0.2704545557498932, 0.1793563961982727, -0.38889428973197937, -0.49885353446006775, 0.77846759557724, -0.2306482046842575, 1.423366904258728, -0.1365714818239212, 0.6381205320358276, -0.281146377325058, -0.41562408208847046, 0.28582704067230225, 0.36451423168182373, -0.1785467565059662, -0.29964056611061096, 0.3085421919822693, 0.1190863773226738, -1.0674666166305542, 0.1234399601817131, 0.9679288864135742, 1.0523948669433594, -1.0317714214324951, 0.4203272759914398, 0.695344090461731, 0.15156972408294678, 0.6266642808914185, 0.8537874817848206, 0.7066443562507629, 0.23055055737495422, 0.6024811863899231, -0.31072238087654114, 0.3668006658554077, -0.7412490844726562, -0.02936926856637001, 0.5850476026535034, 0.7556159496307373, 0.8232616186141968, 0.49375152587890625, -0.7660893797874451, -0.557211697101593, 0.46458569169044495, 1.1736658811569214, 1.6335302591323853, -0.2180365025997162, -0.47323206067085266, -0.5273429155349731, -0.047823287546634674, -0.4838029444217682, 0.011810876429080963, -0.17594832181930542, -0.022805148735642433, -0.7841724753379822, -0.9013075232505798, 0.7890995740890503, 0.3122982680797577, 0.966323733329773, -0.7338660359382629, -0.3251982033252716, 0.020785773172974586, -0.2562941908836365, -0.6947963833808899, -1.0371595621109009, 0.134723499417305, -0.3429291844367981, -0.06813795119524002, -0.09876921772956848, -0.09851035475730896, -0.24388103187084198, -0.49693331122398376, 0.9569653868675232, -0.4261628985404968, 0.05504907667636871, 0.14197999238967896, 0.107729472219944, -0.4425407648086548, -0.5249418020248413, 0.30834561586380005, 0.20097772777080536, -0.10421103984117508, 0.38308292627334595, 0.7658178806304932, 0.05464660003781319, 0.003825124353170395, -0.3438367247581482, 0.08749967813491821, 0.1770244985818863, 0.2053617686033249, 0.40659084916114807, 0.07660551369190216, 0.4466707408428192, -0.8325069546699524, 1.1741262674331665, 0.3920597732067108, -0.36516740918159485, 0.4276803135871887, -0.26904934644699097, -0.3304741382598877, 0.3746701180934906, -0.4944154918193817, -0.272463858127594, -1.1122182607650757, 0.5062739849090576, 0.123253732919693, 0.05389288440346718, 0.7233351469039917, -0.058907657861709595, 0.7857251167297363, -0.080553337931633, 0.47762805223464966, 0.2039916068315506, -0.4496072232723236, 0.366143137216568, -0.6247568726539612, 0.5962109565734863, 0.5959666967391968, -0.11719413846731186, -0.5470588207244873, -0.2545790374279022, -1.0006967782974243, -0.8298736214637756, -0.7227731943130493, -0.45250630378723145, -0.31286752223968506, 0.20215454697608948, -0.30804356932640076, -0.5775555372238159, 0.42524826526641846, -1.427054762840271, -0.006594022270292044, 0.16655686497688293, -0.23308157920837402, 0.0025183602701872587, -1.052046775817871, -1.3956125974655151, -0.39874500036239624, -0.8791325688362122, -0.7124247550964355, 0.2911161780357361, 0.051536642014980316, -0.5388983488082886, -0.5634276866912842, 0.08989999443292618, -0.5644204020500183, 0.9722460508346558, -0.20773418247699738, 0.5682964324951172, -0.2244853675365448, -0.3007931113243103, -0.5775509476661682, 0.22286133468151093, 0.43296295404434204, -0.047160640358924866, 0.1537986397743225, -0.43375706672668457, 0.06629414856433868, -0.09669994562864304, -0.16031968593597412, 0.5599951148033142, 0.701335608959198, 0.09475938230752945, -0.08469981700181961, -0.40534716844558716, -0.2287387251853943, 1.1539325714111328, -0.877489447593689, 0.22668859362602234, 0.14201483130455017, 0.7987726330757141, 0.45475974678993225, 0.13533389568328857, 0.5943193435668945, 0.15921002626419067, 0.14018143713474274, -0.07326196879148483, -0.14285849034786224, -0.33382248878479004, -0.7224056720733643, 0.9448513388633728, 1.9914240837097168, 0.3046419024467468, -0.4969286620616913, -0.9622083902359009, 0.8926292657852173, -1.3763574361801147, -1.2542396783828735, 0.3653526306152344, 0.5271700620651245, 0.22105255722999573, -0.605678141117096, -0.17190752923488617, -0.0958472341299057, 0.6061365008354187, 0.6952677369117737, -0.17408345639705658, -0.62508225440979, -0.3792055547237396, -0.05348488688468933, 0.11863522231578827, 0.862475574016571, -0.18733324110507965, 0.7871622443199158, 14.71937370300293, 0.80799800157547, 0.06646241247653961, 0.2581748962402344, 0.6017677187919617, 0.136567160487175, -0.044309813529253006, -0.1638883799314499, -1.2624772787094116, -0.17130324244499207, 1.251579999923706, -0.4139443337917328, 0.23090054094791412, -0.26528292894363403, 0.5763134360313416, 0.22390849888324738, -0.6033278703689575, 0.5155106782913208, 0.6155271530151367, -1.4014921188354492, 0.7826482057571411, 0.18548116087913513, 0.1634140908718109, 0.5603625178337097, 0.6477958559989929, 0.7500903010368347, 0.5305696129798889, -0.1877298802137375, 0.12428231537342072, 0.46822071075439453, 0.5745946168899536, -0.36848506331443787, 0.960349440574646, 0.4780319929122925, -1.0422383546829224, -0.15155112743377686, -0.6602603197097778, -1.3266634941101074, 0.44858092069625854, 0.37633389234542847, -0.4664948880672455, -0.02007879875600338, -0.2364850789308548, 1.1813033819198608, -0.02800508588552475, 0.5404511094093323, -0.2133709192276001, 0.40583181381225586, 0.11695932596921921, -0.18280281126499176, 0.5369118452072144, 0.6087265610694885, 0.48455625772476196, 0.3145362138748169, 0.29320549964904785, 0.18657037615776062, 0.10966870933771133, -0.014789688400924206, -0.6670095920562744, 0.15531384944915771, -0.30227234959602356, -0.34898072481155396, -0.032798465341329575, 0.6112764477729797, 0.694129228591919, 0.05942154303193092, -0.3550073802471161, 0.17205630242824554, 0.4610334038734436, 0.047191374003887177, -0.32552570104599, -0.520534098148346, 0.33805370330810547, -0.2777559757232666, 0.02151000313460827, 0.5393774509429932, -0.057934947311878204, -0.6009960174560547, -0.9963236451148987, -0.2924412190914154, 0.4314059019088745, -0.7709929347038269, -0.844853401184082, 0.984520673751831, -0.2804315388202667, -0.4411112070083618, 0.00525374710559845, -0.41820237040519714, -0.6901718378067017, 0.41634371876716614, -1.200485110282898, -0.8716892004013062, 0.3406577706336975, -0.413734495639801, 0.045811038464307785, 0.05674610659480095, 1.062164068222046, 0.1010044738650322, -0.3025059700012207, -0.25656822323799133, 0.21252405643463135, -0.09274514764547348, -2.664905878191348e-05, -0.5984986424446106, 0.6118727922439575, 0.7794400453567505, -0.6026091575622559, 0.18347963690757751, 0.19147253036499023, 0.19613982737064362, -0.7203633785247803, -0.3760795593261719, 1.2778841257095337, -1.0032731294631958, -0.23636163771152496, -0.7204031944274902, -0.991265594959259, 0.46445590257644653, 0.9272652268409729, -0.6109601259231567, 0.0772654265165329, 0.22211797535419464, 0.0008037047227844596, -0.1817484200000763, -0.6328092813491821, -0.17488710582256317, 0.16590479016304016, -0.7253026962280273, -0.5391054749488831, -0.20440985262393951, 0.8315300941467285, -0.6551880836486816, -0.5343090891838074, -0.3940412700176239, 0.0051651098765432835, 0.21567018330097198, 0.8258363604545593, -0.23817645013332367, 0.6114322543144226, 0.7578635811805725, -0.07501043379306793, -0.856657087802887, -0.3258008360862732, -1.1037821769714355, 0.17608892917633057, 0.802530825138092, 0.4789609909057617, -0.24851855635643005, -0.002695297123864293, 0.4163592755794525, 0.22149120271205902, -0.32564568519592285, -0.3733343780040741, -0.28846946358680725, 0.13726314902305603, -0.2804448902606964, 0.3196873962879181, -0.23015709221363068, 0.2761344313621521, 0.34253349900245667, -0.14802134037017822, 0.6534196734428406, -0.26207709312438965, -0.5154451131820679, 0.48920196294784546, -0.26995155215263367, 0.6379987001419067, -0.759001612663269, -0.6016363501548767, -1.7702038288116455, -0.12855497002601624, -0.8264980316162109, 0.04724425822496414, -1.4629195928573608, -0.29862698912620544, 0.801201581954956, -0.35205256938934326, 0.12198302149772644, 0.3054318428039551, -0.46908754110336304, -0.4232884645462036, -0.6918456554412842, -0.9734287261962891, 0.9621396064758301, 0.9609240293502808, -0.9593945741653442, -0.05349716916680336, -0.25686225295066833, -0.07847317308187485, 0.26827549934387207, 0.3362186551094055, -0.4467930197715759, -0.46905043721199036, -1.4079896211624146, 0.30508044362068176, -0.044411800801754, -0.10030724108219147, -0.42537474632263184, 0.9584845900535583, 0.5388371348381042, -0.19309896230697632, -0.6977420449256897, 0.0823240801692009, -0.3500683903694153, -0.6237159967422485, 0.20673054456710815, -1.010543704032898, 0.49163687229156494, 0.09839502722024918, -0.7656497359275818, -0.6525763869285583, 0.9124110341072083, -0.10893452912569046, -0.8272829055786133, -0.5884466767311096, 0.4448804557323456, -0.7985973358154297, 0.03433603048324585, -0.48623332381248474, 0.00872057769447565, -1.1510118246078491, -0.5493990778923035, 0.10275119543075562, 0.7993655204772949, -0.4527355134487152, 1.0819511413574219, 0.4926440417766571, -1.2001416683197021, -0.499185711145401, 0.08993090689182281, -0.10782124102115631, -0.15822994709014893, 0.6856838464736938, 0.3583109676837921, -0.034351643174886703, 0.7532968521118164, 0.386116623878479, 0.11405862867832184, -0.9902945160865784, -0.05332871153950691, 0.5276703834533691, -0.8235644102096558, -0.2932804226875305, 0.9248552322387695, -0.44938525557518005, -0.904738187789917, 0.03534820303320885, -1.2125322818756104, -0.8834925889968872, 0.19339728355407715, 1.0696289539337158, 0.5249916315078735, -0.27606460452079773, -0.3004765510559082, -0.5243401527404785, 0.310625284910202, -0.1798841953277588, -0.23970629274845123, 1.0385338068008423, -0.5337948203086853, -0.6493483781814575, 0.7621177434921265, 0.9839212894439697, -0.5563675761222839, -0.37315961718559265, -0.9216532707214355, 0.058078013360500336, 0.04107087478041649, 0.4965953230857849, -0.25842422246932983, -0.2489422857761383, 0.6736035943031311, 0.20226089656352997, 0.7545973062515259, 0.35370367765426636, -0.1679397076368332, 0.45908674597740173, 0.6455015540122986, -0.07836226373910904, -0.34535878896713257, -0.4345146715641022, 1.740636944770813, 1.7016927003860474, -0.5958876013755798, 0.30227401852607727, 0.38305261731147766, -0.7578412294387817, 0.8823844194412231, -0.014226917177438736, -0.1567721664905548, 0.6450374722480774, -0.3759123682975769, 0.06790325790643692, 0.1316080242395401, -1.3065310716629028, -0.07734739035367966, 0.6785343289375305, 0.5527745485305786, 0.7382294535636902, 0.057523228228092194, 0.008070983923971653, 0.8390218615531921, 0.19739218056201935, -0.0737743079662323, 0.685282826423645, 0.20171086490154266, -0.4007224440574646, 0.08440566062927246, 0.1605205088853836, 0.43937280774116516, -0.7331369519233704, -0.4871687889099121, 0.15930165350437164, 0.42115962505340576, -0.1817312091588974, 0.9090935587882996, 0.683449923992157, 0.29172080755233765, 0.5310891270637512, 0.17692144215106964, 0.20687347650527954, -0.4332854449748993, -0.38067469000816345, -0.005022821482270956, -0.5098364949226379, -0.04216785728931427, -0.3623620867729187, -0.915013313293457, -0.15816842019557953, -0.4492398202419281, 0.18640655279159546, 0.3811080753803253, -0.04696483910083771, 1.0336229801177979, 0.6858978271484375, 0.6966265439987183, -0.45438283681869507, -0.6654888391494751, -0.19180822372436523, -1.4513016939163208, -0.13180211186408997, -0.4535923898220062, 0.3151806890964508, 0.1316467970609665, -0.13970224559307098, -0.16660404205322266]}, "authors": [{"authorId": "2189279577", "name": "Le Zhou"}], "references": [{"paperId": "f3ca1504ab4cc14f491f07e5a8b38d93890551e1", "title": "Peek Across: Improving Multi-Document Modeling via Cross-Document Question-Answering"}, {"paperId": "732e3faec4e5be4d144256f2c379b9dc49f0b227", "title": "Efficient Long-Text Understanding with Short-Text Models"}, {"paperId": "24b951275a7a42ef36aca8352caaf6f4cd6238d2", "title": "HiStruct+: Improving Extractive Text Summarization with Hierarchical Structure Information"}, {"paperId": "68cf0b9021f904a765e760291d0c9a509aab0067", "title": "A Multi-Document Coverage Reward for RELAXed Multi-Document Summarization"}, {"paperId": "3dfb1f50f2a34a699c339dabaa6f9b3a977973de", "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences"}, {"paperId": "2d82ee05b132d4681c3bd517afc17d608fe6e525", "title": "Simple Local Attentions Remain Competitive for Long-Context Tasks"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "e7216f9e67904157ff5265921956fee5eb32f103", "title": "Topic-Guided Abstractive Multi-Document Summarization"}, {"paperId": "999deaecf0adb9defa3b233be32c6a1c3f7090a3", "title": "Multi-Document Summarization with Determinantal Point Process Attention"}, {"paperId": "e79d1206292bc5e67ba19737d87d4b2ea4a37105", "title": "Charformer: Fast Character Transformers via Gradient-based Subword Tokenization"}, {"paperId": "84daddd294fa3cc12596b5785f81c2a153d2fb1d", "title": "Hi-Transformer: Hierarchical Interactive Transformer for Efficient and Effective Long Document Modeling"}, {"paperId": "42e41ab2211b8ba78e36326ea21e05bd25d92c42", "title": "Efficiently Summarizing Text and Graph Encodings of Multi-Document Clusters"}, {"paperId": "21c3cb93aea616720276ed23d871abc582a0f56c", "title": "Systematically Exploring Redundancy Reduction in Summarizing Long Documents"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "0964490205fdc38c2f0980c9d778069089ca92e3", "title": "HiPPO: Recurrent Memory with Optimal Polynomial Projections"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "0bdccacaf89bc45c3d9a8a8ac1c4e60a741d5b48", "title": "DynE: Dynamic Ensemble Decoding for Multi-Document Summarization"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "4fb0a181676a5200bc6e53dea1b770613c164aab", "title": "Leveraging Graph to Improve Abstractive Multi-Document Summarization"}, {"paperId": "6e6a2fe517b33e1f29d761ae31fb37ddccb9a213", "title": "A Large-Scale Multi-Document Summarization Dataset from the Wikipedia Current Events Portal"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "01b15017ac59b8d6f2ce3598c4a7d6358c211426", "title": "A Divide-and-Conquer Approach to the Summarization of Long Documents"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "2e14e84ccec924ed770b58108ad1d9de6f0ca295", "title": "BP-Transformer: Modelling Long-Range Context via Binary Partitioning"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "193b92b2c703dff93fbb0d58070fd2b7651ab3f3", "title": "Extractive Summarization of Long Documents by Combining Global and Local Context"}, {"paperId": "cc27ec53160d88c25fc5096c0df65536eb780de4", "title": "Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "54a13bcc9613dcaa76fb25fbe96572f376cfcca9", "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "6f785623450c17f4d4089dd812bc0de8bcfbb55c", "title": "UPER: Boosting Multi-Document Summarization with an Unsupervised Prompt-based Extractor"}, {"paperId": "47830554cc13f7813c5cbb2c366de4c669057116", "title": "SummN: A Multi-Stage Summarization Framework for Long Input Dialogues and Documents: A Multi-Stage Summarization Framework for Long Input Dialogues and Documents"}, {"paperId": null, "title": "\u2018\u2018Rethinkingattentionwithperformers"}, {"paperId": null, "title": "\u2018\u2018Exploringthelimitsoftransferlearningwithaunified text-to-text transformer,\u2019\u2019"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "\u2018\u2018Attentionisallyouneed"}, {"paperId": null, "title": "LongT5-Mulla: LongT5 With Multi-Level Local Attention for a Longer Sequence"}]}