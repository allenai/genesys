{"paperId": "727b058bf0c3c3b5d18f1937783e8c7bbddcd03d", "abstract": "Recent years have witnessed a substantial increase in the use of deep learning to solve various natural language processing (NLP) problems. Early deep learning models were constrained by their sequential or unidirectional nature, such that they struggled to capture the contextual relationships across text inputs. The introduction of bidirectional encoder representations from transformers (BERT) leads to a robust encoder for the transformer model that can understand the broader context and deliver state-of-the-art performance across various NLP tasks. This has inspired researchers and practitioners to apply BERT to practical problems, such as information retrieval (IR). A survey that focuses on a comprehensive analysis of prevalent approaches that apply pretrained transformer encoders like BERT to IR can thus be useful for academia and the industry. In light of this, we revisit a variety of BERT-based methods in this survey, cover a wide range of techniques of IR, and group them into six high-level categories: (i) handling long documents, (ii) integrating semantic information, (iii) balancing effectiveness and efficiency, (iv) predicting the weights of terms, (v) query expansion, and (vi) document expansion. We also provide links to resources, including datasets and toolkits, for BERT-based IR systems. Additionally, we highlight the advantages of employing encoder-based BERT models in contrast to recent large language models like ChatGPT, which are decoder-based and demand extensive computational resources. Finally, we summarize the comprehensive outcomes of the survey and suggest directions for future research in the area.", "venue": "ACM Computing Surveys", "year": 2024, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2403.00784", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "A survey that focuses on a comprehensive analysis of prevalent approaches that apply pretrained transformer encoders like BERT to IR and highlights the advantages of employing encoder-based BERT models in contrast to recent large language models like ChatGPT, which are decoder-based and demand extensive computational resources."}, "embedding": {"model": "specter_v2", "vector": [0.1443883776664734, 0.22473832964897156, -0.7434225082397461, -0.02422020584344864, -0.5930255055427551, -0.35887330770492554, 0.9920028448104858, 0.07557401806116104, -0.6364952921867371, -0.07435542345046997, 0.7680836319923401, -0.33805325627326965, -0.0669577568769455, 0.13181939721107483, -0.2281872183084488, 0.16351577639579773, -0.3584551215171814, 0.8759500980377197, -0.18308065831661224, -0.8402122259140015, -0.07152403146028519, -0.6958979964256287, -0.6266393661499023, 0.16113314032554626, 0.25448209047317505, 0.4671207666397095, 0.20541886985301971, 0.39147791266441345, -0.5957295894622803, 0.16782160103321075, 0.5631598234176636, -0.6573495268821716, 0.18515744805335999, 0.28409257531166077, -0.5652745962142944, -0.5125535130500793, 0.019222335889935493, -0.5855493545532227, -0.6128896474838257, 0.870351254940033, -0.2490064799785614, 0.37191811203956604, 0.8746623992919922, -0.11167161911725998, -0.9024139046669006, 0.7824475765228271, 0.7974001169204712, 0.9043519496917725, 0.020982516929507256, -0.7903991341590881, 1.6305512189865112, -1.3623437881469727, 0.4103454649448395, 1.5495699644088745, 0.3071575462818146, 0.18557381629943848, -0.29017916321754456, -0.5390289425849915, 0.40336641669273376, 0.022160517051815987, -0.9641820192337036, -0.0979679599404335, -0.14642469584941864, 0.09142274409532547, 1.764128565788269, -0.39301830530166626, 0.1295909285545349, 0.311408668756485, -0.347856730222702, 1.691975712776184, -0.32791048288345337, -1.0642647743225098, -0.654244065284729, 0.29622021317481995, 0.058450594544410706, 0.4926985800266266, -0.5545874834060669, 0.2814701795578003, -0.35003337264060974, 0.09855903685092926, 0.04825396090745926, 0.07649470120668411, -0.22589287161827087, 0.15825992822647095, -0.00025838258443400264, 0.7694619297981262, 0.7990430593490601, 0.800541877746582, -0.2681691646575928, 0.4686044752597809, 0.3712618052959442, 0.4800155758857727, 0.058834291994571686, 0.5799940228462219, -0.06940633803606033, 0.460865318775177, -0.6176872849464417, 0.3097434937953949, -0.20788101851940155, 0.5978970527648926, -0.3706493675708771, -0.2519546449184418, -0.9847022294998169, 0.48396381735801697, 1.1898906230926514, -0.07255266606807709, 0.5270159244537354, -0.5974041223526001, 0.43760302662849426, -0.4723286032676697, 0.12434422224760056, -0.6179035902023315, 0.06879730522632599, -0.27267131209373474, -0.37467992305755615, -1.6933479309082031, -0.8609693050384521, 0.4815748631954193, -0.7216964960098267, 0.5937655568122864, -0.49190065264701843, -0.5964801907539368, 0.07483717054128647, 0.6070285439491272, 0.4523666501045227, 0.9172211289405823, 0.15187285840511322, 0.1480497270822525, 0.918709933757782, -0.6173655390739441, -0.8476920127868652, -0.9728434681892395, 1.1897242069244385, -0.18987149000167847, 0.4066925048828125, -0.2615819275379181, -1.0212559700012207, -0.35179442167282104, -0.4051142930984497, -0.27937787771224976, -0.8502282500267029, 0.08439783751964569, 0.8669554591178894, 0.24566622078418732, -1.116433024406433, 0.40007510781288147, 0.22580939531326294, -0.17098204791545868, 0.29906347393989563, 0.28566309809684753, 0.3299088180065155, -0.8873023986816406, -1.3808162212371826, 0.4684674143791199, 0.2774614989757538, -0.6797751784324646, -0.205767422914505, -0.2881234586238861, -1.1545034646987915, 0.1777629852294922, 0.349534273147583, -0.6064815521240234, 1.3430488109588623, -0.30231973528862, -0.8056837320327759, 0.4752441346645355, -0.38789162039756775, 0.18000033497810364, 0.016551349312067032, -0.32719630002975464, -0.23803989589214325, -0.47463563084602356, 0.1817348152399063, 0.4412286579608917, 0.1639542281627655, -0.08683998137712479, 0.02684694528579712, 0.21124538779258728, -0.023397600278258324, 0.4587526321411133, -0.7840167880058289, 1.221412181854248, -0.7627373933792114, -0.304023414850235, -0.022334085777401924, 0.9739241003990173, 0.04093489423394203, -0.04374212026596069, -0.3249988555908203, -1.102527141571045, 0.7303532361984253, -0.19215324521064758, 1.1270065307617188, -0.8833842277526855, -0.3880093991756439, -0.3637378215789795, -0.14071939885616302, 0.09293162077665329, -0.815224289894104, 1.1433223485946655, -0.3947065770626068, 0.6372380256652832, -0.05604183301329613, -0.9805158972740173, 0.04645444452762604, 0.025338131934404373, -0.6625437140464783, -0.494505375623703, 0.05114218592643738, 1.255274772644043, -1.002040982246399, 0.023573530837893486, -0.20471805334091187, 0.33177193999290466, -0.9004355072975159, 1.0532715320587158, -0.5029990077018738, -0.05285158008337021, -0.44960084557533264, 0.18827161192893982, 0.054202448576688766, -0.5388343334197998, 0.4358743131160736, -0.4411303699016571, -0.0606936477124691, 0.745039165019989, 0.20765700936317444, 0.9665660858154297, -0.3693985641002655, 0.49717533588409424, -0.12252358347177505, -0.887907087802887, -0.156950443983078, 0.66156005859375, 0.039680056273937225, -0.8105855584144592, 0.15165619552135468, 0.4628027677536011, -1.1059072017669678, 0.08248327672481537, 0.7880017757415771, 0.229798823595047, -0.18332907557487488, 0.04495605453848839, 0.5587007403373718, -0.1980491727590561, 0.7344858646392822, 0.5418025255203247, 0.6822675466537476, 0.1252177506685257, 0.34577974677085876, 0.29317790269851685, 0.33471158146858215, -0.5531505942344666, -0.22394178807735443, 0.28755491971969604, 0.9901570081710815, 0.5039359927177429, 0.43765076994895935, -0.4210050702095032, -0.38999488949775696, 0.03670790418982506, 0.5181300044059753, 1.2915503978729248, -0.04844069853425026, -0.40523624420166016, -0.1315736323595047, -0.6636521220207214, -0.14076410233974457, 0.24909444153308868, -0.35671061277389526, -0.3559097349643707, -0.3278689682483673, -1.0387744903564453, 0.6772993206977844, 0.3421958088874817, 0.635343074798584, -0.18586523830890656, 0.37428799271583557, -0.5574610233306885, -0.4134359657764435, -0.6625099182128906, -0.8124346137046814, 0.4438079595565796, -0.7691764831542969, -0.0331055112183094, -0.29603394865989685, -0.2996062934398651, 0.26159602403640747, -0.39089956879615784, 1.1257394552230835, -0.3326297998428345, -0.21638067066669464, 0.22404934465885162, 0.31284958124160767, -0.7356235384941101, -0.4288674294948578, -0.15632188320159912, 0.18803296983242035, -0.6191874742507935, 0.7639414668083191, 0.7066052556037903, -0.08176754415035248, 0.13527390360832214, -0.7949813008308411, -0.030213788151741028, 0.1901393085718155, 0.6479132771492004, 0.6971409916877747, -0.23337753117084503, -0.04226535186171532, -0.9346128702163696, 1.0852484703063965, -0.057406600564718246, -0.6979883313179016, 0.39327478408813477, -0.9147753119468689, -0.28133857250213623, 0.5760606527328491, -0.4468832314014435, -0.42700743675231934, -1.1609389781951904, 0.030114516615867615, -0.1937962770462036, 0.1525469869375229, 0.9740583300590515, 0.5892114639282227, 0.45696085691452026, 0.36741241812705994, 0.5485199093818665, 0.3312852382659912, -0.6311312913894653, 0.6087504625320435, -0.33655911684036255, 0.1312839835882187, 0.3677883744239807, 0.19033090770244598, -0.10183507949113846, -0.3469805419445038, -0.48267436027526855, -0.7624545693397522, -0.7891088724136353, 0.01766435243189335, -0.044202420860528946, -0.07426249235868454, -0.6684317588806152, -0.3788488209247589, -0.6736858487129211, -1.0889134407043457, 0.19534125924110413, -0.08003644645214081, -0.2703028619289398, 0.11068045347929001, -1.228893518447876, -1.4252128601074219, -0.6133269667625427, -0.8199900984764099, -0.8591267466545105, 0.7534191012382507, -0.07459436357021332, 0.15910041332244873, -0.7380179166793823, 0.29797473549842834, -0.06222189962863922, 0.8896721005439758, -0.8046674132347107, 1.1181614398956299, 0.134062260389328, 0.056588489562273026, -0.5162136554718018, -0.1404038965702057, 0.6069709062576294, -0.1722147911787033, 0.047236841171979904, -0.4865003526210785, 0.3280605673789978, -0.5060681104660034, -0.2964637577533722, 0.15666167438030243, 0.38848379254341125, 0.6473518013954163, -0.3358744978904724, -0.6148898005485535, 0.3613494336605072, 1.8665416240692139, -0.6073659658432007, -0.06221670284867287, 0.44454526901245117, 0.694841742515564, 0.21809692680835724, -0.12157756835222244, 0.5266696214675903, 0.328808456659317, 0.6558111310005188, 0.36153215169906616, -0.13439247012138367, -0.09418563544750214, -0.8401241302490234, 0.44375038146972656, 1.2222579717636108, 0.31067705154418945, -0.427021861076355, -1.1636316776275635, 0.7099029421806335, -0.9061148166656494, -0.5252596139907837, 0.7624770998954773, 0.5241017937660217, 0.5899629592895508, -0.8076402544975281, -0.3965623378753662, -0.5125612616539001, 0.21113713085651398, 0.05952427163720131, -0.08593548089265823, -0.4077121317386627, 0.06245241314172745, 0.29035714268684387, 0.4921192526817322, 0.33377906680107117, -0.3039173185825348, 0.7348719239234924, 14.755906105041504, 0.8718476295471191, -0.03733295947313309, 0.6300836205482483, 0.43156394362449646, 0.2046753168106079, -0.5259597897529602, -0.1576467603445053, -1.3539066314697266, -0.2719382047653198, 0.9525258541107178, -0.15259462594985962, 0.4186538755893707, 0.040631745010614395, -0.01999957673251629, 0.47398054599761963, -0.5026593208312988, 0.6179274916648865, 0.603980302810669, -1.286118507385254, 0.7533960938453674, 0.5065212845802307, 0.04384780675172806, 0.8263058066368103, 0.9060221314430237, 0.9437901377677917, 0.6094213128089905, -0.4855530560016632, 0.19333574175834656, 0.04435684531927109, 0.9318054914474487, 0.3009507358074188, 0.784106969833374, 0.8169480562210083, -0.6339315176010132, -0.8925228118896484, -0.6014879941940308, -0.7631527781486511, 0.4726966917514801, -0.004155158996582031, -0.7449449896812439, -0.12429268658161163, -0.15177412331104279, 0.9615383148193359, 0.19169513881206512, 0.4061248302459717, -0.127634659409523, 0.46854597330093384, -0.5302159786224365, -0.009127006866037846, 0.6959511637687683, 0.19516153633594513, 0.3317549228668213, 0.13089975714683533, 0.3020171821117401, -0.04415765777230263, 0.1440337896347046, 0.28177565336227417, -1.0170191526412964, 0.25221550464630127, -0.9910956621170044, -0.5015371441841125, -0.19604600965976715, 0.31020957231521606, 0.8681875467300415, 0.13446968793869019, -0.40443646907806396, 0.41596609354019165, 0.6437175869941711, 0.4507470726966858, 0.02709844708442688, -0.13189730048179626, 0.19497214257717133, 0.05017685890197754, 0.018698176369071007, 0.7754255533218384, 0.09834741055965424, -0.4580157399177551, -0.582592248916626, -0.058591969311237335, 0.811112642288208, -0.8470662236213684, -0.9034090042114258, 0.8815732598304749, -0.0018321453826501966, -0.8417062759399414, -0.03709842264652252, -0.8925999402999878, 0.4844895899295807, 0.5647481083869934, -2.0614545345306396, -0.4367216229438782, 0.5561147332191467, -0.2747090756893158, -0.4529900550842285, 0.14431722462177277, 1.2214025259017944, 0.5947389006614685, -0.23158849775791168, -0.0660264641046524, 0.6142876744270325, 0.20146508514881134, -0.25420165061950684, -0.8117125630378723, 0.211858332157135, -0.0976017490029335, -0.015513446182012558, 0.5325950980186462, -0.18569087982177734, 0.09428971260786057, -0.8844662308692932, -0.06191195175051689, 0.8741562366485596, -0.8896285891532898, -0.5582524538040161, -0.39558497071266174, -0.5816909074783325, 0.1698664426803589, 0.5063759684562683, -0.3581402599811554, 0.43867066502571106, 0.40816500782966614, -0.7500259280204773, -0.21617981791496277, -0.8501147627830505, 0.1651371866464615, 0.3762989342212677, -0.6299167275428772, -0.3163760006427765, 0.6134410500526428, 0.34724560379981995, -0.5742320418357849, -0.3292180001735687, -0.0005087009631097317, -0.22919431328773499, 0.46073004603385925, 1.3058726787567139, -0.494611531496048, 0.7226505875587463, 0.834097146987915, -0.29797062277793884, -0.5866971015930176, -0.2601114809513092, -0.4974437654018402, -0.05353914946317673, -0.2584781050682068, 0.7345665693283081, -0.3092971742153168, 0.10315411537885666, 0.853100061416626, 0.3360927999019623, -0.4771685004234314, -0.4596741497516632, -0.5076898336410522, 0.155164897441864, -0.059227075427770615, -0.054869163781404495, -0.12941160798072815, 0.07046622782945633, 0.3594968318939209, 0.5723244547843933, 0.3323225975036621, -0.3398536443710327, -0.8090577125549316, 0.13964112102985382, -0.1734437644481659, 0.09514213353395462, -0.4885835349559784, -0.2856258153915405, -2.0623559951782227, -0.13070231676101685, -1.3007913827896118, 0.026796307414770126, -1.3056106567382812, -0.31853005290031433, -0.05699971690773964, -0.16543243825435638, 0.10808351635932922, 0.6184431910514832, -0.26582953333854675, -0.4389441907405853, -0.20299911499023438, -0.4937926232814789, 1.13105309009552, 0.9755494594573975, -0.7839393615722656, 0.1315385401248932, -0.20125313103199005, -0.16779014468193054, 0.09755726903676987, 0.18039804697036743, -0.4570510685443878, -0.785616397857666, -1.8264529705047607, 0.5921878218650818, -0.060322463512420654, -0.2537913918495178, 0.18644395470619202, 0.5272824168205261, 0.32590317726135254, -0.5275261998176575, 0.12322115153074265, 0.8082348704338074, -1.1211376190185547, -0.7816238403320312, 0.03433274105191231, -0.9137243032455444, 0.36389636993408203, -0.2335723340511322, -0.28215086460113525, -0.7108140587806702, 0.4411068260669708, -0.1829322874546051, -1.3127186298370361, -0.21074920892715454, 0.47250989079475403, -0.7556108236312866, 0.01800706423819065, -0.5796200633049011, -0.11714914441108704, -0.8939195275306702, -0.6969994306564331, 0.4589768350124359, 0.5340014696121216, -0.65742427110672, 0.7129908800125122, 0.7383049726486206, -1.183765172958374, 0.062306229025125504, 0.04047397896647453, 0.07788803428411484, -0.058488693088293076, -0.0981387048959732, 0.36575278639793396, -0.2739187777042389, 0.9219484329223633, 0.6136206388473511, 0.3499624729156494, -0.8837003111839294, 0.20270906388759613, 0.7723295092582703, -0.8409221172332764, -0.4039307236671448, 1.0726696252822876, -0.18410037457942963, -1.2109410762786865, 0.2212689369916916, -0.7914985418319702, -0.8363785147666931, -0.2790934443473816, 0.5822871923446655, -0.2554377317428589, 0.04808787629008293, -0.02555234171450138, -0.3145577907562256, -0.023814426735043526, -0.1426912248134613, -0.6703654527664185, 0.8724213242530823, -0.3022466003894806, -0.5168948173522949, 0.566780149936676, 1.3643776178359985, -1.2092044353485107, 0.012561582960188389, -1.056891679763794, -0.20521831512451172, -0.5613666772842407, 0.5892934799194336, -0.682336151599884, -0.3510114550590515, 0.695805549621582, 0.4699021279811859, 0.16892878711223602, 0.5567335486412048, -0.0016164868138730526, 0.42537716031074524, 1.066371202468872, -0.20834918320178986, -0.7634773850440979, -0.6174874901771545, 1.5836843252182007, 1.3372015953063965, -1.0821932554244995, 0.21785826981067657, -0.18361888825893402, -0.624926745891571, 0.8442138433456421, -0.0981047973036766, 0.4999983608722687, 1.0852370262145996, -0.27767229080200195, -0.0008553208317607641, -0.33594727516174316, -0.973869800567627, -0.3027782142162323, 1.0330276489257812, 1.0086312294006348, 0.9334582686424255, -0.027894048020243645, -0.0522102452814579, 0.48211342096328735, 0.3796418607234955, 0.3652636706829071, 0.042233098298311234, 0.5761925578117371, -0.08507085591554642, -0.3835435211658478, 0.15991193056106567, 0.7738869786262512, -0.7533087730407715, -0.8488940596580505, -0.070600226521492, 0.4090312123298645, -0.29296231269836426, 0.3153577446937561, 0.7226138710975647, 0.09098175913095474, 0.47039711475372314, 0.06069343909621239, 0.01391379814594984, -0.7749108672142029, -0.39542895555496216, -0.12784329056739807, -0.37657803297042847, 0.32276439666748047, -0.2582244873046875, -0.7012923955917358, 0.14389358460903168, 0.2051042914390564, 0.005020663142204285, 0.2988394796848297, 0.5024800896644592, 0.9312711358070374, 0.3773782551288605, 0.0170146394520998, -0.2821250855922699, 0.15953682363033295, -0.7576869130134583, -1.0310100317001343, 0.01347601879388094, -0.40058624744415283, -0.24365200102329254, -0.23488487303256989, 0.008349686861038208, -0.3961484134197235]}, "authors": [{"authorId": "2284407468", "name": "Jiajia Wang"}, {"authorId": "2257129648", "name": "Jimmy X. Huang"}, {"authorId": "2284376401", "name": "Xinhui Tu"}, {"authorId": "2110265731", "name": "Junmei Wang"}, {"authorId": "2146872105", "name": "Angela J. Huang"}, {"authorId": "46437970", "name": "Md Tahmid Rahman Laskar"}, {"authorId": "2284375773", "name": "Amran Bhuiyan"}], "references": [{"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "2d3bc530d8f1ed36932a70bc362ea94d988adec9", "title": "Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting"}, {"paperId": "ea7e6df5b48f36dd13c838fd56744aae6189ee8b", "title": "Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with Fine-Tuned Generative Transformers"}, {"paperId": "d3060876d9ad4e4e50e1c88a8c04186df00f24e2", "title": "A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets"}, {"paperId": "b6d6c33298b852cf63edac233deca70530d69a2a", "title": "PaLM 2 Technical Report"}, {"paperId": "3a14af18549daee147c6c747592be314418eeac3", "title": "Evaluating Embedding APIs for Information Retrieval"}, {"paperId": "11d644abe12e3d7284a3b989eb0b39337c0c2235", "title": "SPRF: A semantic Pseudo-relevance Feedback enhancement for information retrieval via ConceptNet"}, {"paperId": "459c82205d2a27a8542bba7a4d478a8a23be2f5d", "title": "Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "754fad16ccde2328b302162571650254acd38203", "title": "Query Expansion Using Contextual Clue Sampling with Language Models"}, {"paperId": "c641b74e5ee79c154cd3ff0082f985be51ad5cb4", "title": "BERT-based Dense Intra-ranking and Contextualized Late Interaction via Multi-task Learning for Long Document Retrieval"}, {"paperId": "672524688552788d319da3917dd7c7540cabc926", "title": "How to Approach Ambiguous Queries in Conversational Search: A Survey of Techniques, Approaches, Tools, and Challenges"}, {"paperId": "55048371e2f7e5ccbd10f9e9f5a293f2d58cad43", "title": "RLAS-BIABC: A Reinforcement Learning-Based Answer Selection Using the BERT Model Boosted by an Improved ABC Algorithm"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "6296aa7cab06eaf058f7291040b320b5a83c0091", "title": "Generative Adversarial Networks"}, {"paperId": "9de4255f6cab1a3555b660c159e12ebd24671a19", "title": "Improving BERT-based Query-by-Document Retrieval with Multi-Task Optimization"}, {"paperId": "fafc41f99f5664edfb657411f176a2dceca5ecba", "title": "A probabilistic framework for integrating sentence-level semantics via BERT into pseudo-relevance feedback"}, {"paperId": "7e0c7fdad758482375cb89a110b2f5ad4bee57dd", "title": "Domain Adaptation with Pre-trained Transformers for Query-Focused Abstractive Text Summarization"}, {"paperId": "77d2456630d7b22efe84bffcc7d4ad495ce50a6d", "title": "ISEEQ: Information Seeking Question Generation using Dynamic Meta-Information Retrieval and Knowledge Graphs"}, {"paperId": "1c2edf38c684b1938304cf024f5993241642f3d4", "title": "Improving Query Representations for Dense Retrieval with Pseudo Relevance Feedback"}, {"paperId": "9583d94fe6297acb3f287329dff6fe09b1c5c4c2", "title": "KeyBLD: Selecting Key Blocks with Local Pre-ranking for Long Document Information Retrieval"}, {"paperId": "1e8a6de5561f557ff9abf43d538d8d5e9347efa0", "title": "SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking"}, {"paperId": "e1442211e1c68e67bb090e1fefb6069f3e2a8a40", "title": "BERT-based Dense Retrievers Require Interpolation with BM25 for Effective Passage Retrieval"}, {"paperId": "44772b24ae2f68b77476c814b0607370f7195ddb", "title": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval"}, {"paperId": "ab64ea2c1a9a419b21e8b7ea16f5cf12323a5bc8", "title": "Intra-Document Cascading: Learning to Select Passages for Neural Document Ranking"}, {"paperId": "4aa1d28944856ebe1950a27f633c6667ead3cbf8", "title": "Learning Passage Impacts for Inverted Indexes"}, {"paperId": "4deed74a3eee7e629dce2b8ef1e437ca74b2e64a", "title": "Efficiently Teaching an Effective Dense Retriever with Balanced Topic Aware Sampling"}, {"paperId": "5ac627f229fa8d54f5ad43f7f99e9b29d93ada29", "title": "Pyserini: An Easy-to-Use Python Toolkit to Support Replicable IR Research with Sparse and Dense Representations"}, {"paperId": "8640fa2e2b38a4a2daa0426af641190efb887d6d", "title": "OpenMatch: An Open Source Library for Neu-IR Research"}, {"paperId": "faea04bf558c1a8b072bdcfe3cebe06ea4d9d9ca", "title": "WSL-DS: Weakly Supervised Learning with Distant Supervision for Query Focused Multi-Document Abstractive Summarization"}, {"paperId": "83f915d30720f1aa1c6f6a4342d7f9e52add756e", "title": "Distilling Dense Representations for Ranking using Tightly-Coupled Teachers"}, {"paperId": "63c2790ae3e086711e8e28c05867221f49c0401c", "title": "TwinBERT: Distilling Knowledge to Twin-Structured Compressed BERT Models for Large-Scale Retrieval"}, {"paperId": "2c953a3c378b40dadf2e3fb486713c8608b8e282", "title": "Pretrained Transformers for Text Ranking: BERT and Beyond"}, {"paperId": "57a07372e2a620d6ae920f74877eee5f61753a96", "title": "SparTerm: Learning Term-based Sparse Representation for Fast Text Retrieval"}, {"paperId": "7de08d1bc7793f1b47e6e768c81ec1d3bf183500", "title": "BERT-QE: Contextualized Query Expansion for Document Re-ranking"}, {"paperId": "e1d89e5a9585a28c9530e2e336876d3dd41c021d", "title": "PARADE: Passage Representation Aggregation forDocument Reranking"}, {"paperId": "a6b1126e058262c57d36012d0fdedc2417ad04e1", "title": "Declarative Experimentation in Information Retrieval using PyTerrier"}, {"paperId": "5ce90526f8e30178b4d6ade1930bd9fdced51fc1", "title": "Context-Aware Term Weighting For First Stage Passage Retrieval"}, {"paperId": "c9b8593db099869fe7254aa1fa53f3c9073b0176", "title": "Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval"}, {"paperId": "a90548155c28085ac4cd7f502ab6be09562ebcd7", "title": "RepBERT: Contextualized Text Embeddings for First-Stage Retrieval"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "58ed1fbaabe027345f7bb3a6312d41c5aac63e22", "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"}, {"paperId": "26fe14f993b21f6f2cda7cfb2ce74b212516e247", "title": "Query Focused Abstractive Summarization via Incorporating Query Relevance and Transfer Learning with Transformer Models"}, {"paperId": "de028eebe67b2bc74c471c9429914242fd5ed346", "title": "Local Self-Attention over Long Text for Efficient Document Retrieval"}, {"paperId": "050050e30d0f162c4dd87c1aac8d37df266e4c93", "title": "Sparse, Dense, and Attentional Representations for Text Retrieval"}, {"paperId": "28307bc149a74cfcae657f782f1c7630b6f4acce", "title": "Contextualized Embeddings based Transformer Encoder for Sentence Similarity Modeling in Answer Selection Task"}, {"paperId": "0c57dcf959ead9530f9ec3ebe0dd58de42a3e8af", "title": "Expansion via Prediction of Importance with Contextualization"}, {"paperId": "1652ddc918111b7cd014645280876dc532edadd9", "title": "Training Curricula for Open Domain Answer Re-Ranking"}, {"paperId": "60b8ad6177230ad5402af409a6edb5af441baeb4", "title": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT"}, {"paperId": "7b9b756ab509cb9f52dbac95e3e901d571f0784f", "title": "A Survey of the Usages of Deep Learning for Natural Language Processing"}, {"paperId": "03dee59cebd61a26611c7abf5bc19d416a1c5ca1", "title": "Context-Aware Document Term Weighting for Ad-Hoc Search"}, {"paperId": "68e4f65d63822a722422aaf4019435a66aecdd88", "title": "Leveraging Passage-level Cumulative Gain for Document Ranking"}, {"paperId": "b26f2037f769d5ffc5f7bdcec2de8da28ec14bee", "title": "Dense Passage Retrieval for Open-Domain Question Answering"}, {"paperId": "5d34881ff68bd203ff790187e7e5c9e034389cfa", "title": "FastBERT: a Self-distilling BERT with Adaptive Inference Time"}, {"paperId": "d16ab5c19ed33a263b6412ac41a4ea1f068d254a", "title": "Revisiting Pre-Trained Models for Chinese Natural Language Processing"}, {"paperId": "d843bc13306cd816f4628c0bb385230a2265a469", "title": "Rethinking Query Expansion for BERT Reranking"}, {"paperId": "6dbdc34000b034b75b8ff70872fc7c35549e273a", "title": "Interpretable & Time-Budget-Constrained Contextualization for Re-Ranking"}, {"paperId": "8b780041274aebb8390ab0097015ac0887e9de0f", "title": "Selective Weak Supervision for Neural Information Retrieval"}, {"paperId": "421c3f395b4483c2b723ecb3472cb88708b50264", "title": "Capreolus: A Toolkit for End-to-End Neural Ad Hoc Retrieval"}, {"paperId": "7a323447c702ab3d94b28634ffe5d488f49059dd", "title": "OpenNIR: A Complete Neural Ad-Hoc Ranking Pipeline"}, {"paperId": "b80406142c01d3f512764c8ffc92c66acde38aa2", "title": "Cross-Domain Sentence Modeling for Relevance Transfer with BERT"}, {"paperId": "d5b6ed0108c5f5fa48032f04f871f17818480cce", "title": "TU Wien @ TREC Deep Learning '19 - Simple Contextualization for Re-ranking"}, {"paperId": "b1e25e6dcf66029952b4f925c81848c04c97f2b6", "title": "Sentiment analysis using deep learning architectures: a review"}, {"paperId": "6b556a6dd7221aa431941251555e52492a2878f5", "title": "Cross-Lingual Relevance Transfer for Document Retrieval"}, {"paperId": "df12d1d972708250f3769eaaa34f4b156cf695fe", "title": "Applying BERT to Document Retrieval with Birch"}, {"paperId": "63a2fabbe4b1615a84d5f4d90987733cf09e3ff8", "title": "Multi-Stage Document Ranking with BERT"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "29af6163d16b4a245d9fe3efd624e0bf793751d4", "title": "Neural networks for facial age estimation: a survey on recent advances"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "d56c1fc337fb07ec004dc846f80582c327af717c", "title": "StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "1d8f4f54ed7a80d1d7172a09c33cd627de570bca", "title": "MatchZoo: A Learning, Practicing, and Developing System for Neural Text Matching"}, {"paperId": "7a31e2dcbaa1cf6e9f76084793a02a2a4e4c2d15", "title": "Deeper Text Understanding for IR with Contextual Neural Language Modeling"}, {"paperId": "b092b6b843e9421bf42bf96f57ed4658a3e0bdf7", "title": "Document Expansion by Query Prediction"}, {"paperId": "1ec78c0ec945572673fabd50bf263870fe9d3601", "title": "CEDR: Contextualized Embeddings for Document Ranking"}, {"paperId": "2a567ebd78939d0861d788f0fedff8d40ae62bf2", "title": "Publicly Available Clinical BERT Embeddings"}, {"paperId": "ea57734824426a427f8b9139da1ae574cc929543", "title": "Simple Applications of BERT for Ad Hoc Document Retrieval"}, {"paperId": "ecd798da82a879077dabd28cd467f71a441d9a52", "title": "Passage Ranking with Weak Supervsion"}, {"paperId": "47354d4d1915ae3d286d401005ba8a44af7d1fa5", "title": "A Deep Look into Neural Ranking Models for Information Retrieval"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "8452941a175c899628c679523da952b18f63e335", "title": "A survey of the recent architectures of deep convolutional neural networks"}, {"paperId": "85e07116316e686bf787114ba10ca60f4ea7c5b2", "title": "Passage Re-ranking with BERT"}, {"paperId": "f4b96cbeff598f6655ec16bfc754b92fa416df21", "title": "On the Theory of Weak Supervision for Information Retrieval"}, {"paperId": "51bf901f64239ede59f6cef4609c21a318f7d479", "title": "Neural Query Performance Prediction using Weak Supervision from Multiple Signals"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "a76706d350b8c483a3aff73e61b91d15b5687335", "title": "Universal Sentence Encoder"}, {"paperId": "fc3384d631f5e2b2a9d66623d4d3e1d28b96dee7", "title": "Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search"}, {"paperId": "c5027ff2a8b026f00d2c81ec94b0e270667589be", "title": "Learning to Learn from Weak Supervision by Full Supervision"}, {"paperId": "c15679f1e190f559cb6123bfa058b5b8adc8c81e", "title": "Neural information retrieval: at the end of the early years"}, {"paperId": "ac1c247e9edbef62e7f44d863d261aeca280510b", "title": "Training Deep Ranking Model with Weak Relevance Labels"}, {"paperId": "bc34eee11d8ddba18a262a637ea336322c93ba6c", "title": "Enhancing Recurrent Neural Networks with Positional Attention for Question Answering"}, {"paperId": "61344ba701960b3d16e4792216e4b2ef9bc7c570", "title": "Anserini: Enabling the Use of Lucene for Information Retrieval Research"}, {"paperId": "bc8fa64625d9189f5801837e7b133e7fe3c581f7", "title": "Learned in Translation: Contextualized Word Vectors"}, {"paperId": "0b6f172def2f4b37ea85969b4d99e789c647726b", "title": "Deep Learning Based Recommender System"}, {"paperId": "2ba7fd1f72e1219ac1df3d78fc32de9ba5568b17", "title": "Co-PACRR: A Context-Aware Neural IR Model for Ad-hoc Retrieval"}, {"paperId": "ea738439b880ad033ff01602ea52d04b366d0d37", "title": "End-to-End Neural Ad-hoc Ranking with Kernel Pooling"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "4ac36cecc5d87bd5a600fbdc599013442b6dd428", "title": "Neural Models for Information Retrieval"}, {"paperId": "776d9e705c8d27c3a71219e72128e8285119a39e", "title": "A survey of deep neural network architectures and their applications"}, {"paperId": "668db48c6a79826456341680ee1175dfc4cced71", "title": "Get To The Point: Summarization with Pointer-Generator Networks"}, {"paperId": "dd95f96e3322dcaee9b1e3f7871ecc3ebcd51bfe", "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset"}, {"paperId": "cc16e43cce64b649da00892d1493425620c2d61c", "title": "Learning to Match using Local and Distributed Representations of Text for Web Search"}, {"paperId": "d51ed05fd05b9d222427a05a87ed88217447b44f", "title": "A Deep Relevance Matching Model for Ad-hoc Retrieval"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "a5d3dfa6394340fd027425aef9e7384789925726", "title": "Match-SRNN: Modeling the Recursive Matching Structure with Spatial RNN"}, {"paperId": "b9e505fad7ffbb35bd30b7a2b63226291bfd857f", "title": "Text Matching as Image Recognition"}, {"paperId": "bf76690e93fd06ba1f86cf029fd62ae3ac770968", "title": "A Deep Architecture for Semantic Matching with Multiple Positional Sentence Representations"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "9f08b01251cb99f4ffae8c7b3e4468d3af9c98d3", "title": "Convolutional Neural Network Architectures for Matching Natural Language Sentences"}, {"paperId": "5c32734fd4a0765db5c11971f8293e4e2089e5ce", "title": "Overview of the TREC-2014 Microblog Track"}, {"paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "title": "GloVe: Global Vectors for Word Representation"}, {"paperId": "d2d1f7e34d3cedc2f7815200f0eaf87dd19e743f", "title": "Modeling Term Associations for Probabilistic Information Retrieval"}, {"paperId": "fdb813d8b927bdd21ae1858cafa6c34b66a36268", "title": "Learning deep structured semantic models for web search using clickthrough data"}, {"paperId": "bf12bfee8cef735391961c504c6b69f97e6bea6e", "title": "Using Semantic-Based Association Rule Mining for Improving Clinical Text Retrieval"}, {"paperId": "842be61344143bc78cc3a5ebebcedf9f079903b1", "title": "High performance query expansion using adaptive co-training"}, {"paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09", "title": "Efficient Estimation of Word Representations in Vector Space"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "e33cbb25a8c7390aec6a398e36381f4f7770c283", "title": "Deep Neural Networks for Acoustic Modeling in Speech Recognition"}, {"paperId": "38f14e622258cc6055bdd320189c99f910811281", "title": "CRTER: using cross terms to enhance probabilistic information retrieval"}, {"paperId": "a92054c6f26c1ca47139e642fcfaf1733fff8fd9", "title": "Modeling term proximity for probabilistic information retrieval models"}, {"paperId": "d8e4a2966887a371e58079d235f8b75c615dbfe3", "title": "Finding a good query-related topic for boosting pseudo-relevance feedback"}, {"paperId": "35d8e52e72d835bdc20c62df5762b6b6e8354341", "title": "A Survival Modeling Approach to Biomedical Search Result Diversification Using Wikipedia"}, {"paperId": "78234e51531fec5478b75a37c70cdec19f437e37", "title": "TREC-CHEM: large scale chemical information retrieval evaluation at TREC"}, {"paperId": "1485f07d7d9194d15f09ed222388700585f457f3", "title": "Overview of the TREC 2011 Chemical IR Track"}, {"paperId": "50b31cc4a3d7e2742459c272237d8f00a5c92661", "title": "A bayesian learning approach to promoting diversity in ranking for biomedical information retrieval"}, {"paperId": "1a097efc0e15419e24782499e3047e676da24e9d", "title": "A Boolean Model in Information Retrieval for Search Engines"}, {"paperId": "47ced790a563344efae66588b5fb7fe6cca29ed3", "title": "The Probabilistic Relevance Framework: BM25 and Beyond"}, {"paperId": "ee8b844559def77c6a573f2c18b73d1e672c1049", "title": "Search Engines: Information Retrieval in Practice"}, {"paperId": "11543c44ed72784c656362b2ef42f7509250a423", "title": "ARSA: a sentiment-aware model for predicting sales performance using blogs"}, {"paperId": "b128d69fa7ccba2a80a6029d2208feddb246b6bd", "title": "Applying Machine Learning to Text Segmentation for Information Retrieval"}, {"paperId": null, "title": "Using language models for information retrieval"}, {"paperId": "35a2b204ee6da98232674728e82f7fedd9f46931", "title": "Working memory"}, {"paperId": "8b7cbdd9e7fca94e686d726442d94635378ae04f", "title": "Extended Boolean information retrieval"}, {"paperId": "d5f169880e30e1f76827d72f862555d00b01bed9", "title": "A vector space model for automatic indexing"}, {"paperId": "8b84b9b1fd3ac5822dada565d48bcb159f493c04", "title": "Comparing Score Aggregation Approaches for Document Retrieval with Pretrained Transformers"}, {"paperId": "a5fa6e7565dca654eab9372ace4b1ba7f63655f7", "title": "CogLTX: Applying BERT to Long Texts"}, {"paperId": "1dbccfbf6cbae94d8e2cb33765b1b522728c3a5e", "title": "Deep learning on information retrieval and its applications"}, {"paperId": "15cef72e29a94f01ce90f1d3b7e9a4c945e086ba", "title": "Context-Aware Passage Term Weighting For First Stage Retrieval"}, {"paperId": null, "title": "ELECTRA: Pre-training text encoders as discriminators rather than generatorsg"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "95d2820c9fae8f0f858ec982bfe5fb7eb27f38ce", "title": "IDST at TREC 2019 Deep Learning Track: Deep Cascade Ranking with Generation-based Document Expansion and Pre-trained Language Modeling"}, {"paperId": "54fa64b74ec020699fad989f85e74e50c7a34445", "title": "From doc2query to docTTTTTquery"}, {"paperId": null, "title": "Transformer-XL: Attention language models beyond a fixed-length comtext"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "556c3480cd0817fb0968c22b5ce9ca4d13bebaa9", "title": "TREC Complex Answer Retrieval Overview"}, {"paperId": "c68796f833a7151f0a63d1d1608dc902b4fdc9b6", "title": "GENERATIVE ADVERSARIAL NETS"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": "ea67efe9866b245ea2b0bbb526239fbd7070f635", "title": "An Introduction to Information Retrieval"}, {"paperId": "040e3d5d38bdb9f9694f19fb62c583e6a9c34c93", "title": "York University at TREC 2005: Genomics Track"}, {"paperId": "24b27054ab47fe67aa0a25a8a7f3f2fc5bc3e59c", "title": "Overview of the TREC 2004 Robust Track."}, {"paperId": "73a76dd71abfbd29dbba4ea034ab52284626aa71", "title": "A language modeling approach to information retrieval"}, {"paperId": null, "title": "Manuscript submitted to"}, {"paperId": null, "title": "Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges"}, {"paperId": null, "title": "Received 19 July 2021; revised 21 December 2023; accepted 31 January 2024"}, {"paperId": null, "title": "2023. GPT-4 technical report. arXiv:2303.08774"}, {"paperId": null, "title": "Expansion with concepts adds new concepts to the original query by using additional terms"}]}