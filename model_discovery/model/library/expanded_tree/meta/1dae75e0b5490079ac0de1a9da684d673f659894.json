{"paperId": "1dae75e0b5490079ac0de1a9da684d673f659894", "abstract": "Parameter-efficient transfer learning (PETL) has emerged as a flourishing research field for adapting large pre-trained models to downstream tasks, greatly reducing trainable parameters while grappling with memory challenges during fine-tuning. To address it, memory-efficient series (METL) avoid backpropagating gradients through the large backbone. However, they compromise by exclusively relying on frozen intermediate outputs and limiting the exhaustive exploration of prior knowledge from pre-trained models. Moreover, the dependency and redundancy between cross-layer features are frequently overlooked, thereby submerging more discriminative representations and causing an inherent performance gap (vs. conventional PETL methods). Hence, we propose an innovative METL strategy called SHERL for resource-limited scenarios to decouple the entire adaptation into two successive and complementary processes. In the early route, intermediate outputs are consolidated via an anti-redundancy operation, enhancing their compatibility for subsequent interactions; thereby in the late route, utilizing minimal late pre-trained layers could alleviate the peak demand on memory overhead and regulate these fairly flexible features into more adaptive and powerful representations for new domains. Extensive ablations on vision-and-language and language-only tasks show that SHERL combines the strengths of both parameter and memory-efficient techniques, performing on-par or better across diverse architectures with lower memory during fine-tuning. Our code is publicly available at: https://github.com/Paranioar/SHERL.", "venue": "", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Extensive ablations on vision-and-language and language-only tasks show that SHERL combines the strengths of both parameter and memory-efficient techniques, performing on-par or better across diverse architectures with lower memory during fine-tuning."}, "embedding": {"model": "specter_v2", "vector": [0.5616645216941833, 0.20311339199543, -0.4277041554450989, 0.10569687187671661, -0.4073207974433899, 0.2498508095741272, 0.6922438740730286, -0.39357924461364746, -0.7736191749572754, 0.09486022591590881, -0.2594577372074127, 0.15952222049236298, 0.4047253131866455, 0.24296972155570984, -0.05115056037902832, 0.06637795269489288, -1.1631664037704468, 0.35710608959198, 0.5142089128494263, -0.5773738622665405, -0.21124395728111267, -0.15261869132518768, -0.9145511388778687, -0.260267972946167, 0.22399276494979858, 0.8561923503875732, 0.3480757176876068, 0.8911160230636597, -0.1540132462978363, 0.05862891301512718, 0.5524960160255432, -0.44755256175994873, 0.5874819159507751, -0.24520626664161682, -0.4961939752101898, -0.08122844249010086, 0.5606040358543396, -0.5404761433601379, -0.31509050726890564, 0.519528865814209, 0.12164730578660965, 0.432050883769989, 0.6790175437927246, -0.8460261821746826, -0.08891049772500992, 0.24091744422912598, 0.25534895062446594, 0.8341293334960938, -0.982555091381073, -0.31815385818481445, 0.8713306188583374, -1.697098731994629, 0.03557068482041359, 1.0722277164459229, 0.9798741936683655, 0.7485571503639221, -0.27377092838287354, -0.7383076548576355, 0.7226186990737915, -0.06569820642471313, -0.7753161787986755, -0.4531274139881134, 0.01850784197449684, 0.15268827974796295, 1.9336433410644531, -0.8639882206916809, 0.13441766798496246, 0.7724400162696838, -0.20382395386695862, 1.247489333152771, -0.22141580283641815, -0.6627148389816284, -0.503685474395752, 0.29382166266441345, 0.1045524999499321, 1.0548723936080933, -0.4471187889575958, 0.19784007966518402, -1.1864839792251587, 0.16732344031333923, 0.724475085735321, -0.22526738047599792, 0.1599636971950531, -0.3357153832912445, -0.2319009155035019, 0.5987929701805115, 0.8829996585845947, 0.5536196827888489, -0.28669413924217224, 0.6897065043449402, 0.4898394048213959, 0.8198131322860718, 0.4777974486351013, 0.12326031923294067, -0.19619184732437134, 0.6281790137290955, -0.584791362285614, -0.18112368881702423, -0.18016885221004486, 1.1018275022506714, 0.4941224455833435, 0.3853093087673187, -0.47045403718948364, 0.324565052986145, 1.1957666873931885, -0.17996546626091003, 0.5221983790397644, -0.4022241234779358, 0.5494804978370667, -0.6995255351066589, -0.06253674626350403, -0.5434272885322571, -0.20849110186100006, -0.40969860553741455, -0.9403800964355469, -1.149641990661621, -0.772314727306366, 0.2549155652523041, -0.5309597253799438, 0.7416244149208069, -0.2247251719236374, 0.2989276945590973, 0.06966572254896164, 0.5445049405097961, 0.27843764424324036, 0.5640676021575928, 0.9182524681091309, 0.054634567350149155, 0.5525823831558228, -1.3151133060455322, -0.11706359684467316, -1.1906182765960693, 0.4460025727748871, -0.35672029852867126, 0.3503689765930176, -0.6213186979293823, -1.5706762075424194, -1.112714409828186, -1.1401889324188232, 0.14735980331897736, -0.7472686767578125, 0.24234531819820404, 1.077668309211731, -0.026484819129109383, -1.0287272930145264, 1.1809284687042236, -0.1316235512495041, -0.3896405100822449, 0.48894521594047546, 0.803260087966919, 0.15063871443271637, -0.10884882509708405, -1.1191596984863281, 0.5202834606170654, 0.5446293354034424, -0.1025574654340744, -0.27202972769737244, -0.7751316428184509, -0.6163695454597473, -0.16969706118106842, -0.018456818535923958, -1.2006233930587769, 1.1555979251861572, -0.7740170955657959, -1.5964854955673218, 0.7085037231445312, 0.043262582272291183, 0.11924845725297928, 0.6523473858833313, -0.17163416743278503, -0.3361980617046356, -0.018908701837062836, -0.8123908638954163, 1.0832359790802002, 1.0168522596359253, 0.0032437690533697605, -0.12922103703022003, 0.18346838653087616, -0.793250560760498, 0.3980307877063751, -0.6547533869743347, 0.6005539894104004, -0.5878586173057556, -0.07506730407476425, 0.3802758753299713, 0.4626832902431488, 0.10026852041482925, -0.2099572718143463, 0.061072107404470444, -0.9185504913330078, 0.7370203137397766, 0.2673632800579071, 0.6587613224983215, -0.886533260345459, -0.41653311252593994, -0.2399204522371292, -0.1589350700378418, -0.0813043862581253, -1.3055897951126099, 0.5745827555656433, -0.17365117371082306, 0.09034902602434158, -0.1716592013835907, -1.3264696598052979, 0.03508129343390465, -0.7423738241195679, -0.6621622443199158, 0.1851126253604889, 0.7093027830123901, 1.2781481742858887, -0.6826614141464233, 0.09430211782455444, -0.4225921928882599, 0.5780850052833557, -1.0927345752716064, 1.4504456520080566, -0.1676352471113205, 0.3002229630947113, -0.027283838018774986, -0.18884125351905823, 0.1386791169643402, -0.6370663642883301, 0.513313353061676, -0.7526765465736389, 0.10379461199045181, 0.30886462330818176, 0.24133829772472382, 1.5174156427383423, -0.7038004994392395, 0.7587671875953674, -0.3217133581638336, -0.399819940328598, 0.4135741889476776, 0.3250439763069153, -0.09880981594324112, -0.6402653455734253, 0.5967560410499573, 0.7200270891189575, -0.7043710350990295, 0.6371235251426697, 0.9887405633926392, 0.778684139251709, -0.48039710521698, -0.10593027621507645, 0.9964348077774048, -0.1799851357936859, 0.047310806810855865, -0.027057824656367302, 0.18634957075119019, 0.5615350604057312, 0.45589178800582886, 0.04513000324368477, 0.40896180272102356, -0.8953357338905334, -0.35062652826309204, 0.25465741753578186, 0.2683090567588806, 0.7509108185768127, -0.20725774765014648, -0.6635518074035645, -0.5440012812614441, -0.42766883969306946, 0.7772552371025085, 1.8134530782699585, 0.10196852684020996, 0.43935614824295044, -0.6276304125785828, -0.3314392566680908, -0.31389737129211426, -0.5632551312446594, -0.3915981352329254, -0.6349399089813232, -0.6990872025489807, -1.1017223596572876, 0.6069356799125671, 0.17734387516975403, 1.6524738073349, -0.5839657783508301, -0.344356894493103, -0.08855269849300385, 0.4142805337905884, -0.5832319855690002, -0.8894961476325989, 0.27392908930778503, -0.7897968292236328, 0.11794646084308624, -0.33742567896842957, -0.21308259665966034, 0.12955769896507263, -0.3038201630115509, 0.9678830504417419, -0.5900691151618958, -0.41818323731422424, 0.5387622714042664, 0.8608274459838867, -0.45943397283554077, -0.6023675799369812, 0.9165350794792175, 0.023455556482076645, 0.019562309607863426, 0.1431056559085846, 0.1899179071187973, -0.3455820381641388, 0.27372488379478455, -0.15005165338516235, 0.17868629097938538, 0.4309726059436798, 0.043994251638650894, 0.7331002354621887, -0.9179712533950806, 0.7465901970863342, -1.2005964517593384, 0.7997703552246094, -0.0203098077327013, -0.4102431833744049, 0.4863526225090027, -0.7102980613708496, -0.6416827440261841, 0.2729988694190979, -0.82061767578125, -0.5937391519546509, -0.9879040122032166, 0.421711802482605, -0.5154194831848145, 0.1323806494474411, -0.2820986211299896, 0.7231468558311462, -0.3070124387741089, 0.47541162371635437, 0.46551746129989624, 0.28475984930992126, -0.101828932762146, 0.38234591484069824, -1.1319626569747925, 0.6394560933113098, 0.3331011235713959, 0.5180618762969971, -0.2604321241378784, -0.019259491935372353, -0.24533501267433167, -0.42231976985931396, -0.5519773960113525, -0.6522464752197266, -0.3050520718097687, -0.02599543333053589, -0.8752462267875671, -0.7725672721862793, 0.2592672109603882, -0.7669736742973328, -0.7420465350151062, 0.2875644266605377, 0.13265420496463776, -0.6330900192260742, -1.4828391075134277, -1.1935906410217285, -0.0587141178548336, -0.9101405739784241, -0.8382325768470764, 0.14355316758155823, 0.2507530748844147, -0.33516621589660645, -0.9351088404655457, -0.06516703218221664, -0.7038732171058655, 1.4358546733856201, -0.8758191466331482, 0.8263119459152222, 0.2560178339481354, -0.26390090584754944, 0.09764966368675232, -0.13829250633716583, 0.5862109065055847, -0.5407072305679321, 0.03414330258965492, -1.2960131168365479, -0.30889931321144104, -0.9659392833709717, -0.5834570527076721, 0.4974754750728607, -0.03914475813508034, 0.3475659191608429, 0.08001299202442169, -0.47657012939453125, 0.7849398255348206, 1.386846899986267, -0.9909294843673706, 0.1069670021533966, 0.5833699703216553, 0.9464404582977295, 0.21060512959957123, -0.3144194483757019, 0.5107061862945557, 0.4178079068660736, 0.1852230280637741, 0.001488436828367412, -0.4909556806087494, -0.7820512652397156, -0.8477959036827087, 0.6872972846031189, 1.8239625692367554, 0.08765999972820282, 0.010449893772602081, -0.739682137966156, 0.32496824860572815, -1.1082463264465332, -0.155935138463974, 0.9689605832099915, 0.7802163362503052, 0.4551031291484833, -0.652444064617157, -0.13452225923538208, -0.8828619718551636, 0.4393417239189148, 0.2356642484664917, -0.5333507657051086, -0.49049699306488037, 0.09597372263669968, 0.04810424521565437, 0.21659882366657257, 0.2741660177707672, -0.2575133144855499, 1.0842965841293335, 14.333306312561035, 0.6587464213371277, -0.34457701444625854, 0.8011366128921509, 0.5821866989135742, 0.26429787278175354, -0.21606089174747467, -0.5467720031738281, -1.259268045425415, -0.41444867849349976, 1.4878184795379639, 0.22344471514225006, 0.6763293147087097, -0.10240677744150162, -0.35863813757896423, 0.2985263168811798, -0.7574386596679688, 0.7208862900733948, 0.42961159348487854, -1.1437482833862305, 0.6712510585784912, -0.08686324208974838, 0.6748015284538269, 0.7381462454795837, 1.2039389610290527, 1.1528615951538086, 0.13391397893428802, -0.25798407196998596, 0.3455941677093506, 0.08573830127716064, 1.070102334022522, 0.05602112412452698, 0.12554512917995453, -0.021022964268922806, -1.0064637660980225, 0.020076561719179153, -0.8324316143989563, -0.6781572699546814, -0.032231785356998444, -0.3043159246444702, -0.8963757157325745, -0.3380710780620575, -0.11014477163553238, 1.0325168371200562, -0.1443435400724411, 0.4612569808959961, -0.07469314336776733, 0.36095574498176575, 0.04235198721289635, 0.25059372186660767, 0.2460528016090393, 0.38180387020111084, 0.07249350100755692, 0.34690696001052856, 0.2023719698190689, -0.4689231216907501, 0.016580503433942795, 0.31406736373901367, -0.9193612933158875, -0.2035314291715622, -0.3662342131137848, 0.17757739126682281, 0.27074241638183594, 0.5811465382575989, 0.45352333784103394, 0.5146617293357849, -0.3877545893192291, 0.5529930591583252, 1.0650293827056885, 0.4816363751888275, -0.43318337202072144, 0.20230495929718018, 0.23898524045944214, -0.816314160823822, -0.014083022251725197, 0.3683530390262604, -0.03448197618126869, -0.37957140803337097, -0.7951080799102783, 0.03631128743290901, 0.31814512610435486, -0.7287354469299316, -0.7088630199432373, 1.0110005140304565, -0.15051314234733582, -0.5933822393417358, 0.23836693167686462, -0.5125362873077393, -0.155439093708992, 0.6469051837921143, -2.1221394538879395, -0.7635277509689331, 0.12421472370624542, 0.10026459395885468, -0.27017149329185486, -0.439510315656662, 1.1197370290756226, 0.5100656151771545, -0.7654445767402649, 0.6220593452453613, -0.30417582392692566, -0.567332923412323, 0.2048475444316864, -0.08251087367534637, 0.6285187005996704, -0.0234372615814209, -0.7081609964370728, 0.015947813168168068, -0.4654965102672577, 0.7165580987930298, -0.9286589622497559, -0.5229745507240295, 0.44461482763290405, -0.3992580473423004, -0.1508428007364273, -0.40002745389938354, -0.8986926674842834, 0.45279374718666077, 0.6068772673606873, 0.02814457193017006, 0.28318333625793457, -0.10028129816055298, -0.9117942452430725, -0.20884382724761963, -0.6500381231307983, 0.16847586631774902, 0.6156459450721741, -0.86542147397995, -0.10407458245754242, -0.2975115478038788, 0.19862517714500427, -0.6562649607658386, -0.6407384276390076, -0.13954119384288788, -0.05694076791405678, -0.15906959772109985, 1.1871423721313477, -0.2857115864753723, 0.0777287557721138, 0.9113988876342773, -0.0836821123957634, -1.0987131595611572, 0.02694494090974331, -0.9090501070022583, 0.3654986023902893, 0.1797245889902115, 0.5727535486221313, -0.7821009159088135, -0.21378189325332642, 0.30256563425064087, 0.15881086885929108, -0.27638113498687744, -0.4808022379875183, -0.3518425226211548, -0.07551494240760803, -0.13133762776851654, 0.0850229561328888, -0.003261198988184333, -0.505131721496582, 0.30858615040779114, 0.4428533613681793, 0.48295795917510986, -0.05832679197192192, -0.7503761649131775, 0.2915199398994446, -0.1791423261165619, -0.1648038774728775, -0.7290525436401367, -0.28627654910087585, -1.2660456895828247, 0.19438329339027405, -1.436886191368103, -0.005734797101467848, -0.289190411567688, -0.33137544989585876, -0.38505902886390686, -0.34498512744903564, 0.08861402422189713, 0.3909083902835846, 0.14544066786766052, -0.08509413152933121, 0.09667117148637772, -0.6457607746124268, 1.1221452951431274, 1.0067826509475708, -0.5567609071731567, -0.12139961868524551, -0.11320261657238007, 0.49961134791374207, 0.42701059579849243, 0.6596949100494385, -0.43913114070892334, -0.890548586845398, -1.6182475090026855, 0.5005088448524475, -0.30206143856048584, 0.15059109032154083, -0.8043540716171265, 0.6399493217468262, 0.3622957468032837, 0.06380127370357513, 0.35626304149627686, 0.6095892190933228, -1.1497267484664917, -0.49667713046073914, 0.3839662969112396, -0.6006690263748169, 0.32604411244392395, 0.7262671589851379, -0.5532138347625732, -0.3990069627761841, 0.8540615439414978, 0.3252587914466858, -0.605717122554779, -1.4788520336151123, 0.6466758251190186, -0.24452058970928192, -0.04436364397406578, -0.14872923493385315, -0.1414240002632141, -1.596276879310608, 0.08601491153240204, -0.023006359115242958, 0.33194491267204285, -0.5120429992675781, 0.7422335147857666, 0.7288342714309692, -1.2322124242782593, -0.18623000383377075, 0.543972909450531, -0.08206082135438919, 0.029328182339668274, 0.7843217849731445, 0.8488223552703857, -0.2946593463420868, 0.29009807109832764, -0.3910496234893799, 0.37130898237228394, -0.3601922392845154, -0.07944577187299728, 1.197952389717102, -0.4163159132003784, 0.0946430116891861, 1.1020609140396118, 0.024323822930455208, -1.2575803995132446, 0.18027524650096893, -0.24876266717910767, -0.1504182517528534, 0.033550165593624115, 0.38297250866889954, 0.3449845612049103, -0.007052321452647448, 0.1954834759235382, -0.49108800292015076, 0.538870096206665, -0.23499473929405212, -0.21957041323184967, 0.507307231426239, -0.5461542010307312, -0.16547149419784546, 0.770698606967926, 1.4124325513839722, -1.3580862283706665, -1.3395923376083374, -1.1719813346862793, -0.5584514141082764, 0.31123092770576477, 0.37395909428596497, -0.33714160323143005, -0.8699617385864258, 0.8489654064178467, 0.7469324469566345, -0.31912368535995483, 0.4283302426338196, -0.13250736892223358, -0.01164964959025383, 0.9145784974098206, 0.03103376179933548, -0.6474255919456482, -0.17963705956935883, 1.2594902515411377, 1.3162217140197754, -1.1682133674621582, 0.1533898264169693, -0.4353354573249817, -0.5059232115745544, 0.8210985660552979, 0.5586358308792114, -0.15328188240528107, 0.6861472725868225, -0.4982374310493469, -0.06494375318288803, 0.4297882318496704, -1.209407091140747, -0.11873894184827805, 1.0689105987548828, 1.06644868850708, 0.48763561248779297, 0.19170473515987396, 0.3209293782711029, 0.20564664900302887, 0.14186398684978485, -0.0016844503115862608, 0.21468356251716614, 0.19054511189460754, -0.29391735792160034, 0.3889305293560028, 0.19901582598686218, 0.11025181412696838, -0.20368599891662598, -0.5627399682998657, 0.2607943117618561, 0.909476101398468, -0.30140435695648193, 0.005461685359477997, 1.110909342765808, 0.19995169341564178, 0.6409621834754944, 0.25162404775619507, 1.0094537734985352, -0.1668170839548111, -0.46662119030952454, -0.2718995213508606, -0.7812384366989136, 0.07733476907014847, -0.45317086577415466, -0.2706366777420044, -0.21448493003845215, -0.49696606397628784, 0.5880923271179199, -0.4489055871963501, 0.4548088014125824, 0.7255032658576965, 0.5405768752098083, 0.8855061531066895, 0.009659907780587673, -0.9379592537879944, -0.7104169130325317, -0.8045592904090881, 0.17815589904785156, -0.40944746136665344, -0.10770712792873383, -0.12661829590797424, 0.08333157747983932, -0.16376203298568726]}, "authors": [{"authorId": "2044443762", "name": "Haiwen Diao"}, {"authorId": "2310608470", "name": "Bo Wan"}, {"authorId": "49046063", "name": "Xuecong Jia"}, {"authorId": "2936850", "name": "Yunzhi Zhuge"}, {"authorId": "2310719504", "name": "Ying Zhang"}, {"authorId": "2307039319", "name": "Huchuan Lu"}, {"authorId": "2310753528", "name": "Long Chen"}], "references": [{"paperId": "11159e03ed50d72cd84f7949b09bf87b6d717c1a", "title": "Unveiling Encoder-Free Vision-Language Models"}, {"paperId": "d067f19defbb29f344dbb8c67366f9f7decced7d", "title": "Deep Boosting Learning: A Brand-New Cooperative Approach for Image-Text Matching"}, {"paperId": "227204838c27d26c524cb3e5fa7ee7101a32aab9", "title": "Res-Tuning: A Flexible and Efficient Tuning Paradigm via Unbinding Tuner from Backbone"}, {"paperId": "a985f26e9065e8fd341e107ee5c722d279f46d3a", "title": "UniPT: Universal Parallel Tuning for Transfer Learning with Efficient Parameter and Memory"}, {"paperId": "4c22ee4e5fd80e1bdcd19a760e3f34012245b90b", "title": "VLN-PETL: Parameter-Efficient Transfer Learning for Vision-and-Language Navigation"}, {"paperId": "80a791f644defb54f4eb24f99df31e6f995be3aa", "title": "VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity Control"}, {"paperId": "83c48aa341850af478247e3b34ba1ee1db9f1236", "title": "Meta-Transformer: A Unified Framework for Multimodal Learning"}, {"paperId": "94053805cd59f2e9a47fe3f080c7e7afefb337cc", "title": "Generative Pretraining in Multimodality"}, {"paperId": "7dc6da87eaa6f830354feb2db14023cab8678c91", "title": "ImageBind One Embedding Space to Bind Them All"}, {"paperId": "fb9d5ff3a3e0d1d89b874952094c02f8d2e48b07", "title": "Plug-and-Play Regulators for Image-Text Matching"}, {"paperId": "9ea9236895c14af682e6422df05e55b6efd950f0", "title": "Your representations are in the network: composable and parallel adaptation for large scale models"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "97fa699cd5403f6a1fed6f79e02af4ae37f15c4d", "title": "UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling"}, {"paperId": "780a7f5e8ba9b4b451e3dfee1bcfb0f68aba5050", "title": "Multimodal Chain-of-Thought Reasoning in Language Models"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "e835e50b4c067cec7457332ec119994fb1a26422", "title": "FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer"}, {"paperId": "e13eb4473a6be1d2002a59ec81547c3b87724e76", "title": "Visual Query Tuning: Towards Effective Usage of Intermediate Representations for Parameter and Memory Efficient Transfer Learning"}, {"paperId": "a45fd3a9eb9bbd4f265800bb0b46c9ae4bfe3cd7", "title": "VoP: Text-Video Co-Operative Prompt Tuning for Cross-Modal Retrieval"}, {"paperId": "78281482c1fdad8e167bab39cc9955c73d58ae8f", "title": "EVA: Exploring the Limits of Masked Visual Representation Learning at Scale"}, {"paperId": "f0b31fdf53ad60df454afd4ec8633b3aeb347bff", "title": "Scaling & Shifting Your Features: A New Baseline for Efficient Model Tuning"}, {"paperId": "0d0dbfb1b315a43216020abaf74d289456198219", "title": "MaPLe: Multi-modal Prompt Learning"}, {"paperId": "d3135733aa39dec20ce72aa138589dda27c8406d", "title": "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering"}, {"paperId": "02251886950770e82b3d68564d60cdfe15e73199", "title": "Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks"}, {"paperId": "50a260631a28bfed18eccf8ebfc75ff34917518f", "title": "Convolutional Bypasses Are Better Vision Transformer Adapters"}, {"paperId": "960d40497717ad22a7ebb84db238fa2415fc89cc", "title": "LST: Ladder Side-Tuning for Parameter and Memory Efficient Transfer Learning"}, {"paperId": "665348fc446dd5185c93a5be4c766dad43186e6b", "title": "Reversible Vision Transformers"}, {"paperId": "2fe2f849b94cf08b559226bc9d78adcaef5ef186", "title": "AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition"}, {"paperId": "c431408780586268e8bcf2483b01a80728d10960", "title": "Vision Transformer Adapter for Dense Predictions"}, {"paperId": "7cdaa08890895e1ad92afb5fad429690ad7b1dac", "title": "Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning"}, {"paperId": "adb272fbdea3631059cf88ab764bb6c2ce29f965", "title": "Visual Prompt Tuning"}, {"paperId": "b879450f50a6113f44a5baf0bcd5b4331eeb7bbc", "title": "Conditional Prompt Learning for Vision-Language Models"}, {"paperId": "2002afb402fb55bd42108e3cabffe2996bdf5e37", "title": "\n \n \n \n $$\\cal{Y}$$\n \n \n Y\n \n \n -Tuning: an efficient tuning paradigm for large-scale pre-trained models via label representation learning"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "08e6b161480249514fab4d6154bea3f5d6ddd4c6", "title": "Head2Toe: Utilizing Intermediate Representations for Better Transfer Learning"}, {"paperId": "55a19318cc93714802c7ac59e07651789749b20c", "title": "VL-ADAPTER: Parameter-Efficient Transfer Learning for Vision-and-Language Tasks"}, {"paperId": "898b65bdec52856cd66b56dabe33e2a62df816f0", "title": "Prompting Visual-Language Models for Efficient Video Understanding"}, {"paperId": "6d1ef4436904de111c8b1975bbf25d3fe2f165f7", "title": "DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting"}, {"paperId": "d9cdf21e73519edc593bdf1a00fcd778764b13f6", "title": "Training Neural Networks with Fixed Sparse Masks"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "c04067f03fba2df0c14ea51a170f213eb2983708", "title": "CLIP-Adapter: Better Vision-Language Models with Feature Adapters"}, {"paperId": "43a87867fe6bf4eb920f97fc753be4b727308923", "title": "Towards a Unified View of Parameter-Efficient Transfer Learning"}, {"paperId": "a96d244ea80b2b910bfcf81ffa4432dd4f7ebb20", "title": "Counterfactual Samples Synthesizing and Training for Robust Visual Question Answering"}, {"paperId": "e553407be283d018e275f472d4d2fd709a6c9248", "title": "PPT: Pre-trained Prompt Tuning for Few-shot Learning"}, {"paperId": "96ea07447d2f9adefe03852a878517a2a6d45b96", "title": "Learning to Prompt for Vision-Language Models"}, {"paperId": "8f167ec1149921fac63b1ea855443de109bb013a", "title": "How Much Can CLIP Benefit Vision-and-Language Tasks?"}, {"paperId": "01b5412f3d17e90e09226d7c40ad4d4468a1414d", "title": "Multimodal Few-Shot Learning with Frozen Language Models"}, {"paperId": "339b2b711fb5b228d097b03ebc3e62a521779235", "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "656ed155c2d345c19d9bff4b50f2ae00db8407cc", "title": "Compacter: Efficient Low-Rank Hypercomplex Adapter Layers"}, {"paperId": "bb3425318de7eed5641cda147d61c9a057b9d054", "title": "Parameter-efficient Multi-task Fine-tuning for Transformers via Shared Hypernetworks"}, {"paperId": "7ba9c013988eaff5cd186d73704af329d027872d", "title": "MDETR - Modulated Detection for End-to-End Multi-Modal Understanding"}, {"paperId": "281ad83e06d731d5d686acf07cd701576f1188c4", "title": "CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "6d864a6659e2c503cd6d28d05593f0603b9a48bd", "title": "Similarity Reasoning and Filtration for Image-Text Matching"}, {"paperId": "d22e4cc3a501c17881b9478621f29760e429e76e", "title": "Parameter-Efficient Transfer Learning with Diff Pruning"}, {"paperId": "df7d26339adf4eb0c07160947b9d2973c24911ba", "title": "Extracting Training Data from Large Language Models"}, {"paperId": "608006b0c6c223ef449cbafdc064afdb52bf4410", "title": "Learning the Best Pooling Strategy for Visual Semantic Embedding"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "62ea5fe5ac1795297343b20fbaad9397c0f0b6ff", "title": "Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding"}, {"paperId": "27cc280dfb808dfae9a9f28691d118f4df837222", "title": "TinyTL: Reduce Memory, Not Parameters for Efficient On-Device Learning"}, {"paperId": "6871f6c5437a747fae75a19962f418d234ce2dc1", "title": "Multi-modal Transformer for Video Retrieval"}, {"paperId": "98ef0db84e62aef969629264c9de1f4d0013f3b9", "title": "AdapterFusion: Non-Destructive Task Composition for Transfer Learning"}, {"paperId": "7af72a461ed7cda180e7eab878efd5f35d79bbf4", "title": "A Simple Framework for Contrastive Learning of Visual Representations"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "4287533d12143cdbc4948b60ecece28b6c750f17", "title": "Side-Tuning: A Baseline for Network Adaptation via Additive Side Networks"}, {"paperId": "add2f205338d70e10ce5e686df4a690e2851bdfc", "title": "Momentum Contrast for Unsupervised Visual Representation Learning"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "00c957711b12468cb38424caccdf5291bb354033", "title": "ZeRO: Memory optimizations Toward Training Trillion Parameter Models"}, {"paperId": "48530f3d6425f2f150f07ccdd61ba951951a0a7d", "title": "Simple, Scalable Adaptation for Neural Machine Translation"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "a4e67bcbf912e13cebbb1241d05d1ca0a1df9df8", "title": "Identifying and Reducing Gender Bias in Word-Level Language Models"}, {"paperId": "a7ac99d7cf3f568ab1a741392144b646b856ae0c", "title": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "9a1093af92d315def21b90918faf08665157051a", "title": "Training Deep Neural Networks with 8-bit Floating Point Numbers"}, {"paperId": "cb0f3ee1e98faf92429d601cdcd76c69c1e484eb", "title": "Neural Network Acceptability Judgments"}, {"paperId": "0f885fd46064d271d4404cf9bb3d758e1a6f8d55", "title": "Exploring the Limits of Weakly Supervised Pretraining"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "e7fd6848cb29ca221a7e17d823e06fb566f1f135", "title": "Mixed Precision Training"}, {"paperId": "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096", "title": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"}, {"paperId": "3a6d4cd0768ae8768e733280d362bdb4d25924e7", "title": "The Reversible Residual Network: Backpropagation Without Storing Activations"}, {"paperId": "f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8", "title": "VSE++: Improving Visual-Semantic Embeddings with Hard Negatives"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "7e232313a59d735ef7c8a9f4cc7bc980a29deb5e", "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "29efbe391950ae438c63d86ad5c82b2942efb0b4", "title": "Modeling Context in Referring Expressions"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "942deb7d865b7782c03176d95e3a0d56cb71009e", "title": "Training Deep Nets with Sublinear Memory Cost"}, {"paperId": "b8e2e9f3ba008e28257195ec69a00e07f260131d", "title": "MSR-VTT: A Large Video Description Dataset for Bridging Video and Language"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "e65142010431ffc089b272a1174214e00693e503", "title": "Generation and Comprehension of Unambiguous Object Descriptions"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "44040913380206991b1991daf1192942e038fe31", "title": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "72729882f8fa3d9084eaece513f6bf9630be5901", "title": "Collecting Highly Parallel Data for Paraphrase Evaluation"}, {"paperId": "5ef82a8c8aa50f99285f2143b57ca4e82da1af80", "title": "Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "First quora dataset release: Question pairs"}, {"paperId": "db8885a0037fe47d973ade79d696586453710233", "title": "The Sixth PASCAL Recognizing Textual Entailment Challenge"}, {"paperId": "475354f10798f110d34792b6d88f31d6d5cb099e", "title": "Automatically Constructing a Corpus of Sentential Paraphrases"}, {"paperId": null, "title": "Qlora: Efficient fine-tuning of quantized llms"}, {"paperId": null, "title": "Stack more layers differently: High-rank training through low-rank updates"}]}