{"paperId": "41ecff85ec0c8082fcd4efcf31fc5ec3911dce88", "abstract": "By formally defining the training processes of large language models (LLMs), which usually encompasses pre-training, supervised fine-tuning, and reinforcement learning with human feedback, within a single and unified machine learning paradigm, we can glean pivotal insights for advancing LLM technologies. This position paper delineates the parallels between the training methods of LLMs and the strategies employed for the development of agents in two-player games, as studied in game theory, reinforcement learning, and multi-agent systems. We propose a re-conceptualization of LLM learning processes in terms of agent learning in language-based games. This framework unveils innovative perspectives on the successes and challenges in LLM development, offering a fresh understanding of addressing alignment issues among other strategic considerations. Furthermore, our two-player game approach sheds light on novel data preparation and machine learning techniques for training LLMs.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This position paper delineates the parallels between the training methods of LLMs and the strategies employed for the development of agents in two-player games, as studied in game theory, reinforcement learning, and multi-agent systems."}, "embedding": {"model": "specter_v2", "vector": [-0.09803894907236099, 0.7813137769699097, -0.4733251929283142, 0.2430599182844162, -0.5161341428756714, -0.13857798278331757, 0.7489361763000488, -0.24047346413135529, -0.7908114194869995, 0.22829216718673706, -0.01393421646207571, -0.16218377649784088, -0.15467877686023712, 0.0010450290283188224, -0.5447065234184265, 0.15200328826904297, -1.2794843912124634, 0.620305061340332, -0.1586996465921402, -0.5256162285804749, -0.47152161598205566, -1.024359107017517, -0.9933274984359741, -0.049173835664987564, 0.4918123483657837, 0.11895618587732315, 0.03890714794397354, 1.2810550928115845, 0.25219064950942993, 1.1111482381820679, 0.5373315811157227, -0.3709163963794708, 0.6861544251441956, -0.12903748452663422, -0.3439042270183563, -0.04370397701859474, 0.009475978091359138, -0.819629430770874, -0.6751721501350403, 0.7312541007995605, -0.23016007244586945, 0.0030274083837866783, 0.24770016968250275, -0.6258522272109985, 0.14407168328762054, 0.9033790826797485, 0.5235483646392822, 0.41578352451324463, 0.12414538860321045, -0.3423052728176117, 1.521147608757019, -0.7734937071800232, 0.39016401767730713, 1.479297161102295, 0.45357581973075867, 0.4351385831832886, -0.3108814060688019, -0.7798169255256653, 0.6216506958007812, -0.46673911809921265, -0.586103081703186, -0.3760773837566376, -0.23189666867256165, -0.38349413871765137, 1.1560419797897339, -0.17661315202713013, 0.006423900369554758, 0.32968348264694214, 0.05662674084305763, 1.7500628232955933, 0.14114902913570404, -1.074676275253296, -0.1675102412700653, 0.45696181058883667, -0.05061906948685646, 1.047226071357727, -0.2059476375579834, 0.9638535976409912, -1.0270026922225952, -0.512503981590271, 0.39416834712028503, -0.5186224579811096, -0.07030511647462845, -0.4550629258155823, -0.1382513791322708, 1.2300413846969604, -0.17715533077716827, 0.4275813698768616, -0.23126450181007385, 0.7901983261108398, 0.27457356452941895, 0.760432243347168, 0.2567480206489563, 0.42014026641845703, 0.10701373964548111, 0.16077853739261627, -0.4319249093532562, 0.5890296101570129, 0.18111048638820648, 0.24975548684597015, -0.36153772473335266, -0.06450817734003067, -0.6995797753334045, 0.27061375975608826, 1.818036437034607, -0.25954800844192505, 0.5014452934265137, -0.8335683941841125, 0.5840493440628052, -0.8363144993782043, 0.7084433436393738, -0.5456398725509644, -0.2622259855270386, -0.08909191936254501, -0.27694717049598694, -0.6511623859405518, -0.0972001776099205, -0.09011093527078629, -0.2624901533126831, 1.0043306350708008, -0.10893236845731735, -0.015431012958288193, 0.6858283877372742, 0.6130240559577942, 0.1452793926000595, 0.5941969156265259, 0.2776359021663666, -0.14892517030239105, 0.8790179491043091, -0.6153953671455383, -0.3378868103027344, -1.11784827709198, 1.0130239725112915, 0.2729964256286621, 0.16418009996414185, -0.16154231131076813, -1.5179530382156372, -0.7195672988891602, -1.1020673513412476, 0.4988241195678711, -0.16769319772720337, 0.3118484914302826, 1.2661917209625244, 0.6126313209533691, -0.6892732977867126, 0.6713441014289856, -0.11764956265687943, -0.019654927775263786, 0.055178798735141754, 0.3179352879524231, -0.06423015892505646, -0.34361860156059265, -1.4588022232055664, 0.3477478325366974, 0.5303699970245361, -0.522587776184082, -0.18399813771247864, -0.0842834934592247, -1.320581316947937, -0.5834329128265381, 0.41175809502601624, -0.44694629311561584, 1.5230642557144165, -0.3069339394569397, -1.5058894157409668, 0.8307123780250549, 0.31938210129737854, -0.29212021827697754, 0.7492609024047852, -0.23374216258525848, -0.5156761407852173, -0.2849525213241577, -0.23396643996238708, 0.19757011532783508, -0.05851511284708977, -0.5776869654655457, -0.7217938303947449, 0.107530876994133, 0.275643527507782, 0.048827771097421646, 0.0675620436668396, 0.7845874428749084, -0.4654383957386017, -0.2581775486469269, -0.10110919922590256, 0.5473934412002563, -0.4448438584804535, -0.24517138302326202, -0.18609976768493652, -0.7994630932807922, 0.21632921695709229, -0.23342649638652802, 1.107911467552185, -0.5975518822669983, -0.3963415026664734, -0.0522497333586216, 0.1421579122543335, -0.0023815464228391647, -0.9148296117782593, 0.4019570052623749, 0.01749543845653534, 0.30455347895622253, -0.05243270844221115, -1.173811912536621, 0.04212636500597, -0.15572963654994965, -0.3649846017360687, -0.22203728556632996, -0.11325260251760483, 0.7914249300956726, -1.0811313390731812, 0.09350964426994324, -0.21672992408275604, -0.5510356426239014, -0.9657661318778992, 1.5268793106079102, -0.464979887008667, 0.2534220516681671, -0.4054747223854065, -0.7467173933982849, -0.10243334621191025, 0.16901615262031555, 0.7099116444587708, 0.24140675365924835, -0.10044515132904053, 0.4112789034843445, -0.6073817610740662, 1.1347898244857788, -0.03657294437289238, 0.49761125445365906, 0.5256986021995544, -0.5445495843887329, -0.40047699213027954, 0.7030232548713684, -0.23159529268741608, -0.4047849774360657, 0.21701784431934357, 0.5102711915969849, -0.32384932041168213, -0.11055357754230499, 0.4366435110569, 0.397686243057251, -0.42890897393226624, 0.5876927971839905, 0.3903801441192627, -0.4389342963695526, 0.9429786205291748, 0.23083172738552094, 0.44085463881492615, 0.4365254044532776, 0.34237074851989746, 0.1354810744524002, 0.39173170924186707, -0.7366634011268616, 0.07387964427471161, 0.8042267560958862, 0.43717724084854126, 0.382789671421051, 0.335298627614975, -0.8379769921302795, 0.23126859962940216, -0.046327296644449234, 0.9408594965934753, 1.5840332508087158, -0.18092815577983856, -0.22600285708904266, -0.7930718660354614, -0.4792953133583069, -0.031887441873550415, 0.1552545577287674, -0.591960608959198, 0.025264954194426537, -0.7222437262535095, -1.0415788888931274, 0.9261909127235413, -0.04860742762684822, 0.5621010661125183, -0.5535852313041687, -0.3999093472957611, -0.14163745939731598, 0.40778255462646484, -0.5621477961540222, -0.5332804918289185, 0.2827185392379761, -0.19332808256149292, -0.5367038249969482, -0.08200578391551971, -0.27816104888916016, -0.009626086801290512, -0.6420606374740601, 0.7031857371330261, -0.24690763652324677, -0.17605219781398773, 0.3539023995399475, 0.6748886704444885, -1.0297975540161133, -1.571875810623169, -0.40057751536369324, 0.6295472383499146, -0.2741539478302002, -0.17791330814361572, 0.6950401067733765, 0.5209742188453674, 0.007263917475938797, -0.5151156187057495, 0.4117296636104584, 0.3724728524684906, 0.14969593286514282, 0.051146525889635086, -0.41582193970680237, 0.24475902318954468, -1.4627426862716675, 1.5067318677902222, 0.19501475989818573, -0.9978464841842651, 0.6117755770683289, -0.6268035769462585, -0.24947816133499146, 0.262631893157959, -0.5548800230026245, -0.11179172992706299, -1.039176106452942, 0.6217685341835022, 0.13730494678020477, -0.12488192319869995, 0.7981306910514832, 0.7305372953414917, -0.03791994974017143, 0.31430932879447937, 0.3219044804573059, 0.8644431233406067, 0.03341669216752052, 0.5809228420257568, -0.5411186814308167, 0.16349217295646667, -0.12334410846233368, 0.2783486843109131, -0.4095768332481384, -0.48270323872566223, -0.45949050784111023, -0.23861996829509735, 0.01598311960697174, 0.04224938526749611, -0.5816957354545593, 0.09462593495845795, -0.8788966536521912, -0.7052179574966431, 0.16837237775325775, -0.898682177066803, -0.4778951406478882, 0.1546158790588379, 0.21225252747535706, -0.5312033891677856, -0.868841826915741, -1.3957127332687378, -0.8523800373077393, -0.360715389251709, -1.2860081195831299, -0.009825591929256916, -0.044721852988004684, -0.41117167472839355, -0.3930354416370392, 0.7707476019859314, 0.0976235494017601, 0.4184003472328186, -0.900077223777771, 1.041235327720642, 0.09161277115345001, -0.03017759881913662, -0.4312497079372406, 0.7763940691947937, 0.15056689083576202, -0.12622708082199097, 0.13577795028686523, -0.47115057706832886, -0.179941326379776, -0.5627806186676025, -1.1400575637817383, -0.37335190176963806, 0.3016611635684967, 0.10643202066421509, 0.07086902111768723, -0.378744900226593, -0.05085471272468567, 0.9301040172576904, -0.24575640261173248, -0.35818856954574585, 0.23787793517112732, 0.5076004862785339, 0.9237148761749268, -0.002350691705942154, 0.34958335757255554, 0.5812883973121643, 0.7727652192115784, -0.04056024178862572, -0.23185789585113525, 0.2206655889749527, -0.6132725477218628, 0.7113544344902039, 1.3682948350906372, 0.16854918003082275, -0.1784706711769104, -0.9108192324638367, 0.2219083458185196, -1.6418200731277466, -0.6812276840209961, 0.9112583994865417, 0.892230212688446, 0.5196098685264587, -0.08241940289735794, 0.09657832980155945, -0.3570851981639862, 0.3118841350078583, 0.30569398403167725, -0.20818646252155304, -0.5570595264434814, -0.04359622299671173, 0.15580083429813385, -0.1812008023262024, 0.9503450989723206, -0.5792439579963684, 0.4851791560649872, 14.972000122070312, 0.8014466762542725, 0.23058705031871796, 0.43266937136650085, 0.6969131827354431, -0.017941659316420555, -0.4054308235645294, -0.3186374604701996, -0.5186924934387207, -0.36550772190093994, 0.990090012550354, 0.15679773688316345, 0.9241329431533813, -0.2374570220708847, 0.5079808831214905, -0.2627239227294922, -0.44612523913383484, 0.5313256978988647, 0.15073926746845245, -1.2968257665634155, 0.6561596393585205, 0.2924128770828247, 0.22584104537963867, 0.8023785352706909, 0.5154653191566467, 0.9918906688690186, 1.060935616493225, -0.4800318479537964, 1.0389690399169922, -0.114608533680439, 0.6230838298797607, -0.06812012940645218, 0.2658344507217407, 1.172890543937683, -0.8159489631652832, -0.3367260992527008, -0.2437594085931778, -1.3333796262741089, -0.05939818546175957, -0.33691397309303284, -0.14546629786491394, -0.4586668014526367, -0.43192747235298157, 0.14506959915161133, 0.2631262540817261, -0.10181178897619247, -0.04674932733178139, 0.637598991394043, -0.28578752279281616, -0.017772771418094635, 0.28579825162887573, 0.0483538843691349, 0.3968905210494995, -0.3574341833591461, -0.009865938685834408, 0.25752362608909607, 0.1655692309141159, 0.40117141604423523, -0.48125508427619934, 0.07498343288898468, -0.6473898887634277, -0.5254425406455994, 0.03338315337896347, 0.33164602518081665, 1.0366911888122559, 0.4293009638786316, -0.3450388014316559, 0.04865821450948715, 1.0615237951278687, 0.027137096971273422, 0.2024778425693512, 0.10417307168245316, 0.7601891160011292, -0.5722914338111877, -0.3304857015609741, 0.6336755156517029, 0.2771233022212982, -0.5884628891944885, -0.78910231590271, -0.8534139394760132, 0.3135823607444763, -0.5330243110656738, -0.6601848602294922, 0.8575372695922852, -0.29247063398361206, -0.5897980332374573, -0.15318956971168518, -0.6831849217414856, -0.4361439049243927, 0.41800692677497864, -1.113997459411621, -0.8692317605018616, 0.8506697416305542, -0.26978495717048645, -0.3957531154155731, -0.4549737870693207, 1.3073264360427856, -0.22480224072933197, -0.7906354069709778, 0.2975960075855255, 0.6029175519943237, 0.09783460944890976, -0.41343459486961365, -0.5475640296936035, 0.5811283588409424, 0.05886431038379669, 0.3483336865901947, 0.12492404878139496, 0.10709083825349808, 0.061206888407468796, -0.688042402267456, 0.31575581431388855, 0.22422675788402557, -0.8815074563026428, -0.24383080005645752, -0.8081181645393372, -0.40836575627326965, 0.33095091581344604, 0.49589866399765015, -0.35101425647735596, 0.32649871706962585, -0.17502060532569885, -0.25631478428840637, 0.14148175716400146, -0.6432387232780457, 0.26630932092666626, -0.06059328466653824, -0.7647014260292053, -0.15135039389133453, -0.0673377588391304, 0.16842348873615265, -0.8809416890144348, 0.014948781579732895, -0.26840704679489136, 0.29464250802993774, -0.029911614954471588, 0.4431357681751251, -1.0803472995758057, 0.2041471302509308, 0.6600431203842163, 0.07893861085176468, -0.9241958856582642, -0.10776619613170624, -1.2458962202072144, 0.1306399255990982, -0.2765139043331146, 0.8837664723396301, -0.4136224389076233, 0.4653678834438324, 0.8104977011680603, 0.739107608795166, -0.41989585757255554, -0.9754539728164673, 0.07406707108020782, 0.1982749104499817, -0.883452296257019, -0.04392383620142937, -0.27344998717308044, 0.163079172372818, -0.13877810537815094, -0.1465585082769394, 1.0207223892211914, -0.06623141467571259, -0.7323430776596069, 0.8422971963882446, -0.03783120587468147, -0.43249765038490295, -0.7103918194770813, -0.08997538685798645, -1.0769177675247192, -0.09445959329605103, -1.0046802759170532, 0.44091588258743286, -0.6488643884658813, -0.3107627332210541, 0.032161418348550797, -0.20887796580791473, -0.45242011547088623, 0.22393879294395447, -0.4534037113189697, -0.020562153309583664, -0.38189539313316345, -0.5383455753326416, 0.7087370753288269, 0.6475015878677368, -0.7483848333358765, 0.10890795290470123, 0.21495983004570007, 0.2326069176197052, 0.6886168122291565, 0.3100367784500122, -0.5214265584945679, -0.8776617646217346, -1.2222298383712769, 0.5620245337486267, 0.251242071390152, -0.16025950014591217, -0.7269910573959351, 0.5332657098770142, -0.047981146723032, -0.40904730558395386, 0.727074921131134, 0.32040727138519287, -0.6539629101753235, -0.4013901650905609, 0.5778623223304749, -1.0206269025802612, -0.072212815284729, 0.28585338592529297, -0.3413063883781433, -0.48326998949050903, 0.4594460725784302, -0.24023915827274323, -0.8692812323570251, -0.342286616563797, 0.3479086458683014, -1.146756887435913, 0.019193274900317192, 0.23897264897823334, -0.1307528018951416, -0.41872426867485046, -0.7199192643165588, -0.02360406145453453, 0.7553859949111938, -0.5621377229690552, 1.0110442638397217, 0.32130566239356995, -1.0990183353424072, -0.2991924285888672, 0.40670618414878845, 0.15687640011310577, -0.07543669641017914, 0.3396185636520386, -0.02742971107363701, -0.561272382736206, 0.4668736457824707, 0.3551193177700043, 0.9394950866699219, -1.0873394012451172, -0.6705116629600525, 1.0471622943878174, -1.0341637134552002, 0.37606629729270935, 1.2413432598114014, 0.06901539862155914, -1.623885989189148, 0.20001380145549774, -0.7940082550048828, -0.7023687958717346, -0.703048586845398, 0.43202728033065796, -0.23280248045921326, -0.6667996048927307, 0.03562764450907707, 0.051773764193058014, 0.17824475467205048, -0.22483111917972565, -0.693972110748291, 0.39062780141830444, -0.32610175013542175, -0.25910553336143494, 0.7592451572418213, 0.19070354104042053, -0.1664474457502365, -0.7807831168174744, -0.556003987789154, -0.38210955262184143, 0.19868463277816772, 0.23096978664398193, -0.4570675790309906, -0.24179115891456604, 0.4716912508010864, 0.6441245675086975, 0.2008650153875351, -0.41915929317474365, 0.03179500997066498, -0.016288893297314644, 0.5213758945465088, 0.4897855520248413, -0.7444238066673279, -0.5246039628982544, 1.059751033782959, 1.3945412635803223, -1.21421217918396, 0.31630998849868774, -0.044903431087732315, -0.5562848448753357, 0.8178949952125549, 0.5368158221244812, 0.11368759721517563, 0.834490954875946, -0.23951852321624756, 0.731781005859375, 0.028931014239788055, -1.0323498249053955, -0.1432012915611267, 0.8065479397773743, 0.9515382647514343, 0.7319880127906799, 0.7587409615516663, -0.1570613533258438, 1.1492632627487183, 0.17713572084903717, 0.6927017569541931, 0.5217243432998657, 0.6908069849014282, -0.22560007870197296, -0.35264143347740173, 0.1060139462351799, 0.5381940603256226, -0.39677348732948303, -0.2744450867176056, -0.05832832306623459, 0.7574050426483154, 0.43004465103149414, 0.47919222712516785, 0.2836816906929016, -0.13648030161857605, 0.29660797119140625, -0.12061137706041336, 0.5155352354049683, -0.29648688435554504, -0.18057216703891754, -0.3375207781791687, -0.0780104398727417, 0.11192072927951813, -0.23578302562236786, -0.4033697247505188, -0.09157722443342209, -0.1091640442609787, 0.21549047529697418, 0.3073289394378662, -0.3594234585762024, 1.3132399320602417, 0.5532504916191101, -0.059537071734666824, -0.20744594931602478, -0.39201390743255615, -0.7978867888450623, -0.9932222366333008, -0.2748963236808777, -0.7400226593017578, -0.3704349100589752, -0.182186558842659, -0.17585326731204987, -0.745681881904602]}, "authors": [{"authorId": "2283963409", "name": "Yang Liu"}, {"authorId": "2284338434", "name": "Peng Sun"}, {"authorId": "2257196326", "name": "Hang Li"}], "references": [{"paperId": "6b97aa78bcdb88548c44e7e1671c0ed37ed37976", "title": "Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision"}, {"paperId": "27aa6506c45fafa4268207a4daf5a907b38c946e", "title": "Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models"}, {"paperId": "8fd11c6f3eb1d0aeb915369f3c4f0b1bb24cab0c", "title": "Large Language Model Unlearning"}, {"paperId": "40a7c44d1cfaa9faf1f731a6f93a889fab5426da", "title": "Who's Harry Potter? Approximate Unlearning in LLMs"}, {"paperId": "d00735241af700d21762d2f3ca00d920241a15a4", "title": "Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models"}, {"paperId": "cb587eaea753ee38013afb7e5b6bc8fba1248d04", "title": "RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback"}, {"paperId": "7142e920b6b9355d9cbacc9450818f912eca138e", "title": "Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment"}, {"paperId": "a6d3794c23626060781da0f1ff2bcdf7457b6c43", "title": "DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models"}, {"paperId": "0d1c76d45afa012ded7ab741194baf142117c495", "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"}, {"paperId": "5dbffedcabe3fa43060ebbe2b1789500edfd871f", "title": "Reasoning with Language Model is Planning with World Model"}, {"paperId": "4780d0a027c5c5a8e01d7cf697f6296880ffc945", "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate"}, {"paperId": "551a4a4d231e24bacbd7a1285e8f44dd553e5b3f", "title": "Summarizing Strategy Card Game AI Competition"}, {"paperId": "e01515c6138bc525f7aec30fc85f2adf028d4156", "title": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision"}, {"paperId": "ea30bcd9c2b2d0dbaf63e808c59733b8e4d104a4", "title": "Uncertainty-Aware Instance Reweighting for Off-Policy Learning"}, {"paperId": "cd9158097291092edc5cbaf61452697e45d5bc01", "title": "Mastering Strategy Card Game (Legends of Code and Magic) via End-to-End Policy and Optimistic Smooth Fictitious Play"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "08b85bce712168998004ee80ce4e475390413c74", "title": "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT"}, {"paperId": "e65b346d442e9962a4276dc1c1af2956d9d5f1eb", "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions"}, {"paperId": "3936fd3c6187f606c6e4e2e20b196dbc41cc4654", "title": "Constitutional AI: Harmlessness from AI Feedback"}, {"paperId": "4596139b28c3ceacbd7e3c34dc0df079dbf4e96b", "title": "Language Models as Agent Models"}, {"paperId": "4610ffb1b016acaa82a2065ffd1a3adbae1ce722", "title": "Large Language Models Are Human-Level Prompt Engineers"}, {"paperId": "fb49e88c6bd676516898e911e42b4f8479e6f1bf", "title": "Ask Me Anything: A simple strategy for prompting language models"}, {"paperId": "17bcb1edbe068e8fe6a97da552c70a77a15bbce7", "title": "Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned"}, {"paperId": "29acc890e521f7a6415666ab9eb3432c49b4587a", "title": "Self-critiquing models for assisting human evaluators"}, {"paperId": "fe26607ca95c0d1d9005810b4ad12845ee69e9cf", "title": "Multi-Agent Reinforcement Learning is a Sequence Modeling Problem"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "5437e8adab596d7294124c0e798708e050e25321", "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"}, {"paperId": "7cdaa08890895e1ad92afb5fad429690ad7b1dac", "title": "Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning"}, {"paperId": "0286b2736a114198b25fb5553c671c33aed5d477", "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"}, {"paperId": "341bdbcfc3febef7691a97c216ad394653211095", "title": "Can language models learn from explanations in context?"}, {"paperId": "5f19ae1135a9500940978104ec15a5b8751bc7d2", "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "f4df78183261538e718066331898ee5cad7cad05", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"}, {"paperId": "3def68bd0f856886d34272840a7f81588f2bc082", "title": "Survey of Hallucination in Natural Language Generation"}, {"paperId": "5d49c7401c5f2337c4cc88d243ae39ed659afe64", "title": "Red Teaming Language Models with Language Models"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "333d1555564c449908bd090e2af98e3a1e2c5c7f", "title": "Search in Imperfect Information Games"}, {"paperId": "10bd4160b44803ada6a3d2e366c44b7e2a4ffe90", "title": "An Explanation of In-context Learning as Implicit Bayesian Inference"}, {"paperId": "9560080a2c32682bd1c1a9850a54ca6163f1956e", "title": "Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble"}, {"paperId": "f864d4d2267abba15eb43db54f58286aef78292b", "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem"}, {"paperId": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500", "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"}, {"paperId": "4b51f6d49899c364370c6946c02cb304a8cbf118", "title": "Policy Learning Using Weak Supervision"}, {"paperId": "f8492a321d66c381637b693a24af994af41b3cdf", "title": "Transfer Learning in Deep Reinforcement Learning: A Survey"}, {"paperId": "df2b23787a58b10962951d4f663809eb20a828ea", "title": "Combining Deep Reinforcement Learning and Search for Imperfect-Information Games"}, {"paperId": "e2a2b758ccbf7f294c2592190d9aeed41fe3b344", "title": "Monte-Carlo Tree Search as Regularized Policy Optimization"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "baf60d13c98916b77b09bc525ede1cd610ed1db5", "title": "Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping"}, {"paperId": "3507bd62a14bd0e8ead28cdedb1c33ba83c39c6b", "title": "Mastering Atari, Go, chess and shogi by planning with a learned model"}, {"paperId": "361c00b22e29d0816ca896513d2c165e26399821", "title": "Grandmaster level in StarCraft II using multi-agent reinforcement learning"}, {"paperId": "8c54e8575e7c17a4097838305915e6e7b00fd4af", "title": "Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning"}, {"paperId": "7a15950dc71079285a4eaf195de5aadd87c41b40", "title": "Fine-Tuning Language Models from Human Preferences"}, {"paperId": "4625628163a2ee0e6cd320cd7a14b4ccded2a631", "title": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables"}, {"paperId": "13481ca12437363220282e3255eab109f0eeebcc", "title": "Reinforcement Learning with Perturbed Rewards"}, {"paperId": "944bd3b472c8a30163bbfc1b5cbab8545693c3e0", "title": "Learning to Adapt in Dynamic, Real-World Environments through Meta-Reinforcement Learning"}, {"paperId": "ff332c21562c87cab5891d495b7d0956f2d9228b", "title": "World Models"}, {"paperId": "68c108795deef06fa929d1f6e96b75dbf7ce8531", "title": "Meta-Reinforcement Learning of Structured Exploration Strategies"}, {"paperId": "38fb1902c6a2ab4f767d4532b28a92473ea737aa", "title": "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm"}, {"paperId": "b0d8165eecf2aa04a85e701d0c6bb4edd4b3811b", "title": "A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning"}, {"paperId": "c27db32efa8137cbf654902f8f728f338e55cd1c", "title": "Mastering the game of Go without human knowledge"}, {"paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b", "title": "Proximal Policy Optimization Algorithms"}, {"paperId": "5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd", "title": "Deep Reinforcement Learning from Human Preferences"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5d2f5c2dc11c18c0d45203e2b980fe375a56d774", "title": "Emergence of Grounded Compositional Language in Multi-Agent Populations"}, {"paperId": "f2c20cb6ebd2ad704c5bcae4eb8b942d3c62f8e0", "title": "Uncertainty-Aware Reinforcement Learning for Collision Avoidance"}, {"paperId": "a1d2a7ef81960846b9cec00bce8eefa06ccc8796", "title": "Deep Reinforcement Learning from Self-Play in Imperfect-Information Games"}, {"paperId": "b0a70d4d44e5c8594581c0e20c315fd58fee0026", "title": "Convergence of best-response dynamics in extensive-form games"}, {"paperId": "b6cc21b30912bdaecd9f178d700a4c545b1d0838", "title": "Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning"}, {"paperId": "d9dae4ec4a290e198fabd59aea7c55b5f8712b4b", "title": "Multiagent Systems - Algorithmic, Game-Theoretic, and Logical Foundations"}, {"paperId": "a87916a0a64ba8d8d6c7bff4f510de17f62c4446", "title": "The Stuff of Thought: Language as a Window into Human Nature"}, {"paperId": "dc4e9aa01abf579b6e5c8fc43261f9062e77a7f9", "title": "Nash Q-Learning for General-Sum Stochastic Games"}, {"paperId": "1b22b8558d7b0fe488642311d04a1edd24f42f2d", "title": "Evolutionary Dynamics and Extensive Form Games"}, {"paperId": "fb45465f0924795d4eb98d1bf1524d244a05ed3e", "title": "Learning to Play Chess Using Temporal Differences"}, {"paperId": "a20f0ce0616def7cc9a87446c228906cd5da093b", "title": "Policy Gradient Methods for Reinforcement Learning with Function Approximation"}, {"paperId": "38d35d5581e58dca4e9458501e65c1f85ca754d5", "title": "The Dynamics of Reinforcement Learning in Cooperative Multiagent Systems"}, {"paperId": "7fbf55baccbc5fdc7ded1ba18330605909aef5e5", "title": "Markov Games as a Framework for Multi-Agent Reinforcement Learning"}, {"paperId": "d95bb741913c93c7b5fd745668d8538bbbf7b584", "title": "A Unified Approach to Reinforcement Learning, Quantal Response Equilibria, and Two-Player Zero-Sum Games"}, {"paperId": "775f42ed458b8c5b0f2094ea4ff5b64c557b1a34", "title": "A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27"}, {"paperId": "d521ea5f888a6821828f3db345da9a7f1cc9cee3", "title": "Adversarial Policy Learning in Two-player Competitive Games"}, {"paperId": null, "title": "Learning to learn in context"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "0c0a778e6fdf7e36b1750c533dcc916f86608607", "title": "A Survey on Context Learning"}, {"paperId": "f1cfcc211eef2119dc02377019f1f03e6afa9439", "title": "The Theory of Learning in Games"}, {"paperId": "1ea7603876a796f6007e4b6419cb1c9a9cb6bf8e", "title": "TD-Gammon: A Self-Teaching Backgammon Program"}, {"paperId": "a5c5900327c5ce160dde0562e3693bae5489862f", "title": "Two-person Cooperative Games"}, {"paperId": null, "title": ": A family of highly capable multimodal models"}, {"paperId": null, "title": "From poincar\u00b4e recurrence to convergence in imperfect information games: Finding"}, {"paperId": null, "title": "Human-instruction-free"}, {"paperId": null, "title": "Learning to communicate, 2017"}, {"paperId": null, "title": "A large-scale hallucination evaluation benchmark for large language models"}, {"paperId": null, "title": "Towards better llm-based"}]}