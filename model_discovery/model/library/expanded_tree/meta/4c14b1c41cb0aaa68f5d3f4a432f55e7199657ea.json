{"paperId": "4c14b1c41cb0aaa68f5d3f4a432f55e7199657ea", "abstract": "The availability of unprecedented unsupervised training data, along with neural scaling laws, has resulted in an unprecedented surge in model size and compute requirements for serving/training large language models. However, the main performance bottleneck is increasingly shifting to memory bandwidth. Over the past 20 years, peak server hardware floating-point operations per second have been scaling at 3.0${\\times}$\u00d7 per two years, outpacing the growth of dynamic random-access memory and interconnect bandwidth, which have only scaled at 1.6 and 1.4 times every two years, respectively. This disparity has made memory, rather than compute, the primary bottleneck in AI applications, particularly in serving. Here, we analyze encoder and decoder transformer models and show how memory bandwidth can become the dominant bottleneck for decoder models. We argue for a redesign in model architecture, training, and deployment strategies to overcome this memory limitation.", "venue": "IEEE Micro", "year": 2024, "citationCount": 56, "influentialCitationCount": 2, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work analyzes encoder and decoder transformer models and shows how memory bandwidth can become the dominant bottleneck for decoder models, and argues for a redesign in model architecture, training, and deployment strategies to overcome this memory limitation."}, "embedding": {"model": "specter_v2", "vector": [0.41960227489471436, 0.4691257178783417, -0.1834675669670105, 0.018245572224259377, -0.10031896829605103, 0.13521790504455566, 0.7476270198822021, -0.4465065896511078, -0.6304392218589783, -0.5646317601203918, 0.041056204587221146, -0.2886347770690918, 0.2585960924625397, 0.05882597342133522, -0.3969781994819641, 0.1359829604625702, -1.0386954545974731, 0.5230337977409363, 0.17374899983406067, -0.13803167641162872, -0.1238832026720047, -0.3745603561401367, -1.3595541715621948, 0.08789656311273575, 0.2535524368286133, 0.8696653246879578, 0.185654416680336, 0.8910194039344788, -0.2833416759967804, 0.6051120758056641, 0.3432832658290863, -0.40863579511642456, 0.18105047941207886, 0.11621545255184174, 0.07413166016340256, -0.5151721835136414, 0.35639744997024536, -0.455514520406723, -0.5882512927055359, 0.7478204369544983, -0.216806560754776, 0.13996003568172455, 0.3143151104450226, -0.7366621494293213, -0.12371533364057541, 0.5833396911621094, 0.5962984561920166, 0.9210996031761169, -0.4727288782596588, -0.3742566406726837, 1.0708469152450562, -1.3533648252487183, 0.1941966414451599, 1.2123403549194336, 0.3820887506008148, 0.189255490899086, 0.03189925104379654, -0.7679970860481262, 0.4090496897697449, 0.045752640813589096, -0.8626750111579895, -0.8639567494392395, -0.14050830900669098, 0.1225631907582283, 1.8022105693817139, -0.3772084712982178, 0.09331514686346054, 0.44269755482673645, 0.06359702348709106, 1.4596439599990845, -0.3697320222854614, -0.9397362470626831, -0.13746705651283264, -0.09398292750120163, 0.2205476015806198, 1.039832353591919, -0.1952047199010849, -0.204219251871109, -1.170317530632019, -0.06719683855772018, 0.6631873846054077, -0.2625354528427124, 0.21990947425365448, -0.462494432926178, -0.5528787970542908, 0.5904718041419983, -0.005273384042084217, 0.5254026055335999, -0.17846237123012543, 0.707506537437439, 0.5181154012680054, 0.26633837819099426, -0.05655017867684364, 0.14101208746433258, 0.20817406475543976, 0.30456313490867615, -0.8885927796363831, -0.1333000361919403, 0.18577753007411957, 1.3229728937149048, -0.7899495959281921, 0.5759537220001221, -0.540044903755188, 0.17041602730751038, 1.7156132459640503, 0.27281540632247925, 0.7369546890258789, -0.40360650420188904, 0.5572881102561951, -0.9361012578010559, 0.022196773439645767, -0.4881401062011719, -0.12815061211585999, -0.4768548309803009, -0.6918691992759705, -1.3542441129684448, -0.47708413004875183, 0.23577648401260376, -0.925540030002594, 0.3626023232936859, -0.39948564767837524, 0.21251900494098663, -0.06435399502515793, 0.3542211949825287, 0.30369052290916443, 0.596573531627655, 0.35989251732826233, 0.3339467942714691, 0.7335236668586731, -1.0663604736328125, -0.4706709086894989, -1.4529039859771729, 0.4991441071033478, -0.2022010236978531, 0.334232896566391, 0.0012984761269763112, -1.6959601640701294, -0.6824729442596436, -0.9066522121429443, -0.11340286582708359, -0.37846142053604126, 0.23289789259433746, 0.9868351817131042, -0.02648782543838024, -1.0422769784927368, 0.6054509282112122, -0.4862740933895111, 0.048815954476594925, 0.3316960036754608, 0.6269209980964661, 0.4057508707046509, -0.35881277918815613, -1.035651683807373, 0.3962833881378174, 0.1175771951675415, -0.790178656578064, -0.13231228291988373, -0.16461732983589172, -0.9128710627555847, 0.2938293218612671, 0.03898049518465996, -0.6124862432479858, 1.1943552494049072, 0.05566870793700218, -1.2088110446929932, 0.5585785508155823, -0.13252165913581848, -0.17886914312839508, -0.16376924514770508, -0.14002934098243713, -0.8615014553070068, -0.00850547943264246, -0.40758955478668213, 0.5399813055992126, 0.8318796157836914, -0.0757155492901802, -0.0997123122215271, 0.047335442155599594, -0.5034787058830261, 0.06872887164354324, -0.2756424844264984, 1.1570872068405151, -0.8202406167984009, -0.06507799029350281, 0.7127175331115723, 0.488868772983551, -0.17927446961402893, -0.06142940744757652, -0.17690663039684296, -0.8676161170005798, 0.3452342748641968, 0.15746048092842102, 1.2938679456710815, -1.1301072835922241, -0.707680881023407, 0.10451705753803253, -0.14035096764564514, -0.03300530090928078, -0.5676003098487854, 0.6103865504264832, -0.3836524188518524, 0.25734835863113403, 0.015728730708360672, -0.7407295107841492, 0.05017060786485672, -0.3588067591190338, -0.8512588739395142, -0.13978122174739838, 0.08172903209924698, 0.7774165272712708, -0.4730066657066345, -0.11014626175165176, -0.19600361585617065, 0.1711634248495102, -1.1065701246261597, 1.1300066709518433, -0.603941798210144, -0.08244787156581879, -0.17057891190052032, 0.00044522862299345434, -0.13060303032398224, -0.5752416253089905, 0.5360287427902222, -0.3889628052711487, -0.11490914225578308, 0.5861557722091675, -0.2961709499359131, 1.282654881477356, -0.15919649600982666, 0.4344489872455597, 0.115264393389225, -0.8266814351081848, 0.14552049338817596, 0.5734664797782898, -0.2790672481060028, -0.7940175533294678, 0.368476927280426, 0.5124997496604919, -0.02982383780181408, 0.36571019887924194, 0.6805481910705566, 1.0916019678115845, -0.2627237141132355, 0.1693568080663681, 0.6525079607963562, -0.3023349344730377, 0.6112539172172546, 0.1819697767496109, 0.606225848197937, 0.31514492630958557, 0.18601109087467194, -0.14495691657066345, 0.1854054480791092, -0.9540712237358093, -0.6428015828132629, 0.7105666995048523, 0.6103291511535645, 0.737320601940155, 0.11560594290494919, -0.6669356822967529, -0.6797178983688354, -0.1265803575515747, 0.43486130237579346, 1.4355353116989136, -0.2913840413093567, -0.14415721595287323, -0.6867132186889648, 0.1885860711336136, -0.413703054189682, 0.2751133441925049, 0.4059237539768219, -0.28375595808029175, -0.7899022698402405, -0.8249635696411133, 0.6295730471611023, 0.0195968896150589, 1.084066390991211, -0.5607085227966309, -0.5144625902175903, -0.26696309447288513, 0.4767952561378479, -0.8729820251464844, -0.35075637698173523, 0.4508727788925171, -0.6854075789451599, 0.27423539757728577, 0.15403054654598236, -0.1300063133239746, 0.11562106013298035, -0.20417742431163788, 1.2371528148651123, -0.14269208908081055, -0.20451264083385468, 0.17108257114887238, 0.927064836025238, -0.7752633094787598, -0.6579483151435852, 0.18601129949092865, 0.4526349902153015, -0.19966605305671692, 0.29389500617980957, 0.07263732701539993, -0.23712120950222015, -0.3509703278541565, -0.5335080027580261, 0.3777805268764496, 0.2839873135089874, -0.07462683320045471, 0.42029911279678345, -0.4904426038265228, -0.19372111558914185, -1.066079020500183, 0.7248241901397705, -0.2730858027935028, -0.384389191865921, 0.3467852473258972, -0.6405110955238342, -0.14574958384037018, 0.8668848872184753, -0.5911473035812378, -0.11784200370311737, -1.1397461891174316, 0.14376290142536163, -0.522643506526947, -0.0805419534444809, 0.18073192238807678, 0.5746985077857971, 0.16306476294994354, 0.0828697457909584, 0.7855029702186584, 0.358593225479126, 0.04687807336449623, 0.3250003159046173, -0.5766143798828125, 0.6294275522232056, 0.10371826589107513, 0.11847839504480362, -0.06410501152276993, -0.2721753716468811, -0.6095431447029114, -0.13917255401611328, 0.0037482541520148516, -0.26337698101997375, -0.2433522790670395, 0.06387803703546524, -0.7660070657730103, -0.5914307832717896, -0.2916918396949768, -0.8139036893844604, -0.16301295161247253, 0.39004001021385193, 0.04781842976808548, -0.25455906987190247, -1.1698644161224365, -1.1570558547973633, -0.6915754675865173, -0.8658686876296997, -1.0688964128494263, 0.3289754092693329, 0.10789083689451218, -0.36150744557380676, -0.18868909776210785, -0.33111774921417236, -0.295126348733902, 1.0625149011611938, -1.1604243516921997, 0.9211111068725586, -0.24201034009456635, -0.26304784417152405, -0.2868216037750244, 0.12174064666032791, 0.011354761198163033, -1.1111737489700317, 0.44071176648139954, -0.8810620903968811, 0.2197374552488327, -0.36618542671203613, -0.20574551820755005, -0.16224029660224915, 0.0803430899977684, 0.9941229224205017, 0.08976422995328903, -0.5796065330505371, 0.33724725246429443, 1.0299220085144043, -0.3356235921382904, 0.05782267078757286, 0.05188648775219917, 0.8906591534614563, -0.36361533403396606, -0.5403976440429688, 0.6902676820755005, 0.10430508106946945, 0.5013991594314575, 0.0968598797917366, 0.037285786122083664, -0.16674722731113434, -0.4339837431907654, 0.6257556080818176, 1.7953746318817139, 0.38695380091667175, -0.4329279065132141, -0.9696412682533264, 0.3452819585800171, -1.0418907403945923, -0.5838044881820679, 0.7163426876068115, 0.9576786160469055, 0.27157309651374817, -0.006335853133350611, -0.28917834162712097, -0.34634649753570557, 0.17374476790428162, 0.07818939536809921, -0.406231164932251, -0.9436259269714355, 0.22519844770431519, 0.8197851777076721, 0.43162888288497925, 0.25052961707115173, -0.17857994139194489, 0.6042442321777344, 15.1679048538208, 0.7563313841819763, -0.019468072801828384, 0.4938235282897949, 0.44314274191856384, 0.0736062154173851, -0.09618183970451355, -0.5609710216522217, -1.0020838975906372, 0.09672768414020538, 2.039644956588745, 0.07810717076063156, 0.9066000580787659, 0.41304758191108704, -0.49538612365722656, 0.22125661373138428, -0.5784258842468262, 0.6143026351928711, 0.7211776375770569, -1.0050979852676392, 0.5381000638008118, 0.025429002940654755, -0.11840061098337173, 0.9796713590621948, 0.9444085955619812, 0.7538937926292419, 0.6196134686470032, -0.5252023935317993, 0.696022093296051, 0.25272876024246216, 0.8846995830535889, -0.09080706536769867, -0.07530544698238373, 0.6333305239677429, -0.7367170453071594, -0.1327441781759262, -0.6161084175109863, -1.1071256399154663, -0.17819198966026306, -0.23828314244747162, -0.466665655374527, -0.734026312828064, -0.3055284917354584, 0.10807827860116959, 0.09376019239425659, 0.27402836084365845, 0.05134495347738266, 0.8668869733810425, -0.6654301285743713, 0.15986527502536774, 0.1339929699897766, 0.3364376723766327, -0.03109593130648136, -0.11643549054861069, 0.14051778614521027, -0.06504266709089279, 0.02548767440021038, 0.2523675262928009, -0.5084429979324341, -0.2630302608013153, -0.653829038143158, -0.4656330645084381, 0.06649202108383179, 0.501534104347229, 0.24896422028541565, 0.18056724965572357, -0.8104701042175293, 0.5328255891799927, 0.796399712562561, 0.11245401203632355, -0.40834078192710876, 0.26768213510513306, 0.1653503030538559, -0.7211572527885437, -0.07181183993816376, 0.14550207555294037, -0.18766777217388153, -0.6645849943161011, -0.818381667137146, -0.6065691113471985, 0.3233143389225006, -0.9208661317825317, -0.30293378233909607, 0.7865979671478271, -0.1274629682302475, -0.2763780951499939, 0.1720886379480362, -1.048687219619751, -0.0667661726474762, 0.11414261907339096, -1.1853052377700806, -0.439679354429245, 0.6838109493255615, -0.10216027498245239, -0.246744766831398, -0.16221940517425537, 1.5815694332122803, 0.49030032753944397, -0.5255315899848938, 0.33370131254196167, 0.2979492247104645, -0.04874748736619949, -0.5672435760498047, -0.24416491389274597, 0.7959575653076172, 0.33001095056533813, 0.401937872171402, 0.3979801833629608, 0.0022705267183482647, 0.5047097206115723, -1.3178764581680298, 0.5105810165405273, 0.6405123472213745, -0.7129856944084167, -0.047582488507032394, -0.7209251523017883, -0.6349840760231018, 0.5068087577819824, 0.39172470569610596, -0.13193541765213013, 0.36066848039627075, -0.0635470300912857, -0.5627976059913635, 0.09932602941989899, -0.37513267993927, 0.5694188475608826, 0.6375800967216492, -0.7853221893310547, -0.06134158745408058, 0.1520056426525116, 0.11429404467344284, -0.9496532678604126, -0.4889807105064392, -0.1339270919561386, 0.13025303184986115, -0.06978205591440201, 1.2805557250976562, -0.28928983211517334, 0.8597907423973083, 0.8637881278991699, -0.16125956177711487, -0.4445297420024872, -0.08421480655670166, -0.559684693813324, -0.4873529374599457, -0.4152974784374237, 0.6667099595069885, -0.24710379540920258, -0.06400057673454285, 1.3346747159957886, 0.022271977737545967, -0.3853810131549835, -0.8111725449562073, -0.04020874947309494, -0.1133195087313652, -0.5033840537071228, 0.13202840089797974, -0.32992789149284363, 0.1086341068148613, 0.4503791630268097, 0.43519115447998047, 0.4245089292526245, -0.37402966618537903, -0.6741174459457397, 0.28094005584716797, 0.07153346389532089, -0.03150850906968117, -0.6346296072006226, -0.18803644180297852, -1.2731735706329346, -0.2206086367368698, -1.2063488960266113, -0.003143635345622897, -0.47036218643188477, -0.581488311290741, -0.011371850036084652, -0.250081330537796, -0.052348364144563675, 0.5820968747138977, -0.022538956254720688, -0.23453058302402496, -0.022990839555859566, -0.7089335322380066, 0.5950136184692383, 0.831221342086792, -0.37202921509742737, 0.3253472149372101, -0.23343448340892792, 0.5320073962211609, 0.5039933323860168, 0.5009651780128479, -0.016703104600310326, -0.9276503920555115, -1.684071660041809, 0.41609078645706177, -0.04868238791823387, -0.44479456543922424, -1.2109289169311523, 0.8068707585334778, 0.4248998761177063, -0.10065639764070511, 0.2230893224477768, 0.5035552978515625, -1.0464712381362915, -0.4436989724636078, 0.27930310368537903, -0.8084983825683594, 0.2695937752723694, 0.30511435866355896, -0.6787166595458984, 0.07125125080347061, 0.5539668798446655, -0.1129966527223587, -0.9478849768638611, -0.6281126141548157, 0.3198748528957367, -0.5999411940574646, 0.08563966304063797, -0.23382380604743958, -0.03492686524987221, -0.9061869382858276, -0.26901915669441223, 0.14670416712760925, -0.06393492966890335, -0.5271024107933044, 0.7733556628227234, 0.5554671287536621, -0.7628095149993896, 0.22534166276454926, 0.6962025761604309, -0.34442415833473206, -0.06483778357505798, 0.04817863926291466, 0.47664114832878113, -0.5692324042320251, 0.6782947182655334, 0.2953159213066101, 0.5354912281036377, -0.7233424782752991, 0.183697909116745, 0.4272366166114807, -0.43535760045051575, -0.30386969447135925, 1.045179009437561, -0.40624022483825684, -0.8932834267616272, 0.051315467804670334, -0.9431520104408264, -0.43264755606651306, -0.6010817289352417, 0.4368843138217926, -0.25709325075149536, -0.027161676436662674, -0.036656446754932404, -0.3534148037433624, -0.176090270280838, -0.06567755341529846, -0.6031817197799683, 0.16446322202682495, -0.13850173354148865, -0.2524559795856476, 0.7532567381858826, 0.7615084052085876, -0.799168586730957, -0.4057629406452179, -0.6853712201118469, -0.3874184489250183, 0.1717994511127472, 0.4119744598865509, -0.2775336503982544, -0.4162236452102661, 1.000062346458435, 0.432017982006073, 0.0273663941770792, -0.13928398489952087, -0.24742595851421356, 0.18328605592250824, 0.6736637353897095, 0.254819393157959, -0.5971656441688538, -0.7764797806739807, 1.5462584495544434, 1.0092535018920898, -0.6311518549919128, 0.38520437479019165, -0.21103301644325256, -0.5430310964584351, 0.9509074687957764, 0.5530755519866943, -0.007955868728458881, 0.7954817414283752, 0.2453555017709732, -0.29726478457450867, -0.02324713207781315, -1.049307942390442, -0.10530906915664673, 0.7004774212837219, 0.44409817457199097, 0.9616511464118958, 0.31663647294044495, 0.10735304653644562, 0.8115604519844055, -0.1820259839296341, 0.39679092168807983, -0.04407856613397598, 0.6397681832313538, -0.2795010209083557, 0.2720946669578552, -0.10367565602064133, 0.9530875086784363, -0.5945892333984375, -1.1219003200531006, 0.4547874629497528, 0.6978484988212585, -0.049982950091362, 0.25175249576568604, 1.3432806730270386, -0.04341357201337814, 0.2569071054458618, 0.6318795680999756, 0.5811984539031982, -0.5101701021194458, -0.13861671090126038, -0.21242587268352509, -0.326209157705307, 0.25938427448272705, 0.13345861434936523, -0.29063305258750916, -0.6921000480651855, -0.09174390137195587, 0.29904118180274963, -0.25206229090690613, 0.3154163360595703, 1.0135341882705688, 0.9544957280158997, 0.48659664392471313, -0.47260698676109314, -0.38234657049179077, -0.27832335233688354, -0.9869751334190369, 0.2976941466331482, -0.4818323850631714, -0.6026549935340881, -0.21508406102657318, 0.14788545668125153, -0.3180623948574066]}, "authors": [{"authorId": "10419477", "name": "A. Gholami"}, {"authorId": "9088433", "name": "Z. Yao"}, {"authorId": "2262511276", "name": "Sehoon Kim"}, {"authorId": "2029486869", "name": "Coleman Hooper"}, {"authorId": "2271923589", "name": "Michael W. Mahoney"}, {"authorId": "2242659602", "name": "Kurt Keutzer"}], "references": [{"paperId": "db633c6b1c286c0386f0078d8a2e6224e03a6227", "title": "Mistral 7B"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "51db4c39dc0bdf5c95c8bbe89bf4211b48d0b4df", "title": "SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression"}, {"paperId": "db9507cdd3e2d7d9c90ed185bd831e55c62dcec9", "title": "AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration"}, {"paperId": "0a6906bd6f026d3da3031c641ed03081bd0b574e", "title": "Full Stack Optimization of Transformer Inference: a Survey"}, {"paperId": "909ad57ce8caa6b390a65ae09db352d27d8f3996", "title": "SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "b37d57edf4a84da158ab8d77921d4aa39faceb32", "title": "FP8 Formats for Deep Learning"}, {"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "e03609f2587f690867e7ea0bedaf0db25282c548", "title": "ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers"}, {"paperId": "bc8b82e8eb0b0714892e4ec7a54ebdf47c4fde96", "title": "Reducing Activation Recomputation in Large Transformer Models"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "fb145e1e49d3269d8223c7710e22b45438613ff0", "title": "A Fast Post-Training Pruning Framework for Transformers"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "04e283adccf66742130bde4a4dedcda8f549dd7e", "title": "A Survey of Quantization Methods for Efficient Neural Network Inference"}, {"paperId": "9d6acac70b2d1fdb861a08b00766ef263109cd7f", "title": "Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks"}, {"paperId": "f30444fbb6ad806168e2564db4815cd27faa7fd9", "title": "It\u2019s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners"}, {"paperId": "68afea9c892ff499af788ccfa25fa17b507bc993", "title": "Accelerating Recommender Systems via Hardware \"scale-in\""}, {"paperId": "20438e2a38a0c4723fbd9de50b44b7335f6f43cb", "title": "ADAHESSIAN: An Adaptive Second Order Optimizer for Machine Learning"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "fd431005d26100f5453590080683cbae9dc1189f", "title": "Checkmate: Breaking the Memory Wall with Optimal Tensor Rematerialization"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "6e13e111e85d499d781386b182fd855fbb053771", "title": "Deep Learning Recommendation Model for Personalization and Recommendation Systems"}, {"paperId": "e7fd6848cb29ca221a7e17d823e06fb566f1f135", "title": "Mixed Precision Training"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "d21703674ae562bae4a849a75847cdd9ead417df", "title": "Optimization Methods for Large-Scale Machine Learning"}, {"paperId": "f2905b93d056f3c71a4ac92b737a4c77680ce28e", "title": "Minimizing Communication in Numerical Linear Algebra"}, {"paperId": "092217c2267f6e0673590aa151d811e579ff7760", "title": "Roofline: an insightful visual performance model for multicore architectures"}, {"paperId": "843a1567b056c8a1d0deddc8b699e1725194f85c", "title": "Latency lags bandwith"}, {"paperId": "f6b3ea152aa5d35056c677000085333621c54962", "title": "Reflections on the memory wall"}, {"paperId": "4e80b0566c4c548b15b1e3cec6a0864c9008f841", "title": "No exponential is forever: but \"Forever\" can be delayed! [semiconductor industry]"}, {"paperId": "e23080194a78d970bd3cafc48611826d3045484a", "title": "A case for intelligent RAM"}, {"paperId": "4d25bbe6e357095a0de073f09c1fe51d3e663177", "title": "The memory wall and the CMOS end-point"}, {"paperId": "4cdde0eafec8bdbf043dd27686234bee57687aba", "title": "Hitting the memory wall: implications of the obvious"}, {"paperId": "bccb4ff16f52113a93cde7025a82f581695beb19", "title": "Computer Architecture: A Quantitative Approach"}, {"paperId": "363668677c459ebc0ff494655f993a93a0251009", "title": "OPTQ: Accurate Quantization for Generative Pre-trained Transformers"}, {"paperId": "bb0656031cb17adf6bac5fd0fe8d53dd9c291508", "title": "An empirical analysis of compute-optimal large language model training"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "\u201cTensor processing using low precision format,\u201d Dec. 28"}, {"paperId": null, "title": "\u201cStream: Sustainable memory bandwidth in high performance computers,\u201d"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": null, "title": "\u201cIt\u2019s the memory, stupid!\u201d"}, {"paperId": "b968b0f2d77bd93c7d7fada8b87a337c64ee2e67", "title": "Why Aren't Operating Systems Getting Faster As Fast as Hardware?"}, {"paperId": null, "title": "\u201cSqueezellm"}, {"paperId": null, "title": "Dense-and-sparse quantization"}]}