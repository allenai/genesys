{"paperId": "054f4506663e05e6d3e6bcf55f02a2d9d014bcc5", "abstract": "Large Language Model (LLM) pre-training exhausts an ever growing compute budget, yet recent research has demonstrated that careful document selection enables comparable model quality with only a fraction of the FLOPs. Inspired by efforts suggesting that domain-specific training document selection is in fact an interpretable process [Gunasekar et al., 2023], as well as research showing that instruction-finetuned LLMs are adept zero-shot data labelers [Gilardi et al.,2023], we explore a promising direction for scalable general-domain document selection; employing a prompted LLM as a document grader, we distill quality labels into a classifier model, which is applied at scale to a large, and already heavily-filtered, web-crawl-derived corpus autonomously. Following the guidance of this classifier, we drop 75% of the corpus and train LLMs on the remaining data. Results across multiple benchmarks show that: 1. Filtering allows us to quality-match a model trained on the full corpus across diverse benchmarks with at most 70% of the FLOPs, 2. More capable LLM labelers and classifier models lead to better results that are less sensitive to the labeler's prompt, 3. In-context learning helps to boost the performance of less-capable labeling models. In all cases we use open-source datasets, models, recipes, and evaluation frameworks, so that results can be reproduced by the community.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work uses a prompted LLM as a document grader to distill quality labels into a classifier model, which is applied at scale to a large, and already heavily-filtered, web-crawl-derived corpus autonomously and helps to boost the performance of less-capable labeling models."}, "embedding": {"model": "specter_v2", "vector": [-0.03679833933711052, 0.30566513538360596, -0.5941075682640076, 0.07506181299686432, -0.744683027267456, -0.43616315722465515, 0.9513035416603088, -0.34474462270736694, -0.39260584115982056, -0.11345280706882477, 0.41227471828460693, -0.11800716817378998, 0.0580349862575531, 0.1945485770702362, 0.20538362860679626, 0.2946370542049408, -0.8743179440498352, 0.7954645156860352, -0.22851163148880005, -0.3521096706390381, -0.1409609168767929, -0.6904997825622559, -0.837490439414978, -0.00713543314486742, 0.41817498207092285, 0.485437273979187, 0.018446912989020348, 0.6598064303398132, -0.5449753403663635, 0.02369825914502144, 0.41509389877319336, -0.13006004691123962, 0.3858087956905365, -0.25557729601860046, -0.5532240271568298, 0.2553136944770813, 0.2678942382335663, -0.26647597551345825, -0.08145682513713837, 0.6224318742752075, 0.06734764575958252, 0.47407323122024536, 0.17077673971652985, -0.5542550086975098, -0.49416491389274597, 0.7525069117546082, 0.4790630340576172, 0.5554412603378296, 0.11124040186405182, -0.5200069546699524, 1.5181351900100708, -1.2582260370254517, 0.6542967557907104, 1.4328300952911377, 0.367961585521698, 0.6583458781242371, -0.3745156526565552, -0.37609919905662537, 0.7576402425765991, -0.06496401131153107, -1.0623971223831177, 0.017798440530896187, -0.09991534054279327, -0.2884383797645569, 1.6983674764633179, -0.45577752590179443, -0.11419618129730225, 0.6185315847396851, -0.08382640033960342, 1.2802953720092773, -0.27473995089530945, -1.0261896848678589, 0.05976104363799095, 0.3051912486553192, 0.6363676190376282, 0.7193830013275146, -0.3737732172012329, 0.19352751970291138, -0.8458103537559509, -0.5508649349212646, 0.08126191794872284, -0.3221067190170288, -0.007484226021915674, -0.3268578052520752, 0.11992286890745163, 0.7738223075866699, -0.3553256392478943, 0.5940232276916504, 0.05266629531979561, 0.3727610409259796, 0.5174059867858887, 0.5691439509391785, 0.5561739206314087, 0.5198187232017517, -0.3479223847389221, 0.3251153230667114, -0.8072780966758728, 0.27953460812568665, 0.23752738535404205, 1.124700665473938, -0.14908209443092346, 0.10292837768793106, -0.8920701742172241, 0.5216285586357117, 1.1065133810043335, -0.19419197738170624, 0.6852939128875732, -0.5467905402183533, 0.003956850152462721, -0.5740880966186523, 0.33395564556121826, -0.1510676145553589, -0.47980406880378723, -0.23118340969085693, -0.3003663718700409, -1.0298627614974976, -0.7285698652267456, -0.05799844115972519, -0.47065266966819763, 0.7342274188995361, -0.1425068974494934, -0.017205527052283287, -0.1406686156988144, 0.6048024296760559, 0.4513774812221527, 0.31892916560173035, 0.33076801896095276, -0.07149248570203781, 0.7425240278244019, -0.7553708553314209, -0.16562804579734802, -0.9941079020500183, 1.0313572883605957, -0.3852364420890808, 0.7926590442657471, 0.24856574833393097, -1.3133530616760254, -0.8769004344940186, -0.4722044765949249, 0.17534072697162628, -0.7076884508132935, 0.4958955943584442, 1.0150084495544434, 0.4184078872203827, -0.6341440081596375, 0.6707777976989746, 0.11551778763532639, -0.47089892625808716, -0.0029770666733384132, 0.02163177728652954, 0.5122819542884827, -0.8162283301353455, -1.5290733575820923, 0.2759424149990082, -0.23241542279720306, -0.9768791198730469, -0.668099045753479, -0.537265419960022, -0.6574226021766663, -0.5082020163536072, 0.3202877342700958, -0.24664194881916046, 1.4237104654312134, -0.07196004688739777, -1.1995183229446411, 0.6949132084846497, -0.09667505323886871, 0.04246671870350838, 0.6870237588882446, -0.14658749103546143, -0.8438541889190674, -0.4586164057254791, -0.13737910985946655, 0.13342544436454773, 0.45789656043052673, -0.06825219094753265, -0.6180648803710938, 0.44812700152397156, 0.09238699078559875, -0.10071421414613724, -0.6415467858314514, 0.8393068313598633, -0.654572069644928, -0.02300984226167202, -0.04400699585676193, 0.6740548014640808, -0.14721108973026276, -0.5074761509895325, -0.04994107410311699, -1.501535177230835, 0.575328528881073, -0.2348155975341797, 1.1898627281188965, -0.5058678984642029, -0.7263250350952148, -0.25236377120018005, -0.29814666509628296, -0.1026473268866539, -0.9195167422294617, 0.7332174777984619, -0.05826621875166893, 0.664135217666626, 0.1491868793964386, -0.9881899356842041, 0.37115147709846497, -0.7112244963645935, -0.5858324766159058, -0.08174783736467361, 0.14456172287464142, 0.5417149066925049, -0.858529269695282, 0.033191148191690445, -0.34383055567741394, 0.11663606762886047, -0.9819368720054626, 0.914119303226471, -0.8595234751701355, 0.2032044380903244, -0.4267790913581848, -0.27915191650390625, 0.3292055130004883, -0.14924558997154236, 0.4871603846549988, -0.27637794613838196, -0.1389937698841095, 0.43737703561782837, -0.26378175616264343, 1.429849624633789, -0.7176104784011841, 0.3411872386932373, 0.05979106202721596, -0.13959728181362152, 0.3147430121898651, 0.24037492275238037, -0.002567736664786935, -0.4336847960948944, 0.18139348924160004, 0.4103561043739319, -0.9093108177185059, 0.07105752825737, 0.5916589498519897, 0.8686131238937378, -0.5724904537200928, 0.5477926731109619, 0.5211148262023926, -0.1333550661802292, 1.2056217193603516, 0.609033465385437, 0.8721052408218384, 0.7214940190315247, 0.1420806497335434, -0.17434042692184448, 0.5352632403373718, -0.31431639194488525, -0.16682608425617218, 0.672925591468811, 0.7429178357124329, 0.7145461440086365, 0.2387237399816513, -0.8725097179412842, -0.36274388432502747, 0.1245168000459671, 0.7115896344184875, 1.7355022430419922, -0.049182821065187454, -0.45953965187072754, -0.8220279812812805, -0.6086639761924744, -0.2801864445209503, 0.4951789677143097, -0.36164018511772156, -0.21956908702850342, -0.7304293513298035, -1.1093113422393799, 0.3192017078399658, -0.27018648386001587, 0.5571606159210205, -0.4155718982219696, 0.08739069849252701, -0.2009667605161667, 0.2175094485282898, -0.7318119406700134, -0.657722532749176, 0.26612645387649536, -0.08934614807367325, -0.21810586750507355, -0.019502563402056694, -0.23678112030029297, 0.1436401903629303, -0.3728300929069519, 1.3664296865463257, -0.166489377617836, -0.6887710094451904, 0.5758178234100342, 0.03477737680077553, -0.3467962145805359, -0.7207725048065186, 0.4165763556957245, 0.4241385757923126, -0.2328377217054367, 0.7184128165245056, 0.8715032339096069, 0.3006802797317505, 0.11435117572546005, -0.3917328715324402, 0.048988308757543564, -0.2404516339302063, 0.15429909527301788, 0.4486304223537445, 0.06147100031375885, 0.07911022007465363, -1.1311599016189575, 1.4310152530670166, 0.08742854744195938, -0.712863028049469, 0.6352736353874207, -0.9073324799537659, -0.5766791105270386, 0.7577027678489685, -0.9219483733177185, -0.46589866280555725, -1.0308294296264648, 0.6085428595542908, 0.03116622194647789, -0.3227792978286743, 0.11144763231277466, 0.35243043303489685, 0.18515987694263458, 0.46768802404403687, 0.4506887197494507, 0.1592039316892624, -0.8622943758964539, 0.7310298085212708, -0.5154502987861633, 0.05070978403091431, -0.1364443600177765, -0.04225744679570198, 0.05934960022568703, -0.3761110305786133, -0.6478630900382996, -0.6269978284835815, -0.21132910251617432, -0.4820212125778198, -0.3601016104221344, 0.14908289909362793, -0.6734747290611267, -0.31959161162376404, -0.4762933850288391, -0.9699344635009766, -0.6525280475616455, 0.130340114235878, -0.1955919712781906, -0.0512230321764946, -1.0246154069900513, -1.066535472869873, -0.3927702009677887, -0.6690510511398315, -0.9111399054527283, 0.1620425581932068, -0.12862488627433777, -0.6653565764427185, -0.5891813635826111, 0.11417027562856674, -0.3114590346813202, 0.5825942158699036, -0.8700177669525146, 0.9026391506195068, -0.2108594924211502, -0.020167162641882896, -0.722730815410614, 0.26791247725486755, 0.4344016909599304, -0.4311198890209198, 0.22317156195640564, -0.46299469470977783, -0.03834841400384903, -0.4975311756134033, -0.5743170976638794, -0.06932701915502548, 0.14102286100387573, 0.4582352638244629, 0.4279564321041107, -0.558899998664856, 0.3443944454193115, 1.244417428970337, -0.9617990255355835, -0.5658126473426819, 0.2833883762359619, 0.8687641620635986, 0.36714082956314087, 0.09317340701818466, 0.9038494229316711, 0.0079726567491889, 0.46917423605918884, -0.308067262172699, -0.28444430232048035, -0.4996100664138794, -0.3274388015270233, 0.5355834364891052, 1.3835530281066895, 0.6748854517936707, -0.1229066550731659, -0.9711010456085205, 0.7024196982383728, -1.0026555061340332, -0.30156153440475464, 0.508178174495697, 0.7663781642913818, 0.32580795884132385, -0.39011824131011963, -0.13079234957695007, -0.5474445223808289, 0.28816860914230347, -0.13933300971984863, -0.2560770511627197, -0.628577709197998, 0.08088289946317673, 0.10717031359672546, 0.04622213914990425, 0.5376672744750977, -0.3244970738887787, 0.8002451062202454, 15.055506706237793, 1.2285486459732056, 0.3369724452495575, 0.7174818515777588, 0.4753698706626892, -0.3047965466976166, -0.48201319575309753, -0.2204378992319107, -1.543569803237915, -0.0655457079410553, 1.2763053178787231, -0.19309934973716736, 1.0060579776763916, 0.5069850087165833, 0.44870230555534363, 0.1667930632829666, -0.5039620995521545, 0.33764082193374634, 0.8119297027587891, -1.0857802629470825, 0.5399521589279175, 0.39294713735580444, 0.6277147531509399, 0.7191002368927002, 0.5119133591651917, 1.3188438415527344, 0.7824640870094299, -0.12414849549531937, 0.6976652145385742, 0.1244756430387497, 0.8759021759033203, -0.2616666555404663, 0.17413534224033356, 0.6350210905075073, -0.6273119449615479, -0.5259628891944885, -0.8897265195846558, -0.9309824705123901, 0.4113275110721588, 0.24512749910354614, -0.6635808944702148, -0.5293117761611938, -0.3438575863838196, 0.2906264066696167, -0.02300254814326763, 0.24330271780490875, -0.12796005606651306, 0.7881374359130859, 0.04149186238646507, -0.07459473609924316, 0.3276595175266266, 0.3312737047672272, 0.3098752200603485, 0.24443656206130981, -0.13386277854442596, 0.029843715950846672, 0.49706971645355225, 0.2580917179584503, -0.7002235651016235, 0.07615090161561966, -0.15022432804107666, -0.1147845908999443, -0.032318707555532455, 0.9782103300094604, 0.53899085521698, -0.0711069107055664, -0.516025185585022, 0.3411906957626343, 0.6509346961975098, 0.10547937452793121, -0.2196650207042694, 0.10135138779878616, 0.3810635805130005, -0.47973406314849854, -0.19086328148841858, 0.5082183480262756, -0.029677817597985268, -0.7482375502586365, -1.0295652151107788, -0.5499439835548401, 0.5035144090652466, -0.53306645154953, -1.0691776275634766, 0.9815577864646912, -0.2095680832862854, -0.6675068736076355, 0.008415778167545795, -0.7341540455818176, 0.03852558135986328, 0.587124228477478, -1.1685106754302979, -0.6786419153213501, 0.469107061624527, -0.4666168689727783, 0.04444088786840439, -0.28040435910224915, 1.3013635873794556, 0.3642178177833557, -0.6301013827323914, 0.1200084239244461, 0.5510576367378235, -0.1792011708021164, 0.02883724495768547, -0.3762434124946594, 0.9008581042289734, 0.23379270732402802, -0.03964276239275932, 0.2841993272304535, -0.10847605764865875, -0.1812959462404251, -0.712975800037384, -0.2799467444419861, 0.6499677896499634, -1.1769770383834839, -0.18672993779182434, -0.9966591000556946, -0.5921660661697388, 0.011971896514296532, 0.31926682591438293, -0.3541327118873596, 0.4376087188720703, 0.16114617884159088, -0.523076593875885, -0.09663696587085724, -0.9582589268684387, 0.09682316333055496, 0.556709349155426, -0.5194902420043945, 0.12823092937469482, 0.6602513194084167, 0.4315292537212372, -0.6759466528892517, -0.556910514831543, -0.5445182919502258, -0.10782293975353241, 0.3385818898677826, 0.906323254108429, -0.7396121621131897, 0.5832989811897278, 0.942396879196167, -0.12614865601062775, -0.7334751486778259, -0.4037021994590759, -0.9048562049865723, -0.0529266782104969, 0.576921820640564, 0.6618355512619019, -0.038378383964300156, 0.18220306932926178, 1.16878342628479, 0.5877087712287903, -0.47564807534217834, -0.152449369430542, -0.6710519790649414, 0.4843466579914093, -0.6644507050514221, 0.5748558640480042, -0.06189152970910072, 0.021271834149956703, 0.13394665718078613, 0.19757965207099915, 0.6074151396751404, 0.0798906609416008, -0.7271116375923157, 0.6100738048553467, -0.19738687574863434, -0.0002701739431358874, -0.6336272358894348, 0.04911898449063301, -1.492351770401001, 0.06479325145483017, -1.1535847187042236, -0.017472101375460625, -0.979447066783905, -0.4847715497016907, 0.07598916441202164, -0.16009537875652313, -0.29714295268058777, 0.8038648366928101, -0.38214999437332153, -0.4318268299102783, -0.38933610916137695, -1.0268670320510864, 0.44451162219047546, 0.6761460900306702, -0.7250010371208191, 0.13122844696044922, -0.09588593989610672, 0.12608098983764648, 0.3806757926940918, 0.4001803398132324, -0.4358823299407959, -0.7530621886253357, -1.4428596496582031, 0.20328325033187866, -0.3120748698711395, -0.2552201747894287, -0.4883219003677368, 0.27436649799346924, 0.16016452014446259, -0.13995307683944702, 0.14691293239593506, -0.02996506355702877, -0.5460877418518066, -0.8006163239479065, -0.008946238085627556, -1.1359643936157227, -0.124619260430336, -0.03807220235466957, -0.7098283767700195, 0.14104871451854706, 0.18976685404777527, -0.2654982805252075, -1.376997947692871, -0.8263964056968689, 0.35454219579696655, -0.8111669421195984, 0.2463563233613968, -0.4714553654193878, 0.19480492174625397, -0.7299966216087341, -0.3051844835281372, 0.09421476721763611, 0.48246216773986816, -0.13351616263389587, 1.3033818006515503, -0.10654529184103012, -1.1483986377716064, -0.26682695746421814, -0.08339040726423264, 0.03869760036468506, -0.3320823907852173, 0.3436421751976013, 0.10649441927671432, -0.08325107395648956, 0.5552533268928528, 0.6814535856246948, 0.6683215498924255, -0.7066431045532227, 0.1304253190755844, 0.4514576196670532, -0.6775951385498047, -0.26190218329429626, 1.3099244832992554, -0.5112306475639343, -1.076756238937378, 0.15419846773147583, -0.7662541270256042, -0.4438205361366272, -0.3472297787666321, 1.107452630996704, 0.2877117693424225, 0.22698891162872314, 0.09818239510059357, -0.5032516717910767, 0.10504293441772461, 0.01139266137033701, -0.7367399334907532, 0.6769601702690125, -0.6834421157836914, -0.404082715511322, 0.27451491355895996, 1.0697518587112427, -0.43762409687042236, -0.5347382426261902, -0.5146356821060181, -0.14577211439609528, 0.06492265313863754, 0.6214754581451416, -0.8275604844093323, -0.21493610739707947, 0.5020278096199036, 0.7144888043403625, 0.6132732033729553, 0.17778079211711884, -0.27219057083129883, 0.21970336139202118, 0.49109864234924316, 0.5002325177192688, -1.181832194328308, -0.503513514995575, 1.046744704246521, 1.2233328819274902, -1.1672691106796265, 0.6347717046737671, 0.37102004885673523, -0.8117104768753052, 1.0404386520385742, 0.5493859052658081, 0.002585561014711857, 0.78471839427948, -0.32309070229530334, 0.19331276416778564, 0.053750429302453995, -1.2693672180175781, -0.39673885703086853, 0.9134384989738464, 0.9437163472175598, 1.0145330429077148, 0.2845954895019531, -0.29735589027404785, 0.9953169226646423, 0.20369742810726166, 0.45479974150657654, 0.5941036343574524, 0.3265433609485626, -0.12331036478281021, -0.4471839666366577, -0.06366591900587082, 0.5835546851158142, -0.36483198404312134, -0.6849371194839478, -0.2229902297258377, 0.511021077632904, 0.48926597833633423, 0.7502112984657288, 0.6276277899742126, -0.051027897745370865, 0.3597584366798401, 0.10552593320608139, 0.08829709142446518, -0.7663600444793701, -0.4439562261104584, 0.06568047404289246, -0.182098388671875, 0.06734494119882584, 0.30238714814186096, -0.4872538447380066, -0.4285157322883606, -0.01931685395538807, 0.1992049664258957, 0.20367857813835144, 0.27199825644493103, 1.058885931968689, 0.6837894320487976, 0.259860098361969, -0.2095087170600891, -0.6098025441169739, -0.7262895703315735, -0.7006884813308716, -0.14029890298843384, -0.0481085404753685, -0.4689989984035492, -0.3060193955898285, -0.3060585856437683, -0.22541259229183197]}, "authors": [{"authorId": "2291470563", "name": "Xiang Kong"}, {"authorId": "2238621478", "name": "Tom Gunter"}, {"authorId": "2238621132", "name": "Ruoming Pang"}], "references": [{"paperId": "31b2918acc77682b5a499da1aa111f34e76d9603", "title": "How to Train Data-Efficient LLMs"}, {"paperId": "574568e9403ca38d7b3e3c243e2a55ceeecc2ba8", "title": "Autonomous Data Selection with Language Models for Mathematical Texts"}, {"paperId": "2905dc5ad70b462f4f5543df3047dffadb5c0e4e", "title": "Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"}, {"paperId": "590954e15e247cc343710ee97e396ad99f52970f", "title": "Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks"}, {"paperId": "f5789596531fad358c3166fdb5bd72d8e661c32c", "title": "Small-scale proxies for large-scale Transformer training instabilities"}, {"paperId": "e26888285436bc7998e5c95102a9beb60144be5e", "title": "Textbooks Are All You Need II: phi-1.5 technical report"}, {"paperId": "e3052ebca5eeae6a8a73e44517903d39746f5f3a", "title": "From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning"}, {"paperId": "11cf88dce827bd67cbfa60400306318022e736d5", "title": "D4: Improving LLM Pretraining via Document De-Duplication and Diversification"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "e730164e17975547564a1eaa70cea5884b16c89d", "title": "AlpaGasus: Training A Better Alpaca with Fewer Data"}, {"paperId": "9e16d8cc6096ec0d2733a4ecf41ce09d9a4bd19c", "title": "Scaling Data-Constrained Language Models"}, {"paperId": "1567bcac0ab09269c9d0ff33c9a406132417fab9", "title": "A Pretrainer\u2019s Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity"}, {"paperId": "9b4f7c97c0b83a80c32bc0b93595cbcfb4ecb16d", "title": "DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining"}, {"paperId": "28085f480ce456a376ebace9b899e3bc93dbc048", "title": "TinyStories: How Small Can Language Models Be and Still Speak Coherent English?"}, {"paperId": "a9e155fda1d97baa2b8712f580cc61887cc64e9b", "title": "ChatGPT outperforms crowd workers for text-annotation tasks"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "74013b7cfa0fc524803350fca51341004565eb22", "title": "Data Selection for Language Models via Importance Resampling"}, {"paperId": "45122c8f76a4e2fd0163d1f0522db37e97ea4721", "title": "Beyond neural scaling laws: beating power law scaling via data pruning"}, {"paperId": "aa4d9972af3264d032dbee58501ed4ac49477103", "title": "Scaling Laws and Interpretability of Learning from Repeated Data"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "80d0116d77beeded0c23cf48946d9d10d4faee14", "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "a0adc93f9de5cfb1477b4396f01970f8a22e33bb", "title": "The Common"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "5ed791f810da580c78df6a052c6b9f2e258f6b0a", "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "b29447ba499507a259ae9d8f685d60cc1597d7d3", "title": "Semantic Parsing on Freebase from Question-Answer Pairs"}, {"paperId": "7b36c5602930abf08efd2867f92cdb48a1be757a", "title": "Together"}, {"paperId": "4c8cc2383cec93bd9ea0758692f01b98a035215b", "title": "UltraFeedback: Boosting Language Models with High-quality Feedback"}, {"paperId": "0639baa6dfb35d962e46eb0c38763d769ffb0946", "title": "Models"}, {"paperId": null, "title": "A framework for few-shot language model evaluation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Socialiqa: Commonsense reasoning about social interactions"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Less is more for alignment"}, {"paperId": null, "title": "SlimPajama: A 627B token cleaned and deduplicated version of RedPajama"}]}