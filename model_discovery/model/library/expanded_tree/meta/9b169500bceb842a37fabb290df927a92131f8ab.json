{"paperId": "9b169500bceb842a37fabb290df927a92131f8ab", "abstract": "This paper explores a novel dynamic network for vision and language tasks, where the inferring structure is customized on the fly for different inputs. Most previous state-of-the-art approaches are static and hand-crafted networks, which not only heavily rely on expert knowledge, but also ignore the semantic diversity of input samples, therefore resulting in suboptimal performance. To address these issues, we propose a novel Dynamic Transformer Network (DTNet) for image captioning, which dynamically assigns customized paths to different samples, leading to discriminative yet accurate captions. Specifically, to build a rich routing space and improve routing efficiency, we introduce five types of basic cells and group them into two separate routing spaces according to their operating domains, i.e., spatial and channel. Then, we design a Spatial-Channel Joint Router (SCJR), which endows the model with the capability of path customization based on both spatial and channel information of the input sample. To validate the effectiveness of our proposed DTNet, we conduct extensive experiments on the MS-COCO dataset and achieve new state-of-the-art performance on both the Karpathy split and the online test server.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes a novel Dynamic Transformer Network (DTNet) for image captioning, which dynamically assigns customized paths to different samples, leading to discriminative yet accurate captions."}, "embedding": {"model": "specter_v2", "vector": [0.3522989749908447, 0.20841754972934723, -0.671626627445221, -0.19802987575531006, -0.3264032006263733, -0.26119741797447205, 0.6414530277252197, -0.28624802827835083, -0.3376726508140564, -0.19958117604255676, 0.6587896943092346, 0.5334919095039368, 0.47472894191741943, -0.09749545902013779, -0.4088311791419983, 0.5328811407089233, -0.8792782425880432, 0.43639519810676575, 0.905249297618866, -0.39899617433547974, -0.3182876408100128, -0.31439629197120667, -0.975048303604126, 0.42988714575767517, 0.4690462350845337, 0.8237804174423218, 0.4459855556488037, 1.3945610523223877, -0.1758529394865036, -0.07091496884822845, 0.24325458705425262, -0.544877290725708, 0.26323240995407104, -0.4417073130607605, -0.42437493801116943, 0.0984700545668602, 0.6911171674728394, -0.6614469289779663, -0.5216285586357117, 0.8916052579879761, -0.10508168488740921, 0.11027306318283081, 0.41456571221351624, -0.7313098907470703, -0.4043247699737549, 0.6866946816444397, 0.38373056054115295, 0.5881016850471497, -0.07265889644622803, -1.0706976652145386, 1.6868765354156494, -1.1415011882781982, 0.8006365299224854, 1.754597544670105, 0.047646839171648026, 0.6487804651260376, -0.34854450821876526, -0.4324894845485687, 1.087121844291687, 0.6421561241149902, -0.35776519775390625, -0.12483278661966324, 0.07958072423934937, -0.04677286744117737, 1.0591298341751099, -0.8088995218276978, 0.3822735548019409, 0.7444027066230774, -0.2468462735414505, 1.8271911144256592, -0.5171079039573669, -0.6077092885971069, -0.2899124026298523, -0.12666229903697968, -0.3480489253997803, 0.7556172013282776, -0.39010098576545715, -0.02839699387550354, -0.8022357225418091, 0.2102932333946228, 0.7346956133842468, -0.2431657463312149, 0.034150101244449615, -0.29961755871772766, -0.4290291368961334, 0.5627091526985168, 0.9111839532852173, 0.6202439665794373, -0.13534142076969147, 0.801089346408844, 0.6904516220092773, -0.06933464109897614, -0.23602060973644257, 0.05969962850213051, -0.27113500237464905, 0.6773506999015808, -0.7518066763877869, 0.40224000811576843, 0.0020647826604545116, 0.8951877355575562, -0.42753395438194275, -0.33235013484954834, -0.6323336958885193, 0.17737656831741333, 1.293556809425354, -0.12083800882101059, 0.14894527196884155, -0.8708726763725281, 0.24091851711273193, -1.0259568691253662, 0.21746084094047546, -0.965144157409668, 0.14790646731853485, -0.3174768090248108, -0.4576607644557953, -1.318607211112976, -0.34317243099212646, 0.6156079769134521, -1.1205793619155884, 0.6134029030799866, -0.14727897942066193, 0.5089541077613831, -0.2015312761068344, 0.3820543587207794, 0.2297951877117157, 0.6894398331642151, 0.49420931935310364, 0.3959158957004547, 0.7684755921363831, -1.644163727760315, -0.2310820370912552, -1.0616275072097778, 0.23624460399150848, -0.32574188709259033, -0.06872763484716415, -0.3217761814594269, -0.8458332419395447, -1.3105920553207397, -0.9062696099281311, 0.05434169992804527, -0.6431570053100586, 0.14796383678913116, 0.9152252078056335, 0.06272657215595245, -1.276806354522705, 0.6483893394470215, -0.01922057569026947, -0.4592811167240143, 0.7402929663658142, -0.40988582372665405, 0.19011752307415009, -0.8391477465629578, -1.2130436897277832, -0.10389956086874008, -0.19616740942001343, -0.3993423283100128, -0.2864135503768921, -0.4414771795272827, -1.1146700382232666, -0.26942068338394165, 0.3794376254081726, -0.7559927105903625, 1.0839072465896606, -0.5275776386260986, -0.9031990170478821, 0.3721400797367096, -0.2820010781288147, -0.10237077623605728, 0.39562323689460754, -0.3770942687988281, -0.2995498478412628, 0.32010430097579956, 0.24818362295627594, 1.2294092178344727, 0.6346102356910706, -0.5214823484420776, -0.1846814602613449, 0.1536421924829483, -0.056267980486154556, -0.06936099380254745, 0.12553651630878448, 0.9330289363861084, -0.9865350723266602, -0.5241681933403015, 0.2692354619503021, 0.6892088651657104, -0.34868308901786804, 0.5312886834144592, -0.4687693119049072, -0.6191694736480713, 0.9965685606002808, 0.0585276298224926, 0.24711795151233673, -0.6746526956558228, -0.4151247441768646, -0.3183981776237488, -0.4253750443458557, -0.3731023669242859, -1.4322847127914429, 0.1966080665588379, -0.16483867168426514, 0.24242962896823883, -0.16317950189113617, -1.345620036125183, -0.2801688015460968, -0.23519626259803772, -0.43956923484802246, -0.35842499136924744, 0.3737509548664093, 1.1737276315689087, -1.0353295803070068, -0.28378066420555115, -0.24552375078201294, 0.4397095739841461, -1.1717031002044678, 0.8321446180343628, -1.289554476737976, 0.2004534751176834, -0.6200300455093384, 0.18631616234779358, -0.004292821977287531, -0.3790564239025116, 0.42723116278648376, -0.8074421286582947, 0.5136232972145081, 0.49768900871276855, -0.03863920271396637, 1.4709779024124146, 0.13511908054351807, 0.4413088858127594, -0.15518344938755035, -0.5234823226928711, 0.5115605592727661, 0.1582982838153839, -0.06579698622226715, -0.5455704927444458, 0.3336763083934784, 0.138241246342659, -0.8159298300743103, 0.2979135513305664, 0.8362873792648315, 0.9277310967445374, -0.23017624020576477, -0.09375780820846558, 0.31701698899269104, -0.10343696177005768, 0.5491114854812622, 0.7464900612831116, 0.6680874228477478, 0.6661009788513184, 0.019423119723796844, 0.3558436632156372, 0.4474763572216034, -0.67914879322052, -0.1224399283528328, 0.29462772607803345, 0.14022861421108246, 1.4168182611465454, 0.7599955201148987, -0.5814105868339539, -0.7140188217163086, 0.11150554567575455, 0.599632978439331, 1.1469521522521973, 0.1476515829563141, -0.19049450755119324, -0.8595930337905884, -0.8218002915382385, -0.4093679189682007, -0.3615109324455261, -0.760174036026001, 0.32444989681243896, -0.2459726333618164, -0.7551835775375366, 0.5829344987869263, 0.8498332500457764, 1.319385051727295, -0.6869044303894043, 0.12812210619449615, -0.17311246693134308, -0.31232690811157227, -1.0624028444290161, -0.8166224956512451, -0.127360001206398, -0.2323206514120102, -0.35860493779182434, -0.24054192006587982, -0.46291035413742065, 0.2376301884651184, -0.5253136157989502, 0.9962953925132751, -0.36397239565849304, -0.6418647766113281, 0.5378593802452087, -0.15280631184577942, -0.25655654072761536, -0.6373481154441833, 0.03149442374706268, -0.24069131910800934, 0.03650989383459091, 0.04217350110411644, 0.3754030466079712, -0.5740682482719421, 0.5521056652069092, -0.5572828054428101, 0.1380729079246521, -0.011712423525750637, -0.03244911879301071, 1.214838981628418, -0.46542224287986755, 0.28671905398368835, -1.0909008979797363, 0.2948915660381317, -0.046782080084085464, -0.2319619059562683, 0.11899811774492264, -0.2141733318567276, -0.9707850813865662, 0.3641156256198883, -0.4887556731700897, 0.002690499182790518, -0.4898413419723511, 0.3975372016429901, -0.37604618072509766, -0.18784496188163757, -0.16859683394432068, 0.017548760399222374, 0.43856313824653625, 0.4576851725578308, 0.38989463448524475, 0.43781715631484985, -0.11755362898111343, 0.9664831757545471, -1.4112673997879028, 0.8968910574913025, -0.07861373573541641, 0.25605908036231995, 0.36598679423332214, 0.022617321461439133, -0.2556360065937042, -0.5106599926948547, -0.5318539142608643, -0.7827184200286865, -0.7399067282676697, 0.7671785950660706, -0.5523035526275635, -0.27997535467147827, -0.0014993022195994854, -1.3668794631958008, -0.07137788087129593, 0.38682860136032104, -0.5491354465484619, -0.4337821900844574, -1.0808019638061523, -1.0017768144607544, 0.1600794941186905, -0.4220447838306427, -1.1032236814498901, 0.2268785536289215, 0.25752362608909607, -0.14927934110164642, -0.5173967480659485, -0.08126780390739441, -0.14403796195983887, 0.9409727454185486, 0.0178806334733963, 0.8272363543510437, 0.20026983320713043, -0.9917337894439697, -0.5396541357040405, -0.448078989982605, 0.6492254734039307, -0.33623650670051575, 0.35073545575141907, -0.8365055918693542, 0.19139353930950165, -0.6369011402130127, -0.26536205410957336, 0.5588051676750183, 0.4472162425518036, 0.7651219964027405, 0.1773005872964859, -0.7402291297912598, 0.427965372800827, 1.7024364471435547, -0.7480486631393433, 0.4511813223361969, 0.47317996621131897, 0.871196985244751, 0.46952930092811584, -0.0005357407499104738, 0.49217110872268677, 0.4382443130016327, 0.07728838920593262, 0.5049690008163452, -0.06310569494962692, -0.5924308896064758, -1.0790740251541138, 0.41579461097717285, 1.215046763420105, 0.5127555727958679, -0.3704659342765808, -0.4513700604438782, 1.0570547580718994, -1.186586618423462, -0.7851085662841797, 0.7240486145019531, 0.2038891762495041, -0.39307254552841187, -0.43575507402420044, 0.23391126096248627, -0.5476245880126953, 0.8311144113540649, 0.6315804123878479, -0.6739699244499207, -0.22161827981472015, -0.04956895112991333, 0.0923052579164505, 0.14301139116287231, 0.38143840432167053, -0.35350659489631653, 0.5072100162506104, 14.475030899047852, 0.7018972039222717, 0.11372435092926025, 0.12029377371072769, 1.0837008953094482, 0.6885455250740051, -0.5482105612754822, -0.11013078689575195, -1.1664191484451294, -0.35641637444496155, 0.8782755136489868, 0.23638764023780823, 0.21634887158870697, 0.31463998556137085, 0.027515623718500137, 0.09118210524320602, -0.5364526510238647, 0.33924436569213867, 0.972382128238678, -1.5982165336608887, 0.7380801439285278, -0.1189919263124466, 0.282212495803833, 0.8790547251701355, 0.7791542410850525, 0.30903467535972595, 0.1795269101858139, -0.31773579120635986, 0.6363382935523987, 0.11594779789447784, 1.0428160429000854, 0.21333374083042145, 0.16010591387748718, -0.4201187491416931, -1.3778516054153442, -0.17302460968494415, -0.8715420365333557, -0.4932956099510193, 0.60345858335495, -0.19782879948616028, -0.49115604162216187, -0.1881376951932907, 0.3417745530605316, 1.4200944900512695, -0.2784031927585602, 0.7358243465423584, -0.3509595990180969, 0.3118487596511841, 0.09383808821439743, 0.11801818758249283, 0.37926194071769714, 0.5196406245231628, 0.3398318588733673, -0.11616433411836624, -0.0840127021074295, -0.15870937705039978, 0.2720390856266022, 0.39109715819358826, -0.7442343831062317, -0.03954872488975525, -0.35316476225852966, -0.0010996628552675247, 0.105680450797081, 0.7999711036682129, -0.38001748919487, 0.30783921480178833, -0.43838924169540405, 0.5619888305664062, 0.28103768825531006, 0.232209250330925, -0.44894859194755554, 0.32376471161842346, 0.2201046198606491, -0.06667495518922806, 0.6847500205039978, 0.5751760005950928, 0.0707908570766449, -0.16562530398368835, -0.5698684453964233, 0.07585953921079636, 0.5068419575691223, -1.0518888235092163, -1.049519658088684, 1.4112448692321777, -0.012597745284438133, -0.6407560110092163, 0.4229346811771393, -0.9390729665756226, -0.451911598443985, -0.03163198381662369, -1.6641802787780762, -0.7995766997337341, 0.1782567799091339, 0.022793184965848923, -0.3777703046798706, 0.30391886830329895, 1.0605800151824951, 0.4599093198776245, 0.20334330201148987, 0.18323193490505219, 0.014133931137621403, 0.48813098669052124, 0.27162405848503113, -0.7514469623565674, 0.9178453683853149, 0.19742581248283386, -0.06944654881954193, -0.5718349814414978, -0.11500867456197739, 0.09238076210021973, -0.09589692950248718, -0.5458929538726807, 0.18308670818805695, -0.6807235479354858, -0.2930232286453247, -0.42598140239715576, -0.7662751078605652, 0.29045379161834717, 0.6512349247932434, 0.24305781722068787, 0.43549349904060364, -0.39093440771102905, -0.9587857127189636, -0.40372905135154724, -1.2344969511032104, 0.007837049663066864, 0.45231884717941284, -0.39762306213378906, 0.27069151401519775, 0.09757398813962936, 1.0443845987319946, -0.6426663994789124, -0.33672380447387695, -0.392834335565567, 0.11415490508079529, -0.2848381996154785, 1.2896151542663574, -0.12492968887090683, 0.970558762550354, 0.3988024890422821, -0.35875827074050903, -0.6695541143417358, -0.09465306252241135, -0.8520916700363159, 0.5904466509819031, 0.2612787187099457, 0.8560473918914795, -0.11903765052556992, 0.5628598928451538, 0.48830267786979675, 0.48872801661491394, -0.6953091621398926, -0.2531726658344269, -0.022081002593040466, 0.1401461362838745, -0.6053317785263062, 0.15559415519237518, -0.4933851659297943, -0.5468036532402039, 0.19796861708164215, 0.434190958738327, 0.45435455441474915, 0.0886388048529625, -0.7545364499092102, 0.5100585222244263, 0.08252383023500443, -0.29006385803222656, -0.23242437839508057, -0.7835110425949097, -1.645695447921753, -0.2521823048591614, -1.2434239387512207, 0.11910678446292877, -1.1864070892333984, -0.200987309217453, 0.2349797785282135, -0.09939943999052048, -0.1572141945362091, 0.5810208320617676, 0.26114997267723083, 0.1432482749223709, -0.7596558928489685, -0.8080673813819885, 0.8276391625404358, 1.8050916194915771, -0.6962369084358215, 0.30582094192504883, -0.23209704458713531, 0.013104194775223732, 0.5225211381912231, 0.23744730651378632, -0.13724103569984436, -0.847888171672821, -1.1186870336532593, 0.3907221853733063, -0.2653822898864746, 0.25959011912345886, -1.0204459428787231, 0.6792294979095459, 0.7211939096450806, 0.2468387931585312, -0.5012691617012024, 0.47108399868011475, -0.8315421938896179, -0.8577272295951843, -0.03275759518146515, -0.825817883014679, 0.36153972148895264, 0.16583210229873657, 0.2753845453262329, -0.4154023230075836, 1.0600662231445312, 0.3844701945781708, -1.298596739768982, -1.1392133235931396, 0.7027884125709534, -0.21747465431690216, 0.1462949812412262, -0.23435282707214355, -0.11390925943851471, -1.2611901760101318, -0.6673440337181091, -0.3039350211620331, 0.48788055777549744, -0.35734987258911133, 1.2664865255355835, 0.8196465969085693, -1.1847107410430908, -0.22609548270702362, 0.059401173144578934, -0.014690703712403774, 0.6117560267448425, 0.6983757019042969, 0.31087809801101685, -0.41677558422088623, 0.16160856187343597, 0.0012855370296165347, 0.3107348382472992, -0.5525155067443848, 0.1861899346113205, 0.9112349152565002, -0.28645193576812744, -0.39006906747817993, 1.224220871925354, -0.23221422731876373, -0.746529221534729, 0.16751205921173096, -0.8097038269042969, -0.8958011865615845, 0.044718071818351746, 0.8179558515548706, -0.07399248331785202, -0.5779270529747009, -0.20548076927661896, -0.5224042534828186, 0.5643309950828552, -0.6015028953552246, -0.6209896802902222, 0.5794454216957092, -0.3101026117801666, -0.7956447005271912, 0.004021678119897842, 0.9132068753242493, -0.8746093511581421, -0.9327700734138489, -0.898221492767334, -0.8102508187294006, -0.5209422707557678, -0.29292768239974976, -0.707466185092926, -0.7329833507537842, 0.5811219215393066, 0.3050262928009033, 0.16298310458660126, 0.24521827697753906, 0.4502447247505188, 0.7740427255630493, 0.20776914060115814, 0.03529629856348038, -0.4557996392250061, 0.32807451486587524, 0.7679529786109924, 1.3851585388183594, -0.3084341883659363, 0.07915325462818146, -0.36511555314064026, -0.673922598361969, 1.015984296798706, 0.5698346495628357, -0.40711042284965515, 1.1896787881851196, -0.2664121091365814, 0.11812563985586166, 0.5139303803443909, -1.0136960744857788, -0.009292078204452991, 0.6826110482215881, 1.690709114074707, 0.16422133147716522, 0.3549955487251282, 0.29086998105049133, 0.5305039882659912, 0.22056564688682556, 0.004417668096721172, 0.9425578713417053, -0.17058143019676208, -0.3660773038864136, -0.4551679193973541, -0.09446509182453156, 0.5292210578918457, -0.5379016995429993, -0.21971014142036438, -0.12010545283555984, 0.35987070202827454, 0.12015809863805771, 0.5298168659210205, 1.0438967943191528, 0.008950176648795605, 0.4297111928462982, -0.07822329550981522, 0.5559642314910889, -0.5393518209457397, 0.39400234818458557, -0.048768676817417145, -0.8687121272087097, -0.29610174894332886, -0.8676975965499878, -0.8527408242225647, -0.5472253561019897, -0.22133372724056244, 0.5671154260635376, -0.3829502761363983, 0.14564040303230286, 0.844109833240509, 0.6659582257270813, 0.7158944606781006, -0.1825781613588333, -0.6896876096725464, 0.17138928174972534, -0.6927260756492615, 0.3879925310611725, -0.5401369333267212, -0.2874072194099426, -0.19631299376487732, -0.06990255415439606, 0.028339808806777]}, "authors": [{"authorId": "2161655780", "name": "Yiwei Ma"}, {"authorId": "2258718943", "name": "Jiayi Ji"}, {"authorId": "2227806539", "name": "Xiaoshuai Sun"}, {"authorId": "2110191063", "name": "Yiyi Zhou"}, {"authorId": "2304451367", "name": "Xiaopeng Hong"}, {"authorId": "47096329", "name": "Yongjian Wu"}, {"authorId": "2232781359", "name": "Rongrong Ji"}], "references": [{"paperId": "e417617c807e94dc4fb941ee7024703bf5ed0a24", "title": "Rotated Multi-Scale Interaction Network for Referring Remote Sensing Image Segmentation"}, {"paperId": "e44d333323b2cce56cb50a0ee09a481f34f67fae", "title": "Semi-Supervised Panoptic Narrative Grounding"}, {"paperId": "8eebe8a067a267b8b3a975b6db6b2e6e9ad44bab", "title": "Beat: Bi-directional One-to-Many Embedding Alignment for Text-based Person Retrieval"}, {"paperId": "1c509635c1c01e31c6d6e1c493d70ed0b1e8218d", "title": "3D-STMN: Dependency-Driven Superpoint-Text Matching Network for End-to-End 3D Referring Expression Segmentation"}, {"paperId": "d44c82f534bb3f47d81d41084f870ef2e1efdbe9", "title": "Beyond First Impressions: Integrating Joint Multi-modal Cues for Comprehensive 3D Representation"}, {"paperId": "0445dec0464fcbd85c6cefa5da87e82d49460fb3", "title": "Towards Local Visual Modeling for Image Captioning"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "70feb009bc1e8b1cb8dff64bf9fd67789636438b", "title": "From Images to Textual Prompts: Zero-shot Visual Question Answering with Frozen Large Language Models"}, {"paperId": "a6a59c9e4cd446d0d04f76587699e3e8ab5197c2", "title": "Semantic-Conditional Diffusion Networks for Image Captioning*"}, {"paperId": "d13f52cbff1416d11986f996fa68ee9767844c60", "title": "Uncertainty-Aware Image Captioning"}, {"paperId": "26fd105d0b5a458979c012cddb3ba2de943388c4", "title": "Plug-and-Play VQA: Zero-shot VQA by Conjoining Large Pretrained Models with Zero Training"}, {"paperId": "1ec886e2235763b08fa606a5d5ea3f4540f715ec", "title": "X-CLIP: End-to-End Multi-grained Contrastive Learning for Video-Text Retrieval"}, {"paperId": "b4fd191d74c1f37cb471b4ea517bfe518186c470", "title": "S2 Transformer for Image Captioning"}, {"paperId": "95a03fd44f01d71bc2299d2fcec1778c9d8f27bd", "title": "Adaptive Semantic-Enhanced Transformer for Image Captioning"}, {"paperId": "5c23faef38790a279109b22b9f5d404448a7b91c", "title": "Knowing What to Learn: A Metric-Oriented Focal Mechanism for Image Captioning"}, {"paperId": "a8fd9c1625011741f74401ff9bdc1c584e25c86d", "title": "Language Models are General-Purpose Interfaces"}, {"paperId": "afc6c4f3e387e3136a4b46cdfc48c0ce3d23cb55", "title": "DeeCap: Dynamic Early Exiting for Efficient Image Captioning"}, {"paperId": "7f71875f8214dffa4f3276da123c4990a6d437cc", "title": "Enabling Multimodal Generation on CLIP via Vision-Language Knowledge Distillation"}, {"paperId": "b00da02e88a857970d89cd8e69fa77710d03bbfe", "title": "Region-Object Relation-Aware Dense Captioning via Transformer."}, {"paperId": "1bfa62ddfa3f6691e0e40c06f8ead594b6449cfa", "title": "OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "3ea60cbce6c9065661d207fccf021c5d58a83f01", "title": "Scaling Up Vision-Language Pretraining for Image Captioning"}, {"paperId": "32d59ab951be74be351f9777da2cbc71bb68c3c1", "title": "A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models"}, {"paperId": "da74a10824193be9d3889ce0d6ed4c6f8ee48b9e", "title": "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer"}, {"paperId": "af68be45c5e6516100bcd03df9e0405c828cc031", "title": "TRAR: Routing the Attention Spans in Transformer for Visual Question Answering"}, {"paperId": "485c08025157973bb52a935c6aa3bee74f990c01", "title": "Sparse MLP for Image Recognition: Is Self-Attention Really Necessary?"}, {"paperId": "5e00596fa946670d894b1bdaeff5a98e3867ef13", "title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision"}, {"paperId": "8f167ec1149921fac63b1ea855443de109bb013a", "title": "How Much Can CLIP Benefit Vision-and-Language Tasks?"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "01b5412f3d17e90e09226d7c40ad4d4468a1414d", "title": "Multimodal Few-Shot Learning with Frozen Language Models"}, {"paperId": "57689aa1290370702c618713fd8d9202f2d697fe", "title": "TCIC: Theme Concepts Learning Cross Language and Vision for Image Captioning"}, {"paperId": "1e1cb3a5d3d8b80c2a523189246f711686dda669", "title": "Semi-Autoregressive Transformer for Image Captioning"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "46ec4cdec85d95d6253a17feccb5cf59d5861c92", "title": "Aligning Pretraining for Detection via Object-Level Contrastive Learning"}, {"paperId": "afa76fedf8701e057b2bf7a228bf41980ac2d1c9", "title": "RSTNet: Captioning with Adaptive Attention on Visual and Non-Visual Words"}, {"paperId": "63c74d15940af1af9b386b5762e4445e54c73719", "title": "VinVL: Revisiting Visual Representations in Vision-Language Models"}, {"paperId": "5faf75b5c5a4d83bd6407b4aba8fb0bccd7fa31d", "title": "Conformer: Local Features Coupling Global Representations for Visual Recognition"}, {"paperId": "7cda4cc432db2797758d8fd1f2c4703523fd36d0", "title": "Revisiting Dynamic Convolution via Matrix Decomposition"}, {"paperId": "a11676f2864b2d923bb9facc9f6548c812f9e005", "title": "M6: A Chinese Multimodal Pretrainer"}, {"paperId": "cb596bffc5c5042c254058b62317a57fa156fea4", "title": "Unifying Vision-and-Language Tasks via Text Generation"}, {"paperId": "ae7e5a4de962ca4face3bb52b36dfd09db5451d8", "title": "Dual-Level Collaborative Transformer for Image Captioning"}, {"paperId": "c0fa1d7f5ce0fb1520b6a1e469344517ee3c7660", "title": "Auto-Encoding and Distilling Scene Graphs for Image Captioning"}, {"paperId": "92bfff765aa53bde67bebfa006c2e17dbd6b4cf0", "title": "Dynamic feature pyramid networks for object detection"}, {"paperId": "f0edc8eb2d2b53482faf34906dacf996bc4127f6", "title": "Fine-Grained Image Captioning With Global-Local Discriminative Objective"}, {"paperId": "b6473852e19ebb31161b2f62d53912b431231fa5", "title": "Compare and Reweight: Distinctive Image Captioning Using Similar Images Sets"}, {"paperId": "89461319475a12229c72efa0c3517cc4f5931834", "title": "ELF: An Early-Exiting Framework for Long-Tailed Classification"}, {"paperId": "4817764dadf8a3c41c41a8f6ae85a269cc8bb63c", "title": "Parallel processing streams in the hippocampus"}, {"paperId": "b9637ae1fbb8aebc8deb6e3c15dd93839e327e1c", "title": "Non-Autoregressive Image Captioning with Counterfactuals-Critical Multi-Agent Learning"}, {"paperId": "34f88266b8cc7f00061b988628277c9bd5bad5e7", "title": "DyNet: Dynamic Convolution for Accelerating Convolutional Neural Networks"}, {"paperId": "b5ef0f91663f0cbd6910dec9a890c138f7ec10e0", "title": "Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks"}, {"paperId": "4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0", "title": "X-Linear Attention Networks for Image Captioning"}, {"paperId": "0e3be473c72d9449d13dace5c9c21d9310163630", "title": "Dynamic Region-Aware Convolution"}, {"paperId": "69295a3a3be7a00116c43142beae9023020f3c6d", "title": "Learning Dynamic Routing for Semantic Segmentation"}, {"paperId": "a6be0ce5af23feabe24be9cd270003f84adc49d3", "title": "Resolution Adaptive Networks for Efficient Inference"}, {"paperId": "ff5a1ec81f327b711a5433e4cd40467215a13f39", "title": "Image Captioning With End-to-End Attribute Detection and Subsequent Attributes Prediction"}, {"paperId": "c3afcd7e57c3e04b03b0b5001a3854482fa39441", "title": "In Defense of Grid Features for Visual Question Answering"}, {"paperId": "fc9c52f55ffe0e860b1bb4222fe86cce60c05551", "title": "Meshed-Memory Transformer for Image Captioning"}, {"paperId": "fb7972f30812c7dd056d7943c3e3f00af022d607", "title": "Dynamic Convolution: Attention Over Convolution Kernels"}, {"paperId": "7c4530882cfcef1d2b4aa2996f494dfac626b5d9", "title": "Entangled Transformer for Image Captioning"}, {"paperId": "6648b4db5f12c30941ea78c695e77aded19672bb", "title": "Unified Vision-Language Pre-Training for Image Captioning and VQA"}, {"paperId": "4c163d4942117179d3e97182e1b280027d7d60a9", "title": "Attention on Attention for Image Captioning"}, {"paperId": "b499228aa74b59be32711c3926e44de208d6b636", "title": "Image Captioning: Transforming Objects into Words"}, {"paperId": "e71cd563f3e97f58803e2c871a8ab179994cc23e", "title": "Mimic and Fool: A Task-Agnostic Adversarial Attack"}, {"paperId": "d0134f63879cedf3cdfe795bd2fd7c48d9554e4a", "title": "Context-Aware Visual Policy Network for Fine-Grained Image Captioning"}, {"paperId": "8a1744da011375d711ed75fc2d160c6fdca2cf89", "title": "Deep Modular Co-Attention Networks for Visual Question Answering"}, {"paperId": "d4d77495c9d1e6ae4480f330c4fda80121452c63", "title": "Topic-Oriented Image Captioning Based on Order-Embedding"}, {"paperId": "3e70bbe6c4cd98d66599db709e32b748f184a2d4", "title": "CondConv: Conditionally Parameterized Convolutions for Efficient Inference"}, {"paperId": "aaa5625e0dbd9119b54dbb9c3840efd1199a071f", "title": "Multitask Learning for Cross-Domain Image Captioning"}, {"paperId": "eb28671c43e6f3bfeee3b5bec8023887d8c07bc7", "title": "Towards Personalized Image Captioning via Multimodal Memory Networks"}, {"paperId": "bc73f0f7d895a089416bc8f6090f3f8707c6a12f", "title": "Know More Say Less: Image Captioning Based on Scene Graphs"}, {"paperId": "f6feb1af1809dfd872d868dfcc13021cc42f496c", "title": "Auto-Encoding Scene Graphs for Image Captioning"}, {"paperId": "4dea9cce0825c0cdb1a4a28c4ab8416d6e3e047c", "title": "Attentive Linear Transformation for Image Captioning"}, {"paperId": "0000fcfd467a19cf0e59169c2f07d730a0f3a8b9", "title": "Exploring Visual Relationship for Image Captioning"}, {"paperId": "04cd9168dcf1a0d2cf01db95a1af53d0900bc346", "title": "Recurrent Fusion Network for Image Captioning"}, {"paperId": "a5d10341717c0519cf63151b496a6d2ed67aa05f", "title": "Bilinear Attention Networks"}, {"paperId": "0daa3a4118e00b9f63b2d014a16ff1bc3ca9ff7e", "title": "Improving Image Captioning with Conditional Generative Adversarial Nets"}, {"paperId": "7c1802d8d43dfe783650a03f03d41609fa5ae91e", "title": "Discriminability Objective for Training Descriptive Captions"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "7f14e73dade94b8b1f276dcd91257aa7de5f19d7", "title": "Stack-Captioning: Coarse-to-Fine Learning for Image Captioning"}, {"paperId": "0c0f41d3162e76500d4639557ff4463bd246e395", "title": "Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering"}, {"paperId": "b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81", "title": "Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge"}, {"paperId": "8e9ad6f8b2bc97f0412fa0cc243ac6975864534a", "title": "Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual Question Answering"}, {"paperId": "a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8", "title": "Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "125ccd810f43f1cba83c6681836d000f83d1886d", "title": "Multi-Scale Dense Networks for Resource Efficient Image Classification"}, {"paperId": "9f4d7d622d1f7319cc511bfef661cd973e881a4c", "title": "Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning"}, {"paperId": "6c8353697cdbb98dfba4f493875778c4286d3e3a", "title": "Self-Critical Sequence Training for Image Captioning"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "5785466bc14529e94e54baa4ed051f7037f3b1d3", "title": "Boosting Image Captioning with Attributes"}, {"paperId": "29e944711a354c396fad71936f536e83025b6ce0", "title": "Categorical Reparameterization with Gumbel-Softmax"}, {"paperId": "f90d9c5615f4a0e3f9a1ce2a0075269b9bab6b5f", "title": "SPICE: Semantic Propositional Image Caption Evaluation"}, {"paperId": "bf55591e09b58ea9ce8d66110d6d3000ee804bdd", "title": "Image Captioning with Semantic Attention"}, {"paperId": "c3640aae13e344ad70a926510221dada626a44de", "title": "Guiding the Long-Short Term Memory Model for Image Caption Generation"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "3ca194773fe583661b988fbdf33f7680764438b3", "title": "Exploring Nearest Neighbor Approaches for Image Captioning"}, {"paperId": "4d8f2d14af5991d4f0d050d22216825cac3157bd", "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745", "title": "Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)"}, {"paperId": "55e022fb7581bb9e1fce678d21fb25ffbb3fbb88", "title": "Deep visual-semantic alignments for generating image descriptions"}, {"paperId": "258986132bf17755fe8263e42429fe73218c1534", "title": "CIDEr: Consensus-based image description evaluation"}, {"paperId": "f01fc808592ea7c473a69a6e7484040a435f36d9", "title": "Long-term recurrent convolutional networks for visual recognition and description"}, {"paperId": "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0", "title": "Show and tell: A neural image caption generator"}, {"paperId": "7f1b111f0bb703b0bd97aba505728a9b0d9b2a54", "title": "Deep Fragment Embeddings for Bidirectional Image Sentence Mapping"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "44040913380206991b1991daf1192942e038fe31", "title": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions"}, {"paperId": "3f6a4556769e819242d669d073b895f1e45a706f", "title": "Image Description using Visual Dependency Representations"}, {"paperId": "9814df8bd00ba999c4d1e305a7e9bca579dc7c75", "title": "Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics"}, {"paperId": "355de7460120ddc1150d9ce3756f9848983f7ff4", "title": "Midge: Generating Image Descriptions From Computer Vision Detections"}, {"paperId": "bbf1d8ab7c85fd396a55f7e5faa966c456d4cf3e", "title": "Simple line drawings suffice for functional MRI decoding of natural scene categories"}, {"paperId": "a538b05ebb01a40323997629e171c91aa28b8e2f", "title": "Rectified Linear Units Improve Restricted Boltzmann Machines"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "1edae41a9160bba694ca2e72d0256d894a54a787", "title": "Memory-Based Augmentation Network for Video Captioning"}, {"paperId": "c3dd958431836616baf4adda22ecb1507f7d5e98", "title": "Knowing What it is: Semantic-Enhanced Dual Attention Transformer"}, {"paperId": "009a7c54668db7884b51f12492e73daf32b45cf4", "title": "A Text-Guided Generation and Refinement Model for Image Captioning"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}]}