{"paperId": "35bc74de55f2cd3ee6aaa6a6bea94419111c0c0d", "abstract": "The Transformer architecture has become prominent in developing large causal language models. However, mechanisms to explain its capabilities are not well understood. Focused on the training process, here we establish a meta-learning view of the Transformer architecture when trained for the causal language modeling task, by explicating an inner optimization process within the Transformer. Further, within the inner optimization, we discover and theoretically analyze a special characteristic of the norms of learned token representations within Transformer-based causal language models. Our analysis is supported by experiments in various settings.", "venue": "arXiv.org", "year": 2023, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2310.05884", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "A meta-learning view of the Transformer architecture when trained for the causal language modeling task is established by explicating an inner optimization process within the Transformer, and a special characteristic of the norms of learned token representations within Transformer-based causal language models is discovered."}, "embedding": {"model": "specter_v2", "vector": [-0.07318707555532455, 1.047143816947937, -0.5165121555328369, -0.008112611249089241, -0.4675753116607666, -0.01563400961458683, 1.0914932489395142, -0.16288667917251587, -0.3104805052280426, 0.0065117934718728065, 0.795448899269104, -0.45478665828704834, 0.09746105223894119, -0.04135466739535332, -0.44012871384620667, -0.26208075881004333, -0.867153525352478, 0.11506642401218414, -0.24784572422504425, 0.010430706664919853, -0.3657872974872589, -0.5563651919364929, -0.7913146018981934, 0.476599782705307, 0.34920474886894226, 0.15077684819698334, 0.23127904534339905, 0.4713298976421356, -0.499772310256958, 0.8936724066734314, 0.6354002356529236, -0.8556405305862427, 0.49754399061203003, 0.03620358183979988, -0.6382673382759094, -0.29465147852897644, 0.3307461142539978, -0.4233201742172241, -1.1996556520462036, 0.8028658628463745, -0.5367245078086853, -0.021034764125943184, 0.5654228329658508, -0.9298296570777893, -0.2378566712141037, 1.5804383754730225, 0.7261829376220703, 0.8577939867973328, -0.35833701491355896, -0.6912254691123962, 1.7512701749801636, -0.9319732189178467, 0.11608999967575073, 1.6022675037384033, 0.18562673032283783, 0.47486579418182373, -0.11183901876211166, -0.7677651643753052, 0.558552622795105, 0.43107253313064575, -0.6950417160987854, -0.2282595932483673, -0.34968358278274536, -0.23197509348392487, 1.562204360961914, -0.6783536672592163, -0.16280299425125122, 0.7961212992668152, -0.02480887807905674, 1.7195178270339966, 0.28354912996292114, -0.5627303123474121, -0.4556158483028412, 0.3826338052749634, -0.1487698256969452, 0.9245479702949524, -0.35192352533340454, 0.7707564234733582, -1.0886054039001465, -0.239349827170372, 0.7705066204071045, -0.40793687105178833, -0.0901499092578888, -0.0347796194255352, -0.38179832696914673, 0.6977348923683167, 0.3330397605895996, 1.1985160112380981, -0.2968648076057434, 1.004249930381775, 0.7318558096885681, 0.5974467396736145, -0.2609185576438904, 0.3800700902938843, -0.0621604286134243, 0.34754833579063416, -0.5496296286582947, 0.16535674035549164, 0.060823939740657806, 0.43023762106895447, -0.30826711654663086, 0.699051022529602, -0.9621610641479492, 0.2376558631658554, 1.6549021005630493, -0.0014049408491700888, 0.49480390548706055, -0.9237391948699951, 0.48249608278274536, -0.6158365607261658, 0.3476254940032959, -0.4778504967689514, 0.08545457571744919, -0.3379209637641907, -0.5708608627319336, -1.4982270002365112, 0.032214220613241196, 0.4196506440639496, -0.5508384108543396, 0.8995047211647034, -0.5712593197822571, 0.2821796238422394, 0.030039213597774506, 0.23997950553894043, 0.0014467148575931787, 0.6709476113319397, 0.49196740984916687, -0.455966979265213, 0.4899881184101105, -0.23785702884197235, -0.833579421043396, -0.8689622282981873, 0.7413354516029358, -0.00865083560347557, 0.24258312582969666, -0.2550184428691864, -1.25229811668396, -0.8503587245941162, -0.6963450908660889, 0.3643559217453003, -0.080544613301754, 0.06942148506641388, 1.4022334814071655, 0.5636942386627197, -0.6961023807525635, 1.0243159532546997, -0.20985004305839539, 0.011508255265653133, 0.539056658744812, -0.07984056323766708, -0.023887407034635544, -0.12269828468561172, -1.5557842254638672, 0.7158818244934082, 0.5532021522521973, -0.5581430792808533, -0.9721589088439941, -0.8384720087051392, -1.2416049242019653, -0.11664878576993942, 0.30442190170288086, -0.5066864490509033, 1.412845492362976, -0.016921348869800568, -1.181261658668518, 0.41990166902542114, -0.47548750042915344, -0.06308124959468842, 0.48629194498062134, -0.25980332493782043, -0.36470961570739746, -0.45449328422546387, 0.3776771128177643, -0.04353344440460205, 0.30444443225860596, -0.8977583646774292, -0.44937580823898315, -0.04249682277441025, -0.2999349534511566, -0.3207210600376129, -0.1688799113035202, 0.6065642237663269, 0.05461250990629196, -0.3087577819824219, -0.22182077169418335, 1.1730278730392456, -0.18165245652198792, -0.6035341024398804, -0.5733259320259094, -1.361396312713623, 0.18567481637001038, -0.11325203627347946, 1.113649845123291, -0.6808695793151855, -0.6955035924911499, 0.03586336970329285, -0.3477442264556885, -0.19621160626411438, -0.6228766441345215, 0.740186333656311, -0.6406102180480957, 0.5194047093391418, -0.1349346935749054, -0.8699237704277039, 0.05977153405547142, 0.08592632412910461, -1.2087324857711792, -0.15804198384284973, -0.11879993975162506, 0.7884079217910767, -1.0836318731307983, -0.04576723277568817, 0.41513127088546753, -0.007114392705261707, -0.7820193767547607, 1.6050093173980713, -0.060234323143959045, 0.06958168745040894, -0.18052630126476288, -0.754954993724823, -0.3310033679008484, -0.008282321505248547, 0.376666784286499, -0.5586441159248352, -0.312325656414032, 0.7248887419700623, -0.5592610836029053, 1.204736351966858, -0.6212012767791748, 0.40800419449806213, -0.28919318318367004, -1.0592806339263916, -0.1451953947544098, 1.0360803604125977, 0.06718933582305908, -0.5078324675559998, 0.3634868860244751, 0.37566807866096497, -0.5558469295501709, -0.162679523229599, 0.4068897068500519, 0.20460689067840576, 0.010513205081224442, 0.512726902961731, 0.5941845774650574, -0.17208999395370483, 0.6260685324668884, 0.4804859459400177, 0.7218273878097534, 0.13798676431179047, 0.3835735619068146, -0.04238441586494446, 0.2333621233701706, -0.8429206609725952, 0.02744736336171627, 0.7567861080169678, 0.8347077965736389, 0.2235611230134964, 0.6156399846076965, -0.37372148036956787, -0.5102543234825134, -0.6083597540855408, 0.2106345295906067, 1.1932986974716187, -0.48648199439048767, -0.7804702520370483, -0.521308183670044, -0.19704779982566833, -0.1902463287115097, 0.9906690120697021, -0.52702397108078, -0.3966866135597229, -0.6176872253417969, -1.0276259183883667, 1.1835612058639526, 0.4517514109611511, 0.9119000434875488, -0.4724974036216736, -0.020466646179556847, -0.1502462476491928, 0.21050924062728882, -0.5221217274665833, -0.1987956315279007, 0.3215846121311188, -0.6516490578651428, -0.39929455518722534, 0.3708363175392151, 0.34953686594963074, -0.05992797389626503, -0.7651153206825256, 0.4537048935890198, -0.49899032711982727, -0.3265322744846344, 0.4538133442401886, 0.7836592197418213, -0.6848950386047363, -1.0985676050186157, -0.3108538091182709, -0.026756539940834045, -0.19274558126926422, 0.0009701221133582294, 0.5195773243904114, 0.36075159907341003, -0.08512496948242188, -0.4301464557647705, 0.1466948539018631, 0.17048241198062897, 0.4241613447666168, 0.14855529367923737, 0.2950713038444519, -0.17964088916778564, -1.2396193742752075, 0.8818551898002625, 0.02133701927959919, -0.34049567580223083, 0.3003833591938019, -0.7821654677391052, -0.16444474458694458, 0.44976890087127686, -0.3779720962047577, -0.7640236020088196, -1.0944569110870361, 0.5398706793785095, 0.023094220086932182, -0.2529696524143219, 0.40062466263771057, 0.14764092862606049, 0.45950645208358765, 0.17091292142868042, 0.37760716676712036, 0.16662314534187317, -0.13082964718341827, 0.7854433059692383, -0.9301276206970215, 0.42149701714515686, -0.06238396465778351, 0.7716425061225891, 0.05790681391954422, -0.24407529830932617, -0.6512101888656616, -0.7305469512939453, -0.21976551413536072, -0.19194357097148895, -0.25086095929145813, 0.15708987414836884, -0.5274458527565002, -0.9928430318832397, 0.05901271477341652, -1.101225733757019, -0.5434622764587402, 0.1287691742181778, -0.10345398634672165, -0.23034198582172394, -1.0863828659057617, -1.601707100868225, -0.7636173367500305, 0.0643865242600441, -0.8813592791557312, 0.048781391233205795, -0.2686425447463989, -0.12779197096824646, -0.9290451407432556, -0.22124435007572174, -0.1250612884759903, 0.8468210697174072, -0.8918351531028748, 1.3232725858688354, 0.09132267534732819, -0.5034732222557068, 0.2928575873374939, 0.20825421810150146, 0.4519270062446594, -0.18687021732330322, 0.1599086970090866, -1.0625898838043213, 0.1799623966217041, -0.09606828540563583, -0.3495391011238098, 0.05422702431678772, 0.2720993161201477, 0.9079111218452454, -0.05839203670620918, -0.6608710885047913, 0.19143830239772797, 1.3919892311096191, -0.38300246000289917, 0.22099775075912476, 0.29727277159690857, 1.2188602685928345, 0.5800513029098511, -0.17554868757724762, 0.4905364215373993, 0.5436640381813049, 0.28545665740966797, 0.15655705332756042, -0.10094161331653595, 0.32519733905792236, -0.9579403400421143, 0.7190024256706238, 1.3610631227493286, 0.03780851513147354, 0.21347345411777496, -0.9948380589485168, 0.6599921584129333, -1.2932838201522827, -1.161316990852356, 0.5786886811256409, 0.9682652354240417, 0.4480195939540863, -0.46067363023757935, -0.590558648109436, 0.32831984758377075, 0.2527191936969757, 0.38080307841300964, 0.04628443717956543, -0.2794037163257599, 0.2785820960998535, 0.661335289478302, 0.41712602972984314, 0.6646158695220947, -0.24056746065616608, 0.5833058953285217, 14.665185928344727, 0.8014119267463684, 0.18612101674079895, 0.8036105632781982, 0.25781598687171936, 0.5237807035446167, -0.7886762619018555, -0.05226949229836464, -0.844508171081543, -0.5437711477279663, 1.1861906051635742, -0.2691013813018799, 0.7468505501747131, -0.18717554211616516, 0.33499717712402344, -0.07747922837734222, -0.5482822060585022, 0.48817166686058044, 0.18599607050418854, -1.4164029359817505, 1.126024842262268, 0.3123650848865509, 0.19412022829055786, 0.26619863510131836, 0.645609438419342, 0.563414990901947, 0.7604349255561829, -0.7527063488960266, 0.7984436750411987, -0.25997066497802734, 0.7607822418212891, -0.26833075284957886, 0.43627649545669556, 0.3662593364715576, -1.101077675819397, -0.44619515538215637, -0.6454721689224243, -0.9015096426010132, 0.21100209653377533, 0.2639746069908142, -0.5211789608001709, -0.3075316846370697, -0.2676379978656769, 0.9562783241271973, 0.2957199811935425, 0.12539617717266083, -0.7728374004364014, 1.0979708433151245, 0.36654528975486755, 0.7072376608848572, 0.18999487161636353, 0.682543158531189, 0.10681214928627014, -0.09044820815324783, 0.19480279088020325, -0.013050231151282787, -0.07423126697540283, 0.5455180406570435, -0.30685165524482727, 0.15338845551013947, -0.7722451090812683, -0.5676813721656799, 0.21338222920894623, 0.6662338376045227, 0.8261862397193909, 0.3549957573413849, -0.11017892509698868, -0.11241596192121506, 0.6636926531791687, 0.10992620885372162, -0.25138354301452637, 0.13631772994995117, 0.5108169317245483, -0.20846866071224213, -0.371451199054718, 0.5867668390274048, -0.3474089503288269, -0.5085351467132568, -1.0201624631881714, -0.19860704243183136, 0.602278470993042, -0.8030888438224792, -0.9978060722351074, 0.5554187893867493, 0.2732408940792084, -0.11602971702814102, 0.45169734954833984, -0.9717689752578735, -0.593441903591156, -0.033334314823150635, -1.0601096153259277, -0.6766713857650757, 0.5049429535865784, 0.4413098990917206, -0.5191725492477417, -0.15134494006633759, 1.1008535623550415, 0.08027913421392441, -0.5957604646682739, 0.11076381057500839, 0.07116885483264923, 0.25305455923080444, -0.10506581515073776, -1.3290640115737915, 0.42520657181739807, 0.14301234483718872, 0.2388664186000824, 0.8682695031166077, 0.1916842758655548, 0.23784483969211578, -0.787092924118042, -0.07215313613414764, 1.0726691484451294, -0.8071384429931641, 0.17077034711837769, -0.5033769607543945, -0.8646516799926758, 0.5162830352783203, 0.7515197396278381, -0.6777822971343994, 0.3620849549770355, 0.1409626603126526, -0.768092155456543, -0.2834829092025757, -0.617914617061615, 0.1661125272512436, 0.6568377614021301, -0.9920695424079895, -0.8537607789039612, -0.04265611246228218, -0.01813599281013012, -0.6247326731681824, -0.5311143398284912, -0.4563145637512207, -0.31636667251586914, -0.14958935976028442, 0.7966310977935791, -0.6202344298362732, 0.6065677404403687, 0.46448057889938354, 0.11501388251781464, -1.2740415334701538, -0.41644030809402466, -0.8952098488807678, 0.6698286533355713, 0.5184693932533264, 0.7501949667930603, -0.5056021809577942, -0.36369720101356506, 0.6318528056144714, 0.06629686802625656, 0.10250210762023926, -0.9734751582145691, -0.04305568337440491, 0.13311462104320526, -1.0250216722488403, 0.03202072158455849, 0.0374218188226223, 0.13580016791820526, -0.004281109198927879, 0.3537387251853943, 0.9249019026756287, 0.17841492593288422, -1.0542470216751099, 0.10891494154930115, 0.18828605115413666, 0.13773071765899658, -0.46063244342803955, -0.1606713980436325, -0.8915090560913086, 0.4864726960659027, -1.5998167991638184, 0.021582353860139847, -1.2602322101593018, -0.27730122208595276, 0.012998075224459171, -0.3156198561191559, 0.14280840754508972, 0.4089730978012085, -0.6810497045516968, -0.47816240787506104, -0.6288936734199524, 0.08307164162397385, 0.6368277072906494, 0.8388803005218506, -0.6495057344436646, 0.5142278671264648, -0.18597476184368134, 0.08589348942041397, 0.4112725555896759, 0.42315757274627686, -0.7244186997413635, -0.9235357046127319, -1.2599841356277466, 0.3396044969558716, -0.08729597181081772, 0.16344930231571198, -0.011325428262352943, 0.5132587552070618, 0.09589628875255585, -0.22531509399414062, 0.5889910459518433, 0.03527708351612091, -0.9194884300231934, -0.19746103882789612, 0.46073511242866516, -0.9690362215042114, 0.039640624076128006, -0.06156139820814133, -0.4057634770870209, -0.5181666612625122, 0.5794837474822998, 0.14260496199131012, -1.2216886281967163, -0.29805493354797363, 0.46519917249679565, -0.9767658710479736, 0.3592315912246704, 0.03285782039165497, 0.0986320972442627, -0.9374343156814575, -0.10796349495649338, 0.2585463523864746, 0.24807626008987427, -0.5888791084289551, 0.9832565188407898, 0.46907734870910645, -1.2262309789657593, 0.13939021527767181, 0.12535446882247925, -0.02512560784816742, -0.3386870324611664, 0.1382722556591034, 0.20601898431777954, 0.13484779000282288, 0.5891090035438538, 0.17069466412067413, 0.604631245136261, -0.5058262944221497, -0.43639054894447327, 1.004642128944397, -0.5147296786308289, -0.26572462916374207, 1.0278784036636353, -0.015058553777635098, -0.8508609533309937, 0.3029996156692505, -0.9148922562599182, -0.8431132435798645, -0.4333065450191498, 0.7611575126647949, 0.3504416346549988, -0.7346680760383606, 0.08150672167539597, -0.014989049173891544, 0.11476007103919983, -0.007644068915396929, -0.6420168876647949, 0.5046921968460083, -0.03696340695023537, -0.7035912871360779, 1.2272040843963623, 0.3610759973526001, -0.667591392993927, -0.29125893115997314, -0.4961794316768646, -0.1909608095884323, -0.6412966847419739, 0.44138795137405396, -0.21755647659301758, -0.8248003721237183, 0.832777738571167, 0.2501526474952698, 0.3719635307788849, -0.5374230146408081, 0.009664741344749928, -0.08983694016933441, 0.24507971107959747, 0.40209802985191345, -0.6183288097381592, -0.384285569190979, 1.0719256401062012, 1.2804569005966187, -0.5693708062171936, 0.01599070616066456, -0.12696653604507446, -0.7103313207626343, 1.030409812927246, 0.443830668926239, 0.13621731102466583, 0.688182532787323, -0.0411568284034729, 0.15253376960754395, -0.03362034633755684, -1.3524627685546875, -0.15224039554595947, 0.46190309524536133, 1.1830415725708008, 1.061728596687317, 0.584152102470398, 0.16254554688930511, 0.8053973913192749, -0.11168880015611649, 0.22930848598480225, 0.8005373477935791, 0.08990723639726639, -0.11788466572761536, -0.4242296516895294, 0.10701330751180649, 0.7814644575119019, -0.933146059513092, -0.5375899076461792, 0.2616613209247589, 0.7272910475730896, 0.28593119978904724, 0.7057018280029297, 0.48366767168045044, 0.02560129016637802, 0.6226579546928406, 0.32240942120552063, 0.8272652626037598, -0.4969330132007599, -0.6205108761787415, -0.3857361376285553, -0.3323255181312561, -0.2933685779571533, -0.4896260201931, -0.41701632738113403, -0.5880447030067444, -0.24621637165546417, 0.27878886461257935, 0.5188262462615967, 0.08318935334682465, 1.4265174865722656, 0.029820246621966362, 0.27216315269470215, -0.2244604229927063, -0.07317452877759933, -0.4499509930610657, -1.0471843481063843, -0.09848227351903915, -0.39151591062545776, -0.42804619669914246, -0.4121258854866028, -0.4153912663459778, -0.1708664894104004]}, "authors": [{"authorId": "2257081521", "name": "Xinbo Wu"}, {"authorId": "1697944", "name": "L. Varshney"}], "references": [{"paperId": "ec6023c6af6087ae9ed76efff448e0f9dc0254cc", "title": "Why Larger Language Models Do In-context Learning Differently?"}, {"paperId": "c6bf5b971ddd0db1293f70f2a88b652199a56612", "title": "Transformer-based Causal Language Models Perform Clustering"}, {"paperId": "9bb3deca32af8d632e0d916c587cca6c185a6576", "title": "Uncovering mesa-optimization algorithms in Transformers"}, {"paperId": "bb26227a94ddb2b0088a23e2ec0a170c40bc4d78", "title": "Emergent Linear Representations in World Models of Self-Supervised Sequence Models"}, {"paperId": "f5e9337477d7a9eb6267d0310549fdefafbb7fe2", "title": "Transformers learn to implement preconditioned gradient descent for in-context learning"}, {"paperId": "51a0bba0c5fb4257e843040615bb23f712fed4e6", "title": "Summary of ChatGPT-Related Research and Perspective Towards the Future of Large Language Models"}, {"paperId": "154493f69d7db3d49da0e51df0192c6ad5f1724a", "title": "Larger language models do in-context learning differently"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "69c85405cc1986a41f6387d869aa1648a5668d6f", "title": "Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers"}, {"paperId": "525d93a382f6e7873b5d8a2e0713eb3dff7fb250", "title": "Transformers learn in-context by gradient descent"}, {"paperId": "71ba5f845bd22d42003675b7cea970ca9e590bcc", "title": "Editing Models with Task Arithmetic"}, {"paperId": "3097de4b5c82c69eb745e5eb54cef03addd32cc6", "title": "Transductive Decoupled Variational Inference for Few-Shot Classification"}, {"paperId": "491bbfc1cfda90c645d4db485be071a7feadd27c", "title": "Transformers as Meta-Learners for Implicit Neural Representations"}, {"paperId": "663662fbd9be73f99c764a7b85982bf825acfe8a", "title": "The Dual Form of Neural Networks Revisited: Connecting Test Time Predictions to Training Patterns via Spotlights of Attention"}, {"paperId": "996445d847f06e99b0bd259345408a0cf1bce87e", "title": "Locating and Editing Factual Associations in GPT"}, {"paperId": "6cc9484612ab146c9fed9f7dce283c815af3cbc8", "title": "Not All Models Localize Linguistic Knowledge in the Same Place: A Layer-wise Probing on BERToids\u2019 Representations"}, {"paperId": "4072a2333682941d23755e9b7e1e3a6d899683c6", "title": "Probing BERT in Hyperbolic Spaces"}, {"paperId": "5a7f3719decfa4eb4dfeed9af004a5e176db0987", "title": "Topic Modeling with Contextualized Word Representation Clusters"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "2b364917b0c51e91fcf2ab9c1d66a14ed4b44c03", "title": "BERTology Meets Biology: Interpreting Attention in Protein Language Models"}, {"paperId": "7f27e7bf9116ebeeeab1ef010fde5a4d6544ee14", "title": "Normalization"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "7be8c119dbe065c52125ee7716601751f3116844", "title": "Generalization through Memorization: Nearest Neighbor Language Models"}, {"paperId": "10eda4521c032adabaa8e70d6569e17370b29dcd", "title": "Root Mean Square Layer Normalization"}, {"paperId": "afd110eace912c2b273e64851c6b4df2658622eb", "title": "Visualizing and Measuring the Geometry of BERT"}, {"paperId": "97906df07855b029b7aae7c2a1c6c5e8df1d531c", "title": "BERT Rediscovers the Classical NLP Pipeline"}, {"paperId": "770538e506051da89f57f48062db8f374ebf2334", "title": "Meta-Curvature"}, {"paperId": "43c3bfffdcd313c549b2045980855ea001d6f13b", "title": "Numerical Optimization"}, {"paperId": "15561ab20c298e113b0008b7a029486a422e7ca3", "title": "Bilevel Programming for Hyperparameter Optimization and Meta-Learning"}, {"paperId": "c41516420ddbd0f29e010ca259a74c1fc2da0466", "title": "What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "c889d6f98e6d79b89c3a6adf8a921f88fa6ba518", "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"}, {"paperId": "29c887794eed2ca9462638ff853e6fe1ab91d5d8", "title": "Optimization as a Model for Few-Shot Learning"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "573277bf56dd1cd73f0bf27115f9a6a974c25358", "title": "A Kronecker-factored approximate Fisher matrix for convolution layers"}, {"paperId": "cb4dc7277d1c8c3bc76dd7425eb1cc7cbaf99487", "title": "Optimizing Neural Networks with Kronecker-factored Approximate Curvature"}, {"paperId": "d6f2f611da110b5b5061731be3fc4c7f45d8ee23", "title": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification"}, {"paperId": "5d833331b0e22ff359db05c62a8bca18c4f04b68", "title": "One billion word benchmark for measuring progress in statistical language modeling"}, {"paperId": "168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74", "title": "Scikit-learn: Machine Learning in Python"}, {"paperId": "a538b05ebb01a40323997629e171c91aa28b8e2f", "title": "Rectified Linear Units Improve Restricted Boltzmann Machines"}, {"paperId": "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649", "title": "Understanding the difficulty of training deep feedforward neural networks"}, {"paperId": "e75181151e1ccea31d28499cb640ee881b8a58bf", "title": "Does BERT Rediscover a Classical NLP Pipeline?"}, {"paperId": null, "title": "A mathematical framework for transformer circuits"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "fbc6562814e08e416e28a268ce7beeaa3d0708c8", "title": "Large-Scale Machine Learning with Stochastic Gradient Descent"}]}