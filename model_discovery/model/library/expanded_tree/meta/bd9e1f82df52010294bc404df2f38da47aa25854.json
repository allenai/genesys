{"paperId": "bd9e1f82df52010294bc404df2f38da47aa25854", "abstract": "Scaling model parameters usually improves model quality, but at the price of high computation overhead. Sparsely activated models, usually in the form of Mixture of Experts (MoE) architecture, have constant computation cost over their dense counterparts, thus providing opportunities to train and serve a large model at a reasonable cost. However, the distributed training of an MoE model is prone to low ef\ufb01ciency, mainly due to the interleaved all-to-all communication during model computation. This paper makes three main contributions. First, we systematically analyze the all-to-all overhead in distributed training of MoE. Second, we propose a new communication scheduling scheme based on tensor partitioning that prioritizes the all-to-all operations over other communication, due to its blocking nature. Third, we introduce expert packing that reduces the all-to-all transfer size and incorporates optimizations to mitigate its overheads. Both techniques effectively tackle the all-to-all bottleneck, and we integrate them into a new system called Lita. Experiments on an A100 GPU testbed show that Lita improves the training step time of popular NLP models by up to 1.73x over the state-of-the-art.", "venue": "arXiv.org", "year": 2022, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2210.17223", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "A new communication scheduling scheme based on tensor partitioning that prioritizes the all-to-all operations over other communication, due to its blocking nature, and expert packing that reduces the all-to-all transfer size and incorporates optimizations to mitigate its overheads are introduced."}, "embedding": {"model": "specter_v2", "vector": [-0.006780149415135384, 0.4016856849193573, -0.607351541519165, -0.07018136233091354, -0.5352833867073059, -0.2416197806596756, 0.3710717558860779, -0.19675518572330475, -0.37068411707878113, -0.24330714344978333, 0.3678390085697174, 0.1037389487028122, 0.09297751635313034, 0.36175736784935, -0.2672267258167267, 0.06620742380619049, -1.1817643642425537, 0.9133924841880798, 0.12661747634410858, -0.17226026952266693, -0.46013692021369934, -0.36638525128364563, -1.068684697151184, 0.35824716091156006, 0.8099841475486755, 0.6783966422080994, -0.17691203951835632, 0.7925567626953125, -0.2181093990802765, -0.08175971359014511, 0.5122419595718384, -0.19455663859844208, 0.38492628931999207, 0.3854968845844269, -0.10484682768583298, -0.06835031509399414, 0.17706483602523804, -0.47374865412712097, -0.3884723484516144, 0.7364137768745422, 0.09671899676322937, 0.31722086668014526, 0.31972265243530273, -0.732596218585968, -0.03531776741147041, 0.7718736529350281, 0.22756007313728333, 0.7971979975700378, -0.3874348998069763, -0.8152666687965393, 1.173470377922058, -1.7753394842147827, 0.27404290437698364, 1.2861783504486084, 0.4651567041873932, 0.12212534248828888, -0.44082340598106384, -0.2090034782886505, 0.6558126211166382, -0.027905236929655075, -0.776427149772644, -0.46338993310928345, -0.20527224242687225, -0.2600938677787781, 1.9520474672317505, -0.3608814775943756, 0.05237184092402458, 0.1976366639137268, -0.25319015979766846, 1.4848324060440063, -0.06120922043919563, -0.5875589847564697, -0.013250193558633327, 0.03654279187321663, 0.4383418560028076, 0.8501367568969727, -0.18443161249160767, 0.4676235020160675, -1.3073160648345947, -0.6928644776344299, 0.012353935278952122, -0.1579478681087494, 0.03603973239660263, -0.345479816198349, -0.20450454950332642, 0.7593581080436707, 0.3699612021446228, 0.6357991099357605, -0.4928262233734131, 0.6943232417106628, 0.7800975441932678, 0.30695104598999023, 0.33267349004745483, 0.2881790101528168, -0.3671843111515045, 0.15228271484375, -1.1599239110946655, 0.38283610343933105, 0.6004636883735657, 0.701416552066803, -0.11644341051578522, 0.10567976534366608, -0.5732613205909729, 0.3399050533771515, 1.3259384632110596, -0.06681522727012634, 0.2139725536108017, -0.4374542236328125, 0.3247087895870209, -0.6443122625350952, 0.14766603708267212, -0.6437934041023254, -0.13103213906288147, -0.30170875787734985, -0.9658722877502441, -1.4582966566085815, -0.9302780628204346, -0.20363859832286835, -0.8815839290618896, 0.36662009358406067, -0.0993729829788208, 0.641549289226532, -0.05359989032149315, 0.8336737751960754, 0.410224974155426, 0.7714596390724182, 0.32896602153778076, 0.26016920804977417, 1.0582497119903564, -1.1683621406555176, -0.4437304437160492, -1.2096935510635376, 0.839328408241272, -0.24635733664035797, -0.38138261437416077, -0.35156989097595215, -1.345126986503601, -0.7560960650444031, -0.5495248436927795, 0.10308627039194107, -0.22397136688232422, 0.625528872013092, 1.2939444780349731, 0.1038019061088562, -0.9822415113449097, 0.9310936331748962, -0.44396522641181946, 0.04372068867087364, 0.43792685866355896, 0.6232607960700989, 0.18766295909881592, -0.4342663884162903, -1.2735168933868408, 0.21924850344657898, 0.3985018730163574, -0.3367477357387543, -0.4634171724319458, -0.7099482417106628, -0.8109293580055237, 0.2249026745557785, 0.3109411299228668, -0.576410174369812, 1.3754256963729858, 0.191288024187088, -1.24384605884552, 0.27773618698120117, -0.20804500579833984, 0.11114314943552017, -0.07168394327163696, -0.22800543904304504, -0.4834389090538025, -0.34493622183799744, -0.33643007278442383, 0.6178092956542969, 0.5984480977058411, -0.1489071249961853, -0.15417326986789703, 0.18396304547786713, -0.10422088205814362, 0.11622630059719086, -0.301114559173584, 0.6634891033172607, -0.5224023461341858, -0.08133681118488312, 0.4059765338897705, 0.5098804235458374, -0.6634294986724854, -0.24334871768951416, -0.25840669870376587, -1.1861534118652344, 0.92661452293396, -0.0650465339422226, 0.9028099775314331, -0.9314719438552856, -0.17383219301700592, 0.1375359147787094, 0.1539483666419983, 0.17465844750404358, -0.6851152777671814, 0.8259768486022949, -0.3239354193210602, -0.03204246237874031, -0.17644482851028442, -1.0973114967346191, 0.38158732652664185, 0.16767776012420654, -0.7549996972084045, -0.317483514547348, 0.1483583152294159, 1.0608402490615845, -0.8865369558334351, 0.21519772708415985, -0.2856382429599762, 0.4295656681060791, -1.1559736728668213, 1.1127504110336304, -0.7212572693824768, 0.12118469923734665, -0.037728451192379, -0.14245083928108215, 0.20648899674415588, -0.6649662852287292, 0.7679217457771301, -0.6898903846740723, 0.2315373569726944, 0.5700734853744507, -0.6119529604911804, 1.185672640800476, -0.16144265234470367, 0.18684318661689758, 0.07341711968183517, -0.8227630257606506, -0.026565270498394966, 0.8984454870223999, 0.12837252020835876, -0.07558142393827438, 0.3646296560764313, 0.886076033115387, -0.22128210961818695, 0.2074284851551056, 0.9328579306602478, 0.9770137667655945, -0.26641544699668884, 0.15553711354732513, 0.8195597529411316, -0.009558544494211674, 0.8943734765052795, 0.6958591938018799, 0.44315117597579956, 0.39128151535987854, 0.17903193831443787, 0.010653377510607243, 0.25023359060287476, -0.5044830441474915, -0.03149280324578285, 0.21115931868553162, 0.9041632413864136, 0.06850172579288483, 0.4795764088630676, -0.932518720626831, -0.5696384310722351, 0.8291118144989014, 0.621286153793335, 1.7799460887908936, -0.25836509466171265, -0.1864737868309021, -0.7482156157493591, -0.7908235788345337, -0.032023027539253235, -0.3770260810852051, 0.07204246520996094, 0.24544237554073334, -0.5521847605705261, -1.2141927480697632, 0.6768321990966797, 0.605944812297821, 0.7541871070861816, -0.17622238397598267, -0.20690079033374786, -0.4365355372428894, 0.30469420552253723, -0.8648006916046143, -0.5139322876930237, 0.5575155019760132, -0.532762348651886, -0.11712817847728729, -0.2850244641304016, 0.00601955084130168, 0.6238175630569458, -0.6954737305641174, 1.1255439519882202, -0.7995620369911194, -0.14802168309688568, 0.025273777544498444, 0.5517799258232117, -0.33140823245048523, -0.4190692603588104, 0.3344424068927765, 0.1716158539056778, -0.0459117628633976, 0.4881584346294403, 0.5318356156349182, 0.06799951940774918, 0.19891022145748138, -0.3212582767009735, 0.4616604149341583, 0.21237516403198242, -0.21241503953933716, 0.7917861938476562, -0.24679376184940338, -0.09374243021011353, -1.2839508056640625, 0.8695622682571411, -0.2582125663757324, -0.44792619347572327, 0.014461823739111423, -0.27204179763793945, -0.5919681191444397, 0.41964784264564514, -0.9740056395530701, -0.1036178320646286, -0.673625111579895, 0.18004342913627625, -0.3693420886993408, -0.18481262028217316, 0.5743435025215149, 0.5788904428482056, -0.3944851756095886, 0.6282837390899658, -0.0033621275797486305, 0.21047312021255493, -0.35659217834472656, 0.5846745371818542, -0.8861085772514343, 0.21034736931324005, -0.2685612738132477, 0.3831876218318939, -0.4105185568332672, -0.26032060384750366, -0.41828522086143494, -0.28522244095802307, -0.6434069275856018, -0.2291138470172882, -0.03601296618580818, -0.13585327565670013, -0.6283894181251526, -0.6722854971885681, -0.43568411469459534, -1.3210244178771973, -0.09589315205812454, 0.31346601247787476, 0.09899431467056274, 0.1857510656118393, -1.0969094038009644, -1.5893443822860718, -0.32966065406799316, -0.6650768518447876, -1.1682825088500977, 0.5940516591072083, -0.11619091033935547, -0.2104903757572174, -0.39222481846809387, 0.14029917120933533, -0.5436086654663086, 1.0861402750015259, -0.83268803358078, 0.662203311920166, -0.24439702928066254, -0.2912818491458893, -0.5008566975593567, -0.23461443185806274, 0.39383527636528015, -0.9164327383041382, 0.0022565487306565046, -0.861362874507904, -0.15319612622261047, -0.5748053789138794, -0.3332154452800751, 0.35103312134742737, 0.3850439190864563, 0.7764804363250732, -0.08593718707561493, -0.9780809283256531, 0.2696484625339508, 1.4146541357040405, -0.9603902101516724, -0.0070179845206439495, -0.6344866156578064, 1.1553763151168823, 0.20837220549583435, -0.39085280895233154, 0.36666056513786316, 0.15468312799930573, 0.34592998027801514, -0.015622669830918312, -0.2878338396549225, 0.279938668012619, -0.0939166247844696, 0.2666647732257843, 2.002609968185425, -0.044547345489263535, 0.04557844251394272, -0.9663899540901184, 0.4916905164718628, -1.7007790803909302, -0.21881218254566193, 0.676316499710083, 0.39555299282073975, 0.12111945450305939, -0.710949182510376, -0.17437413334846497, -0.6535385847091675, 0.3781185448169708, 0.3620219826698303, -0.6087028980255127, -0.43640923500061035, 0.4203617572784424, 0.5411409139633179, 0.3377653956413269, 0.39323440194129944, -0.17080555856227875, 0.4942733645439148, 14.76971435546875, 1.192191481590271, 0.19372577965259552, 0.9028793573379517, 0.7063441276550293, 0.4677310585975647, -0.3702586591243744, -0.07674744725227356, -1.3807251453399658, -0.10769771039485931, 1.3168883323669434, 0.074618861079216, 0.6474794149398804, 0.6015444993972778, -0.07189927995204926, 0.11930020898580551, -0.5232349038124084, 0.6174153685569763, 0.30937910079956055, -1.5150270462036133, 0.13548460602760315, 0.3996000289916992, 0.7742128968238831, 0.8789126873016357, 0.4256405830383301, 0.9283531904220581, 0.5772554874420166, -0.4458130896091461, -0.18010897934436798, 0.24357567727565765, 0.7992992401123047, 0.05498180538415909, 0.7641522884368896, 0.7053555250167847, -0.9941284656524658, -0.0908120721578598, -0.7374367117881775, -1.003870964050293, 0.43272605538368225, 0.6946794986724854, -0.5706896781921387, -0.3223191797733307, -0.21634414792060852, 0.8978360295295715, 0.40580829977989197, 0.644877016544342, 0.14993835985660553, 0.5267066955566406, -0.3940797448158264, 0.4528657793998718, 0.21792742609977722, 0.30704712867736816, 0.06959599256515503, -0.13973574340343475, 0.08569628745317459, -0.12375929206609726, 0.672855794429779, 0.31657758355140686, -0.7045427560806274, -0.06520064175128937, -0.38493916392326355, -0.6252086758613586, -0.11133826524019241, 1.3094333410263062, 0.456339955329895, -0.10549145936965942, -0.4617653787136078, 0.42580127716064453, 0.6800621151924133, 0.2568392753601074, -0.27473142743110657, 0.19450590014457703, -0.023317672312259674, -0.40206965804100037, -0.12167133390903473, 0.5112898349761963, 0.04974108934402466, -0.45991769433021545, -0.7008076310157776, -0.7352491021156311, 0.26396283507347107, -0.2561393678188324, -1.043336272239685, 0.98346346616745, -0.018593808636069298, -0.46232861280441284, 0.23342563211917877, -0.8051228523254395, -0.019021298736333847, 0.6717498302459717, -1.087296485900879, -0.7031201720237732, 0.4474053680896759, -0.42084380984306335, -0.6446254849433899, 0.09015119075775146, 1.5274089574813843, 0.8090129494667053, -0.3220445513725281, -0.4671020209789276, -0.1844601333141327, -0.09677326679229736, -0.21324174106121063, -0.5362734794616699, 1.0267449617385864, 0.09525878727436066, -0.05978891998529434, 0.2224612534046173, -0.3260641098022461, 0.050989679992198944, -0.6057644486427307, -0.13269294798374176, 0.8335207104682922, -0.43521156907081604, -0.5430469512939453, -0.4379994571208954, -1.0908933877944946, 0.41138073801994324, 0.3102760314941406, 0.087675079703331, 0.6438645124435425, 0.2664378583431244, -0.4654524624347687, -0.06257357448339462, -0.8443784117698669, -0.32136258482933044, 0.2156519889831543, -0.7640196681022644, 0.24628393352031708, 0.6757326722145081, 0.5093943476676941, -1.557824730873108, -0.7945410013198853, -0.16384056210517883, -0.1921006143093109, 0.114218570291996, 0.9513956308364868, -0.2604485750198364, 0.6276144981384277, 0.515522837638855, 0.0546838752925396, -0.7726544737815857, 0.2600373327732086, -0.8149803876876831, -0.6007869243621826, -0.4527868926525116, 0.6520164012908936, -0.36826983094215393, 0.5521414875984192, 0.9337001442909241, 0.12460064142942429, -0.5125958323478699, -0.39022982120513916, 0.05125422030687332, -0.5054389834403992, -0.36619073152542114, 0.27635499835014343, 0.005736337974667549, -0.04298239201307297, -0.08567866683006287, 0.26372218132019043, 0.9652695059776306, -0.06351690739393234, -0.7543798685073853, 0.25512561202049255, -0.3247537314891815, -0.44918742775917053, -0.13186268508434296, -0.10372281074523926, -1.5248438119888306, -0.056933410465717316, -1.1982219219207764, -0.03129333630204201, -0.7958208918571472, -0.4117567241191864, -0.2173764854669571, 0.021118707954883575, 0.2519317865371704, 0.3392162621021271, -0.015798313543200493, -0.5330578088760376, -0.2759409248828888, -0.602631688117981, 0.48656249046325684, 0.9448789358139038, -0.5432211756706238, -0.0857362151145935, -0.1868487447500229, 0.4218267798423767, 0.38344645500183105, 0.41122525930404663, -0.37541407346725464, -0.7327646613121033, -1.1477075815200806, 0.6617963910102844, 0.21688328683376312, 0.05540568754076958, -0.6418880224227905, 1.126308560371399, 0.6279862523078918, -0.2987123727798462, -0.15953300893306732, 0.2881435751914978, -1.0509334802627563, -0.23008818924427032, 0.3323017656803131, -0.6437522768974304, 0.05626126378774643, 0.37943509221076965, -0.571460485458374, -0.42896267771720886, 0.6644017696380615, -0.21297553181648254, -1.0110279321670532, -0.8514851331710815, 0.7629058361053467, -0.17879270017147064, 0.0447353832423687, -0.22495576739311218, 0.277832955121994, -1.2194737195968628, 0.03540068864822388, -0.18776331841945648, 0.30590522289276123, -0.7619591355323792, 0.34743085503578186, 0.15210627019405365, -1.151031732559204, 0.2135230451822281, 0.4359845221042633, -0.3143036663532257, 0.344699501991272, 0.9308801293373108, 0.9263944029808044, -0.24445565044879913, 0.6053497791290283, 0.5317464470863342, 0.08623228967189789, -0.7848123908042908, -0.2101157158613205, 0.8324775099754333, -0.7925075888633728, -0.24241018295288086, 1.2619303464889526, -0.6478303074836731, -1.4020986557006836, 0.06284628808498383, -0.875426173210144, -0.39345642924308777, -0.35692381858825684, 0.5495108366012573, 0.47683271765708923, 0.13249197602272034, -0.014047674834728241, -0.6054081320762634, -0.024491192772984505, -0.3891337811946869, -0.5245568156242371, 0.4575986862182617, 0.04314051568508148, -0.9238753914833069, 0.2360399216413498, 0.38219577074050903, -0.714320957660675, -0.5945262908935547, -1.0713298320770264, -0.4952685236930847, -0.2523254454135895, 0.522962212562561, -0.49830546975135803, -0.6947557926177979, 0.7089775800704956, 0.33086252212524414, 0.486615926027298, -0.17680345475673676, -0.2426011860370636, 0.5716367959976196, 0.4891446828842163, 0.33652263879776, -0.5486872792243958, -0.5185327529907227, 1.13408625125885, 1.0420565605163574, -0.8354419469833374, 0.2633974254131317, -0.4680348038673401, -1.0148557424545288, 0.726605236530304, 0.3933165371417999, -0.11265742033720016, 0.8307009339332581, -0.010433035902678967, -0.20414531230926514, -0.13390563428401947, -0.8868685364723206, -0.4514959752559662, 1.3431137800216675, 0.9773922562599182, 0.630490779876709, 0.24623970687389374, 0.047138512134552, 0.7684009671211243, 0.5225909948348999, 0.456080824136734, -0.18894530832767487, 0.19637931883335114, -0.26919978857040405, -0.24277596175670624, -0.05051276832818985, 0.8437238335609436, -0.6770479679107666, -0.6730883717536926, 0.38270801305770874, 0.23728732764720917, 0.36023056507110596, 0.41980183124542236, 0.6654183268547058, 0.18592794239521027, 0.20650112628936768, 0.13138845562934875, 0.37552013993263245, -0.7686628699302673, -0.21895159780979156, 0.17971068620681763, -0.44671767950057983, -0.21668429672718048, -0.38515713810920715, 0.17196525633335114, -0.44170042872428894, -0.6485000252723694, 0.2976052761077881, 0.31561994552612305, 0.5917815566062927, 1.1197538375854492, 1.0026897192001343, 0.8616138100624084, -0.3781375586986542, -0.9955535531044006, -0.44017308950424194, -0.9659616351127625, -0.1702122688293457, -0.6273453831672668, -0.6366937160491943, -0.04942896589636803, -0.17376282811164856, -0.5294205546379089]}, "authors": [{"authorId": "2144515553", "name": "Jiamin Li"}, {"authorId": "2146419154", "name": "Yimin Jiang"}, {"authorId": "2176234169", "name": "Yibo Zhu"}, {"authorId": "2155373238", "name": "Cong Wang"}, {"authorId": "2146234489", "name": "Hong-Yu Xu"}], "references": [{"paperId": "e47da75675b9a3fe02ef1efadca39bc8cdfcdc17", "title": "Designing Effective Sparse Expert Models"}, {"paperId": "0dab58e476f3f0e6f580a295f7c4756c86f1f198", "title": "FasterMoE: modeling and optimizing training of large-scale dynamic pre-trained models"}, {"paperId": "7d1e512888a2fa4e838c12a02ae7fce867d322a8", "title": "DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale"}, {"paperId": "fb01415a0decfa3f3d6339930e95028ae1ff4170", "title": "Efficient Large Scale Language Modeling with Mixtures of Experts"}, {"paperId": "80d0116d77beeded0c23cf48946d9d10d4faee14", "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"}, {"paperId": "12b71736392209b4292471b7da0aed71ba2aa545", "title": "ZeRO-Offload: Democratizing Billion-Scale Model Training"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "33d735c2f889b5b6a5851f01e741eae535a91127", "title": "Rammer: Enabling Holistic Deep Learning Compiler Optimizations with rTasks"}, {"paperId": "2b2056bf5763e32811a69769fa8c223160125f9e", "title": "DNNFusion: accelerating deep neural networks execution with advanced operator fusion"}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "1e009f755503bffd7644fcd0a45939c54b838b37", "title": "BlueConnect: Decomposing all-reduce for deep learning on heterogeneous network hierarchy"}, {"paperId": "76c929af6735cdff2c4badc9a9c8f39d15ea3e70", "title": "A generic communication scheduler for distributed DNN training acceleration"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "2270b8628fd8ca67ae39d277f45bc3c38ac63d5f", "title": "Mesh-TensorFlow: Deep Learning for Supercomputers"}, {"paperId": "2229ac756f89c3db017293918548555734d2f891", "title": "TicTac: Accelerating Distributed Deep Learning with Communication Scheduling"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "079932bf6ff8b99c899172ba60071818f6b5dfcb", "title": "Poseidon: An Efficient Communication Architecture for Distributed Deep Learning on GPU Clusters"}, {"paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586", "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"}, {"paperId": "fba71eefd060e30f3516fdd46df9a191cd0aaaf7", "title": "Conditional Computation in Neural Networks for faster models"}, {"paperId": "62c76ca0b2790c34e85ba1cce09d47be317c7235", "title": "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation"}, {"paperId": "da94f25d74f076e3e8d30c6a2c82ec498c11755d", "title": "The Case for Tiny Tasks in Compute Clusters"}, {"paperId": "5861636a1c3c0e9ccf6f683fe70b3b5182ef1697", "title": "Whale: Scaling Deep Learning Model Training to the Trillions"}, {"paperId": "08588107b9e37f9601bb5c801aa46b918cc3c8ec", "title": "A Unified Architecture for Accelerating Distributed DNN Training in Heterogeneous GPU/CPU Clusters"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Fairscale: A general purpose modular pytorch library for high performance and large scale training"}]}