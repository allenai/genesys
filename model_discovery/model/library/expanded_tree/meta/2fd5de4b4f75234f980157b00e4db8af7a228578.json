{"paperId": "2fd5de4b4f75234f980157b00e4db8af7a228578", "abstract": "Positional Encodings (PEs) are used to inject word-order information into transformer-based language models. While they can significantly enhance the quality of sentence representations, their specific contribution to language models is not fully understood, especially given recent findings that various positional encodings are insensitive to word order. In this work, we conduct a systematic study of positional encodings in \\textbf{Bidirectional Masked Language Models} (BERT-style) , which complements existing work in three aspects: (1) We uncover the core function of PEs by identifying two common properties, Locality and Symmetry; (2) We show that the two properties are closely correlated with the performances of downstream tasks; (3) We quantify the weakness of current PEs by introducing two new probing tasks, on which current PEs perform poorly. We believe that these results are the basis for developing better PEs for transformer-based language models. The code is available at \\faGithub~ \\url{https://github.com/tigerchen52/locality\\_symmetry}", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A systematic study of positional encodings in Bidirectional Masked Language Models (BERT-style) complements existing work in three aspects and uncovers the core function of PEs by identifying two common properties, Locality and Symmetry."}, "embedding": {"model": "specter_v2", "vector": [0.5890311002731323, 0.6379179954528809, -0.4816458523273468, -0.5121945142745972, -0.6061213612556458, -0.24327312409877777, 0.6108929514884949, -0.15599632263183594, -0.4860931932926178, -0.3596547544002533, 0.9613593220710754, -0.3234456777572632, -0.11007906496524811, -0.16140377521514893, -0.035707853734493256, -0.29096636176109314, -0.7520099878311157, 0.3713496923446655, 0.16931134462356567, -0.41097062826156616, 0.0313587449491024, -0.6212356090545654, -0.658513069152832, 0.7085875272750854, 0.06031021103262901, 0.28851839900016785, 0.31412097811698914, 0.6364550590515137, -0.23638413846492767, 0.6873877644538879, 0.7812098264694214, -0.4401973485946655, 0.19213220477104187, 0.08335885405540466, -0.10738781839609146, -0.2673240602016449, 0.18598176538944244, -0.6538610458374023, -1.0504285097122192, 0.8389992713928223, -0.20654019713401794, -0.09319804608821869, 0.35510772466659546, -0.7423662543296814, -0.6503175497055054, 1.4007936716079712, 0.731113076210022, 0.9111357927322388, -0.24016694724559784, -0.6321288347244263, 1.7693257331848145, -1.3657865524291992, 0.264756977558136, 1.3529142141342163, 0.4683091938495636, 0.5395424365997314, -0.6886025667190552, -0.3153206408023834, 0.6243792176246643, 0.461819589138031, -1.1532695293426514, -0.9068373441696167, 0.03179651498794556, 0.061036624014377594, 1.6587432622909546, -0.13920867443084717, -0.2913758456707001, 0.18843625485897064, 0.012046224437654018, 1.3389204740524292, 0.27113714814186096, -0.7186096906661987, -0.5173355340957642, 0.0458102822303772, 0.40998953580856323, 0.9410089254379272, -0.754956841468811, 0.8598480224609375, -1.3110002279281616, 0.012823554687201977, 0.2645213007926941, -0.1888488084077835, -0.2573709189891815, -0.18017368018627167, -0.35907045006752014, 0.5275983810424805, 0.22835667431354523, 0.7008052468299866, -0.03149791434407234, 0.5663212537765503, 0.32574784755706787, 0.38500580191612244, -0.05862964317202568, 0.07431159913539886, -0.0012556015281006694, 0.24549908936023712, -1.0668574571609497, 0.47853758931159973, -0.252276211977005, 0.4390496611595154, -0.07888969033956528, 0.19662787020206451, -1.1635594367980957, -0.2627163231372833, 1.7620584964752197, 0.13056731224060059, 0.4639395773410797, -0.8312820792198181, 0.23759344220161438, -0.870542049407959, 0.18319323658943176, -1.0666091442108154, -0.0529550202190876, -0.12452323734760284, -0.1844942569732666, -1.8399391174316406, -0.0806153193116188, 0.7193005084991455, -0.6567717790603638, 1.1939315795898438, -0.485866516828537, -0.27804872393608093, -0.0033886635210365057, 0.28508543968200684, 0.5624020099639893, 1.0642154216766357, -0.008750188164412975, 0.20342180132865906, 0.7249113321304321, -0.4496777355670929, -0.7070375680923462, -1.4323351383209229, 1.1678187847137451, -0.28845515847206116, 0.42119285464286804, -0.3558831810951233, -1.4735394716262817, -0.8908453583717346, -0.6576841473579407, 0.10403027385473251, -0.48680081963539124, 0.20278309285640717, 0.3047633469104767, 0.47275224328041077, -1.8710583448410034, 0.8187978863716125, -0.10906659811735153, 0.15397891402244568, 0.2851153016090393, 0.15909625589847565, -0.013084784150123596, -0.653378963470459, -1.7151515483856201, 0.3738080859184265, 0.11929117143154144, -0.33488979935646057, -0.14566883444786072, -0.9046767950057983, -1.692657470703125, 0.24581262469291687, 0.09953111410140991, -0.05887222662568092, 1.11966073513031, 0.8096293807029724, -1.0359795093536377, 0.7450469732284546, -1.2587774991989136, 0.08851812779903412, -0.018093371763825417, 0.22507265210151672, -0.2022104561328888, -0.4623219072818756, -0.0022402333561331034, 0.7195433974266052, 0.0764136016368866, -0.3804191052913666, -0.0707067996263504, -0.23844130337238312, -0.4963843822479248, 0.052546773105859756, -0.47881054878234863, 1.1879727840423584, -0.024547528475522995, -0.025151874870061874, 0.7201205492019653, 0.9403747320175171, 0.11561131477355957, -0.22911681234836578, -0.45001640915870667, -0.9843640923500061, 0.4362860321998596, -0.36897194385528564, 1.5005073547363281, -1.0318235158920288, -0.5395276546478271, -0.29866117238998413, 0.1546355038881302, -0.45558908581733704, -0.6946909427642822, 0.9000775814056396, -0.4915255904197693, 0.7327547073364258, -0.26405972242355347, -1.2542049884796143, 0.45879676938056946, -0.17883415520191193, -0.9109838008880615, -0.08431719988584518, -0.08654721826314926, 1.296323537826538, -0.7328553199768066, -0.031897880136966705, 0.02703290618956089, 0.25682327151298523, -0.7780543565750122, 0.932972252368927, 0.23231278359889984, 0.16790518164634705, 0.46669039130210876, -0.5517950654029846, -0.03915167599916458, -0.2550695240497589, 0.18108505010604858, -0.5046722292900085, -0.2756783962249756, 1.0280413627624512, -0.20810191333293915, 0.6700838208198547, 0.14560642838478088, 0.39217692613601685, -0.2640075981616974, -0.7722011804580688, 0.17208951711654663, 0.4926762878894806, -0.23557183146476746, -0.5607625246047974, 0.11915086954832077, 0.23782354593276978, -0.1852836012840271, 0.6719499230384827, 0.6480624079704285, 0.2892482280731201, -0.4462502598762512, 0.28789544105529785, 0.22425688803195953, -0.09132871776819229, 0.7051642537117004, 0.5540714263916016, 0.861470103263855, 0.100990429520607, 0.263680100440979, -0.34299004077911377, 0.4011956751346588, -0.7851300239562988, -0.039914414286613464, 0.6213110089302063, 0.5512344837188721, 1.0210943222045898, 0.6075383424758911, -0.6618466377258301, -0.3827180862426758, -0.2967967689037323, 0.3621646463871002, 1.4304765462875366, -0.22376477718353271, -0.7063449621200562, -0.37436696887016296, 0.282147616147995, -0.35622262954711914, 0.2798018157482147, -0.5452786684036255, -0.5522984266281128, -0.7953845858573914, -1.0177466869354248, 0.7339269518852234, 0.7406738996505737, 0.5297313332557678, -0.359482079744339, 0.05775082856416702, -0.3221748471260071, 0.2298494130373001, -0.748356819152832, -0.4213860034942627, 0.3996003270149231, -0.39303040504455566, 0.1537257730960846, 0.30175793170928955, -0.09558553248643875, 0.2694224715232849, -0.6066734790802002, 0.6617336273193359, -0.6219371557235718, 0.12416145950555801, -0.252934992313385, 0.6479576230049133, -0.2226748913526535, -0.793088972568512, -0.0004895646125078201, 0.1016688197851181, -0.12468506395816803, 0.6795567274093628, 0.7687662839889526, -0.07512953132390976, 0.4786450266838074, -0.5591877102851868, 0.38676196336746216, 0.09633154422044754, 0.38443461060523987, 0.5977071523666382, -0.11174140870571136, -0.5376831889152527, -0.9535095691680908, 0.7689283490180969, 0.5731127262115479, -0.43288758397102356, 0.4109550714492798, -0.563055157661438, -0.37535545229911804, 0.40963155031204224, -0.21351131796836853, -0.19719843566417694, -1.0513067245483398, 0.3498249650001526, 0.06233319640159607, 0.06620924174785614, 0.3877125084400177, 0.04455981403589249, 0.4717218577861786, -0.05966398864984512, 0.7648302912712097, 0.5641509890556335, 0.06478168815374374, 0.4623284339904785, -0.8154696226119995, 0.23966938257217407, 0.38549771904945374, 0.3240776062011719, -0.08741220831871033, -0.2860383093357086, -0.6043691039085388, -0.5225011110305786, -0.38284891843795776, -0.10277656465768814, -0.11234951764345169, 0.25679585337638855, -0.35330501198768616, -0.7584161162376404, 0.06157258152961731, -1.372462511062622, 0.044895052909851074, 0.139149472117424, -0.7351751327514648, 0.06004101037979126, -0.9474247694015503, -1.8341529369354248, -0.4797820746898651, -0.016250235959887505, -1.3272552490234375, 0.6768126487731934, -0.5205720663070679, -0.6174107193946838, -0.4242321848869324, -0.2683003842830658, -0.19760727882385254, 1.222196340560913, -1.2354456186294556, 1.6444246768951416, -0.09301988780498505, -0.1990084946155548, -0.5194140076637268, 0.10991114377975464, 0.36255913972854614, -0.39495161175727844, 0.14741018414497375, -0.5827680826187134, 0.04964740201830864, -0.013710817322134972, 0.08605019748210907, 0.08305737376213074, 0.521999180316925, 0.6419666409492493, -0.20152413845062256, -0.6343722343444824, 0.04216289892792702, 1.2288546562194824, -0.40371376276016235, 0.3905404508113861, -0.056596964597702026, 1.123186469078064, 0.9535785913467407, -0.4569939970970154, 0.40254682302474976, 0.40638256072998047, 0.46941709518432617, 0.27351120114326477, 0.0868920236825943, 0.1567057967185974, -0.7274826169013977, 0.8362622857093811, 2.0042595863342285, 0.6991891264915466, -0.13217532634735107, -1.3449043035507202, 0.5520250797271729, -1.2439093589782715, -0.8120010495185852, 0.6341453194618225, 0.6986814737319946, 0.3551308810710907, -0.5636077523231506, -0.45601752400398254, 0.5345990657806396, 0.5092164874076843, 0.9469113945960999, 0.4150512218475342, -0.45646417140960693, 0.0915001779794693, 0.2986684739589691, 0.4807526469230652, 1.0497032403945923, -0.30644023418426514, 0.7376899719238281, 14.390503883361816, 0.7496082782745361, -0.04386496916413307, 0.5710998773574829, 0.8110478520393372, 0.45941561460494995, -0.8078415393829346, 0.04051915928721428, -1.6226904392242432, -0.009486133232712746, 1.1190670728683472, -0.07399286329746246, 0.4767955243587494, -0.40488573908805847, 0.21204349398612976, 0.3403512239456177, -0.7312554717063904, 0.31519952416419983, 0.4113582372665405, -1.2346776723861694, 0.4658047556877136, 0.15633536875247955, -0.07360025495290756, 0.1402033120393753, 0.989481508731842, 0.36017414927482605, 0.21387507021427155, -0.9420691132545471, 0.7902563810348511, 0.010233879089355469, 0.6866664886474609, -0.058623313903808594, 0.47246962785720825, 0.5077666640281677, -0.8437756299972534, -0.39267075061798096, -0.675618588924408, -1.4556490182876587, 0.6339427828788757, 0.07870351523160934, -0.6472784280776978, -0.7306067943572998, -0.11625007539987564, 0.9349491596221924, 0.049315836280584335, 0.1628294587135315, -0.2599004805088043, 0.8477683663368225, 0.23306860029697418, -0.02351314388215542, 0.41205650568008423, 0.5673553943634033, 0.3544829189777374, -0.4114331007003784, 0.36740565299987793, -0.35745537281036377, 0.1478814333677292, 0.4145036041736603, -0.02781730145215988, -0.20353245735168457, -0.6051411628723145, -0.43045729398727417, 0.1287926286458969, 0.3060533106327057, 0.3512799143791199, 0.3474274277687073, -0.2687530815601349, -0.17928360402584076, 0.5389496088027954, -0.15106120705604553, 0.08529803156852722, 0.23848079144954681, 0.3400270938873291, 0.25280627608299255, 0.11351598799228668, 0.5456855893135071, -0.32062557339668274, 0.10835814476013184, -0.6747397780418396, -0.3583463132381439, 0.05782816931605339, -0.5565255880355835, -0.6885558366775513, 0.9841212034225464, 0.030367763713002205, -0.06221943348646164, 0.41012850403785706, -1.1748393774032593, 0.05147013068199158, 0.33020639419555664, -1.362696886062622, -0.388960063457489, 0.35885393619537354, -0.44510796666145325, -0.6092805862426758, 0.2945422828197479, 1.418742299079895, 0.1630045771598816, -0.24504457414150238, 0.07661204040050507, 0.13727031648159027, 0.1517224758863449, -0.36106592416763306, -1.0021109580993652, 0.6971064805984497, 0.2788572907447815, 0.1819039136171341, 0.6122939586639404, 0.1894042193889618, 0.28287702798843384, -0.6503017544746399, 0.24293546378612518, 1.7055786848068237, -1.0395580530166626, -0.12529857456684113, -1.0206114053726196, -0.7538866400718689, 0.15042206645011902, 0.48448997735977173, -0.3749774694442749, 0.4370187222957611, -0.19325150549411774, -0.44587787985801697, -0.3696019649505615, -0.3682914674282074, 0.19550597667694092, 0.9067111611366272, -1.0086569786071777, -0.1804892122745514, -0.09659940749406815, 0.27649399638175964, -0.9937064051628113, -0.15121056139469147, 0.17343150079250336, -0.11757329851388931, -0.31620219349861145, 0.8971343636512756, -0.7444071173667908, 1.1270387172698975, 0.4653763473033905, -0.7703436017036438, -0.6899932026863098, -0.6203036904335022, -0.7305835485458374, 0.3726433515548706, 0.1251448690891266, 1.0763860940933228, -0.4000036418437958, 0.4114522337913513, 0.9182530045509338, 0.11971709132194519, -0.5350841283798218, -0.8268114924430847, -0.10259053856134415, 0.10901817679405212, -0.46691152453422546, 0.2750077247619629, -0.3687407374382019, -0.012993869371712208, 0.12285566329956055, 0.3807101249694824, 0.6755079627037048, -0.3401874005794525, -0.7334215641021729, -0.37770140171051025, 0.07847201824188232, 0.008986759930849075, -0.49848076701164246, -0.8848844766616821, -1.6584733724594116, 0.19566331803798676, -1.1802927255630493, 0.41843292117118835, -1.0859003067016602, -0.3975208103656769, 0.257066935300827, -0.4354305565357208, 0.11532366275787354, 0.4748693108558655, -0.05549468845129013, -0.77408766746521, -0.5886819958686829, -0.38050565123558044, 0.8599033951759338, 0.6167612075805664, -0.7475326657295227, 0.6483706831932068, -0.19880381226539612, -0.15234647691249847, 0.18286946415901184, 0.2479313611984253, -0.43332773447036743, -1.0524059534072876, -1.936023473739624, 0.6465988159179688, -0.0497414767742157, 0.014356649480760098, -0.0832284688949585, 0.8127712607383728, 0.5777371525764465, -0.5146954655647278, -0.04949428141117096, 0.5602658987045288, -0.8071644306182861, -0.5294159650802612, 0.4574691355228424, -1.1337060928344727, 0.7298233509063721, -0.16037189960479736, -0.6331393122673035, -0.7246631979942322, 0.6794329881668091, -0.2462519258260727, -1.2617743015289307, -0.5495190620422363, 0.41541779041290283, -0.8133211731910706, -0.010908043012022972, -0.22391901910305023, -0.5713532567024231, -1.14756178855896, -0.5860713720321655, -0.08617857098579407, 0.027716679498553276, -0.2575659453868866, 0.7401440143585205, 0.704979658126831, -1.060889720916748, 0.08620695769786835, 0.4863939881324768, -0.007038000971078873, -0.16129902005195618, 0.3693685233592987, 0.49423012137413025, -0.32771560549736023, 0.8467894792556763, 0.4812670052051544, 0.23613376915454865, -1.2721774578094482, -0.2277461737394333, 0.6053935885429382, -0.3910663425922394, -0.08658204227685928, 1.587528944015503, -0.10147010535001755, -1.1155668497085571, 0.08451375365257263, -0.9966362714767456, -0.43799999356269836, -0.23944151401519775, 0.7656614780426025, 0.35499632358551025, 0.02157135307788849, -0.4121392071247101, -0.6807531714439392, 0.12241348624229431, -0.2985093891620636, -0.627414345741272, 0.44523119926452637, -0.028566628694534302, -1.0779638290405273, 0.384051650762558, 0.7085062265396118, -0.6754270792007446, -0.4082781970500946, -0.7806132435798645, -0.18182890117168427, -0.36559659242630005, 0.4911235272884369, 0.13639508187770844, -0.42298462986946106, 1.1999393701553345, 0.021648941561579704, 0.5675655007362366, -0.18484032154083252, -0.10236708074808121, 0.16253358125686646, 0.15811094641685486, 0.22879774868488312, -0.2524234354496002, -0.8360380530357361, 1.3793091773986816, 0.9383062124252319, -0.5777990221977234, -0.215057834982872, -0.5685216784477234, -0.3562082052230835, 0.5108324885368347, 0.1610472947359085, 0.2311294972896576, 1.0782651901245117, 0.1914379894733429, 0.3532203137874603, 0.035022519528865814, -1.0503219366073608, 0.21453997492790222, 1.0180927515029907, 0.9176739454269409, 0.6559266448020935, 0.14817629754543304, -0.09081358462572098, 0.8568100333213806, -0.026417940855026245, -0.11044220626354218, 0.21592527627944946, 0.7944387793540955, -0.33103835582733154, -0.2679854929447174, 0.3353354334831238, 0.6597400903701782, -0.5008431077003479, -1.300610899925232, -0.09831079840660095, 0.28850889205932617, -0.10017077624797821, 0.6839993596076965, 0.7693998217582703, -0.11770771443843842, 0.07520639896392822, 0.5120694637298584, 0.5434820652008057, -0.6521918773651123, 0.10112912207841873, -0.5769041776657104, -0.39726316928863525, -0.08569701015949249, -0.1567487269639969, -0.5274782776832581, -0.17334039509296417, -0.3954865634441376, 0.4787749648094177, 0.09640960395336151, -0.023368634283542633, 1.2291446924209595, 0.4503486752510071, 0.2254265993833542, -0.22319665551185608, -0.18998628854751587, -0.6987402439117432, -0.6584122180938721, 0.02692432887852192, -0.6791592836380005, -0.4886397123336792, 0.061611659824848175, -0.3138132393360138, -0.1910727620124817]}, "authors": [{"authorId": "2260594517", "name": "Lihu Chen"}, {"authorId": "3025780", "name": "G. Varoquaux"}, {"authorId": "1679784", "name": "Fabian M. Suchanek"}], "references": [{"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "6f6e2e0311589a9af045f6acd00b7dee6d19fce4", "title": "The Impact of Positional Encoding on Length Generalization in Transformers"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "a2fc77f075f666b462d9350e7576f0ba9845c61b", "title": "Transformer Language Models without Positional Encodings Still Learn Positional Information"}, {"paperId": "d2c730502ab895c18bb241261f1efc4268008767", "title": "Word Order Does Matter and Shuffled Language Models Know It"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "91c3f9ed60a383f97a8c38f1e6a28a0e9be232fa", "title": "Local Structure Matters Most: Perturbation Study in NLU"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "4e00843bc5f60d2b9116abc4320af6d184422291", "title": "Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little"}, {"paperId": "7072db6eddb85ecd2c117365d91bd694760f726e", "title": "Position Information in Transformers: An Overview"}, {"paperId": "7defc117a11c16fb70bea6cbc0b58e48244992c8", "title": "BERT & Family Eat Word Salad: Experiments with Text Understanding"}, {"paperId": "0822f8d7e6a72a65e65f147d3a8d8fccd485da40", "title": "Shortformer: Better Language Modeling using Shorter Inputs"}, {"paperId": "776a49616c84d52e8fff9911c561e3bac90910eb", "title": "Out of Order: How important is the sequential order of words in a sentence in Natural Language Understanding tasks?"}, {"paperId": "4889ba5a8ae8b2169dd44d1d3a605bf9820bae8d", "title": "What Do Position Embeddings Learn? An Empirical Study of Pre-Trained Language Model Positional Encoding"}, {"paperId": "8256f48f759cf85044db251cc512f965834945b3", "title": "Rethinking Positional Encoding in Language Pre-training"}, {"paperId": "a048a89e1b3d3a1c84c13e85735f2743f3607da2", "title": "Dependency locality as an explanatory principle for word order"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "6ea13e0980770033482f90ef477316ad5952943a", "title": "Composition is the Core Driver of the Language-selective Network"}, {"paperId": "d0e28f5dc1feae19e41087a92a87992977fd85af", "title": "Encoding word order in complex embeddings"}, {"paperId": "37a23c43ddf09ea97b82b38e2827a2229cfae545", "title": "Novel positional encodings to enable tree-based transformers"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "335613303ebc5eac98de757ed02a56377d99e03a", "title": "What Does BERT Learn about the Structure of Language?"}, {"paperId": "437490c46c06458e9f88a648b88e31fc963bb64e", "title": "The Appendix"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "f89d2da991935549b109d780be3351e0dda92a8f", "title": "Assessing the Ability of Self-Attention Networks to Learn Word Order"}, {"paperId": "ff482c357716e884f64e8e54d8f1307df6e061b5", "title": "Positional Encoding to Control Output Sequence Length"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "526cae4863eb15b5bc39112449c2d5fdf1db85b2", "title": "Multilingual Constituency Parsing with Self-Attention and Pre-Training"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "c41516420ddbd0f29e010ca259a74c1fc2da0466", "title": "What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties"}, {"paperId": "fd5794fc63d5f19bf83cf7baa36e0aa62cbf6299", "title": "Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "7113bd87c3e6f727efae24ee52f20c81358da761", "title": "SentEval: An Evaluation Toolkit for Universal Sentence Representations"}, {"paperId": "2cb94d28bc891a6e57fc13f5167785e255fd6475", "title": "Minimizing Syntactic Dependency Lengths: Typological/Cognitive Universal?"}, {"paperId": "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096", "title": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"}, {"paperId": "79b6de45afaf6746b62b0f8054c1c4cc4fbee604", "title": "Dependency distance: A new perspective on syntactic patterns in natural languages."}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "d821ce08da6c0084d5eacbdf65e25556bc1b9bc3", "title": "Does String-Based Neural MT Learn Source Syntax?"}, {"paperId": "e44da7d8c71edcc6e575fa7faadd5e75785a7901", "title": "Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "f04df4e20a18358ea2f689b4c129781628ef7fc1", "title": "A large annotated corpus for learning natural language inference"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "2a9122ebb38943e86ba91183f12f0336bee1ffff", "title": "Trends in syntactic parsing: anticipation, Bayesian estimation, and good-enough parsing"}, {"paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "title": "GloVe: Global Vectors for Word Representation"}, {"paperId": "c333778104f648c385b4631f7b4a859787e9d3d3", "title": "A SICK cure for the evaluation of compositional distributional semantic models"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "a885f8f943d72cb763db4a7ab0de21be31e81b5a", "title": "Rational integration of noisy evidence and prior semantic expectations in sentence interpretation"}, {"paperId": "8ae55e7016ceee2c2a43765dfefb9a5a8ff888eb", "title": "A Noisy-Channel Model of Human Sentence Comprehension under Uncertain Input"}, {"paperId": "6af58c061f2e4f130c3b795c21ff0c7e3903278f", "title": "Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales"}, {"paperId": "167e1359943b96b9e92ee73db1df69a1f65d731d", "title": "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts"}, {"paperId": "fce6f6b85c3477b18e6f3c03149b07e41f1c6f56", "title": "Good-Enough Representations in Language Comprehension"}, {"paperId": "dc35daba3fb34b2e6a5b12530badb7b799262bbf", "title": "On Position Embeddings in BERT"}, {"paperId": null, "title": "Probing is adopted in this experiment"}, {"paperId": null, "title": "adopt the Identical Word Probing proposed by Wang et al. ("}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Minimizing integration cost: A general theory of constituent order"}, {"paperId": "db8885a0037fe47d973ade79d696586453710233", "title": "The Sixth PASCAL Recognizing Textual Entailment Challenge"}, {"paperId": "de794d50713ea5f91a7c9da3d72041e2f5ef8452", "title": "The Third PASCAL Recognizing Textual Entailment Challenge"}, {"paperId": "136326377c122560768db674e35f5bcd6de3bc40", "title": "The Second PASCAL Recognising Textual Entailment Challenge"}, {"paperId": "475354f10798f110d34792b6d88f31d6d5cb099e", "title": "Automatically Constructing a Corpus of Sentential Paraphrases"}, {"paperId": "e808f28d411a958c5db81ceb111beb2638698f47", "title": "The PASCAL Recognising Textual Entailment Challenge"}, {"paperId": null, "title": "contextual weights"}, {"paperId": null, "title": "a sentence of length 128. These 100 sentences are fed into a language model and the attention weights across different layers are averaged as the positional weight matrix of a particular language"}, {"paperId": null, "title": "2023. Mistral"}, {"paperId": null, "title": "model. A.2 Details of Pre-training We use the configuration of the original BERT"}, {"paperId": null, "title": "A.1 Visualizations of Positional Encodings To understand what positional encodings learn after pre-training, we visualize the positional weights"}]}