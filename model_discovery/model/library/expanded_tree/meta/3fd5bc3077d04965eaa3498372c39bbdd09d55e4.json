{"paperId": "3fd5bc3077d04965eaa3498372c39bbdd09d55e4", "abstract": "This work introduces an efficient method to scale Transformer-based Large Language Models (LLMs) to infinitely long inputs with bounded memory and computation. A key component in our proposed approach is a new attention technique dubbed Infini-attention. The Infini-attention incorporates a compressive memory into the vanilla attention mechanism and builds in both masked local attention and long-term linear attention mechanisms in a single Transformer block. We demonstrate the effectiveness of our approach on long-context language modeling benchmarks, 1M sequence length passkey context block retrieval and 500K length book summarization tasks with 1B and 8B LLMs. Our approach introduces minimal bounded memory parameters and enables fast streaming inference for LLMs.", "venue": "arXiv.org", "year": 2024, "citationCount": 34, "influentialCitationCount": 3, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces an efficient method to scale Transformer-based Large Language Models (LLMs) to infinitely long inputs with bounded memory and computation and introduces a new attention technique dubbed Infini-attention."}, "embedding": {"model": "specter_v2", "vector": [0.281725138425827, 0.45705899596214294, -0.3849187195301056, 0.11440222710371017, -0.47020223736763, -0.29508715867996216, 0.7640740275382996, 0.08857188373804092, -0.2527105212211609, -0.1317659616470337, 0.7763664126396179, -0.11320330947637558, 0.18526171147823334, 0.15862107276916504, -0.15888622403144836, 0.241127610206604, -0.9133756160736084, 0.39912718534469604, 0.1410599946975708, -0.44072645902633667, 0.1564456969499588, -0.9598036408424377, -0.9325792193412781, 0.4116028845310211, 0.39179396629333496, 0.39116203784942627, 0.1288893073797226, 1.0743904113769531, -0.6550828814506531, 0.43091854453086853, 0.38016822934150696, -0.45453014969825745, 0.040697261691093445, -0.1476919949054718, -0.41357922554016113, -0.4001496136188507, 0.2515871524810791, -0.5709187984466553, -0.3232768774032593, 0.6723269820213318, -0.2390756607055664, 0.1334381103515625, 0.5278375744819641, -0.3449780344963074, -0.541385293006897, 1.2228269577026367, 0.7089661955833435, 0.8678194284439087, 0.029327966272830963, -0.8080322742462158, 1.773833990097046, -1.7065906524658203, 0.13734622299671173, 1.6550230979919434, 0.35340046882629395, 0.47379717230796814, 0.027933727949857712, -0.4420316815376282, 1.0699803829193115, 0.2790450155735016, -0.8765519857406616, -0.4392806887626648, -0.06693461537361145, 0.29678207635879517, 2.1981170177459717, -0.13584297895431519, 0.28654715418815613, 0.3513592481613159, -0.047546252608299255, 1.6120816469192505, -0.7858407497406006, -0.8768937587738037, -0.21680337190628052, -0.2801336944103241, 0.11102236807346344, 0.3426435887813568, -0.2862691283226013, -0.21607233583927155, -0.7254270911216736, -0.06196749955415726, 0.14344607293605804, -0.009850198403000832, 0.0020470719318836927, 0.14317741990089417, -0.13141313195228577, 0.4365306496620178, 0.0277971550822258, 0.824670672416687, -0.08472166210412979, 0.5895223021507263, 0.6696361303329468, 0.24479007720947266, 0.1476389318704605, 0.5562930107116699, -0.20779821276664734, 0.15633085370063782, -1.2948585748672485, 0.4759010672569275, 0.09463085979223251, 0.9363957047462463, -0.7014889717102051, 0.05626259744167328, -0.7389864325523376, 0.18479281663894653, 1.0361123085021973, 0.17747996747493744, 0.6819089651107788, -0.7470734715461731, 0.24547390639781952, -0.7312391400337219, 0.21472583711147308, -0.7462868094444275, -0.05723544582724571, -0.22481483221054077, -0.483002632856369, -1.6235071420669556, -0.43923282623291016, 0.3557710647583008, -0.27545294165611267, 0.5567800998687744, -0.24386906623840332, 0.0920105129480362, -0.05457381531596184, 0.3569341003894806, 0.5574729442596436, 1.0571422576904297, 0.21367037296295166, -0.2634482979774475, 0.7548241019248962, -0.9139567017555237, -0.7119452357292175, -1.1645562648773193, 0.9330810904502869, -0.07371985912322998, 0.4879460334777832, 0.13654208183288574, -1.4711647033691406, -0.7534887194633484, -0.9228155016899109, -0.34571337699890137, -0.6991957426071167, -0.02645310014486313, 0.6728718280792236, 0.25677549839019775, -0.9407432079315186, 0.5491599440574646, -0.0003780100669246167, -0.08265922963619232, 0.27490782737731934, 0.22613120079040527, 0.5017260313034058, -0.6368410587310791, -1.421193242073059, 0.011874961666762829, 0.1848210096359253, -0.45977503061294556, 0.11661536246538162, -0.6672236323356628, -1.172088384628296, 0.18991990387439728, 0.6310765743255615, -0.303242027759552, 1.0835464000701904, -0.31857192516326904, -1.3777433633804321, 0.46400249004364014, -0.5794703364372253, -0.06530550867319107, -0.03373221307992935, -0.4543359577655792, -0.37343111634254456, -0.40566983819007874, -0.23290413618087769, 0.23507341742515564, 0.4301966726779938, 0.2342551350593567, -0.3960074484348297, 0.0210945513099432, -0.3709988594055176, 0.06652515381574631, -0.15613266825675964, 1.0088785886764526, -0.7578482627868652, 0.009065873920917511, 0.2791510224342346, 0.9086434841156006, 0.2224826067686081, -0.4954359829425812, -0.3586650788784027, -1.2561858892440796, 0.8556171655654907, -0.2401173710823059, 1.5994035005569458, -0.8049808144569397, -0.46068257093429565, -0.3302474021911621, -0.12665091454982758, 0.22727331519126892, -0.8429130911827087, 0.6872693300247192, -0.10309341549873352, 0.6868335008621216, -0.07782717049121857, -1.0283467769622803, 0.07978661358356476, -0.18285730481147766, -0.7974504232406616, -0.3884322941303253, 0.11478691548109055, 1.3117061853408813, -1.142125129699707, -0.20584692060947418, 0.05238936096429825, 0.21730215847492218, -1.158747911453247, 1.1896902322769165, -0.630372941493988, -0.04921536147594452, -0.34302857518196106, -0.07717026770114899, -0.1494271159172058, -0.2742852568626404, 0.530175507068634, -0.03114495985209942, 0.012308585457503796, 0.45842915773391724, -0.4653559923171997, 1.0190696716308594, -0.39651861786842346, 0.4077387750148773, -0.13377626240253448, -0.8240321278572083, -0.1820603311061859, 0.37858834862709045, -0.2857418358325958, -0.4925132393836975, 0.04699074476957321, 0.46414482593536377, -0.883573591709137, 0.10295551270246506, 0.7852380275726318, 0.7478999495506287, -0.6988808512687683, 0.017059413716197014, 0.6782079339027405, -0.2574026882648468, 0.5522146224975586, 0.5446842312812805, 0.6702293753623962, 0.5182974338531494, 0.6542962789535522, -0.20085538923740387, 0.7041564583778381, -0.8181006908416748, -0.0533522330224514, 0.6199137568473816, 0.7466176152229309, 0.7276148200035095, 0.6951532959938049, -0.6494730710983276, -0.5263268351554871, 0.27616316080093384, 0.752973735332489, 1.7726837396621704, -0.1917053461074829, -0.48088860511779785, -0.7200488448143005, 0.09776327759027481, -0.4641982316970825, 0.18633952736854553, -0.34490063786506653, 0.09142829477787018, -0.6412286162376404, -0.6990152597427368, 0.7729268670082092, 0.40069344639778137, 0.6223719716072083, -0.5777246952056885, -0.04901593551039696, -0.021341655403375626, 0.01823771931231022, -0.77935791015625, -0.7175049185752869, 0.13793134689331055, -0.5402297377586365, 0.07272554934024811, 0.1610414683818817, -0.1324189305305481, -0.12746290862560272, -0.7250626087188721, 1.1742957830429077, -0.23875713348388672, -0.190682515501976, 0.3335486352443695, 0.43199270963668823, -0.6492223143577576, -0.6147990226745605, 0.19092018902301788, 0.21135053038597107, -0.2825426757335663, 0.6528143882751465, 0.5403091907501221, 0.06751909106969833, -0.10939701646566391, -0.3403044044971466, 0.021482497453689575, -0.09282267093658447, 0.18854691088199615, 0.7887212634086609, -0.1771971732378006, 0.22898724675178528, -1.2076165676116943, 0.7535379528999329, 0.0978185385465622, -0.7531898617744446, 0.4787927269935608, -0.589127779006958, -0.556300163269043, 0.889306902885437, -0.733657717704773, -0.28674131631851196, -1.1682194471359253, 0.42758065462112427, -0.2703959047794342, 0.0514739491045475, 0.48686695098876953, -0.28672268986701965, 0.764149010181427, -0.23016227781772614, 0.48294970393180847, 0.06957637518644333, -0.08297254890203476, 0.7580036520957947, -0.7104662656784058, 0.5579589009284973, 0.14601442217826843, -0.24545599520206451, -0.20637452602386475, -0.060636255890131, -1.108396053314209, -0.46727699041366577, -0.5629935264587402, -0.33523082733154297, -0.04249754175543785, 0.1271088421344757, -0.5311643481254578, -0.630696713924408, -0.1906222105026245, -1.035499095916748, -0.4226490557193756, 0.10403157770633698, -0.6309013962745667, -0.06983291357755661, -0.9016742706298828, -1.2559008598327637, -0.6841594576835632, -0.8068204522132874, -0.6540983319282532, 0.5933764576911926, -0.04500332474708557, -0.6085217595100403, -0.7736331224441528, -0.10314967483282089, -0.4769620895385742, 0.9166093468666077, -0.8500588536262512, 0.8237265348434448, -0.35982653498649597, -0.4053690433502197, -0.5717363953590393, 0.4958827793598175, 0.5761379599571228, -0.17648965120315552, 0.2663342356681824, -0.5072174668312073, 0.2739282548427582, -0.49290111660957336, -0.026263590902090073, -0.005415054503828287, 0.5621389150619507, 0.7054252624511719, -0.2505134046077728, -0.5424804091453552, 0.018459031358361244, 1.4340571165084839, -0.5957289934158325, 0.1021873876452446, -0.11420018970966339, 1.0361884832382202, 0.2675257921218872, 0.09434186667203903, 0.5492441654205322, 0.2579314410686493, 0.15482044219970703, 0.1813885122537613, 0.2685331106185913, 0.1949642449617386, -0.7405416965484619, 0.49946722388267517, 1.908926248550415, 0.27184081077575684, -0.3129158914089203, -0.9941547513008118, 1.0048120021820068, -1.2385220527648926, -0.9680705070495605, 0.7861613631248474, 0.9466560482978821, 0.28295257687568665, -0.47700509428977966, -0.4440688192844391, -0.17772383987903595, 0.3146458864212036, 0.18996024131774902, -0.2885773479938507, -0.8286840319633484, 0.03846924006938934, 0.3876771926879883, -0.09002459794282913, 0.7991341352462769, -0.23917454481124878, 0.834899365901947, 14.775432586669922, 0.79212486743927, 0.026350237429142, 0.6214139461517334, 0.6684004664421082, -0.19592931866645813, -0.5038671493530273, -0.025831138715147972, -1.2199842929840088, -0.15235251188278198, 1.4500768184661865, 0.05592505261301994, 0.6979649066925049, 0.07530838251113892, 0.11044327169656754, 0.3245546519756317, -0.7681578397750854, 0.44417744874954224, 0.654732346534729, -1.3083534240722656, 0.6215911507606506, 0.28777578473091125, 0.1725330799818039, 0.5349598526954651, 0.6862612366676331, 1.0885283946990967, 0.18601347506046295, -0.46450239419937134, 0.37234869599342346, 0.1880788803100586, 0.9219220876693726, -0.3743218183517456, 0.4979862570762634, 0.6448484063148499, -0.7489759922027588, -0.7337775230407715, -0.8518486618995667, -1.1755667924880981, 0.1225033774971962, -0.13674741983413696, -0.28210094571113586, -0.5416845083236694, -0.20125971734523773, 0.7348708510398865, -0.0162214208394289, -0.1544947773218155, 0.0780000239610672, 0.7516505718231201, -0.15288525819778442, -0.25581714510917664, 0.2923000156879425, 0.28891101479530334, 0.2503914535045624, 0.05587517470121384, 0.26402753591537476, 0.2516484260559082, -0.11391593515872955, 0.394557923078537, -0.3140171766281128, 0.35806018114089966, -0.4553999900817871, -0.20563575625419617, 0.10772333294153214, 0.4203953742980957, 0.7198328375816345, 0.042561352252960205, -0.7367464303970337, 0.2193981111049652, 0.32567986845970154, 0.20174212753772736, -0.057603444904088974, -0.06202174723148346, 0.19128014147281647, -0.15387876331806183, 0.2544805407524109, 0.732014000415802, 0.030184339731931686, -0.6045676469802856, -0.7109935283660889, -0.46003803610801697, 0.520567774772644, -0.6642951369285583, -0.5557084083557129, 0.5754106044769287, 0.014910911209881306, -0.49071425199508667, -0.05770893394947052, -0.5801593065261841, -0.41056591272354126, 0.3060961067676544, -1.0794025659561157, -0.8537598848342896, 0.5949649214744568, -0.4586995840072632, 0.006543781608343124, 0.23697447776794434, 1.2642966508865356, 0.030545173212885857, -0.29414132237434387, 0.05289805680513382, 0.36883822083473206, -0.035287000238895416, -0.40866023302078247, -0.8317362070083618, 0.7587488889694214, 0.47059157490730286, -0.12195517867803574, 0.4433659315109253, 0.10721912235021591, 0.1405283659696579, -1.0282162427902222, -0.0642191469669342, 1.0199700593948364, -1.2482889890670776, -0.5325122475624084, -0.8534051179885864, -0.9829668998718262, 0.4053969085216522, 0.5701134204864502, -0.16906118392944336, 0.48284247517585754, 0.1954517960548401, -0.2806805372238159, -0.18973615765571594, -0.6179894804954529, 0.18428492546081543, 0.3597722351551056, -0.6250860691070557, -0.36399564146995544, -0.29063931107521057, 0.5047510862350464, -0.7209354639053345, -0.4214378595352173, -0.4200277328491211, 0.2747364044189453, 0.14991173148155212, 0.9894243478775024, -0.4276733994483948, 0.7833061218261719, 0.941091775894165, -0.31709474325180054, -0.4017544984817505, -0.16995340585708618, -0.9018001556396484, -0.36699560284614563, 0.313311368227005, 0.721440851688385, -0.22742913663387299, -0.1573183685541153, 1.069746971130371, 0.6387472748756409, -0.6267566680908203, -0.8191543221473694, -0.19641178846359253, 0.6993527412414551, -0.6499050855636597, 0.595472514629364, -0.3744240701198578, 0.2296249121427536, 0.25193291902542114, 0.30784115195274353, 0.6509935855865479, -0.23185737431049347, -0.7321130037307739, 0.4508218765258789, 0.010973799973726273, 0.03164513781666756, -0.5851132273674011, -0.4988344609737396, -1.436542272567749, -0.052856288850307465, -0.7818627953529358, 0.003223021049052477, -0.9988273978233337, -0.4679992198944092, 0.6554097533226013, -0.3525243103504181, -0.2600727677345276, 0.33904486894607544, -0.43062520027160645, -0.5242818593978882, -0.8449591398239136, -1.0145176649093628, 0.4924162030220032, 0.6730775833129883, -0.9353892803192139, 0.014641160145401955, -0.13737554848194122, -0.16929858922958374, 0.1401073932647705, 0.33207279443740845, -0.1762368381023407, -0.8778409361839294, -1.1121852397918701, 0.5782485008239746, 0.0024513329844921827, -0.3758332431316376, -0.53025221824646, 0.5650620460510254, 0.33304622769355774, -0.13897757232189178, -0.24971476197242737, 0.42951861023902893, -0.6446338295936584, -0.7331571578979492, -0.018530244007706642, -0.9933940172195435, 0.09885259717702866, 0.048435986042022705, -0.4136812388896942, -0.32251372933387756, 0.6177292466163635, -0.3294960856437683, -1.304794192314148, -0.6435552835464478, 0.4224880635738373, -0.7962145209312439, 0.4289071261882782, -0.7661275863647461, -0.14519959688186646, -0.5930312871932983, -0.5797191262245178, 0.26160645484924316, 0.5192302465438843, -0.27583926916122437, 1.0501902103424072, 0.4093043804168701, -0.825899064540863, 0.05684725195169449, 0.32820120453834534, -0.0675957128405571, 0.3236658275127411, 0.5794510841369629, 0.2822965085506439, -0.06799589097499847, 0.7896091341972351, 0.7976042032241821, 0.08128225803375244, -1.0584744215011597, 0.4710249900817871, 0.5551832914352417, -0.6671403646469116, -0.32781195640563965, 1.1017441749572754, -0.23334304988384247, -0.9376262426376343, -0.061504412442445755, -1.536263108253479, -0.6883297562599182, -0.4105195105075836, 1.1424001455307007, 0.013880257494747639, -0.2644166350364685, -0.097971111536026, -0.6229260563850403, 0.3929911255836487, -0.007646110840141773, -0.5383480787277222, 0.7543193101882935, -0.390203058719635, -0.7903807759284973, 0.9002697467803955, 0.9809859991073608, -0.5346689820289612, -0.2681981921195984, -0.7924109101295471, -0.3210602402687073, -0.021767595782876015, 0.4259936809539795, -0.3059747815132141, 0.11938659846782684, 0.778612494468689, 0.26298484206199646, 0.465829998254776, 0.20636236667633057, -0.11820230633020401, 0.2745679020881653, 0.8360950350761414, 0.120038241147995, -0.9056058526039124, -0.5996637344360352, 1.2335745096206665, 1.3935805559158325, -0.8005189299583435, 0.3258085250854492, 0.20229515433311462, -0.6396968364715576, 0.7693578600883484, 0.04671092331409454, -0.0393703319132328, 1.0013936758041382, -0.33394068479537964, 0.06297984719276428, 0.266323447227478, -1.501459002494812, 0.018479568883776665, 0.8579777479171753, 0.7500830888748169, 0.7212942838668823, 0.259016752243042, 0.07016287744045258, 1.1911739110946655, 0.3008502721786499, 0.2019256055355072, 0.6420499682426453, 0.3070325553417206, -0.14303217828273773, 0.09297524392604828, 0.24496111273765564, 0.6166663765907288, -0.9444286227226257, -0.8871967792510986, 0.2027868777513504, 0.3925143778324127, -0.01733744703233242, 0.9060044884681702, 0.8130000233650208, 0.39355525374412537, 0.3091667890548706, 0.3894868493080139, 0.4911070466041565, -0.5747731924057007, -0.005837953183799982, -0.017057189717888832, -0.6928300857543945, -0.03945239260792732, -0.011375904083251953, -0.5367740988731384, -0.2744729816913605, 0.0660259872674942, 0.0588899664580822, 0.09830333292484283, 0.09048077464103699, 1.2909692525863647, 0.5684699416160583, 0.2632952332496643, -0.42007875442504883, -0.5208732485771179, -0.3640206456184387, -0.9907543659210205, -0.18536268174648285, -0.5706921815872192, -0.08703348785638809, 0.0966787040233612, -0.19186344742774963, -0.4214058518409729]}, "authors": [{"authorId": "2227827", "name": "Tsendsuren Munkhdalai"}, {"authorId": "1779225", "name": "Manaal Faruqui"}, {"authorId": "2295888567", "name": "Siddharth Gopal"}], "references": [{"paperId": "f288e2238ac8725baa7ca9874bbc3fed1e89a632", "title": "Data Engineering for Scaling Language Models to 128K Context"}, {"paperId": "ac45bbf9940512d9d686cf8cd3a95969bc313570", "title": "OLMo: Accelerating the Science of Language Models"}, {"paperId": "02ad9f3fefe33cb9ca546591bec65dbdf7766c80", "title": "Ring Attention with Blockwise Transformers for Near-Infinite Context"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "b6346f9fa093b8e85df712485a2b851b9f680dac", "title": "LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "60b0476a97c00e355df28ba35422764a7fbe88e8", "title": "In-context Autoencoder for Context Compression in a Large Language Model"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "c12db2c60e8989f646a29ad4f4d24475e860ad91", "title": "LongNet: Scaling Transformers to 1, 000, 000, 000 Tokens"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "6f6e2e0311589a9af045f6acd00b7dee6d19fce4", "title": "The Impact of Positional Encoding on Length Generalization in Transformers"}, {"paperId": "60b35c6d68acced19b0c66edcfc0ee0a2c11efed", "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers"}, {"paperId": "2f7364d8e5cf94315bf8905f57de9c5543e9a4bf", "title": "Adapting Language Models to Compress Contexts"}, {"paperId": "b6d6c33298b852cf63edac233deca70530d69a2a", "title": "PaLM 2 Technical Report"}, {"paperId": "dbc368bc8b49347dd27679894524fa62f88492c9", "title": "Unlimiformer: Long-Range Transformers with Unlimited Length Input"}, {"paperId": "b9870e130f61ff900fe00dbcc5782c9b31773d32", "title": "Learning to Compress Prompts with Gist Tokens"}, {"paperId": "a8cf0f7a20f886acfb332071c2daaf58ba86a5ca", "title": "Recurrent Memory Transformer"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "0e802c0739771acf70e60d59c2df51cd7e8c50c0", "title": "Memorizing Transformers"}, {"paperId": "274f903041b1a830b37f57929d837c1706e94ec7", "title": "PRIMERA: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "a4ffce66918cfb33150a60bf8e26419199e63b01", "title": "BookSum: A Collection of Datasets for Long-form Narrative Summarization"}, {"paperId": "64a29bee2e1ad29547d590a3cc26274f4c537145", "title": "Not All Memories are Created Equal: Learning to Forget by Expiring"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "5e11e806d24dd80ecf0f91e7aacedbba8d9fd6fc", "title": "Learning Associative Inference Using Fast Weight Memory"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "dfba20af7aacd819e7b22cf2bf189cd7af9da0a1", "title": "Enhancing the Transformer with Explicit Relational Encoding for Math Problem Solving"}, {"paperId": "a513bb6e1967f5a31ad4f38954e66d4169b613e5", "title": "Metalearned Neural Memory"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "5f4a22ee70ca613d9c0630eafc96364fe365fdf8", "title": "Efficient Attention: Attention with Linear Complexities"}, {"paperId": "6398cb8f2af1c988a097ed1e1cefb380195edfb8", "title": "(Preprint)"}, {"paperId": "54a13bcc9613dcaa76fb25fbe96572f376cfcca9", "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost"}, {"paperId": "249ac07c5b87f44b85500e2d26b68a7edb93e83d", "title": "Differentiable plasticity: training plastic neural networks with backpropagation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "470d11b8ca4586c930adbbfc3f60bff08f2a0161", "title": "Meta Networks"}, {"paperId": "c45362793d10a8d56960b9cd43d1f27980ae5bd4", "title": "Citation Analysis with Neural Attention Models"}, {"paperId": "c91ae35dbcb6d479580ecd235eabf98374acdb55", "title": "Using Fast Weights to Attend to the Recent Past"}, {"paperId": "cff79255a94b9b05a4ce893eb403a522e0923f04", "title": "Neural Semantic Encoders"}, {"paperId": "13fe71da009484f240c46f14d9330e932f8de210", "title": "Long Short-Term Memory-Networks for Machine Reading"}, {"paperId": "f63e917638553414526a0cc8550de4ad2d83fe7a", "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)"}, {"paperId": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e", "title": "End-To-End Memory Networks"}, {"paperId": "c1126fbffd6b8547a44c58b192b36b08b18299de", "title": "Neural Turing Machines"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "bc22e87a26d020215afe91c751e5bdaddd8e4922", "title": "Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks"}, {"paperId": "dcdb9bd64e3d7885c10938291153257b94f3df91", "title": "Sparse Distributed Memory"}, {"paperId": "98b4d4e24aab57ab4e1124ff8106909050645cfa", "title": "Neural networks and physical systems with emergent collective computational abilities."}, {"paperId": "b9164335be5808ddd59786869a9f992331af5218", "title": "The organization of behavior: A neuropsychological theory"}, {"paperId": "0eedbc38bc215fdbe4e5bcde8aeac08fb3ce9f44", "title": "Parallel Context Windows Improve In-Context Learning of Large Language Models"}, {"paperId": "9438172bfbb74a6a4ea4242b180d4335bb1f18b7", "title": "Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems"}, {"paperId": "7257eacd80458e70c74494eb1b6759b52ff21399", "title": "Using fast weights to deblur old memories"}, {"paperId": null, "title": "Efficiently scaling trans-former inference"}]}