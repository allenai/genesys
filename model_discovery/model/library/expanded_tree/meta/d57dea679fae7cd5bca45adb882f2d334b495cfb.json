{"paperId": "d57dea679fae7cd5bca45adb882f2d334b495cfb", "abstract": "Knowledge-based visual question answering (VQA) requires world knowledge beyond the image for accurate answer. Recently, instead of extra knowledge bases, a large language model (LLM) like GPT-3 is activated as an implicit knowledge engine to jointly acquire and reason the necessary knowledge for answering by converting images into textual information (e.g., captions and answer candidates). However, such conversion may introduce irrelevant information, which causes the LLM to misinterpret images and ignore visual details crucial for accurate knowledge. We argue that multimodal large language model (MLLM) is a better implicit knowledge engine than the LLM for its superior capability of visual understanding. Despite this, how to activate the capacity of MLLM as the implicit knowledge engine has not been explored yet. Therefore, we propose GeReA, a generate-reason framework that prompts a MLLM like InstructBLIP with question relevant vision and language information to generate knowledge-relevant descriptions and reasons those descriptions for knowledge-based VQA. Specifically, the question-relevant image regions and question-specific manual prompts are encoded in the MLLM to generate the knowledge relevant descriptions, referred to as question-aware prompt captions. After that, the question-aware prompt captions, image-question pair, and similar samples are sent into the multi-modal reasoning model to learn a joint knowledge-image-question representation for answer prediction. GeReA unlocks the use of MLLM as the implicit knowledge engine, surpassing all previous state-of-the-art methods on OK-VQA and A-OKVQA datasets, with test accuracies of 66.5% and 63.3% respectively. Our code will be released at https://github.com/Upper9527/GeReA.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "GeReA is proposed, a generate-reason framework that prompts a MLLM like InstructBLIP with question relevant vision and language information to generate knowledge-relevant descriptions and reasons those descriptions for knowledge-based VQA, surpassing all previous state-of-the-art methods on OK-VQA and A-OKVQA datasets."}, "embedding": {"model": "specter_v2", "vector": [-0.07272815704345703, 0.6228532791137695, -0.09125787019729614, -0.12050177156925201, -0.7759383320808411, -0.4116922616958618, 0.28010642528533936, 0.06485437601804733, -0.25261878967285156, -0.4158051609992981, 0.5183134078979492, -0.0510902963578701, 0.242558091878891, -0.02422361820936203, -0.18024855852127075, 0.22200964391231537, -0.7109169960021973, 0.18623268604278564, 0.37055879831314087, -0.7078676819801331, 0.11575786024332047, -0.8533734083175659, -1.204798936843872, 0.535934567451477, 0.4007287621498108, 0.7943528890609741, 0.01642078533768654, 1.4472005367279053, -0.47235992550849915, 0.7537608742713928, 0.43231475353240967, -0.13884350657463074, -0.10296650230884552, 0.09121619164943695, -0.6722586154937744, 0.5403127670288086, 0.5920913815498352, -0.937100350856781, -0.5178168416023254, 0.4049355685710907, 0.19402775168418884, 0.3903288245201111, 0.6208975911140442, -0.8766810297966003, -0.9978520274162292, -0.0624358169734478, 0.5670444369316101, 0.504080593585968, 0.35132643580436707, -0.21280139684677124, 1.5106853246688843, -1.867392897605896, 0.3942394554615021, 1.6132888793945312, -0.2816733717918396, 0.8588163256645203, 0.2559060752391815, -0.043450672179460526, 0.7216127514839172, 0.32957014441490173, -0.4755691885948181, -0.3393208980560303, -0.24577759206295013, -0.20441822707653046, 1.176688313484192, -0.2859078645706177, -0.27927514910697937, 0.622175931930542, -0.25209903717041016, 1.582032322883606, -0.11581922322511673, -1.0752182006835938, 0.13813313841819763, -0.1374659538269043, 0.3125610947608948, 1.02962327003479, -0.5800864696502686, 0.4881385564804077, -0.7228853106498718, -0.011950251646339893, 0.816137433052063, -0.40618687868118286, -0.7180292010307312, -0.5002546310424805, -0.6135542988777161, 0.8468765020370483, 0.7931519150733948, 0.40614795684814453, -0.24684344232082367, 0.3211553990840912, 0.0324675552546978, 0.15653826296329498, -0.5309364199638367, 0.2604961097240448, -0.17228880524635315, 0.5732993483543396, -0.3583942949771881, 0.5343897938728333, 0.040292274206876755, 0.6832213401794434, -0.20823392271995544, -0.2736802399158478, -1.0220736265182495, 0.010351679287850857, 1.5760656595230103, 0.20120233297348022, 0.2207193225622177, -1.0371179580688477, 0.41018855571746826, -0.5230343341827393, 0.8535118103027344, -0.8119668960571289, -0.19547997415065765, 0.12827889621257782, 0.007064395118504763, -0.7994173765182495, 0.02243351750075817, -0.061528969556093216, -1.2022314071655273, 0.6736196279525757, 0.3127328157424927, -0.2552705407142639, 0.3665909469127655, 1.1054866313934326, 1.3631737232208252, 0.7018808722496033, 0.5522188544273376, 0.529657244682312, 1.5668094158172607, -1.0186469554901123, -0.6698273420333862, -0.9526686668395996, 0.48593321442604065, -0.15466316044330597, 0.6012988090515137, -0.5048823356628418, -0.6912400126457214, -1.311273455619812, -0.660021960735321, -0.3696902394294739, -0.5351565480232239, 0.4972885549068451, 0.7347854375839233, 0.18875083327293396, -1.5052763223648071, -0.2219894826412201, 0.5948589444160461, -0.8007091879844666, -0.1365075707435608, -0.17338505387306213, 0.022924071177840233, -0.9955036640167236, -0.9252138137817383, 0.17626188695430756, -0.03494782745838165, -0.3050433099269867, -0.4460527300834656, 0.13026054203510284, -1.5520856380462646, -0.3845612406730652, 0.6281024813652039, -1.1521731615066528, 1.5238101482391357, -0.12674589455127716, -0.9062852263450623, 0.5072059631347656, -0.5497140884399414, 0.43717777729034424, -0.003860024968162179, -0.16617286205291748, -0.7079702019691467, 0.6434969902038574, 0.014309451915323734, 1.656793236732483, 0.6000757813453674, -0.7882555723190308, -0.26992061734199524, 0.2851129472255707, 0.5021368861198425, 0.14459672570228577, 0.15051119029521942, 0.7682918310165405, -0.5013264417648315, -0.01605476811528206, 0.5100069046020508, 1.0792021751403809, -0.11218481510877609, 0.4722478985786438, -0.37260371446609497, -1.0140643119812012, 0.9971253871917725, 0.021166810765862465, 0.17182385921478271, -0.6747397184371948, -0.7949576377868652, -0.6589775085449219, 0.4038827121257782, -0.4285641610622406, -1.528010368347168, 0.427396684885025, -0.2099572867155075, 0.1509413868188858, -0.17584741115570068, -0.8221687078475952, -0.046977438032627106, -0.03223608434200287, -0.8083100318908691, -0.46593913435935974, 0.6542003750801086, 1.694038987159729, -0.8359615802764893, -0.427128404378891, 0.04873691871762276, 0.007406631950289011, -0.3289453387260437, 1.2682157754898071, -1.1394360065460205, 0.4646649658679962, -0.7251315116882324, 0.2973400950431824, -0.05140414461493492, -0.31412288546562195, -0.26773127913475037, -0.6458392143249512, 0.1737378090620041, -0.3437197804450989, -0.2897529602050781, 1.4110825061798096, 0.2103879600763321, 0.7287464737892151, -0.270878404378891, -0.26134219765663147, 0.4335786998271942, 0.7398040294647217, -0.7320587635040283, -0.5703997015953064, 0.41077035665512085, 0.19179783761501312, -0.7568258047103882, -0.9534602761268616, 0.6998715400695801, 0.8160267472267151, -0.3046477437019348, 0.04380301386117935, 0.17587442696094513, -0.33566993474960327, 0.3811063766479492, 0.669460654258728, 0.7668717503547668, 0.37024763226509094, 0.09498153626918793, 0.3251849114894867, 0.4737875759601593, -0.3632183074951172, -0.6525329947471619, 0.6954897046089172, 0.5073872804641724, 1.4390995502471924, 0.334504634141922, -1.0245692729949951, 0.032056502997875214, -0.03320892155170441, 0.9033438563346863, 1.3431074619293213, 0.5241203308105469, 0.06368648260831833, -0.7309592962265015, -0.7369775772094727, -0.6900070905685425, 0.25755977630615234, -0.8065442442893982, -0.06226752698421478, 0.06795545667409897, -0.37484070658683777, 0.5078448057174683, 0.7240502834320068, 1.3057661056518555, -1.0119980573654175, -0.33031126856803894, -0.5855526924133301, -0.3287082016468048, -0.9025992751121521, -0.6673476696014404, -0.30180639028549194, -0.4109877049922943, -0.745727002620697, -0.33046039938926697, -0.4867434799671173, 0.6253494620323181, -0.55113285779953, 1.06182062625885, -0.4452822506427765, -0.2379857450723648, 1.1729284524917603, 0.0711345225572586, -0.13813930749893188, -0.3852027356624603, -0.5600733160972595, -0.4827868640422821, -0.004647817928344011, 0.45893263816833496, 0.9718586206436157, -0.21169689297676086, 0.3268548250198364, -0.8537819981575012, 0.1206897497177124, 0.35908040404319763, -0.3856574296951294, 0.8760718703269958, -0.8253308534622192, 0.3462623357772827, -0.36621659994125366, 0.8401049375534058, 0.021568186581134796, -0.23190291225910187, 0.4235035479068756, -0.20930132269859314, -0.3588793873786926, -0.17844517529010773, -0.6452884078025818, -0.21632669866085052, -0.6046397089958191, 0.3609335422515869, -0.22002901136875153, -1.1143732070922852, 0.11015719920396805, 0.02676422894001007, 0.03294721618294716, 0.5168946981430054, 0.07363613694906235, 0.2061241865158081, -0.030821608379483223, 1.1932919025421143, -0.7745959758758545, 0.9221253395080566, -0.13120056688785553, 0.07473006844520569, -0.11601150780916214, -0.18105967342853546, -0.46393734216690063, -0.6683273315429688, -0.5355110764503479, -0.21417714655399323, -0.8213006854057312, 0.7600343227386475, -0.511616587638855, -0.6977400183677673, -0.5399587154388428, -1.208638072013855, -0.1311132162809372, -0.201139435172081, -0.4423683285713196, -0.47894999384880066, -0.7634386420249939, -0.5288448333740234, -0.33736106753349304, -0.28322839736938477, -0.7272471785545349, 0.717284083366394, 0.46907857060432434, -0.3564397394657135, -0.23194950819015503, 0.08806262910366058, 0.11276927590370178, 0.41844090819358826, -0.17993904650211334, 0.9627774953842163, 0.03740474581718445, -0.6840149164199829, -0.3085758090019226, -0.26243624091148376, 0.2520467936992645, -0.16547656059265137, -0.10150469839572906, -0.7768587470054626, 0.580520510673523, 0.07429095357656479, -0.6558219194412231, 0.17894533276557922, 0.2990613281726837, 0.12658396363258362, 0.4481910765171051, -0.16561399400234222, -0.30036768317222595, 1.5655851364135742, -0.7022916078567505, 0.14256799221038818, -0.1343633085489273, 0.8881333470344543, 0.9593362212181091, 0.32221129536628723, 0.22226133942604065, 0.8330723643302917, -0.062426235526800156, 0.5523617267608643, -0.4921417832374573, -0.6498013734817505, -0.3742351531982422, 0.5790794491767883, 0.678932785987854, 0.527601420879364, -0.1413886994123459, -1.1903901100158691, 0.9963861703872681, -1.3546037673950195, 0.1303374469280243, 0.12148831784725189, 0.3836849629878998, -0.034778814762830734, -0.958964467048645, -0.08946751803159714, -0.7404695153236389, 0.7220139503479004, 0.1918192356824875, -0.22408895194530487, -0.1274351179599762, -0.13782988488674164, -0.05558345839381218, -0.5814155340194702, 0.661206841468811, -0.3162263035774231, 0.2485714703798294, 14.020476341247559, 0.33994388580322266, 0.3491308391094208, 0.22613932192325592, 0.8319581747055054, 0.6311489343643188, -0.4525529146194458, 0.015087784267961979, -0.8373897075653076, -0.9356869459152222, 1.1076059341430664, 0.6857219934463501, -0.2101014107465744, 0.057093001902103424, -0.005434639751911163, -0.3541862964630127, -0.7331205010414124, 1.0675159692764282, 1.0611225366592407, -0.9362074732780457, 0.6513185501098633, 0.1114206612110138, -0.12943683564662933, 0.1313892900943756, 0.865451991558075, 0.8925741314888, -0.05325979366898537, -0.56598299741745, 0.5254907011985779, 0.407236784696579, 0.8583740592002869, 0.07623200118541718, 0.3393838703632355, 0.2795102298259735, -0.9548542499542236, -0.33569595217704773, -0.7048130631446838, -0.801063060760498, 0.3145464360713959, -0.4188454747200012, -0.439812570810318, -0.18454010784626007, -0.23205581307411194, 0.01824822835624218, -0.4157277047634125, 0.7843701243400574, -0.511788010597229, 0.29347363114356995, 0.22018027305603027, -0.03151398524641991, 0.15398818254470825, 0.8739063143730164, 0.5715221166610718, -0.7741523385047913, 0.0979875847697258, 0.6172094941139221, 0.2761397063732147, 0.7492660284042358, -0.4299722909927368, 0.06280318647623062, -0.3808271586894989, 0.10981263965368271, -0.5616587400436401, 0.938793420791626, -0.01268163975328207, 0.6671853065490723, -0.4820985794067383, 0.1804594099521637, 0.22541868686676025, 0.6149434447288513, -0.059532567858695984, 0.028499312698841095, -0.20769457519054413, -0.2376963496208191, 0.35174715518951416, 0.5922712087631226, 0.18138381838798523, -0.4610389173030853, -0.41591405868530273, -0.18470869958400726, 0.6681810617446899, -1.4420056343078613, -0.9216928482055664, 1.2676470279693604, -0.24472597241401672, -0.8868882060050964, -0.048131074756383896, -0.9325754642486572, -0.43257278203964233, 0.17823930084705353, -1.4769644737243652, -1.0289994478225708, -0.32599934935569763, 0.13398531079292297, 0.01875266060233116, 0.24686037003993988, 1.4056072235107422, -0.5523589849472046, -0.009034291841089725, -0.5367351174354553, -0.7049200534820557, -0.02141425386071205, 0.24904091656208038, -0.84282386302948, 0.40853363275527954, 0.37185001373291016, 0.31054288148880005, -0.3155694007873535, 0.045256976038217545, -0.15213873982429504, -0.5821342468261719, 0.060819726437330246, 0.2679864764213562, -1.557731032371521, -0.8597341775894165, -0.5318993926048279, -0.7993870973587036, -0.1556844413280487, 0.8705052137374878, 0.21789109706878662, 0.22885653376579285, -0.0791330337524414, -0.5599819421768188, 0.06240759417414665, -1.0902553796768188, 0.27290841937065125, -0.07930763810873032, -0.5801014304161072, -1.0017441511154175, 0.07470899075269699, 0.8332427144050598, -0.9527714252471924, -0.07955600321292877, -0.3291899859905243, -0.023606745526194572, -0.035748038440942764, 0.9554092884063721, -0.3532439172267914, 0.5769897699356079, 0.17693611979484558, -0.44138213992118835, -0.4518238604068756, 0.41305777430534363, -0.5279240012168884, -0.06556200236082077, 0.32525569200515747, 0.7489864826202393, -0.12118762731552124, 0.039355285465717316, 1.3702527284622192, 0.719463586807251, -0.5670081377029419, -0.250227689743042, 0.3969722092151642, 0.006700931116938591, -0.5320203900337219, 0.07707451283931732, -0.5210515260696411, -0.4126278758049011, 0.29845744371414185, 0.8011093735694885, 1.1495208740234375, -0.35533326864242554, -0.37361764907836914, 0.5947217345237732, -0.060778021812438965, -0.045870617032051086, 0.18712608516216278, -0.5258838534355164, -1.679692268371582, -0.4339211583137512, -0.4924057126045227, 0.3663339912891388, -1.722760558128357, -0.5865383148193359, 0.9048125743865967, -0.1428261399269104, 0.33007586002349854, 0.11733471602201462, -0.14760586619377136, -0.36039790511131287, -0.5297694206237793, -1.0666199922561646, 0.8276278972625732, 1.328480839729309, -0.5563850402832031, 0.20147278904914856, -0.5359318852424622, -0.617982804775238, 0.17944690585136414, 0.02467474900186062, -0.03211914002895355, -1.0620087385177612, -1.0934176445007324, 0.18688659369945526, 0.19809646904468536, 0.472828209400177, -0.8614839911460876, 0.8953388333320618, 0.8813498020172119, 0.34702014923095703, -0.42729493975639343, 0.5440347194671631, -0.8207362294197083, -1.2834181785583496, -0.03582504019141197, -0.6818464994430542, 0.08706054091453552, 0.6024741530418396, -0.14628033339977264, -0.6882724165916443, 0.5542976260185242, -0.4355508089065552, -0.9720086455345154, -1.480532169342041, 0.39521753787994385, -0.612338662147522, 0.015457374043762684, -0.13118134438991547, -0.09407979995012283, -1.3391691446304321, -0.9083858728408813, -0.20767048001289368, 0.8316608667373657, -0.538953423500061, 1.0323444604873657, 1.5191009044647217, -1.2101835012435913, -0.292816162109375, -0.021588485687971115, 0.590546727180481, 0.33239850401878357, 1.2365657091140747, 0.2670430839061737, -0.07106499373912811, 0.33190155029296875, 0.19739952683448792, 0.13884128630161285, -0.47712692618370056, 0.26799407601356506, 0.8330361843109131, 0.12264248728752136, -0.08233847469091415, 1.194935917854309, 0.30569231510162354, -1.1333374977111816, 0.14370709657669067, -1.0859705209732056, -1.1345990896224976, -0.40062591433525085, 0.9487977027893066, -0.44626376032829285, -0.3081614077091217, -0.3771244287490845, -0.2681671679019928, 0.9042824506759644, -0.07222440838813782, -0.9261682033538818, 0.020453665405511856, -0.5829771757125854, -0.2656960189342499, 0.28432852029800415, 0.49444517493247986, -0.6363530158996582, -0.8634889721870422, -0.3935050070285797, -0.42104461789131165, -0.050975073128938675, 0.008417914621531963, -0.8394731879234314, -0.3023206293582916, 0.7407383322715759, 1.0321242809295654, 0.15075059235095978, 0.6911416053771973, 0.5746788382530212, 0.2978730797767639, 0.7465928792953491, -0.38857463002204895, -0.044436246156692505, 0.20821785926818848, 0.6175864338874817, 1.6288868188858032, -1.0119704008102417, -0.23361697793006897, -0.42379796504974365, -0.7210792303085327, 1.2783350944519043, 0.7743672132492065, 0.14090265333652496, 0.3706502318382263, -0.8078713417053223, 0.7268934845924377, -0.2451603263616562, -0.9903284907341003, -0.5960009694099426, 1.3917803764343262, 1.8318638801574707, 0.19089192152023315, -0.015590622089803219, 0.6665458083152771, 0.860144853591919, 0.5189656615257263, 0.20718912780284882, 0.8003669381141663, 0.0989624559879303, -0.5048057436943054, -0.14088557660579681, -0.3662402927875519, 0.42281100153923035, 0.006871734280139208, -0.3081600069999695, -0.17348526418209076, 0.8577585816383362, 0.18098482489585876, 1.3271143436431885, 0.6322492361068726, 0.27614274621009827, 0.8008013963699341, 0.29437845945358276, 0.6372119784355164, -0.7760176658630371, 0.23666732013225555, -0.22323478758335114, -0.5994523763656616, -0.20997372269630432, -0.6187630295753479, -0.36096978187561035, -0.6941587328910828, 0.6343690156936646, 0.5297561883926392, -0.19652390480041504, 0.11002225428819656, 1.1702817678451538, 0.6631191372871399, 0.29349592328071594, -0.832382082939148, -0.05365440621972084, 0.05422133207321167, -0.9427038431167603, 0.43261420726776123, -0.8353782296180725, 0.12966564297676086, -0.6426068544387817, -0.19042488932609558, -0.3549647927284241]}, "authors": [{"authorId": "1455698032", "name": "Ziyu Ma"}, {"authorId": "2132557255", "name": "Shutao Li"}, {"authorId": "2153219906", "name": "Bin Sun"}, {"authorId": "2282099332", "name": "Jianfei Cai"}, {"authorId": "2184972717", "name": "Zuxiang Long"}, {"authorId": "2051278867", "name": "Fuyan Ma"}], "references": [{"paperId": "ad13b213681b6f634bc83a264df246e83dd9a9d9", "title": "mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration"}, {"paperId": "124d4d374fbef2016fa9880489871a58a7450644", "title": "Improved Baselines with Visual Instruction Tuning"}, {"paperId": "00c1ff63468305ea3fa430c2b3aef156d580c4ff", "title": "PromptCap: Prompt-Guided Image Captioning for VQA with GPT-3"}, {"paperId": "93183f050e0ce0aff8ba0aa850c8353e24fb169d", "title": "Fine-grained Late-interaction Multi-modal Retrieval for Retrieval Augmented Visual Question Answering"}, {"paperId": "3099d6f4965b4d73aa1e2b2880522ec89ed2dc0a", "title": "PaLI-X: On Scaling up a Multilingual Vision and Language Model"}, {"paperId": "d3f79210b54e168c76b8c311488f42d7d1048b81", "title": "PandaGPT: One Model To Instruction-Follow Them All"}, {"paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd", "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"}, {"paperId": "205e4dcae212d74315dd9f82fec1e1d5f4a5f429", "title": "Combo of Thinking and Observing for Outside-Knowledge VQA"}, {"paperId": "81e7e82245c2f230eeb8aaaa1a2b2604c143754a", "title": "MultiModal-GPT: A Vision and Language Model for Dialogue with Humans"}, {"paperId": "d6d3604f369bb0415cbe814e43ca3131323b03e2", "title": "Otter: A Multi-Modal Model with In-Context Instruction Tuning"}, {"paperId": "0046306876ff2d5600699327e52bc29fa5e9ec91", "title": "Transfer Visual Prompt Generator across LLMs"}, {"paperId": "570079bbdd8758dfe865097e05719313c9c1301a", "title": "LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model"}, {"paperId": "7e32aac43e9f1df49e116add03327ee6f365dbf3", "title": "mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality"}, {"paperId": "ca6a2bc279be5a3349a22bfd6866ed633d18734b", "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "38fe8f324d2162e63a967a9ac6648974fc4c66f3", "title": "PaLM-E: An Embodied Multimodal Language Model"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "63483c9387d17e44eeb70c7321ad0dbb59b994fc", "title": "Universal Multimodal Representation for Language Understanding"}, {"paperId": "70feb009bc1e8b1cb8dff64bf9fd67789636438b", "title": "From Images to Textual Prompts: Zero-shot Visual Question Answering with Frozen Large Language Models"}, {"paperId": "3e8251f259dc529b3aa2366fc68c1516b202cfb9", "title": "Reveal: Retrieval-Augmented Visual-Language Pre-Training with Multi-Source Multimodal Knowledge Memory"}, {"paperId": "78281482c1fdad8e167bab39cc9955c73d58ae8f", "title": "EVA: Exploring the Limits of Masked Visual Representation Learning at Scale"}, {"paperId": "26fd105d0b5a458979c012cddb3ba2de943388c4", "title": "Plug-and-Play VQA: Zero-shot VQA by Conjoining Large Pretrained Models with Zero Training"}, {"paperId": "6f85ec89d9c07a8db4545e64888ced820370a21b", "title": "Retrieval Augmented Visual Question Answering with Outside Knowledge"}, {"paperId": "28630034bb29760df01ab033b743e30b37f336ae", "title": "PaLI: A Jointly-Scaled Multilingual Language-Image Model"}, {"paperId": "622428f5122ad12a40229e1768ecb929fd747ee7", "title": "Multimodal Learning With Transformers: A Survey"}, {"paperId": "47a67e76ed84260ff19f7a948d764005d1edf1c9", "title": "A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge"}, {"paperId": "57c64f233a0db4d17e0e750c12516364ca009fb2", "title": "REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual Question Answering"}, {"paperId": "02720ba7a4c0c70506ef63e039387c10b227d8e3", "title": "Transform-Retrieve-Generate: Natural Language-Centric Outside-Knowledge Visual Question Answering"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "1911112ab501b7a60113a71273dcd8779a3c6a04", "title": "MuKEA: Multimodal Knowledge Extraction and Accumulation for Knowledge-based Visual Question Answering"}, {"paperId": "1bfa62ddfa3f6691e0e40c06f8ead594b6449cfa", "title": "OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"}, {"paperId": "79956ac2a4164c298387546fc10139c3d5192842", "title": "Webly Supervised Concept Expansion for General Purpose Vision Models"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "ab8ee8d06ed581c876da3a2e7a5fdb1cbec21a45", "title": "KAT: A Knowledge Augmented Transformer for Vision-and-Language"}, {"paperId": "1a84bb2b59e181e3efe2a91f149d6446027a1dd6", "title": "Knowledge-Based Embodied Question Answering"}, {"paperId": "2672777d25562c9df6fc13b653181db62d39bece", "title": "An Empirical Study of GPT-3 for Few-Shot Knowledge-Based VQA"}, {"paperId": "4e92fec0a61972ae076707d0630d1333affccdfc", "title": "Weakly-Supervised Visual-Retriever-Reader for Knowledge-based Question Answering"}, {"paperId": "251c7fc5496d63a158ea9cf7e8b09a361eecf8ef", "title": "Image Scene Graph Generation (SGG) Benchmark"}, {"paperId": "63c74d15940af1af9b386b5762e4445e54c73719", "title": "VinVL: Revisiting Visual Representations in Vision-Language Models"}, {"paperId": "8dce342a435034fa0521b24b61393397df95c095", "title": "Multi-Modal Answer Validation for Knowledge-Based VQA"}, {"paperId": "b76054d7820249fd4ebd31ed8db949a8ad8b6cbc", "title": "Select, Substitute, Search: A New Benchmark for Knowledge-Augmented Visual Question Answering"}, {"paperId": "98e565fa06f6c7bf7c46833b5106b26dc45130c4", "title": "WIT: Wikipedia-based Image Text Dataset for Multimodal Multilingual Machine Learning"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "394be105b87e9bfe72c20efe6338de10604e1a11", "title": "Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts"}, {"paperId": "5e5fbc41106db9acaaf3a365801051e477f0e984", "title": "UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning"}, {"paperId": "1a9015e511ec3da873f6114eeb542905a92d7d62", "title": "KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA"}, {"paperId": "9958887e8dd5f84595818c50fb734b566996541a", "title": "ConceptBert: Concept-Aware Representation for Visual Question Answering"}, {"paperId": "0030605bfa0a11e7474a8c5ff5b00f3ccdb22b22", "title": "Boosting Visual Question Answering with Context-aware Knowledge Aggregation"}, {"paperId": "ea8c46e193d5121e440daf96edfd15a47151c293", "title": "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "ad5970584754cc7a1d91c95ab84a1e210258183a", "title": "UnifiedQA: Crossing Format Boundaries With a Single QA System"}, {"paperId": "b5ef0f91663f0cbd6910dec9a890c138f7ec10e0", "title": "Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks"}, {"paperId": "c3afcd7e57c3e04b03b0b5001a3854482fa39441", "title": "In Defense of Grid Features for Visual Question Answering"}, {"paperId": "28a786e40717f861920888e2754b9ac043a3232f", "title": "Plenty is Plague: Fine-Grained Learning for Visual Question Answering"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "79c93274429d6355959f1e4374c2147bb81ea649", "title": "LXMERT: Learning Cross-Modality Encoder Representations from Transformers"}, {"paperId": "65a9c7b0800c86a196bc14e7621ff895cc6ab287", "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"}, {"paperId": "d0818dac77eee5b970736e57a478bcedfb1b15fe", "title": "KVQA: Knowledge-Aware Visual Question Answering"}, {"paperId": "8a1744da011375d711ed75fc2d160c6fdca2cf89", "title": "Deep Modular Co-Attention Networks for Visual Question Answering"}, {"paperId": "28ad018c39d1578bea84e7cedf94459e3dbe1e70", "title": "OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge"}, {"paperId": "af1f7739283bdbd2b7a94903041f6d6afd991907", "title": "Towards VQA Models That Can Read"}, {"paperId": "36c3972569a6949ecca90bfa6f8e99883e092845", "title": "Pythia v0.1: the Winning Entry to the VQA Challenge 2018"}, {"paperId": "d2de5d94461d66e6b97e6825ae0fea3d6d925382", "title": "R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "104715e1097b7ebee436058bfd9f45540f269845", "title": "Reading Wikipedia to Answer Open-Domain Questions"}, {"paperId": "7e232313a59d735ef7c8a9f4cc7bc980a29deb5e", "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"}, {"paperId": "5582bebed97947a41e3ddd9bd1f284b73f1648c2", "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"}, {"paperId": "b60630911d7746fba06de7c34abe98c9a61c6bcc", "title": "FVQA: Fact-Based Visual Question Answering"}, {"paperId": "6acd385b2742f65359efb99543ebfb9a0d1b850f", "title": "Image Captioning and Visual Question Answering Based on Attributes and External Knowledge"}, {"paperId": "0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a", "title": "Explicit Knowledge-based Reasoning for Visual Question Answering"}, {"paperId": "97ad70a9fa3f99adf18030e5e38ebe3d90daa2db", "title": "VQA: Visual Question Answering"}, {"paperId": "dab7e605237ad4f4fe56dcba2861b8f0a57112be", "title": "Wikidata"}, {"paperId": "b3fea597033a46d5ae282464a8f16d6715187e70", "title": "ConceptNet \u2014 A Practical Commonsense Reasoning Tool-Kit"}, {"paperId": null, "title": "\u201cVicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality,\u201d"}, {"paperId": null, "title": "\u201cScaling instruction-\ufb01netuned language models,\u201d"}]}