{"paperId": "7072db6eddb85ecd2c117365d91bd694760f726e", "abstract": "Abstract Transformers are arguably the main workhorse in recent natural language processing research. By definition, a Transformer is invariant with respect to reordering of the input. However, language is inherently sequential and word order is essential to the semantics and syntax of an utterance. In this article, we provide an overview and theoretical comparison of existing methods to incorporate position information into Transformer models. The objectives of this survey are to (1) showcase that position information in Transformer is a vibrant and extensive research area; (2) enable the reader to compare existing methods by providing a unified notation and systematization of different approaches along important model dimensions; (3) indicate what characteristics of an application should be taken into account when selecting a position encoding; and (4) provide stimuli for future research.", "venue": "Computational Linguistics", "year": 2021, "citationCount": 106, "influentialCitationCount": 5, "openAccessPdf": {"url": "https://direct.mit.edu/coli/article-pdf/48/3/733/2040503/coli_a_00445.pdf", "status": "GOLD"}, "tldr": {"model": "tldr@v2.0.0", "text": "An overview and theoretical comparison of existing methods to incorporate position information into Transformer models is provided and what characteristics of an application should be taken into account when selecting a position encoding is indicated."}, "embedding": {"model": "specter_v2", "vector": [0.5661692023277283, 0.742475688457489, -0.4763875901699066, -0.4044250547885895, -0.29825258255004883, -0.6080746054649353, 0.4344024956226349, 0.44952401518821716, -0.5925509929656982, -0.5949130058288574, 1.0301917791366577, -0.15662428736686707, 0.0036855435464531183, -0.2109709233045578, 0.13424991071224213, -0.04190930351614952, -0.715167760848999, 0.302238792181015, 0.19543428719043732, -0.46568384766578674, -0.17920014262199402, -0.7533100247383118, -0.6497663259506226, 0.5912640690803528, 0.007800256367772818, 0.3610628843307495, 0.20924173295497894, 0.47315728664398193, -0.4462931752204895, 0.8052141070365906, 0.5636751055717468, -0.43259769678115845, 0.546740710735321, 0.316109299659729, -0.22893965244293213, -0.39122530817985535, 0.2651309370994568, -0.5535269975662231, -0.527428150177002, 0.9219999313354492, -0.6175561547279358, -0.02324652299284935, 0.08283305913209915, -0.8423201441764832, 0.2250889539718628, 1.862105131149292, 1.1796127557754517, 1.1288800239562988, 0.07913151383399963, -1.2336796522140503, 1.8862335681915283, -1.2001419067382812, 0.247022807598114, 1.4332269430160522, 0.6545215845108032, 0.022233717143535614, -0.3112965226173401, -0.23758120834827423, 0.5915392637252808, 0.0823906734585762, -0.8098041415214539, -0.9226282835006714, 0.2905578911304474, 0.1330387443304062, 1.5126715898513794, 0.12032198905944824, 0.12376450002193451, 0.1137351393699646, 0.026751501485705376, 1.5891460180282593, 0.29970571398735046, -0.9254460334777832, -0.5416642427444458, 0.16458655893802643, 0.4485296308994293, 0.7274089455604553, -0.8543855547904968, 0.6035141944885254, -1.0842556953430176, 0.014178126119077206, 0.5838139653205872, -0.1554497331380844, -0.39170998334884644, -0.41266563534736633, -0.6418476700782776, 0.31636133790016174, 0.0776745080947876, 0.9974017143249512, -0.4126438796520233, 0.23915621638298035, 0.509746253490448, 0.5336952805519104, -0.12117979675531387, 0.37731051445007324, 0.11668307334184647, 0.17073918879032135, -0.9242277145385742, 0.21060337126255035, 0.006047785747796297, 0.357530415058136, -0.3621937036514282, 0.4206167161464691, -0.802151083946228, 0.2674444019794464, 1.5634311437606812, -0.03270876407623291, 0.6512852907180786, -1.023520827293396, 0.2064841389656067, -0.6354598999023438, 0.44385722279548645, -0.9192118644714355, 0.09769992530345917, -0.212025448679924, 0.15551802515983582, -1.2370893955230713, -0.01338829193264246, 0.6700977683067322, -0.8048990964889526, 0.7579018473625183, -0.40477216243743896, -0.35534363985061646, 0.3766469359397888, 0.17609182000160217, 0.19638973474502563, 0.7596486806869507, 0.12659858167171478, -0.25424858927726746, 1.1227251291275024, -0.1123574748635292, -1.1435177326202393, -0.7998363375663757, 0.44166067242622375, -0.10470349341630936, -0.0665866956114769, -0.2318667322397232, -1.2109934091567993, -0.6667273640632629, -0.8677550554275513, 0.11453800648450851, -0.4352748692035675, 0.1436420977115631, 0.724161684513092, 0.47856131196022034, -1.5703532695770264, 0.9413412809371948, -0.48343420028686523, -0.12074553966522217, 0.05397147685289383, 0.2616836726665497, 0.30087700486183167, 0.1693556159734726, -1.3546429872512817, 0.2671663165092468, 0.4657078683376312, -0.31354114413261414, 0.14389830827713013, -0.7091250419616699, -1.5704163312911987, -0.20158915221691132, 0.2438143789768219, -0.13783185184001923, 1.4869834184646606, 0.2631385326385498, -1.4924061298370361, 0.6883993744850159, -0.9234429001808167, -0.01626019924879074, -0.21529348194599152, -0.3041509985923767, -0.4131729304790497, -0.40304362773895264, 0.32709455490112305, 0.30486008524894714, 0.07353619486093521, -0.5259957909584045, -0.7678611278533936, -0.3214845359325409, -0.15490056574344635, 0.35072121024131775, -0.06766735762357712, 1.2773383855819702, 0.09728965163230896, -0.25518277287483215, 1.0337530374526978, 0.9086636304855347, 0.21131229400634766, -0.35195618867874146, -0.3232767879962921, -0.9693208336830139, 0.5696425437927246, -0.17823229730129242, 1.5796711444854736, -0.7626701593399048, -0.6516079306602478, -0.12825028598308563, 0.17531968653202057, -0.15836282074451447, -0.5575156807899475, 0.9167951941490173, -0.8601387739181519, 0.44515883922576904, -0.3174249231815338, -0.6137726306915283, 0.11197969317436218, 0.08883138000965118, -0.8642862439155579, -0.20068106055259705, -0.5404862761497498, 1.0668660402297974, -1.0169594287872314, 0.15880316495895386, 0.6234018802642822, -0.11770102381706238, -0.30585798621177673, 1.149662733078003, 0.41028013825416565, -0.15340305864810944, 0.22906650602817535, -0.22440505027770996, -0.057596053928136826, 0.3609660565853119, 0.40260064601898193, -0.780222475528717, -0.8230168223381042, 1.1212488412857056, -0.37165895104408264, 0.7346940636634827, 0.041417837142944336, 0.4941863715648651, 0.010056697763502598, -0.5660216212272644, -0.15067216753959656, 0.6862457394599915, 0.0582459382712841, -0.5156469345092773, 0.2627929151058197, 0.2575642168521881, -0.20474117994308472, 0.6366679072380066, 0.8695867657661438, 0.24200749397277832, -0.44399333000183105, 0.1464526504278183, 0.2656862735748291, -0.27178755402565, 0.5973581075668335, 0.31608325242996216, 0.5725100636482239, 0.2302696704864502, 0.7241618037223816, -0.45559701323509216, 0.17930065095424652, -0.712293803691864, 0.16127575933933258, 0.1271684616804123, 0.6682789325714111, 0.6908870935440063, 0.36275553703308105, -0.5594125390052795, -0.23613616824150085, -0.5603868365287781, 0.46715426445007324, 1.580297589302063, -0.1366632729768753, -0.8683643937110901, -0.5072996616363525, -0.17798079550266266, -0.8153634071350098, 0.7618556618690491, -0.12350321561098099, 0.03467097133398056, -0.99073725938797, -0.4048498868942261, 1.021743893623352, 0.5629342198371887, 0.5781710743904114, -0.4279380142688751, -0.6302729249000549, 0.0361328087747097, -0.26985079050064087, -0.5498211979866028, -0.4781758785247803, 0.6752603054046631, -0.7717582583427429, -0.5324495434761047, 0.3551488518714905, -0.31033292412757874, 0.14889013767242432, -0.8233383893966675, 0.6715413331985474, -0.7981034517288208, 0.4211348593235016, 0.07601220905780792, 0.3961489200592041, -0.8826295733451843, -0.7589911222457886, -0.2960745096206665, 0.12072546780109406, -0.2259734719991684, 0.528797447681427, 0.5815322399139404, 0.494625985622406, 0.11937147378921509, -0.6487250924110413, 0.015962664037942886, -0.22037683427333832, 0.1160859763622284, 0.5703916549682617, 0.19201986491680145, -0.7834892868995667, -1.2871006727218628, 1.0831724405288696, 0.7222550511360168, -0.5713661313056946, 0.2966823875904083, -0.6420058012008667, -0.04849116504192352, 0.4264654815196991, 0.24794289469718933, -0.08895193040370941, -0.9204095602035522, 0.30898842215538025, 0.14993615448474884, -0.0782964676618576, 0.5929450392723083, -0.16490623354911804, 0.6797597408294678, -0.1853097379207611, 0.7409231662750244, 0.5821352005004883, 0.017791876569390297, 0.49001166224479675, -0.5013471245765686, 0.3726480305194855, 0.2946154475212097, 0.022776024416089058, -0.19922567903995514, -0.5200361013412476, -0.9244750738143921, -0.3517371416091919, -0.6186888813972473, -0.25951850414276123, -0.2731480896472931, -0.2359314113855362, -0.11614149808883667, -0.7112429141998291, 0.2838548719882965, -1.1849541664123535, -0.030657775700092316, -0.16039523482322693, -0.42419785261154175, -0.08168725669384003, -0.75890052318573, -1.3240869045257568, -0.5414077043533325, -0.2652808427810669, -0.7234644889831543, 0.3355928063392639, -0.4256817102432251, -0.5233330130577087, -0.5420703291893005, -0.01445831824094057, -0.40225061774253845, 0.864231526851654, -0.7017597556114197, 1.3990813493728638, -0.43306437134742737, 0.04005264490842819, 0.1552008092403412, 0.5468366742134094, 0.5372701287269592, 0.4379051625728607, -0.0010640702676028013, -0.1849270612001419, 0.3900657296180725, 0.25898510217666626, 0.31208863854408264, -0.3418302834033966, 0.4010266661643982, 0.2949274778366089, -0.6150813102722168, -0.4554518759250641, -0.1337042599916458, 1.2235450744628906, -0.009466012939810753, 0.21097105741500854, 0.11860696971416473, 0.9777299761772156, 0.7144361734390259, -0.09665527939796448, 0.26966041326522827, 0.7519438862800598, 0.5262213945388794, 0.3887641131877899, 0.22905829548835754, 0.20153599977493286, -0.5793325304985046, 0.570582389831543, 1.950368881225586, -0.02392696961760521, -0.14069871604442596, -1.293795108795166, 0.6401864886283875, -1.336647391319275, -0.834192156791687, 0.718032717704773, 0.9727127552032471, 0.3831299841403961, -0.5530228614807129, -0.4294801652431488, 0.5838542580604553, 0.6445204615592957, 0.6441874504089355, 0.6080735325813293, -0.3863030672073364, 0.26145139336586, 0.5672879219055176, 0.24421438574790955, 1.0669684410095215, -0.6734187602996826, 0.9088401198387146, 14.49712085723877, 0.34650346636772156, -0.17391131818294525, 0.20473645627498627, -0.016659094020724297, 0.8027841448783875, -0.8356946706771851, 0.1319790780544281, -1.0982624292373657, -0.13837219774723053, 1.0114539861679077, -0.22474123537540436, 0.5020612478256226, -0.2698209285736084, 0.19496631622314453, 0.2050575166940689, -0.9146620631217957, 0.7351946830749512, 0.43394550681114197, -0.7323110699653625, 0.6384700536727905, 0.08356688916683197, -0.6676700115203857, 0.0056663635186851025, 0.412269651889801, 0.26312536001205444, 0.5564852356910706, -0.5298559069633484, 0.9780211448669434, -0.17724891006946564, 0.2596464157104492, -0.5032196044921875, 0.6015480160713196, 0.5451048612594604, -1.3650226593017578, -0.2252912074327469, -0.4993843734264374, -1.263187289237976, 0.540306806564331, 0.18698208034038544, -0.8181654214859009, -0.48607873916625977, -0.31655406951904297, 0.7824642062187195, 0.41367271542549133, 0.1457386612892151, -0.3604734241962433, 0.9241619110107422, -0.357570081949234, 0.08963993936777115, 0.17137028276920319, 0.39366307854652405, 0.9470395445823669, -0.29160070419311523, 0.13736337423324585, 0.5382982492446899, 0.22984015941619873, 0.03819918632507324, 0.050203561782836914, 0.06837858259677887, -0.6040226817131042, -0.5507810115814209, 0.21833722293376923, 0.5266358852386475, -0.08087433874607086, 0.28032851219177246, 0.5015386939048767, 0.18877370655536652, 0.2854298949241638, -0.17926539480686188, 0.10671454668045044, -0.20578308403491974, 0.4892538785934448, 0.4231022596359253, 0.17377696931362152, 0.40565329790115356, 0.10530984401702881, -0.1321827471256256, -0.7673227787017822, -0.3119796812534332, 0.2904796004295349, -0.47426295280456543, -0.5794124603271484, 1.2072792053222656, 0.18862693011760712, -0.4687488377094269, 0.25605496764183044, -1.1810749769210815, 0.054564736783504486, -0.1591804325580597, -1.1043897867202759, -0.5108674764633179, 0.33305659890174866, -0.035059720277786255, -0.3180396258831024, 0.4481698274612427, 1.1291511058807373, -0.19655604660511017, -0.10303990542888641, -0.09020183980464935, -0.3843081295490265, 0.4176458418369293, -0.5991058945655823, -1.3851903676986694, 0.3322238028049469, 0.42794692516326904, 0.2941174805164337, 0.9214634895324707, 0.09333209693431854, -0.01983887329697609, -0.4635971188545227, 0.213578000664711, 1.4324373006820679, -0.9390929937362671, -0.23570755124092102, -0.750690758228302, -0.9286466836929321, 0.4923292100429535, 0.5222958326339722, -0.5453824996948242, 0.5938379764556885, 0.018129078671336174, -0.19157710671424866, -0.2181762009859085, -0.5862609148025513, 0.14239747822284698, 0.7594580054283142, -0.9055050611495972, -1.117010235786438, -0.7384979724884033, 0.1338072270154953, -1.389447569847107, -0.4016852080821991, -0.021951349452137947, 0.019876321777701378, -0.031834520399570465, 0.8328227996826172, -0.4501827359199524, 0.1003340557217598, 0.26901695132255554, -0.6513717770576477, -1.0385702848434448, -0.5449269413948059, -0.8259719610214233, 0.5065356492996216, 0.2419382929801941, 0.8094395399093628, -0.3721149265766144, 0.021259279921650887, 0.6642098426818848, -0.1837378442287445, -0.23714689910411835, -0.9689315557479858, -0.04269688203930855, -0.3057021200656891, -0.7229573726654053, 0.2815396785736084, -0.18279632925987244, 0.2030998319387436, 0.332479864358902, 0.6857286691665649, 0.7850591540336609, -0.23813292384147644, -0.7529302835464478, -0.4922967255115509, -0.30924752354621887, 0.46852171421051025, -0.3264320194721222, -0.8070868253707886, -1.4047373533248901, 0.2347671240568161, -1.104156732559204, 0.6680117249488831, -1.3711514472961426, -0.7321139574050903, 0.01615240052342415, -0.39071300625801086, 0.4573325514793396, 0.7156248092651367, -0.7594435214996338, -0.48486557602882385, -0.2812671661376953, -0.3424406349658966, 0.7031357884407043, 0.10785248875617981, -0.5767810940742493, 0.13252365589141846, 0.20639553666114807, -0.04817213863134384, 0.47462087869644165, 0.3042272925376892, -0.5998695492744446, -0.9178774356842041, -1.352961540222168, 0.28364866971969604, -0.0036907587200403214, -0.3071994185447693, -0.18230989575386047, 0.7962835431098938, 0.33928996324539185, -0.5108960270881653, -0.001208484754897654, 0.45554792881011963, -1.1811163425445557, -0.2515579164028168, 0.23277568817138672, -0.8186761140823364, 0.3416255712509155, -0.20726537704467773, -0.776224672794342, -0.6797581315040588, 0.5362004041671753, -0.19134604930877686, -1.2365585565567017, -0.9833618402481079, 0.2761334180831909, -1.1617110967636108, -0.11231093853712082, -0.12187487632036209, -0.8454734086990356, -0.5756388306617737, 0.01148965209722519, 0.058604929596185684, -0.06692419201135635, -0.2626165449619293, 1.09462571144104, 0.7210791707038879, -0.98810213804245, 0.4031207263469696, 0.42998942732810974, -0.08687862753868103, -0.46822047233581543, -0.33677271008491516, 0.07838725298643112, -0.2694888114929199, 0.7699031829833984, 0.0932437926530838, 0.20752720534801483, -1.645768165588379, -0.6999871134757996, 0.5420368909835815, -0.2760981023311615, -0.22005870938301086, 1.1835819482803345, -0.6708152890205383, -0.9595000743865967, 0.08861638605594635, -1.692594289779663, -0.9031969904899597, -0.04014056548476219, 0.7976787090301514, 0.48477789759635925, -0.036334406584501266, -0.5344852209091187, -0.6889727115631104, 0.10954631119966507, -0.10349820554256439, -0.766136109828949, 0.4258576035499573, -0.272556871175766, -0.7171748280525208, 1.1549595594406128, 0.26811617612838745, -0.1540362685918808, -0.24525177478790283, -0.3058275878429413, -0.1483149379491806, -0.33774083852767944, 0.43394821882247925, -0.09623924642801285, -0.2657324969768524, 0.5177472829818726, 0.31317728757858276, 0.45011764764785767, -0.24940820038318634, -0.09682371467351913, 0.25971806049346924, 0.44125300645828247, 0.83011394739151, -0.7449567914009094, -0.8125776052474976, 1.5418869256973267, 1.3660229444503784, -0.2840438783168793, -0.0620715357363224, -0.7503396272659302, -0.5717670917510986, 1.0345733165740967, -0.08982647210359573, 0.23492905497550964, 1.0496068000793457, 0.11747144907712936, 0.7359112501144409, 0.05917863920331001, -0.3242620527744293, -0.05079546570777893, 0.37365275621414185, 1.3597211837768555, 0.9177998900413513, 0.4902889132499695, 0.09328636527061462, 0.9471879005432129, -0.42751550674438477, 0.0997188612818718, 0.6650747656822205, 1.0195468664169312, -0.5421105623245239, -0.583289384841919, 0.335568368434906, 0.7366064190864563, -0.779172420501709, -0.9459674954414368, -0.11551500856876373, 0.5586795806884766, 0.14472223818302155, 0.7274590134620667, 0.7705854773521423, -0.0915345624089241, 0.5356126427650452, 0.36932411789894104, 0.48882630467414856, -0.9811190366744995, -0.31029078364372253, -0.3225864768028259, -0.19404014945030212, -0.3724043369293213, -0.5770916938781738, -0.6966153979301453, -0.6554602980613708, 0.17602422833442688, 0.28247353434562683, 0.586020290851593, 0.1709945648908615, 1.128909945487976, 0.3097982704639435, 0.22508473694324493, -0.5114883780479431, -0.02063361555337906, -0.5291547179222107, -0.7910283207893372, -0.25505661964416504, -0.9997761845588684, -0.20475541055202484, -0.15284188091754913, -0.1545923799276352, -0.2020367830991745]}, "authors": [{"authorId": "35501453", "name": "Philipp Dufter"}, {"authorId": "49772110", "name": "Martin Schmitt"}, {"authorId": "144418438", "name": "Hinrich Sch\u00fctze"}], "references": [{"paperId": "1dbb523a6555d6e0c5727620e2b57daaa5b79dc0", "title": "Convolutions and Self-Attention: Re-interpreting Relative Positions in Pre-trained Language Models"}, {"paperId": "7509c66a666e2e3f14bc8676b969b945ee6e136f", "title": "CAPE: Encoding Relative Positions with Continuous Augmented Positional Embeddings"}, {"paperId": "1006d191e9eb5b4dbc35fc0bb389328ddc75cba7", "title": "ByT5: Towards a Token-Free Future with Pre-trained Byte-to-Byte Models"}, {"paperId": "08ffdec40291a2ccb5f8a6cc048b01247fb34b96", "title": "Relative Positional Encoding for Transformers with Linear Complexity"}, {"paperId": "a83902f8b3aadfda633968a840ca1738bedef837", "title": "Modeling Graph Structure via Relative Position for Text Generation from Knowledge Graphs"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "0822f8d7e6a72a65e65f147d3a8d8fccd485da40", "title": "Shortformer: Better Language Modeling using Shorter Inputs"}, {"paperId": "50a77f5996a28662d26b85c0020be84edb07050f", "title": "Improving Zero-Shot Translation by Disentangling Positional Information"}, {"paperId": "849b88ddc8f8cabc6d4246479b275a1ee65d0647", "title": "A Generalization of Transformer Networks to Graphs"}, {"paperId": "ac4ae352e2434d4a71c6a79bf5f93df5f600b058", "title": "Increasing Learning Efficiency of Self-Attention Networks through Direct Position Interactions, Learnable Temperature, and Convoluted Attention"}, {"paperId": "26ba63ec6718ca27c6dfe7b0f65b230e77e85328", "title": "Incorporating Noisy Length Constraints into Transformer with Length-aware Positional Encodings"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "cf469e6fffbc5344572959a3f71d03b8037f284b", "title": "DA-Transformer: Distance-aware Transformer"}, {"paperId": "4889ba5a8ae8b2169dd44d1d3a605bf9820bae8d", "title": "What Do Position Embeddings Learn? An Empirical Study of Pre-Trained Language Model Positional Encoding"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "84476fdf6ead3553f4493dff8e02308439d6222b", "title": "Improve Transformer Models with Better Relative Position Embeddings"}, {"paperId": "8256f48f759cf85044db251cc512f965834945b3", "title": "Rethinking Positional Encoding in Language Pre-training"}, {"paperId": "024a2c03be8e468e7c4fdf9bda36cdc0eaae85fb", "title": "Array programming with NumPy"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "07a9f47885cae97efb7b4aa109392128532433da", "title": "Hard-Coded Gaussian Attention for Neural Machine Translation"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "39283c3d6262b24bd61c88038353f3ed0145b6e4", "title": "Self-Attention with Cross-Lingual Position Representation"}, {"paperId": "e8984c6e6c24aab26c332728a5fff616dfb3adbb", "title": "Learning to Encode Position for Transformer with Continuous Dynamical Model"}, {"paperId": "12cf222b05755a59655a5846f990c2aaf6065086", "title": "On the Importance of Word Order Information in Cross-lingual Sequence Labeling"}, {"paperId": "78542c2be9bb853a4e04642f2d315cfb0c6d94b3", "title": "Graph-Bert: Only Attention is Needed for Learning Graph Representations"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "d0e28f5dc1feae19e41087a92a87992977fd85af", "title": "Encoding word order in complex embeddings"}, {"paperId": "bb98bc96e02396d199fc899287d9b84393c86e79", "title": "Graph Transformer for Graph-to-Sequence Learning"}, {"paperId": "d6b414487787d0b6efd735a3236a690ad13aae70", "title": "TENER: Adapting Transformer Encoder for Named Entity Recognition"}, {"paperId": "6fec3e579c7cd4f13bdabbee2b6ac2e8ff5941c6", "title": "Unsupervised Cross-lingual Representation Learning at Scale"}, {"paperId": "f3f90b45f4d9916d65731a1b11e0c2483605c79f", "title": "On the Relation between Position Information and Sentence Length in Neural Machine Translation"}, {"paperId": "4d1316798f575b564d0bd3da96a8b02be760e21c", "title": "An Augmented Transformer Architecture for Natural Language Generation Tasks"}, {"paperId": "37a23c43ddf09ea97b82b38e2827a2229cfae545", "title": "Novel positional encodings to enable tree-based transformers"}, {"paperId": "9e9d919c1de684ca42c8b581ec62c7aa685f431e", "title": "On the Cross-lingual Transferability of Monolingual Representations"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "34e75b1eb986ceab79e5c463cf1a82bcf4e87944", "title": "Non-autoregressive Transformer by Position Learning"}, {"paperId": "4ca4e7ed290617aab8b4d99294d10b0ac8372967", "title": "Self-Attention with Structural Position Representations"}, {"paperId": "afc1824a051f686e18ad87e1244bb0926a361021", "title": "Modeling Graph Structure in Transformer for Better AMR-to-Text Generation"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "f89d2da991935549b109d780be3351e0dda92a8f", "title": "Assessing the Ability of Self-Attention Networks to Learn Word Order"}, {"paperId": "ff482c357716e884f64e8e54d8f1307df6e061b5", "title": "Positional Encoding to Control Output Sequence Length"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "adc276e6eae7051a027a4c269fb21dae43cadfed", "title": "DiSAN: Directional Self-Attention Network for RNN/CNN-free Language Understanding"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "b8bc86a1bc281b15ce45e967cbdd045bcf23a952", "title": "Fully Character-Level Neural Machine Translation without Explicit Segmentation"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e", "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"}, {"paperId": "27725a2d2a8cee9bf9fffc6c2167017103aba0fa", "title": "A Convolutional Neural Network for Modelling Sentences"}, {"paperId": "93c20e38c85b69fc2d2eb314b3c1217913f7db11", "title": "Generating Text with Recurrent Neural Networks"}, {"paperId": "dc35daba3fb34b2e6a5b12530badb7b799262bbf", "title": "On Position Embeddings in BERT"}, {"paperId": "a1ad15d2333cf9d9b55bbc97a3aacd244a8b9fdf", "title": "Demystifying the Better Performance of Position Encoding Variants for Transformer"}, {"paperId": null, "title": "Distributed Representations for Multilingual Language Processing"}, {"paperId": null, "title": "How important is word order for speci\ufb01c tasks? For many tasks, treating sentences as bag-of-words could be suf\ufb01cient"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "8f9089912cd4998cc696949001e601e6df3b7376", "title": "Analysis of Positional Encodings for Neural Machine Translation"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Universal language model \ufb01ne-tuning for text classi\ufb01cation"}, {"paperId": null, "title": "showcasing that position information in Transformer is a vibrant and extensive research area"}, {"paperId": null, "title": "enabling the reader to compare existing methods by providing a uni\ufb01ed notation and systematization of different approaches along important model dimensions"}]}