{"paperId": "73290ecbec2f38d1d647ddef1ada69cee41725b3", "abstract": "Large Language Models (LLMs) are trained with a pre-defined context length, restricting their use in scenarios requiring long inputs. Previous efforts for adapting LLMs to a longer length usually requires fine-tuning with this target length (Full-length fine-tuning), suffering intensive training cost. To decouple train length from target length for efficient context window extension, we propose Positional Skip-wisE (PoSE) training that smartly simulates long inputs using a fixed context window. This is achieved by first dividing the original context window into several chunks, then designing distinct skipping bias terms to manipulate the position indices of each chunk. These bias terms and the lengths of each chunk are altered for every training example, allowing the model to adapt to all positions within target length. Experimental results show that PoSE greatly reduces memory and time overhead compared with Full-length fine-tuning, with minimal impact on performance. Leveraging this advantage, we have successfully extended the LLaMA model to 128k tokens using a 2k training context window. Furthermore, we empirically confirm that PoSE is compatible with all RoPE-based LLMs and position interpolation strategies. Notably, our method can potentially support infinite length, limited only by memory usage in inference. With ongoing progress for efficient inference, we believe PoSE can further scale the context window beyond 128k.", "venue": "arXiv.org", "year": 2023, "citationCount": 38, "influentialCitationCount": 1, "openAccessPdf": {"url": "https://arxiv.org/pdf/2309.10400", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "Positional Skip-wisE (PoSE) training that smartly simulates long inputs using a fixed context window is proposed, and can potentially support infinite length, limited only by memory usage in inference."}, "embedding": {"model": "specter_v2", "vector": [0.20701861381530762, 0.4292377531528473, -0.6191885471343994, -0.35197383165359497, -0.41033703088760376, -0.1679452806711197, 0.6169331073760986, -0.17031078040599823, -0.5648123025894165, -0.12396261841058731, 0.6340801119804382, -0.15232087671756744, 0.7553693652153015, 0.23645131289958954, -0.4602532982826233, 0.013294191099703312, -1.3383361101150513, -0.044659990817308426, 0.019758988171815872, -0.11753682792186737, -0.4223460853099823, -0.7073197364807129, -0.8357475399971008, 0.4725898802280426, 0.14433653652668, 0.3589552044868469, 0.4006415903568268, 0.9284929037094116, -0.5222514271736145, 0.09790963679552078, 0.19451023638248444, -0.2166013866662979, 0.08377909660339355, -0.023918597027659416, -0.30580997467041016, -0.42963889241218567, 0.345193088054657, -0.6588605046272278, -0.27766740322113037, 0.43699225783348083, -0.26695021986961365, 0.6100789904594421, -0.018630554899573326, -0.5185840129852295, -0.2534303367137909, 1.347971796989441, 0.5968785881996155, 0.6241569519042969, -0.5017150640487671, -0.7284784317016602, 1.244556188583374, -1.467522382736206, 0.2259584367275238, 1.5050681829452515, 0.47990238666534424, 0.6425582766532898, -0.49567341804504395, -0.4054071009159088, 0.9254533648490906, 0.03509240597486496, -0.7790722846984863, -0.4397510588169098, -0.16755637526512146, 0.23782901465892792, 1.9678680896759033, -0.10758566111326218, 0.031658973544836044, 0.8578739762306213, -0.21246708929538727, 1.4910104274749756, -0.25162771344184875, -1.0836130380630493, -0.22296686470508575, 0.02224447764456272, 0.2511483132839203, 0.47018465399742126, -0.461323618888855, 0.12178277224302292, -0.9717187881469727, -0.23616939783096313, 0.21703851222991943, -0.22293752431869507, 0.6035473942756653, 0.11634650081396103, -0.5145435333251953, 0.5459087491035461, 0.06552755832672119, 0.8340036273002625, 0.23521828651428223, 0.7140908241271973, 0.5791078209877014, 0.18662230670452118, 0.2556611895561218, 0.18383122980594635, -0.4648377001285553, 0.14936846494674683, -1.0590091943740845, 0.34220921993255615, -0.1979970782995224, 0.7975698113441467, -0.31598570942878723, 0.19865737855434418, -0.8773741126060486, 0.22758956253528595, 1.3643934726715088, 0.2694624364376068, 0.34448540210723877, -0.6562588810920715, 0.5184836387634277, -0.7627706527709961, 0.123064324259758, -0.1632995754480362, -0.2621086835861206, -0.10030003637075424, -0.33449408411979675, -1.268557071685791, -0.12731683254241943, -0.0828697681427002, -0.6429138779640198, 1.0074341297149658, 0.09013232588768005, 0.46098777651786804, 0.1330178827047348, 0.1956397294998169, 0.37751874327659607, 0.8793323040008545, 0.3854016959667206, -0.13783688843250275, 0.8417168259620667, -1.0323035717010498, -0.4847937226295471, -1.183799147605896, 1.0356265306472778, -0.2664088010787964, 0.576403021812439, -0.39446380734443665, -1.1127949953079224, -0.8271215558052063, -1.1129183769226074, -0.1910397708415985, -0.754597008228302, 0.4096982777118683, 1.0592995882034302, 0.5782510042190552, -0.6311889290809631, 0.7816821336746216, -0.4538385570049286, -0.016814252361655235, 0.15273450314998627, 0.08367276191711426, 0.36155176162719727, -0.327605664730072, -1.830653190612793, 0.18291062116622925, 0.45206165313720703, -0.33186957240104675, 0.03165715932846069, -0.7495961785316467, -1.2841919660568237, -0.12464073300361633, 0.3839627504348755, -0.2085784375667572, 1.3033862113952637, -0.02615276910364628, -1.3452394008636475, 0.49712496995925903, -0.5700975060462952, -0.1388036608695984, 0.24437996745109558, -0.4271724224090576, -0.6574945449829102, -0.7003499269485474, -0.4564807713031769, 0.5283070206642151, 0.4387907087802887, 0.08082957565784454, -0.03616996109485626, 0.202037513256073, -0.19207674264907837, -0.055499423295259476, 0.01859728805720806, 0.8800004720687866, -0.3526345193386078, -0.47441864013671875, 0.15742574632167816, 0.5363900661468506, -0.13585534691810608, -0.5001237392425537, -0.19570082426071167, -0.9381669759750366, 0.8442538976669312, -0.023900598287582397, 1.3622901439666748, -0.7643337845802307, -0.9395462870597839, -0.12993045151233673, -0.6359051465988159, 0.13084551692008972, -0.8689096570014954, 0.6457042098045349, 0.01858600787818432, 0.33718451857566833, -0.12626326084136963, -1.4958910942077637, -0.05423704907298088, -0.0783941000699997, -0.8363568782806396, -0.3988095223903656, 0.09353752434253693, 1.0732362270355225, -1.0335843563079834, 0.06107379496097565, 0.0969265028834343, 0.31495630741119385, -1.1795415878295898, 1.1887575387954712, -0.8457404971122742, 0.37433621287345886, -0.10204442590475082, -0.12397027015686035, -0.047250911593437195, -0.22599022090435028, 0.4984670877456665, -0.06060410290956497, -0.11195138841867447, 0.7942173480987549, -0.5991631746292114, 1.5352447032928467, -0.8183445334434509, 0.4160690903663635, 0.06499753892421722, -0.1426457017660141, -0.13821253180503845, 0.18945619463920593, -0.3793029189109802, -0.038274798542261124, 0.14506030082702637, 0.186887726187706, -0.6484551429748535, 0.008199864998459816, 1.005737543106079, 0.9374280571937561, -0.349902480840683, 0.1726638674736023, 0.22182315587997437, -0.07852990925312042, 0.4726356863975525, 0.388502299785614, 0.3361349403858185, 0.5859100222587585, 0.2875503897666931, 0.22950521111488342, 0.32133832573890686, -0.9320328831672668, -0.17490795254707336, 0.6122887134552002, 0.694175660610199, 0.7708867788314819, 0.3837147355079651, -0.6573936939239502, -0.5296380519866943, -0.0006372834905050695, 0.40311405062675476, 2.035107374191284, -0.38118061423301697, -0.1502893716096878, -0.8210062384605408, -0.2748813331127167, -0.11590570956468582, 0.1707012951374054, -0.37119925022125244, 0.35234352946281433, -0.891333818435669, -0.9753642082214355, 0.9239123463630676, 0.33594319224357605, 0.517546534538269, -0.7820807099342346, -0.18628841638565063, -0.06454011052846909, 0.3011022210121155, -0.8994065523147583, -0.6306294798851013, 0.1792161762714386, -0.7648102641105652, 0.26018190383911133, 0.24991647899150848, 0.038534216582775116, 0.026874711737036705, -0.976858913898468, 0.7802910804748535, -0.5456700325012207, -0.22673194110393524, -0.0886939987540245, 0.2529342472553253, -0.29407644271850586, -0.9663208723068237, 0.5156083106994629, 0.3610464334487915, -0.12535360455513, 0.374247282743454, 0.49873873591423035, 0.19525688886642456, -0.25751781463623047, -0.5201066732406616, 0.2182256579399109, 0.2152910828590393, 0.10488404333591461, 0.8013644218444824, -0.7415301203727722, 0.3345775306224823, -1.5386133193969727, 0.6357289552688599, 0.07852790504693985, -0.4096175730228424, 0.27605316042900085, -0.640587568283081, -0.22270748019218445, 0.44332873821258545, -0.8313062191009521, -0.49313589930534363, -0.752496063709259, -0.0631496012210846, -0.14664940536022186, -0.26359978318214417, 0.07929511368274689, 0.07422931492328644, 0.5222166180610657, -0.0363999605178833, 0.3998350501060486, 0.2941434681415558, -0.39664334058761597, 0.92505943775177, -0.5110569596290588, 0.33316007256507874, 0.1570383459329605, -0.07652726024389267, 0.02598467282950878, -0.15058644115924835, -0.9253708124160767, -0.3890172243118286, -0.47117099165916443, -0.4936981201171875, 0.006792146246880293, -0.06314748525619507, -0.5536820888519287, -0.7057061791419983, 0.024775845929980278, -0.8415710926055908, -0.5632104873657227, 0.42669448256492615, -0.06439273804426193, -0.08535546064376831, -0.8974771499633789, -1.2345099449157715, -0.608110785484314, -0.6631706357002258, -0.8343217372894287, 0.5255929827690125, 0.07897938042879105, -0.5590718388557434, -0.8459494113922119, -0.0752534419298172, -0.3765423595905304, 0.9829971194267273, -0.6224240660667419, 0.6853454113006592, -0.10163237899541855, -0.21786214411258698, -0.3830304741859436, 0.49759140610694885, 0.533816933631897, -0.3257408142089844, 0.26458948850631714, -1.1380690336227417, 0.06019365042448044, -0.4844955503940582, -0.3783281743526459, 0.2889018952846527, 0.370048463344574, 0.6580728888511658, -0.26787644624710083, -0.5769346952438354, 0.4149518311023712, 1.2139357328414917, -0.8008137345314026, 0.06591449677944183, 0.04982822760939598, 0.8377506136894226, 0.06138160079717636, -0.04955074563622475, 0.6786664128303528, 0.1483510434627533, 0.29908958077430725, 0.13579227030277252, 0.3130042850971222, 0.02246692031621933, -0.7049554586410522, 0.6870946884155273, 1.4183669090270996, 0.5479884743690491, 0.1512041687965393, -0.8497254848480225, 0.7988998889923096, -0.9836596250534058, -0.8548012375831604, 0.862748920917511, 0.9664402008056641, 0.6878364682197571, -0.35310232639312744, -0.39705774188041687, -0.45509853959083557, 0.2564575970172882, 0.8827027082443237, -0.48714298009872437, -0.9101381897926331, 0.07020857185125351, 0.13014669716358185, -0.1485217809677124, 0.926555335521698, -0.7458831071853638, 0.7955078482627869, 14.749970436096191, 1.02928626537323, 0.08574652671813965, 0.5715466141700745, 0.8855241537094116, -0.1989315003156662, -0.3470233082771301, -0.2963751256465912, -1.7276830673217773, 0.14628586173057556, 1.3710607290267944, 0.5555859804153442, 0.8018590807914734, 0.3826201260089874, 0.3573249876499176, -0.045854438096284866, -0.5333380103111267, 0.31006091833114624, 0.500573992729187, -1.332066535949707, 0.12053948640823364, -0.3444382846355438, 0.6242884993553162, 0.6356933116912842, 0.671486496925354, 0.8885671496391296, 0.1717819720506668, -0.4503660202026367, 0.34807083010673523, 0.15216362476348877, 0.9531558752059937, -0.14628835022449493, 0.20391976833343506, 0.5121457576751709, -0.8616138696670532, -0.08146341890096664, -0.556125283241272, -1.3662840127944946, 0.06138771399855614, 0.17024804651737213, -0.5528512001037598, -0.6907905340194702, -0.28677552938461304, 0.599335789680481, -0.05043596401810646, 0.2329772710800171, -0.03297603130340576, 0.8849887847900391, -0.04299270361661911, -0.11959069222211838, 0.43130725622177124, 0.46495160460472107, 0.361092746257782, 0.29368799924850464, -0.1254548728466034, -0.1889956295490265, -0.002377700060606003, 0.4776567220687866, -0.5852442979812622, -0.0667201429605484, -0.14395679533481598, -0.06900732964277267, 0.31239187717437744, 0.703157901763916, 0.7177273035049438, 0.1840730905532837, -0.39785146713256836, 0.20489434897899628, 0.4647170305252075, 0.3011450171470642, -0.10989504307508469, -0.10551061481237411, 0.7969467639923096, -0.770995557308197, 0.10922267287969589, 0.4341946542263031, -0.3319801092147827, -0.5810474157333374, -0.4482432007789612, -0.1435050070285797, 0.20702072978019714, -0.47364312410354614, -0.49046438932418823, 0.4895940124988556, 0.008992783725261688, -0.3597414791584015, -0.13698701560497284, -0.798187255859375, -0.37625008821487427, 0.6919231414794922, -1.1271600723266602, -1.0055396556854248, 0.9786003232002258, -0.6971806883811951, -0.21183402836322784, 0.40854427218437195, 1.2844573259353638, 0.10881458967924118, -0.5342933535575867, 0.36136817932128906, 0.742388904094696, 0.22028647363185883, 0.08053554594516754, -0.6167271137237549, 1.1081541776657104, 0.48258844017982483, -0.24522870779037476, 0.6078016757965088, 0.02420310489833355, 0.15963640809059143, -0.5788944363594055, -0.2776638865470886, 0.9223482012748718, -1.218595027923584, -0.32320067286491394, -1.008776068687439, -0.6757131218910217, 0.6169158816337585, 0.43492552638053894, 0.009838497266173363, 0.5680239200592041, 0.4027866721153259, -0.5829929113388062, -0.41287752985954285, -0.5763047933578491, -0.009593435563147068, 0.38629427552223206, -0.6197868585586548, -0.44681328535079956, -0.39817091822624207, 0.7737717032432556, -1.3443377017974854, -0.7761777639389038, -0.3360876142978668, 0.5388554930686951, -0.027059754356741905, 1.0928336381912231, -0.5982950329780579, 0.643325924873352, 0.9099881052970886, -0.22088247537612915, -0.7630696296691895, 0.48174533247947693, -0.653257429599762, -0.4669548571109772, 0.3824286460876465, 0.838600218296051, -0.2209739238023758, 0.22600573301315308, 0.8264291286468506, 0.5055347084999084, -0.8253747820854187, -0.7895858883857727, -0.47748905420303345, 0.39688876271247864, -0.7891235947608948, 0.6918604969978333, -0.14471085369586945, 0.016751306131482124, -0.05314945429563522, 0.13790977001190186, 0.8658161163330078, -0.20902787148952484, -0.6282836198806763, 0.2656274735927582, 0.34696272015571594, -0.47409898042678833, -0.2911691665649414, -0.3495670258998871, -1.3539319038391113, -0.12352825701236725, -0.83543860912323, -0.1390669196844101, -0.5506345629692078, -0.5140364766120911, -0.2341502159833908, -0.24866320192813873, 0.053289227187633514, 0.031535014510154724, -0.288514107465744, -0.4656621813774109, -0.7420414686203003, -0.4448407292366028, 0.6037102937698364, 0.7552855610847473, -0.5517089366912842, -0.05485346168279648, 0.4218139350414276, 0.604372501373291, 0.23666447401046753, 0.5205808877944946, -0.23902539908885956, -0.721078634262085, -1.4737807512283325, 0.598884105682373, -0.11951421946287155, -0.23223210871219635, -0.40688368678092957, 0.21238641440868378, 0.06555794179439545, 0.0801670029759407, -0.2146248072385788, 0.36117106676101685, -0.6744173169136047, -0.6753819584846497, 0.17159898579120636, -0.9465320110321045, -0.14334748685359955, 0.3238002359867096, -0.5335960984230042, -0.16644889116287231, 0.4577347934246063, -0.30763760209083557, -0.962704062461853, -1.0010340213775635, 0.2458726465702057, -0.5610756874084473, 0.19660428166389465, -0.46240130066871643, 0.28436869382858276, -1.0281486511230469, -0.16107897460460663, -0.3075624704360962, 0.42911869287490845, -0.3579714894294739, 1.1618967056274414, 0.3005632162094116, -1.0334022045135498, 0.2197137326002121, 0.4262392222881317, -0.14506463706493378, 0.35177552700042725, 0.712449312210083, 0.2981563210487366, -0.21817703545093536, 0.6889572739601135, 0.5007505416870117, 0.35069483518600464, -1.103482961654663, -0.007144793402403593, 0.5046331286430359, -0.5014643669128418, -0.015325094573199749, 1.2737046480178833, -0.5988722443580627, -1.2127717733383179, 0.3880671560764313, -1.6983531713485718, -0.45487135648727417, -0.18746072053909302, 1.0835967063903809, 0.2690827250480652, -0.13930454850196838, -0.01956438273191452, -0.4863629639148712, 0.0787687823176384, -0.1241227462887764, -0.4335228502750397, 0.48836731910705566, -0.6021134257316589, -0.47408953309059143, 0.9900968074798584, 0.8893167972564697, -0.22110003232955933, -1.0151370763778687, -0.6628573536872864, -0.45839110016822815, -0.06704775243997574, 0.1041988730430603, -0.48859748244285583, 0.01754605956375599, 0.7714115381240845, 0.31577327847480774, 0.27161872386932373, -0.15317443013191223, 0.04789065197110176, 0.39253875613212585, 0.9854733347892761, 0.14813470840454102, -0.7892375588417053, -0.8729327321052551, 1.215116262435913, 0.9440873861312866, -1.2084832191467285, 0.29155001044273376, 0.26129812002182007, -0.6383740305900574, 0.6546710133552551, 0.40373092889785767, 0.26750749349594116, 0.9894807934761047, -0.32799234986305237, 0.2778532803058624, 0.8786894679069519, -1.1413816213607788, 0.0036495127715170383, 0.7310370206832886, 0.7355379462242126, 0.7429894208908081, 0.5334420800209045, 0.1566946804523468, 0.9533079266548157, 0.15135282278060913, -0.21216796338558197, 0.5228311419487, 0.5483211278915405, -0.3555249571800232, -0.39974120259284973, -0.21839958429336548, 0.677302896976471, -0.8831758499145508, -0.8948147296905518, 0.27946051955223083, 0.5107111930847168, 0.43385472893714905, 0.554455578327179, 0.9120165705680847, 0.26250648498535156, 0.07807178050279617, 0.5399060845375061, 0.5186958312988281, -0.5596697330474854, -0.232096329331398, -0.3847287893295288, -0.6454412937164307, -0.2093552052974701, 0.028026610612869263, -0.5712341666221619, -0.5727947354316711, -0.28375282883644104, 0.5139217972755432, -0.2535282373428345, 0.28494423627853394, 1.2892429828643799, 0.57146817445755, 0.18372195959091187, -0.2045377939939499, -0.42749321460723877, -0.3960833251476288, -1.1154545545578003, -0.06031953543424606, -0.5768142342567444, 0.10216934978961945, 0.33944278955459595, 0.21817322075366974, -0.15515007078647614]}, "authors": [{"authorId": "2116276849", "name": "Dawei Zhu"}, {"authorId": "2242947624", "name": "Nan Yang"}, {"authorId": "145769448", "name": "Liang Wang"}, {"authorId": "2183730942", "name": "Yifan Song"}, {"authorId": "2139644141", "name": "Wenhao Wu"}, {"authorId": "49807919", "name": "Furu Wei"}, {"authorId": "1695451", "name": "Sujian Li"}], "references": [{"paperId": "b6346f9fa093b8e85df712485a2b851b9f680dac", "title": "LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"}, {"paperId": "c96297261467b5daa2d01227496a70d444602434", "title": "Baichuan 2: Open Large-scale Language Models"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "b069c32fcd77160f944ab3ba71ab6f0cfb782c68", "title": "Focused Transformer: Contrastive Training for Context Scaling"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "80980cd10d19f021c14a6b7eee871b6a5d328024", "title": "Augmenting Language Models with Long-Term Memory"}, {"paperId": "af385c0fdd0eda2bbf429bea6fedffc327c8a180", "title": "Randomized Positional Encodings Boost Length Generalization of Transformers"}, {"paperId": "60b35c6d68acced19b0c66edcfc0ee0a2c11efed", "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "2e6fa3095df1d1ed041dfb4f5a18e31d4b7bd7bb", "title": "In-Context Learning with Many Demonstration Examples"}, {"paperId": "ccdb7e7721b442e85823a3016e48dfedf1ca401c", "title": "Fine-Grained Distillation for Long Document Retrieval"}, {"paperId": "9575afb5702bc33d7df14c48feeee5901ea00369", "title": "A Length-Extrapolatable Transformer"}, {"paperId": "a8cf0f7a20f886acfb332071c2daaf58ba86a5ca", "title": "Recurrent Memory Transformer"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "a2fc77f075f666b462d9350e7576f0ba9845c61b", "title": "Transformer Language Models without Positional Encodings Still Learn Positional Information"}, {"paperId": "0e802c0739771acf70e60d59c2df51cd7e8c50c0", "title": "Memorizing Transformers"}, {"paperId": "77d956cdab4508d569ae5741549b78e715fd0749", "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "9dc624d7258d1a56117ca720aea953ce46b66b21", "title": "Efficient Attentions for Long Document Summarization"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "9770fff7379a7ab9006b48939462354dda9a2053", "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": null, "title": "Dynamically scaled rope further increases performance of long context llama with zero fine-tuning"}, {"paperId": "e3aa232577bb427b1f3a34acbdef84bd85734042", "title": "LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models"}, {"paperId": null, "title": "xformers: A modular and hackable transformer modelling library. https://github.com/ facebookresearch/xformers, 2022"}, {"paperId": null, "title": "GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": null, "title": "Ntk-aware scaled rope allows llama models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation"}, {"paperId": null, "title": "Things i\u2019m learning while training superhot"}, {"paperId": null, "title": "Hugging Face. Open llm leaderboard"}, {"paperId": null, "title": "vllm: Easy, fast, and cheap llm serving with pagedat-tention"}, {"paperId": null, "title": ": A modular and hackable transformer modelling library"}]}