{"paperId": "242b3798abb9996bb6342905b884ab0a006c0c00", "abstract": "Vision Transformers (ViTs) have become a dominant paradigm for visual representation learning with self-attention operators. Although these operators provide flexibility to the model with their adjustable attention kernels, they suffer from inherent limitations: (1) the attention kernel is not discriminative enough, resulting in high redundancy of the ViT layers, and (2) the complexity in computation and memory is quadratic in the sequence length. In this paper, we propose a novel attention operator, called lightweight structure-aware attention (LiSA), which has a better representation power with log-linear complexity. Our operator learns structural patterns by using a set of relative position embeddings (RPEs). To achieve log-linear complexity, the RPEs are approximated with fast Fourier transforms. Our experiments and ablation studies demonstrate that ViTs based on the proposed operator outperform self-attention and other existing operators, achieving state-of-the-art results on ImageNet, and competitive results on other visual understanding benchmarks such as COCO and Something-Something-V2. The source code of our approach will be released online.", "venue": "arXiv.org", "year": 2022, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2211.16289", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is demonstrated that ViTs based on the proposed operator outperform self-attention and other existing operators, achieving state-of-the-art results on ImageNet, and competitive results on other visual understanding benchmarks such as COCO and Something-Something-V2."}, "embedding": {"model": "specter_v2", "vector": [0.41690346598625183, 0.648415744304657, -0.18625403940677643, 0.008594914339482784, 0.3557114899158478, 0.03979877382516861, 0.5706444978713989, 0.13018368184566498, -0.3125828504562378, -0.9788621068000793, 0.8898629546165466, 0.4458928406238556, 0.29592764377593994, -0.15990445017814636, -0.3021043539047241, 0.3301498293876648, -0.5813490748405457, -0.020783783867955208, 0.2535768747329712, -0.43597540259361267, 0.41738131642341614, -0.6556524634361267, -1.5092897415161133, 0.2828279137611389, 0.27602383494377136, 1.130980372428894, 0.8282946348190308, 1.160373330116272, -0.46429651975631714, 0.6493576765060425, 0.4597594141960144, -0.040473658591508865, -0.07621777802705765, 0.19745762646198273, -0.6110901236534119, 0.04297763109207153, 0.7936758995056152, -0.1611507534980774, -0.4216022193431854, 0.8368493318557739, -0.19233721494674683, 0.1619138866662979, 0.6686797738075256, -0.5538615584373474, -0.32851555943489075, 0.4048357605934143, 0.37520790100097656, 0.7776718735694885, -0.02399289980530739, -0.5872460603713989, 1.7296229600906372, -1.2048718929290771, 0.3883967697620392, 1.4764164686203003, 0.4313373863697052, 0.2250700443983078, -0.13781936466693878, -0.25529545545578003, 0.8324097394943237, 0.764064610004425, -0.583223283290863, -0.1891104131937027, 0.14191509783267975, -0.21711157262325287, 2.171924352645874, -0.6582252979278564, 0.14764109253883362, 0.5375232696533203, 0.07586664706468582, 1.3771791458129883, -0.0587824247777462, -0.5836212038993835, -0.40146657824516296, -0.27583473920822144, 0.2878803014755249, 1.1539361476898193, -0.42994123697280884, 0.42666932940483093, -0.9044920206069946, 0.2546064257621765, 0.8623862862586975, -0.21065936982631683, -0.06607747822999954, -0.5546280741691589, -0.35501325130462646, 0.5440620183944702, 1.1493301391601562, 0.5271217226982117, -0.5259595513343811, 0.978049635887146, 0.5722874402999878, 0.05931786447763443, -0.5155348181724548, 0.45692670345306396, 0.1424376666545868, 0.4700580835342407, -0.5516802072525024, -0.10513347387313843, -0.27312588691711426, 0.8382685780525208, 0.04415101930499077, 0.5439093708992004, -0.20513011515140533, -0.10286978632211685, 1.2619519233703613, -0.07171396166086197, 0.43622729182243347, -0.5077324509620667, -0.15733575820922852, -0.6661069393157959, -0.24181854724884033, -1.0919139385223389, 0.14113259315490723, -0.43128955364227295, -0.7524688839912415, -0.7891684174537659, -0.5488985776901245, 0.8634290099143982, -1.2046922445297241, 0.44442564249038696, -0.5145846605300903, 0.4192173480987549, -0.2739329934120178, 0.299984872341156, 0.7940381169319153, 0.40651318430900574, 0.5032229423522949, 0.7420508861541748, 1.5107265710830688, -1.0683445930480957, -0.5134780406951904, -0.9425091743469238, 0.26562759280204773, -0.35245776176452637, 0.3769424557685852, -0.10752110183238983, -1.0227841138839722, -1.784295678138733, -0.9137042164802551, -0.301835834980011, -0.5233825445175171, 0.11086969822645187, 0.9550117254257202, 0.07856851816177368, -1.0777456760406494, 0.7732740640640259, -0.27424079179763794, -0.4671366512775421, 0.5812480449676514, -0.24907049536705017, 0.3221467435359955, -0.09799527376890182, -0.8631531000137329, 0.28384581208229065, 0.12551863491535187, -0.5770053267478943, -0.6510433554649353, -0.5948889851570129, -1.896885871887207, 0.3734278082847595, 0.31357312202453613, -0.8440258502960205, 0.7788925170898438, -0.25094956159591675, -0.6872342824935913, 0.6595243215560913, -0.7766143083572388, -0.06839986145496368, -0.1251993030309677, -0.3680143654346466, -0.11117696762084961, -0.1205100566148758, -0.11039486527442932, 0.8393843770027161, 0.8954949378967285, -0.5504753589630127, -0.2693493664264679, 0.3066609799861908, -0.3098905384540558, -0.0762941762804985, -0.26534631848335266, 0.9137206673622131, -0.22525523602962494, -0.46144789457321167, 0.35332292318344116, 0.9455043077468872, 0.4188593626022339, -0.1491672694683075, -0.12386542558670044, -1.1235263347625732, 1.2493493556976318, 0.33636510372161865, 0.6236212849617004, -1.0157387256622314, -0.4800509512424469, -0.33629313111305237, 0.3612367808818817, -0.24768942594528198, -1.2219874858856201, 0.5273711085319519, -0.6723870038986206, 0.4027167558670044, -0.03933596983551979, -1.1235569715499878, -0.0027950480580329895, -0.13906200230121613, -0.8449681401252747, -0.336614191532135, 0.2933136522769928, 1.3466131687164307, -1.0369096994400024, 0.03854040056467056, 0.1593950092792511, 0.33729156851768494, -0.818917989730835, 1.299528956413269, -0.4354182779788971, -0.1662106066942215, -0.024789899587631226, 0.026760296896100044, -0.05962899327278137, -0.6098781824111938, 0.06780773401260376, -1.188977599143982, 0.04551062732934952, 0.5007915496826172, -0.2115168422460556, 1.2065417766571045, -0.534707248210907, 0.8556893467903137, -0.449249267578125, -0.6856476664543152, 0.45723384618759155, 0.20642490684986115, -0.4491846263408661, -0.5110688805580139, 0.2709990441799164, -0.16470932960510254, -0.5681337118148804, -0.06919829547405243, 0.41119828820228577, 1.0277304649353027, -0.08573895692825317, 0.2175009846687317, 0.5238877534866333, -0.5149738788604736, 0.1332007348537445, 0.5281002521514893, 0.7004348635673523, 0.530339777469635, 0.5854161381721497, -0.147194966673851, 0.2173316478729248, -0.8461323380470276, -0.2739223539829254, 0.5593262314796448, 0.6027780771255493, 1.2548142671585083, 0.3034862279891968, -1.163435459136963, -0.6758872866630554, -0.07859790325164795, 0.7643963098526001, 1.5022788047790527, 0.11898767948150635, -0.442230761051178, -0.6059168577194214, -0.296962708234787, -0.4309805631637573, -0.18598419427871704, -0.905118465423584, -0.36960530281066895, -0.10974448174238205, -0.5395630598068237, 0.6478450894355774, 0.9443073868751526, 1.5953623056411743, -1.0014896392822266, -0.767392635345459, -0.24470731616020203, 0.3148335814476013, -0.7419053316116333, -0.7179155349731445, 0.3048423230648041, -0.35179299116134644, -0.49730509519577026, 0.24515420198440552, -0.2174791395664215, 0.19680489599704742, -0.32447442412376404, 1.0322962999343872, -0.3178638219833374, -0.7372835874557495, 0.4697680175304413, 0.41831645369529724, -0.9803484082221985, -0.20194897055625916, 0.19485948979854584, -0.15596778690814972, 0.05377667769789696, 0.5134437680244446, 0.38690081238746643, -0.248002290725708, 0.337136834859848, -0.5497512817382812, -0.10119248181581497, 0.17489193379878998, -0.20938646793365479, 0.820302426815033, -0.12358991801738739, -0.07327624410390854, -0.7634814381599426, 0.5210711359977722, 0.3478241562843323, 0.04568588733673096, 0.20666012167930603, -0.5279830098152161, -0.15771566331386566, 0.14299671351909637, -0.475984662771225, -0.4365538954734802, -0.44216275215148926, 0.5268310904502869, -0.48820942640304565, -0.6665221452713013, 0.08728083968162537, 0.2169913500547409, -0.20996882021427155, 0.3960740864276886, 0.4540691077709198, 0.35389384627342224, -0.07757881283760071, 0.3507172167301178, -1.0821284055709839, 0.8220468163490295, 0.10192447900772095, 0.2784203588962555, 0.26133325695991516, -0.09212352335453033, -0.9326244592666626, -1.0855656862258911, -0.8679043650627136, -0.5264893174171448, -0.40945103764533997, 0.8571630716323853, -0.4941439628601074, -1.1731817722320557, 0.06799133121967316, -1.1139737367630005, -0.08301927894353867, -0.11978910863399506, -0.2878451943397522, -0.46619170904159546, -0.7861387133598328, -0.6614269018173218, -0.3120994567871094, -0.32724013924598694, -0.7319127917289734, 0.24637185037136078, 0.4164290726184845, -0.4108608663082123, -0.6894623041152954, -0.10408386588096619, -0.24635663628578186, 1.1930937767028809, -0.09047447890043259, 0.7806009650230408, 0.2949070334434509, -0.7245939373970032, 0.19378866255283356, -0.4805918335914612, 0.5145463943481445, 0.0872940868139267, 0.015025039203464985, -1.1122159957885742, 0.14321988821029663, 0.1548098921775818, -0.44804903864860535, 0.7859023809432983, 0.5112656950950623, 0.851487934589386, 0.3953363299369812, -0.27712753415107727, 0.6331157088279724, 1.6039785146713257, -0.7234871983528137, 0.40719109773635864, 0.3638764023780823, 1.3860023021697998, 0.5127768516540527, -0.40676453709602356, 0.512376070022583, 0.7063122391700745, -0.011502871289849281, 0.8778778910636902, -0.5913652777671814, -0.7432900071144104, -0.724877655506134, 0.20648951828479767, 1.1666250228881836, -0.2923915684223175, 0.36614131927490234, -1.1930570602416992, 1.0459109544754028, -1.072121500968933, -0.7383586764335632, 0.5978596806526184, 0.5362563133239746, -0.04868647828698158, -0.33307790756225586, -0.2799610197544098, -0.5625649094581604, 0.7613285779953003, 0.8385403752326965, -0.550525426864624, -0.5892238616943359, -0.09693142026662827, 0.6808760762214661, 0.12374978512525558, 0.6786754727363586, -0.3748651146888733, 0.47033363580703735, 14.325416564941406, 0.4023447334766388, 0.06317127496004105, 0.04092064127326012, 0.6906896233558655, 0.8205555081367493, -0.3662239909172058, 0.2452985644340515, -0.9455852508544922, -0.7725855112075806, 0.4693444073200226, 0.3650396764278412, 0.33492428064346313, 0.045023053884506226, -0.11137070506811142, 0.34167933464050293, -0.6528123617172241, 0.9765008091926575, 0.8750155568122864, -1.3015058040618896, 0.6140871644020081, 0.19177836179733276, 0.11789513379335403, 0.17338506877422333, 0.9214047193527222, 0.40736666321754456, -0.05670147389173508, -0.8316323161125183, 0.35117605328559875, 0.47969841957092285, 0.9871814846992493, -0.09358029067516327, 0.28528472781181335, 0.19574017822742462, -1.827926516532898, -0.21358348429203033, -0.9886772036552429, -1.1028608083724976, 0.24233338236808777, -0.35532861948013306, -0.31891340017318726, -0.4106789231300354, 0.17482627928256989, 1.1369739770889282, -0.2857482135295868, 0.5103093385696411, -0.3940742611885071, 0.35162922739982605, 0.258905827999115, 0.1776539832353592, 0.5182676911354065, 0.8500615358352661, 0.36663660407066345, -0.08838408440351486, -0.1345103681087494, 0.20684443414211273, 0.10228373110294342, 0.6835559010505676, -0.19488772749900818, -0.41399332880973816, -0.18456122279167175, -0.04915812984108925, -0.40454810857772827, 0.7976183891296387, 0.35116344690322876, 0.2243524193763733, -0.16530795395374298, 0.2342517077922821, 0.35912027955055237, 0.10661450028419495, -0.21202866733074188, -0.353682279586792, 0.14223049581050873, 0.006284321192651987, 0.5752835869789124, 0.48493215441703796, -0.13966229557991028, -0.4633868932723999, -0.8832463622093201, -0.18987718224525452, 0.6899014115333557, -1.1072770357131958, -0.7595489621162415, 1.1649765968322754, -0.13143397867679596, -0.04366341978311539, 0.5490661859512329, -1.0364099740982056, -0.7925567626953125, 0.1523732990026474, -1.6484125852584839, -0.8998451232910156, -0.673996090888977, -0.2298511564731598, 0.008558140136301517, -0.05777721107006073, 1.0462764501571655, -0.36428403854370117, 0.2508910000324249, -0.11679726839065552, -0.8294150233268738, -0.12657932937145233, -0.153160959482193, -1.1995689868927002, 1.0382274389266968, -0.038480669260025024, 0.21464838087558746, 0.13235826790332794, 0.1874774992465973, 0.013926537707448006, -0.36202219128608704, 0.22801128029823303, 0.5986033082008362, -0.7221209406852722, -0.47265589237213135, -0.6715204119682312, -1.3179471492767334, 0.1788938045501709, 0.9761773943901062, -0.14356176555156708, 0.15465375781059265, 0.19261303544044495, -1.0085500478744507, 0.08792353421449661, -0.6386157870292664, -0.21408963203430176, 0.49354565143585205, -0.9829589128494263, -0.8267711400985718, -0.4860568642616272, 0.1414051055908203, -0.5942383408546448, -0.2734065651893616, -0.21675601601600647, 0.16788066923618317, -0.5171839594841003, 1.298837423324585, -0.3532979488372803, 0.6275404095649719, 0.39433130621910095, 0.18828335404396057, -0.6442312002182007, -0.24507413804531097, -0.8566814064979553, 0.137436643242836, 0.10249901562929153, 0.33132097125053406, -0.2935801148414612, 0.33025890588760376, 0.4558335840702057, 0.48693400621414185, -0.3306455612182617, -0.06679081171751022, -0.04918736219406128, -0.44996577501296997, -0.3679139316082001, 0.10090461373329163, -0.1069779172539711, -0.5099706649780273, 0.38962191343307495, 0.5552071928977966, 0.5804198384284973, 0.24678562581539154, -0.4972743093967438, 0.27527642250061035, -0.329061359167099, -0.3286758065223694, -0.5041400790214539, -0.7176753878593445, -1.66652512550354, -0.28661298751831055, -0.9538111090660095, -0.3517608940601349, -1.2804193496704102, -0.3222154378890991, 0.6162277460098267, -0.4556410610675812, 0.06299802660942078, 0.2802807688713074, -0.2564075291156769, -0.08171514421701431, -0.449484258890152, -0.7032865285873413, 0.7146788239479065, 1.162370204925537, -0.7349522709846497, 0.32191988825798035, -0.1883963644504547, -0.22819964587688446, 0.5222510099411011, 0.23673245310783386, -0.4849035441875458, -1.0323166847229004, -0.9752070307731628, 0.36482730507850647, -0.5266034603118896, 0.2133323699235916, -0.9047672748565674, 0.9719358086585999, 0.7240909934043884, 0.18093858659267426, -0.262422651052475, 0.28487521409988403, -0.8408782482147217, -0.8032885789871216, 0.5464668273925781, -0.7202017307281494, 0.3291383385658264, 0.30705785751342773, -0.10716281086206436, -0.6277964115142822, 0.5231773257255554, 0.25819310545921326, -1.2603480815887451, -1.3001290559768677, 0.4489857256412506, -0.33120205998420715, 0.07220573723316193, -0.2065303921699524, -0.5131804943084717, -1.236794352531433, -0.7379175424575806, -0.22863386571407318, 0.4107714593410492, -0.38925817608833313, 0.8529641032218933, 1.1296082735061646, -0.9976123571395874, 0.006621580105274916, 0.45316097140312195, 0.2903382480144501, 0.19723762571811676, 0.8230603337287903, 0.005493101663887501, -0.194664865732193, 0.18519306182861328, -0.27415746450424194, 0.20833444595336914, -0.8673903346061707, 0.22177031636238098, 0.9420643448829651, -0.2080407738685608, -0.2844112813472748, 1.0447392463684082, 0.5220971703529358, -0.6638120412826538, 0.21661904454231262, -1.0302221775054932, -0.9047632813453674, 0.014132838696241379, 0.7849197387695312, -0.08038832992315292, -0.4273220896720886, -0.20512905716896057, -0.40313610434532166, 0.9564442038536072, -0.3779630661010742, -0.2733483612537384, 0.49651390314102173, -0.048046357929706573, -0.20108787715435028, 0.32058584690093994, 0.8869394659996033, -0.9822636842727661, -1.3691028356552124, -0.8536913990974426, -0.4055238962173462, -0.47543251514434814, 0.12020818889141083, -0.13626030087471008, -0.7063562273979187, 1.2227178812026978, 0.5752171277999878, 0.5983707308769226, 0.39278361201286316, 0.08677393943071365, 0.21117205917835236, 0.7959207892417908, -0.5042073130607605, -0.45148345828056335, 0.31406840682029724, 1.3114367723464966, 1.532393217086792, -0.6784971952438354, 0.1590254157781601, -0.4019036591053009, -0.874417245388031, 0.9696523547172546, 0.4808450937271118, -0.505512535572052, 0.7629989981651306, -0.37457209825515747, 0.12522242963314056, -0.2496180385351181, -1.0526691675186157, -0.6689672470092773, 1.231232762336731, 1.6734390258789062, 0.6030426025390625, -0.17853417992591858, 0.90033358335495, 0.18827442824840546, 0.2664049565792084, -0.38285085558891296, 0.48239803314208984, 0.03969002142548561, -0.4665724039077759, 0.12472040951251984, 0.047515615820884705, 0.44729194045066833, -0.3903270959854126, -0.438373863697052, 0.1116122156381607, 0.6669377088546753, -0.020602978765964508, 0.29240983724594116, 1.1305047273635864, 0.4290326237678528, 0.7264706492424011, 0.08514026552438736, 0.5166109800338745, -0.7346411943435669, -0.23379623889923096, -0.2035292387008667, -0.9817968606948853, -0.22190037369728088, -0.6324673891067505, -0.4340044856071472, -0.5723737478256226, 0.22691263258457184, 0.4004392623901367, -0.44033321738243103, 0.4295143485069275, 0.7399652004241943, 0.5933436751365662, 0.8569672107696533, -0.39550065994262695, -0.3486640453338623, -0.1571909636259079, -0.9155591726303101, 0.2861907184123993, -0.2875617444515228, 0.08743593096733093, -0.7305181622505188, -0.21941959857940674, 0.058451198041439056]}, "authors": [{"authorId": "30557120", "name": "Heeseung Kwon"}, {"authorId": "144655318", "name": "F. M. Castro"}, {"authorId": "1398347979", "name": "M. Mar\u00edn-Jim\u00e9nez"}, {"authorId": "65794868", "name": "N. Guil"}, {"authorId": "72492981", "name": "Alahari Karteek"}], "references": [{"paperId": "c49ac1f916d6d2edeb187e6619c8d23acd95eb21", "title": "cosFormer: Rethinking Softmax in Attention"}, {"paperId": "c8831d0629f0eaf7f723317d71bbd60b8eb3c39f", "title": "UniFormer: Unified Transformer for Efficient Spatiotemporal Representation Learning"}, {"paperId": "9137efc758f80dd22bb56f82cca5c94f78a5db3e", "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and Detection"}, {"paperId": "e0cbf89351edc12eafe6905c76b890bfb5077439", "title": "Relational Self-Attention: What's Missing in Attention for Video Understanding"}, {"paperId": "bb363c8c5bc1c473f0801c647c88d0c071792858", "title": "PermuteFormer: Efficient Relative Position Encoding for Long Sequences"}, {"paperId": "9b6af0e358e76d22f209c75b1702c3e6ea7815b1", "title": "Global Filter Networks for Image Classification"}, {"paperId": "7b664a306b7d2f68dd816ea1d6586cf3472d75c1", "title": "Early Convolutions Help Transformers See Better"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "0d508600d77d8a7e6a655cdb6d139779732f649f", "title": "Stable, Fast and Accurate: Kernelized Attention with Relative Positional Encoding"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "08ffdec40291a2ccb5f8a6cc048b01247fb34b96", "title": "Relative Positional Encoding for Transformers with Linear Complexity"}, {"paperId": "68f080e0ac836ea230cb5316fbed273c70422d75", "title": "Segmenter: Transformer for Semantic Segmentation"}, {"paperId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "title": "FNet: Mixing Tokens with Fourier Transforms"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "b6382a7351c0c595f91472ac71d3b2d87b3c4844", "title": "ViViT: A Video Vision Transformer"}, {"paperId": "91e8117e7ebc966bc76de2cb52ec717d2acdb1a4", "title": "Scaling Local Self-Attention for Parameter Efficient Visual Backbones"}, {"paperId": "610b302950a19acef1c45456111dcd495f638c18", "title": "ConViT: improving vision transformers with soft convolutional inductive biases"}, {"paperId": "fbd730a948a06cd4918c1d632ffdb4572b52d99b", "title": "Involution: Inverting the Inherence of Convolution for Visual Recognition"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "cec7872b194aadf54140578b9be52939eb1112e9", "title": "LambdaNetworks: Modeling Long-Range Interactions Without Attention"}, {"paperId": "265737312976d5830d09171a6f6b27ca039851d8", "title": "Learning Self-Similarity in Space and Time as Generalized Motion for Video Action Recognition"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "4d2534fbcecc32bc181d1eb8e9f00d3e71cfe14f", "title": "WeightNet: Revisiting the Design Space of Weight Networks"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "54c7445f319823c7dcc948c830e75e2fa7460b33", "title": "Exploring Self-Attention for Image Recognition"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "fb7972f30812c7dd056d7943c3e3f00af022d607", "title": "Dynamic Convolution: Attention Over Convolution Kernels"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "c2c083df88e88223e1a411e61040b94c233b1b63", "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"}, {"paperId": "d6dccb5d71fbb6f5765f89633ba3a8e6809a720d", "title": "Stand-Alone Self-Attention in Vision Models"}, {"paperId": "45a924794b2c6501b671cf4249c6ac4fa1671597", "title": "Video Modeling With Correlation Networks"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "5f4a22ee70ca613d9c0630eafc96364fe365fdf8", "title": "Efficient Attention: Attention with Linear Complexities"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "b68811a9b5cafe4795a11c1048541750068b7ad0", "title": "The \u201cSomething Something\u201d Video Database for Learning and Evaluating Visual Common Sense"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "ea3d7de6c0880e14455b9acb28f1bc1234321456", "title": "Temporal Segment Networks: Towards Good Practices for Deep Action Recognition"}, {"paperId": "aba48504f4f9563eafa44e0cfb22e1345d767c80", "title": "Dynamic Filter Networks"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "5feb23e3c01c12c797b271fa5cd2a1f2f096130f", "title": "Matching Local Self-Similarities across Images and Videos"}, {"paperId": "cc04a1dd59da13b005955289de56babbfd191a55", "title": "A proposal for toeplitz matrix calculations"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "5a9bc55f6332e38f62eb509b684147a1d4f10fd9", "title": "Focal Attention for Long-Range Interactions in Vision Transformers"}, {"paperId": "083ca4bd4d5b231a1d7a0715ec55cc57a0f44b13", "title": "Aggregating Nested Transformers"}, {"paperId": null, "title": "C. Visualization In Fig. 8, we additionally visualize both self-attention and LiSA kernels of different layers and heads from isotropic models"}]}