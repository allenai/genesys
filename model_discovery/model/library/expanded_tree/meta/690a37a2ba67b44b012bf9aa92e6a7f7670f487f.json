{"paperId": "690a37a2ba67b44b012bf9aa92e6a7f7670f487f", "abstract": "Transformers are the mainstream of NLP applications and are becoming increasingly popular in other domains such as Computer Vision. Despite the improvements in model quality, the enormous computation costs make Transformers difficult at deployment, especially when the sequence length is large in emerging applications. Processing attention mechanism as the essential component of Transformer is the bottleneck of execution due to the quadratic complexity. Prior art explores sparse patterns in attention to support long sequence modeling, but those pieces of work are on static or fixed patterns. We demonstrate that the sparse patterns are dynamic, depending on input sequences. Thus, we propose the Dynamic Sparse Attention (DSA) that can efficiently exploit dynamic sparse patterns in attention. Compared with other methods, our approach can achieve better trade-offs between accuracy and model complexity. Moving forward, we identify challenges and provide solutions to implement DSA on existing hardware (GPUs) and specialized hardware in order to achieve practical speedup and efficiency improvements for Transformer execution.", "venue": "IEEE transactions on computers", "year": 2022, "citationCount": 12, "influentialCitationCount": 3, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes the Dynamic Sparse Attention (DSA) that can efficiently exploit dynamic sparse patterns in attention and demonstrates that the sparse patterns are dynamic, depending on input sequences."}, "embedding": {"model": "specter_v2", "vector": [0.44506141543388367, 0.4813809096813202, -0.220156729221344, 0.032933350652456284, -0.5863500833511353, -0.31755173206329346, 0.5654972791671753, -0.05308061093091965, -0.3755403459072113, -0.4824105203151703, 0.5354557633399963, 0.1580263376235962, 0.46245527267456055, 0.11552241444587708, -0.1264103651046753, 0.2994545102119446, -0.42780885100364685, 0.5461989641189575, 0.27725744247436523, -0.38542699813842773, -0.20166222751140594, -0.5534193515777588, -1.1866021156311035, 0.24685321748256683, 0.4499649703502655, 0.5266033411026001, 0.7684067487716675, 0.8032965660095215, -0.6342719197273254, 0.20848935842514038, 0.5378661155700684, -0.43234920501708984, 0.14250338077545166, 0.05781793221831322, -0.1657697707414627, -0.41817349195480347, 0.657128632068634, -0.0734511986374855, -0.49317726492881775, 1.1973813772201538, -0.4318104684352875, 0.2020779848098755, 0.10023277997970581, -1.011051058769226, -0.547875702381134, 0.8498663902282715, 0.36130738258361816, 1.1121803522109985, 0.14979326725006104, -0.541768491268158, 1.5273953676223755, -1.3563264608383179, 0.4035770893096924, 1.649406909942627, 0.6535391211509705, 0.2265675812959671, 0.009773720055818558, -0.7095810770988464, 0.8099432587623596, 0.7444943189620972, -0.5898082852363586, -0.47749531269073486, -0.11975104361772537, -0.0795152559876442, 2.2490906715393066, -0.24319355189800262, 0.38515013456344604, 0.4548807740211487, -0.18072503805160522, 1.444577693939209, -0.4117955267429352, -0.8227829933166504, -0.5256189107894897, -0.299935907125473, 0.2737022340297699, 0.9915774464607239, -0.47803831100463867, 0.14273300766944885, -1.0840919017791748, -0.329965204000473, 0.25673264265060425, 0.04682930186390877, 0.00013266650785226375, -0.10641822963953018, -0.3590282201766968, 0.7909690141677856, 0.37429600954055786, 0.7390605807304382, -0.27948856353759766, 0.5949196219444275, 0.5620732307434082, 0.058773670345544815, -0.38442790508270264, 0.4411792457103729, -0.17238402366638184, 0.02363303303718567, -1.0240432024002075, 0.2740933299064636, 0.18077892065048218, 1.0906856060028076, -0.5175749063491821, 0.2317395806312561, -0.7436856627464294, 0.21238955855369568, 1.2240546941757202, 0.5567201972007751, 0.4509012997150421, -0.41020655632019043, 0.38230106234550476, -0.6341726779937744, 0.09137469530105591, -1.0389904975891113, -0.07043600082397461, -0.13527408242225647, -0.8861827850341797, -1.3462164402008057, -0.20526865124702454, 0.2542884647846222, -1.012708306312561, 0.652168333530426, -0.4081757664680481, 0.46275562047958374, -0.23077614605426788, 0.2510148584842682, 0.4508768618106842, 0.844491183757782, 0.272941529750824, 0.13637453317642212, 1.225852131843567, -0.8851245641708374, -0.6643288731575012, -1.2636762857437134, 0.3749825358390808, -0.5088213086128235, 0.3482975959777832, -0.350030779838562, -1.2027016878128052, -0.6508006453514099, -0.43640562891960144, -0.2097577154636383, -0.3281004726886749, 0.1459989696741104, 0.8268316388130188, -0.12917503714561462, -1.0683895349502563, 0.4993528127670288, -0.43123120069503784, -0.4830951988697052, 0.6894603967666626, 0.06396704912185669, 0.34391430020332336, -0.32303673028945923, -1.281588077545166, 0.41418206691741943, -0.3045737147331238, -0.6375550627708435, -0.2772906422615051, -0.8650427460670471, -1.400663137435913, 0.7449340224266052, 0.23369131982326508, -0.3736116290092468, 1.4990894794464111, -0.042431894689798355, -1.009479284286499, 0.5047875046730042, -0.8944382071495056, -0.2808460295200348, 0.005238090176135302, -0.12671981751918793, -0.3334837555885315, -0.44900450110435486, 0.13557331264019012, 0.45791396498680115, 0.6155930161476135, 0.4136715829372406, -0.7129027247428894, 0.22287635505199432, -0.21506886184215546, -0.25886058807373047, -0.22926755249500275, 1.2512757778167725, -0.3856357932090759, -0.11115942895412445, 0.20543043315410614, 0.6361492872238159, -0.37867167592048645, -0.32084643840789795, -0.17986635863780975, -1.1177828311920166, 1.0244147777557373, -0.16882935166358948, 0.8085721135139465, -0.9366096258163452, -0.5273638963699341, -0.27068957686424255, 0.02491014264523983, -0.024809615686535835, -0.9489652514457703, 0.5926017165184021, -0.4413966238498688, 0.1374722123146057, -0.028910774737596512, -0.7892844080924988, 0.04875033348798752, -0.3788137137889862, -1.0003396272659302, -0.3480731248855591, 0.23334187269210815, 1.2683695554733276, -1.0535582304000854, 0.02172425575554371, 0.015892665833234787, 0.20756763219833374, -1.0525164604187012, 0.9025828838348389, -0.6482493281364441, -0.16930703818798065, -0.06506370007991791, 0.09421458840370178, -0.05781283602118492, -0.6088190078735352, 0.5733832716941833, -0.6914570927619934, -0.11258352547883987, 0.43094611167907715, -0.191061332821846, 1.0843085050582886, -0.33132606744766235, 0.5863261222839355, -0.12353616952896118, -0.6786789298057556, 0.37953975796699524, 0.26593533158302307, -0.3591694235801697, -0.555409848690033, 0.11624539643526077, 0.340900719165802, -0.41356414556503296, 0.07388751953840256, 0.7157571911811829, 0.8137012124061584, -0.20196379721164703, -0.12313678115606308, 0.6979540586471558, -0.18726393580436707, 0.8015823364257812, 0.469451904296875, 0.9821102619171143, 0.07289180159568787, 0.5850305557250977, -0.014378570020198822, 0.32870712876319885, -0.43910014629364014, 0.06381601840257645, 0.6431946754455566, 0.7424795031547546, 0.5429381132125854, 0.4467664062976837, -0.7350850701332092, -0.6233818531036377, 0.7462434768676758, 0.8590576648712158, 1.5452748537063599, -0.14260879158973694, -0.3592343032360077, -0.5054404139518738, -0.5161486268043518, -0.34708699584007263, -0.046195872128009796, -0.18489642441272736, 0.24051310122013092, -0.522878885269165, -0.8268923759460449, 0.667366087436676, 0.47209420800209045, 0.6176099181175232, -0.8209254741668701, -0.2954707145690918, -0.2530215084552765, -0.0032301542814821005, -1.081513524055481, -0.6419640779495239, 0.3718155026435852, -0.3462091386318207, -0.5909359455108643, 0.2687929570674896, -0.24424102902412415, 0.12812933325767517, -0.5601401925086975, 0.9981204271316528, -0.8137850761413574, -0.12815631926059723, 0.30154961347579956, 0.46707862615585327, -0.9188169240951538, -0.5256868600845337, 0.4273461103439331, -0.1290610134601593, -0.4089990556240082, 0.7913365364074707, 0.20034049451351166, 0.3095097839832306, -0.032409533858299255, -0.09386476874351501, -0.12323957681655884, 0.09390471130609512, 0.13337084650993347, 0.9217942357063293, -0.5643380284309387, -0.06969175487756729, -1.0465131998062134, 0.6999406814575195, 0.047543153166770935, -0.9378989934921265, 0.19932258129119873, -0.25843411684036255, -0.5666054487228394, 0.6844447255134583, -0.7525013089179993, -0.1414513885974884, -0.1780601441860199, -0.034654486924409866, -0.7552303075790405, -0.14961862564086914, 0.3280622959136963, 0.27476659417152405, 0.08095100522041321, 0.3331294059753418, 0.7194591760635376, 0.36120229959487915, -0.04536667838692665, 0.5006215572357178, -0.9283691644668579, 0.48903074860572815, 0.5206895470619202, 0.11114722490310669, -0.13580520451068878, -0.003951157908886671, -0.6815083622932434, -0.7170185446739197, -0.5579929947853088, -0.324360191822052, 0.1456480175256729, -0.1330816149711609, -0.4725964665412903, -1.0028730630874634, -0.39193403720855713, -1.3361502885818481, 0.14226730167865753, -0.15000638365745544, -0.28156086802482605, -0.1483476758003235, -1.0800349712371826, -1.1170108318328857, -0.3999578356742859, -0.8172184228897095, -0.9584317803382874, 0.6843146085739136, 0.15861357748508453, -0.3992697596549988, -0.33255189657211304, 0.1253337413072586, -0.5835791230201721, 1.017270803451538, -0.5505722165107727, 0.8962081074714661, -0.4297949969768524, -0.5205742120742798, -0.491550475358963, 0.06852679699659348, 0.11071722209453583, -0.25909605622291565, 0.14375022053718567, -0.7790584564208984, 0.3913313150405884, -0.2391558289527893, -0.05308394879102707, 0.32472237944602966, 0.5909354090690613, 0.5265023708343506, -0.17040979862213135, -0.965430498123169, 0.4061388671398163, 1.4253809452056885, -0.4496573805809021, -0.08083314448595047, 0.1474020779132843, 1.1562260389328003, -0.11418585479259491, 0.10639631748199463, 0.4512588679790497, 0.2932719886302948, 0.4207408130168915, 0.34637171030044556, 0.053394615650177, -0.12391176074743271, -0.5999876260757446, 0.5368925929069519, 1.6616230010986328, 0.43878185749053955, 0.05172651633620262, -1.2819970846176147, 0.8654701709747314, -1.4152727127075195, -1.210376262664795, 0.5060550570487976, 0.14030970633029938, 0.264229416847229, -0.6760904788970947, -0.38726940751075745, -0.3624348044395447, 0.5994678139686584, 0.45214372873306274, -0.49457699060440063, -0.4009537696838379, 0.10962270200252533, 0.5039475560188293, 0.19261743128299713, 0.6974939703941345, -0.32755324244499207, 0.7362257838249207, 14.708234786987305, 1.2053554058074951, 0.005677223205566406, 0.6120846271514893, 0.2656002938747406, 0.3841683566570282, -0.28698036074638367, -0.1639719158411026, -1.7024801969528198, -0.24799950420856476, 0.8088298439979553, -0.3772760331630707, 0.5215132832527161, 0.5031957626342773, -0.02296781912446022, 0.37954697012901306, -0.6112378239631653, 0.9167623519897461, 0.7241068482398987, -1.5851778984069824, 0.4145684838294983, -0.08595622330904007, 0.1066582202911377, 0.7467896938323975, 0.5636892318725586, 0.751231849193573, 0.6705755591392517, -0.5117281675338745, 0.28277909755706787, 0.39620697498321533, 0.9177390336990356, 0.16636493802070618, 0.659589409828186, 0.5935170650482178, -1.2050944566726685, -0.44975030422210693, -0.7798415422439575, -1.02372407913208, 0.4117628037929535, 0.20997168123722076, -0.9391565322875977, -0.5929728150367737, -0.060142505913972855, 1.2440845966339111, 0.11737887561321259, 0.567575991153717, -0.2750283479690552, 0.5416043996810913, -0.4240756928920746, 0.061288341879844666, 0.27539554238319397, 0.5531331896781921, 0.4861668348312378, 0.07377934455871582, 0.4311695992946625, -0.05417751520872116, 0.1971794068813324, 0.5044220089912415, -0.5913456082344055, -0.21256226301193237, -0.5676483511924744, -0.38227739930152893, 0.043661683797836304, 1.0091584920883179, 0.34153854846954346, 0.3478185832500458, -0.5234677791595459, 0.10882361233234406, 0.7639747858047485, -0.03459857031702995, -0.24968813359737396, 0.025064807385206223, 0.13153114914894104, -0.23313435912132263, 0.46776387095451355, 0.7632067203521729, -0.06480106711387634, -0.5864435434341431, -0.8332003355026245, -0.7284917235374451, 0.6423050165176392, -0.6379096508026123, -0.8885382413864136, 0.873667299747467, -0.3161896765232086, -0.2501533627510071, 0.14626124501228333, -0.47468313574790955, -0.06263501197099686, 0.4179883599281311, -1.2871512174606323, -0.9802324771881104, 0.1633121222257614, -0.1471586674451828, 0.16712002456188202, -0.08363160490989685, 1.412698745727539, 0.09585201740264893, 0.07584644854068756, -0.1958458423614502, -0.12330890446901321, -0.13932909071445465, -0.39144831895828247, -0.6523647904396057, 1.0783209800720215, 0.49350517988204956, 0.3580647110939026, -0.03949721157550812, 0.018899818882346153, -0.014878450892865658, -0.6621859669685364, -0.1893795281648636, 0.9376010298728943, -1.0570852756500244, -0.15756583213806152, -0.7711952924728394, -0.9457395076751709, 0.7619127631187439, 0.37418684363365173, -0.30128374695777893, 0.12452326714992523, 0.29154929518699646, -0.485449880361557, -0.028420940041542053, -0.8700839281082153, -0.022515803575515747, 0.5488709807395935, -0.6115500926971436, -0.3857278525829315, -0.05453476309776306, 0.6524921655654907, -1.3234623670578003, -0.21918036043643951, -0.09134270995855331, 0.10613327473402023, 0.3500480353832245, 1.055193305015564, -0.42149031162261963, 0.6612325310707092, 0.7261488437652588, -0.07692691683769226, -0.5937801003456116, -0.17640900611877441, -0.722141683101654, -0.3956453800201416, 0.12882965803146362, 0.6426479816436768, -0.22160355746746063, 0.3593273460865021, 0.5923711061477661, 0.5042304396629333, -0.22070524096488953, -0.6110191941261292, -0.15160349011421204, -0.3815847635269165, -0.3932936489582062, 0.42081719636917114, -0.10093236714601517, -0.16036687791347504, 0.1933419555425644, 0.3366768956184387, 0.8550397753715515, -0.34464189410209656, -0.24266906082630157, 0.23888860642910004, -0.17421062290668488, 0.07992152869701385, -0.2872248888015747, -0.44451287388801575, -1.3406065702438354, 0.14880840480327606, -1.2188369035720825, 0.030262095853686333, -1.0455726385116577, -0.36354759335517883, 0.35344159603118896, -0.03389522433280945, 0.43017813563346863, 0.2764185070991516, -0.419167697429657, -0.038630153983831406, -0.5312736630439758, -0.6100404262542725, 0.7370930314064026, 0.8392680883407593, -0.8774936199188232, 0.08119939267635345, 0.1628403514623642, 0.04005963355302811, 0.6209818720817566, 0.2726449966430664, -0.7504618167877197, -0.5471868515014648, -1.0540437698364258, 0.5309060215950012, -0.07867664843797684, -0.18817295134067535, -0.4226962924003601, 1.2421777248382568, 0.28428810834884644, -0.27327248454093933, -0.11501288414001465, 0.4334769546985626, -1.174397587776184, -0.6146165132522583, 0.3115014135837555, -0.6093929409980774, 0.26536402106285095, 0.46490105986595154, -0.44999560713768005, -0.559237539768219, 0.6403403878211975, 0.12652058899402618, -1.136084794998169, -0.7291905879974365, 0.6033241748809814, -0.4379943013191223, 0.4220629036426544, -0.2673908770084381, 0.03938349708914757, -1.0300242900848389, -0.4309662878513336, -0.21392223238945007, 0.4786057770252228, -0.5395843982696533, 0.7412294745445251, 0.5622117519378662, -1.0882723331451416, 0.24786128103733063, 0.25289350748062134, -0.22475233674049377, 0.17254014313220978, 0.4646798074245453, 0.5118356347084045, -0.007748387288302183, 0.6163933873176575, 0.2102298140525818, 0.029636042192578316, -1.4160853624343872, 0.15644392371177673, 0.7722561955451965, -0.7486729025840759, -0.4892486333847046, 1.0892878770828247, -0.3729448616504669, -0.8476711511611938, 0.18397001922130585, -1.2722734212875366, -0.815146267414093, -0.08000796288251877, 0.7811991572380066, 0.025735843926668167, -0.17391403019428253, -0.09613251686096191, -0.7842146158218384, 0.18922625482082367, -0.1398158073425293, -0.21805110573768616, 0.9758268594741821, 0.05102730914950371, -0.6100277304649353, 0.3211340606212616, 0.20640410482883453, -0.610924243927002, -0.4070222079753876, -0.8583056330680847, -0.13263903558254242, -0.5352582931518555, -0.018520314246416092, -0.2708742618560791, -0.5777822136878967, 0.8532734513282776, 0.39464515447616577, 0.5197914838790894, 0.18847723305225372, 0.055175818502902985, 0.37489205598831177, 0.8300529718399048, -0.026197398081421852, -0.19506870210170746, -0.7289592027664185, 1.71255624294281, 1.5314581394195557, -0.6890193223953247, -0.05907188355922699, -0.6189537048339844, -0.7092209458351135, 0.9157494902610779, 0.3000756800174713, -0.19542962312698364, 0.7351438999176025, 0.16405056416988373, -0.11563664674758911, -0.04867332801222801, -1.1115608215332031, -0.5344038009643555, 0.8152508735656738, 1.3477481603622437, 0.3347550928592682, -0.3435501158237457, 0.47863972187042236, 0.8784540891647339, 0.09193021804094315, 0.48071956634521484, 0.2459193915128708, 0.14894263446331024, -0.310200572013855, -0.03469603881239891, -0.046148039400577545, 0.9595752358436584, -0.8849440217018127, -1.0091882944107056, 0.2584262490272522, 0.595197856426239, 0.021313171833753586, 0.4149211645126343, 0.7523850798606873, 0.3242301642894745, 0.821880042552948, 0.21327076852321625, 0.5392467975616455, -0.8600126504898071, -0.17469821870326996, -0.2473185658454895, -0.690657377243042, -0.3858485519886017, -0.31883108615875244, -0.6529403328895569, -0.21406324207782745, -0.05232615023851395, 0.4378981590270996, 0.011183548718690872, 0.0727040022611618, 0.8897671103477478, 0.7220655083656311, 0.48786506056785583, -0.805740475654602, -0.41956305503845215, -0.3061692416667938, -1.1774622201919556, 0.333778977394104, -0.628308117389679, -0.10603161156177521, -0.028853945434093475, -0.09642481803894043, -0.0510089136660099]}, "authors": [{"authorId": "2109528333", "name": "Liu Liu"}, {"authorId": "46989001", "name": "Zheng Qu"}, {"authorId": "2029325771", "name": "Zhaodong Chen"}, {"authorId": "1910352", "name": "Fengbin Tu"}, {"authorId": "1766680", "name": "Yufei Ding"}, {"authorId": "2154871047", "name": "Yuan Xie"}], "references": [{"paperId": "da0d38cf2ac7e2a6908e0d9e1fff07058daab2ed", "title": "Sparse is Enough in Scaling Transformers"}, {"paperId": "5679ff44de6c462c6320ab497f80860d2faa14e8", "title": "Efficient Tensor Core-Based GPU Kernels for Structured Sparsity under Reduced Precision"}, {"paperId": "daab62304d0b1beeddad06846eaadce9c7610d9d", "title": "On the Distribution, Sparsity, and Inference-time Quantization of Attention Values in Transformers"}, {"paperId": "5af69480a7ae3b571df6782a11ec4437b386a7d9", "title": "ELSA: Hardware-Software Co-design for Efficient, Lightweight Self-Attention Mechanism in Neural Networks"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "4badd753be64c5c5b57dd2bb2e515fbe0c0720d8", "title": "SparseBERT: Rethinking the Importance Analysis in Self-attention"}, {"paperId": "ce591264d1dde550aa8492aca989779df55c905e", "title": "NeuroMeter: An Integrated Power, Area, and Timing Modeling Framework for Machine Learning Accelerators Industry Track Paper"}, {"paperId": "73e0f38ab49b19b86321016b773e15f1d02e3a72", "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "332ed8f86fb5b81c41067f04aa194d29db2b0491", "title": "DUET: Boosting Deep Neural Network Efficiency on Dual-Module Architecture"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "804a6d7c23335bbca6eec3b7d3c8366dcbe395a5", "title": "Hopfield Networks is All You Need"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "70e9a09de05aa7ed8a74d56cf2d13ea9e38a6328", "title": "Sparse GPU Kernels for Deep Learning"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "1b0c8b26affd13e10ace5770e85478d60dcc368e", "title": "GOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy Efficient Inference"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "d3c6c635b9cfd8890c7244d3db4be53d45944963", "title": "A^3: Accelerating Attention Mechanisms in Neural Networks with Approximation"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "f6390beca54411b06f3bde424fb983a451789733", "title": "Adaptively Sparse Transformers"}, {"paperId": "3366e9eb81880d172752d4397cb8e9e6de02b935", "title": "Efficient 8-Bit Quantization of Transformer Neural Machine Language Translation Model"}, {"paperId": "7edacd94dc1509803d9bbcc1d92fea780d71cb3e", "title": "MnnFast: A Fast and Scalable System Architecture for Memory-Augmented Neural Networks"}, {"paperId": "5a3749929bf5fb8b1f98a7b2a43c3b957bcf6c88", "title": "Efficient Training of BERT by Progressively Stacking"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "bf8fe437f779f2098f9af82b534aa51dc9edb06f", "title": "Scaling Neural Machine Translation"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "69e220145b5a7886f9c92da8a253b6cc97181f57", "title": "Bit Fusion: Bit-Level Dynamically Composable Architecture for Accelerating Deep Neural Network"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "e01eae8dea6fbaa1ae7fc83535053932268df430", "title": "The ACL anthology network corpus"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "\u201cCusparse library,\u201d"}]}