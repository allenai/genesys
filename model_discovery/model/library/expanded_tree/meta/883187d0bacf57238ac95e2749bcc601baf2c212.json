{"paperId": "883187d0bacf57238ac95e2749bcc601baf2c212", "abstract": "Transformer-based language models (LMs) are inefficient in long contexts. We propose Dodo, a solution for context compression. Instead of one vector per token in a standard transformer model, Dodo represents text with a dynamic number of hidden states at each layer, reducing the cost of self-attention to a fraction of typical time and space. Moreover, off-the-shelf models such as LLaMA can be adapted to Dodo by efficient parameter tuning methods such as LoRA. In use, Dodo can act as either an autoregressive LM or a context compressor for downstream tasks. We demonstrate through experiments in language modeling, question answering, and summarization that Dodo retains capabilities in these tasks, while drastically reducing the overhead during decoding. For example, in the autoencoding task, Dodo shrinks context at a 20x compression ratio with a BLEU score of 98% for reconstruction, achieving nearly lossless encoding.", "venue": "", "year": 2023, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Dodo is proposed, a solution for context compression that represents text with a dynamic number of hidden states at each layer, reducing the cost of self-attention to a fraction of typical time and space."}, "embedding": {"model": "specter_v2", "vector": [0.40532386302948, 0.42517852783203125, -0.12719732522964478, -0.0936586782336235, -0.654573380947113, -0.1929928958415985, 0.7445921897888184, 0.2330087274312973, -0.4990507662296295, -0.3294532001018524, 1.0198419094085693, -0.5119798183441162, 0.4348437190055847, -0.05398089438676834, 0.007613680325448513, 0.06867839395999908, -0.7676020860671997, -0.025682048872113228, -0.25589507818222046, -0.41146013140678406, -0.21201537549495697, -0.7234914302825928, -0.5741204619407654, 0.36194440722465515, 0.5348820686340332, 0.30599895119667053, 0.49153685569763184, 1.0442112684249878, -0.6346729397773743, 0.5794889330863953, 0.23776063323020935, -0.0802629292011261, -0.3817930221557617, -0.5706642270088196, -0.14043110609054565, -0.03041749633848667, 0.283596932888031, -0.3747205436229706, -0.5536134243011475, 0.5478606820106506, 0.012684942223131657, 0.07166565954685211, 0.30497196316719055, -0.11293117702007294, -0.29024064540863037, 1.1902002096176147, 0.622870683670044, 0.8693880438804626, 0.003993845544755459, -0.878003716468811, 1.263837456703186, -1.2033554315567017, 0.047718167304992676, 1.448811411857605, 0.4335482716560364, 0.6126893758773804, -0.2617799937725067, -0.22692126035690308, 0.933721661567688, 0.20788578689098358, -0.5857571363449097, -0.6250268220901489, 0.13107070326805115, 0.1610102504491806, 1.7351049184799194, -0.11188285052776337, 0.05106774717569351, 0.4390776455402374, 0.11568372696638107, 1.238122820854187, -0.028816044330596924, -0.9747395515441895, -0.18079842627048492, 0.13388724625110626, 0.06753096729516983, 0.44619810581207275, -0.5077853798866272, -0.2524130940437317, -0.7946258783340454, 0.01446577813476324, -0.23912957310676575, -0.21571120619773865, -0.026840656995773315, -0.20126865804195404, 0.04939797520637512, 0.5701088309288025, -0.10974204540252686, 0.9130852818489075, 0.1414312720298767, 0.7257000803947449, 0.5827792286872864, 0.39035120606422424, 0.42406731843948364, 0.31077975034713745, -0.002432668348774314, 0.1716064214706421, -1.034950613975525, 0.21173858642578125, -0.0774548202753067, 0.7093738317489624, -0.3709552586078644, 0.4330523610115051, -0.7352184057235718, 0.40789347887039185, 1.224799394607544, 0.3679311275482178, 0.7077294588088989, -0.7540926933288574, 0.48370760679244995, -0.9613127708435059, -0.08172018080949783, -0.6448092460632324, -0.07381780445575714, -0.79417484998703, -0.4999116063117981, -1.5301475524902344, -0.7137641310691833, -0.09961622208356857, -0.3874336779117584, 0.8682019114494324, -0.2635372579097748, 0.00798968318849802, 0.21505628526210785, 0.08533211797475815, 0.3376394510269165, 0.9362754225730896, -0.013198387809097767, -0.3175092041492462, 0.8110887408256531, -0.9927030205726624, -1.082777976989746, -1.4519364833831787, 0.8084477186203003, -0.24422869086265564, 0.30007803440093994, -0.06920165568590164, -1.2354997396469116, -0.6968696713447571, -0.9408472776412964, -0.20451627671718597, -0.46018943190574646, 0.17128071188926697, 0.48660755157470703, 0.6065018773078918, -0.9207890033721924, 0.6707236766815186, -0.312013179063797, -0.05575556308031082, 0.36095625162124634, -0.2512211203575134, 0.449527770280838, -0.4490378797054291, -1.2044390439987183, 0.21079055964946747, -0.17230629920959473, -0.8220527768135071, -0.055554069578647614, -0.6257733702659607, -1.2201465368270874, 0.06044163182377815, 0.18224897980690002, -0.5081253051757812, 1.254538893699646, 0.22520315647125244, -1.5156164169311523, 0.13549363613128662, -0.9071332216262817, -0.2427428662776947, 0.09714601933956146, -0.6847388744354248, -0.44252821803092957, -0.07599123567342758, -0.2592383027076721, 0.10978509485721588, 0.43785208463668823, 0.12586495280265808, -0.2984189987182617, 0.15696822106838226, -0.46953848004341125, 0.0081971799954772, -0.25344061851501465, 0.8030585646629333, -0.6091884970664978, -0.30362942814826965, 0.2621120512485504, 0.8613079190254211, -0.07869040966033936, -0.6275749802589417, -0.22723518311977386, -0.8384016156196594, 0.9968583583831787, -0.30773985385894775, 1.6099705696105957, -0.891167938709259, -0.7753268480300903, -0.432300329208374, -0.3219504952430725, -0.1309833824634552, -0.813795268535614, 0.7405869364738464, -0.44340309500694275, 0.3198617100715637, -0.3118387460708618, -1.4963034391403198, 0.04086269065737724, -0.2981475591659546, -0.9983887076377869, -0.1772102415561676, 0.262938916683197, 0.9207656383514404, -0.7821224331855774, 0.06434519588947296, 0.07521725445985794, 0.392516165971756, -1.1458075046539307, 1.0637476444244385, -0.4291878044605255, 0.4203665554523468, -0.0943901315331459, -0.09144719690084457, 0.024296971037983894, -0.09642692655324936, 0.664305567741394, -0.08199668675661087, -0.10158415138721466, 0.779735267162323, -0.24894551932811737, 1.2054297924041748, -0.7295987606048584, 0.9140422344207764, 0.04231953248381615, -0.7171156406402588, 0.040992189198732376, 0.28009119629859924, -0.0549202561378479, -0.40641921758651733, 0.4708646237850189, 0.29425325989723206, -0.7139827013015747, 0.32576897740364075, 0.7849141955375671, 0.8853799700737, -0.3738059401512146, 0.0598069503903389, 0.6926684975624084, -0.4941524565219879, 0.5927740335464478, 0.6977657675743103, 0.9509299993515015, 0.5400181412696838, 0.36113759875297546, 0.18894343078136444, 0.4047214090824127, -0.8517181277275085, -0.15183860063552856, 0.5251895189285278, 0.6829874515533447, 1.0716434717178345, 0.5764852166175842, -0.25589513778686523, -0.6690388321876526, 0.2146022617816925, 0.45274901390075684, 1.370442271232605, -0.6016208529472351, -0.6849116683006287, -1.0943888425827026, -0.20029804110527039, -0.6334136128425598, 0.526512086391449, -0.23974402248859406, -0.1330632120370865, -0.6705065965652466, -0.9004960656166077, 0.7599780559539795, 0.09885118901729584, 0.6275789737701416, -0.021410051733255386, -0.18384473025798798, -0.09244590997695923, -0.02337825298309326, -0.9179295301437378, -0.6814121603965759, 0.548617422580719, -0.7372303605079651, 0.040531981736421585, -0.08199438452720642, 0.08609580248594284, -0.04782294109463692, -0.5087942481040955, 0.8812965750694275, -0.5852011442184448, -0.008419685065746307, 0.4527147710323334, 0.2040022313594818, -0.6428512334823608, -0.9971396923065186, 0.11807821691036224, 0.06220141798257828, -0.059897229075431824, 0.22809018194675446, 0.11784522980451584, 0.08622261881828308, -0.29701048135757446, -0.38668403029441833, 0.09404782950878143, -0.072746641933918, -0.02070021815598011, 0.6023871302604675, -0.43402358889579773, -0.13151484727859497, -1.276259422302246, 0.9934478998184204, 0.10834822058677673, -0.16922134160995483, 0.029654178768396378, -0.8247292637825012, -0.32966211438179016, 0.6036458611488342, -0.3016556203365326, -0.3360884189605713, -0.9361546039581299, -0.010997137054800987, -0.045633282512426376, -0.13397563993930817, 0.30033260583877563, 0.0293809212744236, 0.7319471836090088, 0.05783757194876671, 0.5541507005691528, 0.2352418750524521, -0.4967336058616638, 0.745329737663269, -0.505416750907898, 0.6259968280792236, 0.4338028132915497, -0.026339448988437653, -0.10997769236564636, -0.0225023552775383, -0.9037320017814636, -0.40181392431259155, -0.246491476893425, -0.04609828442335129, -0.3931104242801666, 0.13945144414901733, -0.7278514504432678, -0.311020165681839, -0.43375641107559204, -0.9557696580886841, -0.09747882932424545, -0.08695758879184723, -0.3845897614955902, -0.19055408239364624, -0.719427764415741, -1.046746850013733, -0.6058803796768188, -0.5242027640342712, -0.9387463331222534, 0.3612467050552368, -0.11135228723287582, -0.3177344799041748, -0.5606588125228882, 0.08028383553028107, -0.35915136337280273, 0.8532932996749878, -0.5174977779388428, 0.8853980302810669, 0.000985032063908875, 0.030577899888157845, -0.3487408757209778, 0.5434389710426331, 0.6002097725868225, -0.3461322486400604, 0.03167827054858208, -0.8130250573158264, 0.06623149663209915, -0.09521062672138214, 0.014813369140028954, 0.24516315758228302, 0.4393707811832428, 0.5661101341247559, -0.12290329486131668, -0.46896159648895264, 0.4416366219520569, 1.229093313217163, -0.5297038555145264, 0.006526900455355644, 0.1478242129087448, 0.6627695560455322, 0.2038726806640625, -0.22866696119308472, 0.7383618950843811, 0.19774296879768372, 0.2725381553173065, 0.24035197496414185, 0.11268280446529388, -0.3327084481716156, -0.7066516876220703, 0.7812466621398926, 1.8618916273117065, 0.665533185005188, -0.44881367683410645, -0.9282139539718628, 0.6577585935592651, -0.8762355446815491, -0.4924129247665405, 0.4239158034324646, 0.41105028986930847, 0.33113279938697815, -0.6676274538040161, -0.6326807737350464, -0.01809084787964821, 0.3702862560749054, 0.5846943259239197, -0.19226525723934174, -0.8863839507102966, -0.15434236824512482, 0.39152002334594727, 0.14351624250411987, 0.9954791069030762, -0.45620599389076233, 0.37001171708106995, 15.011417388916016, 0.7415473461151123, 0.09713836759328842, 0.7662505507469177, 0.5516047477722168, -0.08040047436952591, -0.3132568299770355, 0.05966707319021225, -1.0354499816894531, -0.07529762387275696, 1.5184831619262695, 0.12291021645069122, 0.19459111988544464, 0.11193230748176575, 0.3365010917186737, 0.12536555528640747, -0.37244200706481934, 0.3607769310474396, 0.736430287361145, -1.242272973060608, 0.17074696719646454, 0.29995405673980713, 0.3284885287284851, 0.5404330492019653, 0.9804494976997375, 0.8042094111442566, 0.16090212762355804, -0.2047189474105835, 0.5933902859687805, 0.2343343198299408, 0.8464069962501526, -0.3219892382621765, 0.3463977575302124, 0.6226803064346313, -0.6950481534004211, -0.5395979285240173, -0.5267305374145508, -0.9372309446334839, 0.39364898204803467, 0.2645404040813446, -0.34587281942367554, -0.4593278765678406, -0.15334539115428925, 0.6579465866088867, -0.27299705147743225, 0.15989674627780914, 0.0724894255399704, 1.0588637590408325, -0.13795343041419983, -0.1449337750673294, 0.40053531527519226, 0.4400635361671448, 0.6276090145111084, 0.2912823557853699, 0.22799621522426605, -0.044624581933021545, -0.2352103739976883, 0.07535072416067123, -0.48806455731391907, 0.07447120547294617, -0.4046148359775543, -0.243803933262825, 0.062300391495227814, 0.2899080216884613, 0.7292221784591675, 0.11020578444004059, -0.38560616970062256, 0.2600615322589874, 0.3106546998023987, -0.0434669628739357, -0.06595735251903534, -0.4675453305244446, 0.11795704066753387, -0.14484241604804993, 0.3086143434047699, 0.420087069272995, -0.16074644029140472, -0.6983051896095276, -0.7965014576911926, -0.5852368474006653, 0.15914294123649597, -0.7462141513824463, -0.1221490427851677, 0.7873221635818481, -0.11690653860569, -0.583128809928894, 0.14838112890720367, -0.541885256767273, -0.1503390222787857, 0.3183928430080414, -1.3038429021835327, -0.2510562241077423, 0.677802562713623, -0.6060692071914673, -0.20921702682971954, -0.13968288898468018, 1.2254027128219604, 0.11885254830121994, -0.16826984286308289, -0.01786908693611622, 0.6688244938850403, -0.06798390299081802, -0.14160773158073425, -1.004867672920227, 0.6427700519561768, 0.6582551002502441, 0.11879885941743851, 0.3281450867652893, 0.48950526118278503, 0.4345042407512665, -0.8025747537612915, -0.08142944425344467, 0.9873728156089783, -0.8181923627853394, -0.3403085172176361, -0.9331338405609131, -0.7358655333518982, 0.05913792923092842, 0.7567673325538635, -0.30607926845550537, 0.45841434597969055, 0.07649185508489609, -0.19719825685024261, -0.2020452469587326, -0.705427348613739, 0.1752321422100067, 0.2482905089855194, -0.7561483979225159, -0.42461150884628296, -0.28985774517059326, 0.5651432871818542, -1.1599845886230469, -0.20082326233386993, -0.3791598677635193, -0.08828163146972656, -0.07293164730072021, 0.6381972432136536, -0.2303619235754013, 0.9231148362159729, 0.8507078886032104, -0.42206594347953796, -0.8132883310317993, 0.17616361379623413, -0.8307571411132812, -0.2861580550670624, 0.6572704911231995, 0.5565524101257324, -0.06126328185200691, 0.150007963180542, 0.6582208871841431, 0.1470664143562317, -0.5476775169372559, -0.9830027222633362, 0.020028330385684967, 0.5190979838371277, -0.9466849565505981, 0.37855979800224304, -0.28710049390792847, 0.03354928269982338, 0.33268189430236816, 0.3736668527126312, 0.6257553696632385, -0.28496116399765015, -0.9675857424736023, 0.37922418117523193, 0.35457471013069153, -0.1222449317574501, -0.43375298380851746, -0.5161725878715515, -1.686676025390625, -0.20383226871490479, -0.9266448616981506, -0.18371038138866425, -0.9431525468826294, -0.6630292534828186, 0.40037041902542114, 0.019999297335743904, -0.28903457522392273, 0.3414551317691803, -0.35279789566993713, -0.05250292271375656, -1.1266934871673584, -0.7045823931694031, 1.002095341682434, 0.606827974319458, -0.9255009293556213, 0.19230671226978302, -0.056103356182575226, -0.013019395060837269, 0.3439112603664398, 0.3294382095336914, -0.5261194109916687, -0.7612231969833374, -1.6287846565246582, 0.3648354411125183, -0.00962966587394476, -0.3504767417907715, -0.8212833404541016, 0.47642725706100464, 0.6966432332992554, -0.20435956120491028, -0.2299259901046753, 0.2379613220691681, -0.7031093835830688, -0.7461112141609192, 0.22798308730125427, -1.093605399131775, 0.29105719923973083, 0.16695339977741241, -0.3226248025894165, -0.38584572076797485, 0.5620272159576416, -0.05928172916173935, -0.9904204607009888, -0.2732622027397156, 0.1382654905319214, -1.1163033246994019, 0.33450791239738464, -0.7068535685539246, 0.09462810307741165, -0.9281215667724609, -0.813547670841217, -0.042159561067819595, 0.25207337737083435, -0.4933464527130127, 1.0307252407073975, 0.1940121203660965, -0.8556191325187683, -0.0070622945204377174, 0.1342705488204956, -0.3840108811855316, -0.13806073367595673, 0.5429533123970032, 0.20492665469646454, -0.3798503875732422, 0.8212292194366455, 0.8143457174301147, 0.13997025787830353, -0.9985031485557556, -0.10904446989297867, 0.7128155827522278, -0.6028594970703125, -0.29906022548675537, 0.9548189043998718, -0.5673120617866516, -0.8692361116409302, 0.03500380739569664, -1.3090262413024902, -0.6506302356719971, -0.06391936540603638, 0.9364598989486694, 0.23548327386379242, -0.017197122797369957, -0.026824889704585075, -0.5106547474861145, 0.2551611661911011, 0.11060502380132675, -0.7536609172821045, 0.8868684768676758, -0.786449134349823, -0.4845620095729828, 0.677078902721405, 0.9100071787834167, -0.09773460775613785, -0.5440282225608826, -0.788771390914917, -0.5281383395195007, -0.056537218391895294, 0.7517228126525879, -0.44694727659225464, -0.03060591034591198, 1.056478500366211, 0.6605823636054993, 0.5157667994499207, 0.3586094379425049, -0.11782676726579666, 0.08611347526311874, 0.6529286503791809, -0.15041081607341766, -0.7023135423660278, -0.7494493126869202, 1.447013258934021, 1.157673716545105, -0.4860664904117584, 0.5184646844863892, 0.40826237201690674, -0.6437759399414062, 0.9169459342956543, -0.09548110514879227, 0.07351935654878616, 0.9556649327278137, 0.02552020736038685, 0.19550099968910217, 0.7021351456642151, -1.4879897832870483, -0.21633869409561157, 0.6059199571609497, 1.1378651857376099, 0.8629934191703796, -0.004141737706959248, -0.031643133610486984, 1.097342610359192, 0.1416618973016739, -0.15133507549762726, 0.7781402468681335, 0.5682356953620911, -0.29346904158592224, -0.41771429777145386, -0.23227426409721375, 0.5244410634040833, -1.1554625034332275, -0.62913978099823, 0.27953580021858215, 0.31075403094291687, 0.2481481283903122, 1.1248598098754883, 0.7960971593856812, 0.14805075526237488, 0.502910315990448, 0.3906385898590088, 0.4536347985267639, -0.6521536707878113, -0.1282229721546173, 0.1236339658498764, -0.45282331109046936, 0.06349837779998779, 0.01772521808743477, -0.7965399026870728, -0.11726614087820053, -0.09701264649629593, 0.34152889251708984, 0.31074124574661255, 0.5109833478927612, 1.0841032266616821, 0.6255783438682556, 0.7796569466590881, 0.06383172422647476, -0.28742459416389465, -0.32729652523994446, -0.9748170971870422, 0.05462019145488739, -0.827838659286499, 0.16952145099639893, 0.30854538083076477, -0.043912675231695175, -0.037621721625328064]}, "authors": [{"authorId": "38733050", "name": "Guanghui Qin"}, {"authorId": "41016119", "name": "Corby Rosset"}, {"authorId": "2253668443", "name": "Ethan C. Chau"}, {"authorId": "2253470896", "name": "Nikhil Rao"}, {"authorId": "7536576", "name": "Benjamin Van Durme"}], "references": [{"paperId": "531b37c44c7e39539f617fb1a4149ef8cce8f4ec", "title": "Nugget: Neural Agglomerative Embeddings of Text"}, {"paperId": "5e0cb1c4b91a7486e1c2b15a44a0be56bd74bdc0", "title": "Effective Long-Context Scaling of Foundation Models"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "b069c32fcd77160f944ab3ba71ab6f0cfb782c68", "title": "Focused Transformer: Contrastive Training for Context Scaling"}, {"paperId": "c12db2c60e8989f646a29ad4f4d24475e860ad91", "title": "LongNet: Scaling Transformers to 1, 000, 000, 000 Tokens"}, {"paperId": "2f7364d8e5cf94315bf8905f57de9c5543e9a4bf", "title": "Adapting Language Models to Compress Contexts"}, {"paperId": "ffdf78392747ad50c6bb39adab124726db05c3da", "title": "Vcc: Scaling Transformers to 128K Tokens or More by Prioritizing Important Tokens"}, {"paperId": "dbc368bc8b49347dd27679894524fa62f88492c9", "title": "Unlimiformer: Long-Range Transformers with Unlimited Length Input"}, {"paperId": "fd689ba4d1db7c92664ea4176943d640405f0ef2", "title": "Why Does ChatGPT Fall Short in Providing Truthful Answers?"}, {"paperId": "b9870e130f61ff900fe00dbcc5782c9b31773d32", "title": "Learning to Compress Prompts with Gist Tokens"}, {"paperId": "27d391d65ab42c30dc35595213ba6585633afa5d", "title": "CoLT5: Faster Long-Range Transformers with Conditional Computation"}, {"paperId": "4afda39036206dcb3f97829dccb897f1fc80f459", "title": "Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models"}, {"paperId": "1d26c947406173145a4665dd7ab255e03494ea28", "title": "GLM-130B: An Open Bilingual Pre-trained Model"}, {"paperId": "2fc384087f55111a196c96d88029aab324aa543e", "title": "ChordMixer: A Scalable Neural Attention Model for Sequences with Different Lengths"}, {"paperId": "00b28e5f100aa35e83487b17013b8235cdf45c3c", "title": "Multi-View Document Representation Learning for Open-Domain Dense Retrieval"}, {"paperId": "8db711adf1beb3e0c2ec492f3936841d827404e9", "title": "The NLP Task Effectiveness of Long-Range Transformers"}, {"paperId": "e0cbbca02b332f398c6639b3bea0613f79166220", "title": "ABC: Attention with Bounded-memory Control"}, {"paperId": "cddf40e579a596d0110b260313adf43470617c4c", "title": "Datasets: A Community Library for Natural Language Processing"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": null, "title": "Transformers: State-of-the-Art Natural Language Processing"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "725264948d7b6946259af5b8d966e996b9570f99", "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"}, {"paperId": "ea8c46e193d5121e440daf96edfd15a47151c293", "title": "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "58ed1fbaabe027345f7bb3a6312d41c5aac63e22", "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "e1678aece552737a99e46b3e4ddb854347466e1e", "title": "Differentiable Top-k Operator with Optimal Transport"}, {"paperId": "832fff14d2ed50eb7969c4c4b976c35776548f56", "title": "REALM: Retrieval-Augmented Language Model Pre-Training"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "7be8c119dbe065c52125ee7716601751f3116844", "title": "Generalization through Memorization: Nearest Neighbor Language Models"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "668db48c6a79826456341680ee1175dfc4cced71", "title": "Get To The Point: Summarization with Pointer-Generator Networks"}, {"paperId": "29e944711a354c396fad71936f536e83025b6ce0", "title": "Categorical Reparameterization with Gumbel-Softmax"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "62c76ca0b2790c34e85ba1cce09d47be317c7235", "title": "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": null, "title": "Rethinking Attention with Per-formers"}, {"paperId": null, "title": "William A. Falcon and The PyTorch Lightning team"}, {"paperId": null, "title": "2024. In-context Autoencoder for Context Compression in a Large Language Model"}, {"paperId": null, "title": "Together Computer"}, {"paperId": null, "title": "2022. Efficient Transformers: A Survey"}, {"paperId": null, "title": "2023. How Long Can Context Length of Open-Source LLMs truly Promise?"}, {"paperId": null, "title": "2023. Fast, Dif-ferentiable and Sparse Top-k: A Convex Analysis Perspective"}, {"paperId": null, "title": "2022. Recurrent Memory Transformer"}, {"paperId": null, "title": "2022. PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods"}, {"paperId": null, "title": "2022. LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": null, "title": "2023. LLMLingua: Compress-ing Prompts for Accelerated Inference of Large Language Models"}]}