{"paperId": "17a8bd6a5763f6607863348ce1757ac2ad3417fd", "abstract": "The transformer model has become a crucial deep learning model as it provides accuracy superior to that by conventional models in various domains, such as image processing, genomics, and natural language processing. Recently, the importance of the softmax layer has increased as a growing number of transformer models process longer sequences to improve their accuracy rates. However, it is difficult to accelerate a softmax layer with methods introduced in previous studies due to the differences in the data access patterns of softmax layers and other adjacent layers. We address this challenge by accelerating the softmax layer through a recomposition strategy. By decomposing the softmax layer into multiple sub-layers, we change its data access pattern. Then, we fuse the decomposed softmax sub-layers with the subsequent and preceding operations. Softmax recomposition achieves up to 1.25 $\\times$, 1.12 $\\times$, 1.57 $\\times$, and 1.65 $\\times$ speedups in inferring BERT, GPT-Neo, BigBird, and Longformer on a modern GPU by significantly reducing the off-chip memory traffic.", "venue": "IEEE International Symposium on Workload Characterization", "year": 2022, "citationCount": 7, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The transformer model has become a crucial deep learning model as it provides accuracy superior to that by conventional models in various domains, such as image processing, genomics, and natural language processing, and this work addresses this challenge by accelerating the softmax layer through a recomposition strategy."}, "embedding": {"model": "specter_v2", "vector": [0.19542619585990906, 0.6185305118560791, -0.34577256441116333, -0.2534443438053131, 0.13278336822986603, -0.004005728755146265, 0.5844182968139648, -0.2655735909938812, -0.6015695929527283, -0.4457356929779053, 0.4532637596130371, 0.03336780518293381, 0.8557974100112915, -0.13034743070602417, -0.2376934289932251, 0.017736006528139114, -0.7595477104187012, 0.0007301817531697452, 0.5376313328742981, -0.32186171412467957, -0.07368727028369904, -0.38008931279182434, -1.4795281887054443, 0.4275560677051544, -0.011225711554288864, 0.9921247363090515, 0.17508265376091003, 0.9013221859931946, -0.5101064443588257, 0.552055835723877, 0.46404343843460083, -0.582641065120697, 0.3517100214958191, 0.1909547746181488, -0.3368999660015106, -0.16236867010593414, 0.1914486587047577, -0.37633052468299866, -0.552597165107727, 1.0158292055130005, -0.3450467586517334, 0.38840216398239136, -0.05411641299724579, -0.7410181164741516, 0.09564722329378128, 0.7984535098075867, 0.7413667440414429, 0.764887809753418, -0.7107033133506775, -0.7791472673416138, 1.0634042024612427, -1.0594260692596436, -0.31388503313064575, 1.246693730354309, 0.7018154263496399, 0.22396017611026764, 0.18897908926010132, -0.572827935218811, 0.7222335338592529, 0.06208048388361931, -0.41013041138648987, -0.4638751447200775, 0.009023929014801979, -0.0061521464958786964, 1.9412446022033691, -0.34318816661834717, 0.051112446933984756, 0.7231336832046509, 0.13436603546142578, 1.3251838684082031, -0.13752497732639313, -0.3755408823490143, -0.18740683794021606, -0.037849944084882736, 0.518225908279419, 1.1237103939056396, -0.3880816698074341, 0.4013083577156067, -1.3298616409301758, -0.1317024677991867, 0.2056226283311844, 0.4044841527938843, 0.5148078203201294, 0.05856535583734512, -0.2589838206768036, 0.5516419410705566, 0.3830238878726959, 0.3620772659778595, -0.3976118564605713, 1.046701431274414, 0.5635386109352112, -0.08093895763158798, -0.026863129809498787, 0.16823944449424744, -0.07630472630262375, 0.17961221933364868, -0.8381279110908508, -0.3048182427883148, -0.18110814690589905, 0.8997610211372375, -0.478141725063324, 0.29403311014175415, -0.41041165590286255, 0.2112666368484497, 1.4447914361953735, -0.039610423147678375, 0.3234597444534302, -0.5146564841270447, 0.22191718220710754, -0.6795045137405396, -0.2835580110549927, -0.35408300161361694, -0.2394045740365982, -0.586177408695221, -0.7777814269065857, -0.812828004360199, -0.6748509407043457, 0.09297673404216766, -1.1741524934768677, 0.5160415172576904, -0.538982629776001, 0.45087379217147827, 0.014535712078213692, 0.04924376681447029, 0.24680037796497345, 0.8448585271835327, 0.23109690845012665, 0.233132466673851, 1.2167994976043701, -1.3866825103759766, -0.3674125671386719, -1.0742344856262207, 0.021229105070233345, -0.2530474066734314, -0.1514805108308792, 0.05341165512800217, -1.15244722366333, -1.060245394706726, -1.0450050830841064, 0.22415679693222046, -0.568742036819458, -0.07068668305873871, 1.095651388168335, 0.27205735445022583, -1.180423378944397, 0.9759235382080078, -0.6766384840011597, -0.18782010674476624, 0.4070018529891968, 0.17613328993320465, 0.4442037343978882, 0.16527992486953735, -1.0828824043273926, 0.177560955286026, 0.6305710673332214, -0.552753210067749, -0.32208603620529175, -0.6782947778701782, -0.8046454787254333, 0.5327476859092712, -0.06057300791144371, -0.5663108825683594, 1.3457088470458984, 0.01306375302374363, -1.2505671977996826, 0.4723602533340454, -0.2058619260787964, 0.09838692098855972, 0.2298712432384491, 0.010532364249229431, -0.6055052280426025, -0.28479495644569397, -0.6535050868988037, 0.27870842814445496, 0.5537911057472229, 0.1979525089263916, -0.47165554761886597, 0.4184211492538452, -0.2599278390407562, -0.45272767543792725, -0.6804189085960388, 0.925512433052063, -0.4446498155593872, -0.4631645381450653, 0.38130053877830505, 0.7069345712661743, -0.1767507642507553, -0.0461176298558712, -0.4495569169521332, -0.7271343469619751, 0.5356981754302979, -0.10213931649923325, 0.6550341248512268, -0.9970282912254333, -0.8063969016075134, 0.03481689840555191, 0.04410035163164139, -0.01639125682413578, -0.8690019249916077, 0.35208845138549805, -0.4149482548236847, 0.03881661221385002, 0.18727324903011322, -1.0192358493804932, 0.00605354318395257, -0.14478401839733124, -0.5782508850097656, -0.33207017183303833, 0.31995508074760437, 1.0687216520309448, -0.9917973279953003, 0.18682317435741425, -0.19950000941753387, 0.40700748562812805, -1.0615557432174683, 1.2167937755584717, -0.2625312805175781, -0.37046441435813904, 0.25558534264564514, 0.202632337808609, 0.23631729185581207, -0.620728075504303, 0.5599996447563171, -0.5680434107780457, -0.02588321454823017, 0.7004241943359375, -0.13423018157482147, 1.1026848554611206, 0.009055458009243011, 0.38885319232940674, -0.10754748433828354, -1.038543462753296, 0.4418413043022156, 0.2135254591703415, -0.2080749273300171, -0.5405194163322449, 0.4939388036727905, 0.12943241000175476, -0.7482885718345642, 0.4040038287639618, 0.8948757648468018, 0.6438895463943481, -0.2168421894311905, -0.15315544605255127, 0.8195196390151978, 0.3255695700645447, 0.21854549646377563, 0.10061480849981308, 0.5333569645881653, 0.2745932936668396, 0.11354061216115952, 0.042131226509809494, 0.11816776543855667, -1.0696016550064087, 0.20319145917892456, 0.5935056209564209, 0.3598477840423584, 0.5367833971977234, 0.54884934425354, -0.6078506112098694, -0.25635355710983276, -0.10635971277952194, 0.5739208459854126, 1.7788385152816772, -0.162567138671875, -0.029237153008580208, -0.43525055050849915, -0.45125749707221985, -0.18310359120368958, -0.32094407081604004, -0.20032058656215668, -0.5830204486846924, -0.15222345292568207, -1.5888614654541016, 1.1804581880569458, 0.5338165760040283, 1.1438654661178589, -0.21471692621707916, -0.2946934401988983, -0.3719797432422638, 0.1351981908082962, -0.9150824546813965, -0.3554983139038086, 0.7974795699119568, -0.8096511363983154, -0.012093639001250267, 0.1715438812971115, -0.2059079259634018, 0.23810791969299316, -0.7216537594795227, 0.7413881421089172, -0.6261422038078308, 0.1516009420156479, -0.24672509729862213, 0.298811137676239, -0.565811812877655, -0.9392009973526001, 0.3051910698413849, 0.16681526601314545, -0.05319688841700554, 0.2067217081785202, 0.35992178320884705, 0.27987608313560486, 0.06359081715345383, -0.46870675683021545, 0.23273581266403198, 0.1084374263882637, -0.16871145367622375, 0.6344168186187744, -0.3548935055732727, 0.13269448280334473, -0.973471999168396, 0.6419286131858826, -0.10007882863283157, -0.5667452216148376, 0.34417539834976196, -0.675631046295166, 0.2266831248998642, 0.578576922416687, -0.5967960357666016, -0.24956262111663818, -0.7930600047111511, -0.1539468914270401, -0.4832650125026703, 0.2775624692440033, 0.15491387248039246, 0.4782876968383789, 0.04172830656170845, 0.14077675342559814, 0.747303307056427, 0.3576335310935974, -0.21819329261779785, 0.201841339468956, -0.8638174533843994, 0.7161816358566284, 0.5759183168411255, 0.18748682737350464, -0.2190561145544052, 0.003494895761832595, -0.4471723735332489, -0.4275229573249817, -0.36627399921417236, -0.1563660055398941, -0.3903307020664215, -0.061390023678541183, -0.46371662616729736, -1.044886589050293, 0.20021651685237885, -0.9431488513946533, -0.05769335478544235, 0.3685859441757202, -0.3384856581687927, 0.008357973769307137, -0.9448453187942505, -1.1961960792541504, -0.5516583323478699, -0.7527421712875366, -0.9713636040687561, 0.034653179347515106, 0.3563483655452728, 0.0355030782520771, -0.44593602418899536, -0.326895534992218, -0.24991704523563385, 1.1590698957443237, -0.5440795421600342, 0.5238080024719238, -0.17540185153484344, -0.30302631855010986, -0.23961928486824036, 0.13468898832798004, 0.7853877544403076, -0.2900899350643158, 0.3096201419830322, -1.2638477087020874, 0.4505203664302826, -0.5495006442070007, 0.02178383804857731, 0.6239098310470581, 0.10575494170188904, 0.7222736477851868, 0.07465190440416336, -0.5632578134536743, 0.7525113224983215, 1.075576901435852, -0.36751797795295715, -0.07732907682657242, 0.20292505621910095, 0.8470267057418823, -0.3180335462093353, -0.26053234934806824, 0.6983863115310669, -0.03490862250328064, 0.15352493524551392, 0.4966576397418976, -0.22979162633419037, 0.022124648094177246, -0.5267657041549683, 0.536998450756073, 1.4372100830078125, 0.2432439923286438, 0.04045051708817482, -0.9044131636619568, 0.3666393458843231, -1.3217016458511353, -0.898717999458313, 0.7717369794845581, 0.477989137172699, 0.33500826358795166, -0.002914512762799859, -0.3219742774963379, -0.0381053201854229, 0.33217817544937134, 0.60410076379776, -0.678540825843811, -0.761832058429718, 0.06769107282161713, 0.4660170376300812, 0.4682222604751587, 0.7241833806037903, -0.36025360226631165, 0.4133380949497223, 15.01732349395752, 0.5205554962158203, -0.3765864670276642, 0.5564387440681458, 0.5758059620857239, 0.015453916043043137, -0.022779442369937897, -0.312786340713501, -1.509629249572754, 0.04658001661300659, 1.2784149646759033, 0.4051362872123718, 0.5914022922515869, 0.4871624708175659, -0.39411619305610657, 0.2025844305753708, -0.35092538595199585, 0.6654796004295349, 0.4846048355102539, -1.6053168773651123, 0.05184921994805336, -0.0622280091047287, -0.08394059538841248, 0.8608816266059875, 0.6256402730941772, 0.7661995887756348, 0.6313745975494385, -0.19751174747943878, 0.7099162340164185, 0.3163771331310272, 0.6026521921157837, -0.10425344109535217, 0.8138229846954346, 0.3901183605194092, -0.9564964771270752, -0.012239203788340092, -0.55179762840271, -1.086142659187317, 0.10155642777681351, 0.31576231122016907, -0.7377206683158875, -0.37003377079963684, 0.050997596234083176, 0.9851811528205872, 0.12937523424625397, 0.28302690386772156, -0.25232020020484924, 0.5366445779800415, -0.2862323522567749, -0.07461722940206528, -0.00018899801943916827, 0.6162449717521667, 0.10945096611976624, 0.1734241247177124, -0.05931733548641205, -0.11575981974601746, -0.03598249703645706, 0.29882049560546875, -0.6924528479576111, -0.6658916473388672, 0.31890520453453064, -0.5996482968330383, -0.10348107665777206, 0.9413806200027466, 0.2362363636493683, 0.06791219115257263, -0.42059773206710815, 0.5279539227485657, 0.3667679727077484, 0.048342522233724594, -0.7739202976226807, -0.18398141860961914, 0.767315149307251, -0.4972282350063324, 0.10324560850858688, 0.7454684972763062, -0.21683050692081451, -0.6908342242240906, -0.5749145150184631, -0.2107110470533371, 0.6074154376983643, -0.7532840371131897, -0.5876187086105347, 1.083688735961914, -0.5598196983337402, -0.24589461088180542, 0.4727210998535156, -1.069315791130066, -0.13473312556743622, 0.5554690361022949, -1.5476484298706055, -0.24647995829582214, 0.0897536501288414, -0.33721742033958435, -0.5244559049606323, -0.10403642803430557, 1.1175668239593506, 0.34565237164497375, -0.2917359471321106, 0.132403165102005, -0.14412568509578705, 0.1907009780406952, -0.3259586989879608, -0.5101978182792664, 1.0734226703643799, 0.6223196387290955, -0.31240081787109375, 0.08987811952829361, -0.154899001121521, 0.37573927640914917, -0.5045837759971619, -0.19066445529460907, 0.7278462648391724, -0.5228842496871948, -0.27061405777931213, -0.7894167304039001, -0.7084041237831116, 0.635984480381012, 0.31177055835723877, -0.21045126020908356, 0.3190630078315735, 0.2920021712779999, -0.7777741551399231, -0.40893858671188354, -0.45710304379463196, 0.01454958040267229, 0.6612000465393066, -0.6375178694725037, -0.1219327300786972, -0.3634549677371979, 0.4476265013217926, -0.8690100908279419, -0.6231271028518677, -0.022896116599440575, 0.338430255651474, -0.31718987226486206, 1.381089687347412, -0.5872564315795898, 0.9206093549728394, 0.8996878862380981, -0.15496285259723663, -0.524495005607605, -0.20644409954547882, -0.6025756001472473, -0.14375728368759155, 0.04172255098819733, 0.4168549180030823, -0.6429979205131531, 0.5010297298431396, 0.40211740136146545, 0.08137168735265732, -0.4773890972137451, -0.40566012263298035, -0.1412259191274643, -0.42547518014907837, -0.7218750715255737, 0.37935927510261536, 0.12154768407344818, 0.24084152281284332, -0.20065949857234955, 0.3359213173389435, 0.7752465009689331, -0.22099818289279938, -0.6864085793495178, -0.13381484150886536, -0.35412824153900146, -0.48712560534477234, -0.6870339512825012, -0.7310172319412231, -1.3002588748931885, -0.21556542813777924, -1.5161385536193848, 0.06329755485057831, -0.6688500046730042, -0.30534443259239197, 0.19281446933746338, -0.7193426489830017, 0.6549656391143799, 0.014838513918220997, -0.39164653420448303, -0.2252873033285141, -0.7508604526519775, -0.47651544213294983, 0.7907500863075256, 0.6877821683883667, -0.6931347250938416, 0.3604831099510193, 0.06556614488363266, -0.07378994673490524, 0.4324449896812439, 0.5345837473869324, -0.4562687277793884, -0.6632663011550903, -1.1602623462677002, 0.5077359676361084, -0.08628036826848984, -0.10845592617988586, -0.8429521918296814, 0.8645972609519958, 0.20280300080776215, 0.10990216583013535, 0.11001456528902054, 0.4771503508090973, -0.8059471249580383, -0.5388507843017578, 0.6734719276428223, -0.5584366321563721, 0.257487416267395, 0.5735900402069092, -0.6831362247467041, -0.2943466007709503, 0.8019147515296936, 0.11669094115495682, -0.7753744721412659, -1.1550981998443604, 0.31492501497268677, -0.6482272744178772, -0.24371232092380524, -0.32523205876350403, -0.029375944286584854, -1.3515321016311646, -0.11674930900335312, -0.10283690690994263, 0.44948065280914307, -0.5923235416412354, 1.144658088684082, 0.3820509612560272, -1.0688081979751587, 0.33422863483428955, 0.5700942277908325, -0.08415589481592178, -0.23380155861377716, 0.34459224343299866, 0.5775269269943237, -0.461589515209198, 0.20641884207725525, -0.08387728780508041, 0.30828991532325745, -1.057201623916626, 0.08031735569238663, 1.0616110563278198, -0.5609468221664429, -0.018361322581768036, 1.4755632877349854, -0.5105400681495667, -1.0552899837493896, 0.3903914988040924, -1.383048176765442, -0.4559241831302643, -0.19116072356700897, 0.6814661622047424, 0.1900760382413864, 0.24097850918769836, 0.5081670880317688, -0.8322290778160095, -0.36328041553497314, -0.04369324445724487, -0.2535454034805298, 0.646013617515564, 0.4236302077770233, -0.4320162236690521, 0.39934444427490234, 0.6260327696800232, -0.8749949932098389, -0.9576119184494019, -0.8967111110687256, -0.3457097113132477, 0.03212115541100502, 0.29996663331985474, -0.20731887221336365, -0.8492271900177002, 0.733777642250061, 0.4756660461425781, 0.1462172269821167, 0.4689173698425293, -0.11907634884119034, 0.20922912657260895, 0.7311473488807678, -0.12412342429161072, -0.6017990708351135, -0.3887445628643036, 1.534968614578247, 0.797046959400177, -0.8436286449432373, 0.07299739122390747, -0.4162099063396454, -0.49238017201423645, 0.8311579823493958, 0.09974250942468643, 0.12038148939609528, 1.1917672157287598, 0.28303366899490356, -0.013445223681628704, 0.5481486916542053, -0.9734213352203369, -0.1812572479248047, 0.6043602824211121, 0.726231575012207, 0.5789523720741272, 0.1460934281349182, 0.6401331424713135, 1.2926387786865234, 0.16070078313350677, 0.11205920577049255, 0.21608978509902954, 0.6999945044517517, -0.16227978467941284, -0.08592776209115982, -0.1651313602924347, 0.6753385663032532, -0.7057706713676453, -0.9283549189567566, 0.4264428913593292, 0.196048766374588, 0.18963608145713806, 0.3698233962059021, 1.0520858764648438, -0.5502258539199829, 0.6124687790870667, 0.3983544409275055, 0.2094707041978836, -0.2542836368083954, -0.3397584557533264, -0.40526747703552246, -0.574988603591919, -0.1697802096605301, -0.11726238578557968, -0.4486476182937622, -0.5228247046470642, -0.603032112121582, 0.6621195673942566, -0.1587473750114441, 0.366001695394516, 0.9912724494934082, 0.6705095171928406, 1.2569282054901123, -0.3240068256855011, -0.5373544692993164, -0.539608895778656, -0.7806928753852844, 0.07229622453451157, -0.7585781216621399, -0.020466003566980362, 0.004251884296536446, -0.10140785574913025, 0.03802826255559921]}, "authors": [{"authorId": "1624393348", "name": "Jaewan Choi"}, {"authorId": "2120459970", "name": "Hailong Li"}, {"authorId": "2109885180", "name": "Byeongho Kim"}, {"authorId": "2185199205", "name": "Seunghwan Hwang"}, {"authorId": "2575874", "name": "Jung Ho Ahn"}], "references": [{"paperId": "f193bb0e865eb0dfe8fb7eed49baa3d40174e5ba", "title": "Future Scaling of Memory Hierarchy for Tensor Cores and Eliminating Redundant Shared Memory Traffic Using Inter-Warp Multicasting"}, {"paperId": "a7a62a32989afe90d514e744a436229724cc04a7", "title": "A Slice and Dice Approach to Accelerate Compound Sparse Attention on GPU"}, {"paperId": "0f1358b84f319947e20304edd42ec6fdd2d5de2c", "title": "A length adaptive algorithm-hardware co-design of transformer on FPGA through sparse attention and dynamic pipelining"}, {"paperId": "8bb197ec64709c305c007cfff4260e2a782c8577", "title": "Accelerating Framework of Transformer by Hardware Design and Model Compression Co-Optimization"}, {"paperId": "7e5008713c404445dd8786753526f1a45b93de12", "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow"}, {"paperId": "b080ba53a471348e7e76234decdf14e730fea7db", "title": "Softermax: Hardware/Software Co-Design of an Efficient Softmax for Transformers"}, {"paperId": "73e0f38ab49b19b86321016b773e15f1d02e3a72", "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"}, {"paperId": "0c775d7ed34fb4690b4291490778649ae75c48d2", "title": "TurboTransformers: an efficient GPU serving system for transformer models"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "7c6c31412c5dad22543bb71e31620e8868d644a3", "title": "FTRANS: energy-efficient acceleration of transformers using FPGA"}, {"paperId": "725264948d7b6946259af5b8d966e996b9570f99", "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"}, {"paperId": "3836ccb33191799e748e8e96f85a813eaf650ff8", "title": "Data Movement Is All You Need: A Case Study on Optimizing Transformers"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "d3c6c635b9cfd8890c7244d3db4be53d45944963", "title": "A^3: Accelerating Attention Mechanisms in Neural Networks with Approximation"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "661d142c23cb2a3207d5f1ba2ac7ff61f2d4fb2f", "title": "Triton: an intermediate language and compiler for tiled neural network computations"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "b4cc6d84341a57d628c05439c6bd13757976a60a", "title": "Restructuring Batch Normalization to Accelerate CNN Training"}, {"paperId": "cb91c2f8d3cac0b655a39be318b603334eb18987", "title": "Learning to Optimize Tensor Programs"}, {"paperId": "ec1f582446aa24f3f0920123ee6f05feea0b5e0a", "title": "Online normalizer calculation for softmax"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "b36a5bb1707bb9c70025294b3a310138aae8327a", "title": "Automatic differentiation in PyTorch"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "6757659aeba247db2a35691ee3b4c029e1a2dcf4", "title": "Kernel Fusion: An Effective Method for Better Power Efficiency on Multithreaded GPU"}, {"paperId": null, "title": "Nsight Compute Documentation"}, {"paperId": null, "title": "NVIDIA A100 Tensor Core GPU Architecture"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "5f5c839797d5619a8c67d17abbfe85d5ae76f321", "title": "Neural Information Processing"}, {"paperId": "a07609c2ed39d049d3e59b61408fb600c6ab0950", "title": "GPU Kernels for Block-Sparse Weights"}, {"paperId": null, "title": "CUTLASS: Fast Linear Algebra in CUDA C++"}, {"paperId": null, "title": "Efficient inference with tensorrt"}, {"paperId": null, "title": "Introduction to Machine Learning 3rd edition"}, {"paperId": null, "title": "GPU Performance Analysis and Optimization"}, {"paperId": null, "title": "cuBLAS"}]}