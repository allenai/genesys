{"paperId": "86c8d930b492a4f9cadc6c60aecdaaded49acc86", "abstract": "Recently, numerous efficient Transformers have been proposed to reduce the quadratic computational complexity of standard Transformers caused by the Softmax attention. However, most of them simply swap Softmax with an efficient attention mechanism without considering the customized architectures specially for the efficient attention. In this paper, we argue that the handcrafted vanilla Transformer architectures for Softmax attention may not be suitable for efficient Transformers. To address this issue, we propose a new framework to find optimal architectures for efficient Transformers with the neural architecture search (NAS) technique. The proposed method is validated on popular machine translation and image classification tasks. We observe that the optimal architecture of the efficient Transformer has the reduced computation compared with that of the standard Transformer, but the general accuracy is less comparable. It indicates that the Softmax attention and efficient attention have their own distinctions but neither of them can simultaneously balance the accuracy and efficiency well. This motivates us to mix the two types of attention to reduce the performance imbalance. Besides the search spaces that commonly used in existing NAS Transformer approaches, we propose a new search space that allows the NAS algorithm to automatically search the attention variants along with architectures. Extensive experiments on WMT' 14 En-De and CIFAR-10 demonstrate that our searched architecture maintains comparable accuracy to the standard Transformer with notably improved computational efficiency.", "venue": "arXiv.org", "year": 2022, "citationCount": 17, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2207.13955", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper argues that the handcrafted vanilla Transformer architectures for Softmax attention may not be suitable for efficient Transformers, and proposes a new framework to find optimal architectures for efficientTransformers with the neural architecture search (NAS) technique."}, "embedding": {"model": "specter_v2", "vector": [0.04156627878546715, 0.6924014687538147, -0.21170246601104736, 0.13251818716526031, -0.31116771697998047, -0.1599602848291397, 0.31642961502075195, -0.650551974773407, -0.5077574253082275, -0.3058316111564636, 0.4837091267108917, -0.044271741062402725, 0.5741931796073914, 0.21573708951473236, 0.18419836461544037, -0.2026256024837494, -0.19084882736206055, 0.24423301219940186, 0.12175828218460083, -0.485903799533844, 0.05483975633978844, -0.5360972881317139, -0.7621088624000549, -0.1449703425168991, 0.29121097922325134, 1.3878777027130127, 0.4497825503349304, 0.6141095161437988, -0.6873734593391418, 0.4699103534221649, 0.37791258096694946, -0.8535382747650146, 0.15128853917121887, 0.3759705126285553, -0.611733078956604, 0.023163622245192528, 0.41873255372047424, -0.22011233866214752, -0.470253586769104, 1.0775607824325562, -0.185921311378479, 0.15090319514274597, 0.34092584252357483, -0.7615570425987244, -0.3318833112716675, 0.4737802743911743, 0.6538341045379639, 0.8733492493629456, -1.0922716856002808, -0.2385796755552292, 1.344648838043213, -1.3663647174835205, -0.11982081830501556, 0.9642014503479004, 0.12214688956737518, 0.2552373707294464, -0.010130650363862514, -0.8385491967201233, 0.42298418283462524, 0.46372634172439575, -0.9198924899101257, -0.6605463027954102, 0.36777883768081665, -0.044046685099601746, 2.0236425399780273, -0.4965095818042755, -0.13183672726154327, 0.4184066951274872, 0.20348022878170013, 1.151978850364685, -0.17926810681819916, -0.6631166934967041, 0.055495187640190125, -0.1403820514678955, 0.5115737318992615, 0.8433488607406616, -0.0983550101518631, 0.029401391744613647, -0.9190027117729187, -0.03264407068490982, 0.2613932490348816, -0.026419896632432938, 0.11113300919532776, -0.21197809278964996, -0.042806267738342285, 0.8369290828704834, 0.7960490584373474, 0.7211684584617615, -0.3820933699607849, 1.0392311811447144, 0.5664071440696716, 0.16479374468326569, -0.11497654765844345, 0.8136327266693115, -0.4230455756187439, 0.6602315306663513, -0.8728099465370178, -0.25358548760414124, -0.5463295578956604, 0.8345814347267151, -0.18242742121219635, 0.9030902981758118, -0.505912184715271, 0.1734117865562439, 1.3313593864440918, 0.2515169382095337, 0.5356841087341309, -0.5663557648658752, 0.40900784730911255, -0.35303041338920593, -0.2627064287662506, -0.2289172261953354, -0.18491435050964355, -0.5613557696342468, -1.204551339149475, -0.7803949117660522, -0.7887047529220581, 0.29333439469337463, -0.9905897974967957, 0.4534572660923004, -0.607054591178894, 0.24559946358203888, -0.15164898335933685, 0.4881080985069275, 0.3835742175579071, 0.5432595610618591, 0.19083161652088165, 0.24686679244041443, 1.1324704885482788, -1.1867393255233765, -0.6872550249099731, -0.9378055930137634, 0.21280108392238617, -0.6791352033615112, 0.274777352809906, -0.21794764697551727, -1.2511712312698364, -0.8691781759262085, -1.0350240468978882, 0.005046014674007893, -0.30203142762184143, 0.08682563900947571, 0.733471155166626, 0.4527505338191986, -1.2191134691238403, 0.5214309692382812, -0.4533483386039734, -0.10010983794927597, 0.7946251630783081, 0.5729371309280396, 0.6989476680755615, 0.20691055059432983, -0.8442627191543579, 0.6613683104515076, 0.09896230697631836, -0.5682244300842285, -0.3278050720691681, -0.1366071105003357, -0.8947097063064575, 0.5698021054267883, 0.10392114520072937, -0.9988270401954651, 1.3388746976852417, -0.633039116859436, -1.3724045753479004, 0.23031137883663177, -0.090596504509449, 0.2303425818681717, -0.5196613073348999, 0.1768309473991394, -0.48575231432914734, -0.3236146867275238, -0.6676675081253052, 0.3402574956417084, 0.8804715871810913, 0.21671970188617706, -0.05577744171023369, 0.3849911391735077, -0.1154390349984169, -0.18062736093997955, -0.8986530303955078, 0.993180513381958, -0.15350410342216492, -0.40875425934791565, 0.2968408167362213, 0.6035046577453613, -0.12357242405414581, -0.15181560814380646, -0.5521253347396851, -0.8358311653137207, 0.524018406867981, 0.22165729105472565, 0.9302048683166504, -0.8112832307815552, -0.5255432724952698, 0.04534181207418442, 0.14523562788963318, -0.08437225967645645, -0.9439800977706909, -0.3196534812450409, -0.5604743361473083, 0.0662500336766243, 0.1397850662469864, -0.8199891448020935, 0.3047957122325897, -0.2842741906642914, -0.5669692754745483, -0.04768173396587372, -0.043856799602508545, 1.3063633441925049, -0.14732691645622253, 0.027679696679115295, -0.17277686297893524, 0.3981969356536865, -0.8715240955352783, 1.1280601024627686, 0.17759574949741364, -0.16123180091381073, -0.08682778477668762, 0.10159967839717865, 0.04983043298125267, -0.8610004186630249, 0.27046406269073486, -0.8822548985481262, 0.22187666594982147, 0.5775669813156128, -0.1875927895307541, 1.0494043827056885, -0.34359297156333923, 0.8717857599258423, 0.10639763623476028, -0.9482083916664124, 0.019375547766685486, 0.6071556210517883, -0.3039929270744324, -0.735297441482544, 0.7072786092758179, 0.1736879199743271, -0.45304369926452637, 0.33409255743026733, 0.7857515215873718, 1.0142364501953125, -0.4455041289329529, 0.05385735258460045, 0.8832526803016663, -0.07120029628276825, -0.09109083563089371, 0.13351422548294067, 0.6517481207847595, -0.20253707468509674, 0.3924160301685333, -0.22748203575611115, 0.3659292757511139, -0.8517407178878784, -0.029565639793872833, 0.17830845713615417, 0.3437190353870392, 0.7605177760124207, 0.005615371745079756, -0.8547638654708862, -0.5077714920043945, -0.17565006017684937, 0.7335339784622192, 1.506522536277771, -0.08214545994997025, 0.03370583429932594, -0.5655442476272583, -0.24710971117019653, -1.1229431629180908, -0.11167945712804794, 0.05923996493220329, -0.3839855194091797, -0.5156779289245605, -1.1973625421524048, 1.0295946598052979, 0.24790288507938385, 1.2936816215515137, -0.17203381657600403, -0.40503406524658203, -0.6367033123970032, -0.17257973551750183, -0.9149670004844666, -0.7933167815208435, 0.3048606216907501, -0.7246726155281067, -0.18975286185741425, -0.08970673382282257, -0.28784212470054626, 0.24385268986225128, -0.6467844247817993, 1.039143681526184, -0.6027316451072693, 0.06752868741750717, 0.03005238249897957, 0.6467011570930481, -0.4890832006931305, -0.31633689999580383, 0.6320009231567383, -0.012636701576411724, -0.21355465054512024, 0.2548447549343109, 0.4120248854160309, -0.153648242354393, 0.04034203290939331, -0.025532016530632973, -0.04563125967979431, 0.2885824739933014, 0.316849023103714, 0.6855617761611938, -0.4527633786201477, 0.0782211571931839, -0.7265167236328125, 1.0255180597305298, 0.34843340516090393, -0.7312626838684082, 0.4685874879360199, -0.8475269675254822, 0.41305971145629883, 0.3987278640270233, -0.32463666796684265, -0.22406969964504242, -0.8122628927230835, 0.040889889001846313, -0.7123655080795288, 0.22101828455924988, -0.11057310551404953, 0.2471809834241867, -0.23323024809360504, 0.3718189597129822, 0.6022505164146423, 0.06090812012553215, 0.08642611652612686, 0.22709967195987701, -0.8445367217063904, 0.3623812794685364, 0.6066776514053345, 0.5371443629264832, -0.38338813185691833, -0.24251769483089447, -0.4077129364013672, -0.20767328143119812, -0.020918745547533035, 0.10428027808666229, -0.03150453418493271, 0.2461193948984146, -0.5658413171768188, -0.7416771054267883, -0.07025318592786789, -1.1638683080673218, 0.061768822371959686, 0.001213941490277648, -0.022421924397349358, 0.0058437129482626915, -1.249963402748108, -1.1992018222808838, -0.17594893276691437, -1.263288974761963, -1.636974811553955, 0.18826666474342346, 0.1763424575328827, -0.3570418655872345, -0.2682884633541107, -0.32565683126449585, -0.15975376963615417, 1.8777791261672974, -1.0059181451797485, 0.9574882388114929, -0.19483210146427155, -0.6270617842674255, 0.01406991295516491, 0.10639741271734238, 0.39258304238319397, -0.5525456070899963, -0.047127049416303635, -1.1087017059326172, 0.4908333718776703, -0.20740005373954773, -0.05134468525648117, 0.08633600920438766, 0.6100412011146545, 0.7492956519126892, -0.20198966562747955, -0.2240016907453537, 0.6916406750679016, 1.2918413877487183, -0.608275294303894, 0.4182196855545044, 0.38197076320648193, 1.0567716360092163, -0.3002546727657318, -0.6699601411819458, 0.14710605144500732, 0.2808806598186493, 0.44424769282341003, 0.6979996562004089, -0.2543802559375763, -0.29102301597595215, 0.19677159190177917, 0.2072727382183075, 1.7998926639556885, -0.02781573310494423, 0.23762176930904388, -0.7177548408508301, 0.4705202877521515, -1.0279256105422974, -0.6348089575767517, 0.7225072383880615, 0.5560926795005798, 0.09144744277000427, -0.31819239258766174, -0.7145834565162659, -0.10457601398229599, 0.6329157948493958, 0.43395504355430603, -0.09568620473146439, -1.0662174224853516, 0.049995020031929016, 1.026501178741455, 0.6495876312255859, 0.5032421350479126, -0.1302344650030136, 0.5152889490127563, 14.724183082580566, 0.9896222949028015, -0.2543339729309082, 1.0719943046569824, 0.5384947657585144, 0.0809212252497673, -0.19455185532569885, -0.15920239686965942, -0.7595705389976501, 0.0651351660490036, 0.8811190724372864, 0.3233635723590851, 0.6493293046951294, 0.4448282718658447, -0.5428625345230103, 0.7155938744544983, -0.13248027861118317, 1.112298846244812, 0.24518252909183502, -1.7282931804656982, 0.2999875247478485, 0.18016742169857025, 0.41687750816345215, 0.8339210748672485, 0.7139021754264832, 0.6653170585632324, 0.30892592668533325, -0.35193127393722534, 0.3939838707447052, -0.12924912571907043, 0.9078003764152527, -0.17602847516536713, 0.5660819411277771, -0.02352277748286724, -1.055468201637268, -0.07446810603141785, -0.6048239469528198, -1.0612761974334717, -0.13402169942855835, 0.11512306332588196, -0.0532803051173687, -0.5100125074386597, -0.12524229288101196, 0.181452676653862, 0.15762875974178314, 0.6404818892478943, -0.6092196702957153, 0.49534881114959717, -0.05958276614546776, 0.019073422998189926, 0.24489726126194, 0.7410182356834412, 0.34449344873428345, -0.5616018176078796, 0.15989872813224792, -0.2803277373313904, -0.10194168984889984, 0.2579087018966675, -0.9192796945571899, -0.2856774628162384, 0.1607542634010315, -0.13052715361118317, 0.2064608484506607, 0.9632318615913391, 0.1727241426706314, 0.08227238804101944, -0.24958573281764984, 0.3581642508506775, 0.5605334043502808, 0.4934195876121521, -0.7554240226745605, -0.36832284927368164, 0.5492064952850342, -0.6452324390411377, 0.015452926978468895, 0.6456130743026733, -0.6898813247680664, -0.897155225276947, -0.7691578269004822, -0.2801717221736908, 0.5189942717552185, -1.121174693107605, -0.33744075894355774, 1.5298658609390259, -0.46370255947113037, -0.346634179353714, 0.7471554279327393, -0.8147037625312805, -0.2484249323606491, 0.3551691770553589, -1.53296959400177, -0.6688499450683594, 0.17254748940467834, 0.029613221064209938, -0.11344611644744873, -0.7311922907829285, 1.128611445426941, 0.3522108197212219, -0.5880742073059082, 0.48238393664360046, -0.25265029072761536, 0.17005997896194458, -0.29062819480895996, -0.3056982159614563, 0.7133058905601501, 0.5131784081459045, -0.11634320765733719, -0.2839808762073517, 0.01883064955472946, 0.9360467791557312, -0.5619672536849976, -0.0577348992228508, 0.6640283465385437, -0.6521467566490173, -0.23160332441329956, -0.5182065367698669, -0.4227840304374695, 0.375715434551239, 0.8691546320915222, -0.37160423398017883, 0.19434323906898499, 0.017721666023135185, -0.6731663942337036, -0.3901275396347046, -0.7183647155761719, 0.16653452813625336, 0.21677470207214355, -0.7675925493240356, -0.5815311074256897, -0.17996518313884735, 0.3221658170223236, -0.7936064600944519, -0.23167307674884796, -0.21802960336208344, -0.06655888259410858, 0.3051353096961975, 1.2221928834915161, -0.07342135906219482, 0.6197400093078613, 0.7540461421012878, -0.3046993315219879, -0.842971682548523, -0.3429374694824219, -0.7064366936683655, -0.113195039331913, -0.08773616701364517, 0.5828765630722046, -0.8008355498313904, 0.42600110173225403, 0.9233005046844482, -0.12106730788946152, -0.31469282507896423, -0.9558494091033936, 0.15785102546215057, -0.5575973987579346, -0.5401710271835327, 0.6765307784080505, -0.0814133808016777, 0.04461327940225601, 0.45183566212654114, 0.6866187453269958, 0.5014766454696655, -0.0630590096116066, -0.3969593346118927, -0.05837325006723404, -0.05875334143638611, -0.12208706885576248, -1.1426433324813843, -0.696915864944458, -1.564927577972412, -0.0191152635961771, -1.19855535030365, -0.28493303060531616, -0.7971577644348145, -0.4384704530239105, 0.23206065595149994, -0.5182856321334839, 0.4109429717063904, 0.38969823718070984, 0.03967989981174469, -0.3143848180770874, -0.1864631623029709, -0.4967744052410126, 0.9921772480010986, 0.6280139684677124, -1.19704270362854, 0.23087289929389954, -0.18837939202785492, -0.399293452501297, 0.5104191303253174, 0.4059860408306122, -0.5759740471839905, -0.8447543382644653, -1.5594494342803955, 0.35156863927841187, -0.49987274408340454, -0.40941303968429565, -0.7212134003639221, 1.174882173538208, 0.33156150579452515, -0.09540466219186783, 0.368907630443573, 0.37259140610694885, -1.2065014839172363, -0.6401318311691284, 0.5427024960517883, -0.525854766368866, 0.608614444732666, 0.06165720522403717, -0.8994261026382446, -0.3135696351528168, 0.6378730535507202, 0.3877236545085907, -0.79599529504776, -1.121138572692871, 0.354295551776886, -0.6740879416465759, 0.007102526258677244, -0.25017550587654114, -0.36052724719047546, -1.594414472579956, 0.016782589256763458, -0.17925933003425598, 0.3712989389896393, -0.5442541241645813, 0.45469385385513306, 0.581885576248169, -1.1462198495864868, 0.2831364870071411, 0.35301175713539124, -0.08749151974916458, -0.22796089947223663, 0.43266531825065613, 0.7574024796485901, -0.642143726348877, 0.45499974489212036, 0.10044846683740616, 0.22248804569244385, -0.7159407734870911, -0.06763659417629242, 1.2116752862930298, -0.6892215013504028, 0.13404348492622375, 1.1905723810195923, -0.06776940077543259, -0.7898645997047424, 0.1328115463256836, -1.2714624404907227, -0.46424600481987, -0.46104395389556885, 0.5002995729446411, -0.045010652393102646, 0.19103705883026123, 0.047075916081666946, -0.771952748298645, 0.19727489352226257, 0.036023084074258804, -0.2865038514137268, 0.5343212485313416, -0.27912646532058716, -0.43275174498558044, -0.14854630827903748, 0.8040046095848083, -1.3622691631317139, -0.36231380701065063, -0.740313708782196, -0.22679276764392853, -0.0688072070479393, 0.6472890377044678, -0.19641540944576263, -1.6060487031936646, 0.7376186847686768, 0.9504971504211426, -0.19487597048282623, 0.8151397705078125, -0.028248749673366547, 0.2524469196796417, 0.7254718542098999, 0.13614532351493835, -0.7047687768936157, -0.28733959794044495, 1.4008667469024658, 1.0656166076660156, -0.6093320250511169, 0.330487459897995, -0.04561397060751915, -0.5136648416519165, 0.8631599545478821, 0.22042487561702728, -0.027811206877231598, 0.9202696084976196, 0.10727246105670929, -0.21741926670074463, -0.1386684775352478, -1.0120859146118164, -0.36853623390197754, 0.901627242565155, 0.796838641166687, 0.3841061592102051, -0.015777727589011192, 0.4211733937263489, 1.0767693519592285, 0.03554638475179672, -0.11395473033189774, 0.5466516613960266, 0.3182518184185028, -0.1509232372045517, 0.25316494703292847, -0.1570197343826294, 0.4475591778755188, -0.9957163333892822, -0.7665448188781738, 0.28899314999580383, 0.5221849083900452, 0.012998457998037338, 0.3766920864582062, 0.9286481142044067, -0.11504023522138596, 0.6917138695716858, 0.2221573442220688, 0.45117709040641785, -0.18638527393341064, -0.42644137144088745, -0.13660113513469696, -0.6287223696708679, -0.10488612949848175, -0.0898161381483078, 0.15873242914676666, -0.02167670428752899, -0.3724082410335541, -0.039282385259866714, -0.30152860283851624, 0.5478095412254333, 1.0696227550506592, 0.6922150254249573, 1.1029831171035767, -0.21495576202869415, -0.7865609526634216, -0.286482572555542, -0.7135947942733765, 0.142573282122612, -0.5333101749420166, -0.23497994244098663, -0.14502355456352234, -0.08255831897258759, -0.22761812806129456]}, "authors": [{"authorId": "2846136", "name": "Zexiang Liu"}, {"authorId": "2179703418", "name": "Dong Li"}, {"authorId": "8500733", "name": "Kaiyue Lu"}, {"authorId": "2171650015", "name": "Zhen Qin"}, {"authorId": "8397429", "name": "Weixuan Sun"}, {"authorId": "34837371", "name": "Jiacheng Xu"}, {"authorId": "2015152", "name": "Yiran Zhong"}], "references": [{"paperId": "6be32b4321f95b79bb2e37feeab0c3c7f902195e", "title": "Vicinity Vision Transformer"}, {"paperId": "c49ac1f916d6d2edeb187e6619c8d23acd95eb21", "title": "cosFormer: Rethinking Softmax in Attention"}, {"paperId": "4a8964ea0de47010fb458021b68fa3ef5c4b77b2", "title": "Primer: Searching for Efficient Transformers for Language Modeling"}, {"paperId": "255c526f78bbfec35d4ed73b6dd8eacd9ef2c0b3", "title": "RankNAS: Efficient Neural Architecture Search by Pairwise Ranking"}, {"paperId": "66775d9f16b3f4ca43dba2b31c7c42ca6dcba72b", "title": "GLiT: Neural Architecture Search for Global and Local Image Transformer"}, {"paperId": "d645bd08fc19d52164695f9cd5ae863345459a06", "title": "AutoFormer: Searching Transformers for Visual Recognition"}, {"paperId": "472fb54ea252d56bc28b2a5f7f4726fa9619e649", "title": "HR-NAS: Searching Efficient High-Resolution Neural Architectures with Lightweight Transformers"}, {"paperId": "1a57318be32b740aef1d9b2070db6c0cc565ab0a", "title": "Memory-Efficient Differentiable Transformer Architecture Search"}, {"paperId": "a7721b6523971394a8bd4bfda139122ef59b22cd", "title": "Sparse Attention with Linear Units"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "465d1f6a0db8fd981897a251afb1e79b601a9fc6", "title": "A Survey on Evolutionary Neural Architecture Search"}, {"paperId": "ffb0bbe26f1cbc0ab22ef34784248f2dcd3a5e5c", "title": "Finding Fast Transformers: One-Shot Neural Architecture Search by Component Composition"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "0b991a1a5bcdb13646ac0b6873d09bde4cc36fb5", "title": "Masked Language Modeling for Proteins via Linearly Scalable Long-Context Transformers"}, {"paperId": "ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7", "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language Processing"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "ace0f5e70a7c3632ffdcd7c216c8e7deb63eac41", "title": "TextNAS: A Neural Architecture Search Space tailored for Text Representation"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "16c844fd4d97f3c6eb38b0d6527c87d184efedc3", "title": "The Evolved Transformer"}, {"paperId": "c1f457e31b611da727f9aef76c283a18157dfa83", "title": "DARTS: Differentiable Architecture Search"}, {"paperId": "b79e5e4622a95417deec313cd543617b19611bea", "title": "Deep Learning using Rectified Linear Units (ReLU)"}, {"paperId": "50bdda28de3dcf82a0e10f9ec13eea248b19edb5", "title": "Regularized Evolution for Image Classifier Architecture Search"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "1071b2435e0afa04c797dc09bf4ed9a630767b0c", "title": "On the Properties of the Softmax Function with Application in Game Theory and Reinforcement Learning"}, {"paperId": "01434a4153d5340c00d9e2f910f462a841a7bca3", "title": "One-vs-Each Approximation to Softmax for Scalable Estimation of Probabilities"}, {"paperId": "5ec85a0d88adcc4344bb5cc81b0d1aef9bcd8dcc", "title": "Findings of the 2014 Workshop on Statistical Machine Translation"}, {"paperId": "b8a919f4a2aaa97bef19aa43e01f8bc347693b73", "title": "NASViT: Neural Architecture Search for Efficient Vision Transformers with Gradient Conflict aware Supernet Training"}, {"paperId": "764c400ac71c73eb533223723520b6b8a44cd5bf", "title": "AutoAttend: Automated Attention Representation Search"}, {"paperId": null, "title": "Set transformer: A framework for attention-based permutation-invariant neural networks"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": null, "title": "Feature Importance in mFormer With RankNAS [16], we can know the importance of each feature when searching the proposed mFormer"}, {"paperId": null, "title": "Neural architecture search: A survey"}]}