{"paperId": "5fcb8a666d2becb26cc0d64677bb8c9c6d74cadc", "abstract": null, "venue": "", "year": 2020, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": null, "embedding": null, "authors": [{"authorId": "2238982194", "name": "Steven Shearing"}, {"authorId": "2238980230", "name": "Abigail Gertner"}, {"authorId": "2238980238", "name": "Benjamin Wellner"}, {"authorId": "2238980356", "name": "Liz Merkhofer"}], "references": [{"paperId": "4f09e6ec1b7d4390d23881852fd7240994abeb58", "title": "A statistical interpretation of term specificity and its application in retrieval"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "4fb0a181676a5200bc6e53dea1b770613c164aab", "title": "Leveraging Graph to Improve Abstractive Multi-Document Summarization"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "5092c0a0d6c0bfefc89e4d19a803e00f67aad969", "title": "Graph-based Neural Sentence Ordering"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "cca42b7e53a2d5e5c0f995735043e84a3b1cc89c", "title": "Studying Summarization Evaluation Metrics in the Appropriate Scoring Range"}, {"paperId": "9d6e6cd09b2f47a74c41848563608367db3df363", "title": "A Survey on Neural Network Language Models"}, {"paperId": "cc27ec53160d88c25fc5096c0df65536eb780de4", "title": "Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model"}, {"paperId": "7cc730da554003dda77796d2cb4f06da5dfd5592", "title": "Hierarchical Transformers for Multi-Document Summarization"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22", "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"}, {"paperId": "62cb1067cd297d9fb36e87ccddf93a01d4a7b3e1", "title": "A Simple and Effective Approach to Coverage-Aware Neural Machine Translation"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "80becd9dacaa403e1dc7da5ea2f148db6a252ec2", "title": "Graph-based Neural Multi-Document Summarization"}, {"paperId": "668db48c6a79826456341680ee1175dfc4cced71", "title": "Get To The Point: Summarization with Pointer-Generator Networks"}, {"paperId": "7228d90f4241c7da5ca8e53182a2d89bf74db565", "title": "Unsupervised Learning of Sentence Embeddings Using Compositional n-Gram Features"}, {"paperId": "1bc49abe5145055f1fa259bd4e700b1eb6b7f08d", "title": "SummaRuNNer: A Recurrent Neural Network Based Sequence Model for Extractive Summarization of Documents"}, {"paperId": "b108211139032738c21d2937a63433b97b31e77d", "title": "Efficient Summarization with Read-Again and Copy Mechanism"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "29a294eaec7b485245aa21d994f7300f6b5da8fc", "title": "Neural Summarization by Extracting Sentences and Words"}, {"paperId": "f37076f426023241f19cdc2fb0a0fd733a6fa7fa", "title": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond"}, {"paperId": "221ef0a2f185036c06f9fb089109ded5c888c4c6", "title": "Sequence-to-Sequence RNNs for Text Summarization"}, {"paperId": "1ac30af5522c7a50ec4d1ee43fd2bd8652a9bd52", "title": "A Neural Attention Model for Abstractive Sentence Summarization"}, {"paperId": "b631b2cad1771418c2c71251bd608277c2797a1e", "title": "Extractive Summarization by Maximizing Semantic Volume"}, {"paperId": "f04df4e20a18358ea2f689b4c129781628ef7fc1", "title": "A large annotated corpus for learning natural language inference"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "dbe193dc6d9bb313cb4298da26f9ab38b807e51e", "title": "Summarization Through Submodularity and Dispersion"}, {"paperId": "3d4a123b8036f3bd81ad2659af69865cde404909", "title": "Towards Coherent Multi-Document Summarization"}, {"paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09", "title": "Efficient Estimation of Word Representations in Vector Space"}, {"paperId": "f5ce3e9636bed47b377405cd85d3a4abc3b3a234", "title": "A Class of Submodular Functions for Document Summarization"}, {"paperId": "e652a53cad618fa6cf1c7e20dc72691d8b055436", "title": "DivRank: the interplay of prestige and diversity in information networks"}, {"paperId": "9cc8c1e575c59f2c89212895054f7e2060837bee", "title": "Multi-document Summarization via Budgeted Maximization of Submodular Functions"}, {"paperId": "a45e8c83e137b5b4490be0046784e9f74ce1216a", "title": "Improving Diversity in Ranking using Absorbing Random Walks"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "7b95d389bc6affe6a127d53b04bcfd68138f1a1a", "title": "TextRank: Bringing Order into Text"}, {"paperId": "44fca068eecce2203d111213e3691647914a3945", "title": "LexRank: Graph-based Lexical Centrality as Salience in Text Summarization"}, {"paperId": "ffb46f26ebff29b31b16c6e4b60d85019e19ac75", "title": "Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies"}, {"paperId": "eb82d3035849cd23578096462ba419b53198a556", "title": "The PageRank Citation Ranking : Bringing Order to the Web"}, {"paperId": "95d1b7763d9359644bbc08268bf1f9f118b0a14d", "title": "Siamese Neural Networks: An Overview"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Attention is all you"}, {"paperId": "a9075f6332542e12b2bf3cdbdb3a6ed44733fb41", "title": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)"}, {"paperId": "bbd66cbe4014c24c6a5223017dbe79186358636e", "title": "Automatic Summarization"}, {"paperId": "70cb232a6e391bfa49b0441a9956820c52ec32f2", "title": "Evaluating Content Selection in Summarization: The Pyramid Method"}, {"paperId": null, "title": "An introduction to duc2004"}]}