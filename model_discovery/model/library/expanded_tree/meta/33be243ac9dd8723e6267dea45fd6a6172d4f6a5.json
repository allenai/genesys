{"paperId": "33be243ac9dd8723e6267dea45fd6a6172d4f6a5", "abstract": "Layer-wise distillation is a powerful tool to compress large models (i.e. teacher models) into small ones (i.e., student models). The student distills knowledge from the teacher by mimicking the hidden representations of the teacher at every intermediate layer. However, layer-wise distillation is difficult. Since the student has a smaller model capacity than the teacher, it is often under-fitted. Furthermore, the hidden representations of the teacher contain redundant information that the student does not necessarily need for the target task's learning. To address these challenges, we propose a novel Task-aware layEr-wise Distillation (TED). TED designs task-aware filters to align the hidden representations of the student and the teacher at each layer. The filters select the knowledge that is useful for the target task from the hidden representations. As such, TED reduces the knowledge gap between the two models and helps the student to fit better on the target task. We evaluate TED in two scenarios: continual pre-training and fine-tuning. TED demonstrates significant and consistent improvements over existing distillation methods in both scenarios. Code is available at https://github.com/cliang1453/task-aware-distillation.", "venue": "arXiv.org", "year": 2022, "citationCount": 35, "influentialCitationCount": 1, "openAccessPdf": {"url": "http://arxiv.org/pdf/2210.01351", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": null}, "embedding": {"model": "specter_v2", "vector": [0.09569729119539261, 0.8427050113677979, -0.3372220993041992, 0.021317599341273308, -0.4147317111492157, 0.038533855229616165, 0.5291072726249695, -0.08472707867622375, -0.5564488172531128, -0.21243751049041748, 0.6789941191673279, -0.19447162747383118, 0.05434410274028778, 0.40053147077560425, -0.04009079560637474, 0.1594885140657425, -0.47894448041915894, 0.5035272240638733, -0.07295016199350357, -0.5097179412841797, -0.6452771425247192, -0.8872729539871216, -0.940035343170166, 0.25859665870666504, 0.9211668968200684, 0.5238233208656311, 0.48898789286613464, 0.9143292903900146, -0.5460646748542786, 0.3019985258579254, 0.47532176971435547, -0.38716208934783936, 0.347480833530426, -0.2068205624818802, -0.32187962532043457, -0.04642205685377121, 0.3084699511528015, -0.37495893239974976, -0.4170394837856293, 0.6816492676734924, 0.013418104499578476, 0.2731325626373291, 0.8375255465507507, -0.2322918027639389, -0.3237895369529724, 0.9195495843887329, 0.7025372982025146, 0.6732861995697021, -0.47285914421081543, -0.9721000790596008, 0.8643312454223633, -1.3727478981018066, -0.3320644199848175, 1.5241297483444214, 0.5580646991729736, 0.7456768155097961, -0.6510717868804932, -0.9521206617355347, 0.82535320520401, 0.15484721958637238, -0.7915269732475281, -0.15052059292793274, 0.11943808943033218, -0.32944679260253906, 1.4467424154281616, -0.20924189686775208, -0.01835317350924015, 0.5987973213195801, -0.4076897203922272, 1.8119227886199951, 0.1098141223192215, -0.6377197504043579, -0.4513258635997772, 0.3360041379928589, 0.10072720050811768, 0.9141859412193298, -0.3426190912723541, 0.32147690653800964, -0.8818603754043579, 0.02859550341963768, 0.13066807389259338, -0.1604754477739334, -0.14155727624893188, -0.2841459810733795, 0.0735517367720604, 0.7741062641143799, 0.2195989191532135, 0.8445425033569336, -0.021546674892306328, 0.6321531534194946, 0.3072146475315094, 0.4067372679710388, 0.33122172951698303, 0.6460227966308594, -0.03549639880657196, 0.4807156026363373, -1.3017295598983765, 0.3002597689628601, 0.020698124542832375, 0.7318937182426453, -0.1289132833480835, 0.2784571945667267, -0.9394798278808594, 0.40648502111434937, 1.399754524230957, -0.3966623842716217, 0.9547163248062134, -0.8276291489601135, 0.4960303008556366, -1.0100620985031128, -0.3770773112773895, -0.5930958986282349, -0.07996290922164917, -0.4172610938549042, -0.6692847013473511, -1.3293898105621338, -0.7416305541992188, -0.15058310329914093, -1.0346263647079468, 0.8337883353233337, -0.5137103199958801, 0.6345092058181763, -0.06201652064919472, 0.33626148104667664, 0.3388081192970276, 0.5443044900894165, 0.49178004264831543, 0.16516214609146118, 0.8491405248641968, -1.0410765409469604, -0.7810304760932922, -1.1428381204605103, 0.5697246789932251, -0.5178626775741577, -0.030383877456188202, -0.04984406754374504, -1.4706456661224365, -1.175021767616272, -1.0406038761138916, -0.35939842462539673, -0.6079010963439941, 0.3386085033416748, 0.8607322573661804, 0.44507545232772827, -0.5242915749549866, 0.8985400795936584, -0.2594141662120819, 0.1794903427362442, 0.4430137574672699, -0.08196555078029633, 0.30236223340034485, -0.49569007754325867, -1.0954903364181519, 0.2661103904247284, 0.7026203870773315, -0.8176237940788269, -0.33555859327316284, -1.0543848276138306, -0.8794490694999695, 0.06784792989492416, 0.2721276879310608, -0.7051849365234375, 1.4321460723876953, 0.2781812846660614, -1.24993097782135, 0.37946176528930664, -0.2674788534641266, -0.11092371493577957, 0.4776346683502197, -0.4805256128311157, -0.39142346382141113, -0.40749579668045044, -0.3363204896450043, 0.7035138607025146, 0.5500728487968445, -0.24539390206336975, -0.07851821184158325, 0.48009932041168213, -0.42597851157188416, 0.2467762976884842, -0.298817902803421, 0.4502220153808594, -0.44749563932418823, -0.7480919361114502, 0.603766679763794, 0.8716879487037659, 0.061513833701610565, -0.2135591059923172, -0.5180811285972595, -0.9790663123130798, 0.9690155386924744, -0.16536271572113037, 1.0258463621139526, -0.9334842562675476, -0.5771186351776123, -0.33160698413848877, 0.3587084114551544, 0.25144168734550476, -1.0126898288726807, 0.4853654205799103, -0.24978865683078766, 0.47354769706726074, -0.22175346314907074, -1.6658663749694824, 0.3582455813884735, -0.13234876096248627, -0.5968242883682251, -0.6811786890029907, 0.05219743773341179, 0.90398108959198, -0.7318658232688904, -0.11051356792449951, -0.015471142716705799, 0.5150351524353027, -1.4329948425292969, 1.2862330675125122, -0.5804387927055359, 0.3839108645915985, -0.20873136818408966, -0.3645208179950714, 0.12709477543830872, -0.10146090388298035, 0.13698558509349823, -0.3439859449863434, 0.27745699882507324, 0.8103567957878113, -0.4765222668647766, 1.779013991355896, -0.4293312132358551, 0.5748628973960876, -0.06828437000513077, -0.7586112022399902, 0.28895634412765503, 0.6583753824234009, -0.0587337464094162, -0.16351428627967834, 0.12852343916893005, 0.7629330158233643, -0.3886565864086151, 0.356994092464447, 0.8387432098388672, 0.4018508493900299, -0.23136430978775024, 0.1999453902244568, 0.7039294242858887, -0.6235260963439941, 0.43448105454444885, 0.39775463938713074, 0.5588839054107666, 0.15022072196006775, 0.06731463223695755, 0.10001606494188309, 0.33567285537719727, -0.9160839915275574, -0.1442270278930664, 0.5433032512664795, 0.7478389143943787, 0.948340892791748, 0.1289941966533661, -0.6927005648612976, -0.12452887743711472, -0.09163598716259003, 0.8132460117340088, 1.6874608993530273, -0.3290106952190399, -0.3551657497882843, -0.6698830723762512, -0.5721655488014221, 0.16742484271526337, 0.368265837430954, -0.4081723690032959, -0.4713766276836395, -0.5226258635520935, -0.9412886500358582, 0.5986199378967285, -0.09575004875659943, 1.2377358675003052, 0.13679806888103485, 0.034964077174663544, -0.07566985487937927, 0.09989313036203384, -0.76646488904953, -0.8002418875694275, 0.6192880868911743, -0.4255458414554596, -0.26218485832214355, -0.21682456135749817, -0.11895884573459625, 0.04780040308833122, -0.4098495543003082, 0.917806088924408, -0.6400800347328186, -0.32014623284339905, -0.1531619429588318, 0.6008209586143494, -0.6261246800422668, -0.7921534776687622, 0.2520308494567871, 0.17197726666927338, -0.303181916475296, 0.39066195487976074, 0.3993886709213257, 0.008313476108014584, -0.05459395796060562, -0.3152424097061157, 0.5454939007759094, -0.016660211607813835, -0.12313089519739151, 0.8257059454917908, -0.04732690379023552, -0.2350669801235199, -1.335736632347107, 1.346458077430725, 0.06463421136140823, -0.11426497995853424, 0.20958870649337769, -0.7132642269134521, -0.11085367202758789, 0.42979010939598083, -0.8677778840065002, -0.32758891582489014, -1.1966376304626465, 0.23337531089782715, -0.6180102229118347, -0.1334546059370041, 0.29161176085472107, 0.79035484790802, 0.19484490156173706, 0.3428732752799988, 0.34464696049690247, 0.39414888620376587, -0.8750005960464478, 0.720592200756073, -0.9911365509033203, 0.5517538785934448, -0.07648719102144241, 0.16640034317970276, -0.6557019948959351, -0.33877670764923096, -0.32560068368911743, -0.6672918796539307, -0.16136302053928375, -0.011983868665993214, 0.12731751799583435, 0.34728968143463135, -0.8267013430595398, -0.4766550660133362, -0.4805038273334503, -0.8768672347068787, -0.2567308843135834, -0.18324397504329681, 0.1795533448457718, -0.37311580777168274, -1.2657145261764526, -1.2408047914505005, -0.2500515878200531, -0.2688474953174591, -1.4374558925628662, 0.19883796572685242, -0.12769639492034912, -0.35842370986938477, -0.7308475971221924, -0.09179824590682983, -0.27192315459251404, 1.3861559629440308, -0.9704129099845886, 1.131029725074768, -0.41808903217315674, -0.10034982115030289, -0.2108510136604309, 0.03948875144124031, 0.8437456488609314, -0.1440902054309845, -0.09388817846775055, -1.116062879562378, 0.02190406620502472, -0.2588682770729065, -0.5052105784416199, 0.5617561340332031, 0.1676759123802185, 1.0195738077163696, -0.3082306981086731, -0.6027395129203796, 0.7837244272232056, 1.113419532775879, -0.832460343837738, -0.20233510434627533, -0.08305784314870834, 0.9691429138183594, 0.07768005132675171, -0.7188571095466614, 0.20905302464962006, 0.4694954454898834, 0.37095722556114197, -0.048395801335573196, -0.0654660239815712, -0.7095630168914795, -0.8185437321662903, 0.14757856726646423, 2.1785027980804443, 0.5304446816444397, 0.1932506114244461, -1.021161675453186, 0.2999056577682495, -1.04630446434021, -0.19214822351932526, 0.9996390342712402, 0.6015588045120239, 0.7412499785423279, -0.7621721625328064, -0.5103649497032166, -0.21504010260105133, 0.06087260693311691, 0.4286576509475708, -0.24972480535507202, -0.7839137315750122, 0.6065187454223633, 0.501613438129425, -0.006351599469780922, 0.9310163855552673, -0.4272606670856476, 0.6078653931617737, 14.351993560791016, 0.9480521082878113, 0.07977859675884247, 0.8701592087745667, 0.6884389519691467, 0.05948852747678757, -0.39002159237861633, -0.5794487595558167, -1.2564972639083862, 0.258486807346344, 0.9267609715461731, 0.34172677993774414, 0.6598744988441467, 0.1086345762014389, -0.23243367671966553, 0.38052603602409363, -0.4059213697910309, 0.6330561637878418, 0.3698645234107971, -1.3429639339447021, 0.5126707553863525, 0.19536401331424713, 0.6603447794914246, 0.23012208938598633, 1.0082592964172363, 1.3985702991485596, 0.5572302341461182, -0.5417155027389526, 0.35158708691596985, 0.3903648555278778, 0.5116686224937439, -0.04224565625190735, 0.21462053060531616, 0.8926588296890259, -0.765029788017273, -0.21747952699661255, -0.6260934472084045, -0.923902153968811, 0.15560753643512726, 0.19683422148227692, -0.49593064188957214, -0.6059289574623108, -0.3915103077888489, 0.47779175639152527, -0.1464400440454483, 0.40687423944473267, -0.09815020859241486, 0.6341180205345154, -0.17537550628185272, 0.43547120690345764, 0.5059860348701477, 0.5690672993659973, 0.2969984710216522, 0.13439887762069702, 0.4179430305957794, -0.19657756388187408, 0.4495490491390228, 0.6692560911178589, -0.4783339202404022, -0.3210485577583313, -0.27180907130241394, -0.13865001499652863, 0.12546312808990479, 0.3650372326374054, 1.077280879020691, 0.25848501920700073, -0.4105367064476013, 0.5145551562309265, 0.747418999671936, 0.43281227350234985, -0.01373179629445076, 0.15057119727134705, 0.7021948099136353, -0.3811134696006775, -0.1172560527920723, 0.43435537815093994, -0.09100059419870377, -0.35886484384536743, -0.8969762921333313, -0.6220936179161072, 0.256339430809021, -0.7392892837524414, -0.8824390172958374, 0.7822128534317017, 0.03215694800019264, -0.3447377681732178, -0.17003679275512695, -0.4913330376148224, -0.1695920079946518, 0.8975780010223389, -1.6801012754440308, -0.2757364511489868, 0.42115095257759094, -0.36513811349868774, -0.150740846991539, -0.5574778318405151, 1.4553272724151611, 0.39003267884254456, -0.3694744110107422, 0.2713770866394043, 0.0757780596613884, -0.17118516564369202, -0.1303384006023407, -0.8769780397415161, 0.8324745893478394, 0.016858836635947227, -0.025926802307367325, 0.23621584475040436, -0.08288613706827164, 0.17254574596881866, -0.49419134855270386, -0.2680741846561432, 0.7942946553230286, -0.3860675096511841, -0.5976213812828064, -0.6184650659561157, -0.8849286437034607, 0.32979637384414673, 0.5988779067993164, -0.268541157245636, 0.8057697415351868, 0.08437205851078033, -0.8853894472122192, 0.1752135008573532, -0.9052096009254456, 0.1860889196395874, 0.10319506376981735, -0.8215811252593994, -0.3492772877216339, 0.13313834369182587, 0.5682310461997986, -1.1479790210723877, -0.5594480633735657, -0.17825806140899658, -0.11772233992815018, 0.002947153989225626, 1.3042303323745728, -0.332884818315506, 0.6078472137451172, 1.06265127658844, -0.25473493337631226, -1.235510230064392, -0.16830821335315704, -0.8743716478347778, -0.14840717613697052, -0.1638955920934677, 0.6571434736251831, -0.16217654943466187, 0.3481327295303345, 0.9547969102859497, 0.01418340764939785, -0.5228045582771301, -0.4317241311073303, -0.32791873812675476, 0.36068105697631836, -0.546811580657959, 0.3346298336982727, 0.2685207724571228, -0.2501157224178314, 0.11056330054998398, 0.5030980110168457, 0.2678263187408447, -0.2110678255558014, -1.3139348030090332, 0.22642816603183746, -0.17303533852100372, -0.39078211784362793, -0.739534318447113, -0.2523433268070221, -1.5442756414413452, -0.170854389667511, -1.5537326335906982, -0.19208814203739166, -0.97248375415802, -0.7158706784248352, -0.19049830734729767, -0.35155245661735535, -0.06003294140100479, 0.16469472646713257, -0.3786317706108093, 0.04233087599277496, -0.5493707656860352, -0.24734747409820557, 0.8940451741218567, 1.1594616174697876, -0.5771193504333496, 0.13563966751098633, -0.04414815083146095, -0.19408392906188965, 0.4808489978313446, 0.5081673264503479, -0.3884022533893585, -1.0360472202301025, -1.5938879251480103, 0.17908573150634766, -0.23545193672180176, -0.3171502351760864, -1.10001802444458, 0.8949042558670044, 0.5446377992630005, -0.08097177743911743, 0.05222994461655617, 0.7697355151176453, -1.2860978841781616, -0.7624983191490173, 0.3326115906238556, -1.0596871376037598, -0.014248281717300415, 0.24561777710914612, -0.47313886880874634, -0.49097299575805664, 0.3935708999633789, 0.01909160614013672, -1.0836777687072754, -0.6183570623397827, 0.31190329790115356, -0.3287636935710907, 0.18618914484977722, -0.3864510655403137, 0.1186724379658699, -1.3176130056381226, -0.3408343195915222, -0.16703803837299347, 0.26375535130500793, -0.8770136833190918, 0.76643306016922, 0.3521750271320343, -1.3036932945251465, -0.03717048466205597, 0.9133651256561279, -0.11477780342102051, 0.1776917576789856, 0.5048296451568604, 0.4687023162841797, -0.2918076515197754, 0.5613327026367188, 0.48844245076179504, 0.6029309034347534, -0.575465202331543, -0.10624831914901733, 0.931911051273346, -0.7901741862297058, -0.03776295483112335, 1.56063973903656, -0.4688946604728699, -1.1272892951965332, 0.5052313208580017, -1.188367486000061, -0.30536583065986633, -0.21334925293922424, 0.73090660572052, 0.23430263996124268, -0.07337112724781036, 0.2981037497520447, -0.1059371680021286, 0.10313548147678375, -0.4262603223323822, -0.6664459705352783, 0.42179593443870544, -0.07066212594509125, -0.18685945868492126, 0.4820590615272522, 1.1979807615280151, -0.7392443418502808, -0.8744181394577026, -0.9567146897315979, -0.422964870929718, -0.12104406207799911, 0.575033962726593, -0.663658618927002, -0.6824194192886353, 0.9556735754013062, 0.4232858419418335, 0.3769451975822449, 0.12089314311742783, -0.2548253536224365, 0.22903846204280853, 0.6145086884498596, -0.24380211532115936, -0.6091982126235962, -0.4459855258464813, 1.4188393354415894, 1.0697486400604248, -0.9415053725242615, 0.36458057165145874, -0.25638657808303833, -0.5818560123443604, 0.6396943926811218, 0.26940053701400757, -0.02803865447640419, 1.0935332775115967, -0.4108409285545349, -0.06167922168970108, 0.2615038752555847, -1.0763137340545654, -0.5333161354064941, 1.348641037940979, 1.1073538064956665, 0.9725032448768616, 0.4712124466896057, 0.18576879799365997, 0.8983424305915833, -0.1888805329799652, -0.1464741975069046, 0.17894740402698517, 0.3010254502296448, -0.541019856929779, -0.3437839448451996, 0.08204209059476852, 0.6574638485908508, -0.6215879321098328, -0.8012421727180481, 0.2697814702987671, 0.6379614472389221, 0.5225155353546143, 0.6044384837150574, 0.6518871188163757, -0.23577207326889038, 0.41074445843696594, 0.6446217894554138, 0.4779362976551056, -0.6325992941856384, -0.21529708802700043, -0.1375499963760376, -0.7243112921714783, 0.09774679690599442, 0.005875262897461653, -0.02096184715628624, 0.052863605320453644, -0.202887162566185, 0.8097838759422302, -0.054419200867414474, 0.6556199193000793, 0.9777804613113403, 0.6413446068763733, 1.077401041984558, -0.40920037031173706, -0.3692774176597595, -0.36010339856147766, -0.8968032598495483, 0.09591136872768402, -0.6332253813743591, -0.14516212046146393, -0.20060580968856812, -0.15182578563690186, -0.3861136734485626]}, "authors": [{"authorId": "98703980", "name": "Chen Liang"}, {"authorId": "52194893", "name": "Simiao Zuo"}, {"authorId": "153441799", "name": "Qingru Zhang"}, {"authorId": "50462546", "name": "Pengcheng He"}, {"authorId": "2109136147", "name": "Weizhu Chen"}, {"authorId": "2153707398", "name": "Tuo Zhao"}], "references": [{"paperId": "02529b2666a536053a2e2940de5b28de36fd594b", "title": "Lion: Adversarial Distillation of Proprietary Large Language Models"}, {"paperId": "aad167be3c902388ea625da4117fcae4325b8b7d", "title": "Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes"}, {"paperId": "9e8cb8c91a0acb6e661b58ad724aa758490f2bea", "title": "Instruction Tuning with GPT-4"}, {"paperId": "b835345c6168d7b179516700aa4460912a8857e9", "title": "HomoDistil: Homotopic Task-Agnostic Distillation of Pre-trained Transformers"}, {"paperId": "f2b0017ddd77fa38760a18145e63553105a1a236", "title": "The Flan Collection: Designing Data and Methods for Effective Instruction Tuning"}, {"paperId": "df434c1289f3c7243b585cb9982afac3c5bf0439", "title": "MoEBERT: from BERT to Mixture-of-Experts via Importance-Guided Adaptation"}, {"paperId": "972706306f85b1bfb40c7d35c796ad5174eb0c9c", "title": "DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "1cb134e23264d0796c08f7187c6af735455e6c9a", "title": "Follow Your Path: a Progressive Method for Knowledge Distillation"}, {"paperId": "b5b006dc558cb7fbd532d67e989173b536e8ac80", "title": "MiniLMv2: Multi-Head Self-Attention Relation Distillation for Compressing Pretrained Transformers"}, {"paperId": "1013750582c20bbdf1164127b5f26b1e06e817e3", "title": "MixKD: Towards Efficient Distillation of Large-scale Language Models"}, {"paperId": "9f0272bb258506fdc0ee7d8951593914d4f9c39d", "title": "Analyzing Individual Neurons in Pre-trained Language Models"}, {"paperId": "0abb08c4ec5feab4cdd82c471866dd4395c573ce", "title": "Contrastive Distillation on Intermediate Representations for Language Model Compression"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "3b504f939e55d567652737ef093c1087cd40689b", "title": "Analyzing Redundancy in Pretrained Transformer Models"}, {"paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b", "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"}, {"paperId": "1c332cfa211400fc6f56983fb01a6692046116dd", "title": "DynaBERT: Dynamic BERT with Adaptive Width and Depth"}, {"paperId": "c6c734e16f66fbfcefac7625cc64599e83292c1e", "title": "MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "2e27f119e6fcc5477248eb0f4a6abe8d7cf4f6e7", "title": "BERT-of-Theseus: Compressing BERT by Progressive Module Replacing"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf", "title": "Patient Knowledge Distillation for BERT Model Compression"}, {"paperId": "4d1c856275744c0284312a3a50efb6ca9dc4cd4c", "title": "Know What You Don\u2019t Know: Unanswerable Questions for SQuAD"}, {"paperId": "d7b6753a2d4a2b286c396854063bde3a91b75535", "title": "A Simple Method for Commonsense Reasoning"}, {"paperId": "cb0f3ee1e98faf92429d601cdcd76c69c1e484eb", "title": "Neural Network Acceptability Judgments"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096", "title": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "3a29aa4eff48624752c07059a44d3288a678c8ab", "title": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "5ed791f810da580c78df6a052c6b9f2e258f6b0a", "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "8604f376633af8b347e31d84c6150a93b11e34c2", "title": "FitNets: Hints for Thin Deep Nets"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": null, "title": "ELECTRA: pre-training text encoders as discriminators rather than generators"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "2017), paraphrase detection (MRPC, Dolan & Brockett 2005), and natural language inference (RTE & MNLI"}, {"paperId": null, "title": "), two popular machine reading comprehension benchmarks from approximately 500 Wikipedia articles with questions and answers obtained by crowdsourcing. The SQuAD v2"}, {"paperId": null, "title": "Cc-news"}, {"paperId": null, "title": "Less is More: Task-aware Layer-wise"}, {"paperId": "db8885a0037fe47d973ade79d696586453710233", "title": "The Sixth PASCAL Recognizing Textual Entailment Challenge"}, {"paperId": "136326377c122560768db674e35f5bcd6de3bc40", "title": "The Second PASCAL Recognising Textual Entailment Challenge"}, {"paperId": null, "title": "linguistic acceptability (CoLA, Warstadt et al. 2019), sentiment analysis"}, {"paperId": "475354f10798f110d34792b6d88f31d6d5cb099e", "title": "Automatically Constructing a Corpus of Sentential Paraphrases"}, {"paperId": "e808f28d411a958c5db81ceb111beb2638698f47", "title": "The PASCAL Recognising Textual Entailment Challenge"}, {"paperId": null, "title": "2018) tasks. Details of the GLUE benchmark, including tasks, statistics, and evaluation metrics"}, {"paperId": null, "title": "Stanford alpaca: An instruction-following llama model"}]}