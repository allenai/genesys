{"paperId": "82de481ebb5cf401b215178c20b058c7c1a4f9cd", "abstract": "Text embedding methods have become increasingly popular in both industrial and academic fields due to their critical role in a variety of natural language processing tasks. The significance of universal text embeddings has been further highlighted with the rise of Large Language Models (LLMs) applications such as Retrieval-Augmented Systems (RAGs). While previous models have attempted to be general-purpose, they often struggle to generalize across tasks and domains. However, recent advancements in training data quantity, quality and diversity; synthetic data generation from LLMs as well as using LLMs as backbones encourage great improvements in pursuing universal text embeddings. In this paper, we provide an overview of the recent advances in universal text embedding models with a focus on the top performing text embeddings on Massive Text Embedding Benchmark (MTEB). Through detailed comparison and analysis, we highlight the key contributions and limitations in this area, and propose potentially inspiring future research directions.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "An overview of the recent advances in universal text embedding models with a focus on the top performing text embeddings on Massive Text Embedding Benchmark (MTEB), and highlights the key contributions and limitations in this area."}, "embedding": {"model": "specter_v2", "vector": [0.023964382708072662, 0.22445297241210938, -0.5406124591827393, 0.09628581255674362, -0.7010257244110107, -0.1217387467622757, 0.85140061378479, -0.0748925432562828, -0.8522758483886719, -0.05723821371793747, 0.9038016200065613, -0.12759613990783691, 0.09275022149085999, 0.22614283859729767, -0.11773936450481415, -0.024053795263171196, -0.722618043422699, 0.5758082270622253, -0.2764064371585846, -0.6557207703590393, -0.31271660327911377, -0.9879280924797058, -0.5356356501579285, 0.022791853174567223, 0.3396196961402893, 0.11656992882490158, -0.03467364236712456, 0.9677482843399048, -0.5603410005569458, -0.04266437888145447, 0.518629252910614, -0.6857298016548157, 0.17296704649925232, 0.286822110414505, -0.2224133461713791, -0.011582204140722752, 0.4440607726573944, -1.0009722709655762, -0.9783836007118225, 0.5783319473266602, -0.25533443689346313, 0.4580835700035095, 0.6960563659667969, -0.42783811688423157, -0.5471295714378357, 0.7497344613075256, 0.6590296626091003, 0.4993576109409332, -0.1758035272359848, -0.4399859309196472, 1.7091108560562134, -1.5980236530303955, 0.6264010071754456, 1.076529860496521, 0.32318389415740967, 0.42853033542633057, -0.6138418316841125, -0.3838730454444885, 0.05103728175163269, -0.10165146738290787, -0.7254210710525513, -0.336276650428772, 0.004094933625310659, -0.2059834748506546, 1.9711912870407104, -0.09401509165763855, -0.12986327707767487, 0.4690888524055481, 0.09206700325012207, 1.5026330947875977, -0.0201325174421072, -0.8967166543006897, -0.6992185115814209, 0.30890774726867676, 0.4927002191543579, 0.6524438858032227, -0.40806320309638977, 0.41935113072395325, -0.8867408037185669, -0.13758079707622528, -0.3859236240386963, -0.0665399581193924, -0.14384454488754272, -0.01851063221693039, -0.7208265662193298, 0.9032832980155945, 0.2588914632797241, 0.5578145980834961, -0.3145298957824707, 0.809429943561554, 0.7876150608062744, 0.5968632102012634, 0.33854979276657104, 0.18613223731517792, 0.00809311494231224, 0.5025012493133545, -0.8866699934005737, 0.5582260489463806, 0.025045063346624374, 0.48005250096321106, 0.11852548271417618, -0.01641106978058815, -1.1403162479400635, 0.34311267733573914, 1.0387907028198242, 0.044185761362314224, 0.9405032396316528, -0.16454699635505676, 0.5215427279472351, -0.40906164050102234, 0.2738712728023529, -0.9495877027511597, 0.022761927917599678, -0.06992487609386444, -0.5079357028007507, -1.54423189163208, -0.6973442435264587, 0.18569767475128174, -0.5533999800682068, 0.7891942858695984, -0.06892459839582443, -0.20309343934059143, 0.4354970157146454, 0.39389684796333313, 0.7650442719459534, 1.023343563079834, 0.11274505406618118, 0.2920916676521301, 1.2142176628112793, -0.9569583535194397, -1.2229145765304565, -1.296651840209961, 1.3996593952178955, -0.5332624912261963, 0.5327649712562561, -0.5951104760169983, -0.751304030418396, -0.6066722273826599, -1.1495792865753174, 0.05013659968972206, -0.8245523571968079, 0.6436644792556763, 0.6166259050369263, 0.5948638319969177, -0.8060271143913269, 0.6455416679382324, -0.0876488909125328, -0.27974435687065125, -0.15597543120384216, 0.4713306725025177, -0.09055701643228531, -0.6215765476226807, -1.480043649673462, 0.6392282247543335, 0.4236706793308258, -0.6168671250343323, -0.32318174839019775, -0.07294584065675735, -1.3928767442703247, -0.3435172140598297, 0.15347687900066376, -0.4837677776813507, 0.9844784736633301, 0.575413167476654, -1.126015305519104, 0.5035688281059265, -0.39241477847099304, 0.14287452399730682, 0.3669080138206482, -0.43127724528312683, -0.6307018399238586, -0.6278970241546631, -0.10497681796550751, 0.5910996794700623, 0.25819578766822815, 0.26550137996673584, 0.41690975427627563, 0.4892745018005371, -0.6737855672836304, 0.1367408037185669, -1.364672064781189, 0.9509113430976868, -0.11061184853315353, -0.41638997197151184, 0.3483586609363556, 0.7163970470428467, -0.020846474915742874, -0.3534284830093384, -0.6064820289611816, -1.1430013179779053, 0.8881130218505859, -0.27425819635391235, 1.287834882736206, -1.0800501108169556, -0.3364149332046509, -0.4972665309906006, 0.021225163713097572, -0.2695596218109131, -0.8338189721107483, 1.5630937814712524, -0.46791860461235046, 0.5399341583251953, 0.11162853240966797, -1.6211003065109253, 0.9291931390762329, -0.17002621293067932, -1.077187418937683, -0.19414356350898743, 0.12037280201911926, 1.3229739665985107, -0.482212096452713, -0.09555710107088089, 0.12912891805171967, 0.14260132610797882, -0.5568899512290955, 1.159303069114685, -0.27005326747894287, -0.5127999782562256, 0.14371231198310852, -0.5608759522438049, -0.15912778675556183, -0.3255934715270996, 0.199796661734581, -0.5052579641342163, -0.015385420992970467, 0.7386701107025146, -0.32593002915382385, 1.0889899730682373, 0.013571050949394703, 0.6891167759895325, -0.5402532815933228, -0.3548368513584137, 0.3091665506362915, 0.694149911403656, -0.36865246295928955, -0.1580648422241211, 0.24660363793373108, 0.7838044166564941, -0.7177493572235107, 0.1521838903427124, 1.355906367301941, 0.4262350797653198, -0.364178866147995, 0.6765971183776855, 0.4649668335914612, 0.1030973568558693, 0.8147743344306946, 0.8948919773101807, 0.6878626942634583, 0.08931156992912292, 0.17834439873695374, 0.2461731731891632, 0.101559579372406, -0.6484166383743286, -0.5768786668777466, 0.09725519269704819, 0.7174329161643982, 0.49494805932044983, 0.13554106652736664, -0.6921045184135437, -0.47816237807273865, 0.04950178414583206, 0.7485487461090088, 1.438323736190796, -0.22274264693260193, -0.8791550993919373, -0.4282737672328949, -0.5914671421051025, -0.13168883323669434, -0.08938127756118774, -0.6499170660972595, -0.4499779939651489, -0.6376994848251343, -1.6069854497909546, 0.4565351903438568, 0.18055874109268188, 0.4969441592693329, -0.3874042332172394, 0.1239294558763504, -0.27746665477752686, -0.2082398682832718, -0.8268892765045166, -0.7801287770271301, 0.2882061302661896, -0.711644172668457, 0.1005820482969284, -0.2584913372993469, -0.07880005240440369, 0.18493592739105225, -0.43624451756477356, 0.6749869585037231, -0.30110636353492737, -0.10285370796918869, -0.09727185219526291, 0.39470475912094116, -0.11483223736286163, -0.7364934086799622, 0.47011080384254456, 0.441287100315094, -0.367878794670105, 0.5126033425331116, 0.8759537935256958, 0.024941278621554375, 0.2699694335460663, -0.7544921636581421, 0.46444323658943176, 0.13386785984039307, 0.7057916522026062, 0.1995927393436432, -0.42323213815689087, 0.3198152482509613, -0.625219464302063, 1.2504074573516846, 0.17457455396652222, -0.03174689784646034, 0.28888994455337524, -0.6416692137718201, -0.4646826386451721, 0.265615850687027, -0.8975481390953064, 0.08620348572731018, -1.1223514080047607, 0.42210057377815247, 0.15263399481773376, 0.2545526623725891, 0.6209276914596558, 0.5671581029891968, 0.22464896738529205, 0.47446563839912415, 0.6017895340919495, 0.22817228734493256, -0.08224636316299438, 0.44873496890068054, -0.39157354831695557, -0.032813239842653275, 0.14753401279449463, 0.6058573722839355, -0.29391130805015564, -0.4256744980812073, -0.3999471068382263, -0.3033984899520874, -0.1756049394607544, -0.17810244858264923, -0.49064233899116516, 0.06864988803863525, -0.36718299984931946, -0.43099623918533325, -0.4818575382232666, -0.8781723380088806, 0.18449725210666656, 0.11792560666799545, -0.2187521904706955, 0.04962906986474991, -0.6510793566703796, -1.5535974502563477, -0.42489704489707947, -0.8962885141372681, -1.3069345951080322, 0.719828188419342, -0.2661069631576538, -0.47881364822387695, -0.6923978924751282, 0.4077000617980957, -0.1282961219549179, 0.6876048445701599, -0.474997341632843, 0.988019585609436, -0.09089256823062897, -0.05669368803501129, -0.9272225499153137, 0.2115403711795807, 0.5754461884498596, -0.30054613947868347, 0.3223320245742798, -0.6896948218345642, -0.3866351544857025, -0.4051288366317749, -0.32402804493904114, 0.08661527931690216, 0.045653730630874634, -0.11912303417921066, -0.09185042232275009, -0.6861550807952881, 0.10182619094848633, 1.4036563634872437, -1.046800971031189, -0.0184521172195673, 0.3048817813396454, 0.7305113673210144, 0.6804572939872742, -0.2186637967824936, 0.44079431891441345, 0.3813563287258148, 0.7946181893348694, -0.01886974275112152, -0.3711325526237488, -0.3212704062461853, -0.8761574029922485, 0.9791355133056641, 2.124687910079956, 1.062253475189209, -0.23443761467933655, -1.2020130157470703, 0.7324323058128357, -1.2363576889038086, -0.06740232557058334, 0.33920490741729736, 0.404509037733078, 0.32744672894477844, -0.6992906332015991, -0.2962638735771179, 0.11640516668558121, 0.43358543515205383, 0.48983100056648254, -0.14773081243038177, -0.39466923475265503, -0.23459970951080322, 0.19614212214946747, 0.18865256011486053, 0.16672955453395844, -0.49658098816871643, 0.6468985080718994, 14.398852348327637, 1.0569063425064087, 0.3241881728172302, 0.6314202547073364, 0.567268967628479, 0.14293648302555084, -0.4239884912967682, -0.1114719808101654, -1.0948121547698975, -0.10270654410123825, 1.2761255502700806, -0.07052656263113022, 0.3455340564250946, -0.3171791136264801, -0.3094581663608551, 0.43902722001075745, -0.6256217360496521, 0.5348743796348572, 0.5835803151130676, -1.2297208309173584, 0.7116985321044922, 0.6189095973968506, 0.38223910331726074, 0.5829551219940186, 1.1144806146621704, 0.9159407615661621, 0.3761788308620453, -0.3988386392593384, 0.38018861413002014, -0.15190738439559937, 0.8093354105949402, -0.045788656920194626, 0.8014755249023438, 0.6944546699523926, -0.7607787847518921, -0.3930959403514862, -0.8497045636177063, -0.9116945862770081, 0.36308059096336365, 0.1170264333486557, -0.964280903339386, -0.05960022285580635, -0.4797278642654419, 0.9433929324150085, -0.05630812793970108, 0.02672124095261097, -0.03359995782375336, 0.5498030781745911, -0.018227191641926765, -0.31667783856391907, 0.6459456086158752, 0.3100886046886444, 0.3100951313972473, 0.11665806174278259, 0.5780837535858154, -0.3753325641155243, 0.07784312963485718, 0.3511272072792053, -0.6772894859313965, 0.5620488524436951, -0.6463838219642639, -0.7168286442756653, -0.28929033875465393, 1.1078277826309204, 0.7138298153877258, 0.08609021455049515, -0.29373985528945923, 0.3935311436653137, 0.8552041053771973, 0.5399587750434875, -0.04347195103764534, -0.437151700258255, 0.3050589859485626, -0.3253793716430664, -0.3301243484020233, 0.3615248501300812, 0.03280132636427879, -0.6284804344177246, -0.5446615815162659, -0.2639336884021759, 0.3490934669971466, -0.7288367748260498, -0.9769780039787292, 1.1332937479019165, -0.4808685779571533, -0.6576176881790161, -0.02668941393494606, -1.0465954542160034, 0.2887318730354309, 0.6869997382164001, -1.525620937347412, -0.6671687960624695, 0.3726552724838257, -0.6810134053230286, -0.6551503539085388, -0.5448837280273438, 1.3996500968933105, 0.5065979361534119, -0.7774853706359863, 0.09055081009864807, 0.6028206944465637, 0.10259455442428589, 0.040885381400585175, -0.7263835072517395, 0.759106457233429, 0.09700069576501846, 0.13286374509334564, 0.5360903143882751, 0.1542975902557373, 0.06505345553159714, -1.0260035991668701, -0.05591829493641853, 0.959283709526062, -1.079258918762207, -0.0869879201054573, -0.9875052571296692, -0.7100825309753418, 0.19894194602966309, 0.7210157513618469, -0.6530043482780457, 0.6964444518089294, 0.22579678893089294, -0.5227065086364746, -0.024721352383494377, -0.5876720547676086, 0.6618353128433228, -0.041618190705776215, -0.8752672672271729, -0.2430843710899353, 0.5618380904197693, 0.42440977692604065, -0.5681024789810181, -0.618535041809082, 0.0670413076877594, -0.17484410107135773, 0.38188421726226807, 1.0000890493392944, -0.6695108413696289, 1.0654149055480957, 0.6625322103500366, -0.502930223941803, -0.7986965775489807, 0.41468530893325806, -0.9678783416748047, -0.22981953620910645, -0.11126679927110672, 0.6333622932434082, -0.5240908265113831, 0.6730631589889526, 0.7644020915031433, 0.48612114787101746, -0.5022223591804504, -0.6353660821914673, -0.39158520102500916, 0.001406868570484221, -0.06753809750080109, 0.3352694809436798, -0.10920234024524689, 0.2452351450920105, 0.1405055671930313, 0.12446563690900803, 0.1313932090997696, -0.21039313077926636, -0.7694411277770996, 0.7480894923210144, 0.17855773866176605, 0.0343310609459877, -0.6229602694511414, -0.25471246242523193, -1.6054704189300537, 0.2563304305076599, -1.7944958209991455, -0.15470941364765167, -1.0202759504318237, 0.1775093376636505, 0.21336083114147186, -0.002525478834286332, -0.03496580198407173, 0.2122635692358017, 0.13084660470485687, -0.39326390624046326, -0.4663425087928772, -0.2726227045059204, 1.3103015422821045, 1.0047881603240967, -0.722175121307373, 0.46210554242134094, -0.628854513168335, 0.3021349608898163, -0.25916436314582825, 0.2321348637342453, -0.5584178566932678, -0.6219901442527771, -1.4533532857894897, 0.5140675902366638, -0.08715710788965225, -0.13393016159534454, -0.08463378250598907, 0.6702696681022644, 0.7762241363525391, -0.3492189943790436, -0.026343729346990585, 0.7574716806411743, -0.6316081881523132, -0.22254642844200134, 0.34319934248924255, -0.8513950109481812, 0.7072328329086304, 0.094044990837574, -0.5953845977783203, -0.5323916673660278, 0.4030565917491913, -0.42620810866355896, -0.3360174298286438, -0.020490331575274467, 0.5259847640991211, -0.587186872959137, -0.18653102219104767, -0.36012643575668335, -0.4136628210544586, -1.3933268785476685, -0.5277782082557678, 0.10605127364397049, 0.2676377594470978, -0.5559355020523071, 0.6238623261451721, 0.7629103064537048, -1.6586045026779175, -0.26002711057662964, 0.33747899532318115, 0.4454409182071686, -0.9975660443305969, 0.4201514422893524, 0.45052412152290344, -0.05411941930651665, 0.5876163840293884, 0.5542176961898804, 0.3363645076751709, -1.1512070894241333, -0.3000911474227905, 0.5993813276290894, -0.8043289184570312, -0.22847582399845123, 0.7548172473907471, -0.291973352432251, -1.5274829864501953, -0.21224632859230042, -0.5530267357826233, -0.3693949282169342, -0.39938440918922424, 0.567217230796814, 0.3842509090900421, 0.0856991857290268, -0.4335790276527405, -0.06677573919296265, 0.14451557397842407, -0.41230666637420654, -0.8587945699691772, 0.6933208703994751, -0.17991071939468384, -0.7567214965820312, 0.625515878200531, 1.161341905593872, -1.0987577438354492, -0.22190909087657928, -0.8819065690040588, -0.07063373178243637, -0.5174950361251831, 0.4511856138706207, -0.34409087896347046, -0.19930484890937805, 0.8604987263679504, 0.4500778913497925, 0.5436741709709167, 0.11626134812831879, -0.47750476002693176, 0.7861745357513428, 0.9685775637626648, -0.3331907093524933, -0.6497200131416321, -0.1714128702878952, 1.4314587116241455, 1.2780420780181885, -0.8438394069671631, 0.29836663603782654, -0.049060553312301636, -0.4628888964653015, 0.5810202360153198, 0.13569238781929016, 0.33219897747039795, 0.76897794008255, -0.31560760736465454, 0.1609775871038437, 0.07992301881313324, -1.2314672470092773, 0.0662013441324234, 1.2420283555984497, 0.5628945231437683, 1.0026761293411255, 0.3765646815299988, -0.242637500166893, 0.6398030519485474, -0.15788687765598297, -0.2918604016304016, 0.3756347894668579, 0.26931387186050415, -0.2896166443824768, -0.455618679523468, 0.11348403990268707, 0.6579397916793823, -0.6377190947532654, -0.7512702941894531, -0.1441391557455063, 0.7258718609809875, -0.42310595512390137, 0.5849214792251587, 0.41350752115249634, -0.5004156231880188, 0.49147671461105347, 0.4281036853790283, 0.1161590963602066, -0.37098821997642517, -0.5554646253585815, -0.11818922311067581, -0.3540830910205841, 0.470441073179245, 0.1335955262184143, -0.4196050465106964, 0.14476731419563293, -0.5322923064231873, 0.15090970695018768, 0.24367547035217285, 0.6018372178077698, 0.8328711986541748, 0.3509933352470398, 0.3586064577102661, -0.4276919662952423, -0.21219965815544128, -0.6805055141448975, -1.253699779510498, -0.29382267594337463, -0.4571593403816223, -0.1587490439414978, -0.12047518789768219, -0.20287205278873444, -0.5875541567802429]}, "authors": [{"authorId": "2304744152", "name": "Hongliu Cao"}], "references": [{"paperId": "18594d3f15b39385bace39657d14f0c8c7479db1", "title": "LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders"}, {"paperId": "f9c4c6c804930f751debe29780e9741315595aa8", "title": "Gecko: Versatile Text Embeddings Distilled from Large Language Models"}, {"paperId": "703236b38d0be229bf8d107c5758b0f4ab34805b", "title": "Text clustering with LLM embeddings"}, {"paperId": "ee43fc5579deac342b91576d3e443e95cee281ed", "title": "Is Cosine-Similarity of Embeddings Really About Similarity?"}, {"paperId": "74f7b80e2e5463fce4cd064afe2921929612049a", "title": "GISTEmbed: Guided In-sample Selection of Training Negatives for Text Embedding Fine-tuning"}, {"paperId": "a3c4047f82d7120e2bbc600dbe79b930e1dc4e41", "title": "Repetition Improves Language Model Embeddings"}, {"paperId": "0e8176ecced2a01ca3c7dc31e8a3f72d0a7d3767", "title": "Generative Representational Instruction Tuning"}, {"paperId": "85ceb93a797481b5203b36f4e77a0828107c42fd", "title": "Multilingual E5 Text Embeddings: A Technical Report"}, {"paperId": "03bdd9cbb3b768ff3e96c97b28e106748b6e4fd0", "title": "Nomic Embed: Training a Reproducible Long Context Text Embedder"}, {"paperId": "411114f989a3d1083d90afd265103132fee94ebe", "title": "Mixtral of Experts"}, {"paperId": "2b8439f319dfa73df62ca8957ff6d0c1f3c7a73c", "title": "Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon"}, {"paperId": "88ca4ee548d07263386ca8e4effc4a001bb2716f", "title": "Improving Text Embeddings with Large Language Models"}, {"paperId": "37680e5cb6030e01f1a44a5abe2257972196ae26", "title": "Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2"}, {"paperId": "3e31b15b29bd3fa4b70034a21d89d71dfb3301d4", "title": "How Well Do Text Embedding Models Understand Syntax?"}, {"paperId": "da9b8b4073e6ad44b3da66e1e117cb1ddbf8836d", "title": "Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring Fine-Grained Relevance Labels"}, {"paperId": "db633c6b1c286c0386f0078d8a2e6224e03a6227", "title": "Mistral 7B"}, {"paperId": "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0", "title": "Qwen Technical Report"}, {"paperId": "20d0dbcdcf9356396086fe1bbd77637f65b9da1f", "title": "AnglE-optimized Text Embeddings"}, {"paperId": "9e3facfdf48fc6fbdeab602647f360ceaf9c6313", "title": "MIRACL: A Multilingual Retrieval Dataset Covering 18 Diverse Languages"}, {"paperId": "84109e1235b725f4bb44a54bab8b493bd723fdd3", "title": "Towards General Text Embeddings with Multi-stage Contrastive Learning"}, {"paperId": "f11b9b89a6bf298881586b889c259d3c85287f57", "title": "Dense Passage Retrieval: Architectures and Augmentation Methods"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "d58ef6e9d1551140ab1fa0f5474f39f0f2895418", "title": "SamToNe: Improving Contrastive Loss for Dual Encoder Retrieval Models with Same Tower Negatives"}, {"paperId": "e7c97e953849f1a8e5d85ceb4cfcc0a5d54d2365", "title": "Enabling Large Language Models to Generate Text with Citations"}, {"paperId": "8579ad4a8e835cada64c0eae142a00205ce857b5", "title": "A Comprehensive Survey of Sentence Representations: From the BERT Epoch to the CHATGPT Era and Beyond"}, {"paperId": "20fdae9ab2d46c67efbe4baebe67d9f783c1f625", "title": "Contrastive Learning Models for Sentence Representations"}, {"paperId": "d0359d834e2d18a6aed634b085fa1cdc41559b2b", "title": "T2Ranking: A Large-scale Chinese Benchmark for Passage Ranking"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "76427fe94e4564fd5df2177bb259d93527fddca5", "title": "InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval"}, {"paperId": "63c0dbe2426f9c92f469151d1773e5265ae6580e", "title": "One Embedder, Any Task: Instruction-Finetuned Text Embeddings"}, {"paperId": "5a3c1afe73d8bcc8288d17cb17be2baec8a98464", "title": "Text Embeddings by Weakly-Supervised Contrastive Pre-training"}, {"paperId": "8cf05ed2b7cd3b0f601c454914a678c24d393de3", "title": "Task-aware Retrieval with Instructions"}, {"paperId": "88a74e972898de887ad9587d4c87c3a9f03f1dc5", "title": "MTEB: Massive Text Embedding Benchmark"}, {"paperId": "e86009d9f9b1cdf083a48d087552bc4153784451", "title": "Promptagator: Few-shot Dense Retrieval From 8 Examples"}, {"paperId": "aa676125041cd284b4a1313d70143ba6f77c074b", "title": "Matryoshka Representation Learning"}, {"paperId": "06d7cb8c8816360feb33c3367073e0ef66d7d0b0", "title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks"}, {"paperId": "5f8f992d84d5f8b5e8806dad6076bcc4dca11a34", "title": "Improving Passage Retrieval with Zero-Shot Question Generation"}, {"paperId": "741776172685b9717159a9fcd21841461bb33b14", "title": "MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering"}, {"paperId": "b1dad820853464b30c93b52366b32690ba4b99a6", "title": "A Brief Overview of Universal Sentence Representation Methods: A Linguistic View"}, {"paperId": "8fd2aba6fcd6368f8db836f61af10cf661746881", "title": "DuReader-Retrieval: A Large-scale Chinese Benchmark for Passage Retrieval from Web Search Engine"}, {"paperId": "4529a0d6ba1720ce57ad81cc5c74ccca403262f7", "title": "Multi-CPR: A Multi Domain Chinese Dataset for Passage Retrieval"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "6d8fd22d960745ec9dcaf52511895c6c63776734", "title": "Leveraging statistical information in fine-grained financial sentiment analysis"}, {"paperId": "9f2cf7b35224aad3a8d261e4456fe2d65a5f5d3e", "title": "Large Dual Encoders Are Generalizable Retrievers"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "a35b5f92af58358483a75c50cead24f48b0be112", "title": "Not All Negatives are Equal: Label-Aware Contrastive Loss for Fine-grained Text Classification"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "5fbe287249c71eb080962ad0c180b15edb72f75f", "title": "Contrastive Domain Adaptation for Question Answering using Limited Text Corpora"}, {"paperId": "dbe87b171bfb789e1d22a047aeeee69105e6fd02", "title": "Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text Models"}, {"paperId": "1b09222cfe10f11c4cb0b18a9727d2baf6b991ac", "title": "Mr. TyDi: A Multi-lingual Benchmark for Dense Retrieval"}, {"paperId": "4097ae9aca6444fd7536bfbed1e62560521b70d3", "title": "PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "31948894774ee1e14ca4db9a2deffc53793a4d7f", "title": "Merging Statistical Feature via Adaptive Gate for Improved Text Classification"}, {"paperId": "c26759e6c701201af2f62f7ee4eb68742b5bf085", "title": "SimCSE: Simple Contrastive Learning of Sentence Embeddings"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "c50a909e20bd07f4aea09dc6dae539b45b406a96", "title": "Evaluation of BERT and ALBERT Sentence Embedding Performance on Downstream NLP Tasks"}, {"paperId": "b5b006dc558cb7fbd532d67e989173b536e8ac80", "title": "MiniLMv2: Multi-Head Self-Attention Relation Distillation for Compressing Pretrained Transformers"}, {"paperId": "4f712fb13d575cb4f608770ed21372b9fef478a3", "title": "Parallelograms revisited: Exploring the limitations of vector space models for simple analogies"}, {"paperId": "00d63299b5cd49574b806c5b8e813f3c3208d894", "title": "A Novel Random Forest Dissimilarity Measure for Multi-View Learning"}, {"paperId": "c9b8593db099869fe7254aa1fa53f3c9073b0176", "title": "Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval"}, {"paperId": "38f93092ece8eee9771e61c1edaf11b1293cae1b", "title": "Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning"}, {"paperId": "b26f2037f769d5ffc5f7bdcec2de8da28ec14bee", "title": "Dense Passage Retrieval for Open-Domain Question Answering"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "e092ecf56fcca38d0cd6fe9e1e6b11c380f6c286", "title": "A Survey on Contextual Embeddings"}, {"paperId": "7af72a461ed7cda180e7eab878efd5f35d79bbf4", "title": "A Simple Framework for Contrastive Learning of Visual Representations"}, {"paperId": "f1f294aa5dc957920394348a1a36ce22ed3258ac", "title": "Random forest for dissimilarity based multi-view learning: application to radiomics. (For\u00eat al\u00e9atoire pour l'apprentissage multi-vues bas\u00e9 sur la dissimilarit\u00e9: Application \u00e0 la Radiomique)"}, {"paperId": "ff0347fc260ed8e976ae748297d4653114c13d7c", "title": "A survey of word embeddings based on deep learning"}, {"paperId": "6fec3e579c7cd4f13bdabbee2b6ac2e8ff5941c6", "title": "Unsupervised Cross-lingual Representation Learning at Scale"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "17dbd7b72029181327732e4d11b52a08ed4630d0", "title": "Natural Questions: A Benchmark for Question Answering Research"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "ebf59587f8f170ff4241c42263bbfb9da5bd2135", "title": "ELI5: Long Form Question Answering"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "8aacb2e5389a2318eafa666655a8b21a70e60f84", "title": "Random forest dissimilarity based multi-view learning for Radiomics application"}, {"paperId": "9e313d1ba2a871fa38ef4a6bfea8a44aec5dd56a", "title": "Extreme classification"}, {"paperId": "8f096071a09701012c9c279aee2a88143a295935", "title": "RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space"}, {"paperId": "22655979df781d222eaf812b0d325fa9adf11594", "title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering"}, {"paperId": "b227f3e4c0dc96e5ac5426b85485a70f2175a205", "title": "Representation Learning with Contrastive Predictive Coding"}, {"paperId": "bf9db8ca2dce7386cbed1ae0fd6465148cdb2b98", "title": "From Word to Sense Embeddings: A Survey on Vector Representations of Meaning"}, {"paperId": "a76706d350b8c483a3aff73e61b91d15b5687335", "title": "Universal Sentence Encoder"}, {"paperId": "b1d24e8e08435b7c52335485a0d635abf9bc604c", "title": "FEVER: a Large-scale Dataset for Fact Extraction and VERification"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "8760bc7631c0cb04e7138254e9fd6451b7def8ca", "title": "Revisiting Unreasonable Effectiveness of Data in Deep Learning Era"}, {"paperId": "46c112747fb44f82d3096c07c6d8a8faeee8b3d4", "title": "A Survey of Cross-lingual Word Embedding Models"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "dd95f96e3322dcaee9b1e3f7871ecc3ebcd51bfe", "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "e2dba792360873aef125572812f3673b1a85d850", "title": "Enriching Word Vectors with Subword Information"}, {"paperId": "f04df4e20a18358ea2f689b4c129781628ef7fc1", "title": "A large annotated corpus for learning natural language inference"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "title": "GloVe: Global Vectors for Word Representation"}, {"paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09", "title": "Efficient Estimation of Word Representations in Vector Space"}, {"paperId": "9e698010f9d8fa374e7f49f776af301dd200c548", "title": "Reciprocal rank fusion outperforms condorcet and individual rank learning methods"}, {"paperId": "fc3272302461b74217662085a8a05a5e500dbf05", "title": "Challenges in building large-scale information retrieval systems: invited talk"}, {"paperId": "164125a65d42a791d2c1e108559344caef96d08b", "title": "Indexing by Latent Semantic Analysis"}, {"paperId": "f718309706172d6fb1e89f583927274f9a4cdf4f", "title": "Features of Similarity"}, {"paperId": "2ff694e20f492a7acf7fd0646c5e1576f0b3c901", "title": "C-Pack: Packaged Resources To Advance General Chinese Embedding"}, {"paperId": "9159408884cbe7f5f7a79d90c9f91ba5cee0d932", "title": "A Survey of Text Representation and Embedding Techniques in NLP"}, {"paperId": "277dd00ab02f122133bf56b485dfb7c730acdcde", "title": "Retrieval-based Language Models and Applications"}, {"paperId": "4972b88f8f324a4fa18e921f62a9857af2b5fc7b", "title": "Crosslingual Generalization through Multitask Finetuning"}, {"paperId": "46dff1c24effa2fe8df0bec4f020d45ac1f30018", "title": "PaRaDe: Passage Ranking using Demonstrations with LLMs"}, {"paperId": "f9150ecc4950237218e305d8390c2d027a166ce4", "title": "A Review on Word Embedding Techniques for Text Classification"}, {"paperId": null, "title": "\u201cVertex ai matching engine,\u201d"}, {"paperId": "5c5751d45e298cea054f32b392c12c61027d2fe7", "title": "S2ORC: The Semantic Scholar Open Research Corpus"}, {"paperId": null, "title": "\u201cElectra: Pre-training text encoders as discriminators rather than generators,\u201d"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "8ff46c88964a36985f2b45933a3d47b81bd87bd0", "title": "Quora Question Pairs"}, {"paperId": "ea67efe9866b245ea2b0bbb526239fbd7070f635", "title": "An Introduction to Information Retrieval"}, {"paperId": "0f3ab6835042ea45d2aab8e4a70151c11ca9a1d6", "title": "Topics in Semantic Representation"}, {"paperId": "22208f19fcef9f94102d43416a7ff99febd1347c", "title": "The Dissimilarity representations in pattern recognition. Concepts, theory and applications."}, {"paperId": "aab6f3b98cda74cfa252c710cf9b652afc024947", "title": "Handbook of Natural Language Processing"}, {"paperId": "4c98b6b0756588f1ad41f2c128523419bdfd2244", "title": "Nearest neighbor analysis of psychological spaces."}, {"paperId": "decd9bc0385612bdf936928206d83730718e737e", "title": "Distributional Structure"}, {"paperId": null, "title": "\u201c2d matryoshka sentence embeddings,\u201d"}, {"paperId": null, "title": "\u201cSfr-embedding-mistral:enhance text retrieval with transfer learning"}, {"paperId": null, "title": "AIMeta (2024)"}, {"paperId": null, "title": "\u201cOpen source strikes bread - new fluffy embeddings model,\u201d"}, {"paperId": null, "title": "Web page (147M): Common Crawl, Clue Webs, MS MARCO documents, title as query and the body text as document"}, {"paperId": null, "title": "\u201cLlama 3 model card,\u201d"}, {"paperId": null, "title": "Academic Paper (45M): arXiv, bioRxiv, medRxiv, PubMed and Semantic Scholar, title as query and its abstract as document"}]}