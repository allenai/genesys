{"paperId": "157ed5647da39a7f5d33a84a90414b2a9e97e301", "abstract": "We present Eagle (RWKV-5) and Finch (RWKV-6), sequence models improving upon the RWKV (RWKV-4) architecture. Our architectural design advancements include multi-headed matrix-valued states and a dynamic recurrence mechanism that improve expressivity while maintaining the inference efficiency characteristics of RNNs. We introduce a new multilingual corpus with 1.12 trillion tokens and a fast tokenizer based on greedy matching for enhanced multilinguality. We trained four Eagle models, ranging from 0.46 to 7.5 billion parameters, and two Finch models with 1.6 and 3.1 billion parameters and find that they achieve competitive performance across a wide variety of benchmarks. We release all our models on HuggingFace under the Apache 2.0 license. Models at: https://huggingface.co/RWKV Training code at: https://github.com/RWKV/RWKV-LM Inference code at: https://github.com/RWKV/ChatRWKV Time-parallel training code at: https://github.com/RWKV/RWKV-infctx-trainer", "venue": "arXiv.org", "year": 2024, "citationCount": 17, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work presents Eagle and Finch, sequence models improving upon the RWKV (RWKV-4) architecture, which introduces a new multilingual corpus with 1.12 trillion tokens and a fast tokenizer based on greedy matching for enhanced multilinguality."}, "embedding": {"model": "specter_v2", "vector": [0.15648138523101807, 0.5933333039283752, -0.8010147213935852, -0.2872134745121002, -0.1392904818058014, -0.55002760887146, 0.7493359446525574, -0.2652808129787445, -0.7528398633003235, 0.06212577223777771, 0.8629034161567688, -0.40685564279556274, 0.5890395045280457, 0.39788660407066345, -0.16063864529132843, 0.18454162776470184, -1.1155681610107422, -0.06610806286334991, -0.3961133062839508, -0.28030696511268616, 0.10653123259544373, -0.6857135891914368, -0.765963077545166, 0.1404189169406891, -0.04249575734138489, 0.174814373254776, 0.34327659010887146, 0.877105176448822, -0.7314866781234741, 1.0053411722183228, 0.269390732049942, -0.3664533197879791, 0.34321996569633484, -0.00970411952584982, -0.7007474899291992, -0.4841769337654114, 0.30441200733184814, -0.2593710422515869, -0.5181183218955994, 0.6473036408424377, -0.23481088876724243, 0.4305087924003601, 0.23807194828987122, -0.5160349607467651, -0.2891860604286194, 1.487769603729248, 0.7038053870201111, 0.6051345467567444, -0.13756246864795685, -0.5244061350822449, 1.4013804197311401, -1.217449426651001, 0.748091995716095, 1.1327574253082275, 0.5645806193351746, 0.7817058563232422, 0.06453778594732285, -0.5386017560958862, 1.0654462575912476, 0.4855041801929474, -0.7821618914604187, -0.6265486478805542, -0.30383118987083435, -0.1278935670852661, 2.179689884185791, -0.22525034844875336, 0.4971787631511688, 0.6792763471603394, -0.1344078630208969, 1.1584231853485107, -0.3300318419933319, -0.8808784484863281, -0.3839389681816101, -0.04325724020600319, 0.24358032643795013, 0.7348439693450928, -0.6525008082389832, 0.3824116885662079, -0.7215303182601929, 0.1919298619031906, 0.4233274459838867, 0.07256390899419785, 0.17640213668346405, 0.05143746733665466, -0.690481424331665, 0.7064467668533325, 0.2951551675796509, 0.9563006162643433, -0.2709193527698517, 0.6929661631584167, 0.6235256791114807, 0.23390688002109528, -0.352088987827301, 0.13241633772850037, -0.29274845123291016, 0.02832382544875145, -0.9545634388923645, 0.28064998984336853, -0.21290035545825958, 0.4472425878047943, -0.11017607897520065, 0.45675790309906006, -0.7073075175285339, -0.06903865933418274, 1.5875048637390137, -0.15108972787857056, 0.5582157373428345, -0.9461400508880615, 0.003770775394514203, -0.7597161531448364, 0.11694475263357162, -0.5135971903800964, -0.2743576169013977, -0.28363683819770813, -0.5072970390319824, -1.3051681518554688, -0.3463684916496277, 0.10719184577465057, -0.7458096146583557, 1.0691239833831787, -0.31858885288238525, 0.4307093620300293, 0.4497748911380768, 0.40571340918540955, 0.8684487342834473, 0.8712804913520813, 0.1901606172323227, -0.19302478432655334, 0.7331866025924683, -0.9470946192741394, -1.0158107280731201, -1.0563082695007324, 0.8083042502403259, 0.017474310472607613, -0.20428237318992615, -0.414225310087204, -1.0558382272720337, -0.8137280344963074, -0.7036270499229431, -0.08632280677556992, -0.34008678793907166, 0.0680275559425354, 0.9989776611328125, 0.11289788037538528, -1.1405266523361206, 0.6878870129585266, -0.25662028789520264, 0.07731401175260544, -0.11236303299665451, 0.14446061849594116, 0.19528044760227203, -0.2132192850112915, -1.5989201068878174, 0.478121280670166, 0.3598342537879944, 0.24489997327327728, 0.19387026131153107, -0.585304319858551, -1.3078060150146484, -0.31179317831993103, 0.10873477160930634, -0.08410349488258362, 1.550555944442749, 0.14852868020534515, -1.3241260051727295, 0.8217177987098694, -0.5134413242340088, -0.18024887144565582, 0.15329484641551971, 0.015619384124875069, -0.936485230922699, -0.6655969023704529, -0.23187877237796783, 0.6464815735816956, 0.22415007650852203, -0.029523370787501335, -0.03836597502231598, -0.04794096574187279, -0.5781474113464355, -0.14936034381389618, 0.10257115960121155, 1.059080958366394, -0.04745597764849663, 0.13581912219524384, 0.21938039362430573, 0.6513219475746155, -0.038290541619062424, -0.43685513734817505, -0.7386448979377747, -1.0865496397018433, 0.5565940737724304, -0.18020737171173096, 1.0356736183166504, -0.697733461856842, -0.7481962442398071, -0.25279057025909424, -0.08477882295846939, 0.18538445234298706, -0.6541100144386292, 0.7048931121826172, -0.5245230197906494, 0.42624756693840027, 0.05117809399962425, -0.736278235912323, -0.08543965220451355, -0.03083529882133007, -0.5817388296127319, -0.038350287824869156, 0.01094351802021265, 1.1091303825378418, -0.9499494433403015, -0.11891797184944153, 0.3433712422847748, 0.32479679584503174, -0.7370926141738892, 1.0055711269378662, -0.2635687291622162, 0.14133493602275848, 0.18369248509407043, -0.7658655047416687, -0.11123908311128616, -0.23931008577346802, 0.9009783864021301, -0.32312852144241333, -0.761809766292572, 0.9357675313949585, -0.8785561323165894, 1.4504384994506836, -0.4564938545227051, 0.6063281893730164, -0.06721702963113785, -0.5539551973342896, 0.3623446822166443, 0.28519564867019653, -0.16171981394290924, -0.3389606475830078, 0.15640385448932648, 0.21453042328357697, -0.28015053272247314, 0.2146913856267929, 0.9099935293197632, 0.8621188998222351, -0.14935584366321564, -0.07388956099748611, 0.3639906942844391, 0.14413389563560486, 0.3548980951309204, 0.747779905796051, 0.6758628487586975, 0.39662015438079834, 0.4810038208961487, 0.07020200788974762, 0.11793433129787445, -0.7299807667732239, 0.4211708903312683, 0.22645151615142822, 0.6545515060424805, 0.5610393285751343, 0.0845254585146904, -0.8254821300506592, -0.3334008753299713, 0.2043296843767166, 0.3388442397117615, 0.9770717024803162, -0.10946687310934067, -0.4366660416126251, -0.40237149596214294, 0.03324578329920769, -0.3351558744907379, 0.15281158685684204, -0.2897903621196747, 0.05981060862541199, -0.9543493390083313, -0.35385236144065857, 0.8190866112709045, 0.3413691520690918, 0.9110709428787231, -1.0389206409454346, -0.3958474397659302, -0.16650545597076416, -0.1616055965423584, -0.7022059559822083, -0.46420779824256897, 0.4706695079803467, -0.21840913593769073, -0.004296962637454271, 0.18690943717956543, -0.3734658360481262, -0.23324233293533325, -1.0368402004241943, 1.0027800798416138, -0.2625730335712433, -0.3314948081970215, -0.4402201175689697, 0.5002568960189819, -0.13551008701324463, -0.6967348456382751, 0.23711122572422028, 0.21234120428562164, -0.3061508536338806, 0.15736277401447296, 0.6454922556877136, -0.14064188301563263, -0.41268065571784973, -0.19427375495433807, 0.2546474039554596, -0.15134964883327484, -0.001176593010313809, 0.4822287857532501, -0.725435197353363, 0.22994238138198853, -1.2814210653305054, 0.1563737690448761, 0.3434399366378784, -0.35291987657546997, 0.04248429462313652, -0.5832671523094177, -0.17781858146190643, 0.40175002813339233, -0.3174152076244354, -0.35476556420326233, -0.5621720552444458, -0.03370990231633186, -0.20391398668289185, -0.1459302008152008, 0.1524178832769394, 0.35999608039855957, 0.8234021663665771, 0.07344520837068558, 0.4535446763038635, 0.3442423939704895, 0.19405987858772278, 1.0267846584320068, -0.4621250629425049, 0.9952916502952576, 0.6460917592048645, -0.023691829293966293, -0.3455655574798584, -0.389322429895401, -0.6123678088188171, -0.24487295746803284, -0.5661974549293518, -0.24284835159778595, -0.45117706060409546, 0.4054930508136749, -0.5081779956817627, -1.2715483903884888, 0.1710437536239624, -1.394374132156372, -0.45552799105644226, 0.012231000699102879, -0.03879909962415695, -0.03426080197095871, -0.675172746181488, -1.4504175186157227, -1.062398910522461, -0.4304455816745758, -0.5876035094261169, 0.09676668047904968, 0.07628598064184189, -0.5304504036903381, -0.43476730585098267, 0.4854007065296173, -0.727276086807251, 0.7971483469009399, -0.6255630850791931, 0.679977536201477, 0.17963339388370514, 0.029716985300183296, 0.053107600659132004, 0.490844190120697, 0.34846746921539307, -0.43313419818878174, 0.6944460868835449, -0.49709248542785645, 0.500175416469574, -0.8459177017211914, -0.4011556804180145, 0.10237276554107666, 0.41119635105133057, 0.3450761139392853, -0.16885998845100403, -0.5110969543457031, 0.29386991262435913, 1.1977744102478027, -0.44667673110961914, 0.42316117882728577, 0.17317423224449158, 0.7137975096702576, 0.3020015060901642, -0.24900692701339722, 0.7500067353248596, 0.31922608613967896, 0.7085748910903931, 0.38527828454971313, 0.18849629163742065, -0.05100172385573387, -0.5550583004951477, 0.7919025421142578, 1.573592185974121, 0.382906436920166, -0.08951443433761597, -0.7535943388938904, 0.7080338001251221, -1.4817441701889038, -1.2797738313674927, 0.3074202537536621, 0.5060350894927979, 0.6481746435165405, -0.8848761320114136, 0.009104846976697445, 0.08008526265621185, 0.9092317223548889, 0.6303495764732361, -0.5422654747962952, -1.0247972011566162, -0.14234954118728638, 0.363222599029541, 0.27422595024108887, 0.7841200828552246, 0.09208105504512787, 0.907158613204956, 14.955967903137207, 0.4987017810344696, -0.2157038152217865, 0.21742494404315948, 0.23438265919685364, -0.018339689821004868, -0.530475914478302, -0.13690577447414398, -1.6031787395477295, -0.08564867824316025, 1.3926759958267212, 0.31802815198898315, 0.7115634083747864, -0.20780612528324127, 0.2265056073665619, 0.4633552134037018, -0.34423932433128357, 0.6318436861038208, 0.1991228461265564, -1.4564428329467773, -0.09998781234025955, -0.009117686189711094, 0.13475878536701202, 0.7015103101730347, 0.7793977856636047, 0.8147362470626831, 0.9210183024406433, -0.58176189661026, 0.7988079190254211, 0.5094960927963257, 1.1136810779571533, -0.1415855586528778, 0.357972115278244, 0.3794879615306854, -0.9839879274368286, -0.21487551927566528, -0.5259929895401001, -1.3295115232467651, 0.4959660768508911, 0.23641830682754517, -0.5244452357292175, -0.3308112621307373, -0.14730575680732727, 0.9660765528678894, 0.706771731376648, 0.15023070573806763, -0.3192764222621918, 0.7393032908439636, 0.18288810551166534, -0.05026844143867493, 0.3521038293838501, 0.297674298286438, -0.08612389862537384, 0.17336136102676392, -0.15878430008888245, -0.13184770941734314, 0.03855537995696068, 0.2799072563648224, -0.45901915431022644, -0.06499415636062622, -0.309836208820343, -0.4112635850906372, 0.32052183151245117, 1.033165693283081, 0.7234458327293396, 0.46202993392944336, -0.2693239748477936, 0.2648707628250122, 0.7472541928291321, -0.09953144937753677, -0.301613450050354, -0.00827973522245884, 0.8040567636489868, -0.6095120310783386, 0.1117524579167366, 0.3149230182170868, 0.23513564467430115, -0.44848892092704773, -1.0032835006713867, -0.16357897222042084, 0.25944551825523376, -0.5611288547515869, -0.43752625584602356, 0.9986445903778076, -0.6527387499809265, -0.23819468915462494, -0.6203520894050598, -0.7267444133758545, -0.01834431104362011, 0.37527233362197876, -1.4963979721069336, -0.3468863368034363, 0.45979043841362, -0.009900445118546486, -0.6624241471290588, 0.42653951048851013, 1.2366642951965332, 0.19475212693214417, -0.45442789793014526, -0.012803299352526665, 0.249019056558609, 0.454206645488739, -0.317162424325943, -0.6115740537643433, 1.0423859357833862, 0.3134462833404541, 0.22708746790885925, 0.3240041732788086, 0.036898914724588394, 0.20696555078029633, -0.7363389134407043, -0.2708214521408081, 0.952914834022522, -0.8132064938545227, -0.478633314371109, -0.8497307896614075, -0.5840310454368591, 0.7809397578239441, 0.582508385181427, -0.044281601905822754, 0.24720022082328796, 0.23364903032779694, -0.7403750419616699, 0.04330237954854965, -0.7441579699516296, 0.05561412125825882, 0.8927661180496216, -0.6461384892463684, -0.3020502030849457, -0.19554917514324188, 0.5260747075080872, -0.8707281947135925, -0.42214295268058777, -0.28622204065322876, 0.36713188886642456, 0.06002777814865112, 0.7666307687759399, -0.6236551403999329, 0.5283015370368958, 0.7880829572677612, -0.14570100605487823, -0.9511913061141968, -0.25916188955307007, -0.8609641790390015, -0.11980513483285904, 0.34665828943252563, 0.8122881054878235, -0.2767753303050995, 0.35959675908088684, 0.38930606842041016, 0.10131428390741348, -0.4110397398471832, -0.6253991723060608, -0.6678526997566223, 0.0081716263666749, -0.44826388359069824, 0.31215593218803406, 0.0976778119802475, 0.23601602017879486, 0.1825827658176422, 0.14762678742408752, 0.16282396018505096, -0.5969563722610474, -0.8424700498580933, -0.052922144532203674, -0.09417103976011276, -0.2321702241897583, -0.45803597569465637, -0.9479765295982361, -1.2431106567382812, 0.4283815920352936, -1.3538953065872192, 0.3054473400115967, -1.1692039966583252, -0.3429963290691376, 0.15816333889961243, -0.10883812606334686, 0.34364578127861023, 0.48278093338012695, -0.16558073461055756, -0.3905355632305145, -0.6149513125419617, -0.5791235566139221, 0.5310877561569214, 0.48905476927757263, -0.4885367453098297, 0.21472395956516266, -0.31185996532440186, 0.12306283414363861, -0.2057819962501526, 0.4680427014827728, -0.2897300720214844, -0.3741588890552521, -1.282446026802063, 0.720088005065918, 0.16796770691871643, -0.14190617203712463, -0.4618673324584961, 0.37200453877449036, 0.5668463706970215, -0.25092828273773193, -0.11052051186561584, 0.3285888135433197, -0.32994794845581055, -0.07018378376960754, 0.5284281969070435, -0.9285568594932556, 0.4571492671966553, 0.04727359861135483, -0.5773608088493347, 0.02243075892329216, 0.4704391658306122, -0.016137976199388504, -1.0638195276260376, -1.07218599319458, 0.4538865089416504, -0.9711105823516846, 0.15866771340370178, -0.2714962065219879, -0.2162841111421585, -1.07582688331604, -0.5735008120536804, -0.03742004930973053, 0.30372825264930725, -0.4437532424926758, 0.8992165923118591, 0.19031257927417755, -1.0004733800888062, -0.09430283308029175, 0.1370214819908142, -0.16109313070774078, -0.19198107719421387, 0.39170268177986145, 0.03406070917844772, -0.22496868669986725, 0.4350709617137909, 0.22121629118919373, 0.34785497188568115, -0.9395124912261963, 0.013613244518637657, 0.7470389008522034, -0.348965585231781, -0.24276399612426758, 1.1158045530319214, -1.0260288715362549, -1.4370718002319336, 0.20062638819217682, -1.137503981590271, -0.7838692665100098, -0.3322724401950836, 0.6528081893920898, 0.24766066670417786, 0.22716541588306427, -0.38977348804473877, -0.844463050365448, 0.11987011134624481, -0.14485785365104675, -0.7051536440849304, 0.428898423910141, -0.08348686248064041, -0.2192666083574295, 0.8697230815887451, 0.9578747153282166, -0.4278556704521179, -0.4257733225822449, -0.5870640277862549, -0.44701793789863586, 0.2992080748081207, 0.1818266212940216, -0.43926700949668884, -0.6830973029136658, 0.6385689377784729, 0.39780497550964355, 0.1784563660621643, -0.4661045968532562, -0.1154053583741188, 0.33839908242225647, 0.7433702349662781, -0.07553377002477646, -0.4146837592124939, -0.7227804064750671, 1.4868812561035156, 0.7221047282218933, -0.4307469427585602, -0.2090393453836441, -0.12315460294485092, -0.5782190561294556, 0.6089465618133545, 0.17575789988040924, -0.06089380756020546, 0.689017653465271, -0.004154479131102562, 0.6036862134933472, 0.21900425851345062, -1.1486849784851074, -0.3098897635936737, 0.04269595816731453, 0.9736188650131226, 0.9751507043838501, 0.3531377613544464, -0.0247372854501009, 0.44045957922935486, -0.13508233428001404, -6.949710950721055e-05, 0.45983001589775085, 0.49521785974502563, -0.007257265038788319, -0.344372034072876, 0.4343522787094116, 0.7618873119354248, -0.6988251209259033, -0.8412117958068848, 0.09235063940286636, 0.5903218984603882, 0.1628674864768982, 0.9695098400115967, 1.0920931100845337, -0.03525328263640404, 0.28164440393447876, 0.2726019620895386, 0.7203155755996704, -0.48531466722488403, -0.6031832098960876, -0.6510884165763855, -0.4451961815357208, -0.40024393796920776, -0.2677341401576996, -0.9385492205619812, -1.0341144800186157, -0.38899165391921997, 0.08986251801252365, 0.3657935857772827, 0.5025416612625122, 1.2429242134094238, 0.5996987819671631, 0.38672634959220886, -0.25398826599121094, -0.16582411527633667, -0.5081840753555298, -0.9131253361701965, -0.22361283004283905, -0.5849131941795349, -0.01597963459789753, 0.08636429160833359, -0.06748352199792862, -0.5582149624824524]}, "authors": [{"authorId": "2295773183", "name": "Bo Peng"}, {"authorId": "2295733582", "name": "Daniel Goldstein"}, {"authorId": "2260401329", "name": "Quentin Anthony"}, {"authorId": "2044198106", "name": "Alon Albalak"}, {"authorId": "79046907", "name": "Eric Alcaide"}, {"authorId": "103476203", "name": "Stella Biderman"}, {"authorId": "2295732709", "name": "Eugene Cheah"}, {"authorId": "2284067181", "name": "Teddy Ferdinan"}, {"authorId": "2295734267", "name": "Haowen Hou"}, {"authorId": "2274771600", "name": "P. Kazienko"}, {"authorId": "101433524", "name": "G. Kranthikiran"}, {"authorId": "2284064003", "name": "Jan Koco'n"}, {"authorId": "2208962106", "name": "Bartlomiej Koptyra"}, {"authorId": "1387484410", "name": "Satyapriya Krishna"}, {"authorId": "2295732467", "name": "Ronald McClelland"}, {"authorId": "2037383772", "name": "Niklas Muennighoff"}, {"authorId": "2295732463", "name": "Fares Obeid"}, {"authorId": "2186861874", "name": "Atsushi Saito"}, {"authorId": "2295749628", "name": "Guangyu Song"}, {"authorId": "2239200170", "name": "Haoqin Tu"}, {"authorId": "2284064954", "name": "Stanislaw Wo'zniak"}, {"authorId": "2218987422", "name": "Ruichong Zhang"}, {"authorId": "2239378815", "name": "Bingchen Zhao"}, {"authorId": "2295775910", "name": "Qihang Zhao"}, {"authorId": "2296035480", "name": "Peng Zhou"}, {"authorId": "2295965843", "name": "Jian Zhu"}, {"authorId": "2239507803", "name": "Ruijie Zhu"}], "references": [{"paperId": "d53fe76bd2795a19ddf52d012917782f6f6f2c1e", "title": "Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models"}, {"paperId": "917096f28209ef90c9e6363cf49438341120af5e", "title": "Theoretical Foundations of Deep Selective State-Space Models"}, {"paperId": "31ef7b614fa58a4e71c87f2c38b1e9edd7bbb424", "title": "A Survey on Data Selection for Language Models"}, {"paperId": "de41158515fa7260a0983e787650884a98eed811", "title": "On the Resurgence of Recurrent Models for Long Sequences - Survey and Research Opportunities in the Transformer Era"}, {"paperId": "de643836277d108e1f8410ea85b0c3ed0e686163", "title": "MaLA-500: Massive Language Adaptation of Large Language Models"}, {"paperId": "98ab627dd147db88b5e5cfa9a74f1bd8da110021", "title": "TinyGPT-V: Efficient Multimodal Large Language Model via Small Backbones"}, {"paperId": "5851121df5ce46be5faea265c868ec0beabfce96", "title": "Efficient Large Language Models: A Survey"}, {"paperId": "194e57aee2d936f5f8ffa038e663bcb3bb2fdc1f", "title": "Efficient Online Data Mixing For Language Model Pre-Training"}, {"paperId": "434d751d355d7a7c20efa570e785c76286245e77", "title": "Hierarchically Gated Recurrent Neural Network for Sequence Modeling"}, {"paperId": "124d4d374fbef2016fa9880489871a58a7450644", "title": "Improved Baselines with Visual Instruction Tuning"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "42d83576ee920c1b6df318e212047d9ba57fc4fd", "title": "BAMBOO: A Comprehensive Benchmark for Evaluating Long Text Modeling Capacities of Large Language Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "240103933ffe3dac2179cc160a2bd91299357a53", "title": "Retentive Network: A Successor to Transformer for Large Language Models"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "17fbffb05fa14e21d1c506fd5f0f568b955fe983", "title": "Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "206400aba5f12f734cdd2e4ab48ef6014ea60773", "title": "Evaluating Object Hallucination in Large Vision-Language Models"}, {"paperId": "9b4f7c97c0b83a80c32bc0b93595cbcfb4ecb16d", "title": "DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining"}, {"paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd", "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"}, {"paperId": "f393aff1593c2d370ec0ae004910d18e40524967", "title": "Resurrecting Recurrent Neural Networks for Long Sequences"}, {"paperId": "5848737f78397f72ceae2ba6f3419a6a8502b8ba", "title": "ChatGPT: Jack of all trades, master of none"}, {"paperId": "998ac3e945857cf2676ee7efdbaf443a0c6f820a", "title": "Hyena Hierarchy: Towards Larger Convolutional Language Models"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "8ca9e32b779bc2e23b6dfcfd00abb7d89c0b81f1", "title": "TunesFormer: Forming Irish Tunes with Control Codes by Bar Patching"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "88a74e972898de887ad9587d4c87c3a9f03f1dc5", "title": "MTEB: Massive Text Embedding Benchmark"}, {"paperId": "2c676ecdc954ec24e1907c76accb1e8ac06deec0", "title": "Data-Efficiency with a Single GPU: An Exploration of Transfer Methods for Small Language Models"}, {"paperId": "70e91e16eb321067d9402710e14a40cf28311f73", "title": "Mega: Moving Average Equipped Gated Attention"}, {"paperId": "d3135733aa39dec20ce72aa138589dda27c8406d", "title": "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "71e15a9a52dcafca57bff5f310b95e2c7d0cfc87", "title": "Diagonal State Spaces are as Effective as Structured State Spaces"}, {"paperId": "4724ebee34ca2cd0a19c3a1ddb83d6d870dd7904", "title": "Few-shot Learning with Multilingual Generative Language Models"}, {"paperId": "3dfb1f50f2a34a699c339dabaa6f9b3a977973de", "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "64902a5077ee68011cd467398dbb66511e8e891a", "title": "It\u2019s All in the Heads: Using Attention Heads as a Baseline for Cross-Lingual Transfer in Commonsense Reasoning"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "d5e999aae76d5270ef272076979c809817458212", "title": "An Attention Free Transformer"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "1d3dd6a85ef874a328d34305b884eac5113e292d", "title": "Think you have Solved Direct-Answer Question Answering? Try ARC-DA, the Direct-Answer AI2 Reasoning Challenge"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "0964490205fdc38c2f0980c9d778069089ca92e3", "title": "HiPPO: Recurrent Memory with Optimal Polynomial Projections"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "d97e7561fa7710213ccd4f8128044ea6849be377", "title": "XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning"}, {"paperId": "8f34ee2ec88e8b19b2736de55eb170539d26e527", "title": "Making Monolingual Sentence Embeddings Multilingual Using Knowledge Distillation"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "34eccf3528e4350543c76752cac978e0f2c5b7a2", "title": "Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks"}, {"paperId": "04a7021fe6be6bddcfae476493fcc7571e7c613c", "title": "PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification"}, {"paperId": "92343cecdc990380de362b969eec60081959f507", "title": "Asynchronous Pipeline for Processing Huge Corpora on Medium to Low Resource Infrastructures"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "af1f7739283bdbd2b7a94903041f6d6afd991907", "title": "Towards VQA Models That Can Read"}, {"paperId": "a7ac99d7cf3f568ab1a741392144b646b856ae0c", "title": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering"}, {"paperId": "1c3112ef8a346b9817382ed34a8c146c53d5bcf5", "title": "XNLI: Evaluating Cross-lingual Sentence Representations"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "d08b35243edc5be07387a9ed218070b31e502901", "title": "Group Normalization"}, {"paperId": "fdfa7dc73dc1fc6772d26f88c72e98b68d1f8498", "title": "Parallelizing Linear Recurrent Neural Nets Over Sequence Length"}, {"paperId": "932a5de79d8a8ebb75ea0c43493450fd9922e738", "title": "Crowdsourcing Multiple Choice Science Questions"}, {"paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586", "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"}, {"paperId": "5ed791f810da580c78df6a052c6b9f2e258f6b0a", "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context"}, {"paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e", "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"}, {"paperId": "5cfbbf3cdff0f905874589bcd21b2646340a5447", "title": "Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning"}, {"paperId": "1a628e6273db34e1685c83953fa0ea616570f311", "title": "Benchmarking"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "bc22e87a26d020215afe91c751e5bdaddd8e4922", "title": "Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks"}, {"paperId": "7f0ea2dd48c88319b6a2e0679aa3b68c9a1de0da", "title": "The Influence Curve and Its Role in Robust Estimation"}, {"paperId": "9f757e70aaba31edb4b889a00a5fe7bdf101658f", "title": "Self-learning--What is it?"}, {"paperId": "b407333315ed98c023caf04ca8cac90c74f2fb3e", "title": "CritiqueLLM: Scaling LLM-as-Critic for Effective and Explainable Evaluation of Large Language Model Generation"}, {"paperId": null, "title": "A mathematical framework for transformer circuits"}, {"paperId": "327ca68ef78290f784bdc2d405d0d4f5cb96d33b", "title": "State Space"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "ec0bc920662693375a881d8beb8c97bf08281dba", "title": "Prefix sums and their applications"}, {"paperId": null, "title": "BigScience Workshop"}, {"paperId": null, "title": "Reduce the heat to low and simmer for about 10 minutes, stirring occasionally to prevent sticking. The sauce should be thickened slightly"}, {"paperId": null, "title": "Introducing idefics: An open reproduction of state-of-the-art visual language model"}, {"paperId": null, "title": "SlimPajama: A 627B token cleaned and dedu-plicated version of RedPajama"}, {"paperId": null, "title": "Teknium"}, {"paperId": null, "title": "better large"}, {"paperId": null, "title": "Simmering with bay leaves: Add 1-2 bay leaves to the pot and bring it to a simmer over low heat for about 10-15 minutes, stirring occasionally to prevent sticking or scorching"}, {"paperId": null, "title": "A framework for few-shot language model evaluation"}, {"paperId": null, "title": "length-extrapolatable"}, {"paperId": null, "title": "Once the sauce is thickened, carefully place the pork belly back in the pot skin side down, with a layer of sauce underneath it to help seal in the flavors"}, {"paperId": null, "title": ": Fully data-controlled linear recurrence for sequence"}]}