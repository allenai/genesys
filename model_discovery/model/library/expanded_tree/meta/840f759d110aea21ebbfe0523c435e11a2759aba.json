{"paperId": "840f759d110aea21ebbfe0523c435e11a2759aba", "abstract": "Despite large neural networks demonstrating remarkable abilities to complete different tasks, they require excessive memory usage to store the optimization states for training. To alleviate this, the low-rank adaptation (LoRA) is proposed to reduce the optimization states by training fewer parameters. However, LoRA restricts overall weight update matrices to be low-rank, limiting the model performance. In this work, we investigate the dynamics of LoRA and identify that it can be approximated by a random projection. Based on this observation, we propose Flora, which is able to achieve high-rank updates by resampling the projection matrices while enjoying the sublinear space complexity of optimization states. We conduct experiments across different tasks and model architectures to verify the effectiveness of our approach.", "venue": "arXiv.org", "year": 2024, "citationCount": 7, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work investigates the dynamics of LoRA and identifies that it can be approximated by a random projection, and proposes Flora, which is able to achieve high-rank updates by resampling the projection matrices while enjoying the sublinear space complexity of optimization states."}, "embedding": {"model": "specter_v2", "vector": [0.13955283164978027, 0.33252403140068054, -0.36473527550697327, -0.11264351010322571, 0.23621894419193268, 0.3579781651496887, 0.4065406620502472, -0.5448225140571594, -0.7141830325126648, -0.25881510972976685, 0.41361165046691895, 0.20631828904151917, 0.22845424711704254, 0.16593621671199799, -0.4276549220085144, -0.18883581459522247, -1.2597979307174683, 0.14908453822135925, -0.06692421436309814, -0.4279250204563141, -0.13360200822353363, -0.2211425006389618, -0.8638284802436829, 0.04505127668380737, 0.18907038867473602, 1.0159673690795898, 0.029384151101112366, 0.8926478624343872, -0.36761435866355896, 0.4196493923664093, 0.8048959374427795, -0.3306278586387634, 0.9128655791282654, -0.20623956620693207, -0.07598016411066055, -0.09003672003746033, 0.3386112153530121, -0.6261383295059204, -0.3371274471282959, 1.0297741889953613, -0.15167683362960815, 0.45284998416900635, 0.22118136286735535, -0.2577863931655884, -0.008658247999846935, 0.23114974796772003, 0.5057275891304016, 0.7463452219963074, -0.4511023163795471, -0.3159674406051636, 1.0653326511383057, -1.4815924167633057, 0.17993764579296112, 1.262845516204834, 0.9751127362251282, 0.5954585075378418, -0.36431416869163513, -0.7554371356964111, 1.1109459400177002, -0.07180823385715485, -0.8730600476264954, -0.26694348454475403, 0.012760160490870476, 0.14343544840812683, 1.3778860569000244, -0.5809194445610046, -0.10650626569986343, 0.9397386312484741, 0.40706849098205566, 0.9407899379730225, 0.1645374596118927, -0.46497616171836853, 0.1036568284034729, 0.34697622060775757, 0.19092951714992523, 0.825286328792572, -0.08419720083475113, 0.39377331733703613, -1.354615330696106, 0.14259347319602966, 0.757023811340332, 0.008421397767961025, -0.25679683685302734, -0.3012842535972595, 0.05809127911925316, 0.5900631546974182, 0.6584194302558899, 0.18188928067684174, -0.6567962169647217, 0.958365261554718, 0.3353167474269867, 0.9472383260726929, 0.26224881410598755, 0.5448706746101379, 0.09257850050926208, 0.22343340516090393, -0.3927672505378723, -0.027267873287200928, 0.08252166211605072, 0.7116799354553223, -0.10882878303527832, 0.3460531234741211, -0.12933970987796783, 0.5110564231872559, 1.2210673093795776, -0.4314386546611786, 0.90263831615448, -0.516481339931488, 0.41488415002822876, -0.7805164456367493, -0.1384190022945404, -0.9330851435661316, -0.31812527775764465, -1.0161949396133423, -1.3434391021728516, -0.5651516318321228, -0.641304075717926, 0.11473029851913452, -0.2556167542934418, 0.7722970247268677, -0.2853870689868927, 0.13276156783103943, -0.10004221647977829, 0.9947209358215332, -0.14963805675506592, 0.6921747922897339, -0.1412135660648346, 0.16563329100608826, 0.37035396695137024, -1.1582450866699219, -0.8153475522994995, -1.375050663948059, 0.052109066396951675, 0.01676924340426922, 0.5677364468574524, 0.16069334745407104, -1.311514973640442, -0.9717602133750916, -1.2202118635177612, 0.47670474648475647, -0.5695710182189941, 0.4017912745475769, 1.3397877216339111, 0.24947509169578552, -0.5842766165733337, 1.4697686433792114, -0.40640413761138916, -0.11467430740594864, 0.5395877957344055, 0.522087037563324, 0.029312148690223694, -0.33230850100517273, -0.8371392488479614, 0.21690423786640167, 0.4630642235279083, -0.07201626151800156, -0.17420761287212372, -0.54201740026474, -0.3268142342567444, 0.21709352731704712, 0.3572574257850647, -0.8676653504371643, 0.8641692996025085, -0.11282852292060852, -1.7335560321807861, 0.1331986039876938, 0.32142961025238037, 0.03028772957623005, 0.46481847763061523, -0.32768264412879944, -0.4611893892288208, -0.06731303781270981, -0.8227722644805908, 0.42952805757522583, 0.7393137812614441, -0.35676249861717224, 0.0043275319039821625, -0.04346412420272827, -0.5153325796127319, 0.01375044696033001, -0.6264409422874451, 0.39649665355682373, -0.7959039807319641, -0.2978823781013489, 0.9038265943527222, 0.6082369089126587, -0.1530715376138687, 0.18822097778320312, -0.24897924065589905, -0.36052000522613525, 0.10122914612293243, 0.10712666064500809, 0.9165040850639343, -0.8695688843727112, -0.43709826469421387, 0.1878058761358261, -0.15387441217899323, -0.32716190814971924, -1.0772634744644165, 0.3054531514644623, -0.4722346067428589, 0.3138776123523712, -0.08561411499977112, -1.211303949356079, -0.2499571442604065, -0.02391744963824749, -0.6962870955467224, 0.13262557983398438, 0.3947654664516449, 0.7719980478286743, -1.049727439880371, 0.4946468472480774, -0.4844646751880646, 0.1444489061832428, -1.3252267837524414, 1.174126386642456, 0.004992049653083086, 0.041051119565963745, 0.12094076722860336, -0.2676771581172943, -0.17575503885746002, -0.5269190669059753, 0.34134796261787415, -0.6090356111526489, 0.3993837237358093, 0.47549694776535034, -0.8758894801139832, 1.3427072763442993, -0.6231487393379211, 0.5126409530639648, 0.16622453927993774, -0.5142209529876709, -0.04303409531712532, 0.11554938554763794, 0.068837970495224, -0.08589605242013931, 0.6824302077293396, 0.3442147970199585, -0.5791967511177063, 0.580651044845581, 0.3334394097328186, 0.8036516308784485, -0.06319322437047958, 0.13272860646247864, 0.6916097402572632, -0.15454228222370148, 0.4506394863128662, 0.1281100958585739, 0.4111936390399933, 0.2837839424610138, 0.5307632088661194, 0.00512773497030139, 0.047789476811885834, -1.1260371208190918, -0.06762392818927765, 0.6306332349777222, 0.869215190410614, 0.9255478382110596, 0.3015476167201996, -0.8955909609794617, -0.3522646725177765, -0.4230024516582489, 0.5765635371208191, 1.2312959432601929, -0.3224935233592987, -0.07102660089731216, -0.2923817038536072, 0.13478294014930725, -0.3767023980617523, -0.3110067844390869, -0.46876996755599976, -0.570917010307312, -0.44307762384414673, -1.5452861785888672, 0.4389614462852478, 0.04381582885980606, 1.2894827127456665, -0.07437203824520111, -0.04364028945565224, -0.1594218909740448, 0.802402913570404, -0.5107353925704956, -0.8091055154800415, 0.5364826917648315, -0.9919266700744629, -0.1484643667936325, 0.16030004620552063, 0.22138534486293793, 0.40676772594451904, -0.6730781197547913, 0.6542036533355713, -0.5695875287055969, -0.03656422346830368, -0.08067723363637924, 0.6843946576118469, -0.5115788578987122, -0.39900538325309753, 0.3123835027217865, 0.4452117383480072, 0.3251969814300537, -0.3261728882789612, -0.21798613667488098, -0.05471409112215042, 0.07098232209682465, -0.4207191467285156, 0.26093029975891113, 0.4534029960632324, 0.31179970502853394, 0.7805668115615845, -0.5791907906532288, 0.350181519985199, -1.540502905845642, 1.4985069036483765, -0.01958981342613697, -0.49276429414749146, -0.2614719867706299, -1.2009576559066772, -0.04241887107491493, 0.6477419137954712, -1.1391083002090454, -0.14743661880493164, -0.9442977905273438, -0.01982983760535717, -0.6102527976036072, 0.32180389761924744, 0.38666826486587524, 0.7751548290252686, -0.34054574370384216, 0.7864878177642822, 0.10374225676059723, 0.6153181791305542, -0.459897518157959, 0.33626362681388855, -1.2596269845962524, 1.009279489517212, 0.3666628301143646, 0.344634085893631, -0.0015677771298214793, 0.11737537384033203, -0.23500889539718628, -0.6877298355102539, -0.40139245986938477, -0.03459108993411064, -0.359895795583725, -0.17882387340068817, -0.7124338150024414, -0.7647035121917725, -0.07259655743837357, -0.2544766664505005, -0.6047233939170837, -0.23191460967063904, 0.20641203224658966, -0.19831311702728271, -1.1587907075881958, -1.6136844158172607, -0.28878480195999146, -0.8533986806869507, -0.9820263385772705, -0.3005462884902954, 0.16890040040016174, 0.0010369544615969062, -0.23975925147533417, -0.39771899580955505, -1.1690361499786377, 1.4365577697753906, -0.6866472363471985, 0.4914740324020386, 0.2923806607723236, -0.09076100587844849, -0.4325556457042694, 0.19234143197536469, 0.7827364802360535, -0.5438004732131958, -0.32743918895721436, -0.7948868274688721, 0.04302661865949631, -0.17432405054569244, -0.5314168930053711, 0.2540854513645172, 0.07886911183595657, 0.7572658061981201, -0.43812090158462524, -0.021777832880616188, 1.0789837837219238, 1.5420403480529785, -0.8957021236419678, 0.03596512973308563, 0.23717202246189117, 0.6523808836936951, 0.07841543853282928, -0.5650855898857117, 0.6606928706169128, -0.3178788721561432, 0.2852328419685364, 0.3761102259159088, 0.024490106850862503, -0.52469402551651, -0.7518226504325867, 0.5034837126731873, 1.9448161125183105, 0.47076526284217834, 0.38618752360343933, -0.3656136393547058, 0.06068481504917145, -0.9756045341491699, -0.544714093208313, 0.9046652913093567, 0.9544647932052612, 0.6062658429145813, -0.1985064446926117, -0.6478849649429321, -0.4484638571739197, 0.08239443600177765, 0.4346654415130615, -0.6762732863426208, -0.4485722482204437, 0.04663208872079849, 0.15808893740177155, 0.6415557265281677, 0.6713747978210449, 0.25754785537719727, 0.3709554076194763, 14.685218811035156, 0.34682315587997437, -0.11664364486932755, 0.837846577167511, 0.6199743151664734, -0.2646249234676361, 0.0747794434428215, -0.47429487109184265, -0.841728687286377, -0.021726815029978752, 1.177914023399353, 0.5807974338531494, 1.389810562133789, 0.3922744691371918, -0.1911776065826416, 0.29291629791259766, -0.2890419065952301, 0.9467036724090576, 0.4519466459751129, -1.4935359954833984, 0.1551811397075653, 0.053005535155534744, 0.8222524523735046, 0.9302189946174622, 0.8124458193778992, 0.8593289852142334, 0.42050701379776, -0.08998418599367142, 0.39490804076194763, 0.5719087719917297, 1.0647655725479126, -0.017510000616312027, 0.47402116656303406, 0.3835056722164154, -0.7022549510002136, -0.5075994729995728, -0.766622006893158, -1.0921742916107178, 0.2287723422050476, 0.14231333136558533, -0.19337984919548035, -0.5109540820121765, 0.18042908608913422, 0.8358619213104248, -0.25742968916893005, 0.5268310308456421, -0.07312780618667603, 0.5979319214820862, -0.44020602107048035, 0.1976301670074463, 0.16731512546539307, -0.3696492314338684, 0.0022557361517101526, -0.27749982476234436, 0.16462309658527374, -0.22934392094612122, 0.02685871534049511, 0.6816788911819458, -0.7228721380233765, -0.027790501713752747, 0.15662892162799835, -0.16982311010360718, -0.1094188317656517, 0.6969876289367676, 1.0116891860961914, 0.21156658232212067, -0.20776663720607758, 0.478849321603775, 0.8390272259712219, 0.4329386353492737, 0.15519998967647552, -0.1275905966758728, 0.572223424911499, -0.5462137460708618, -0.5569281578063965, 0.3922064006328583, -0.5041931867599487, -0.708842933177948, -0.5423653721809387, -0.6304150223731995, -0.07696321606636047, -0.9441728591918945, -0.9427739381790161, 0.875612735748291, -0.21754543483257294, -0.5087646842002869, 0.3850826323032379, -0.9273659586906433, -0.28113970160484314, 0.4206674098968506, -1.285565972328186, 0.24823510646820068, 0.053080517798662186, -0.45938214659690857, -0.3318878710269928, -0.5008009076118469, 0.9939515590667725, 0.5201172828674316, -0.7711127996444702, 0.28361809253692627, 0.2855685353279114, -0.4800187349319458, -0.09732509404420853, -0.4727517366409302, 0.7653362154960632, 0.41218748688697815, -0.19742737710475922, 0.7228280901908875, 0.0001700136053841561, 0.550727367401123, -0.9053269028663635, -0.0900401696562767, 0.022454218938946724, -0.10449822247028351, -0.020462840795516968, -0.5551421642303467, -0.9464976191520691, 0.27427807450294495, 0.16700837016105652, 0.008789452724158764, 0.23019395768642426, 0.34779173135757446, -0.7717663645744324, -0.6434707641601562, -0.543409526348114, 0.3668110966682434, 0.572720468044281, -0.703394889831543, -0.08952318876981735, -0.0030302205123007298, -0.00865007471293211, -0.9984070658683777, -0.5405756235122681, -0.32332831621170044, -0.06497802585363388, -0.1826677769422531, 1.3604427576065063, -0.38675856590270996, 0.5272492170333862, 0.6835553050041199, 0.11577104032039642, -1.0136654376983643, 0.030412601307034492, -0.6255735158920288, 0.10368022322654724, -0.3244771361351013, 0.3152850866317749, -0.9628720283508301, 0.34784993529319763, 0.38928136229515076, -0.047250181436538696, -0.7149367928504944, -0.6735636591911316, -0.34080785512924194, -0.3430466055870056, -0.44471901655197144, 0.002036393852904439, -0.20674434304237366, -0.1588657796382904, 0.3331489861011505, 0.26469624042510986, 0.4574948251247406, -0.30164459347724915, -1.055778980255127, 0.2760476768016815, 0.13827678561210632, -0.42408084869384766, -0.6801717281341553, -0.12460071593523026, -1.6137363910675049, -0.45427361130714417, -1.3023334741592407, -0.05534154549241066, -0.5065730810165405, -0.8405968546867371, -0.02857767604291439, -0.3459383547306061, -0.17306135594844818, 0.4163726270198822, -0.1923113316297531, -0.05263952910900116, -0.04529924318194389, -0.3786908686161041, 1.1246240139007568, 0.6926960349082947, -0.5112308859825134, -0.09654945135116577, 0.13038037717342377, 0.2447485774755478, 0.31600892543792725, 0.7623366117477417, -0.5214001536369324, -0.7605829238891602, -1.2759737968444824, 0.8428346514701843, -0.5182444453239441, -0.21328376233577728, -1.5274277925491333, 0.8969324827194214, 0.4024467468261719, 0.1726924479007721, 0.4235297441482544, 0.5316096544265747, -1.2557153701782227, -0.16687984764575958, 0.5614498853683472, -0.9037606120109558, 0.6327217817306519, 0.1303945630788803, -0.059608571231365204, -0.24417820572853088, 0.4315517842769623, 0.2567336857318878, -0.7496204376220703, -0.49408572912216187, 0.4632144272327423, -0.5665327310562134, -0.160214364528656, -0.6913787126541138, 0.08835789561271667, -1.1509854793548584, -0.340786337852478, 0.11096851527690887, 0.25905072689056396, -0.33456647396087646, 0.5575886964797974, 0.39653047919273376, -1.256455898284912, 0.3406383693218231, 0.6840711236000061, -0.13454554975032806, -0.205110564827919, 0.3446108400821686, 0.5797597169876099, -0.5676612257957458, -0.002147145802155137, -0.08012130111455917, 0.661851167678833, 0.026880137622356415, 0.006736640818417072, 1.030910849571228, -0.5672518014907837, -0.18645301461219788, 1.1323400735855103, -0.5642492175102234, -1.1771074533462524, 0.5261692404747009, -1.0287702083587646, -0.19188041985034943, -0.49328747391700745, 0.6766330003738403, 0.1759422868490219, -0.044946301728487015, 0.5505655407905579, -0.176671102643013, -0.006045318208634853, -0.07116825878620148, -0.2736225128173828, 0.45788052678108215, -0.36783602833747864, -0.12084333598613739, 0.846143364906311, 1.142138957977295, -0.7087891697883606, -1.19640052318573, -0.9602381587028503, -0.638678252696991, -0.29452142119407654, 0.5442704558372498, -0.2653624713420868, -1.118097186088562, 0.5585043430328369, 1.011961817741394, -0.37407439947128296, 0.5362398624420166, -0.45808783173561096, -0.26174524426460266, 1.1671113967895508, 0.012527372688055038, -0.7998523116111755, -0.004079409409314394, 0.927274227142334, 1.559183120727539, -0.854483962059021, 0.9214065670967102, -0.17997051775455475, -0.4423271417617798, 0.8277066349983215, 0.2382696568965912, -0.5087517499923706, 0.75096195936203, -0.36010509729385376, -0.20728878676891327, 0.16038164496421814, -1.2258267402648926, -0.13051797449588776, 0.7645711302757263, 0.6265502572059631, 0.2591203451156616, -0.1496831625699997, -0.1558663696050644, 0.720352053642273, -0.00271743000485003, 0.004298575688153505, 0.6940091848373413, -0.010505001991987228, -0.017752360552549362, 0.2344447821378708, -0.012511439621448517, 1.0036007165908813, -0.5687360167503357, -0.5629687905311584, 0.6816946864128113, 0.779995858669281, -0.2698919177055359, 0.34593963623046875, 0.6737449169158936, -0.19839613139629364, 0.8994229435920715, -0.12690123915672302, 0.1771082729101181, -0.2647743225097656, -0.522232711315155, -0.21287213265895844, -0.7876754999160767, -0.6001152992248535, 0.2740662693977356, -0.29552552103996277, -0.05597776919603348, -0.17736050486564636, 0.46270138025283813, -0.3275940716266632, 0.5209894776344299, 0.46814244985580444, 0.43071919679641724, 0.8893665075302124, -0.087620310485363, -1.068884015083313, -1.1330105066299438, -1.0449092388153076, 0.12811610102653503, -0.21580784022808075, -0.3962306082248688, -0.12414249032735825, -0.5345633029937744, -0.34567129611968994]}, "authors": [{"authorId": "2283824015", "name": "Yongchang Hao"}, {"authorId": "2254149760", "name": "Yanshuai Cao"}, {"authorId": "2282534661", "name": "Lili Mou"}], "references": [{"paperId": "c1fa6255cc9fc3128f74befc7855e255bc7a2c6e", "title": "GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "f4bdec0cf595720bc8ee5df2196324bac8f52ab4", "title": "Full Parameter Fine-tuning for Large Language Models with Limited Resources"}, {"paperId": "ad4b365630f1c13d74d78f0f5d8cee87ef356d41", "title": "Fine-Tuning Language Models with Just Forward Passes"}, {"paperId": "32ac52069e562d4f900afee70bdca63f53461481", "title": "QLoRA: Efficient Finetuning of Quantized LLMs"}, {"paperId": "dde69c0eb38e0e12bf19032c8815f3291dcd23ea", "title": "Sketchy: Memory-efficient Adaptive Regularization with Frequent Directions"}, {"paperId": "ea55230102f589d37f71992b97ba3dfe38fcbadc", "title": "Towards understanding how momentum improves generalization in deep learning"}, {"paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d", "title": "High-Resolution Image Synthesis with Latent Diffusion Models"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "11fe37ab6faf6bf85ad2f5746c154dec5412bd04", "title": "8-bit Optimizers via Block-wise Quantization"}, {"paperId": "a6fdb277d0a4b09899f802bda3359f5c2021a156", "title": "Recursively Summarizing Books with Human Feedback"}, {"paperId": "339b2b711fb5b228d097b03ebc3e62a521779235", "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "766bd9633ea0ed0ee2d8cc11ab083322666a3db9", "title": "Randomized Automatic Differentiation"}, {"paperId": "2dbdd9a64ed5dda1c5e5dedd9f5b55ccbb53900b", "title": "FetchSGD: Communication-Efficient Federated Learning with Sketching"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "1187c70c4011f935642084e84186284ac0add3d0", "title": "Exploring Versatile Generative Language Model Via Parameter-Efficient Transfer Learning"}, {"paperId": "d1bc9492eabb2cac705c26bcaca98a222772b437", "title": "Rethinking the Hyperparameters for Fine-tuning"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "90afc52bbacf37e6d3ca16ead35499f661222d7d", "title": "Momentum-Based Variance Reduction in Non-Convex SGD"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22", "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"}, {"paperId": "b4bfadfca9742bb3ee98a0cd322d5ce4e59a3ceb", "title": "A Call for Clarity in Reporting BLEU Scores"}, {"paperId": "03cf148638e007ddb42ac49f91225712b6c66a08", "title": "Revisiting Small Batch Training for Deep Neural Networks"}, {"paperId": "54a13bcc9613dcaa76fb25fbe96572f376cfcca9", "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "3299aee7a354877e43339d06abb967af2be8b872", "title": "Don't Decay the Learning Rate, Increase the Batch Size"}, {"paperId": "e7fd6848cb29ca221a7e17d823e06fb566f1f135", "title": "Mixed Precision Training"}, {"paperId": "f9c602cc436a9ea2f9e7db48c77d924e09ce3c32", "title": "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms"}, {"paperId": "3e8ccf9d3d843c9855c5d76ab66d3e775384da72", "title": "Why Momentum Really Works"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "942deb7d865b7782c03176d95e3a0d56cb71009e", "title": "Training Deep Nets with Sublinear Memory Cost"}, {"paperId": "d0b0c3e5a1e768490bc9b759685930541957508b", "title": "Introductory Lectures on Convex Optimization - A Basic Course"}, {"paperId": "562e7f497eff8363825abad8d0008a42ce00eb49", "title": "A Tutorial on Principal Component Analysis"}, {"paperId": "5fb8a9271af105a5065a5a855e71a7d25c7a6f1b", "title": "Variance Reduction for Stochastic Gradient Optimization"}, {"paperId": "7ae42cc4b475a2192707d0ada7b3c60c347b621e", "title": "Approximate Nearest Neighbor: Towards Removing the Curse of Dimensionality"}, {"paperId": "b77a727db76d7196d29815ea7ddd31e554cc033c", "title": "Simple and deterministic matrix sketching"}, {"paperId": "413c1142de9d91804d6d11c67ff3fed59c9fc279", "title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"}, {"paperId": "0a65097bcb2dd400a27a65d42608658dc9f6898d", "title": "On variants of the Johnson\u2013Lindenstrauss lemma"}, {"paperId": "d9211bc2f53b93bc2501aef8d8d929eac60451ad", "title": "Nonnegative matrix factorization and I-divergence alternating minimization\u2606"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "f55238913918c61b0dad87974699d05a5d71e709", "title": "An elementary proof of a theorem of Johnson and Lindenstrauss"}, {"paperId": "3c58166098c07f2efe30651446a0f4f19b9b7ce9", "title": "Random projection in dimensionality reduction: applications to image and text data"}, {"paperId": "549ca001fa8559f9e37ea55058f1faf4fc6f0376", "title": "Experiments with Random Projection"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": null, "title": "The DeepMind JAX Ecosystem"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "JAX: composable transformations of Python+NumPy programs"}, {"paperId": "cb0ab255c4079e2082ba6e3a807529527d96687c", "title": "Overview of the IWSLT 2017 Evaluation Campaign"}, {"paperId": null, "title": "Low-Rank Adapters Are Secretly algorithms"}, {"paperId": null, "title": "Neural networks for machine learning lecture 6a overview of mini-batch gradient descent"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "3ead228b4061d7053ebbeb0603555bd288a83656", "title": "ADAPTIVE ESTIMATION OF A QUADRATIC FUNCTIONAL BY MODEL SELECTION"}, {"paperId": null, "title": "Stack more layers differently: High-rank training through low-rank updates"}, {"paperId": null, "title": "Low-rank adaptation of large language models"}]}