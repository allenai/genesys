{"paperId": "319b84be7a843250bc81d7086f79a4126d550277", "abstract": "Pre-trained models have achieved state-of-the-art results in various Natural Language Processing (NLP) tasks. Recent works such as T5 and GPT-3 have shown that scaling up pre-trained language models can improve their generalization abilities. Particularly, the GPT-3 model with 175 billion parameters shows its strong task-agnostic zero-shot/few-shot learning capabilities. Despite their success, these large-scale models are trained on plain texts without introducing knowledge such as linguistic knowledge and world knowledge. In addition, most large-scale models are trained in an auto-regressive way. As a result, this kind of traditional fine-tuning approach demonstrates relatively weak performance when solving downstream language understanding tasks. In order to solve the above problems, we propose a unified framework named ERNIE 3.0 for pre-training large-scale knowledge enhanced models. It fuses auto-regressive network and auto-encoding network, so that the trained model can be easily tailored for both natural language understanding and generation tasks with zero-shot learning, few-shot learning or fine-tuning. We trained the model with 10 billion parameters on a 4TB corpus consisting of plain texts and a large-scale knowledge graph. Empirical results show that the model outperforms the state-of-the-art models on 54 Chinese NLP tasks, and its English version achieves the first place on the SuperGLUE benchmark (July 3, 2021), surpassing the human performance by +0.8% (90.6% vs. 89.8%).", "venue": "arXiv.org", "year": 2021, "citationCount": 305, "influentialCitationCount": 53, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A unified framework named ERNIE 3.0 is proposed for pre-training large-scale knowledge enhanced models that fuses auto-regressive network and auto-encoding network, so that the trained model can be easily tailored for both natural language understanding and generation tasks with zero-shot learning, few- shot learning or fine-tuning."}, "embedding": {"model": "specter_v2", "vector": [0.10050114244222641, 0.8980154395103455, 0.12527285516262054, 0.134665846824646, -0.09303969889879227, -0.5503982305526733, 0.6220198273658752, -0.25551727414131165, -0.3733682334423065, 0.21224647760391235, 0.5734782814979553, -0.26850008964538574, 0.39725562930107117, -0.42330142855644226, -0.35888516902923584, 0.43403106927871704, -0.6232998967170715, 0.4880685806274414, 0.0018882062286138535, -0.7092719674110413, -0.05753554403781891, -1.1829607486724854, -0.6483433842658997, -0.008962325751781464, 0.7592936158180237, 0.32745644450187683, 0.33519402146339417, 1.0304043292999268, -0.4475422203540802, 0.08206892013549805, 0.35955071449279785, -0.40647220611572266, -0.04899929091334343, -0.08041564375162125, -0.6240494251251221, 0.0595068633556366, -0.2925298810005188, -0.32937198877334595, -0.2778688073158264, 0.7321443557739258, -0.06328214704990387, 0.4271300733089447, 0.30539965629577637, -0.37897613644599915, -0.9083572626113892, 1.19206702709198, 0.7604650855064392, 0.3477199673652649, 0.005388261284679174, -0.36948439478874207, 0.9770801663398743, -1.0947890281677246, 0.47694340348243713, 1.4575183391571045, 0.5059165954589844, 0.7522982358932495, 0.08629472553730011, -0.42882710695266724, 0.5112099647521973, 0.13887891173362732, -0.8298619985580444, 0.20512166619300842, -0.46227020025253296, 0.08353102207183838, 2.16784405708313, -0.8720835447311401, 0.08123163133859634, 0.5371537804603577, -0.10467267036437988, 0.9700831770896912, -0.2406437247991562, -0.7337573766708374, -0.623856782913208, -0.13359621167182922, 0.39570364356040955, 1.0514572858810425, -0.44547274708747864, 0.26990243792533875, -0.5570392608642578, 0.18540601432323456, 0.37745198607444763, -0.04917631298303604, -0.2731233835220337, 0.2332025170326233, -0.24067890644073486, 0.6057064533233643, 0.3270649015903473, 0.6391275525093079, -0.18678894639015198, 0.4117055833339691, 0.5287075042724609, 0.6792718172073364, 0.1357874572277069, 0.5723518133163452, -0.45591896772384644, 0.36406683921813965, -0.46395137906074524, 0.3292814791202545, 0.1759965866804123, 1.0970669984817505, 0.09165152907371521, 0.2893713712692261, -0.7098543643951416, -0.013286684639751911, 1.0049717426300049, -0.11706659197807312, 0.49211686849594116, -0.7488122582435608, 0.06654960662126541, -0.19305895268917084, 0.1185748428106308, -0.4070073068141937, -0.24828022718429565, -0.020344339311122894, -0.8082476258277893, -1.3789478540420532, -0.5678530931472778, -0.37599706649780273, -1.0403037071228027, 1.0318104028701782, -0.3017044961452484, 0.3263136148452759, 0.5686657428741455, 0.3055654466152191, 0.9416812658309937, 0.9387209415435791, 0.03988044708967209, 0.06773120164871216, 0.9010578989982605, -0.9823803305625916, -0.829584002494812, -0.813927412033081, 0.8523948192596436, 0.1726435422897339, 0.18834854662418365, -0.3298134207725525, -1.1051949262619019, -0.8524222373962402, -0.7168056964874268, -0.06446919590234756, -1.031785488128662, 0.08655406534671783, 1.0550763607025146, 0.8734961748123169, -0.7009005546569824, 0.6920695900917053, 0.07069767266511917, -0.3165247440338135, 0.18912698328495026, 0.14330951869487762, 0.028677668422460556, -0.6615965962409973, -1.8395788669586182, 0.5586944818496704, 0.7999079823493958, -0.22259745001792908, -0.5431137681007385, -0.8292672038078308, -1.2671571969985962, 0.19778414070606232, 0.8712193965911865, -0.8514143228530884, 1.2803517580032349, 0.035887159407138824, -1.4101085662841797, 0.4446254074573517, -0.22991222143173218, 0.03708038479089737, 0.307533323764801, -0.4317970871925354, -0.5513493418693542, -0.6217814087867737, -0.10744738578796387, 0.4228439927101135, 0.07426528632640839, 0.21837124228477478, -0.1019541546702385, 0.362647145986557, 0.03956863656640053, -0.24884389340877533, -0.25063320994377136, 0.8633177876472473, -0.8346648216247559, 0.02101152203977108, 0.010701381601393223, 0.7782816886901855, -0.11456329375505447, -0.7608180046081543, -0.3805176019668579, -1.2075753211975098, 0.7958027720451355, -0.1899890899658203, 0.8832688927650452, -0.6364383697509766, -0.5315958261489868, -0.1906193345785141, -0.23149196803569794, 0.21418417990207672, -0.9218937158584595, 0.4564598798751831, -0.27213117480278015, 0.9486364722251892, -0.07319618761539459, -0.6807047128677368, 0.16413308680057526, -0.22861510515213013, -0.7187128067016602, -0.5802887082099915, 0.3086290955543518, 1.4661861658096313, -1.053027868270874, 0.4175284206867218, -0.0711149200797081, 0.37739869952201843, -0.9637913703918457, 1.035316824913025, -0.8261121511459351, 0.17887212336063385, -0.47601139545440674, -0.26032787561416626, 0.30874931812286377, -0.368324339389801, 0.2485193908214569, -0.251496285200119, -0.10580621659755707, 0.10131311416625977, -0.4759856164455414, 1.543531060218811, -0.36678192019462585, 0.579826831817627, -0.22711093723773956, -0.507713258266449, 0.30241480469703674, 0.7488266229629517, -0.6449797749519348, -0.288068026304245, 0.4270164668560028, 0.22809374332427979, -0.6892956495285034, 0.0040052286349236965, 0.6524677872657776, 0.7101455330848694, -0.5832914113998413, 0.6272492408752441, 0.7509588003158569, -0.4977976679801941, 0.7606127858161926, 0.6934701204299927, 0.5937649607658386, 0.4005454182624817, 0.5793054699897766, 0.16665127873420715, 0.5284262895584106, -0.6466913819313049, 0.05553976073861122, 0.7130688428878784, 0.9893800020217896, 0.7894480228424072, 0.5250073671340942, -0.6291583776473999, -0.42649516463279724, 0.33292272686958313, 1.1740785837173462, 1.5860573053359985, -0.06101100146770477, -0.1493271440267563, -1.0374096632003784, -0.32331401109695435, -0.7538352608680725, 0.45642271637916565, -0.4674506187438965, -0.13639840483665466, -0.3843119144439697, -1.0663093328475952, 0.7655107378959656, 0.38232195377349854, 1.4737352132797241, -0.6327912211418152, -0.05408964306116104, -0.13222141563892365, -0.024101629853248596, -0.9032215476036072, -0.650827944278717, -0.21259716153144836, -0.09950028359889984, -0.3852400481700897, -0.036268338561058044, -0.04772983491420746, 0.317636102437973, -0.7153358459472656, 1.110785961151123, -0.22199808061122894, -0.4596691429615021, 0.29373079538345337, 0.15713338553905487, -0.8052846193313599, -0.7498913407325745, 0.10428012162446976, 0.18220968544483185, -0.39201322197914124, 0.4975675642490387, 0.7614700198173523, 0.18213684856891632, 0.15113776922225952, -0.494276225566864, 0.11983876675367355, 0.015913594514131546, 0.11077844351530075, 0.5559270977973938, 0.11403696238994598, 0.4846939146518707, -1.4475626945495605, 0.9768736362457275, 0.28400468826293945, -0.6243517398834229, 0.7056971788406372, -0.30087924003601074, -0.34830188751220703, 0.6539486646652222, -0.5237398743629456, -0.9425238370895386, -1.109811782836914, 0.21759511530399323, -0.02356536127626896, -0.3147333562374115, 0.6403548717498779, 0.007243326399475336, 0.24724248051643372, 0.16739711165428162, 0.5439285039901733, 0.027837242931127548, -0.14997878670692444, 0.8783320784568787, -0.7932761907577515, 0.47391626238822937, 0.2403823435306549, 0.22685782611370087, -0.2763572037220001, -0.2136208862066269, -0.6485974192619324, -0.8312778472900391, -0.1849563717842102, -0.4198234975337982, -0.0589093454182148, 0.544628381729126, -0.6795472502708435, -0.9135726690292358, -0.0075925071723759174, -1.3882904052734375, -0.41794365644454956, 0.24710233509540558, -0.540826141834259, -0.23199467360973358, -0.8141421675682068, -0.7421693801879883, -0.24696962535381317, -0.8346513509750366, -0.6081340312957764, 0.21047046780586243, 0.3937545716762543, -0.15945781767368317, -0.8646472692489624, 0.2266891449689865, -0.27876976132392883, 0.8345210552215576, -0.4699990749359131, 0.7780827283859253, -0.19508330523967743, -0.38118624687194824, -0.24199113249778748, 0.03894582390785217, 0.6890936493873596, -0.3961125314235687, -0.06606216728687286, -0.5322350859642029, 0.3923196792602539, -0.5343048572540283, -0.7930896878242493, 0.5910674929618835, 0.3322877287864685, 0.49668872356414795, 0.48419883847236633, -0.24545514583587646, 0.3121689558029175, 1.5875318050384521, -0.9164648652076721, 0.4198574721813202, 0.12841454148292542, 0.8973271250724792, 0.1429474800825119, -0.301918089389801, 0.2092629373073578, 0.33935242891311646, -0.0394890159368515, -0.09004081040620804, 0.042006418108940125, 0.046703092753887177, -0.6520485281944275, 0.4235418736934662, 1.0043447017669678, -0.30522000789642334, -0.34321945905685425, -1.0821142196655273, 0.8748994469642639, -1.2249647378921509, -0.46852564811706543, 0.6191996932029724, 0.4779292643070221, 0.5858328938484192, -0.5978460907936096, -0.8304510712623596, -0.6158847212791443, 0.6366987824440002, -0.08180226385593414, -0.46344053745269775, -0.7935318946838379, -0.14463099837303162, 0.2885819375514984, 0.015474162995815277, 0.6811920404434204, -0.15686210989952087, 1.1597894430160522, 14.413570404052734, 0.9568778872489929, 0.4819624125957489, 0.6201984882354736, 0.6176087856292725, 0.4300248622894287, -0.36763134598731995, -0.12703996896743774, -1.3505610227584839, -0.7850039601325989, 0.8823907375335693, -0.3966568112373352, 0.4219462275505066, -0.048657264560461044, 0.1964312493801117, 0.2849583923816681, -0.5988723635673523, 0.32765522599220276, 0.45558229088783264, -1.392960786819458, 0.8308629989624023, 0.22959643602371216, 0.9501177668571472, 0.632283627986908, 0.6776303052902222, 1.4472875595092773, 0.6052379608154297, -0.5569086670875549, -0.037931155413389206, 0.6396503448486328, 0.8691107034683228, -0.208767369389534, 0.6689585447311401, 0.8697206974029541, -0.6461741924285889, -0.4258404076099396, -0.8651427030563354, -0.8627380132675171, 0.704818069934845, -0.07275781780481339, -0.19942447543144226, -0.09336598962545395, -0.4401801824569702, 0.5688557624816895, 0.31203627586364746, 0.1727731078863144, -0.8607574701309204, 0.44030943512916565, -0.14469359815120697, 0.16944171488285065, 0.4369906783103943, 0.4063923954963684, 0.2970464825630188, -0.22304585576057434, 0.41140735149383545, 0.7285441756248474, 0.0057077291421592236, 1.1209782361984253, -1.0318691730499268, -0.2642446756362915, -0.24919027090072632, -0.33455538749694824, -0.21001364290714264, 0.6666477918624878, 0.5145098567008972, -0.0008453340269625187, -0.5961065292358398, 0.20601055026054382, 0.2777671217918396, 0.3111022710800171, -0.14593473076820374, -0.3871062397956848, -0.1568376123905182, -0.5860186815261841, 0.1369457244873047, 0.7317661643028259, 0.08032301813364029, -0.7344222664833069, -0.9921836853027344, -0.6089221835136414, 0.1305854618549347, -0.942790687084198, -0.6521308422088623, 0.8793850541114807, -0.6212842464447021, 0.008020032197237015, -0.21737489104270935, -0.814947247505188, -0.5957435965538025, 0.6778889894485474, -1.5134971141815186, -1.0190192461013794, 0.3888953924179077, -0.1843634694814682, -0.23625348508358002, -0.2804788649082184, 1.4096612930297852, -0.25399866700172424, -0.5052713751792908, -0.31694409251213074, 0.013892069458961487, 0.10736965388059616, -0.34681233763694763, -0.7526673674583435, 0.7839098572731018, 0.28979557752609253, -0.4801727533340454, 0.11413949728012085, -0.0007928058039397001, -0.26222774386405945, -0.6300323009490967, -0.34047967195510864, 0.6719444394111633, -1.0222418308258057, -0.5813784599304199, -0.7919192314147949, -1.0838721990585327, 0.5061309337615967, 0.6958704590797424, -0.6598473191261292, 0.16015909612178802, 0.3507755696773529, -0.47336164116859436, 0.38919597864151, -0.9314870238304138, 0.09715826064348221, 0.2721098065376282, -0.5078771114349365, -0.6400678753852844, 0.06887511163949966, 0.7319878339767456, -0.8123186826705933, -0.8010226488113403, -0.16288310289382935, -0.1092214435338974, -0.03991226479411125, 0.9357993602752686, -0.20315375924110413, 0.554665744304657, 0.9554670453071594, 0.5623537302017212, -0.827712893486023, 0.17907550930976868, -1.1230268478393555, 0.13644154369831085, 0.14820577204227448, 0.9300612211227417, -0.31428614258766174, 0.08475161343812943, 1.0625553131103516, 0.3136686384677887, -0.3325791358947754, -0.3301432728767395, -0.46288976073265076, 0.23724503815174103, -0.3673025667667389, 0.38542789220809937, -0.0745745599269867, -0.008164877071976662, 0.14869998395442963, 0.32039928436279297, 0.9136901497840881, -0.2235809564590454, -0.6652073264122009, 0.4053821265697479, -0.12164187431335449, -0.1924360692501068, -0.32938024401664734, -0.13255801796913147, -1.5635566711425781, 0.11024264991283417, -0.9286143779754639, -0.06289784610271454, -1.2384778261184692, -0.14087001979351044, 0.6620084643363953, 0.1348997950553894, 0.07653438299894333, 0.005274527706205845, -0.36988571286201477, -0.5293068885803223, -1.1164196729660034, -0.827483594417572, 0.7621839046478271, 1.0049984455108643, -0.4140714108943939, -0.32824379205703735, -0.30953550338745117, -0.10735973715782166, 0.5544623136520386, 0.45666030049324036, -0.16214659810066223, -0.8532772660255432, -1.5833503007888794, 0.6465058326721191, -0.12077776342630386, -0.024292323738336563, -0.19275124371051788, 0.9251371622085571, 0.8668580055236816, -0.3508511781692505, -0.15799984335899353, 0.06422802060842514, -0.34266382455825806, -0.7781115174293518, 0.2784077227115631, -0.6489792466163635, -0.1959310621023178, 0.521522045135498, -0.3946610689163208, -0.4560161232948303, 0.5102908611297607, -0.4523548185825348, -1.3903393745422363, -1.0774383544921875, 0.37441134452819824, -0.7267094850540161, 0.24342899024486542, -0.2701265811920166, -0.18280334770679474, -1.205507516860962, -0.6082765460014343, -0.3932494521141052, 0.7004013657569885, -0.872419536113739, 0.6354100704193115, 0.675071120262146, -0.7214357256889343, -0.5336260795593262, 0.3509964942932129, -0.055771660059690475, 0.19545574486255646, 0.7989973425865173, 0.21370352804660797, -0.06269864737987518, 0.7846941351890564, 0.5276007056236267, 0.8029967546463013, -0.7431861758232117, 0.1268170326948166, 1.050356149673462, -0.6966253519058228, -0.3590323030948639, 0.966721773147583, -0.22028398513793945, -1.4958760738372803, -0.0899185836315155, -0.9812647104263306, -0.744214653968811, -0.5141482353210449, 0.9261877536773682, 0.14680276811122894, -0.6102467775344849, -0.0010799699230119586, 0.07622609287500381, 0.4210224151611328, -0.1004294902086258, -0.2898222804069519, 0.9126264452934265, -0.462695449590683, -0.6171817183494568, 0.2002560794353485, 0.43950164318084717, -0.9896666407585144, -0.4398747682571411, -0.8620975017547607, -0.23598366975784302, 0.20881494879722595, 0.4674285650253296, -0.6747563481330872, -0.3072464168071747, 0.8654212951660156, 0.22603240609169006, 0.32500559091567993, 0.46318838000297546, -0.06985249370336533, 0.26629307866096497, 1.2931663990020752, -0.018765345215797424, -0.8312007784843445, -0.3599085807800293, 1.6089078187942505, 1.4609670639038086, -1.1760996580123901, 0.20159992575645447, -0.6550095677375793, -0.770574688911438, 1.1330927610397339, 0.3062937557697296, 0.16930805146694183, 0.8522518277168274, -0.49250736832618713, -0.2217363864183426, 0.14251887798309326, -1.2987109422683716, -0.660186231136322, 0.8056509494781494, 1.1793208122253418, 0.5793918371200562, -0.14772912859916687, 0.3682295083999634, 1.3664085865020752, 0.15827102959156036, 0.34414997696876526, 0.7785430550575256, -0.2098773568868637, -0.3891332447528839, -0.05503888800740242, 0.22651307284832, 0.11229122430086136, -0.6222306489944458, -0.7256353497505188, -0.09946025907993317, 0.6067585945129395, 0.41499063372612, 0.9158872365951538, 0.6663216948509216, 0.4524058699607849, 0.6305178999900818, 0.20192581415176392, 0.4190274477005005, -0.7079946994781494, -0.4539355933666229, -0.13396775722503662, -0.5143663287162781, -0.17118501663208008, -0.26716557145118713, -0.07734695822000504, -0.5599077343940735, -0.36055299639701843, 0.007981275208294392, 0.07813812047243118, 0.2622024416923523, 1.4080569744110107, 0.5516282916069031, 0.6029423475265503, -0.7292978763580322, -0.10945659875869751, -0.18869709968566895, -1.1007131338119507, 0.0717448964715004, -0.5654587149620056, -0.4263295531272888, 0.04900996387004852, -0.03312955051660538, -0.24560466408729553]}, "authors": [{"authorId": "2117103617", "name": "Yu Sun"}, {"authorId": "104463827", "name": "Shuohuan Wang"}, {"authorId": "1718657", "name": "Shikun Feng"}, {"authorId": "2093193326", "name": "Siyu Ding"}, {"authorId": "2054086618", "name": "Chao Pang"}, {"authorId": "40861754", "name": "Junyuan Shang"}, {"authorId": "2144130913", "name": "Jiaxiang Liu"}, {"authorId": "2109214103", "name": "Xuyi Chen"}, {"authorId": "2117889541", "name": "Yanbin Zhao"}, {"authorId": "2140025135", "name": "Yuxiang Lu"}, {"authorId": "2109563578", "name": "Weixin Liu"}, {"authorId": "47039787", "name": "Zhihua Wu"}, {"authorId": "2117587198", "name": "Weibao Gong"}, {"authorId": "2118676105", "name": "Jianzhong Liang"}, {"authorId": "2117586669", "name": "Zhizhou Shang"}, {"authorId": "2075416111", "name": "Peng Sun"}, {"authorId": null, "name": "Wei Liu"}, {"authorId": "2227615315", "name": "Ouyang Xuan"}, {"authorId": "3046102", "name": "Dianhai Yu"}, {"authorId": "50007795", "name": "Hao Tian"}, {"authorId": "40354707", "name": "Hua Wu"}, {"authorId": "144270731", "name": "Haifeng Wang"}], "references": [{"paperId": "00a95c2e2af1c6ef7ba41fe502a8cc729cdd284d", "title": "CPM-2: Large-scale Cost-effective Pre-trained Language Models"}, {"paperId": "04b40daa1ca74bdbb578beb314bf662538ecd18e", "title": "ZEN 2.0: Continue Training and Adaption for N-gram Enhanced Text Encoders"}, {"paperId": "78bd4518950e3f0bcd6aa9f7f8e09cbbf13eb11f", "title": "PanGu-\u03b1: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation"}, {"paperId": "1e5b05838e16244310db554b04ff6541f05acb0b", "title": "Blow the Dog Whistle: A Chinese Dataset for Cant Understanding with Common Sense and World Knowledge"}, {"paperId": "8f8f73f0f208302546c825ed474432389ed63be4", "title": "EfficientNetV2: Smaller Models and Faster Training"}, {"paperId": "fb5d827bb514fa285723557cc39a8200d31d4d1a", "title": "Robo-writers: the rise and risks of language-generating AI"}, {"paperId": "a11676f2864b2d923bb9facc9f6548c812f9e005", "title": "M6: A Chinese Multimodal Pretrainer"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "afad10da0a3b83a4f2a94e8c16c84ac64338e9fe", "title": "ERNIE-Doc: A Retrospective Long-Document Modeling Transformer"}, {"paperId": "cc50f846ed7222698d130cddbc58ed4d547914ed", "title": "CPM: A Large-scale Generative Chinese Pre-trained Language Model"}, {"paperId": "70e11c102a6231049307449a7181127889946606", "title": "Chinese Medical Question Answer Matching Based on Interactive Sentence Representation Learning"}, {"paperId": "abaadb4c6affc4d874c4f59bfac60686e851cb5e", "title": "Pre-training Text-to-Text Transformers for Concept-centric Common Sense"}, {"paperId": "e50aabe91493365034f8c997bb1d1db689526a89", "title": "ERNIE-Gram: Pre-Training with Explicitly N-Gram Masked Language Modeling for Natural Language Understanding"}, {"paperId": "7eda139d737eea10fc1d95364327a41ec0cee4a4", "title": "CoLAKE: Contextualized Language and Knowledge Embedding"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "d7d5bb7c5424a725d3c2b7d352aa299f0f90a5e5", "title": "SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis"}, {"paperId": "1cc0b98b938b984e5da85f86c1a24099b9b4b582", "title": "SegaBERT: Pre-training of Segment-aware BERT for Language Understanding"}, {"paperId": "414f232eda907f7fe7eb5b56f0efcde6c78b0d0b", "title": "DuReaderrobust: A Chinese Dataset Towards Evaluating the Robustness of Machine Reading Comprehension Models"}, {"paperId": "18318b10e7c2dd4ad292208f4399eb1d4dca5768", "title": "CLUE: A Chinese Language Understanding Evaluation Benchmark"}, {"paperId": "2081ac22151c1075fcc6533f0935c29d486bfa6f", "title": "A Sentence Cloze Dataset for Chinese Machine Reading Comprehension"}, {"paperId": "d16ab5c19ed33a263b6412ac41a4ea1f068d254a", "title": "Revisiting Pre-Trained Models for Chinese Natural Language Processing"}, {"paperId": "4980093337f6b4a3a960ba95a54689ee491bc8ca", "title": "KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation"}, {"paperId": "725d5acdbdf0a11677f785a16e1722b92c55a47f", "title": "MATINF: A Jointly Labeled Large-Scale Dataset for Classification, Question Answering and Summarization"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "4f03e69963b9649950ba29ae864a0de8c14f1f86", "title": "K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters"}, {"paperId": "6191a5122d67dfbab421bc89540d264822dd8173", "title": "ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "c7fc1cac162c0e2a934704184c7554fd6b6253f0", "title": "Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model"}, {"paperId": "f1957038e9ded19108d3c71340d7462152b70f25", "title": "Integrating Graph Contextualized Knowledge into Pre-trained Language Models"}, {"paperId": "56cafbac34f2bb3f6a9828cd228ff281b810d6bb", "title": "KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "bfeb827d06c1a3583b5cc6d25241203a81f6af09", "title": "Knowledge Enhanced Contextual Word Representations"}, {"paperId": "04a7021fe6be6bddcfae476493fcc7571e7c613c", "title": "PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification"}, {"paperId": "9ec95c1130a6ac4238ac2e5c7b2b66047511ea92", "title": "Long and Diverse Text Generation with Planning-based Hierarchical Variational Model"}, {"paperId": "80f9f109d1564cb8f82aa440a5f6f3fbe220c9ef", "title": "ERNIE 2.0: A Continual Pre-training Framework for Language Understanding"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "39e801ca0dbc69c3697f118e24dac964abb63d4a", "title": "The CommitmentBank: Investigating projection in naturally occurring discourse"}, {"paperId": "81f5810fbbab9b7203b9556f4ce3c741875407bc", "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans"}, {"paperId": "7334f45c06555d4b6bf7e6b4437574c11369697e", "title": "Chinese Relation Extraction with Multi-Grained Information and External Linguistic Knowledge"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "2ff41a463a374b138bb5a012e5a32bc4beefec20", "title": "Pre-Training with Whole Word Masking for Chinese BERT"}, {"paperId": "e278e072774f23675266881750e20bca74804cb9", "title": "ChID: A Large-scale Chinese IDiom Dataset for Cloze Test"}, {"paperId": "5f994dc8cae24ca9d1ed629e517fcc652660ddde", "title": "ERNIE: Enhanced Language Representation with Informative Entities"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "1b07a24b81834116f6ad1d0232485ba81b9445f3", "title": "Investigating Prior Knowledge for Challenging Chinese Machine Reading Comprehension"}, {"paperId": "031e4e43aaffd7a479738dcea69a2d5be7957aa3", "title": "ERNIE: Enhanced Representation through Knowledge Integration"}, {"paperId": "b401aca53c04cec865e1a733090a2c60ca7ebe97", "title": "Glyce: Glyph-vectors for Chinese Character Representations"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "889ad3c713bd7f1b3a8e9b07e136ec4a88651893", "title": "Multi-Scale Attentive Interaction Networks for Chinese Medical Question Answer Selection"}, {"paperId": "be2e66b8b28bfad2cbfa3087176b79ec5ab1ec04", "title": "Character-based BiLSTM-CRF Incorporating POS and Dictionaries for Chinese Opinion Target Extraction"}, {"paperId": "a5b66ee341cb990f7f70a124b5fab3316d3b7e27", "title": "ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension"}, {"paperId": "1c3112ef8a346b9817382ed34a8c146c53d5bcf5", "title": "XNLI: Evaluating Cross-lingual Sentence Representations"}, {"paperId": "a925f818f787e142c5f6bcb7bbd7ede2deb34860", "title": "WiC: the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations"}, {"paperId": "549c1a581b61f9ea47afc6f6871845392eaebbc4", "title": "LCQMC:A Large-scale Chinese Question Matching Corpus"}, {"paperId": "2e29be79de2bb255784b65f4ecd59824b8cc21fe", "title": "CAIL2018: A Large-Scale Legal Dataset for Judgment Prediction"}, {"paperId": "d7b6753a2d4a2b286c396854063bde3a91b75535", "title": "A Simple Method for Commonsense Reasoning"}, {"paperId": "c997d481606f0346164511cabe74c6d1ef3f6be5", "title": "DRCD: a Chinese Machine Reading Comprehension Dataset"}, {"paperId": "99ad0533f84c110da2d0713d5798e6e14080b159", "title": "Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences"}, {"paperId": "b4bfadfca9742bb3ee98a0cd322d5ce4e59a3ceb", "title": "A Call for Clarity in Reporting BLEU Scores"}, {"paperId": "c0fdddc750f58373ad6b1e30660812ef9903b7fe", "title": "Matching Article Pairs with Graphical Decomposition and Convolutions"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "9589244bbff8c5b5e57f52f99776cda332e6ba48", "title": "A Discourse-Level Named Entity Recognition and Relation Extraction Dataset for Chinese Literature Text"}, {"paperId": "995b7affd684b910d5a1c520c3af00fd20cc39b0", "title": "DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "678fd7c48efe21434148b4b3482c2b8b3ee618fc", "title": "Deep Neural Solver for Math Word Problems"}, {"paperId": "96bc7e517759afa2972278ef206796154a295c98", "title": "Chinese Medical Question Answer Matching Using End-to-End Character-Level Multi-Scale CNNs"}, {"paperId": "ea738439b880ad033ff01602ea52d04b366d0d37", "title": "End-to-End Neural Ad-hoc Ranking with Kernel Pooling"}, {"paperId": "bdf28e3cadbabda3261bd904c37edea66ab84766", "title": "Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "d64561879a2fbd3d39a5e876a667ffa4561eed80", "title": "Named Entity Recognition for Chinese Social Media with Jointly Trained Embeddings"}, {"paperId": "f04df4e20a18358ea2f689b4c129781628ef7fc1", "title": "A large annotated corpus for learning natural language inference"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "b122a828f5fee3c6afc54e70f41b00184d6383fc", "title": "LCSTS: A Large Scale Chinese Short Text Summarization Dataset"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "5cfbbf3cdff0f905874589bcd21b2646340a5447", "title": "Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning"}, {"paperId": "128cb6b891aee1b5df099acb48e2efecfcff689f", "title": "The Winograd Schema Challenge"}, {"paperId": "d84b57362e2010f6f65357267df7e0157af30684", "title": "Distant supervision for relation extraction without labeled data"}, {"paperId": "10f97f1fb4f5c2c8e6c44d4a33da46d331dd4aeb", "title": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition"}, {"paperId": "f6d8a7fc2e2d53923832f9404376512068ca2a57", "title": "Hierarchical Mixtures of Experts and the EM Algorithm"}, {"paperId": "c8d90974c3f3b40fa05e322df2905fc16204aa56", "title": "Adaptive Mixtures of Local Experts"}, {"paperId": "e8f297e161f57e461ede2d4e0c26573981cad077", "title": "Findings of the 2020 Conference on Machine Translation (WMT20)"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "4ae2960d3c6ac489b3b072666fb0b91d0480a170", "title": "A Span-Extraction Dataset for Chinese Machine Reading Comprehension"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Iflytek: a multiple categories chinese text classifier. competition official website"}, {"paperId": null, "title": "openweb-text corpus"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "7afb83134d5b7914131e10b229d30dc2593266f6", "title": "The BQ Corpus: A Large-scale Domain-specific Chinese Corpus For Sentence Semantic Equivalence Identification"}, {"paperId": null, "title": "cc-news. http://web.archive.org/save/http://commoncrawl.org/2016/10/ news-dataset-available"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": null, "title": "Ontonotes release 4.0. LDC2011T03, Philadelphia, Penn"}, {"paperId": "e03d300581e16f6664157d2c1c6ceec33ec528ce", "title": "Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment"}, {"paperId": "e808f28d411a958c5db81ceb111beb2638698f47", "title": "The PASCAL Recognising Textual Entailment Challenge"}, {"paperId": null, "title": "Hyperclova from naver"}]}