{"paperId": "db3d7316f72d6cc283c556e12db31a2d47727d7f", "abstract": "More and more evidence has shown that strengthening layer interactions can enhance the representation power of a deep neural network, while self-attention excels at learning interdependencies by retrieving query-activated information. Motivated by this, we devise a cross-layer attention mechanism, called multi-head recurrent layer attention (MRLA), that sends a query representation of the current layer to all previous layers to retrieve query-related information from different levels of receptive fields. A light-weighted version of MRLA is also proposed to reduce the quadratic computation cost. The proposed layer attention mechanism can enrich the representation power of many state-of-the-art vision networks, including CNNs and vision transformers. Its effectiveness has been extensively evaluated in image classification, object detection and instance segmentation tasks, where improvements can be consistently observed. For example, our MRLA can improve 1.6% Top-1 accuracy on ResNet-50, while only introducing 0.16M parameters and 0.07B FLOPs. Surprisingly, it can boost the performances by a large margin of 3-4% box AP and mask AP in dense prediction tasks. Our code is available at https://github.com/joyfang1106/MRLA.", "venue": "International Conference on Learning Representations", "year": 2023, "citationCount": 2, "influentialCitationCount": 1, "openAccessPdf": {"url": "http://arxiv.org/pdf/2302.03985", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "A cross-layer attention mechanism, called multi-head recurrent layer attention (MRLA), that sends a query representation of the current layer to all previous layers to retrieve query-related information from different levels of receptive fields to enrich the representation power of many state-of-the-art vision networks."}, "embedding": {"model": "specter_v2", "vector": [0.03210980445146561, 0.33875489234924316, -0.5165310502052307, -0.1902901977300644, -0.37041333317756653, 0.49630844593048096, 0.53438401222229, -0.21157358586788177, -0.5495719313621521, -0.27953341603279114, 0.4645863175392151, 0.9121968746185303, 0.4864695966243744, 0.168091282248497, 0.0234123133122921, 0.3709890842437744, -1.0824822187423706, 0.05148167535662651, 1.0112814903259277, -0.2527700364589691, 0.315016508102417, -0.4967171549797058, -1.4830913543701172, 0.6208062171936035, -0.18739642202854156, 1.1340984106063843, 0.36260974407196045, 0.9091097116470337, -0.26108625531196594, 0.5353822112083435, 0.37137317657470703, -0.5149222016334534, 0.30083736777305603, -0.04922288656234741, -0.629008412361145, 0.01770683564245701, 0.5029007196426392, -0.21272990107536316, -0.21091076731681824, 0.6254796981811523, 0.0049523720517754555, 0.23843254148960114, 0.24629583954811096, -0.3511447012424469, -0.17902109026908875, 0.5183282494544983, 0.20873279869556427, 0.8100989460945129, -0.41830116510391235, -0.9022520184516907, 1.478576421737671, -1.3443857431411743, 0.12986713647842407, 1.5183323621749878, 0.27207648754119873, 0.4227137863636017, -0.11616365611553192, -0.7319514751434326, 1.0066214799880981, 0.10452160984277725, -0.7376232147216797, -0.1188393384218216, 0.42573079466819763, -0.2644815742969513, 1.7848703861236572, -0.5304601788520813, -0.03892093524336815, 0.37384235858917236, 0.044448453933000565, 1.8534963130950928, -0.41935497522354126, -0.5279536247253418, -0.3988516926765442, 0.015527148731052876, 0.4862177073955536, 0.8750857710838318, -0.16249336302280426, 0.25261035561561584, -0.8345789313316345, 0.17170581221580505, 0.7220003604888916, 0.27656155824661255, 0.1768067628145218, -0.4245947301387787, -0.09912215173244476, 0.5631914734840393, 1.1351133584976196, 0.6232109069824219, -0.6828352212905884, 0.7185373306274414, 0.45949453115463257, 0.03869849070906639, -0.12322865426540375, 0.5016365647315979, 0.08855419605970383, 1.1808744668960571, -0.764775276184082, -0.18184661865234375, -0.26256275177001953, 1.0291545391082764, 0.2209637463092804, -0.2359657734632492, -0.38320255279541016, 0.3761390745639801, 1.508472204208374, -0.6036266684532166, 0.3866642117500305, -0.6721868515014648, 0.24348731338977814, -0.3378017246723175, -0.3934502601623535, -0.7796161770820618, -0.14738650619983673, -0.5593129992485046, -0.609082818031311, -0.9849333167076111, -0.783245325088501, 0.583962619304657, -0.7233254909515381, 0.18001911044120789, -0.44785216450691223, 0.019148288294672966, -0.1870490163564682, 0.5492998957633972, 0.4796201288700104, 0.294109046459198, 0.760169506072998, 0.4123830199241638, 1.1982219219207764, -1.4327126741409302, -0.0740709975361824, -1.029923915863037, 0.15641705691814423, -0.33706676959991455, -0.10181351006031036, -0.22208867967128754, -1.2588967084884644, -1.348019003868103, -0.8791205286979675, 0.018761558458209038, -0.7545323967933655, -0.05769404023885727, 1.0358768701553345, -0.2692027688026428, -1.0977956056594849, 0.8928593993186951, -0.10235469788312912, -0.49053776264190674, 0.6962749361991882, 0.1678023785352707, 0.1416780948638916, -0.15343421697616577, -1.0190467834472656, 0.031174153089523315, 0.32479456067085266, -0.18910713493824005, -0.2148304134607315, -0.4892995059490204, -0.8217815160751343, -0.23576241731643677, 0.4202952980995178, -0.9039175510406494, 1.2476441860198975, -0.5583744645118713, -0.9613123536109924, 0.9359318017959595, -0.12106840312480927, -0.05295359343290329, 0.18289905786514282, -0.3306431770324707, -0.34726107120513916, -0.15912532806396484, 0.007246355060487986, 0.7830466628074646, 0.662330687046051, -0.44022566080093384, -0.5381569266319275, -0.2953721284866333, -0.16028782725334167, -0.1213807687163353, -0.07992424815893173, 0.932502269744873, -1.102830171585083, -0.10817243158817291, 0.620424211025238, 1.0315027236938477, 0.1040257066488266, -0.09148354828357697, -0.24520987272262573, -1.2581095695495605, 0.9426953196525574, 0.5101105570793152, 0.6066501140594482, -0.7999869585037231, -0.9098222255706787, -0.4033738970756531, -0.029771480709314346, -0.05808469280600548, -0.9817487597465515, 0.3114526569843292, -0.3152347505092621, 0.36234068870544434, -0.10247548669576645, -1.1333767175674438, -0.3782472610473633, -0.2813274562358856, -0.4578188955783844, -0.26263946294784546, 0.7819552421569824, 1.2005821466445923, -1.0316476821899414, -0.3437509536743164, -0.422748863697052, 0.2582508325576782, -0.865498960018158, 1.1623917818069458, -0.5079972147941589, -0.25192371010780334, -0.6102139949798584, 0.03750928118824959, -0.03882157802581787, -0.3663221299648285, -0.07416944950819016, -0.7998979091644287, -0.25805726647377014, 0.5431535243988037, 0.015475325286388397, 1.3778399229049683, -0.04684927314519882, 0.7581493854522705, 0.03404432535171509, -0.5364852547645569, 0.353737473487854, 0.10862811654806137, -0.21927432715892792, -0.8847573399543762, 0.5959584712982178, -0.028626879677176476, -0.9061455726623535, 0.1434544175863266, 0.8609773516654968, 1.1513164043426514, -0.2567225992679596, -0.06353574991226196, 0.7996878027915955, -0.020312417298555374, 0.10223134607076645, 0.4124087393283844, 0.3582209348678589, 0.42996764183044434, 0.39533621072769165, -0.12803173065185547, 0.16829626262187958, -0.9708473682403564, -0.033566057682037354, 0.6004769206047058, 0.27277109026908875, 1.0611989498138428, 0.38582780957221985, -0.8121113181114197, -0.3406434953212738, 0.330687016248703, 0.6079145669937134, 1.6180754899978638, 0.04469221830368042, 0.2874380052089691, -0.5147977471351624, -0.5770319104194641, -0.1793702095746994, -0.39310580492019653, -0.9639289975166321, -0.16748784482479095, -0.23122604191303253, -0.7900237441062927, 0.6077681183815002, 0.43571749329566956, 1.7094650268554688, -0.9835557341575623, -0.4033661186695099, -0.17261932790279388, 0.5139204859733582, -0.6778284311294556, -0.4091286361217499, 0.3487144112586975, -0.4494403898715973, -0.34037554264068604, -0.13692033290863037, -0.09918175637722015, 0.12159691751003265, -0.3480258584022522, 1.3208162784576416, -0.049467213451862335, -0.3942449986934662, 0.34606045484542847, 0.5563609600067139, -0.6658356189727783, 0.01985197141766548, 0.41216006875038147, -0.2694516181945801, 0.23524975776672363, 0.5042619705200195, 0.794813334941864, -0.45742473006248474, 0.5340296030044556, -0.5126647353172302, 0.05998625606298447, 0.18098042905330658, -0.24026450514793396, 0.9856967926025391, -0.4906989634037018, 0.38043344020843506, -1.392386555671692, 0.6258465647697449, -0.13281729817390442, -0.5232608914375305, 0.2581363320350647, -0.4236133396625519, -0.5489771962165833, -0.1499214917421341, -0.3313385844230652, -0.35933825373649597, -0.7653521299362183, 0.7190067172050476, -0.8586127758026123, -0.34673693776130676, -0.04436676949262619, 0.4417605400085449, 0.25110742449760437, 0.42467954754829407, -0.12994182109832764, 0.2576083242893219, -0.22116409242153168, 0.12385167181491852, -1.0326344966888428, 0.6762237548828125, 0.30776289105415344, -0.38312768936157227, 0.04182513430714607, -0.25709256529808044, -0.5089155435562134, -0.8755592703819275, -1.0476267337799072, -0.38833481073379517, -0.38187336921691895, 0.8144609332084656, -0.5684054493904114, -0.6223946213722229, 0.08805512636899948, -0.8963180184364319, -0.3372752070426941, 0.2553817331790924, -0.04002237692475319, -0.15932312607765198, -1.4735084772109985, -0.970374345779419, -0.6841522455215454, -0.5369360446929932, -0.8329286575317383, 0.21036213636398315, 0.4830626845359802, -0.01184679102152586, -0.4255077838897705, -0.30541467666625977, -0.41749733686447144, 1.1339563131332397, -0.387163370847702, 0.019941799342632294, -0.2201499491930008, -0.7523428201675415, -0.44997864961624146, -0.6032294034957886, 0.45942917466163635, -0.021789181977510452, 0.06479646265506744, -1.1619919538497925, 0.39821794629096985, -0.251801073551178, -0.25680720806121826, 0.8955022692680359, 0.3667652904987335, 0.9270305633544922, 0.5607320666313171, -0.8666834831237793, 0.1396612524986267, 1.5729767084121704, -0.9109680652618408, 0.18412739038467407, 0.1912187784910202, 0.7223820090293884, 0.3875349462032318, -0.275823712348938, 0.35329025983810425, 0.42498767375946045, 0.1563989520072937, 0.62386155128479, -0.7002347707748413, -0.5027978420257568, -0.38508185744285583, -0.05462070554494858, 1.0376896858215332, 0.14127129316329956, 0.3120461106300354, -0.8754680752754211, 0.9820471405982971, -1.1865744590759277, -0.5987926125526428, 0.7733952403068542, 0.529381513595581, -0.11483488976955414, -0.2845105528831482, 0.029538609087467194, -0.8244510889053345, 0.860853374004364, 0.44885730743408203, -0.58469557762146, -0.43195271492004395, 0.22168517112731934, 0.03060089983046055, 0.36348801851272583, 0.5273403525352478, -0.5109833478927612, 0.69135582447052, 14.54200553894043, 0.08562266826629639, -0.062208499759435654, 0.3009799122810364, 0.8262333869934082, 0.34365180134773254, -0.029051274061203003, -0.2354394942522049, -1.416561245918274, -0.465911865234375, 0.6672544479370117, 0.5483752489089966, 0.3196223974227905, 0.2047114372253418, -0.28623685240745544, 0.07753878086805344, -0.7850824594497681, 0.6995111107826233, 0.8021661639213562, -1.1922640800476074, 0.2302805632352829, 0.11306154727935791, 0.22479607164859772, 1.0961426496505737, 0.698110044002533, 0.9520320892333984, 0.4737856090068817, 0.12038303166627884, 0.15867626667022705, 0.6784549951553345, 0.5072489380836487, 0.32327699661254883, 0.3295954763889313, -0.062214646488428116, -1.0596643686294556, -0.25986236333847046, -0.78505539894104, -0.7563408613204956, 0.018253248184919357, -0.12278668582439423, -0.35526975989341736, -0.20430822670459747, 0.2949329614639282, 0.915569543838501, -0.29332953691482544, 0.719602108001709, -0.12760595977306366, 0.09802515059709549, 0.14630073308944702, -0.002822044538334012, 0.4417884945869446, 0.8685394525527954, 0.12780775129795074, 0.2710949778556824, -0.4595266878604889, 0.3781932294368744, 0.19258220493793488, 0.4462679326534271, -0.9049832820892334, -0.31334802508354187, -0.2732066512107849, 0.25603699684143066, -0.3876303732395172, 0.7770556807518005, 0.5275023579597473, 0.02803068421781063, -0.3398398756980896, 0.35679110884666443, 0.48995348811149597, 0.41395246982574463, -0.4381892681121826, -0.06338340044021606, 0.4456990361213684, -0.24762216210365295, 0.4392203092575073, 0.733670711517334, -0.10640502721071243, -0.17904521524906158, -0.8331688046455383, 0.3859832286834717, 0.9605962634086609, -1.0917943716049194, -1.0258485078811646, 1.281253457069397, -0.22980602085590363, -0.228149875998497, 0.27459245920181274, -0.6583693027496338, -0.3647867441177368, 0.40065860748291016, -2.064037799835205, -0.2970895767211914, -0.12188086658716202, -0.1464649885892868, -0.04676159843802452, -0.13690505921840668, 0.7227941751480103, 0.43817996978759766, -0.6165397763252258, 0.02045760490000248, -0.9074040055274963, 0.2539294362068176, -0.25994715094566345, -0.5217229723930359, 0.4525042474269867, 0.023779187351465225, -0.2683177888393402, 0.12179573625326157, -0.597042977809906, 0.33921703696250916, -0.26435601711273193, -0.4222722351551056, 0.33311110734939575, -0.4361293911933899, -0.568568766117096, -0.21830874681472778, -1.0529186725616455, 0.362144410610199, 0.8385041952133179, 0.3616727888584137, 0.21611523628234863, 0.3283148407936096, -0.8391429781913757, -0.40975087881088257, -0.7454405426979065, -0.06776177138090134, 0.32965096831321716, -0.7528003454208374, -0.27715790271759033, -0.35339412093162537, 0.5262616872787476, -0.5408986210823059, -0.3351381719112396, -0.21933962404727936, 0.07186465710401535, -0.44536420702934265, 1.1780816316604614, -0.6811444759368896, 0.5926374793052673, 0.5434766411781311, -0.2198784500360489, -0.3024257719516754, -0.46921855211257935, -0.5188130736351013, 0.3518708348274231, 0.40395838022232056, 0.7704089283943176, -0.5211887955665588, 0.290930837392807, 1.030411720275879, 0.24217067658901215, -0.6882621049880981, -0.21318361163139343, 0.07705794274806976, -0.1972178816795349, -0.5894683003425598, 0.498719185590744, 0.14651978015899658, -0.5277751684188843, -0.04842596501111984, 0.9217349290847778, 0.7738778591156006, 0.029654279351234436, -0.5959059596061707, 0.18899980187416077, -0.4862443506717682, 0.11417749524116516, -0.8307561874389648, -0.7685282826423645, -1.330313801765442, -0.21402397751808167, -1.1477304697036743, -0.06592055410146713, -1.2643405199050903, -0.36653557419776917, 0.10509886592626572, -1.0646132230758667, 0.1897149682044983, 0.38217830657958984, -0.1180148720741272, -0.08967519551515579, -0.08205945044755936, -1.2655855417251587, 0.5994947552680969, 1.0971550941467285, -0.515496015548706, 0.10996949672698975, 0.013599015772342682, -0.23261958360671997, 0.36403414607048035, 0.46591809391975403, -0.3545042872428894, -0.343934565782547, -1.403489589691162, 0.4073190987110138, -0.1581788808107376, 0.1166820153594017, -1.0953028202056885, 1.0992884635925293, 0.7343233823776245, 0.23533421754837036, -0.4431687593460083, 0.2715522348880768, -1.0159564018249512, -0.8706953525543213, -3.154072328470647e-05, -0.853820264339447, 0.15319040417671204, 0.28794053196907043, -0.3456830680370331, -0.5029846429824829, 0.8207284808158875, 0.23339450359344482, -1.2941347360610962, -1.2726869583129883, 0.7336720824241638, -0.2235075980424881, 0.023416470736265182, -0.13381776213645935, -0.04538096860051155, -1.2210384607315063, 0.010982917621731758, -0.02124054543673992, 0.7621749043464661, -0.6962592601776123, 1.0599980354309082, 0.5462849736213684, -1.1441400051116943, -0.07766512781381607, 0.5029944181442261, 0.0851929560303688, 0.3726995587348938, 0.4889013171195984, 0.5436344146728516, -0.12228497862815857, 0.2546650469303131, 0.1465614140033722, -0.03672782704234123, -0.3152201175689697, 0.3118143081665039, 1.3410431146621704, -0.5075135827064514, 0.0752607136964798, 1.3077514171600342, 0.11191843450069427, -0.6401505470275879, 0.27296149730682373, -0.9333449602127075, -0.6856468915939331, 0.10619157552719116, 0.6325511336326599, 0.058291468769311905, 0.1740165799856186, -0.054050639271736145, -0.6176044940948486, 0.1561390459537506, -0.5740277767181396, -0.15364745259284973, 0.540194571018219, 0.0389910563826561, -0.3114456832408905, 0.5720310807228088, 1.1811928749084473, -1.0728826522827148, -1.0774307250976562, -1.1333531141281128, -0.20172718167304993, -0.016227906569838524, 0.3704977035522461, -0.25180861353874207, -1.1211000680923462, 0.5342310667037964, 0.5237197875976562, 0.7228911519050598, 0.3647342026233673, 0.332148939371109, -0.14371643960475922, 0.46332648396492004, -0.2807658016681671, -0.562795877456665, -0.09341932833194733, 0.9627931714057922, 1.5247184038162231, -0.9234283566474915, 0.2528923451900482, -0.15886925160884857, -0.6142192482948303, 0.5570605397224426, 0.48615899682044983, -0.6574246287345886, 1.132202386856079, -0.6071993708610535, 0.06692352890968323, -0.14987777173519135, -1.1612967252731323, -0.7662246227264404, 0.8878467679023743, 0.9964277148246765, 0.5816817283630371, 0.010802729986608028, 0.49837836623191833, 0.5653573870658875, 0.5385251641273499, -0.05246211960911751, 0.18788285553455353, 0.09899353235960007, -0.06522879749536514, 0.24637043476104736, 0.1091151013970375, 0.5222809314727783, -0.6735636591911316, -0.2340908944606781, 0.03359853848814964, 0.9154791235923767, 0.07413627952337265, 0.5209674835205078, 1.239844560623169, 0.13654327392578125, 0.8812714219093323, -0.023640234023332596, 0.06878813356161118, -0.6460102200508118, -0.5389654636383057, -0.1859990358352661, -0.8939226269721985, -0.4266303479671478, -0.6680404543876648, -0.9034950137138367, -0.24300670623779297, 0.4938091039657593, 0.16402924060821533, -0.3492915630340576, 0.4249996244907379, 0.6144949793815613, 0.8507662415504456, 0.9053564667701721, -0.15517549216747284, -0.6338386535644531, 0.03476659953594208, -0.8827225565910339, 0.10859664529561996, -0.5826860070228577, 0.30923283100128174, -0.3740648031234741, 0.06955970078706741, -0.6940822601318359]}, "authors": [{"authorId": "2051851545", "name": "Yanwen Fang"}, {"authorId": "2163374183", "name": "Yuxi Cai"}, {"authorId": "2278585764", "name": "Jintai Chen"}, {"authorId": "49530627", "name": "Jingyu Zhao"}, {"authorId": "123750202", "name": "Guangjian Tian"}, {"authorId": "2108271170", "name": "Guodong Li"}], "references": [{"paperId": "14793e6f4b64f622210dc123f4895c473aaba826", "title": "Adaptive Cross-Layer Attention for Image Restoration"}, {"paperId": "17b5a5ec9324aba422df4b616f56188818f39432", "title": "BA-Net: Bridge Attention for Deep Convolutional Neural Networks"}, {"paperId": "e76fa7530528bbc06c74aec5cad34cb9d6275c8d", "title": "TDAM: Top-Down Attention Module for Contextually Guided Feature Selection in CNNs"}, {"paperId": "dc7f88d234a359223fc1e209145b9456c2835096", "title": "Recurrence along Depth: Deep Convolutional Neural Networks with Recurrent Layer Aggregation"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "8de07f75faa4a8657b59eca1183a6a6fe3911a9e", "title": "Cross-layer Navigation Convolutional Neural Network for Fine-grained Visual Classification"}, {"paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0", "title": "Incorporating Convolution Designs into Visual Transformers"}, {"paperId": "8514e90a83b2609d188c07be1cde90307b2c6afe", "title": "OmniNet: Omnidirectional Representations from Transformers"}, {"paperId": "5cee90b85b88e4de1d51b2963613a48b68916ac7", "title": "How to Represent Part-Whole Hierarchies in a Neural Network"}, {"paperId": "0fe8b49369d70a2be473435a82b01544704b3c9f", "title": "Evolving Attention with Residual Convolutions"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "6914a7997ff4be207fa7b3472a9c5879abaec646", "title": "RealFormer: Transformer Likes Residual Attention"}, {"paperId": "35248e4b63c96067ccf1bc3f3fa0f2e27a0e6cee", "title": "RelationNet++: Bridging Visual Representations for Object Detection via Transformer Decoder"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "13da774fe604027bff2951ba82f4c3d9be7e415e", "title": "Augment Your Batch: Improving Generalization Through Instance Repetition"}, {"paperId": "8cb34cbdcf65c23ef98430441b14a648c4e8d992", "title": "ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks"}, {"paperId": "2e257b5f0a0148076e9161202880b022e521ac59", "title": "Score-CAM: Score-Weighted Visual Explanations for Convolutional Neural Networks"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "c2c083df88e88223e1a411e61040b94c233b1b63", "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"}, {"paperId": "257e48098d564e26f021f596bea5c98ff6398fd1", "title": "DIANet: Dense-and-Implicit Attention Network"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "5e19eba1e6644f7c83f607383d256deea71f87ae", "title": "Searching for MobileNetV3"}, {"paperId": "66143960c0325c70329a3869cc8052f0416b87aa", "title": "GCNet: Non-Local Networks Meet Squeeze-Excitation Networks and Beyond"}, {"paperId": "27ac832ee83d8b5386917998a171a0257e2151e2", "title": "Attention Augmented Convolutional Networks"}, {"paperId": "b7339c1deeb617c894cc08c92ed8c2d4ab14b4b5", "title": "A2-Nets: Double Attention Networks"}, {"paperId": "8fec5d6ac57e90f459e7330775165f2671abc445", "title": "Training Deeper Neural Machine Translation Models with Transparent Attention"}, {"paperId": "de95601d9e3b20ec51aa33e1f27b1880d2c44ef2", "title": "CBAM: Convolutional Block Attention Module"}, {"paperId": "f723eb3e7159f07b97464c8d947d15e78612abe4", "title": "AutoAugment: Learning Augmentation Policies from Data"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "79cfb51a51fc093f66aac8e858afe2e14d4a1f20", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "5694e46284460a648fe29117cbc55f6c9be3fa3c", "title": "Densely Connected Convolutional Networks"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": null, "title": "2021), which are the default settings in MMDetection"}, {"paperId": "47dd4ee3cad740dd0edc0966eb5fbb24c77e44c1", "title": "Cross-Layer Attention Network for Small Object Detection in Remote Sensing Imagery"}, {"paperId": null, "title": "Pytorch image models. https://github.com/rwightman/ pytorch-image-models, 2019"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": null, "title": "OUT-OF-MEMORY PROBLEM AND THE NECESSITY OF MRLA-LIGHT Though it is possible to train a naive quadratic version with MLA (Eq. (4)) and MRLA-base"}]}