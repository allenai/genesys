{"paperId": "c4d3b9a87295db0b9f6466b7f3ce2f175c6d3157", "abstract": "The evolving sophistication and intricacies of Large Language Models (LLMs) yield unprecedented advancements, yet they simultaneously demand considerable computational resources and incur significant costs. To alleviate these challenges, this paper introduces a novel, simple, and effective method named ``\\growlength'' to accelerate the pretraining process of LLMs. Our method progressively increases the training length throughout the pretraining phase, thereby mitigating computational costs and enhancing efficiency. For instance, it begins with a sequence length of 128 and progressively extends to 4096. This approach enables models to process a larger number of tokens within limited time frames, potentially boosting their performance. In other words, the efficiency gain is derived from training with shorter sequences optimizing the utilization of resources. Our extensive experiments with various state-of-the-art LLMs have revealed that models trained using our method not only converge more swiftly but also exhibit superior performance metrics compared to those trained with existing methods. Furthermore, our method for LLMs pretraining acceleration does not require any additional engineering efforts, making it a practical solution in the realm of LLMs.", "venue": "arXiv.org", "year": 2023, "citationCount": 6, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2310.00576", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper introduces a novel, simple, and effective method named ``\\growlength'' to accelerate the pretraining process of LLMs, and reveals that models trained using this method not only converge more swiftly but also exhibit superior performance metrics compared to those trained with existing methods."}, "embedding": {"model": "specter_v2", "vector": [0.07338635623455048, 0.41611650586128235, -0.37149107456207275, -0.3020292818546295, -0.18854855000972748, -0.1868915557861328, 0.4900911748409271, -0.05370185524225235, -0.7736482620239258, -0.4272085428237915, 0.24574752151966095, -0.2399650514125824, 0.9336158633232117, 0.4925084710121155, -0.2200145721435547, 0.09194672852754593, -1.0758591890335083, 0.029823310673236847, -0.4778595268726349, -0.02248872071504593, -0.27307310700416565, -0.45037606358528137, -1.0208646059036255, 0.053194310516119, 0.5540730953216553, 0.4274677336215973, 0.5652836561203003, 0.749626874923706, -0.6035343408584595, -0.017533086240291595, 0.4935404658317566, -0.33380913734436035, 0.3050008714199066, -0.025262048467993736, -0.3483869731426239, -0.01464256551116705, 0.4130772352218628, -0.4065740704536438, -0.2721867263317108, 0.7404765486717224, -0.39455312490463257, 0.6772329211235046, 0.013018237426877022, -0.48891115188598633, -0.06255118548870087, 1.0124714374542236, 0.2484501302242279, 0.7388390898704529, -0.5644757747650146, -0.4760189354419708, 0.9440762996673584, -1.7319672107696533, 0.09423987567424774, 1.5207841396331787, 0.8818876147270203, 0.49706852436065674, -0.13614796102046967, -0.8031465411186218, 0.7902817726135254, -0.19648398458957672, -0.7298088073730469, -0.7730435729026794, -0.22100484371185303, 0.15493586659431458, 2.0790212154388428, -0.42490947246551514, -0.04289660602807999, 0.37434121966362, -0.34713447093963623, 1.6189132928848267, -0.06996896862983704, -0.9080565571784973, -0.41242244839668274, 0.16015644371509552, 0.314905047416687, 0.730854332447052, -0.47412198781967163, 0.30263152718544006, -0.8855291604995728, -0.10289201140403748, 0.22451193630695343, 0.04663736745715141, 0.5031968355178833, 0.20718427002429962, -0.19678360223770142, 0.9667168855667114, 0.23811505734920502, 0.9270743727684021, -0.32221105694770813, 0.775435745716095, 0.502604603767395, 0.17187173664569855, 0.46918055415153503, 0.3876924514770508, -0.19570834934711456, 0.29612410068511963, -1.0297738313674927, -0.0031613102182745934, -0.19831696152687073, 0.7883191704750061, -0.3599085509777069, 0.7823492884635925, -0.3292872905731201, 0.5105610489845276, 1.3543094396591187, 0.2685481607913971, 0.4765736162662506, -0.48717591166496277, 0.6576589345932007, -0.8893656134605408, -0.04525149613618851, -0.14860114455223083, -0.26732900738716125, -0.5346862077713013, -0.9179875254631042, -1.436522126197815, -0.5450378060340881, -0.19159747660160065, -0.7969244718551636, 0.9573895931243896, -0.08697125315666199, 0.4483799934387207, 0.3900788724422455, 0.057524651288986206, 0.3677479326725006, 1.0598124265670776, 0.500774085521698, -0.3039182424545288, 0.870880663394928, -1.1459057331085205, -0.6297998428344727, -1.2023431062698364, 0.874732494354248, -0.3142576515674591, 0.21476706862449646, -0.3110835552215576, -1.2571072578430176, -1.0686142444610596, -0.7943530678749084, 0.3047259449958801, -0.3694850206375122, 0.5783103108406067, 1.1168620586395264, 0.1981840431690216, -1.1616296768188477, 0.8983006477355957, -0.1866030991077423, -0.0914105549454689, 0.18719831109046936, 0.06097560003399849, 0.3667552173137665, -0.13067829608917236, -1.4374955892562866, 0.36503109335899353, 0.3913498818874359, -0.371263712644577, -0.10007006675004959, -0.5289952158927917, -1.1789222955703735, 0.03425849974155426, 0.0007876586751081049, -0.09935387223958969, 1.433496117591858, -0.10922551900148392, -1.2474350929260254, 0.7026800513267517, -0.4353548586368561, -0.09864835441112518, 0.19351105391979218, -0.2142304927110672, -0.8083449602127075, -0.5616607666015625, -0.5319784283638, 0.9007028341293335, 0.49402061104774475, -0.02492503449320793, -0.3010150194168091, 0.4501829147338867, -0.3326864242553711, 0.1183541938662529, -0.6324244737625122, 0.9882771968841553, -0.24077923595905304, -0.5634768009185791, 0.5057782530784607, 0.40835294127464294, -0.4808454215526581, -0.5953741073608398, -0.1711394190788269, -1.1235673427581787, 0.6721732020378113, -0.23856928944587708, 0.9389979839324951, -0.919230580329895, -1.0050746202468872, -0.1935444474220276, -0.31735387444496155, 0.35347533226013184, -1.0163249969482422, 0.8730286955833435, -0.15173204243183136, 0.4072342813014984, 0.1445429027080536, -1.49541437625885, 0.02521735243499279, -0.33770880103111267, -0.7056732773780823, -0.21662500500679016, 0.16189183294773102, 0.7862560153007507, -0.9283613562583923, 0.08149632811546326, -0.00704536447301507, 0.5202516317367554, -0.877753734588623, 1.1048510074615479, -0.1335955262184143, 0.15399909019470215, 0.273457407951355, -0.3150414228439331, 0.1475231647491455, -0.3194579780101776, 0.5179619789123535, -0.1295901983976364, -0.4604816734790802, 0.524334728717804, -0.5656675100326538, 1.5167113542556763, -0.48559170961380005, 0.300094872713089, -0.15752297639846802, -0.3914163112640381, 0.04955924302339554, 0.4391753673553467, -0.09411652386188507, -0.29848387837409973, 0.2927559018135071, 0.4593399465084076, -0.7577069997787476, 0.5434268712997437, 1.020388126373291, 0.9167299270629883, -0.35591229796409607, 0.2490079253911972, 0.5563722848892212, 0.13672322034835815, 0.7637611627578735, 0.3763633966445923, 0.04876438528299332, 0.13438434898853302, 0.20975586771965027, -0.018918028101325035, 0.5764551162719727, -0.9369697570800781, -0.0756605789065361, 0.5283345580101013, 0.6952033042907715, 0.15122345089912415, -0.17865511775016785, -0.6919314861297607, -0.526096761226654, 0.09768970310688019, 0.6497275233268738, 1.7177563905715942, -0.352413147687912, -0.025937465950846672, -0.768150269985199, -0.2987566292285919, -0.09078192710876465, -0.06306358426809311, 0.1190824806690216, 0.0855771005153656, -0.6929566264152527, -0.8705232739448547, 1.1109936237335205, 0.20535899698734283, 0.8774693012237549, -0.7924726605415344, -0.35031527280807495, -0.20867125689983368, 0.19061896204948425, -0.9403805136680603, -0.6033662557601929, 0.3375706672668457, -1.033653736114502, 0.13365283608436584, -0.12164976447820663, -0.45604678988456726, 0.3591090142726898, -0.5312676429748535, 0.662613034248352, -0.2534155547618866, -0.05409466475248337, -0.542314350605011, 0.3804832100868225, -0.6664955615997314, -1.0687167644500732, 0.26831236481666565, 0.712796688079834, -0.3210964500904083, 0.1343977004289627, 0.7403563857078552, 0.2785360515117645, -0.3056853711605072, -0.26778310537338257, 0.498360276222229, 0.2896069586277008, -0.2788306474685669, 0.7943276166915894, -0.3296317160129547, 0.4818726181983948, -1.2795228958129883, 0.9108762741088867, 0.3318401277065277, -0.4488702714443207, 0.42502376437187195, -0.8102158308029175, -0.12158434092998505, 0.6780125498771667, -0.7918169498443604, -0.18249446153640747, -0.6841282844543457, 0.008280693553388119, -0.21009014546871185, -0.2035910189151764, 0.23529888689517975, 0.6227346062660217, 0.14812056720256805, -0.1801859736442566, 0.6951920986175537, 0.2541508972644806, -0.6136043071746826, 0.47403743863105774, -0.7101373076438904, 0.5896521210670471, 0.6212062835693359, 0.33564993739128113, -0.49507200717926025, -0.5697420239448547, -0.7103843092918396, -0.25730159878730774, -0.7872111797332764, -0.40725430846214294, -0.21665044128894806, -0.3453129529953003, -0.5578034520149231, -0.73837810754776, 0.23852136731147766, -1.066152811050415, -0.07554861903190613, 0.2765240967273712, 0.23075760900974274, 0.12081189453601837, -0.8466922640800476, -1.6316477060317993, -0.798275887966156, -1.0915104150772095, -0.7676873803138733, 0.21443361043930054, 0.11782006919384003, -0.30750152468681335, -0.6059308648109436, -0.05839602276682854, -0.5245035290718079, 1.0989724397659302, -0.9203959703445435, 0.5957196950912476, -0.06943384557962418, 0.30333635210990906, -0.41867125034332275, 0.36722052097320557, 0.7341931462287903, -0.44985896348953247, 0.2071308046579361, -1.0593682527542114, -0.16732431948184967, -0.289426326751709, -0.31593385338783264, 0.05885512754321098, 0.3566734790802002, 0.5786041617393494, -0.3001437783241272, -0.44110581278800964, 0.4102325737476349, 1.2918143272399902, -0.5942720770835876, -0.2922757565975189, -0.1161021888256073, 0.8913233280181885, 0.0416640043258667, -0.26102086901664734, 0.6885717511177063, 0.11748155951499939, 0.0980413630604744, -0.09879301488399506, -0.5887095332145691, -0.1718718409538269, -0.48201242089271545, 0.5478700995445251, 2.249009370803833, 0.44400420784950256, -0.21758300065994263, -0.9825172424316406, 0.3456858992576599, -0.9353624582290649, -0.7365614771842957, 0.6490367650985718, 0.75424724817276, 0.5505005717277527, -0.5520883202552795, -0.19547779858112335, -0.01304550375789404, 0.595059871673584, 0.7125695943832397, -0.452923059463501, -0.9798274636268616, 0.09616446495056152, 0.21948948502540588, 0.1427781879901886, 0.5427050590515137, -0.5576587319374084, 0.9679771065711975, 14.633223533630371, 0.8551682233810425, -0.09446751326322556, 0.652745246887207, 0.7413671612739563, 0.14665161073207855, -0.16302502155303955, -0.48638036847114563, -1.6648938655853271, -0.02595352753996849, 1.4286258220672607, 0.2764895260334015, 0.8966180682182312, 0.3359031081199646, 0.32990148663520813, 0.21061201393604279, -0.27402427792549133, 0.9973551630973816, 0.5402610898017883, -1.2070040702819824, 0.32293832302093506, 0.07566747814416885, 0.569364070892334, 0.5562818050384521, 0.6209379434585571, 1.1607472896575928, 0.3841606080532074, -0.28753921389579773, 0.8067049384117126, 0.04312240332365036, 0.7857751846313477, -0.31847044825553894, 0.6021974086761475, 0.8194660544395447, -1.188841700553894, 0.10832177102565765, -0.5328277945518494, -1.1346614360809326, 0.44472256302833557, 0.26371076703071594, -0.8585698008537292, -0.5901661515235901, -0.43962544202804565, 0.8112690448760986, -0.13153550028800964, 0.47535058856010437, -0.08194921910762787, 0.9696449637413025, -0.05150611326098442, 0.022668559104204178, 0.5957111120223999, 0.416620671749115, 0.07498957961797714, 0.2564903497695923, 0.006191514898091555, -0.23083655536174774, 0.33359476923942566, 0.09055035561323166, -0.7314398288726807, 0.20885448157787323, -0.0848323181271553, -0.4684399366378784, 0.09608089923858643, 0.8462327122688293, 0.3013700544834137, -0.03893781080842018, -0.2397090643644333, 0.26831725239753723, 0.6310623288154602, 0.21552158892154694, -0.5006021857261658, 0.08460117876529694, 0.2820993661880493, -0.7204006910324097, -0.3779194951057434, 0.35088491439819336, -0.19901107251644135, -0.6179597973823547, -0.6893489956855774, -0.4364866018295288, 0.19086682796478271, -0.5137844681739807, -0.5091949701309204, 0.9261295795440674, -0.38344606757164, -0.2310923933982849, -0.04098432511091232, -0.48407888412475586, 0.0667167454957962, 0.7193818092346191, -1.3758704662322998, -0.620039701461792, 0.682374894618988, -0.488815575838089, -0.07470041513442993, 0.03605898469686508, 1.3082149028778076, 0.3554999530315399, -0.554826021194458, 0.2373671680688858, 0.3327765166759491, 0.028538865968585014, -0.5461026430130005, -0.2780991494655609, 1.2419207096099854, 0.7064839005470276, -0.01725812815129757, 0.3563052713871002, -0.16659606993198395, 0.12638986110687256, -0.7335860133171082, -0.18112291395664215, 1.2413780689239502, -0.41689804196357727, -0.5023763179779053, -0.9593613147735596, -0.8273974061012268, 0.22778953611850739, 0.2938472032546997, -0.39400747418403625, 0.30285128951072693, 0.47275230288505554, -0.41421622037887573, -0.02942313253879547, -0.6155121922492981, -0.05091674625873566, 0.5220545530319214, -0.8960172533988953, -0.1854245513677597, 0.05681068077683449, 0.37815484404563904, -0.9775472283363342, -0.46165257692337036, -0.13789872825145721, -0.05222848057746887, 0.37563180923461914, 0.9231750965118408, -0.3715542256832123, 0.33890408277511597, 1.1939094066619873, 0.02091887779533863, -0.7741788029670715, 0.12841695547103882, -0.7133111357688904, -0.13290660083293915, 0.11243291199207306, 0.7563811540603638, -0.18996909260749817, 0.34155938029289246, 0.5589905381202698, 0.04686684161424637, -0.5204412341117859, -0.4515765905380249, -0.623772919178009, -0.14551253616809845, -0.630094587802887, 0.34964898228645325, 0.1996907889842987, 0.128081813454628, -0.17618069052696228, 0.22485987842082977, 0.6085730791091919, -0.29792916774749756, -0.6297010779380798, 0.23985594511032104, -0.0657588467001915, -0.03169283643364906, -0.5901764035224915, -0.1286194920539856, -1.4050203561782837, 0.19970741868019104, -1.3040351867675781, 0.21662744879722595, -0.9010366797447205, -0.3071683347225189, -0.24069033563137054, -0.2275734841823578, 0.3625844419002533, 0.2931745946407318, -0.28671425580978394, -0.20376895368099213, -0.15475685894489288, -0.6424090266227722, 0.7480708360671997, 0.7188072800636292, -0.41691145300865173, -0.06768012791872025, 0.007825485430657864, 0.8348736763000488, 0.41904011368751526, 0.4891957640647888, -0.4054887890815735, -0.8466764092445374, -1.5840572118759155, 0.34006330370903015, -0.16407577693462372, -0.3350171744823456, -0.7336673736572266, 0.4597141742706299, 0.33846044540405273, -0.23048065602779388, -0.1602301299571991, 0.25987112522125244, -0.5870440006256104, -0.47136354446411133, 0.682104229927063, -0.8202921152114868, 0.6248005628585815, 0.40602636337280273, -0.846382737159729, -0.26343777775764465, 0.5220178961753845, -0.05605784058570862, -0.8682664632797241, -1.0441869497299194, 0.5636519193649292, -0.5692713260650635, 0.005960764829069376, -0.31670036911964417, -0.02300863526761532, -0.7054808139801025, -0.05406372621655464, -0.16484110057353973, 0.3796122074127197, -0.4313317835330963, 1.1450275182724, 0.4888245463371277, -1.1235933303833008, -0.09742077440023422, 0.7384289503097534, -0.3137405812740326, -0.3384920656681061, 0.6685726046562195, 0.4523766338825226, -0.3927454650402069, 0.7980416417121887, 0.3467269837856293, 0.23137614130973816, -1.2759199142456055, -0.23009522259235382, 0.6043144464492798, -0.7946733236312866, -0.2137995809316635, 1.5442326068878174, -0.523615837097168, -1.1914221048355103, 0.4304269552230835, -1.3804080486297607, -0.6048818230628967, -0.3160339593887329, 0.755986750125885, 0.18952223658561707, 0.10393022745847702, -0.3299235999584198, -0.5994011163711548, -0.16760508716106415, -0.0026957993395626545, -0.5399418473243713, 0.6884461045265198, -0.42982062697410583, -0.06793712824583054, 0.6137562394142151, 0.7548474669456482, -0.6823685765266418, -1.0698312520980835, -0.7350090146064758, -0.21700656414031982, -0.12296483665704727, 0.29236850142478943, -0.2893185019493103, -0.7268762588500977, 0.7608304023742676, 0.5498999953269958, 0.15369656682014465, -0.2215995043516159, -0.5198273062705994, 0.5845026969909668, 0.5956138968467712, 0.43570709228515625, -0.8916850090026855, -0.6654316186904907, 1.560072660446167, 0.8873713612556458, -1.1086527109146118, 0.09705735743045807, 0.1367829591035843, -0.8167782425880432, 0.6449579000473022, 0.15850114822387695, 0.17426550388336182, 0.7313626408576965, -0.3008570671081543, 0.15422314405441284, 0.38567909598350525, -0.8739387392997742, -0.028086377307772636, 0.8812853693962097, 0.4433853328227997, 0.973197340965271, 0.3746151924133301, -0.06779549270868301, 0.7276608347892761, 0.09685170650482178, -0.04875084385275841, 0.16866347193717957, 0.5524287223815918, -0.3540235459804535, -0.2357722818851471, 0.1949346661567688, 0.45369860529899597, -0.7500162124633789, -1.044235348701477, 0.3359210789203644, 0.500609815120697, 0.4422079920768738, 0.6725084185600281, 0.784965991973877, 0.14885561168193817, 0.2754233777523041, 0.4830085039138794, 0.4290733337402344, -0.6539790034294128, -0.5183338522911072, -0.11563277244567871, -0.6536620259284973, 0.07378572225570679, -0.13251830637454987, -0.5028372406959534, -0.6489570736885071, -0.6937506794929504, 0.10271340608596802, 0.16749784350395203, 0.7736930251121521, 1.0793418884277344, 0.42325693368911743, 0.39424192905426025, -0.12047185748815536, -0.6852073073387146, -0.6278849244117737, -1.1215498447418213, -0.23037439584732056, -0.29405295848846436, -0.3666386604309082, 0.3236640989780426, 0.12300989031791687, -0.11336591094732285]}, "authors": [{"authorId": "1791983892", "name": "Hongye Jin"}, {"authorId": "2249766229", "name": "Xiaotian Han"}, {"authorId": "2250031863", "name": "Jingfeng Yang"}, {"authorId": "47653902", "name": "Zhimeng Jiang"}, {"authorId": "2166879577", "name": "Chia-yuan Chang"}, {"authorId": "2249844820", "name": "Xia Hu"}], "references": [{"paperId": "5e0cb1c4b91a7486e1c2b15a44a0be56bd74bdc0", "title": "Effective Long-Context Scaling of Foundation Models"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "f8afa4bd5b05f52ffa304f56aed7a5792a42ef1f", "title": "FLM-101B: An Open LLM and How to Train It with $100K Budget"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "0b0debb710366cdff461938c80763eace1651af6", "title": "Code Llama: Open Foundation Models for Code"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "7d22ad3573101337bca2091fb0114b377c4f3db6", "title": "A Simple and Effective Pruning Approach for Large Language Models"}, {"paperId": "7a1e71cb1310c4a873e7a4e54d1a6dab0553adce", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"}, {"paperId": "6f6e2e0311589a9af045f6acd00b7dee6d19fce4", "title": "The Impact of Positional Encoding on Length Generalization in Transformers"}, {"paperId": "6bd3ee1ca608bc66a490f63f2fb107d79b44f3e2", "title": "LLM-QAT: Data-Free Quantization Aware Training for Large Language Models"}, {"paperId": "017010b941d902a467f6d329ae5e74fd67e67912", "title": "LLM-Pruner: On the Structural Pruning of Large Language Models"}, {"paperId": "131c6f328c11706de2c43cd16e0b7c5d5e610b6a", "title": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond"}, {"paperId": "9e8cb8c91a0acb6e661b58ad724aa758490f2bea", "title": "Instruction Tuning with GPT-4"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d", "title": "A Survey of Large Language Models"}, {"paperId": "0a6906bd6f026d3da3031c641ed03081bd0b574e", "title": "Full Stack Optimization of Transformer Inference: a Survey"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "f2b0017ddd77fa38760a18145e63553105a1a236", "title": "The Flan Collection: Designing Data and Methods for Effective Instruction Tuning"}, {"paperId": "9575afb5702bc33d7df14c48feeee5901ea00369", "title": "A Length-Extrapolatable Transformer"}, {"paperId": "17a8bd6a5763f6607863348ce1757ac2ad3417fd", "title": "Accelerating Transformer Networks through Recomposing Softmax Layers"}, {"paperId": "4be7d1524edb0137599a5cc95f72844b85a52fe1", "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "ee8984a6712791d4e0f2c776dad8119a3b893dd9", "title": "Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "8256f48f759cf85044db251cc512f965834945b3", "title": "Rethinking Positional Encoding in Language Pre-training"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "d79a26226393f687ddbc375e32055b40b8ad8d38", "title": "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": null, "title": "Things I\u2019m learning while training superhot"}, {"paperId": "8264257f573696fc0a1ef7531c825041832197f8", "title": "Understanding INT4 Quantization for Transformer Models: Latency Speedup, Composability, and Failure Cases"}, {"paperId": "426235b80b11b9910334c19fad55e0f9be1e6bac", "title": "Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "A suite for analyzing large"}, {"paperId": null, "title": "GPTQ: Accurate post-training compression for generative pretrained transformers"}]}