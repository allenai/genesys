{"paperId": "b00d3c32f25da4dd0bb97a87a7054bacd3bc3034", "abstract": "Training large transformers is slow, but recent innovations on GPU architecture give us an advantage. NVIDIA Ampere GPUs can execute a fine-grained 2:4 sparse matrix multiplication twice as fast as its dense equivalent. In the light of this property, we comprehensively investigate the feasibility of accelerating feed-forward networks (FFNs) of transformers in pre-training. First, we define a ``flip rate'' to monitor the stability of a 2:4 training process. Utilizing this metric, we propose three techniques to preserve accuracy: to modify the sparse-refined straight-through estimator by applying the masked decay term on gradients, to determine a feasible decay factor in warm-up stage, and to enhance the model's quality by a dense fine-tuning procedure near the end of pre-training. Besides, we devise two techniques to practically accelerate training: to calculate transposable 2:4 masks by convolution, and to accelerate gated activation functions by reducing GPU L2 cache miss. Experiments show that our 2:4 sparse training algorithm achieves similar convergence to dense training algorithms on several transformer pre-training tasks, while actual acceleration can be observed on different shapes of transformer block apparently. Our toolkit is available at https://github.com/huyz2023/2by4-pretrain.", "venue": "arXiv.org", "year": 2024, "citationCount": 2, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work comprehensively investigates the feasibility of accelerating feed-forward networks of transformers in pre-training and devise two techniques to practically accelerate training: to calculate transposable 2:4 masks by convolution, and to accelerate gated activation functions by reducing GPU L2 cache miss."}, "embedding": {"model": "specter_v2", "vector": [0.277590274810791, 0.6185105443000793, -0.24092482030391693, 0.06699848920106888, 0.1197008565068245, 0.23250754177570343, 0.3457062542438507, -0.4830017685890198, -0.25388339161872864, -0.5103831887245178, 0.38931897282600403, -0.21360214054584503, 0.6713989973068237, -0.1501227170228958, -0.20514243841171265, -0.14626340568065643, -1.3179186582565308, 0.01852908730506897, 0.1780671328306198, -0.15982428193092346, -0.21363139152526855, -0.27599209547042847, -0.9491378664970398, 0.19275671243667603, 0.4357127249240875, 1.4096359014511108, -0.19246111810207367, 0.602182149887085, -0.4384367763996124, 0.6167256236076355, 0.8818930983543396, -0.19658927619457245, 0.7089642286300659, -0.06898323446512222, -0.28396883606910706, -0.11799576133489609, 0.30691176652908325, -0.517187774181366, -0.532747745513916, 0.782966673374176, -0.37060460448265076, 0.475108802318573, 0.26105010509490967, -0.672645092010498, 0.12824299931526184, 0.3748035430908203, 0.22720199823379517, 0.9448668360710144, -0.9348376393318176, -0.6552145481109619, 0.7899691462516785, -1.3906596899032593, -0.36806151270866394, 0.8260902762413025, 0.9005406498908997, 0.23287272453308105, -0.05664830654859543, -0.5587594509124756, 0.6084050536155701, 0.0951906219124794, -0.4702061414718628, -0.21621741354465485, 0.03998976945877075, -0.2769411504268646, 1.535164475440979, -0.22697113454341888, 0.5190314650535583, 0.6559649109840393, 0.04807323217391968, 1.1518386602401733, 0.29048222303390503, -0.5692217350006104, -0.09670687466859818, 0.2487560510635376, 0.21360917389392853, 0.7658953666687012, -0.3677065074443817, 0.32425880432128906, -0.9881400465965271, 0.03730861097574234, 0.9476149678230286, 0.023039741441607475, 0.25397947430610657, -0.10858955979347229, -0.005170860327780247, 0.7488383054733276, 0.5714157819747925, 0.7086676955223083, -0.47828370332717896, 0.8573707938194275, 0.7630196809768677, 0.29861441254615784, 0.10575150698423386, 0.14737065136432648, 0.2727774381637573, 0.5618764162063599, -0.8558233976364136, -0.07935765385627747, -0.3395235538482666, 0.7144394516944885, -0.12371500581502914, 0.8770769834518433, -0.34359675645828247, 0.18419863283634186, 1.2501041889190674, -0.04226620867848396, 0.44230562448501587, -0.3569100797176361, -0.010793739929795265, -0.6583669781684875, -0.2155829668045044, -0.4440595507621765, -0.05743981525301933, -0.9462701678276062, -1.2777892351150513, -0.800697386264801, -0.547316312789917, 0.2764151096343994, -1.0718705654144287, 0.3247748911380768, -0.26766878366470337, 0.6475970149040222, -0.428036093711853, 0.7866678237915039, 0.17600107192993164, 0.47152456641197205, 0.11019431799650192, 0.1593949794769287, 0.9683988690376282, -1.3909955024719238, -0.5663063526153564, -0.8757639527320862, 0.019169338047504425, -0.09320663660764694, -0.09407463669776917, 0.18959766626358032, -1.469614028930664, -1.2186325788497925, -0.7701191306114197, 0.3750624656677246, -0.17749395966529846, -0.05680447816848755, 1.6198217868804932, 0.26998937129974365, -1.1996749639511108, 0.9798153042793274, -0.744442343711853, -0.13039962947368622, 0.5781669616699219, 0.45012760162353516, 0.35371947288513184, 0.2392672747373581, -1.1294314861297607, 0.5051630735397339, -0.07232712209224701, -0.2545170783996582, -0.5820749998092651, -1.066893458366394, -0.5446130633354187, 0.1609691083431244, -0.17139415442943573, -0.6574220657348633, 1.0318044424057007, -0.3277095854282379, -1.0502853393554688, 0.8475654721260071, 0.012296944856643677, -0.2972046434879303, 0.33358824253082275, -0.12535768747329712, -0.4848833978176117, -0.34944796562194824, -0.20005369186401367, 0.5558950304985046, 0.8625370860099792, -0.06567317992448807, -0.08716235309839249, -0.008931322954595089, -0.4699608087539673, -0.07057128846645355, -0.5849220156669617, 0.5657589435577393, -0.4203079640865326, -0.4171510636806488, 0.3788350224494934, 0.6766388416290283, -0.6335960626602173, -0.04381975904107094, -0.09065891802310944, -0.4978514015674591, 0.7269678711891174, 0.009369488805532455, 0.9024795889854431, -0.951259434223175, -0.9592682123184204, 0.48562827706336975, 0.45130276679992676, -0.18201938271522522, -0.6146261096000671, 0.3288961350917816, -0.7374913096427917, -0.3016246557235718, 0.14376254379749298, -0.7149320244789124, -0.3024384379386902, -0.4288790822029114, -0.9155433177947998, -0.032135672867298126, 0.0953540951013565, 0.8241469264030457, -0.8526541590690613, 0.4444025754928589, 0.0063877226784825325, 0.6154244542121887, -1.1404516696929932, 1.237273931503296, 0.1637452095746994, 0.16939786076545715, -0.057848744094371796, 0.06812377274036407, 0.2602582573890686, -0.8410613536834717, 0.4002532660961151, -0.7873836755752563, 0.07873134315013885, 0.3328697681427002, -0.5214518308639526, 1.3120343685150146, -0.3871198892593384, 0.45797768235206604, 0.10693371295928955, -1.0344903469085693, 0.3866492807865143, 0.30245131254196167, 0.1507306843996048, -0.720502495765686, 0.7195570468902588, 0.5180976390838623, -0.46499133110046387, 0.6160621643066406, 0.570960521697998, 0.7361370921134949, -0.004399668890982866, -0.12581492960453033, 0.8201414942741394, -0.12709186971187592, 0.1097516268491745, 0.34864360094070435, 0.525935173034668, 0.07228385657072067, -0.06877803802490234, -0.40070414543151855, 0.04005710780620575, -1.1201720237731934, -0.1226176917552948, 0.6841225624084473, 0.5199296474456787, 0.7478275299072266, 0.2519395649433136, -0.7776296138763428, -0.6214825510978699, -0.2652108669281006, 0.5707433819770813, 1.245226502418518, -0.40475305914878845, -0.015322936698794365, -0.46621111035346985, -0.1795019507408142, -0.18511849641799927, -0.38350218534469604, -0.48227325081825256, -0.23668408393859863, -0.31562453508377075, -1.3991658687591553, 0.6804578900337219, 0.5228344202041626, 1.2160426378250122, 0.13181358575820923, -0.5881917476654053, -0.32885339856147766, 0.6332972049713135, -0.858921468257904, -0.3880546987056732, 0.9998947381973267, -1.1740896701812744, 0.058372657746076584, -0.1028846949338913, -0.2032984495162964, 0.39650800824165344, -0.5913581848144531, 0.70440274477005, -0.09702785313129425, -0.17375938594341278, 0.008689298294484615, 0.6639414429664612, -0.24121907353401184, -0.17991319298744202, 0.07401806861162186, 0.31910714507102966, -0.01688125543296337, 0.034660033881664276, -0.6057427525520325, -0.25074073672294617, -0.12752790749073029, 0.047207243740558624, 0.3311346769332886, 0.07287867367267609, 0.0543348491191864, 0.48345091938972473, -0.514958381652832, 0.10199985653162003, -1.0067334175109863, 0.7268094420433044, 0.13227757811546326, -0.5460509657859802, -0.30629175901412964, -0.6145762801170349, -0.2783188819885254, 0.7638518810272217, -0.6588496565818787, 0.16461223363876343, -0.7052367329597473, -0.1379745602607727, -0.9056954979896545, 0.2275802046060562, -0.33639079332351685, 0.6240233182907104, -0.8623128533363342, 0.6089146137237549, 0.1552169919013977, 0.3419533967971802, 0.015851762145757675, 0.5312393307685852, -1.4714490175247192, 0.7164075970649719, 0.2980723977088928, 0.6550607681274414, 0.10208389163017273, 0.12434034794569016, -0.49720102548599243, -0.49057039618492126, -0.5408461689949036, -0.1278882920742035, -0.4386517405509949, -0.08198732137680054, -0.7995760440826416, -0.8572341799736023, 0.08454139530658722, -0.5569775104522705, -0.4437398314476013, 0.03149702027440071, -9.74412978393957e-06, -0.14287257194519043, -1.1074517965316772, -1.560273289680481, -0.43545183539390564, -1.2107874155044556, -1.1446553468704224, 0.018938859924674034, 0.07324673235416412, -0.28514087200164795, -0.8820200562477112, -0.4686143100261688, -0.7140242457389832, 1.4379633665084839, -0.5112219452857971, 0.5605646967887878, -0.003333278466016054, -0.12882505357265472, 0.29498499631881714, -0.019831029698252678, 0.6232581734657288, -0.5080084800720215, -0.016356026753783226, -1.1587002277374268, 0.4598773717880249, -0.07733843475580215, -0.2489926666021347, 0.09963655471801758, 0.36959436535835266, 0.9587895274162292, 0.0989513024687767, -0.31338220834732056, 0.8568425178527832, 1.289925456047058, -0.4761170446872711, 0.3132152259349823, 0.19642722606658936, 1.1179012060165405, -0.22267484664916992, -0.31620845198631287, 0.7948779463768005, -0.291063129901886, -0.019624002277851105, 0.4236895442008972, -0.6088753938674927, -0.38792598247528076, -0.3738194406032562, 0.1453648805618286, 1.7573425769805908, 0.26937004923820496, 0.6800486445426941, -0.7404175400733948, 0.727276086807251, -0.7802635431289673, -0.5000481009483337, 0.44656693935394287, 0.5282861590385437, 0.25327032804489136, -0.12687402963638306, -0.24509069323539734, 0.14781245589256287, 0.3353264331817627, 0.4427965581417084, -0.2581753134727478, -0.5546030402183533, 0.24357903003692627, 1.1737500429153442, 0.5672886371612549, 0.5494396686553955, -0.1745574027299881, 0.2750319242477417, 14.963196754455566, 0.7727978825569153, -0.25918450951576233, 0.6460785269737244, 0.866309404373169, 0.5130602717399597, -0.4959227740764618, 0.011191163212060928, -0.9444693922996521, 0.07373302429914474, 0.9425334334373474, 0.5640286207199097, 0.852439820766449, 0.6474316716194153, -0.0023079542443156242, 0.17856676876544952, -0.35145142674446106, 0.9074351191520691, 0.2731862962245941, -1.5399361848831177, 0.2178584188222885, 0.019049016758799553, 0.3940751254558563, 0.45707204937934875, 0.8537341356277466, 0.6642079949378967, 0.12872296571731567, -0.2956852614879608, 0.33304280042648315, -0.07010716944932938, 1.1244027614593506, 0.07654382288455963, 0.22245757281780243, 0.10780906677246094, -1.0532968044281006, 0.18211986124515533, -0.28391197323799133, -1.2215642929077148, 0.21448343992233276, 0.6524078249931335, -0.6213325262069702, -0.501851499080658, 0.05306899920105934, 0.7867971062660217, 0.15174099802970886, 0.5056226849555969, -0.21069110929965973, 0.7390682697296143, -0.3345813453197479, 0.4370885193347931, 0.6099517345428467, 0.04082062467932701, -0.26214149594306946, -0.16140057146549225, 0.22461973130702972, 0.16826409101486206, 0.00018498112331144512, 0.5437047481536865, -0.45490604639053345, -0.33995521068573, 0.032378505915403366, -0.09152588993310928, -0.3255671560764313, 1.2635451555252075, 0.0038992371410131454, 0.19053976237773895, -0.35109883546829224, 0.44091796875, 0.44961732625961304, -0.1067090779542923, -0.7974918484687805, -0.3279637098312378, 0.41942098736763, -0.10058877617120743, -0.11255624145269394, 0.5541268587112427, -0.66797935962677, -0.7394087314605713, -0.8570297360420227, -0.6168116927146912, 0.20857176184654236, -0.9756836891174316, -0.7449212074279785, 0.9897659420967102, -0.5287348031997681, -0.2186281532049179, 0.5869629979133606, -0.9037588834762573, -0.5821084976196289, 0.34465664625167847, -1.2546019554138184, -0.41005823016166687, -0.18458913266658783, 0.0320625826716423, -0.5363513827323914, 0.015621715225279331, 0.9311196208000183, 0.7831864953041077, -0.12945674359798431, 0.12849177420139313, -0.4694523513317108, -0.2052565962076187, -0.33695539832115173, -0.4155557453632355, 1.3042316436767578, 0.5419771075248718, -0.23166844248771667, 0.21649140119552612, -0.01627681963145733, 0.4154704213142395, -0.9461156725883484, 0.007448673248291016, 0.20252923667430878, -0.3590729832649231, 0.3887172341346741, -0.9570269584655762, -1.1730724573135376, 0.46139711141586304, 0.4964176118373871, 0.1814250349998474, 0.1963702291250229, 0.30013254284858704, -0.49620747566223145, -0.3498450219631195, -0.5341761112213135, -0.09705433249473572, 0.6058403253555298, -0.7051990032196045, -0.1992347091436386, -0.14018775522708893, -0.18831953406333923, -1.2109096050262451, -0.7500929832458496, 0.04709684103727341, 0.060762353241443634, -0.2966403365135193, 1.1282496452331543, -0.04276900738477707, 0.41698169708251953, 0.9673097133636475, 0.07259491086006165, -0.7921822667121887, -0.01630401611328125, -0.8293188214302063, -0.09005259722471237, -0.40030795335769653, 0.12650734186172485, -0.3032020926475525, 0.8788215517997742, 0.22818222641944885, -0.14114931225776672, -0.5425975918769836, -0.31129226088523865, -0.00937097892165184, -0.4480825960636139, -0.6688043475151062, -0.10854876786470413, 0.1508561372756958, -0.07978516817092896, 0.054688192903995514, 0.3018931746482849, 0.44923582673072815, -0.10635524988174438, -0.7557476758956909, 0.05424852296710014, -0.06800054758787155, -0.21154071390628815, -0.49300605058670044, -0.6477585434913635, -1.5604088306427002, -0.19862715899944305, -1.4787551164627075, -0.2646673917770386, -0.7337902784347534, -0.47232213616371155, -0.4046012759208679, -0.22559554874897003, 0.2702568769454956, 0.2444480061531067, -0.01708243601024151, -0.4440532922744751, -0.5978043675422668, -0.44869861006736755, 0.8723254203796387, 0.8586915135383606, -0.2886868417263031, 0.2663169205188751, -0.10717406123876572, 0.29888004064559937, 0.4139876961708069, 0.2717590034008026, -0.22783862054347992, -0.866096556186676, -1.2492362260818481, 0.23099754750728607, -0.23928870260715485, 0.03559979051351547, -1.1388026475906372, 0.6097386479377747, 0.6852929592132568, 0.21087023615837097, -0.048775557428598404, 0.3328920304775238, -0.934089183807373, -0.27138134837150574, 0.27809518575668335, -0.21183322370052338, 0.2941325604915619, 0.7168174982070923, -0.9569783210754395, -0.12178471684455872, 0.7219476699829102, 0.3049280345439911, -0.8758799433708191, -0.9784798622131348, 0.63236403465271, -0.7422821521759033, 0.25167644023895264, -0.5033770799636841, -0.17230714857578278, -0.7205833792686462, -0.12491798400878906, -0.4612111747264862, 0.3134215474128723, -0.5430413484573364, 0.5477750897407532, 0.4511953592300415, -1.540479302406311, 0.6017121076583862, 0.6992961764335632, -0.6429792642593384, -0.30180129408836365, 0.7629322409629822, 0.7616129517555237, -0.3886668086051941, 0.09224698692560196, -0.5175965428352356, 0.08926352113485336, -0.5145281553268433, -0.16312134265899658, 0.9898837804794312, -0.6670666933059692, -0.29252684116363525, 1.3449150323867798, -0.21700137853622437, -0.8358783721923828, 0.4629831314086914, -1.0990285873413086, -0.32440489530563354, -0.3825352191925049, 0.6701814532279968, 0.1385195404291153, 0.40507540106773376, 0.5185234546661377, -0.6270104050636292, 0.16011768579483032, -0.018137918785214424, -0.18199773132801056, 0.38471394777297974, 0.24799245595932007, -0.270686537027359, 0.4857548773288727, 0.7036685347557068, -0.7263545393943787, -0.8670789003372192, -0.4299981892108917, -0.6379119753837585, -0.3191414475440979, 0.3896951973438263, -0.10906419157981873, -1.4733723402023315, 1.2130588293075562, 0.8032673597335815, 0.09139855206012726, 0.6625621318817139, -0.40793317556381226, 0.29371219873428345, 0.2810211777687073, 0.32212579250335693, -0.48893874883651733, -0.39219391345977783, 1.2090234756469727, 0.6991376280784607, -0.6846155524253845, 0.355435848236084, -0.5613466501235962, -0.5385564565658569, 0.8875906467437744, 0.5604550242424011, -0.4953174293041229, 0.8625760078430176, 0.06249464675784111, -0.04008074477314949, 0.10229181498289108, -0.7631174921989441, -0.28987088799476624, 0.562272310256958, 1.1410770416259766, 0.6397328972816467, -0.1755698323249817, 0.5530191659927368, 0.9574765563011169, 0.2784993648529053, -0.04884723201394081, 0.18383508920669556, 0.257967084646225, 0.015621757134795189, 0.17885923385620117, -0.08773110061883926, 0.7861614227294922, -0.717031717300415, -0.774074137210846, 0.6827139258384705, 0.7679378986358643, 0.03205098956823349, 0.14198994636535645, 1.046055555343628, -0.11878607422113419, 0.6522669792175293, -0.2349368929862976, 0.9855501651763916, -0.13257938623428345, -0.7697890996932983, 0.19489149749279022, -0.6901716589927673, -0.37351980805397034, -0.15669779479503632, 0.011965141631662846, -0.36260512471199036, -0.5955870747566223, 0.3757903575897217, 0.3447939455509186, 0.15516458451747894, 0.5545012354850769, 0.4556400775909424, 0.9335222244262695, -0.07735669612884521, -0.7841609716415405, -0.3964352309703827, -0.5841728448867798, 0.004162594676017761, -0.4738055467605591, -0.22293031215667725, -0.257342666387558, -0.28916558623313904, -0.35810914635658264]}, "authors": [{"authorId": null, "name": "Yuezhou Hu"}, {"authorId": "2292367492", "name": "Kang Zhao"}, {"authorId": "2303522576", "name": "Wei Huang"}, {"authorId": "2276707", "name": "Jianfei Chen"}, {"authorId": "2287800407", "name": "Jun Zhu"}], "references": [{"paperId": "bdb68c5e2369633b20e733774ac66eb4600c34d1", "title": "LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "05deb6c1862b2f129d6652a09eaedbc1f655cc8f", "title": "STEP: Learning N: M Structured Sparsity Masks from Scratch with Precondition"}, {"paperId": "4b308ba40e67b0b4b25c6fde17195d5a456a2f41", "title": "Cramming: Training a Language Model on a Single GPU in One Day"}, {"paperId": "722e0640c064c4068c46a02fdf0ddf3037740ac3", "title": "Towards Fully Sparse Training: Information Restoration with Spatial Similarity"}, {"paperId": "b96fc157c6035978188ac8bb24c469fcd24ab5d5", "title": "Minimum Variance Unbiased N: M Sparsity for the Neural Gradients"}, {"paperId": "30342ef80d2d5dbb8b4e212356a7e19757e7111f", "title": "Accelerating DNN Training with Structured Data Gradient Pruning"}, {"paperId": "90d5e6f8d3b9f2617b3a3cf00fb02e730eb011cb", "title": "Accelerating Sparse Deep Neural Networks"}, {"paperId": "b4d207a2096aee4a3764933373eef6edb574c952", "title": "Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N: M Transposable Masks"}, {"paperId": "5e38dc1ccf33ac1df09b8eb6476f110cb3d1966f", "title": "Learning N: M Fine-grained Structured Sparse Neural Networks From Scratch"}, {"paperId": "0c9d97d2ba489256d4f1760598dc2c7be6d90d96", "title": "EarlyBERT: Efficient BERT Training via Early-bird Lottery Tickets"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "389036b1366b64579725457993c1f63a4f3370ba", "title": "The Lottery Ticket Hypothesis for Pre-trained BERT Networks"}, {"paperId": "f46c562229c5bc419bbbfb63239431590e4b340a", "title": "Train Big, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers"}, {"paperId": "c898b685d9167fe48d5a6401e2007c59ee0bdacc", "title": "Go Wide, Then Narrow: Efficient Training of Deep Thin Networks"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "2e3002f131e1815bda7a10303eff97f79dea01ec", "title": "Rigging the Lottery: Making All Tickets Winners"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "336868be817536e7c7fc88c391a2860cd869ea2b", "title": "Drawing early-bird tickets: Towards more efficient training of deep networks"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "075da5ebbb890924267b4b163292ad21d0b100a0", "title": "Stabilizing the Lottery Ticket Hypothesis"}, {"paperId": "cf440ccce4a7a8681e238b4f26d5b95109add55d", "title": "SNIP: Single-shot Network Pruning based on Connection Sensitivity"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "21937ecd9d66567184b83eca3d3e09eb4e6fbd60", "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "642d0f49b7826adcf986616f4af77e736229990f", "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"}, {"paperId": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff", "title": "Learning both Weights and Connections for Efficient Neural Network"}, {"paperId": "5ec85a0d88adcc4344bb5cc81b0d1aef9bcd8dcc", "title": "Findings of the 2014 Workshop on Statistical Machine Translation"}, {"paperId": "62c76ca0b2790c34e85ba1cce09d47be317c7235", "title": "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation"}, {"paperId": "3832057ac487f43e885cdb485a6ca1462834bb8d", "title": "Estimating or Propagating Gradients Through Stochastic Neurons"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": null, "title": "Exploiting nvidia ampere structured sparsity with cusparselt"}, {"paperId": null, "title": "Carbon-tracker: Tracking and predicting the carbon footprint of training deep learning models"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Openwebtext corpus"}, {"paperId": null, "title": "A method for stochastic optimization"}, {"paperId": null, "title": "Bi-directional masks for efficient"}, {"paperId": null, "title": "General language model pretraining with autoregressive blank"}]}