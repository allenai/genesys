{"paperId": "77706ee4cbdbb23345da22af37bc1b9f5ec8f110", "abstract": "The Transformer architecture has revolutionized deep learning on sequential data, becoming ubiquitous in state-of-the-art solutions for a wide variety of applications. Yet vanilla Transformers are notoriously resource-expensive, requiring $O(L^2)$ in serial time and memory as functions of input length $L$. Recent works proposed various linear self-attention mechanisms, scaling only as $O(L)$ for serial computation. We perform a thorough analysis of recent Transformer mechanisms with linear self-attention, Performers, in terms of overall computational complexity. We observe a remarkable computational flexibility: forward and backward propagation can be performed with no approximations using sublinear memory as a function of $L$ (in addition to negligible storage for the input sequence), at a cost of greater time complexity in the parallel setting. In the extreme case, a Performer consumes only $O(1)$ memory during training, and still requires $O(L)$ time. This discovered time-memory tradeoff can be used for training or, due to complete backward-compatibility, for fine-tuning on a low-memory device, e.g. a smartphone or an earlier-generation GPU, thus contributing towards decentralized and democratized deep learning.", "venue": "Neural Information Processing Systems", "year": 2020, "citationCount": 16, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A thorough analysis of recent Transformer mechanisms with linear self-attention, Performers, results in a remarkable computational flexibility: forward and backward propagation can be performed with no approximations using sublinear memory as a function of $L$ (in addition to negligible storage for the input sequence), at a cost of greater time complexity in the parallel setting."}, "embedding": {"model": "specter_v2", "vector": [0.2962419092655182, 0.8125109076499939, -0.2655326724052429, -0.13014569878578186, 0.06618338823318481, -0.02190224826335907, 0.5160359740257263, -0.1313977688550949, -0.7126181125640869, -0.42801183462142944, 0.08867660164833069, 0.051599882543087006, 0.6618013381958008, -0.10500933229923248, -0.41389337182044983, 0.028941387310624123, -1.1374906301498413, 0.0301862433552742, 0.3751232326030731, -0.12421895563602448, 0.06229885667562485, -0.2982281744480133, -1.176207423210144, 0.27360019087791443, 0.3564937114715576, 0.794611930847168, 0.17838340997695923, 0.9051088690757751, -0.17628508806228638, 0.8769892454147339, 0.4572637379169464, -0.20962584018707275, 0.42345643043518066, 0.2129906266927719, -0.36153262853622437, -0.33021748065948486, 0.7377105951309204, -0.4844073951244354, -0.4648662507534027, 0.6538254022598267, -0.08446719497442245, 0.17561592161655426, -0.16769930720329285, -0.7329255938529968, -0.1814817637205124, 0.7103307843208313, 0.6404418349266052, 0.9490039944648743, -0.4344409108161926, -0.3603275716304779, 1.3831346035003662, -1.3541969060897827, -0.14809751510620117, 1.0526628494262695, 0.755709707736969, 0.4239523112773895, -0.198599711060524, -0.5786656141281128, 0.9187381267547607, 0.35116925835609436, -0.6449581980705261, -0.5368823409080505, 0.10485837608575821, -0.059966668486595154, 1.7757353782653809, -0.4710147976875305, 0.16771413385868073, 0.4167977571487427, 0.12003595381975174, 1.6810734272003174, 0.3301565945148468, -0.6415786147117615, -0.07181110233068466, 0.25864505767822266, 0.5203749537467957, 1.043529748916626, -0.14801199734210968, 0.1038694679737091, -1.331905722618103, -0.03721732273697853, 0.6941240429878235, 0.12001757323741913, 0.06825767457485199, -0.6635404229164124, 0.0626491978764534, 0.8552090525627136, 0.81499183177948, 0.7964100241661072, -0.3298038840293884, 0.765758752822876, 0.6361889839172363, 0.23672258853912354, -0.06227553263306618, 0.28358539938926697, 0.22855886816978455, 0.47637149691581726, -1.4248007535934448, 0.20431655645370483, -0.048413071781396866, 0.8516978025436401, 0.04413806274533272, 0.3202793598175049, -0.4337503910064697, -0.13591352105140686, 1.030714511871338, -0.1402996927499771, 0.66439288854599, -0.4554390609264374, 0.12091249227523804, -0.7132366895675659, -0.010506083257496357, -0.46835407614707947, -0.4181611239910126, -0.6608690619468689, -1.1082767248153687, -0.8491822481155396, -0.49351295828819275, 0.476422518491745, -0.5767098665237427, 0.28780704736709595, -0.437389999628067, 0.02165791764855385, -0.2140776515007019, 0.49830928444862366, 0.3784193694591522, 0.2669389247894287, 0.09789144992828369, 0.16443301737308502, 0.9210080504417419, -1.3919376134872437, -0.39527297019958496, -1.2722399234771729, 0.34820860624313354, 0.05658091977238655, 0.262087345123291, -0.0687364861369133, -1.6025989055633545, -1.1615073680877686, -0.8978631496429443, 0.11139120161533356, -0.3693297207355499, 0.23675118386745453, 1.226333737373352, 0.16413109004497528, -1.4355686902999878, 1.1816084384918213, -0.5561334490776062, 0.11696082353591919, 0.736288845539093, 0.36849960684776306, 0.39704763889312744, -0.05159558355808258, -0.811501681804657, 0.22731491923332214, 0.11781246960163116, -0.45873555541038513, -0.47369998693466187, -0.7306365966796875, -0.7622470259666443, 0.046899646520614624, 0.24506111443042755, -0.3157099485397339, 1.2639663219451904, -0.46978235244750977, -0.7221410274505615, 1.043067455291748, -0.2874999940395355, -0.4203973710536957, 0.6328586935997009, -0.3546159863471985, -0.31106188893318176, -0.15747779607772827, -0.13276249170303345, 0.37262052297592163, 0.5925598740577698, -0.44606727361679077, -0.14660169184207916, -0.003567047882825136, -0.4333590269088745, -0.34601089358329773, -0.2696264386177063, 0.531112015247345, -0.4337952136993408, -0.21644747257232666, 0.43108752369880676, 0.6045671105384827, -0.21014845371246338, -0.1268395036458969, -0.3652140200138092, -1.0670781135559082, 0.4497664272785187, 0.26569244265556335, 1.1465805768966675, -1.052946925163269, -1.263095736503601, 0.1603023111820221, 0.3047104477882385, -0.1253160685300827, -0.6317203640937805, 0.22841618955135345, -0.36838462948799133, 0.22260722517967224, 0.024900177493691444, -0.8925862908363342, 0.031064588576555252, -0.4864402711391449, -0.6507089138031006, 0.02732284739613533, 0.04868856072425842, 0.9956046938896179, -1.0302314758300781, 0.0493505597114563, -0.2484668791294098, 0.277377724647522, -1.2356137037277222, 1.5294477939605713, -0.02574280835688114, -0.21611352264881134, 0.16283510625362396, -0.2998165786266327, 0.27154475450515747, -0.7594233155250549, 0.3662989139556885, -0.706552267074585, -0.226557195186615, 0.6308276653289795, -0.2923966646194458, 1.128831148147583, -0.41394880414009094, 0.9088259935379028, 0.2414640188217163, -0.7782511115074158, 0.018558282405138016, 0.06935399025678635, -0.13520528376102448, -0.6728267073631287, 0.1838996559381485, 0.11869202554225922, -0.6297847628593445, 0.5603227615356445, 0.899975597858429, 1.0952718257904053, -0.08432254195213318, 0.013167237862944603, 0.4997837543487549, 0.0987013727426529, 0.22350053489208221, 0.37115737795829773, 0.836077868938446, 0.4726509749889374, 0.30087167024612427, -0.09069810062646866, 0.1342676877975464, -0.8495847582817078, -0.1323159635066986, 0.9569449424743652, 0.43066105246543884, 0.3591885268688202, 0.09531824290752411, -0.7277936935424805, -0.5890306830406189, -0.09452260285615921, 0.6278203725814819, 1.722815990447998, -0.24327152967453003, 0.025470316410064697, -0.7438859939575195, -0.2666011452674866, -0.38779976963996887, -0.02395736798644066, -0.2809586822986603, -0.09084794670343399, -0.604835033416748, -0.8342256546020508, 0.7254496812820435, 0.5840994715690613, 1.469007968902588, -0.6007212996482849, -1.0221482515335083, 0.033128488808870316, 0.6923683881759644, -1.0024490356445312, -0.5253281593322754, 0.517204999923706, -0.8209686875343323, 0.06123741343617439, 0.02813662774860859, -0.10333366692066193, 0.2239869385957718, -0.47912460565567017, 1.1196775436401367, -0.26932334899902344, -0.3306638300418854, 0.26546111702919006, 0.7758567929267883, -0.3917643129825592, -0.2345133125782013, 0.21290716528892517, 0.07801671326160431, -0.16613103449344635, 0.22160856425762177, 0.005075567401945591, -0.6876161694526672, -0.028169892728328705, 0.03770758956670761, 0.04727623611688614, 0.45510348677635193, -0.1529460996389389, 0.48142069578170776, -0.26414158940315247, -0.12183939665555954, -1.3133224248886108, 0.7848531603813171, 0.3714343309402466, -0.2188403308391571, -0.09885567426681519, -1.149094581604004, -0.15785399079322815, 0.5453444719314575, -0.9130833745002747, 0.13874755799770355, -0.8477007746696472, 0.33217471837997437, -0.5947912931442261, -0.0005419095396064222, -0.4933609068393707, 0.4582253098487854, -0.35728612542152405, 0.17558787763118744, 0.8749668598175049, 0.1053331047296524, 0.06362738460302353, 0.4392186999320984, -1.1688625812530518, 0.7087559700012207, 0.4771912693977356, 0.4530104994773865, 0.13492396473884583, -0.22333581745624542, -0.47834378480911255, -0.6337307691574097, -0.30207452178001404, -0.15952731668949127, -0.3421666920185089, 0.23119951784610748, -0.6985196471214294, -1.3409440517425537, 0.08292035758495331, -0.9421516060829163, -0.54474276304245, 0.023245463147759438, -0.48808273673057556, -0.3227755129337311, -1.1605757474899292, -1.1509225368499756, -0.8248934149742126, -0.8597632646560669, -0.7582868933677673, -0.03678789734840393, 0.044399261474609375, -0.23981104791164398, -0.5079953074455261, -0.4749350845813751, -0.39410245418548584, 1.4097930192947388, -0.7261444330215454, 0.4124247133731842, -0.15168704092502594, -0.7098899483680725, -0.0358956903219223, -0.29999274015426636, 0.40476807951927185, -0.6179125905036926, -0.3390111029148102, -1.1193410158157349, -0.003365439362823963, -0.448883056640625, -0.4028843641281128, 0.37119260430336, 0.09660182148218155, 0.8573853373527527, -0.48098087310791016, -0.5155797600746155, 0.3954898416996002, 1.6818480491638184, -0.6781896352767944, 0.12484677881002426, 0.47506698966026306, 1.0519251823425293, -0.13048966228961945, -0.34404483437538147, 0.6228623390197754, 0.4380519390106201, 0.025285055860877037, 0.23325684666633606, -0.45077624917030334, -0.010440095327794552, -0.6624673008918762, 0.34932270646095276, 1.1666674613952637, 0.17421776056289673, 0.3625224828720093, -0.63454669713974, 0.5664407014846802, -1.0535311698913574, -0.9878512620925903, 0.8359020948410034, 0.7746720314025879, 0.23297925293445587, 0.055697549134492874, -0.20081102848052979, -0.08731541782617569, 0.07605167478322983, 0.547185480594635, -0.5842452049255371, -0.6540298461914062, 0.01655348390340805, 0.6366618871688843, 0.9316691160202026, 0.26361986994743347, -0.25744491815567017, 0.7169176936149597, 15.067708015441895, 0.5562546849250793, -0.1820247620344162, 0.9317492246627808, 0.6713588833808899, 0.1063246876001358, -0.2911350131034851, -0.03873135894536972, -1.180627465248108, -0.12795290350914001, 0.9968336820602417, 0.2327692061662674, 0.5654184818267822, 0.40148159861564636, 0.13991789519786835, 0.024647239595651627, -0.7531737685203552, 0.9258501529693604, 0.4771251380443573, -1.4966561794281006, 0.19281291961669922, 0.11944591999053955, 0.14994385838508606, 0.4056287705898285, 0.8969443440437317, 0.8363340497016907, 0.7727007269859314, -0.3387993276119232, 0.6274128556251526, 0.40646663308143616, 0.9817836880683899, 0.0022342561278492212, -0.04353545978665352, 0.46365630626678467, -1.0795437097549438, -0.1718069463968277, -0.41348791122436523, -1.0422337055206299, -0.023668911308050156, 0.27309221029281616, -0.1688293218612671, -0.705689549446106, 0.1473688781261444, 0.5193885564804077, 0.021922726184129715, 0.29742103815078735, 0.02306305430829525, 0.5704283714294434, 0.05801345780491829, -0.06867782026529312, 0.4681364595890045, 0.7892500758171082, -0.05874836444854736, -0.04884064570069313, -0.1637972742319107, 0.058409128338098526, -0.018541015684604645, 0.6262365579605103, -0.3881310522556305, -0.0032578303944319487, 0.03218325227499008, -0.18414010107517242, -0.021297359839081764, 0.6676254868507385, 0.6154696941375732, 0.2601449489593506, -0.16894376277923584, 0.7798470854759216, 0.9008810520172119, -0.061633337289094925, -0.3166540861129761, 0.07366036623716354, 0.07707621902227402, -0.12103578448295593, 0.2537478804588318, 0.26517513394355774, -0.2520520091056824, -0.4221529960632324, -0.5337712168693542, -0.5302304625511169, 0.21874476969242096, -0.8814259767532349, -0.32704588770866394, 0.9151746034622192, -0.6258178353309631, -0.2832556366920471, 0.7223094701766968, -0.8657370805740356, -0.540122926235199, 0.06822093576192856, -1.3368009328842163, -0.4153292775154114, 0.025294514372944832, -0.3604222238063812, -0.3588390648365021, -0.15448765456676483, 0.8329050540924072, 0.22846432030200958, -0.16874444484710693, 0.5442666411399841, -0.21328310668468475, -0.05455394461750984, -0.28982144594192505, -0.577226996421814, 0.7724810242652893, 0.115609310567379, -0.2665192186832428, 0.2039504200220108, 0.13076314330101013, 0.7231304049491882, -0.7741332054138184, 0.05208662897348404, 0.5837095379829407, -0.6118999123573303, -0.07633724808692932, -0.6952639818191528, -0.7419512271881104, 0.29134905338287354, 0.4391981065273285, -0.13140133023262024, 0.09318050742149353, -0.13534535467624664, -0.6495426893234253, -0.3668923079967499, -0.6737304925918579, 0.11269273608922958, 0.7383211851119995, -0.7749937772750854, -0.12313701212406158, -0.1841147541999817, 0.11892876774072647, -0.8352733254432678, -0.35927867889404297, -0.39834558963775635, 0.12626269459724426, -0.9004335403442383, 1.0019781589508057, -0.11052436381578445, 0.5712566375732422, 1.0782066583633423, 0.17100001871585846, -0.3339029550552368, -0.1861409991979599, -0.6814320683479309, 0.0031582117080688477, 0.2630636692047119, 0.38907402753829956, -0.4854663610458374, 0.7423552870750427, 0.7625715732574463, 0.4601098597049713, -0.6550527215003967, -0.4413071870803833, -0.2374258190393448, -0.33360975980758667, -0.7169802188873291, 0.17351247370243073, -0.01785392127931118, -0.39481425285339355, 0.08672785013914108, 0.36964187026023865, 0.2958546280860901, 0.41063475608825684, -0.5342957377433777, 0.2360793650150299, -0.18645071983337402, 0.027759963646531105, -0.5848230719566345, -0.45557430386543274, -1.7036664485931396, -0.08307020366191864, -1.2528700828552246, -0.20199516415596008, -1.0185463428497314, -0.4636681377887726, -0.283221572637558, -0.24464288353919983, 0.03278176859021187, 0.46420222520828247, -0.11571379005908966, -0.30693334341049194, -0.2653382420539856, -0.6468175053596497, 0.4015296995639801, 0.5823987722396851, -0.6116000413894653, 0.1359158605337143, 0.10300988703966141, 0.04550929740071297, 0.308330237865448, 0.38643378019332886, -0.31580471992492676, -0.4971249997615814, -0.9773712158203125, 0.5036616921424866, -0.23217564821243286, 0.20705018937587738, -1.0531611442565918, 0.9495032429695129, 0.5048856735229492, -0.08110582083463669, -0.4233899414539337, 0.24978597462177277, -1.2714924812316895, -0.6954403519630432, 0.6192020177841187, -0.7604809403419495, 0.3637341856956482, 0.24634751677513123, -0.5594227910041809, -0.15170110762119293, 0.6363247632980347, 0.2025713175535202, -1.2102515697479248, -1.0622694492340088, 0.42678749561309814, -0.5191285610198975, 0.3334471881389618, -0.2941597104072571, -0.3564485013484955, -1.0512704849243164, -0.18255358934402466, -0.20468421280384064, 0.42233771085739136, -0.38068580627441406, 0.568821132183075, 0.2536241114139557, -1.1416103839874268, 0.34351295232772827, 0.3790362477302551, -0.3197009563446045, 0.03918265178799629, 0.7512070536613464, 0.45483243465423584, -0.32420334219932556, 0.22679249942302704, 0.09211262315511703, 0.33279070258140564, -0.7309542894363403, 0.3557157814502716, 0.9880071878433228, -0.8152402639389038, -0.2021828293800354, 1.0828275680541992, -0.2957860231399536, -0.7303305864334106, 0.2559237480163574, -0.7875243425369263, -0.4132766127586365, -0.0533512607216835, 0.4471771717071533, 0.3307563364505768, -0.12481948733329773, 0.24279934167861938, -0.8539772033691406, 0.2565961182117462, -0.06941832602024078, -0.35863450169563293, 0.473103404045105, 0.05754135549068451, -0.3200056552886963, 0.6127930879592896, 0.8319253921508789, -0.5897029638290405, -0.9418631792068481, -0.9542087912559509, -0.3914201557636261, 0.058205071836709976, 0.5537981390953064, 0.044427063316106796, -0.8157358169555664, 0.9442663788795471, 0.6942745447158813, 0.29503145813941956, 0.2826080322265625, -0.21982240676879883, -0.002872540382668376, 0.6720651388168335, 0.23463627696037292, -0.769199013710022, -0.3069363534450531, 1.1437420845031738, 0.7794708609580994, -0.6903497576713562, 0.1879480481147766, -0.15709750354290009, -0.5116427540779114, 0.7107256054878235, 0.5658029317855835, -0.48524075746536255, 0.8673054575920105, 0.1198308989405632, -0.002334336983039975, 0.08320938050746918, -1.1426031589508057, -0.3154957592487335, 0.6046615242958069, 0.651033341884613, 0.7868412733078003, 0.13274991512298584, 0.32593631744384766, 0.8973534107208252, -0.198009192943573, 0.09804502129554749, 0.36556151509284973, 0.45171359181404114, -0.33322227001190186, 0.6597377061843872, 0.07382240891456604, 0.7042504549026489, -0.6947525143623352, -0.889180064201355, 0.6424609422683716, 0.5734848380088806, 0.08376886695623398, 0.34850504994392395, 1.1760517358779907, 0.07696057856082916, 0.725644052028656, 0.0819200798869133, 0.6250391006469727, -0.22707638144493103, -0.40038272738456726, -0.3454563021659851, -0.8791735768318176, -0.39027661085128784, -0.21701981127262115, -0.3334433436393738, -0.3388562500476837, -0.32518085837364197, 0.22347447276115417, -0.07325909286737442, 0.16573752462863922, 0.7052200436592102, 0.3526202142238617, 0.883825957775116, 0.04777539521455765, -0.8107722401618958, -0.4706014394760132, -0.5695102214813232, 0.2628161609172821, -0.5503399968147278, -0.10440365970134735, 0.017609240487217903, -0.48052963614463806, -0.38894733786582947]}, "authors": [{"authorId": "52314889", "name": "Valerii Likhosherstov"}, {"authorId": "1805203", "name": "K. Choromanski"}, {"authorId": "29827891", "name": "Jared Davis"}, {"authorId": "32725720", "name": "Xingyou Song"}, {"authorId": "145689461", "name": "Adrian Weller"}], "references": [{"paperId": "ca2f1088d3e581b2c6c75cf0ebc96506d620f64d", "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c"}, {"paperId": "df7d26339adf4eb0c07160947b9d2973c24911ba", "title": "Extracting Training Data from Large Language Models"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "91aeb0a3acf199883819d0d6bb30ee1d5b70b2fa", "title": "Linear Attention Mechanism: An Efficient Attention for Semantic Segmentation"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "0b991a1a5bcdb13646ac0b6873d09bde4cc36fb5", "title": "Masked Language Modeling for Proteins via Linearly Scalable Long-Context Transformers"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "8af925f4edf45131b5b6fed8aa655089d58692fa", "title": "Lite Transformer with Long-Short Range Attention"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "7f27e7bf9116ebeeeab1ef010fde5a4d6544ee14", "title": "Normalization"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "59a916cdc943f0282908e6f3fa0360f4c5fb78d0", "title": "Stabilizing Transformers for Reinforcement Learning"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "bc789aef715498e79a74f857fa090ece9e383bf1", "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes"}, {"paperId": "3c6dca9041f54583aeab60587c9e6e9272104dc1", "title": "Reducing BERT Pre-Training Time from 3 Days to 76 Minutes"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "bed7c155b843fda8a1c994ce71e9176e43b20f77", "title": "Factorized Attention: Self-Attention with Linear Complexities"}, {"paperId": "5dc62bdeb879e030a05d1d1bdab9a04de9d23b32", "title": "Transformer-XL: Language Modeling with Longer-Term Dependency"}, {"paperId": "449310e3538b08b43227d660227dfd2875c3c3c1", "title": "Neural Ordinary Differential Equations"}, {"paperId": "bf8fe437f779f2098f9af82b534aa51dc9edb06f", "title": "Scaling Neural Machine Translation"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "b36a5bb1707bb9c70025294b3a310138aae8327a", "title": "Automatic differentiation in PyTorch"}, {"paperId": "fdfa7dc73dc1fc6772d26f88c72e98b68d1f8498", "title": "Parallelizing Linear Recurrent Neural Nets Over Sequence Length"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "4361e64f2d12d63476fdc88faf72a0f70d9a2ffb", "title": "Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units"}, {"paperId": "942deb7d865b7782c03176d95e3a0d56cb71009e", "title": "Training Deep Nets with Sublinear Memory Cost"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e", "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "0b44fcbeea9415d400c5f5789d6b892b6f98daff", "title": "Building a Large Annotated Corpus of English: The Penn Treebank"}, {"paperId": "995538af8de9868713128b35c511810445e65916", "title": "Parallel Prefix Computation"}, {"paperId": null, "title": "2020) propose the following algorithm for computation of (3-4). Initialize buffers curR = 0d\u00d7M"}, {"paperId": null, "title": "2020) use low-level CUDA extensions to make the algorithm practical"}, {"paperId": null, "title": "Dawn Song, \u00dalfar Erlingsson, Alina Oprea, and Colin Raffel"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "TensorFlow: Largescale machine learning on heterogeneous systems"}, {"paperId": null, "title": "Software available from tensorflow.org"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": null, "title": "Large text compression benchmark"}, {"paperId": null, "title": "Sub-Linear Memory: How to Make Performers SLiM"}, {"paperId": "7d77bab7757fa4dd07a7873b3e3e8491025cbf8c", "title": "Thinking in Parallel: Some Basic Data-Parallel Algorithms and Techniques"}, {"paperId": "cb11771cbfd45aa09e00f1f3b0fc156a087fa544", "title": "Evaluating derivatives - principles and techniques of algorithmic differentiation, Second Edition"}, {"paperId": "fad51de16c93a9803caeecd413fcba9962109712", "title": "Achieving logarithmic growth of temporal and spatial complexity in reverse automatic differentiation"}, {"paperId": null, "title": "We outline conditions when the algorithm can be extended beyond Performers"}, {"paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5", "title": "of the Association for Computational Linguistics"}]}