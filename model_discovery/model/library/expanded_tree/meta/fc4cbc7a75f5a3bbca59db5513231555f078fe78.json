{"paperId": "fc4cbc7a75f5a3bbca59db5513231555f078fe78", "abstract": "MetaFormer, the abstracted architecture of Transformer, has been found to play a significant role in achieving competitive performance. In this paper, we further explore the capacity of MetaFormer, again, by migrating our focus away from the token mixer design: we introduce several baseline models under MetaFormer using the most basic or common mixers, and demonstrate their gratifying performance. We summarize our observations as follows: <list list-type=\"ordered\"> <list-item><label>1)</label><p><italic>MetaFormer ensures solid lower bound of performance:</italic> By merely adopting identity mapping as the token mixer, the MetaFormer model, termed <italic>IdentityFormer</italic>, achieves <inline-formula><tex-math notation=\"LaTeX\">$> $</tex-math><alternatives><mml:math><mml:mo>></mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq1-3329173.gif\"/></alternatives></inline-formula>80% accuracy on ImageNet-1 K.</p></list-item> <list-item><label>2)</label><p><italic>MetaFormer works well with arbitrary token mixers:</italic> When specifying the token mixer as even a random matrix to mix tokens, the resulting model <italic>RandFormer</italic> yields an accuracy of <inline-formula><tex-math notation=\"LaTeX\">$> $</tex-math><alternatives><mml:math><mml:mo>></mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq2-3329173.gif\"/></alternatives></inline-formula>81%, outperforming IdentityFormer. Rest assured of MetaFormer's results when new token mixers are adopted.</p></list-item> <list-item><label>3)</label><p><italic>MetaFormer effortlessly offers state-of-the-art results:</italic> With just conventional token mixers dated back five years ago, the models instantiated from MetaFormer already beat state of the art.</p></list-item> </list> <list list-type=\"ordered\"> <list-item><label>a)</label><p><italic>ConvFormer outperforms ConvNeXt:</italic> Taking the common depthwise separable convolutions as the token mixer, the model termed <italic>ConvFormer</italic>, which can be regarded as pure CNNs, outperforms the strong CNN model ConvNeXt.</p></list-item> <list-item><label>b)</label><p><italic>CAFormer sets new record on ImageNet-1 K:</italic> By simply applying depthwise separable convolutions as token mixer in the bottom stages and vanilla self-attention in the top stages, the resulting model <italic>CAFormer</italic> sets a new record on ImageNet-1 K: it achieves an accuracy of 85.5% at <inline-formula><tex-math notation=\"LaTeX\">$224 \\times 224$</tex-math><alternatives><mml:math><mml:mrow><mml:mn>224</mml:mn><mml:mo>\u00d7</mml:mo><mml:mn>224</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href=\"wang-ieq3-3329173.gif\"/></alternatives></inline-formula> resolution, under normal supervised training without external data or distillation.</p></list-item> </list> In our expedition to probe MetaFormer, we also find that a new activation, <italic>StarReLU</italic>, reduces 71% FLOPs of activation compared with commonly-used GELU yet achieves better performance. Specifically, StarReLU is a variant of Squared ReLU dedicated to alleviating distribution shift. We expect StarReLU to find great potential in MetaFormer-like models alongside other neural networks.", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2022, "citationCount": 63, "influentialCitationCount": 9, "openAccessPdf": {"url": "https://arxiv.org/pdf/2210.13452", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "The capacity of MetaFormer is explored, again, by migrating the focus away from the token mixer design, and several baseline models under MetaFormer are introduced using the most basic or common mixers, and demonstrate their gratifying performance."}, "embedding": {"model": "specter_v2", "vector": [0.41585081815719604, 0.6489917635917664, -0.3997025489807129, 0.3608311116695404, -0.6639637351036072, 0.2688978612422943, 0.8068560361862183, -0.61423659324646, -0.46299871802330017, -0.6320568323135376, 0.6803215146064758, 0.7815541625022888, 0.2563053369522095, -0.08232619613409042, 0.16710588335990906, -0.35140159726142883, -0.8426838517189026, -0.35848304629325867, -0.21389472484588623, -0.18628370761871338, 0.18268203735351562, -0.3540216386318207, -1.0184887647628784, 0.5295019745826721, 0.12956209480762482, 0.9510217905044556, 0.3914455473423004, 0.9324953556060791, -0.13260462880134583, 0.7700532078742981, 0.48621875047683716, -0.32847532629966736, 0.8016210794448853, -0.05169142410159111, 0.224759042263031, -0.09056196361780167, 1.1256024837493896, -0.716202437877655, -1.0682612657546997, 0.959311842918396, 0.2535276710987091, 0.17490236461162567, 0.44589370489120483, -0.9500443339347839, -0.00256164837628603, 0.7142419815063477, 0.4132891595363617, 0.9237090945243835, -0.6987671256065369, -0.43586549162864685, 1.3082383871078491, -1.3404476642608643, 0.08183535933494568, 1.569525122642517, 0.5332496166229248, 0.031606145203113556, -0.07996688038110733, -0.6975595951080322, 0.8245465159416199, 0.03426138311624527, -0.5807245969772339, -0.4864761233329773, 0.2621273398399353, 0.052424944937229156, 1.1528927087783813, -0.5732851028442383, -0.18603277206420898, 0.7977818846702576, 0.44476020336151123, 1.2040202617645264, 0.37706634402275085, -0.6461210250854492, -0.19822707772254944, -0.020181145519018173, 0.279955118894577, 0.7424454092979431, -0.20065274834632874, 0.3312104642391205, -1.4241646528244019, 0.030425716191530228, 0.7472270131111145, 0.07963339984416962, -0.04333914443850517, 0.025921322405338287, -0.7939172387123108, 0.3722843825817108, 0.6905881762504578, 0.634971022605896, -0.5738925337791443, 0.7749603390693665, 0.35055404901504517, 0.22197119891643524, -0.18437059223651886, 0.23279060423374176, 0.567537784576416, 0.8473439812660217, -0.8755653500556946, 0.11096043884754181, -0.15261876583099365, 0.8491823673248291, -0.3192424476146698, 0.3015446364879608, -0.7577682733535767, 0.008546339347958565, 1.7954304218292236, 0.4367619752883911, 0.6003106236457825, -0.7434872984886169, 0.4510593116283417, -0.9673846364021301, 0.4157434105873108, -1.006479024887085, 0.004858662839978933, -0.6862943768501282, -1.0841906070709229, -0.5764090418815613, -0.18757477402687073, 0.8190613389015198, -1.1984471082687378, 0.32061177492141724, -0.8192238807678223, 0.23488353192806244, -0.033827826380729675, 0.6884849071502686, 0.46438413858413696, 0.3621736466884613, 0.3985133767127991, 0.02963537909090519, 1.1127303838729858, -1.3296489715576172, -0.6125781536102295, -0.6968758702278137, -0.31000038981437683, -0.3343575894832611, 0.05965203419327736, 0.1300058662891388, -0.9711740612983704, -1.3911899328231812, -0.9950094819068909, 0.23511871695518494, -0.6721897721290588, 0.13904356956481934, 1.0145764350891113, 0.49405160546302795, -1.2371113300323486, 0.47502294182777405, -0.4352254271507263, -0.13667193055152893, 0.5167835354804993, 0.18910421431064606, 0.24788883328437805, 0.11874619871377945, -0.8323095440864563, 0.5197881460189819, -0.05164877325296402, 0.12117329239845276, -0.5403814315795898, -0.6411694884300232, -0.5486859083175659, -0.17524453997612, -0.22859470546245575, -0.8178339004516602, 0.9861102104187012, -0.12309747189283371, -0.8786864280700684, 0.5358187556266785, -0.27103424072265625, -0.2516915500164032, 0.6145486235618591, -0.09692293405532837, -0.5200293660163879, -0.07427646219730377, -0.10279039293527603, 0.7745597958564758, 0.5388051271438599, -0.5111919045448303, -0.5201334357261658, -0.07127369940280914, -0.2844284474849701, -0.0531373955309391, -0.2761134207248688, 0.7822048664093018, -0.2205108255147934, -0.6436966061592102, 0.9280329346656799, 0.9009129405021667, -0.478823721408844, -0.07550811767578125, -0.11771131306886673, -0.5560408234596252, 0.34296807646751404, 0.24692144989967346, 0.4467133581638336, -0.7569915652275085, -1.0334688425064087, 0.11756585538387299, 0.17836089432239532, -0.43504324555397034, -1.1866883039474487, 0.43474280834198, -0.2011387050151825, 0.13134397566318512, 0.6416290402412415, -1.0303113460540771, 0.1971753090620041, -0.5268354415893555, -1.0464264154434204, 0.17914500832557678, -0.14363564550876617, 1.0661845207214355, -0.9276739954948425, 0.0684349462389946, 0.14683417975902557, 0.35717424750328064, -0.7063980102539062, 1.2036213874816895, 0.2691642940044403, -0.16340216994285583, -0.15753304958343506, 0.17880703508853912, 0.4395546317100525, -0.22482804954051971, 0.4388708472251892, -1.0748369693756104, -0.1533372551202774, 0.32981568574905396, -0.9253984093666077, 1.43441903591156, -0.1400083601474762, 0.6461135745048523, 0.09379000961780548, -0.6961298584938049, 0.2613934278488159, 0.26710206270217896, 0.13979780673980713, -0.7068307399749756, 0.2743688225746155, 0.20778627693653107, -0.6384248733520508, 0.49794018268585205, 0.8031402826309204, 1.100574016571045, 0.05911729857325554, -0.08833946287631989, 0.7576673626899719, 0.12940789759159088, 0.09009382873773575, 0.38939690589904785, 0.42273518443107605, -0.0751696228981018, 0.06053904443979263, -0.3647434115409851, -0.047586724162101746, -1.1728277206420898, -0.17618831992149353, 1.444712519645691, 0.41668882966041565, 1.152618169784546, -0.06828319281339645, -0.7914400696754456, -0.22632084786891937, -0.7646551132202148, 0.5955401659011841, 1.1036794185638428, 0.43957164883613586, -0.08250275254249573, -0.3484138250350952, -0.11077024787664413, -0.4466067850589752, -0.6329089403152466, -0.34141603112220764, 0.12495798617601395, -0.48221734166145325, -1.2847707271575928, 0.8389171361923218, 0.5228129029273987, 1.3658382892608643, -0.6258050203323364, -0.7257570028305054, -0.17768265306949615, 0.1284361332654953, -0.731900155544281, -0.709308922290802, 0.23547689616680145, -0.6291422843933105, -0.18664038181304932, -0.3966832458972931, -0.0873795822262764, 0.26411834359169006, -0.18593154847621918, 0.5816398859024048, -0.8254347443580627, -0.28986069560050964, 0.4754725396633148, 0.5705961585044861, -0.5066220164299011, -0.17709051072597504, -0.1372910737991333, 0.11873302608728409, 0.2776104509830475, -0.28065115213394165, -0.158265620470047, -0.41357117891311646, 0.11725915968418121, -0.07788427919149399, 0.22645896673202515, 0.48477116227149963, 0.30790069699287415, 0.5790590643882751, -0.2201090306043625, 0.10182806849479675, -0.7641260623931885, 0.950196385383606, 0.44012778997421265, -0.352682888507843, 0.10631228983402252, -0.830511748790741, -0.4675125479698181, 0.016821110621094704, -0.5797196626663208, -0.16150285303592682, -0.7506881356239319, 0.3787417709827423, -0.6190330982208252, -0.03514425456523895, -0.10146772116422653, -0.016392052173614502, -0.06452763080596924, 0.3151009678840637, 0.49129384756088257, 0.00904848799109459, -0.06301680207252502, 0.8173185586929321, -0.6375442743301392, 0.9823176860809326, 0.4219396710395813, 0.2556775212287903, 0.5401418805122375, -0.08989434689283371, -0.727209746837616, -0.3480880856513977, -0.7783615589141846, -0.319597065448761, -0.7369650602340698, 0.0003282421384938061, -0.796317994594574, -1.0531879663467407, 0.6469791531562805, -1.031274437904358, 0.22634257376194, 0.11374976485967636, -0.12765419483184814, -0.5079597234725952, -1.2298991680145264, -0.7712092995643616, -0.8099502921104431, -0.7906873822212219, -0.7889038324356079, 0.2636365592479706, 0.40278229117393494, 0.20974262058734894, -0.31834688782691956, -0.20148825645446777, -0.24113862216472626, 1.2025713920593262, -0.14854595065116882, 0.23553098738193512, -0.2429697960615158, -0.9244450926780701, -0.17507217824459076, 0.025302432477474213, 0.5790824890136719, -0.07588467001914978, 0.0940781757235527, -1.3190828561782837, 0.31233885884284973, -0.20791547000408173, 0.15409983694553375, 0.6886438131332397, 0.5064763426780701, 0.3113527297973633, -0.1089882105588913, -0.7581562399864197, 0.4573221802711487, 1.3068962097167969, -0.41229984164237976, 0.4270869493484497, 0.19677121937274933, 0.8350350856781006, -0.16449646651744843, -0.3179578483104706, 0.5950751304626465, 0.24101293087005615, 0.2500308156013489, 0.402994304895401, -0.5711423754692078, -0.5391424298286438, -0.5954446196556091, 0.3878861963748932, 0.9522988200187683, 0.12755347788333893, -0.27943316102027893, -0.696087658405304, 0.6536747813224792, -1.4030333757400513, -1.3418456315994263, 0.6799613237380981, 0.8725054264068604, -0.2646900713443756, -0.10319112241268158, -0.07388321310281754, -0.1385461986064911, 0.6990180015563965, 0.6972963213920593, -0.055702243000268936, -0.08739595115184784, -0.24756595492362976, 0.8801792860031128, 0.462327241897583, 0.6027345657348633, -0.7082669734954834, 0.2097548097372055, 14.960675239562988, 0.5548967123031616, -0.21580873429775238, 0.5409769415855408, 0.673851728439331, 0.3472907245159149, -0.05564988777041435, -0.06176063418388367, -1.0605764389038086, -0.005226454231888056, 0.673586368560791, 0.14057816565036774, 0.42090296745300293, 0.23963569104671478, 0.0012231534346938133, 0.09362395107746124, -0.5653053522109985, 1.011946439743042, 0.6112982630729675, -1.5010292530059814, 0.5137831568717957, 0.3621613085269928, 0.3542315363883972, 0.6487055420875549, 0.8780832886695862, 0.34979602694511414, 0.0030152027029544115, -0.5704023241996765, 0.7460921406745911, 0.6836579442024231, 0.34627416729927063, 0.1637244075536728, 0.18804915249347687, 0.16474364697933197, -1.1090114116668701, -0.1732722520828247, -0.6247096061706543, -0.8917102217674255, 0.02479827217757702, 0.25741899013519287, -0.33572691679000854, -0.3345780670642853, -0.10613785684108734, 0.5346329808235168, 0.22046135365962982, 0.7037279009819031, 0.03830122947692871, 0.2472962886095047, -0.26339179277420044, 0.29406002163887024, 0.19751760363578796, 0.7358529567718506, 0.34522151947021484, 0.21854011714458466, -0.2113586962223053, 0.09522268921136856, 0.40795066952705383, 0.4449809789657593, -0.6240944266319275, -0.2502923607826233, -0.1355365812778473, -0.09325859695672989, -0.06826421618461609, 1.4355815649032593, -0.10337112843990326, 0.18110373616218567, -0.04935402423143387, 0.07588423043489456, -0.04985735937952995, 0.14042054116725922, -0.5110570192337036, -0.3895316421985626, 0.48333168029785156, -0.31246721744537354, -0.1812237948179245, 0.3567335903644562, -0.29532375931739807, -0.5604183077812195, -0.7705228328704834, -0.31961315870285034, 0.38551950454711914, -0.8965587615966797, -0.8683597445487976, 1.1343730688095093, -0.16342411935329437, -0.39530515670776367, 0.6602329015731812, -1.0831412076950073, -0.551002562046051, 0.41984647512435913, -1.5002979040145874, -1.1979268789291382, -0.3276330232620239, -0.3012709319591522, -0.2608667314052582, -0.3473469018936157, 0.497802197933197, -0.0758688747882843, 0.3640650510787964, 0.5053128600120544, -0.22997073829174042, 0.1980624794960022, -0.2070796638727188, -0.4573494493961334, 0.6674949526786804, 0.37972110509872437, 0.5111242532730103, 0.35924583673477173, 0.028396716341376305, 0.7150412201881409, -0.6663095355033875, 0.18923097848892212, 0.4043230414390564, -0.5578941702842712, -0.21349315345287323, -0.8046194911003113, -0.32149162888526917, -0.035498976707458496, 0.981415331363678, -0.008832293562591076, -0.348838210105896, -0.052887093275785446, -0.6720566749572754, -0.5773858428001404, -0.46714654564857483, 0.036346301436424255, 0.5713534355163574, -0.5541396141052246, -0.3991858661174774, -0.20684148371219635, -0.46061402559280396, -0.9981343746185303, -0.36582157015800476, -0.07040641456842422, 0.6008108854293823, -0.5323895812034607, 1.3746732473373413, -0.40777310729026794, 0.32556429505348206, 0.5253978967666626, -0.4199809432029724, -0.6434965133666992, -0.08926323056221008, -1.0377377271652222, 0.391324907541275, 0.2043701708316803, 0.1361938863992691, -0.6000984311103821, 0.09156806766986847, 0.2548896074295044, 0.34297364950180054, -0.4943147897720337, -0.9749733805656433, -0.3467344641685486, -0.2777937650680542, -0.37429431080818176, -0.026081938296556473, -0.38936883211135864, 0.03364325687289238, -0.31903594732284546, 0.45992445945739746, 0.7456297278404236, 0.3416558802127838, -0.3743617534637451, 0.35164007544517517, 0.050233062356710434, -0.039762482047080994, -0.7098529934883118, -0.9248595833778381, -1.6217963695526123, -0.014119907282292843, -1.1018567085266113, 0.11652033030986786, -1.0910005569458008, -0.38142257928848267, 0.28990116715431213, -0.8582549095153809, -0.024062497541308403, 0.5947588086128235, 0.12422285974025726, 0.12252163887023926, -0.3069603145122528, -0.3634299039840698, 0.5977362394332886, 1.0644781589508057, -1.1865103244781494, 0.24979811906814575, -0.02866031788289547, -0.16886228322982788, 0.5389006733894348, 0.27340736985206604, -0.3331361711025238, -0.7910423278808594, -0.8271524310112, -0.09505736082792282, 0.0003756161022465676, 0.23355767130851746, -1.223812222480774, 1.274532437324524, 0.40600019693374634, 0.2626000642776489, -0.009305275045335293, 0.48262372612953186, -0.7795475721359253, -0.3172057569026947, 0.35186341404914856, -1.071652889251709, 0.4202463924884796, -0.25436294078826904, -0.58763188123703, -0.2951660752296448, 1.2035759687423706, 0.2868659794330597, -1.0378336906433105, -0.6243479251861572, 0.49414053559303284, -0.5989482998847961, 0.1390802413225174, -0.30912497639656067, -0.41714999079704285, -1.122437596321106, -0.2667120695114136, -0.2581319808959961, 0.1458517163991928, -0.7722985148429871, 1.1923257112503052, 0.7118476629257202, -1.2144529819488525, -0.12414055317640305, 0.4029734134674072, -0.33342933654785156, -0.6289351582527161, 0.3395073115825653, 0.517866849899292, -0.08961916714906693, 0.2511892318725586, -0.23761147260665894, 0.1880766749382019, -0.5795467495918274, -0.11291288584470749, 1.1760549545288086, -0.37380722165107727, -0.19946520030498505, 1.028061032295227, -0.080147884786129, -0.06312955170869827, 0.37539446353912354, -1.0591012239456177, -0.1775609403848648, 0.09413550794124603, 0.8010146021842957, 0.5128907561302185, -0.04318932071328163, -0.2143126279115677, -0.7502210736274719, 0.04826795309782028, -0.273460328578949, -0.7423423528671265, 0.24740928411483765, 0.11827608197927475, -0.07712668180465698, 0.1775849461555481, 0.4108829200267792, -0.5298435091972351, -0.8092730045318604, -0.3289772570133209, -0.36716127395629883, -0.4908006191253662, 0.33493736386299133, -0.4270741045475006, -0.9127407670021057, 0.7359194755554199, 1.2521926164627075, 0.09949337691068649, 0.5597196817398071, -0.3355681896209717, -0.3309711813926697, 0.5258095264434814, 0.2573221027851105, -0.6033132076263428, -0.3399258255958557, 0.7775595784187317, 1.2199633121490479, -0.4178523123264313, 0.1977699100971222, 0.012827028520405293, -0.17219744622707367, 0.7673322558403015, 0.3524625599384308, -0.5926046371459961, 0.8413705229759216, 0.16217036545276642, 0.5007228255271912, 0.5009818077087402, -0.9984772801399231, -0.45345211029052734, 0.7969623804092407, 1.285834789276123, 0.45461753010749817, -0.11276121437549591, 0.22096997499465942, 0.6673139333724976, 0.40837761759757996, -0.3260139524936676, 0.31107380986213684, 0.07427748292684555, -0.09262747317552567, 0.056773845106363297, -0.08454486727714539, 0.3554398715496063, -0.4150371551513672, -0.6188323497772217, 0.325223445892334, 0.848365068435669, 0.250163197517395, 0.7596986293792725, 0.7464604377746582, -0.0025723481085151434, 0.8714767098426819, -0.11453636735677719, 0.9000928997993469, -0.08281989395618439, -0.45040974020957947, 0.25749316811561584, -1.0234074592590332, -0.3145815432071686, -0.6839948892593384, -0.5135994553565979, 0.11595766246318817, 0.015493901446461678, 0.22860389947891235, -0.1964462846517563, 0.10265597701072693, 0.7501795291900635, 0.32998114824295044, 0.3887637257575989, -0.052893586456775665, -0.895512580871582, -0.38675636053085327, -1.0054967403411865, -0.013675129972398281, -0.573434054851532, 0.09332738816738129, -0.44112104177474976, 0.023405123502016068, 0.08470039069652557]}, "authors": [{"authorId": "23476952", "name": "Weihao Yu"}, {"authorId": "39927579", "name": "Chenyang Si"}, {"authorId": "2153245275", "name": "Pan Zhou"}, {"authorId": "2109495772", "name": "Mi Luo"}, {"authorId": "1864078340", "name": "Yichen Zhou"}, {"authorId": "33221685", "name": "Jiashi Feng"}, {"authorId": "143653681", "name": "Shuicheng Yan"}, {"authorId": "48631088", "name": "Xinchao Wang"}], "references": [{"paperId": "3e448df5aa191f7a3945d0fd609c8bc5966a2333", "title": "HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions"}, {"paperId": "0307caf20f0ea22d6ae979b65c7ab85f3abf2af1", "title": "Dual Vision Transformer"}, {"paperId": "d1869155960e4b1b882b39171dbecd25a7eda3cd", "title": "More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity"}, {"paperId": "fd4c076e0229ccd1a992cb89285d14fd4adcb7ad", "title": "Can CNNs Be More Robust Than Transformers?"}, {"paperId": "270195c8ecc14b98a206461282b88f8fae798932", "title": "Vision GNN: An Image is Worth Graph of Nodes"}, {"paperId": "dbf6e95cb618f207f029276a6df11f4a9a6313d4", "title": "Inception Transformer"}, {"paperId": "44aa16ed0f3e22c82b10fcc9d23459ecfb7fcdb3", "title": "Sequencer: Deep LSTM for Image Classification"}, {"paperId": "05f6d8319fd30e56e0216a708e1bb74b7d763ac8", "title": "Understanding The Robustness in Vision Transformers"}, {"paperId": "ad7bcec33f5206d4f28687a6a5a950de67010651", "title": "Neighborhood Attention Transformer"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc", "title": "MaxViT: Multi-Axis Vision Transformer"}, {"paperId": "fa717a2e31f0cef4e26921f3b147a98644d2e64c", "title": "Focal Modulation Networks"}, {"paperId": "9f1b0e4c42a5a85d4c023030557ade4419f82ecf", "title": "Scaling Up Your Kernels to 31\u00d731: Revisiting Large Kernel Design in CNNs"}, {"paperId": "ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2", "title": "Visual attention network"}, {"paperId": "c8831d0629f0eaf7f723317d71bbd60b8eb3c39f", "title": "UniFormer: Unified Transformer for Efficient Spatiotemporal Representation Learning"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "9137efc758f80dd22bb56f82cca5c94f78a5db3e", "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and Detection"}, {"paperId": "e0e6ae2ef8ef9f02e0c65ada61eadd82b7ce8a9c", "title": "Shunted Self-Attention via Multi-Scale Token Aggregation"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "2582a04918f6fe62dc142f2fca9ca0bb0b1d7895", "title": "NormFormer: Improved Transformer Pretraining with Extra Normalization"}, {"paperId": "f454f6b5f2ca9749ddf442eb5134612ef7f758c1", "title": "ResNet strikes back: An improved training procedure in timm"}, {"paperId": "4a8964ea0de47010fb458021b68fa3ef5c4b77b2", "title": "Primer: Searching for Efficient Transformers for Language Modeling"}, {"paperId": "abc6708e013413cd4e69d3caeeb95a28a18e3bdf", "title": "A Battle of Network Structures: An Empirical Study of CNN, Transformer, and MLP"}, {"paperId": "f75cddf2d42ed01b34686704eb3504becef67442", "title": "CycleMLP: A MLP-like Architecture for Dense Prediction"}, {"paperId": "71363797140647ebb3f540584de0a8758d2f7aa2", "title": "AS-MLP: An Axial Shifted MLP Architecture for Vision"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "9b6af0e358e76d22f209c75b1702c3e6ea7815b1", "title": "Global Filter Networks for Image Classification"}, {"paperId": "2435ffb8ed3212156d6b6f19f633a861399cf30e", "title": "Vision Permutator: A Permutable MLP-Like Architecture for Visual Recognition"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "6b6ffb94626e672caffafc77097491d9ee7a8682", "title": "On the Connection between Local Attention and Dynamic Depth-wise Convolution"}, {"paperId": "8602fd5b0ac73bb422f238b265479f363c0ffe61", "title": "Refiner: Refining Self-attention for Vision Transformers"}, {"paperId": "77366bef01df1ab277149b330336a0ef9c5041c4", "title": "Transformer"}, {"paperId": "b8cee43a51c44f8f4448e78e41ecf081987707cf", "title": "Towards Robust Vision Transformer"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "title": "FNet: Mixing Tokens with Fourier Transforms"}, {"paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5", "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "8f8f73f0f208302546c825ed474432389ed63be4", "title": "EfficientNetV2: Smaller Models and Faster Training"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "51f46cb42668cfe3745ecf029d032bf30253574f", "title": "GradInit: Learning to Initialize Neural Networks for Stable and Efficient Training"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "022622e024890d6e044ac50e2da6b44c59bdf418", "title": "The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization"}, {"paperId": "13da774fe604027bff2951ba82f4c3d9be7e415e", "title": "Augment Your Batch: Improving Generalization Through Instance Repetition"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "0170fc76e934ee643f869df18fb617d5357e8b4e", "title": "Conformer: Convolution-augmented Transformer for Speech Recognition"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "8d908042f139575d6688c745e94156c9df6eae07", "title": "Understanding the Difficulty of Training Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "c5e475417ad4bb22175e170f52f8ebf1e042a42d", "title": "Dynamic ReLU"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "d6b414487787d0b6efd735a3236a690ad13aae70", "title": "TENER: Adapting Transformer Encoder for Named Entity Recognition"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "29962ae812e7142f56f5f67c2db9d00ab3dfa4c4", "title": "T-GSA: Transformer with Gaussian-Weighted Self-Attention for Speech Enhancement"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "dfc7b58b67c31932b48586b3e23a43cc94695290", "title": "UNITER: UNiversal Image-TExt Representation Learning"}, {"paperId": "54416048772b921720f19869ed11c2a360589d03", "title": "UNITER: Learning UNiversal Image-TExt Representations"}, {"paperId": "5aec474c31a2f4b74703c6f786c0a8ff85c450da", "title": "VisualBERT: A Simple and Performant Baseline for Vision and Language"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "45557cc70cd6989ab6b03e5aeb787e34299099f7", "title": "Natural Adversarial Examples"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "4ae0c4a511697e960c477ea3e37b3e11bf3e0e02", "title": "Learning Robust Global Representations by Penalizing Local Predictive Power"}, {"paperId": "f2bb7e2f5a1afad5370159c15760c44df93c0438", "title": "Very Deep Self-Attention Networks for End-to-End Speech Recognition"}, {"paperId": "bc789aef715498e79a74f857fa090ece9e383bf1", "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes"}, {"paperId": "49b64383fe36268410c430352637ed23b16820c5", "title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations"}, {"paperId": "1e7678467b1807777dcd9be557b79328ce9419a8", "title": "MultiGrain: a unified image embedding for classes and instances"}, {"paperId": "fea820b7d953d32069e189af2961c28fd213470b", "title": "Pay Less Attention with Lightweight and Dynamic Convolutions"}, {"paperId": "9f2dd5cc190fc713f1339fca838a5537931744f8", "title": "Neural Speech Synthesis with Transformer Network"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "de95601d9e3b20ec51aa33e1f27b1880d2c44ef2", "title": "CBAM: Convolutional Block Attention Module"}, {"paperId": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4", "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"}, {"paperId": "04957e40d47ca89d38653e97f728883c0ad26e5d", "title": "Cascade R-CNN: Delving Into High Quality Object Detection"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "424a6e62084d919bfc2e39a507c263e5991ebdad", "title": "Self-Normalizing Neural Networks"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "5b6ec746d309b165f9f9def873a2375b6fb40f3d", "title": "Xception: Deep Learning with Depthwise Separable Convolutions"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "d6f2f611da110b5b5061731be3fc4c7f45d8ee23", "title": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd", "title": "ImageNet Large Scale Visual Recognition Challenge"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "4dbc68cf2e14155edb6da0def30661aca8c96c22", "title": "Simplifying ConvNets for Fast Learning"}, {"paperId": "a538b05ebb01a40323997629e171c91aa28b8e2f", "title": "Rectified Linear Units Improve Restricted Boltzmann Machines"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "79ad463104c7b7afeab11c2046fe7c18d5108ac6", "title": "Pattern"}, {"paperId": "6dc61f37ecc552413606d8c89ffbc46ec98ed887", "title": "Acceleration of stochastic approximation by averaging"}, {"paperId": "b9124861e4e874bbc477b4b726adf94f7d2ecdc4", "title": "Learning"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "5a9bc55f6332e38f62eb509b684147a1d4f10fd9", "title": "Focal Attention for Long-Range Interactions in Vision Transformers"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9dca2dcad6798862d2756b1727cea332902f8fc8", "title": "TRANSFORMER WITH GAUSSIAN WEIGHTED SELF-ATTENTION FOR SPEECH ENHANCEMENT"}, {"paperId": null, "title": "science fromPekingUniversity,in2016,andthePhD degree in computer science from the National University of Singapore"}, {"paperId": null, "title": "Pytorch image models"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Stack Overflow users. How many flops does tanh need?"}, {"paperId": "6038d62f22be3162324d3cb5214512966fc6ddb0", "title": "Music Transformer \uae30\ubc18 \uc74c\uc545"}]}