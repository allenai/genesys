{"paperId": "4d76206515d6b33903937474273885476fc2771e", "abstract": "As the Large Language Model (LLM) becomes increasingly important in various domains. However, the following challenges still remain unsolved in accelerating LLM inference: (1) Synchronized partial softmax update. The softmax operation requires a synchronized update operation among each partial softmax result, leading to ~20% overheads for the attention computation in LLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices performing GEMM in LLM inference is flat, leading to under-utilized computation and>50% performance loss after padding zeros in previous designs. (3) Performance loss due to static dataflow. Kernel performance in LLM depends on varied input data features, hardware configurations, etc. A single and static dataflow may lead to a 50.25% performance loss for GEMMs of different shapes in LLM inference. We present FlashDecoding++, a fast LLM inference engine supporting mainstream LLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++ creatively proposes: (1) Asynchronized softmax with unified max value. FlashDecoding++ introduces a unified max value technique for different partial softmax computations to avoid synchronization. (2) Flat GEMM optimization with double buffering. FlashDecoding++ points out that flat GEMMs with different shapes face varied bottlenecks. Then, techniques like double buffering are introduced. (3) Heuristic dataflow with hardware resource adaptation. FlashDecoding++ heuristically optimizes dataflow using different hardware resource considering input dynamics. Due to the versatility of optimizations in FlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on both NVIDIA and AMD GPUs compared to Hugging Face implementations. FlashDecoding++ also achieves an average speedup of 1.37x compared to state-of-the-art LLM inference engines on mainstream LLMs.", "venue": "arXiv.org", "year": 2023, "citationCount": 28, "influentialCitationCount": 2, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "FlashDecoding++ creatively proposes a unified max value technique for different partial softmax computations to avoid synchronization, and points out that flat GEMMs with different shapes face varied bottlenecks, and proposes heuristic dataflow with hardware resource adaptation."}, "embedding": {"model": "specter_v2", "vector": [-0.11487630009651184, 0.4121584892272949, -0.767124593257904, 0.14579185843467712, -0.09528560936450958, 0.18635353446006775, 0.6033971905708313, -0.1826917827129364, -0.5557877421379089, -0.5495457053184509, 0.6288867592811584, -0.1717536747455597, 0.911753237247467, 0.13156607747077942, 0.0007282182923518121, 0.3217727243900299, -0.6664672493934631, -0.1308615654706955, 0.09915995597839355, -0.2022782415151596, -0.09220267832279205, -0.4809698164463043, -1.5604993104934692, 0.4050118625164032, 0.052318062633275986, 0.7975526452064514, 0.3281637728214264, 1.147045373916626, -0.5779923796653748, 0.5118864178657532, 0.43234050273895264, -0.031221143901348114, 0.19576488435268402, 0.3094905912876129, -0.17906323075294495, -0.27516666054725647, 0.21271143853664398, -0.6705708503723145, -0.5392625331878662, 0.8910145163536072, -0.18094657361507416, 0.24326904118061066, 0.06585758179426193, -0.8281340599060059, -0.028183752670884132, 0.8535647392272949, 0.244247704744339, 0.7040655016899109, -0.5613054633140564, -0.48695647716522217, 1.0106762647628784, -1.7487947940826416, 0.06907914578914642, 1.3625239133834839, 0.23645757138729095, -0.046265799552202225, 0.05075466260313988, -0.3350963592529297, 0.7295628786087036, -0.12181668728590012, -1.0574626922607422, -0.8249233365058899, -0.5236244201660156, -0.1197027862071991, 2.2075679302215576, -0.18351028859615326, -0.11214588582515717, 0.2508469820022583, 0.10839978605508804, 1.087207317352295, -0.245186448097229, -0.9689224362373352, -0.15257292985916138, 0.12382319569587708, 0.7047058343887329, 0.9021559953689575, -0.2369132936000824, 0.21920520067214966, -1.0900044441223145, -0.4084116220474243, 0.33740735054016113, -0.15328240394592285, 0.5126110315322876, 0.12791264057159424, -0.1064852699637413, 0.6322130560874939, -0.07000622898340225, 0.3827345669269562, -0.04320027306675911, 0.7991477847099304, 0.6376209855079651, 0.11709567904472351, 0.06903307139873505, -0.2745586335659027, -0.0065016900189220905, 0.05390520393848419, -1.1380999088287354, 0.06379204243421555, 0.21023604273796082, 1.0158971548080444, -0.3576521575450897, 0.48325103521347046, -0.7652639746665955, 0.02352825552225113, 1.4947932958602905, 0.3434891402721405, 0.24138088524341583, -0.43743202090263367, 0.3333019018173218, -0.9697938561439514, -0.1181771457195282, -0.48361098766326904, -0.23576031625270844, -0.27589064836502075, -0.5893813371658325, -0.49793490767478943, -0.424725741147995, -0.2858976721763611, -0.7670705318450928, 0.6685129404067993, -0.2972466051578522, 0.23327964544296265, 0.1971261203289032, 0.44955676794052124, 0.761381983757019, 0.7077564001083374, 0.405281126499176, 0.2271907925605774, 1.3622630834579468, -1.2498468160629272, -0.3731372058391571, -1.152114987373352, 0.6201698780059814, -0.5349370241165161, -0.03524487838149071, -0.3429604470729828, -1.3138309717178345, -1.1013911962509155, -0.9255998730659485, -0.1266983449459076, -0.6068561673164368, 0.40270477533340454, 1.2316327095031738, 0.49363794922828674, -1.2892208099365234, 0.3166770040988922, -0.532604455947876, -0.25677815079689026, 0.0606485977768898, 0.4271908700466156, 0.6373292803764343, -0.014299608767032623, -1.439329981803894, 0.021342163905501366, 0.3994254171848297, -0.5630221962928772, 0.09799326956272125, -0.4622502326965332, -1.1878072023391724, 0.2356780767440796, 0.19577175378799438, -0.42296120524406433, 1.2080999612808228, -0.11417065560817719, -1.5379763841629028, 0.6231032013893127, -0.41742655634880066, 0.05436381697654724, 0.010480380617082119, -0.12477274984121323, -0.9801121950149536, -0.4686999022960663, -0.766619086265564, 0.5772944688796997, 0.8036795854568481, 0.27099648118019104, -0.44918444752693176, 0.24850092828273773, -0.3565821349620819, 0.13692674040794373, -0.482697457075119, 1.4215941429138184, -0.7342871427536011, 0.020963994786143303, -0.032228484749794006, 0.6224756240844727, -0.29534339904785156, 0.04175161197781563, -0.42303627729415894, -0.579206109046936, 0.7646111249923706, 0.14911805093288422, 1.4476052522659302, -1.0877269506454468, -1.1278350353240967, 0.05198615789413452, 0.07354630529880524, 0.3438224494457245, -0.5250279903411865, 0.3203536570072174, -0.17271068692207336, -0.10794477164745331, 0.5194615721702576, -0.8574690818786621, 0.21904394030570984, -0.6323090195655823, -0.8025563955307007, -0.2503677308559418, -0.15238280594348907, 1.0720003843307495, -0.5338884592056274, -0.11520830541849136, -0.08235538005828857, 0.29300761222839355, -0.9516971707344055, 1.175252914428711, -0.4287179708480835, -0.513508677482605, -0.13077425956726074, -0.156183123588562, 0.44661393761634827, -0.4183969795703888, 0.6039368510246277, -0.5337838530540466, -0.474204957485199, 0.2265908420085907, -0.7568493485450745, 1.240667462348938, -0.437224417924881, 0.5305958390235901, 0.26329097151756287, -0.31835609674453735, 0.3269795775413513, 0.2592206299304962, -0.41295158863067627, -0.3684558570384979, 0.44618135690689087, 0.2703642249107361, -0.6590863466262817, 0.21557249128818512, 1.3722007274627686, 1.437464714050293, -0.5051655173301697, 0.21447183191776276, 0.36481836438179016, 0.13948526978492737, 0.28220269083976746, 0.43341007828712463, 0.44101446866989136, 0.3423859775066376, 0.47756144404411316, -0.36827051639556885, 0.4009673297405243, -0.9110754728317261, -0.1906934529542923, 0.7806665301322937, 0.7106934785842896, 0.6155407428741455, 0.49201327562332153, -0.5289730429649353, -0.1724890172481537, 0.12025508284568787, 0.3280909061431885, 1.7222013473510742, -0.06874382495880127, -0.1276261955499649, -0.8176532983779907, -0.22168265283107758, -0.03676151484251022, -0.16261963546276093, 0.07034867256879807, -0.06264004111289978, -0.43690910935401917, -1.290130615234375, 0.8739656805992126, 0.2743918299674988, 0.6517013907432556, -0.6486234068870544, -0.4233035147190094, -0.3623051047325134, 0.717654824256897, -1.1835285425186157, -0.5831860303878784, 0.37213003635406494, -0.3678596019744873, 0.4211600124835968, 0.19743570685386658, -0.15277992188930511, 0.44888150691986084, -0.6960130929946899, 0.9147661328315735, -0.7071918249130249, -0.4819882810115814, 0.021243231371045113, 0.605972409248352, -0.3169437050819397, -0.9020891189575195, 0.4304628372192383, 0.05942878499627113, -0.14845266938209534, 0.4479862451553345, 0.7318532466888428, 0.2985115945339203, -0.18137308955192566, -0.18352945148944855, 0.42848750948905945, 0.16971570253372192, -0.41212013363838196, 0.5004280805587769, -0.577923059463501, 0.09893795847892761, -1.0379925966262817, 0.8364007472991943, -0.18682290613651276, -0.7750566601753235, 0.11897069215774536, -0.7211237549781799, -0.008048693649470806, 0.5254120826721191, -0.6153767704963684, -0.5302667617797852, -0.7519386410713196, 0.09841716289520264, -0.3474215567111969, -0.2562215328216553, 0.12150511145591736, 0.29806771874427795, 0.039151739329099655, -0.008563249371945858, 0.47861388325691223, 0.4096098840236664, -0.18156765401363373, 0.6516479849815369, -0.2459997534751892, 0.5046173930168152, 0.11042288690805435, -0.2630127966403961, -0.21866370737552643, -0.19898147881031036, -0.962871789932251, -0.1325100064277649, -0.2280196100473404, -0.0974300429224968, -0.11229649931192398, 0.1625039279460907, -0.7161414623260498, -0.8772938251495361, 0.06825417280197144, -1.031604528427124, -0.28025200963020325, 0.49519798159599304, -0.07096968591213226, 0.04003268480300903, -1.089942216873169, -1.2394397258758545, -0.4088173508644104, -0.952548623085022, -1.1862704753875732, 0.42319855093955994, 0.30370330810546875, -0.5974858999252319, -0.6087690591812134, -0.226362407207489, -0.8338014483451843, 1.1946260929107666, -0.8377436995506287, 0.699492335319519, -0.06350651383399963, -0.1568765789270401, -0.2549360394477844, -0.11113208532333374, 0.2965822219848633, -0.4464624524116516, 0.518726110458374, -0.8921200037002563, 0.42299848794937134, -0.6019947528839111, -0.16708898544311523, 0.25999751687049866, 0.4008829593658447, 0.9041104912757874, 0.282740980386734, -0.7379353046417236, 0.5640713572502136, 1.370455026626587, -0.7135998010635376, 0.1403135061264038, -0.37858784198760986, 0.9406192302703857, -0.32832515239715576, -0.226397305727005, 0.9586533904075623, 0.0373707041144371, 0.7387052178382874, 0.12793752551078796, -0.3353366553783417, -0.44601500034332275, -0.03973110392689705, 0.7422463297843933, 1.550559401512146, 0.7332707643508911, -0.2266460657119751, -0.708604633808136, 0.2990817129611969, -1.2536929845809937, -0.4263137876987457, 0.21903982758522034, 0.8393279910087585, 0.39888429641723633, 0.027067212387919426, -0.4502437710762024, -0.668485164642334, 0.7128865718841553, 0.6157503128051758, -0.3343032896518707, -1.5202378034591675, 0.12342383712530136, 0.38396260142326355, 0.24696265161037445, 0.881043016910553, -0.47045981884002686, 0.7634974718093872, 14.738627433776855, 1.0394073724746704, -0.30963781476020813, 0.4047555923461914, 0.642774224281311, 0.19596591591835022, -0.04189341142773628, -0.18272367119789124, -2.0106377601623535, 0.014862450771033764, 1.3875538110733032, 0.07220134884119034, 0.2655954360961914, 0.3974893093109131, -0.03162343055009842, -0.0940849632024765, -0.24558225274085999, 0.6733913421630859, 0.5090259909629822, -1.331027865409851, 0.13246825337409973, 0.051982615143060684, 0.2374718338251114, 0.7364548444747925, 0.7679149508476257, 0.6916991472244263, 0.630693793296814, -0.32690244913101196, 0.45943066477775574, 0.3753663897514343, 1.1553525924682617, -0.021809332072734833, 0.32619842886924744, 0.46822434663772583, -1.0197558403015137, 0.19711318612098694, -0.43315941095352173, -1.2470427751541138, 0.09018196165561676, 0.4565650224685669, -0.7089064121246338, -0.6606074571609497, -0.6482301950454712, 0.545508623123169, 0.3458554744720459, 0.2380213737487793, 0.13693611323833466, 0.3714677393436432, -0.28434979915618896, -0.15858407318592072, -0.015804672613739967, 0.7241210341453552, 0.18459133803844452, 0.3742535412311554, -0.03508337587118149, -0.2977399528026581, 0.33234691619873047, 0.540621817111969, -0.3336464762687683, -0.23545771837234497, 0.05329792574048042, -0.1776888519525528, -0.05490180477499962, 1.1213256120681763, 0.41177546977996826, 0.19620534777641296, -0.9383292198181152, 0.3351882994174957, 0.7031427621841431, 0.14176224172115326, -0.4815719425678253, 0.11822184920310974, 0.9312275052070618, -0.5220652222633362, 0.15222659707069397, 0.4282177984714508, -0.17664441466331482, -0.6925418376922607, -1.0674521923065186, -0.20132264494895935, 0.6044436097145081, -0.48128706216812134, -0.3436554968357086, 0.850687563419342, -0.21709810197353363, -0.35943523049354553, 0.06306031346321106, -0.8201431632041931, -0.17934033274650574, 0.8264994621276855, -1.2169233560562134, -0.4486545920372009, 0.41862183809280396, -0.37593311071395874, -0.36357519030570984, 0.05714281275868416, 1.4201462268829346, 0.18077947199344635, -0.6105408668518066, 0.2922535538673401, 0.10169793665409088, -0.0602496936917305, -0.14889806509017944, -0.20873786509037018, 1.2555561065673828, 0.6051763892173767, -0.2495393455028534, 0.05584431812167168, -0.3218459188938141, 0.07291924208402634, -0.8955100774765015, -0.2610149085521698, 0.6574349403381348, -0.5152063965797424, -0.14158791303634644, -1.0976178646087646, -0.5708104372024536, 0.3142969012260437, 0.4689369797706604, 0.3090150058269501, 0.08699049800634384, 0.11832789331674576, -0.4445895850658417, -0.0626150593161583, -0.2893209159374237, 0.20167839527130127, 0.27192631363868713, -0.5644251704216003, 0.2699534296989441, -0.28665676712989807, 0.399802565574646, -1.385703444480896, -0.6337851881980896, -0.3112930655479431, 0.21135561168193817, 0.057641658931970596, 1.0149779319763184, -0.4264236092567444, 0.7702209949493408, 0.9483519196510315, -0.13585186004638672, -0.35350301861763, 0.14508266746997833, -0.9940614104270935, -0.6684914231300354, -0.03746863082051277, 0.7600603103637695, -0.39781394600868225, 0.3606938421726227, 0.8047083020210266, 0.19031865894794464, -0.6166214346885681, -0.18646125495433807, -0.17484533786773682, -0.16002242267131805, -0.7102756500244141, 0.2330784946680069, -0.36860889196395874, 0.1639755666255951, -0.20745524764060974, 0.2711040675640106, 0.7224176526069641, -0.17350773513317108, -0.30903568863868713, 0.4182364046573639, 0.11447004973888397, -0.47149625420570374, -0.7791758179664612, -0.6016240119934082, -1.464664340019226, 0.2101258933544159, -1.345128059387207, 0.08688300102949142, -0.22311504185199738, -0.26675888895988464, -0.027156449854373932, -0.3198215067386627, 0.24222879111766815, 0.1945583075284958, -0.3285940885543823, -0.5229223370552063, -0.7113211750984192, -0.6824401617050171, 0.3961490988731384, 0.6648842096328735, -0.16199642419815063, 0.0201487485319376, -0.003283742582425475, 0.13767732679843903, 0.38094258308410645, 0.3607374429702759, -0.4120783805847168, -0.5244542360305786, -1.2089482545852661, 0.33676865696907043, 0.03214999660849571, -0.22338120639324188, -0.646986722946167, 0.9394875168800354, 0.23334865272045135, -0.21133431792259216, 0.33482155203819275, 0.15718404948711395, -0.44051578640937805, -0.6234941482543945, 0.41818368434906006, -0.6972118020057678, 0.049975767731666565, 0.6846926808357239, -0.9861884117126465, -0.17105567455291748, 0.5320508480072021, -0.09740171581506729, -0.5401616096496582, -1.5123406648635864, 0.49323543906211853, -0.5890238881111145, 0.30821895599365234, -0.33114978671073914, 0.052094992250204086, -1.3470854759216309, -0.19111475348472595, -0.1543596088886261, 0.09321389347314835, -0.5409354567527771, 1.2348259687423706, 0.33746904134750366, -0.9685652852058411, -0.015527400188148022, 0.6077961921691895, -0.29378488659858704, -0.45509058237075806, 0.4433771073818207, 0.4853816628456116, -0.46586698293685913, 0.4875509440898895, 0.19416223466396332, 0.3071751594543457, -1.1080658435821533, 0.0161161907017231, 0.4190252721309662, -0.33071884512901306, -0.26854825019836426, 1.0047744512557983, -0.39176714420318604, -0.550777792930603, -0.010366756469011307, -1.211870789527893, -0.22828160226345062, -0.47481027245521545, 0.8794928193092346, 0.11572936922311783, 0.36856505274772644, 0.04377087578177452, -0.6138449907302856, -0.0877695381641388, -0.258187860250473, -0.4900554418563843, -0.05242343246936798, -0.19512015581130981, -0.4649042785167694, 0.0874992161989212, 1.084204912185669, -0.453839510679245, -0.6662305593490601, -0.7071347832679749, -0.5169094204902649, 0.1115950345993042, 0.7544024586677551, -0.12137803435325623, -0.6886543035507202, 0.5615952014923096, 0.46127328276634216, 0.1832800954580307, 0.02280423231422901, -0.1637437790632248, 0.3010101914405823, 0.38460466265678406, 0.13667525351047516, -0.6898337602615356, -1.0737007856369019, 1.4091497659683228, 0.7857703566551208, -0.6737178564071655, 0.2527012228965759, -0.500363826751709, -0.5951053500175476, 1.0328476428985596, 0.4908575117588043, 0.09163080900907516, 1.2795946598052979, 0.8165194392204285, 0.10312706232070923, 0.4915751516819, -0.9538295865058899, -0.4486694931983948, 0.8079630136489868, 0.41959279775619507, 0.8351873159408569, 0.38056957721710205, 0.1280108392238617, 0.860175609588623, 0.3011658489704132, 0.2747637927532196, 0.2830932140350342, 0.6093377470970154, -0.3315061628818512, -0.11303514242172241, -0.17349475622177124, 0.7269873023033142, -0.627396821975708, -1.1475719213485718, 0.593399703502655, 0.43890380859375, 0.128119096159935, 0.45362550020217896, 1.2248437404632568, 0.14282803237438202, 0.21921637654304504, 0.11468975991010666, 0.4574100375175476, -0.6121727824211121, -0.21088984608650208, -0.2168956696987152, -0.4582226574420929, -0.27620729804039, 0.5485660433769226, -0.35994237661361694, -0.9037058353424072, -0.3965608477592468, 0.6891306042671204, -0.4843534827232361, 0.4253719747066498, 0.9097248315811157, 0.9521998763084412, 0.7216948866844177, -0.387661337852478, -0.39289724826812744, -0.3436029851436615, -0.5453030467033386, -0.2501945197582245, -0.7267910838127136, -0.33671408891677856, 0.19139349460601807, 0.15033012628555298, -0.17517413198947906]}, "authors": [{"authorId": "2241616962", "name": "Ke Hong"}, {"authorId": "144290348", "name": "Guohao Dai"}, {"authorId": "2264991200", "name": "Jiaming Xu"}, {"authorId": "2264077072", "name": "Qiuli Mao"}, {"authorId": "2264969921", "name": "Xiuhong Li"}, {"authorId": "2264141921", "name": "Jun Liu"}, {"authorId": "2264539929", "name": "Kangdi Chen"}, {"authorId": "2287809786", "name": "Yuhan Dong"}, {"authorId": "2241604835", "name": "Yu Wang"}], "references": [{"paperId": "10158879cdb64ce7d3f7bb5572c4617ea808602e", "title": "Receive, Reason, and React: Drive as You Say, With Large Language Models in Autonomous Vehicles"}, {"paperId": "282c568302701bc163d454702eae10e43ca784a3", "title": "The future landscape of large language models in medicine"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "94ce1d5924e05e8d75e43ce70044293ddcef850a", "title": "Large language models in medicine"}, {"paperId": "42a14d824caa3348046eb34c37e2ab7985faa7a3", "title": "High-throughput Generative Inference of Large Language Models with a Single GPU"}, {"paperId": "68adb03744692247fb834406798894db9fe77010", "title": "A Survey on Long Text Modeling with Transformers"}, {"paperId": "c022f75b00d795c6297d6a9ea948856ea4d365a1", "title": "DeepSpeed- Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "50796b0f3edf9cb5ff1e447c298b33755378aa4f", "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "a538b05ebb01a40323997629e171c91aa28b8e2f", "title": "Rectified Linear Units Improve Restricted Boltzmann Machines"}, {"paperId": "c8c4ab59ac29973a00df4e5c8df3773a3c59995a", "title": "Searching for Activation Functions"}, {"paperId": null, "title": "Cutlass: Cuda templates for linear algebra subroutines"}, {"paperId": null, "title": "cublas: Basic linear algebra on nvidia gpus"}, {"paperId": null, "title": "Fastertransformer: About transformer related optimization, including bert, gpt"}, {"paperId": "830ccb44084d9d6cdcb70d623df5012ae4835142", "title": "Training Stochastic Model Recognition Algorithms as Networks can Lead to Maximum Mutual Information Estimation of Parameters"}, {"paperId": null, "title": "Flash-decoding for long-context inference"}, {"paperId": null, "title": "Optimizing inference on large language models with nvidia tensorrt-llm, now publicly available"}, {"paperId": null, "title": "OpenAI"}, {"paperId": null, "title": "A light and fast inference service for llm"}, {"paperId": null, "title": "Up-to-date chatgpt statistics & user numbers [oct 2023]"}, {"paperId": null, "title": "Machine learning compilation for large language models"}, {"paperId": null, "title": "High-speed gemv kernels"}, {"paperId": null, "title": "The inference cost of search disruption - large language model cost analysis"}, {"paperId": null, "title": "Nvidia tensorrt: An sdk for high-performance deep learning inference"}]}