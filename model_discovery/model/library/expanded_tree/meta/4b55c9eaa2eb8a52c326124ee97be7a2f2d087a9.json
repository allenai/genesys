{"paperId": "4b55c9eaa2eb8a52c326124ee97be7a2f2d087a9", "abstract": "Parameter-efficient tuning aims to mitigate the large memory requirements of adapting pretrained language models for downstream tasks. For example, one popular method, prefix-tuning, prepends trainable tokens to sequences while freezing the rest of the model\u2019s parameters. Although such models attain comparable performance with fine-tuning when applied to sequences with short to moderate lengths, we show their inferior performance when modelling long sequences. To bridge this gap, we propose prefix-propagation, a simple but effective approach that conditions prefixes on previous hidden states. We empirically demonstrate that prefix-propagation outperforms prefix-tuning across long-document tasks, while using 50% fewer parameters. To further investigate the proposed architecture, we also show its advantage in calibration, and perform additional study on its relationship with kernel attention. To the best of our knowledge, this work is the first to focus on parameter-efficient learning for long-sequence language tasks.", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2023, "citationCount": 7, "influentialCitationCount": 1, "openAccessPdf": {"url": "http://arxiv.org/pdf/2305.12086", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work empirically demonstrates that prefix-propagation outperforms prefix-tuning across long-document tasks, while using 50% fewer parameters, and is the first to focus on parameter-efficient learning for long-sequence language tasks."}, "embedding": {"model": "specter_v2", "vector": [0.2734687626361847, 0.2346174120903015, -0.44196122884750366, -0.2875981032848358, 0.15140178799629211, -0.5767916440963745, 0.8052297830581665, -0.23369844257831573, -0.8377957940101624, -0.30288830399513245, 0.6388328075408936, -0.20064187049865723, 0.24909155070781708, 0.28823837637901306, -0.44782519340515137, 0.07529190182685852, -0.9992244839668274, 0.5260713696479797, -0.04704944044351578, -0.1516597867012024, -0.2430289387702942, -0.7054435610771179, -0.6951963901519775, -0.08795904368162155, 0.06225131079554558, 0.26940566301345825, 0.39414292573928833, 0.7468076944351196, -0.683702290058136, -0.19863183796405792, 0.3519192934036255, -0.5632557272911072, 0.1874910444021225, 0.047368697822093964, -0.4702392816543579, -0.07158972322940826, 0.1765097677707672, -0.42074304819107056, -0.26026079058647156, 0.7140761017799377, -0.44466301798820496, 0.3946464955806732, 0.646385669708252, -0.34418022632598877, -0.3465287983417511, 1.2254230976104736, 0.9104782342910767, 0.6091275811195374, -0.21933355927467346, -0.4754067659378052, 1.1170092821121216, -0.9446942210197449, 0.3879640996456146, 1.2429296970367432, 0.7257083058357239, 0.4422535002231598, -0.22099460661411285, -0.7571638226509094, 0.919158935546875, 0.010189460590481758, -0.9035167098045349, -0.07321824878454208, -0.1352635622024536, -0.4935324192047119, 2.112664222717285, -0.7440664172172546, 0.1669098287820816, 0.9846682548522949, -0.17693786323070526, 1.1029255390167236, -0.4615187346935272, -0.7795740962028503, -0.546111524105072, -0.03650031238794327, 0.3253863453865051, 0.6947369575500488, -0.5953653454780579, 0.4838891327381134, -0.5809052586555481, -0.14061948657035828, 0.4569976329803467, -0.22035682201385498, 0.14544883370399475, -0.00036044453736394644, -0.7366366982460022, 0.6725072860717773, -0.08326239138841629, 0.5400370359420776, -0.1952875405550003, 0.6679421663284302, 0.771760880947113, 0.37607672810554504, 0.023753030225634575, 0.5631961226463318, -0.3949434161186218, 0.2301057130098343, -0.7992642521858215, 0.3236219584941864, 0.2723637819290161, 0.8924009799957275, 0.09972590953111649, 0.31770139932632446, -0.7840481400489807, 0.5003845691680908, 1.1230541467666626, -0.07219759374856949, 0.532705545425415, -0.7388116717338562, 0.23197191953659058, -0.8583785891532898, 0.6029385328292847, -0.4804077446460724, -0.42182180285453796, -0.4478864371776581, -0.5122918486595154, -1.6827681064605713, -0.17242427170276642, 0.1393854171037674, -0.5055333971977234, 1.0369524955749512, -0.1403358429670334, 0.5513477325439453, -0.10821770131587982, 0.4375278949737549, 0.19536294043064117, 1.0720778703689575, 0.6869228482246399, -0.14340730011463165, 1.1687577962875366, -0.9469873309135437, -0.7512026429176331, -1.09819757938385, 0.7929369807243347, -0.354831337928772, 0.5851348042488098, -0.17574606835842133, -0.90223228931427, -1.0841848850250244, -1.0474573373794556, 0.25466787815093994, -0.5589039921760559, 0.4375322163105011, 1.1101361513137817, 0.4724019169807434, -0.4372188448905945, 1.0307557582855225, -0.09156063199043274, -0.2530492842197418, 0.11643476039171219, 0.024908673018217087, 0.4760373532772064, -0.4741886854171753, -1.864190697669983, 0.44847410917282104, 0.8538569808006287, -0.6415516138076782, -0.2447851002216339, -0.7853825688362122, -0.8941147923469543, -0.05001067370176315, 0.40372931957244873, -0.6481264233589172, 1.4238736629486084, -0.1086302325129509, -1.5678038597106934, 0.7085499167442322, -0.03347640484571457, -0.06752624362707138, 0.06178070977330208, -0.2977321147918701, -0.8135587573051453, -0.6363281011581421, -0.5005406141281128, 0.633561372756958, 0.727353572845459, 0.3245493471622467, -0.15116415917873383, 0.3953237533569336, -0.21742019057273865, 0.022081291303038597, -0.47041356563568115, 0.9421533346176147, -0.4989473223686218, -0.4533572196960449, -0.05910298973321915, 0.48827341198921204, 0.025671442970633507, -0.68755704164505, -0.274994820356369, -1.1550039052963257, 0.30202147364616394, 0.03476058691740036, 1.233884334564209, -0.8561862111091614, -0.7399764657020569, -0.11900754272937775, -0.7933957576751709, 0.25660914182662964, -0.9150285720825195, 0.8345239162445068, -0.16068528592586517, 0.1861458420753479, -0.05702326074242592, -1.1714304685592651, 0.2616221308708191, -0.03263787180185318, -0.5074866414070129, -0.09683148562908173, 0.11251096427440643, 1.0866734981536865, -1.040941834449768, 0.12390217185020447, -0.03953912481665611, 0.3691461980342865, -0.9642881751060486, 1.114758849143982, -0.7438009977340698, 0.06076245382428169, 0.22135145962238312, -0.5964117646217346, -0.011739336885511875, -0.5043585300445557, 0.4414534270763397, -0.21089154481887817, -0.0792330652475357, 0.6931610107421875, -0.5340611338615417, 1.8489493131637573, -0.386345773935318, 0.11318405717611313, -0.3181858956813812, -0.5753913521766663, 0.23758530616760254, 0.31164804100990295, -0.05414639040827751, -0.271270215511322, 0.12137850373983383, 0.39819902181625366, -0.8714960813522339, -0.057298872619867325, 0.8295129537582397, 0.5648666024208069, -0.4496018886566162, 0.34395503997802734, 0.7228125333786011, -0.06087326258420944, 0.7716917991638184, 0.26524263620376587, 0.36551254987716675, 0.7025949358940125, 0.29075881838798523, 0.014775983057916164, 0.33765724301338196, -0.6827687621116638, -0.17913056910037994, 0.19373874366283417, 0.807996392250061, 0.30890482664108276, 0.16555523872375488, -0.726093590259552, -0.7393273115158081, -0.15764838457107544, 0.4850286543369293, 2.0114235877990723, -0.4891180694103241, -0.22226792573928833, -0.9188571572303772, -0.0551864355802536, -0.09587904065847397, 0.08910361677408218, -0.4531770348548889, -0.16213947534561157, -0.8522372245788574, -0.9372426867485046, 0.971253514289856, 0.17189127206802368, 0.4476095736026764, -0.5907569527626038, -0.26173076033592224, 0.3404179811477661, -0.15819239616394043, -0.627880334854126, -1.0861713886260986, 0.2666734755039215, -0.5930964946746826, 0.16068293154239655, -0.1464606076478958, -0.2712450921535492, -0.23227617144584656, -0.906436026096344, 1.1762902736663818, -0.8429930210113525, -0.03270731121301651, -0.11385001242160797, 0.5504134893417358, -0.4704340398311615, -0.9056330323219299, 0.7588779926300049, 0.3603639602661133, -0.0031107384711503983, 0.43396979570388794, 0.5929517149925232, 0.011513421311974525, 0.054448507726192474, -0.5269075036048889, 0.21183420717716217, 0.00879548117518425, 0.1465507596731186, 0.6580137014389038, -0.47248491644859314, 0.4736880958080292, -1.4175809621810913, 0.7492003440856934, 0.12262628227472305, -0.6135241389274597, 0.322846919298172, -0.7396933436393738, -0.23654009401798248, 0.4876546263694763, -1.1471359729766846, -0.47267434000968933, -0.6950393319129944, -0.010874796658754349, -0.2957376539707184, -0.3090384602546692, 0.4088262915611267, 0.36939772963523865, 0.6153230667114258, 0.5714100003242493, 0.3583066463470459, 0.20233795046806335, -0.3921385407447815, 0.8513782620429993, -0.7914493083953857, 0.9826228618621826, 0.18784332275390625, 0.08390549570322037, -0.23998084664344788, -0.4641697108745575, -0.6068345308303833, -0.660025954246521, -0.8905782103538513, -0.4840107262134552, -0.2345665842294693, 0.05813616141676903, -0.3258969783782959, -0.8808681964874268, 0.07012077420949936, -1.0836200714111328, -0.24181577563285828, 0.23611682653427124, 0.0023908161092549562, -0.2523757815361023, -0.9715261459350586, -1.440485954284668, -0.24524322152137756, -0.5532755255699158, -0.5653780102729797, -0.1994902640581131, -0.12272550910711288, -0.3827427327632904, -0.7964792847633362, 0.4121299982070923, -0.5475509762763977, 1.0927637815475464, -0.8149322867393494, 0.8481690883636475, 0.009781002067029476, -0.07715032994747162, -0.038316868245601654, 0.3898211121559143, 0.6368840932846069, -0.5299651026725769, 0.2536545395851135, -0.8865288496017456, -0.08212273567914963, -0.7082449793815613, -0.16017158329486847, 0.12007944285869598, 0.33552107214927673, 0.7048561573028564, -0.1893889307975769, -0.5558362007141113, 0.7720790505409241, 1.3294754028320312, -0.6915283799171448, -0.09998688846826553, 0.35739952325820923, 0.7796533703804016, 0.40437284111976624, -0.11416106671094894, 0.7688582539558411, 0.17146345973014832, 0.3622857332229614, -0.16455742716789246, 0.21874886751174927, -0.011794599704444408, -0.773280680179596, 0.4246608316898346, 1.7977290153503418, 0.34003913402557373, -0.10726692527532578, -1.047926425933838, 0.700441837310791, -1.0533801317214966, -0.7008811235427856, 0.6517385244369507, 0.6592445969581604, 0.6521625518798828, -0.5189756751060486, 0.031108684837818146, -0.4430111348628998, 0.2336939126253128, 0.39215484261512756, -0.46152567863464355, -0.7778337597846985, 0.17431065440177917, 0.07209774106740952, 0.045424528419971466, 0.4279026389122009, -0.6653356552124023, 0.7680845260620117, 14.720949172973633, 0.8640109300613403, -0.03983228653669357, 0.5845788717269897, 0.06273192167282104, 0.17772802710533142, -0.529532253742218, -0.4536866545677185, -1.4427905082702637, -0.003256566124036908, 1.652747392654419, 0.2738208770751953, 0.9517856240272522, -0.08294214308261871, 0.16150739789009094, 0.4727613925933838, -0.5134216547012329, 0.6383906602859497, 0.45148560404777527, -1.3482143878936768, 0.15959659218788147, -0.08945539593696594, 0.49811750650405884, 0.6127156615257263, 0.8793352842330933, 1.134974479675293, 0.476105660200119, -0.24003909528255463, 0.6850710511207581, 0.28099775314331055, 0.8484491109848022, -0.2976182997226715, 0.2533743381500244, 0.5087019205093384, -0.7316377758979797, -0.16823701560497284, -0.9026649594306946, -0.875828206539154, 0.6168949007987976, 0.300780713558197, -1.0014324188232422, -0.3969374895095825, -0.34882694482803345, 0.8274971842765808, 0.19021953642368317, 0.49441060423851013, -0.17620065808296204, 1.1134775876998901, 0.20748741924762726, 0.25423794984817505, 0.8729954361915588, 0.0422273613512516, 0.07164332270622253, 0.5448623299598694, -0.165383443236351, -0.08243472129106522, 0.031259894371032715, 0.36291417479515076, -0.26041877269744873, 0.16049477458000183, -0.12328669428825378, -0.3675435185432434, 0.20955519378185272, 0.4968426525592804, 0.6657925248146057, 0.11401056498289108, -0.3123333752155304, 0.4235115349292755, 0.7104690670967102, 0.5163124799728394, -0.5891013741493225, -0.043756093829870224, 0.4488510489463806, -0.6571663022041321, 0.015393048524856567, 0.3277827501296997, 0.005259883124381304, -0.3419664800167084, -1.0157783031463623, 0.038046944886446, 0.5341159105300903, -0.5847094655036926, -0.7122587561607361, 0.5823110342025757, -0.04753279685974121, -0.31002694368362427, -0.2570037245750427, -0.7569870948791504, 0.22808457911014557, 0.6542316675186157, -1.4551723003387451, -0.6582844853401184, 0.439878910779953, -0.2263556569814682, -0.48101454973220825, 0.16221678256988525, 1.4459081888198853, 0.49599650502204895, -0.45136764645576477, 0.07751467078924179, 0.5682162046432495, 0.04213518649339676, -0.030560748651623726, -0.3893032968044281, 1.0741039514541626, -0.06696109473705292, -0.13044756650924683, 0.4956671893596649, -0.03176644444465637, 0.14925362169742584, -0.2828231453895569, -0.32316577434539795, 0.7295740842819214, -0.9469885230064392, -0.38867753744125366, -0.7624029517173767, -1.2235772609710693, 0.4113977551460266, 0.49638086557388306, -0.5480369329452515, 0.6062278151512146, 0.30497995018959045, -0.8010973334312439, 0.06911472231149673, -0.39965906739234924, -0.37987786531448364, 0.6543282270431519, -0.7573978900909424, -0.33134153485298157, -0.09692534059286118, 0.5874164700508118, -0.8826993107795715, -0.7236425280570984, -0.3599722385406494, 0.27745509147644043, 0.46521514654159546, 1.290284514427185, -0.5368624925613403, 0.2715364098548889, 0.9153807163238525, 0.14218145608901978, -1.0124421119689941, -0.3443112075328827, -0.7588067650794983, 0.05425426736474037, 0.13335177302360535, 0.8217503428459167, -0.31233352422714233, 0.21679024398326874, 0.22751104831695557, -0.0028175741899758577, -0.45944085717201233, -0.22122463583946228, -1.061293601989746, 0.312185674905777, -0.5409032702445984, 0.63591468334198, 0.2274373471736908, -0.21554668247699738, 0.12592162191867828, 0.36110612750053406, 0.5756204724311829, -0.2823091149330139, -0.7142441868782043, 0.08137017488479614, -0.03084448352456093, -0.23780669271945953, -0.5591869354248047, -0.029907289892435074, -1.426271915435791, 0.27167198061943054, -1.2831648588180542, -0.12804141640663147, -0.9498094916343689, -0.36866024136543274, -0.18501605093479156, -0.24329310655593872, -0.08980191498994827, 0.3917931914329529, -0.6343862414360046, -0.4870753288269043, -0.32520219683647156, -0.3619602620601654, 0.6447149515151978, 0.8463454246520996, -0.6118561029434204, 0.023827360942959785, -0.006614298559725285, 0.8758140802383423, 0.09258036315441132, 0.5257125496864319, -0.4190495014190674, -0.8393219113349915, -1.4424225091934204, 0.5931435227394104, -0.2613529860973358, -0.3862037658691406, -0.3520128130912781, 0.32694756984710693, -0.06829550862312317, -0.41855350136756897, -0.19743941724300385, 0.4706849455833435, -0.649703323841095, -0.10859616845846176, 0.2703077793121338, -0.6461808085441589, 0.1490236222743988, 0.10774435102939606, -0.33784082531929016, -0.017202895134687424, 0.40639418363571167, 0.05517188459634781, -1.1154069900512695, -1.0794910192489624, 0.5237240195274353, -0.6709077954292297, 0.2711917459964752, -0.2777719497680664, -0.20062747597694397, -0.9833374619483948, -0.039513301104307175, 0.21176232397556305, 0.3479210436344147, -0.3735693693161011, 1.0652581453323364, 0.14425066113471985, -1.056963562965393, 0.029705753549933434, 0.4859316945075989, 0.22709500789642334, -0.1583581566810608, 0.5343770384788513, 0.42276623845100403, -0.28216058015823364, 0.9660753011703491, -0.04914800077676773, 0.22897972166538239, -0.7069914937019348, 0.2008463740348816, 0.7190229892730713, -0.5162889957427979, -0.04356074705719948, 1.2316771745681763, -0.3956383764743805, -1.3623554706573486, 0.3450419306755066, -1.211613416671753, -0.6701323986053467, -0.05340476334095001, 0.5362672805786133, 0.17991650104522705, -0.06566648185253143, 0.08438346534967422, -0.4450116753578186, 0.06766542792320251, 0.028760340064764023, -0.6642743349075317, 0.4650474786758423, -0.44357776641845703, 0.10890913754701614, 0.8658035397529602, 1.0517507791519165, -1.0947346687316895, -0.8672733902931213, -0.8206906914710999, -0.19709539413452148, -0.08956973254680634, 0.028245659545063972, -0.679488480091095, -0.13480423390865326, 0.7740323543548584, 0.18451115489006042, -0.13504894077777863, -0.12047062069177628, -0.14726877212524414, 0.3059649169445038, 0.7578264474868774, 0.029929708689451218, -0.829443097114563, -0.3681158125400543, 1.5603017807006836, 0.8823407888412476, -0.7007431387901306, -0.1335557997226715, 0.04040873795747757, -0.6481260657310486, 0.705964207649231, 0.03164108470082283, 0.15169347822666168, 0.9136895537376404, -0.39178386330604553, 0.26229721307754517, 0.1375049352645874, -1.0393201112747192, -0.015505608171224594, 0.880872905254364, 0.9168571829795837, 0.5366035103797913, 0.6753796935081482, 0.3686825931072235, 0.9191268086433411, -0.03773735836148262, 0.0880427360534668, 0.4412718713283539, 0.14463302493095398, -0.2987297773361206, -0.2860938012599945, -0.029867494478821754, 0.6744107007980347, -0.7903138995170593, -0.4640585780143738, 0.29350364208221436, 0.4286190867424011, 0.20877501368522644, 0.22983451187610626, 0.9522085785865784, 0.2625180780887604, 0.5968390107154846, 0.6647759675979614, 0.6278272271156311, -0.4487787187099457, -0.49813586473464966, -0.3544324040412903, -0.40297427773475647, -0.19612962007522583, -0.1455162912607193, -0.6850528120994568, -0.2320939004421234, -0.38915833830833435, 0.17575383186340332, -0.04377024993300438, 0.7399665117263794, 1.0515254735946655, 0.39495140314102173, 0.377580851316452, -0.49133235216140747, -0.42949235439300537, -0.843451738357544, -1.1650445461273193, -0.0665319561958313, -0.22451165318489075, -0.2995148003101349, -0.1810453087091446, 0.059122513979673386, 0.0845944881439209]}, "authors": [{"authorId": "2124950910", "name": "Jonathan Li"}, {"authorId": "2188834394", "name": "Will Aitken"}, {"authorId": "2008160154", "name": "R. Bhambhoria"}, {"authorId": "1854999", "name": "Xiao-Dan Zhu"}], "references": [{"paperId": "289700f4570733b612147883ad29b963bbffe31a", "title": "Inducer-tuning: Connecting Prefix-tuning and Adapter-tuning"}, {"paperId": "6c46b7b401be5ada79f00b36cb8e5b41286ae2aa", "title": "Measuring Forgetting of Memorized Training Examples"}, {"paperId": "6281c40c66febca1d8003bcc6fdfd2189b30c38f", "title": "SCROLLS: Standardized CompaRison Over Long Language Sequences"}, {"paperId": "43a87867fe6bf4eb920f97fc753be4b727308923", "title": "Towards a Unified View of Parameter-Efficient Transfer Learning"}, {"paperId": "e553407be283d018e275f472d4d2fd709a6c9248", "title": "PPT: Pre-trained Prompt Tuning for Few-shot Learning"}, {"paperId": "cddf40e579a596d0110b260313adf43470617c4c", "title": "Datasets: A Community Library for Natural Language Processing"}, {"paperId": "339b2b711fb5b228d097b03ebc3e62a521779235", "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "8cef9900c04d7f661c08f4b5b1ed4337ace042a3", "title": "Transformer Dissection: An Unified Understanding for Transformer\u2019s Attention via the Lens of Kernel"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "fc089a09074c84979d1f34e89341318a5bc26d3d", "title": "SemEval-2019 Task 4: Hyperpartisan News Detection"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "db9b452f34e5dd6522acaad64e1d0d11868aa5d3", "title": "Long Document Classification From Local Word Glimpses via Recurrent Attention Learning"}, {"paperId": "8cf29f44cd5f813d8352473460ea71ae31f975e4", "title": "GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration"}, {"paperId": "7d5cf22c70484fe217936c66741fb73b2a278bde", "title": "Constructing Datasets for Multi-hop Reading Comprehension Across Documents"}, {"paperId": "d65ce2b8300541414bfe51d03906fca72e93523c", "title": "On Calibration of Modern Neural Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "8d115c3b2ee80e0754360a154a9369bc1658b607", "title": "Obtaining Well Calibrated Probabilities Using Bayesian Binning"}, {"paperId": "38b3a4447a47a6a6ed1869f3da03352c487f8fe3", "title": "NewsWeeder: Learning to Filter Netnews"}, {"paperId": "ec936b808e0fab9281c050ad4010cddec92c8cbe", "title": "P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks"}, {"paperId": "2551990a1ccdffb1a4d1d9040b2d493ba6d26dd1", "title": "Towards Visual Question Answering on Pathology Images"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Huggingface datasets (which we reviewed for correctness). The original dataset has labels leaked in the source text, so we use the no_ref version that has those labels filtered"}, {"paperId": null, "title": "crowdworkers) or research with human participants?"}, {"paperId": null, "title": "Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators"}, {"paperId": null, "title": "Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? See Appendix B"}, {"paperId": null, "title": "crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic"}, {"paperId": null, "title": "arxiv-classification 10"}, {"paperId": null, "title": "error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run? In various places, for example"}, {"paperId": null, "title": "Was the data collection protocol approved (or determined exempt) by an ethics review board? No response"}, {"paperId": null, "title": "C Did you run computational experiments? See section 4"}, {"paperId": null, "title": "Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? No response"}]}