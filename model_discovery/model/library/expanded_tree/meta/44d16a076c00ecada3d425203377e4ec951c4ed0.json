{"paperId": "44d16a076c00ecada3d425203377e4ec951c4ed0", "abstract": "Large language models (LLMs), despite their remarkable progress across various general domains, encounter significant barriers in medicine and healthcare. This field faces unique challenges such as domain-specific terminologies and reasoning over specialized knowledge. To address these issues, we propose MedAgents, a novel multi-disciplinary collaboration framework for the medical domain. MedAgents leverages LLM-based agents in a role-playing setting that participate in a collaborative multi-round discussion, thereby enhancing LLM proficiency and reasoning capabilities. This training-free framework encompasses five critical steps: gathering domain experts, proposing individual analyses, summarising these analyses into a report, iterating over discussions until a consensus is reached, and ultimately making a decision. Our work focuses on the zero-shot setting, which is applicable in real-world scenarios. Experimental results on nine datasets (MedQA, MedMCQA, PubMedQA, and six subtasks from MMLU) establish that our proposed MedAgents framework excels at mining and harnessing the medical expertise within LLMs, as well as extending its reasoning abilities. Our code can be found at https://github.com/gersteinlab/MedAgents.", "venue": "arXiv.org", "year": 2023, "citationCount": 45, "influentialCitationCount": 4, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Experimental results establish that the proposed MedAgents framework excels at mining and harnessing the medical expertise within LLMs, as well as extending its reasoning abilities, which is applicable in real-world scenarios."}, "embedding": {"model": "specter_v2", "vector": [-0.19271665811538696, 0.9635481834411621, -0.5798365473747253, -0.07910805940628052, -0.6931264996528625, -0.04125511273741722, 0.4801029562950134, 0.07293765991926193, -0.4387393891811371, 0.09908454865217209, 0.5227840542793274, -0.28644824028015137, 0.011399363167583942, 0.49765196442604065, 0.3437589406967163, -0.08759226649999619, -1.056288719177246, 0.8425175547599792, 0.0601532906293869, -0.563260018825531, -0.5785922408103943, -0.8106591701507568, -0.44322139024734497, 0.5444567203521729, 0.7195538878440857, -0.09729026257991791, -0.2167806327342987, 0.663847029209137, -0.010847949422895908, 1.1295865774154663, 0.5181429982185364, -0.4767947793006897, 0.29532355070114136, -0.020905494689941406, -0.5134830474853516, 0.19479574263095856, -0.05159173905849457, -0.576961100101471, -0.3866167366504669, 0.6462926864624023, -0.03595300018787384, 0.0554199256002903, 0.545222818851471, -0.8175415992736816, -0.14360292255878448, 0.9254375100135803, 0.7279016375541687, 0.18669137358665466, 0.1343926042318344, -0.44340699911117554, 1.274294376373291, -1.0313268899917603, 0.8849474191665649, 1.5753703117370605, 0.3972207307815552, 0.8008200526237488, 0.22160027921199799, -0.5820007920265198, 0.2511506676673889, -0.005694398656487465, -0.925577700138092, -0.44902366399765015, -0.3780014216899872, -0.482323557138443, 1.3233122825622559, -0.5372763872146606, -0.4568445086479187, 0.2332114577293396, 0.5594514608383179, 1.164426565170288, -0.12249860912561417, -0.6696507334709167, 0.16763249039649963, 0.3520830571651459, 0.09602891653776169, 1.2136924266815186, -0.2650471329689026, -0.04196838662028313, -0.8345705270767212, -0.6617258787155151, 0.13203094899654388, -0.05631880834698677, -0.47405126690864563, -0.4792335033416748, -0.6845800280570984, 0.5909351706504822, 0.07549269497394562, 0.7519385814666748, -0.35351717472076416, 0.044534675776958466, 0.06074545904994011, 0.6582313179969788, 0.07506563514471054, 0.3820978105068207, -0.07538842409849167, 0.6169511079788208, -0.39965203404426575, 0.3855321705341339, 0.17494186758995056, 0.5860169529914856, -0.6578338146209717, -0.5161803960800171, -0.970282256603241, 0.23761603236198425, 1.7006500959396362, -0.5096981525421143, 0.3892178237438202, -0.8172199130058289, 0.3672387897968292, -0.2771892845630646, 0.9620749950408936, -0.26208987832069397, -0.38809728622436523, 0.23487532138824463, -0.5174596905708313, -0.913957953453064, -0.3304189443588257, 0.050004102289676666, -0.657468855381012, 0.8884404897689819, 0.026704108342528343, -0.14172914624214172, 0.8571884632110596, 0.6463701725006104, 1.2676981687545776, 0.21537750959396362, 0.4555549919605255, -0.28064945340156555, 1.1803866624832153, -0.5161187052726746, -0.8946091532707214, -0.8231642246246338, 1.236210584640503, 0.20469588041305542, -0.5231364965438843, -0.22798733413219452, -1.5834417343139648, -0.38254642486572266, -0.840395987033844, 0.065956249833107, -0.30181238055229187, 0.1537250280380249, 0.554599404335022, -0.04841766506433487, -0.9769287705421448, 0.5256210565567017, 0.06781361997127533, -0.42917850613594055, -0.01562256459146738, 0.14709384739398956, -0.058321088552474976, -0.7747310996055603, -1.7673561573028564, 0.6976400017738342, 0.3090474307537079, -0.4698389768600464, -0.5283488631248474, -0.5884787440299988, -1.1255500316619873, -0.5236610770225525, 0.625704824924469, -0.8729069232940674, 1.4679888486862183, 0.3042110800743103, -0.919928789138794, 1.340781331062317, -0.16972066462039948, 0.0018581406911835074, 0.91342693567276, 0.2900344431400299, -0.9901317358016968, 0.01587592624127865, -0.025249557569622993, 0.5292536616325378, 0.005009490065276623, -0.21992334723472595, -0.15277425944805145, 0.1277400553226471, 0.31772175431251526, -0.28142407536506653, 0.16195403039455414, 0.827933669090271, -0.3534609377384186, -0.20428186655044556, 0.18099401891231537, 0.7791950702667236, -0.5417006015777588, 0.26090699434280396, -0.17259396612644196, -1.1921685934066772, 0.049829497933387756, 0.12630796432495117, 0.7920109629631042, -0.6239321827888489, -0.1498289704322815, -0.35874852538108826, 0.4845368564128876, -0.10112285614013672, -0.5486575961112976, 0.557255208492279, -0.16881969571113586, 0.33581286668777466, -0.5699385404586792, -1.0682340860366821, -0.16054676473140717, 0.04999075084924698, -0.46434277296066284, -0.0467856265604496, 0.06297118216753006, 0.9766519665718079, -1.2481616735458374, -0.5291223526000977, -0.12616239488124847, -0.2788551449775696, -0.6220840811729431, 1.1285667419433594, -0.5638285875320435, 0.2012735903263092, -0.3078356683254242, -0.049655091017484665, 0.06954368203878403, -0.42372843623161316, 0.8429635167121887, -0.4429842531681061, -0.06342094391584396, -0.053704600781202316, -0.5526065230369568, 1.3839631080627441, 0.11948555707931519, -0.0809796079993248, 0.6094587445259094, -0.6179823279380798, -0.36547115445137024, 1.1604317426681519, 0.04029722139239311, -0.23130057752132416, 0.47891777753829956, 0.3641573488712311, -0.3725995421409607, -0.5136444568634033, -0.11853303015232086, 0.3644576668739319, -0.146189346909523, 0.3875199258327484, 0.48900023102760315, -0.17940977215766907, 0.6325074434280396, 0.8185010552406311, 0.7431837916374207, -0.21160811185836792, 0.6893224120140076, -0.12160982191562653, 0.8369989395141602, -0.5122874975204468, 0.10940687358379364, 0.5754115581512451, 0.3475339114665985, 0.34849268198013306, 0.1788809448480606, -0.7564879059791565, 0.29824575781822205, 0.04228007793426514, 0.36889171600341797, 1.2713844776153564, 0.3426450192928314, -0.45633959770202637, -0.6004648804664612, -0.43698248267173767, -0.18759523332118988, 0.16551554203033447, -0.6998035907745361, -0.18623562157154083, -0.2397974282503128, -0.7657685279846191, 0.7651348114013672, 0.11493740975856781, 0.5674659609794617, -0.7223790287971497, -0.35988590121269226, -0.3570496439933777, -0.03564593940973282, -0.7941521406173706, -0.2739706337451935, -0.11738346517086029, -0.27911126613616943, -0.5926401615142822, -0.4189967215061188, -0.24665510654449463, 0.3411913812160492, -0.7394885420799255, 0.9879111647605896, -0.6246516704559326, -0.8878666758537292, 0.6491055488586426, 0.7045660018920898, -0.6607206463813782, -1.5023839473724365, -0.8943555951118469, -0.0056306482292711735, -0.3197881281375885, 0.0802607610821724, 0.8492910861968994, 0.11214510351419449, 0.23000025749206543, -0.4324131906032562, 0.28000879287719727, 0.3924658000469208, -0.09467433393001556, 0.2667621076107025, -0.404752641916275, 0.3627157211303711, -1.3442744016647339, 1.3774477243423462, -0.2730672359466553, -0.44784682989120483, 0.8528271913528442, -0.5823642611503601, -0.2912823557853699, 0.365621954202652, -0.5165473818778992, -0.3423203229904175, -1.5100005865097046, 0.7377020716667175, -0.19635939598083496, -0.20769748091697693, 0.7014114856719971, 0.45545047521591187, 0.5101553797721863, 0.5338705778121948, 0.06972881406545639, 0.650615394115448, -0.0312935896217823, 0.8733665347099304, -0.5567520260810852, 0.287334144115448, 0.5785768032073975, -0.048921674489974976, 0.039071958512067795, -0.08906543999910355, -0.46493101119995117, -0.2970113754272461, -0.37035873532295227, -0.1912952959537506, -0.23927457630634308, 0.48941168189048767, -0.7847617268562317, -0.6982781291007996, -0.059459589421749115, -0.8636044263839722, -0.23421792685985565, 0.42863428592681885, 0.07486935704946518, 0.0366235114634037, -0.744556188583374, -1.041248083114624, -0.4445205628871918, -0.5359522700309753, -0.7887395620346069, 0.30359217524528503, -0.2867806553840637, -0.7453479170799255, -0.5994693636894226, 0.20165669918060303, 0.14111675322055817, 0.2498195916414261, -0.5849483013153076, 1.1523205041885376, -0.12707284092903137, 0.08832815289497375, -0.3134288489818573, 0.5781516432762146, -0.07816014438867569, 0.28148791193962097, -0.25287967920303345, -0.20661237835884094, 0.15163493156433105, -0.03138674423098564, -0.7473283410072327, -0.14395655691623688, 0.19786159694194794, 0.5605151057243347, 0.47426122426986694, -0.7962314486503601, -0.5821431875228882, 0.7471666932106018, -0.2794916033744812, -0.5282874703407288, -0.39348986744880676, 0.600627064704895, 0.9005129933357239, 0.2631695866584778, 0.6925068497657776, 0.41059228777885437, 0.2924240827560425, 0.028749307617545128, -0.40260666608810425, 0.41295361518859863, 0.28182050585746765, 0.28867924213409424, 0.6494246125221252, 0.1449522078037262, -0.07603892683982849, -1.4012458324432373, 0.5947992205619812, -1.5891731977462769, -0.5030248761177063, 0.7416607141494751, 0.6207249760627747, 0.3886209726333618, -0.4712788164615631, -0.603165864944458, -0.572952926158905, 0.42677372694015503, 0.05056118220090866, -0.4349047839641571, -0.17124122381210327, 0.24422723054885864, 0.21883612871170044, -0.3553473949432373, 0.634638249874115, -0.3472820818424225, 0.19824984669685364, 14.862565040588379, 0.2792375981807709, 0.30394038558006287, 0.6638482809066772, 0.37235215306282043, 0.07327276468276978, -0.3188402056694031, -0.5525238513946533, -0.6957192420959473, -0.7134150266647339, 1.1081327199935913, -0.00995134748518467, 0.06000811606645584, 0.09258607029914856, 0.25099998712539673, 0.056828390806913376, -0.9231955409049988, 0.4952385425567627, 0.5099840760231018, -1.3626854419708252, 0.7702658772468567, 0.2112949639558792, 0.3061826229095459, 0.5655456185340881, 0.5028929710388184, 0.7440968155860901, 0.7818030118942261, -0.9540883302688599, 0.2572818398475647, 0.3708615303039551, 0.5671204924583435, -0.1669480949640274, 0.7868899703025818, 0.8386167287826538, -0.8660462498664856, -0.40587034821510315, -0.3699397146701813, -0.4513553977012634, 0.12835238873958588, -0.18357053399085999, -0.8840188980102539, -0.046268194913864136, -0.35537809133529663, 0.55817049741745, 0.42479315400123596, -0.041262708604335785, -0.00793467741459608, 0.01962432451546192, 0.6823583841323853, 0.27052363753318787, 0.22251629829406738, 0.33542630076408386, 0.3824227452278137, -0.29633378982543945, -0.03263186663389206, 0.4711133539676666, 0.39780715107917786, 0.5858213305473328, -0.5805650353431702, 0.085732601583004, -0.49482133984565735, -0.5575406551361084, -0.33897244930267334, 0.6072623133659363, 0.827785313129425, -0.015074462629854679, -0.5397921800613403, 0.03418337181210518, 0.357616662979126, -0.03461248800158501, 0.007615615613758564, -0.036131978034973145, 0.5397047400474548, -0.22918850183486938, -0.3549158275127411, 0.9704971313476562, 0.4174545705318451, -0.5884855389595032, -0.6848806738853455, -0.6333380341529846, 0.7864210605621338, -0.8509083390235901, -1.0172147750854492, 0.9151482582092285, -0.15569695830345154, -1.1546763181686401, -0.17902247607707977, -0.7232326865196228, -0.15283910930156708, 0.3409996032714844, -0.8397770524024963, -0.8546978235244751, 0.13482962548732758, 0.1767883449792862, -0.15786698460578918, -0.25366371870040894, 1.4660323858261108, -0.1625012755393982, -0.32723721861839294, -0.18336597084999084, -0.0012569285463541746, -0.1599176675081253, 0.4521150588989258, -0.4348456859588623, 0.1260531097650528, -0.27761310338974, -0.48450028896331787, 0.7645159959793091, 0.025593187659978867, -0.17136983573436737, -0.8361985683441162, -0.19186648726463318, 0.4868239760398865, -0.9579477310180664, -0.2579754889011383, -0.8445309400558472, -1.0466328859329224, 0.21735605597496033, 0.5300961136817932, -0.10500741004943848, 0.5982483625411987, -0.25884056091308594, -0.1845971643924713, 0.11717551201581955, -1.229567289352417, 0.32910218834877014, 0.531110942363739, -0.8024483919143677, -0.9246097207069397, 0.5052877068519592, 0.2978832721710205, -0.7579079866409302, -0.6291729211807251, 0.09896914660930634, 0.12723101675510406, 0.3150930404663086, 0.6288473606109619, -1.0265240669250488, 0.3825724124908447, 0.7394145131111145, 0.2600768506526947, -0.5695033073425293, 0.08883880078792572, -0.8818729519844055, 0.005369257181882858, -0.2704835832118988, 0.8553371429443359, -0.3406327962875366, -0.40497007966041565, 1.1104629039764404, 0.46515852212905884, -0.6825333833694458, -0.7461248636245728, 0.25251251459121704, 0.1307557225227356, -0.3164098262786865, -0.11532073467969894, 0.1675363928079605, 0.5007025599479675, -0.2989199459552765, 0.3095371723175049, 1.177833080291748, -0.11746204644441605, -0.5157766342163086, 0.31614628434181213, -0.5040878057479858, -0.09214624762535095, -0.3235340416431427, -0.23285573720932007, -0.7000954747200012, 0.04364778846502304, -1.112830400466919, 0.3901059627532959, -1.215576171875, -0.39696675539016724, 0.5367196798324585, -0.5620080828666687, -0.09718496352434158, 0.45461004972457886, -0.6228746175765991, -1.091181755065918, -0.5295329689979553, -0.8189966678619385, 0.2660176157951355, 1.0041934251785278, -0.9290642738342285, 0.11703374236822128, -0.14727796614170074, -0.033588308840990067, 0.5970646739006042, 0.1780771017074585, -0.3229512870311737, -1.2552064657211304, -0.7874050736427307, 0.20756961405277252, 0.26905086636543274, 0.02164245769381523, -0.42032742500305176, 0.8617260456085205, 0.2795792520046234, -0.39836710691452026, 0.031146716326475143, 0.41663113236427307, -0.5947101712226868, -0.2304796427488327, 0.7397851347923279, -1.054006576538086, -0.2754829227924347, 0.07938196510076523, -0.5590542554855347, -0.25743457674980164, 0.5535003542900085, 0.08349147439002991, -1.5103695392608643, -0.4935944974422455, 0.3419506549835205, -1.2553942203521729, 0.17876321077346802, 0.345175176858902, 0.2392033040523529, -0.7623975276947021, -0.2574705481529236, -0.513730525970459, 1.137219786643982, -0.5860229134559631, 1.0098590850830078, 0.5527236461639404, -0.5737977623939514, -0.3563635051250458, 0.0699584037065506, 0.35110655426979065, -0.1790270060300827, 1.0151132345199585, 0.4253798723220825, -0.1594073474407196, 0.5330286026000977, 0.39447021484375, 0.29806622862815857, -1.3259576559066772, -0.09814147651195526, 1.0880769491195679, -0.5875759720802307, -0.23387938737869263, 1.0758367776870728, 0.31048205494880676, -1.1278269290924072, 0.3655814230442047, -1.0047653913497925, -0.9051498174667358, -0.44327253103256226, 0.9878990054130554, 0.09995871037244797, -0.06226755678653717, -0.02040724828839302, -0.8784639239311218, 0.2571515440940857, -0.37464192509651184, -0.6389174461364746, 0.4526955783367157, -0.020175613462924957, -0.6040346622467041, 0.7881456017494202, 0.028415631502866745, -0.3783796429634094, 0.1735725700855255, -0.37654000520706177, -0.41271641850471497, 0.6956217885017395, 0.2312418818473816, -0.6580715775489807, 0.10618741810321808, 0.3468959927558899, 0.6488971710205078, 0.035873301327228546, -0.3453722894191742, 0.3983183205127716, -0.3307121992111206, 0.8830490112304688, 0.09959530085325241, -0.47610872983932495, -0.49183210730552673, 0.5107548832893372, 1.675170660018921, -1.3317209482192993, 0.13723483681678772, -0.29718926548957825, -0.9510650634765625, 0.949741780757904, 0.5412074327468872, 0.4620281755924225, 0.8710808157920837, -0.346428245306015, 0.7999238967895508, -0.40679895877838135, -1.4268097877502441, -0.01490492932498455, 1.0091053247451782, 0.7464924454689026, 0.7982237935066223, 0.37914296984672546, -0.27457451820373535, 0.8727631568908691, 0.6806237101554871, 0.6896581649780273, 0.6605730056762695, 0.6302709579467773, 0.06912780553102493, -0.22081983089447021, 0.2745458483695984, 0.29664742946624756, -0.5579435229301453, -0.2884001135826111, -0.5109983682632446, 0.47008970379829407, 0.652076244354248, 0.9113061428070068, 0.35465797781944275, 0.4275136888027191, 0.33119362592697144, 0.3295416235923767, 0.21766825020313263, -0.7661475539207458, -0.07321926206350327, -0.28303956985473633, -0.2699974477291107, -0.19020602107048035, -0.46579039096832275, -0.09337428212165833, -0.9112113118171692, 0.33551499247550964, 0.6539060473442078, 0.34029844403266907, -0.20087887346744537, 1.6515443325042725, 0.7238999605178833, 0.36449265480041504, -0.603724479675293, 0.3825136721134186, -0.6261904835700989, -0.827586829662323, -0.11808660626411438, -0.5191494822502136, -0.05594789236783981, -0.36958613991737366, -0.17585478723049164, -0.6476900577545166]}, "authors": [{"authorId": "47274259", "name": "Xiangru Tang"}, {"authorId": "2187586628", "name": "Anni Zou"}, {"authorId": "3322871", "name": "Zhuosheng Zhang"}, {"authorId": "46316984", "name": "Yilun Zhao"}, {"authorId": "2267545169", "name": "Xingyao Zhang"}, {"authorId": "2266838179", "name": "Arman Cohan"}, {"authorId": "2201323142", "name": "Mark B. Gerstein"}], "references": [{"paperId": "7e55d8701785818776323b4147cb13354c820469", "title": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"}, {"paperId": "15a2682ba1b479dea284062dd097a9a349a2eceb", "title": "AlpaCare: Instruction-tuned Large Language Models for Medical Application"}, {"paperId": "f0227a0500f2875d9af3d62b5afb3bb93c2b4561", "title": "OpenAgents: An Open Platform for Language Agents in the Wild"}, {"paperId": "a80546c9847710af1ba8d5f8dca9386e7a520d0a", "title": "Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration"}, {"paperId": "1562390dd212516cd857009cbd4f857a902d1f3d", "title": "MetaAgents: Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination via Collaborative Generative Agents"}, {"paperId": "844bc3b26b5c63ec3b251ae634c194dcfb41a7d2", "title": "InvestLM: A Large Language Model for Investment using Financial Domain Instruction Tuning"}, {"paperId": "0c72450890a54b68d63baa99376131fda8f06cf9", "title": "The Rise and Potential of Large Language Model Based Agents: A Survey"}, {"paperId": "5e761e9f5cd9672a181b256299cd2916a8079461", "title": "Augmenting Black-box LLMs with Medical Textbooks for Clinical Question Answering"}, {"paperId": "0a10b5af8d6024b1888ae8faed08d5b4e62b09a6", "title": "MedChatZH: a Better Medical Adviser Learns from Better Instructions"}, {"paperId": "28c6ac721f54544162865f41c5692e70d61bccab", "title": "A Survey on Large Language Model based Autonomous Agents"}, {"paperId": "aade40af0d85b0b4fe15c97f6222d5c2e4d6d9b3", "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models"}, {"paperId": "e3fd89a7f6b28973cfc68bfc51caebd8fb93f0bc", "title": "BioMedGPT: Open Multimodal Generative Pre-trained Transformer for BioMedicine"}, {"paperId": "e41482f4ee984f17382f6cdd900df094d928be06", "title": "WebArena: A Realistic Web Environment for Building Autonomous Agents"}, {"paperId": "aff0fe00ed7892d1185e8c5b66d318d3892abe6e", "title": "Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health"}, {"paperId": "8ea61d037bfe3a8e6f0211e9e63f840ead34cc72", "title": "Evaluation of the performance of GPT-3.5 and GPT-4 on the Medical Final Examination"}, {"paperId": "f22d71c7ce9720ba1f717a4f1181488200e78198", "title": "LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day"}, {"paperId": "385c74957858e7d6856d48e72b5a902b4c1aa28c", "title": "Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate"}, {"paperId": "ebf3a59aacdd9982283d7f41229ee2a93800d6ef", "title": "Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks"}, {"paperId": "4780d0a027c5c5a8e01d7cf697f6296880ffc945", "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate"}, {"paperId": "2e6b6de08f459e2165b11ed8d2103916966b0fcf", "title": "Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback"}, {"paperId": "7ac387fa5d2bbfa99d8d1957d76e58e5154d1e0c", "title": "Summarizing, Simplifying, and Synthesizing Medical Evidence using GPT-3 (with Varying Success)"}, {"paperId": "7445ca3b53cf597b1c81b347b3e954e70b71dee9", "title": "GersteinLab at MEDIQA-Chat 2023: Clinical Note Summarization from Doctor-Patient Conversations through Fine-tuning and In-context Learning"}, {"paperId": "23b8dd1978dd2d27e5ab4dc4a8fe11ea6dd57064", "title": "Evaluating large language models on medical evidence summarization"}, {"paperId": "05e003a34148d4663734d3f39deefa0979d2a0e6", "title": "GeneGPT: Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information"}, {"paperId": "5278a8eb2ba2429d4029745caf4e661080073c81", "title": "Generative Agents: Interactive Simulacra of Human Behavior"}, {"paperId": "9faa2b0e5cb93f20df0555c3c350fab0b2eccf3a", "title": "Foundation models for generalist medical artificial intelligence"}, {"paperId": "44bab2836177f8bf9775e7ca536b8e200757aac7", "title": "Hallucinations in Large Multilingual Translation Models"}, {"paperId": "4a7f6c4e71e20311ade4e76e8d0945d499c31fcd", "title": "ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge"}, {"paperId": "574beee702be3856d60aa482ec725168fe64fc99", "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4"}, {"paperId": "348a1efa54376fa39053e5e25d52bd0eb6a0ba68", "title": "Capabilities of GPT-4 on Medical Challenge Problems"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "3d68522abfadfc8ee6b7ec9edaaf91f1b2f38e5e", "title": "Large Language Models Can Be Easily Distracted by Irrelevant Context"}, {"paperId": "680c72c29b518398d9c45b5995a160583ea8e090", "title": "Analysis of large-language model versus human performance for genetics questions"}, {"paperId": "6052486bc9144dc1730c12bf35323af3792a1fd0", "title": "Large language models encode clinical knowledge"}, {"paperId": "cc43306e22dbfd5bc35251ab8c8ba37e4fc2a1b3", "title": "Legal Prompting: Teaching a Language Model to Think Like a Lawyer"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "d697b440dd0e65a05fe027e4c0ea85f62dcba033", "title": "Can large language models reason about medical questions?"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "5f19ae1135a9500940978104ec15a5b8751bc7d2", "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"}, {"paperId": "fc97c3f375c7228a1df7caa5c0ce5d2a6a171bd7", "title": "What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "dbeeca8466e0c177ec67c60d529899232415ca87", "title": "On Faithfulness and Factuality in Abstractive Summarization"}, {"paperId": "0c3c4c88c7b07596221ac640c7b7102686e3eae3", "title": "PubMedQA: A Dataset for Biomedical Research Question Answering"}, {"paperId": "156d217b0a911af97fa1b5a71dc909ccef7a8028", "title": "SciBERT: A Pretrained Language Model for Scientific Text"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "95ea28c0175f5807eaf26ea75bd2f34a385c2fd4", "title": "HIPAA Privacy Rule"}, {"paperId": "71e958a8398038fbf02c25fc7522eb7eb3c1dec2", "title": "How expertise develops in medicine: knowledge encapsulation and illness script formation"}, {"paperId": "1a4c6856292b8c64d19a812a77f0aa6fd47cb96c", "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework"}, {"paperId": "75c08892179fc478f87d7020b5daff9fca4f3389", "title": "Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models"}, {"paperId": "7ca954844bc1dd405bc43445b1c990e42d865095", "title": "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society"}, {"paperId": "ad97671a924a9b3a060fee857e561f140ec79dd7", "title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents"}, {"paperId": "fbd4a876cee20eaf98f344aca597a55338f663f5", "title": "Examining the Inter-Consistency of Large Language Models: An In-depth Analysis via Debate"}, {"paperId": null, "title": "Hallucinations refer to instances where the language model starts generating inaccurate or irrelevant information based on its insufficient understanding"}, {"paperId": null, "title": ". Task-driven autonomous agent"}, {"paperId": null, "title": ". Chain-of-thought prompting elicits"}, {"paperId": null, "title": "employing a CoT approach might sometimes lead to hallucination (Bubeck et al., 2023; Guerreiro et al., 2023; Ji et al., 2023; Maynez et al.,"}, {"paperId": "45fbc6adba5f83acae4737ac1cd08f77e5b8c386", "title": "[Models in medicine]."}, {"paperId": null, "title": "2022. Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering"}, {"paperId": null, "title": "2023. Large language models answer medical questions accurately, but can\u00e2 \u02d8A\u00b4Zt match clinicians\u00e2 \u02d8 A \u00b4 Z knowledge"}, {"paperId": null, "title": "2023. Performance of chatgpt on usmle: Potential for ai-assisted medical education using large language models"}, {"paperId": null, "title": "2023. Survey of hallucination in natural language generation"}, {"paperId": null, "title": "2023. Communicative agents for software development"}, {"paperId": null, "title": "A Analysis on the Addition of CoT We provide an intriguing example that reveals a seemingly counter-intuitive observation: the addition of the CoT in a zero-shot setting led to"}, {"paperId": null, "title": "2023c. Theory of mind for multi-agent collaboration via large language models"}, {"paperId": null, "title": "our experiments, with a substantial 77% of errors related to domain knowledge, compared to a minor 8% due to CoT (as shown in Figure 5)"}, {"paperId": null, "title": "originate from a lack of domain knowledge (Harris, 2023; Kung et al., 2023; Tian et al., 2024) instead of reasoning rationale"}, {"paperId": null, "title": "2023d. Unleashing cognitive synergy in large language models: A task-solving agent through multi-persona self-collaboration"}, {"paperId": null, "title": "You are a medical expert who specializes in categorizing a specific medical scenario into specific areas of medicine"}, {"paperId": null, "title": "As demonstrated in the example, for specialist domains that demand considerable expert knowledge such as the medical domain knowledge, employing a CoT approach might sometimes lead to hallucination"}, {"paperId": null, "title": "2023. Chameleon: Plug-and-play compositional reasoning with large language models"}, {"paperId": null, "title": "Such failures in medical question-answering originate from a lack of domain knowledge"}, {"paperId": null, "title": "2023. Towards generalist biomedical ai"}, {"paperId": null, "title": "the results from Li\u00e9vin et al. (2022) demonstrate that CoT improvements are significantly limited"}, {"paperId": null, "title": "2023. Gpt-4 technical report"}, {"paperId": null, "title": "2023a. Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models"}, {"paperId": null, "title": ": our use of role-playing"}, {"paperId": null, "title": "2024. Biomedlm: A 2.7 b parameter language model trained on biomedical text"}, {"paperId": null, "title": "a recent shift toward utilizing RAG (Retrieval-Augmented Generation) for domain knowledge enhancement (Wang et al., 2023b; L\u00e1la et al., 2023) in"}, {"paperId": null, "title": "This issue is particularly stated in the medical question-answering field by some recent work, where it has been demonstrated that the CoT\u2019s step-by-step approach is unable to generate correct"}, {"paperId": null, "title": "2023. Baize: An open-source chat model with parameter-efficient tuning on self-chat data"}, {"paperId": null, "title": "OpenAI"}, {"paperId": null, "title": "Interpretability: Case Study We analyze instances where our proposed MC framework manages to correct previous errors. Table B illustrates"}, {"paperId": null, "title": "or irrelevant information based on its insufficient understanding (Wei et al., 2022; Kojima et al., 2022; Shi et al., 2023). Consequently"}, {"paperId": null, "title": "2023b. Aligning factual consistency for clinical studies summarization through reinforcement learning"}]}