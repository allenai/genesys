{"paperId": "9fdf392c20b4aa9e756e07e9acb10e14f7379418", "abstract": "Recently, many methods have been developed to extend the context length of pre-trained large language models (LLMs), but they often require fine-tuning at the target length ($\\gg4K$) and struggle to effectively utilize information from the middle part of the context. To address these issues, we propose $\\textbf{C}$ontinuity-$\\textbf{R}$elativity ind$\\textbf{E}$xing with g$\\textbf{A}$ussian $\\textbf{M}$iddle (CREAM), which interpolates positional encodings by manipulating position indices. Apart from being simple, CREAM is training-efficient: it only requires fine-tuning at the pre-trained context window (eg, Llama 2-4K) and can extend LLMs to a much longer target context length (eg, 256K). To ensure that the model focuses more on the information in the middle, we introduce a truncated Gaussian to encourage sampling from the middle part of the context during fine-tuning, thus alleviating the ``Lost-in-the-Middle'' problem faced by long-context LLMs. Experimental results show that CREAM successfully extends LLMs to the target length for both Base and Chat versions of $\\texttt{Llama2-7B}$ with ``Never Miss A Beat''. Our code will be publicly available soon.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A truncated Gaussian is introduced to encourage sampling from the middle part of the context during fine-tuning, thus alleviating the ``Lost-in-the-Middle'' problem faced by long-context LLMs."}, "embedding": {"model": "specter_v2", "vector": [0.0446137897670269, 0.6766351461410522, -0.4333556592464447, -0.18565066158771515, -0.5294856429100037, -0.13242694735527039, 0.3926413655281067, -0.31619808077812195, -0.39477819204330444, -0.3882690370082855, 0.5844371914863586, -0.054091181606054306, 0.6035223007202148, 0.15627020597457886, -0.29878509044647217, -0.26937106251716614, -1.0538235902786255, 0.0705336332321167, -0.11117395013570786, -0.4913578927516937, -0.478590726852417, -1.0905163288116455, -0.3880873918533325, 0.33518245816230774, 0.31103289127349854, 0.2727663815021515, 0.5199273228645325, 1.0025384426116943, -0.44154828786849976, 0.18619856238365173, 0.36716151237487793, -0.5236806273460388, 0.35451796650886536, -0.15038277208805084, -0.15896739065647125, -0.03942790627479553, -0.10572060197591782, -0.6144067049026489, -0.31389594078063965, 0.6435675024986267, 0.03241540119051933, 0.20757727324962616, -0.15963727235794067, -0.6096017956733704, -0.23222613334655762, 1.3601073026657104, 0.39259493350982666, 0.6431471705436707, -0.6119685173034668, -0.7568624019622803, 1.4831023216247559, -1.2943395376205444, 0.2750283479690552, 1.5427888631820679, 0.5478858351707458, 0.5407477021217346, -0.4854643642902374, -0.5600936412811279, 0.8663265705108643, -0.0654681921005249, -0.8749997019767761, -0.4502769708633423, 0.008172568865120411, 0.135172039270401, 1.5768978595733643, -0.19378165900707245, -0.08547495305538177, 0.91685950756073, -0.3513275384902954, 1.220572590827942, -0.6251429319381714, -0.9012680053710938, -0.5836693644523621, 0.22324401140213013, 0.0904892310500145, 0.47084763646125793, -0.7009501457214355, 0.4888577461242676, -0.6576755046844482, -0.4884490668773651, 0.3235694169998169, -0.2935395836830139, 0.08585599064826965, -0.042269181460142136, -0.3661898374557495, 0.8878999352455139, 0.10069252550601959, 0.8028035759925842, 0.3561966121196747, 0.8398207426071167, 0.6004421710968018, 0.48286986351013184, 0.3175448477268219, -0.07332345843315125, -0.16680751740932465, 0.06382932513952255, -0.7304829359054565, 0.3773270845413208, -0.10115505009889603, 0.8404852747917175, -0.23419003188610077, 0.13167704641819, -0.8559791445732117, 0.6022255420684814, 1.338320255279541, -0.03518451750278473, 0.29009729623794556, -0.874449610710144, 0.5879809260368347, -0.8556607365608215, 0.2584778964519501, -0.07939326018095016, -0.30586040019989014, -0.041217636317014694, -0.5490304231643677, -1.2661672830581665, 0.013860304839909077, -0.2221977412700653, -0.30993348360061646, 0.9621109962463379, 0.05328434333205223, 0.27123764157295227, 0.1120145246386528, 0.2549101710319519, 0.35046979784965515, 1.0266640186309814, -0.05194080248475075, -0.06184336170554161, 0.8137248158454895, -1.1482840776443481, -0.8337727189064026, -1.1963104009628296, 0.9443161487579346, -0.4537508189678192, 0.6588003635406494, -0.1294994205236435, -0.9429798126220703, -0.9079028964042664, -0.987265944480896, 0.03443315252661705, -0.36748749017715454, 0.29059094190597534, 0.7090693712234497, 0.5359871983528137, -0.8940420150756836, 0.8403133749961853, -0.10698530822992325, 0.00800083763897419, -0.07121779024600983, -0.16909250617027283, 0.21663716435432434, -0.3474651873111725, -1.6577160358428955, 0.17198728024959564, 0.24461382627487183, -0.4042414128780365, 0.01221300195902586, -0.5077172517776489, -1.0088598728179932, -0.425655335187912, 0.7001513242721558, -0.27804356813430786, 1.5155283212661743, 0.0544116385281086, -1.333531141281128, 0.3472279906272888, -0.2836805284023285, 0.12276839464902878, 0.3411559760570526, -0.39342519640922546, -0.5047567486763, -0.6875271201133728, -0.6646051406860352, 0.46734619140625, 0.31955790519714355, -0.13847480714321136, -0.26541751623153687, 0.08302195370197296, -0.16269375383853912, 0.12529826164245605, -0.07603401690721512, 1.0160490274429321, -0.5526929497718811, -0.40553542971611023, -0.028143858537077904, 0.4129863381385803, -0.23581570386886597, -0.4023059904575348, -0.13881193101406097, -0.939213216304779, 0.9937433004379272, -0.05489426106214523, 1.5972506999969482, -0.8258976340293884, -0.7855278253555298, -0.3111758530139923, -0.519286572933197, -0.19859884679317474, -0.7683805227279663, 0.4792415201663971, -0.03415987640619278, 0.28055229783058167, -0.013166707940399647, -1.3474465608596802, 0.19799402356147766, -0.09705229103565216, -0.709716260433197, -0.20396234095096588, -0.06483867764472961, 0.9068669676780701, -1.0136865377426147, 0.08358871936798096, -0.1454404592514038, 0.44323328137397766, -1.0998913049697876, 1.1879997253417969, -0.6210457682609558, 0.31985780596733093, 0.22502337396144867, -0.2579475939273834, -0.05858943611383438, -0.06894046068191528, 0.30311301350593567, 0.019047657027840614, -0.00587643263861537, 0.45997515320777893, -0.657447874546051, 1.5363085269927979, -0.38672855496406555, 0.3484068214893341, 0.3528015911579132, -0.42708897590637207, -0.029011951759457588, 0.5769268870353699, -0.28331229090690613, 0.08097808808088303, 0.3619864284992218, 0.50380539894104, -0.35523441433906555, 0.34144842624664307, 0.7907295227050781, 0.8180513381958008, -0.45357170701026917, 0.005046240985393524, 0.41884860396385193, -0.11208153516054153, 0.40348461270332336, 0.30590322613716125, 0.06884286552667618, 0.6400717496871948, 0.33702903985977173, 0.15205566585063934, 0.2421106994152069, -1.1139816045761108, -0.024891557171940804, 0.4777078330516815, 0.5354713797569275, 0.8229971528053284, 0.5841774344444275, -0.6184101700782776, -0.4413660764694214, 0.25201690196990967, 0.39839208126068115, 1.9553892612457275, -0.2721225619316101, -0.49160659313201904, -0.8645740747451782, -0.3001469075679779, -0.3699294328689575, 0.08227146416902542, -0.5503324270248413, 0.06787095963954926, -0.886238694190979, -1.0722466707229614, 0.9691945910453796, 0.18177616596221924, 0.4517345428466797, -0.2703862190246582, -0.0025780033320188522, -0.05168263241648674, 0.11200326681137085, -0.9855974912643433, -1.057539701461792, 0.3852098286151886, -0.7272869348526001, 0.22370414435863495, -0.2589624226093292, -0.12416645884513855, -0.3037979304790497, -1.0357156991958618, 0.5860117077827454, -0.6089909076690674, -0.006580458953976631, -0.22144021093845367, 0.3340687155723572, -0.584662139415741, -1.1831059455871582, 0.11385613679885864, 0.11771401017904282, 0.015904290601611137, 0.07702969759702682, 0.5323036909103394, 0.2497437596321106, 0.11156369000673294, -0.26271852850914, 0.18427810072898865, -0.036244142800569534, 0.3192034065723419, 0.5120599269866943, -0.6285135746002197, 0.25898486375808716, -1.1317715644836426, 0.9085023403167725, 0.545575737953186, -0.4625970125198364, 0.16419824957847595, -0.5972015261650085, -0.2901512682437897, 0.49664512276649475, -0.8465756177902222, -0.2025052011013031, -1.0129413604736328, -0.09331011027097702, -0.20148944854736328, 0.09043552726507187, 0.019452746957540512, -0.005820804741233587, 0.4012737274169922, 0.3247944116592407, 0.30255910754203796, 0.32065367698669434, -0.2834804952144623, 0.7398240566253662, -0.3842167258262634, 0.2645787298679352, 0.14431054890155792, -0.30545103549957275, -0.11082536727190018, -0.5102724432945251, -0.5693111419677734, -0.257729172706604, -0.6121997237205505, -0.3146938681602478, -0.09740059822797775, -0.05877763777971268, -0.532657265663147, -0.46258124709129333, -0.11198196560144424, -0.975013017654419, -0.4936946630477905, 0.31361111998558044, -0.14543168246746063, -0.4207770526409149, -0.7067277431488037, -1.340254306793213, -0.517920970916748, -0.6100688576698303, -1.2040208578109741, 0.3732132315635681, -0.1432407796382904, -0.42580628395080566, -0.5823943614959717, 0.05155222490429878, -0.4170367121696472, 0.903232753276825, -0.8644081354141235, 0.6449754238128662, -0.16320516169071198, 0.20806652307510376, -0.31513455510139465, 0.47347569465637207, 0.6337816119194031, -0.30250826478004456, 0.10441362112760544, -1.149478793144226, 0.2731999456882477, -0.2073952555656433, 0.012579821050167084, 0.1840701699256897, 0.5068928599357605, 0.5947917699813843, -0.14690300822257996, -0.6481714248657227, 0.2788037061691284, 0.8471471667289734, -0.5186237096786499, 0.42534130811691284, -0.05205462500452995, 0.7780474424362183, 0.08247245848178864, -0.04668421670794487, 0.758067786693573, 0.04488169401884079, 0.4736163318157196, 0.005542594939470291, 0.04856688529253006, 0.03693003952503204, -0.3973415493965149, 0.9178726077079773, 1.4631526470184326, 0.25655704736709595, 0.13857223093509674, -0.7463950514793396, 0.6821861863136292, -1.3998526334762573, -0.8933923840522766, 0.9201802015304565, 0.9588910937309265, 0.7994587421417236, -0.23537695407867432, -0.04437030851840973, -0.44119876623153687, 0.706638753414154, 0.5817008018493652, 0.008154996670782566, -0.9714691042900085, 0.21017935872077942, -0.19927874207496643, -0.17808090150356293, 0.8919534087181091, -0.49265119433403015, 0.5853346586227417, 14.983389854431152, 1.073573112487793, 0.07438269257545471, 0.7068768739700317, 0.7798061370849609, -0.13446247577667236, -0.10821336507797241, -0.13994649052619934, -1.534955382347107, 0.007232136558741331, 1.3650153875350952, 0.33746981620788574, 0.8862177729606628, 0.2627982199192047, 0.3798280358314514, 0.37887686491012573, -0.5165982246398926, 0.7816272377967834, 0.32141637802124023, -1.0708197355270386, 0.12454681098461151, 0.1992684155702591, 0.3649895489215851, 0.740424394607544, 0.5750726461410522, 1.0115021467208862, 0.31154391169548035, -0.13898588716983795, 0.4994874894618988, -0.04633688926696777, 0.6715885400772095, -0.4152868092060089, 0.30180972814559937, 0.6483357548713684, -0.8040001392364502, -0.48695608973503113, -0.7361341714859009, -1.017282485961914, 0.2749314606189728, 0.28588032722473145, -0.4318448305130005, -0.6462268829345703, -0.18907636404037476, 0.3521999418735504, 0.18513061106204987, 0.24383120238780975, 0.2473287284374237, 0.5986664891242981, -0.1626647561788559, 0.011921885423362255, 0.7061725854873657, 0.05220725014805794, 0.5743367075920105, 0.3147227466106415, 0.39606890082359314, -0.2804100811481476, 0.15720780193805695, 0.6190125942230225, -0.44764402508735657, 0.12219700962305069, -0.20558016002178192, -0.2974175214767456, 0.052075713872909546, 0.7162719964981079, 0.7116742730140686, -0.09237551689147949, -0.44231873750686646, 0.15246576070785522, 0.479267954826355, 0.19596508145332336, -0.384827196598053, -0.318205863237381, 0.5612481236457825, -0.4632214903831482, 0.04431203380227089, 0.6783583760261536, -0.10848186910152435, -0.48790624737739563, -0.682889997959137, -0.2801181375980377, 0.38801345229148865, -0.6211177706718445, -0.32083606719970703, 0.7994550466537476, -0.08983629196882248, -0.4215696454048157, 0.056195616722106934, -0.41374263167381287, -0.2760576009750366, 0.5564766526222229, -1.1642698049545288, -0.8096898198127747, 0.7120518684387207, -0.41113999485969543, -0.2308645397424698, 0.282365083694458, 1.381137728691101, 0.2027309089899063, -0.4478888511657715, 0.35558146238327026, 0.545099139213562, 0.1257055699825287, 0.1790686696767807, -0.7584022283554077, 1.036840558052063, 0.3325020372867584, -0.06605777144432068, 0.25692546367645264, 0.1529936045408249, 0.29677867889404297, -0.2458658218383789, -0.04002667963504791, 0.6647945046424866, -0.918443500995636, -0.22610314190387726, -1.0683284997940063, -0.71819669008255, 0.4416968822479248, 0.6401150226593018, -0.00592133728787303, 0.268269419670105, 0.3911088705062866, -0.6009470820426941, -0.5776639580726624, -0.46015575528144836, 0.18347129225730896, 0.45439034700393677, -0.6610544323921204, -0.22693860530853271, -0.2875915467739105, 0.6256013512611389, -1.2927577495574951, -0.5639705657958984, -0.12207268923521042, 0.07680976390838623, -0.023322422057390213, 0.8884749412536621, -0.10539598762989044, 0.31986719369888306, 0.9262760877609253, -0.27050191164016724, -0.9864262938499451, 0.25163787603378296, -1.4187731742858887, -0.21758031845092773, 0.32174620032310486, 0.7248084545135498, -0.03159741684794426, -0.07852981984615326, 0.6008697748184204, 0.18507888913154602, -0.6557492613792419, -0.858395516872406, -0.39656803011894226, 0.4794345498085022, -1.0361506938934326, 0.5194999575614929, -0.32716941833496094, 0.5019925236701965, 0.05351332202553749, 0.036640845239162445, 0.6070708632469177, -0.4144221544265747, -0.7202588319778442, 0.39293327927589417, 0.3043847382068634, -0.2585003972053528, -0.6335006952285767, -0.2696816027164459, -1.465693712234497, -0.4277600944042206, -1.0127946138381958, 0.0910116657614708, -0.5249233245849609, -0.37824878096580505, 0.008845096454024315, -0.18762683868408203, -0.25278550386428833, 0.2793544828891754, -0.2657153010368347, -0.42786848545074463, -0.8627844452857971, -0.49913743138313293, 0.7305017113685608, 0.9540952444076538, -0.5343281626701355, -0.16538554430007935, 0.17175517976284027, 0.0016180549282580614, 0.41105788946151733, 0.401814728975296, -0.45975756645202637, -0.6245642900466919, -1.291459321975708, 0.5085591673851013, -0.13362285494804382, -0.17525559663772583, -0.32561466097831726, 0.06615745276212692, 0.27609047293663025, -0.17712946236133575, -0.014733455143868923, 0.40881672501564026, -0.7063189148902893, -0.5677049160003662, 0.04074707627296448, -0.8210642337799072, 0.035104501992464066, 0.2410936802625656, -0.5871537327766418, -0.24575671553611755, 0.485605925321579, 0.09902302920818329, -1.0111260414123535, -0.5091491937637329, 0.16996914148330688, -0.47977957129478455, 0.22853270173072815, -0.4688841700553894, 0.18592368066310883, -0.7931885719299316, -0.3344496488571167, -0.37741971015930176, 0.11702876538038254, -0.45250704884529114, 1.1005923748016357, 0.04678914695978165, -1.3033159971237183, -0.07995534688234329, 0.44106417894363403, 0.10473374277353287, 0.13294817507266998, 0.5129293203353882, 0.5318347811698914, -0.01623474434018135, 0.40851226449012756, 0.8206181526184082, 0.1249045804142952, -1.2077357769012451, -0.0348496250808239, 0.793920636177063, -0.5299583673477173, -0.3427448570728302, 1.3140150308609009, -0.30376163125038147, -1.325903296470642, 0.6089861989021301, -1.7803897857666016, -0.2602143883705139, -0.25980818271636963, 1.1622658967971802, 0.19299940764904022, -0.012889917939901352, -0.1364794820547104, -0.30713772773742676, -0.03789824992418289, -0.0947452262043953, -0.4576954245567322, 0.4388968050479889, -0.7441987991333008, -0.249506413936615, 0.8184413909912109, 0.8968258500099182, -0.3477441370487213, -1.0019372701644897, -0.5971302390098572, -0.3580804169178009, 0.045160405337810516, 0.24902966618537903, -0.3861891031265259, -0.2588476240634918, 1.0091605186462402, 0.4835444688796997, 0.2829560935497284, -0.23908141255378723, 0.13033133745193481, 0.3671188950538635, 0.826030433177948, -0.06944788992404938, -1.165103554725647, -0.7377052307128906, 1.2599773406982422, 1.4101130962371826, -0.9661461710929871, 0.011823535896837711, 0.18023228645324707, -0.970839262008667, 0.720245897769928, 0.2302897423505783, 0.30267682671546936, 1.0552895069122314, -0.024582302197813988, 0.5147974491119385, 0.6672094464302063, -1.110697627067566, -0.08808174729347229, 0.8062900304794312, 0.7137352824211121, 0.632728099822998, 0.18469876050949097, 0.3012557029724121, 1.3124065399169922, 0.11457355320453644, 0.00724938977509737, 0.5822843313217163, 0.3364015221595764, -0.4371488094329834, -0.2490537017583847, -0.4105195105075836, 0.2960324287414551, -1.075798511505127, -0.6718226075172424, 0.19765357673168182, 0.5941038131713867, 0.30347970128059387, 0.6006302833557129, 0.547123372554779, 0.18043920397758484, 0.22989048063755035, 0.6392483711242676, 0.533552348613739, -0.37870973348617554, -0.2519375681877136, 0.5302571058273315, -0.5183796882629395, -0.07697034627199173, 0.17771971225738525, -0.4534417688846588, -0.4667777717113495, -0.14899824559688568, -0.018637554720044136, -0.17006734013557434, 0.10377269238233566, 1.1025993824005127, 0.44815683364868164, 0.3076314330101013, -0.29477789998054504, -0.5065996050834656, -0.6217719912528992, -1.1007139682769775, -0.20210281014442444, -0.42978739738464355, -0.08368677645921707, 0.310258150100708, -0.016874687746167183, -0.22180160880088806]}, "authors": [{"authorId": "2305744825", "name": "Tong Wu"}, {"authorId": "2305745806", "name": "Yanpeng Zhao"}, {"authorId": "2305710447", "name": "Zilong Zheng"}], "references": [{"paperId": "93765da00ae8f14bb7675b95fc55a8a57fff091f", "title": "Can Perplexity Reflect Large Language Model's Ability in Long Text Understanding?"}, {"paperId": "ebc746fe7d2d580912498a98ec76a1e60020c95d", "title": "Long Context Alignment with Short Instructions and Synthesized Positions"}, {"paperId": "61e113406312785f8471e53dc28da7377ab6ced4", "title": "LLoCO: Learning Long Contexts Offline"}, {"paperId": "3fd5bc3077d04965eaa3498372c39bbdd09d55e4", "title": "Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention"}, {"paperId": "c9603ec967879c24973b5bd48861df2e5555932e", "title": "LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens"}, {"paperId": "9da427202cc48370fd66359f5d72ff5ff3bc8b57", "title": "Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks"}, {"paperId": "0595dac8260443365dfbe4821787419736baaa66", "title": "Extending LLMs' Context Window with 100 Samples"}, {"paperId": "1be73fa3e856c33d0aed1d9e46693523e7fa3c60", "title": "Zoology: Measuring and Improving Recall in Efficient Language Models"}, {"paperId": "0484f05b6b3c11a9344cb623649ae867f172046f", "title": "LooGLE: Can Long-Context Language Models Understand Long Contexts?"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "5e0cb1c4b91a7486e1c2b15a44a0be56bd74bdc0", "title": "Effective Long-Context Scaling of Foundation Models"}, {"paperId": "73290ecbec2f38d1d647ddef1ada69cee41725b3", "title": "PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "b31a5884a8ebe96b6300839b28608b97f8f8ef76", "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding"}, {"paperId": "2dfb9171e180dcb0af23d305e024d43d311708ab", "title": "Giraffe: Adventures in Expanding Context Lengths in LLMs"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "b069c32fcd77160f944ab3ba71ab6f0cfb782c68", "title": "Focused Transformer: Contrastive Training for Context Scaling"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "6f6e2e0311589a9af045f6acd00b7dee6d19fce4", "title": "The Impact of Positional Encoding on Length Generalization in Transformers"}, {"paperId": "af385c0fdd0eda2bbf429bea6fedffc327c8a180", "title": "Randomized Positional Encodings Boost Length Generalization of Transformers"}, {"paperId": "60b35c6d68acced19b0c66edcfc0ee0a2c11efed", "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "9dc624d7258d1a56117ca720aea953ce46b66b21", "title": "Efficient Attentions for Long Document Summarization"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": null, "title": "How long can context length of open-source LLMs truly promise?"}, {"paperId": "e3aa232577bb427b1f3a34acbdef84bd85734042", "title": "LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models"}, {"paperId": null, "title": "Proof-pile"}, {"paperId": null, "title": "Controlling, planning, and interacting with large language models in embodied text environments"}, {"paperId": null, "title": "AI@Meta"}, {"paperId": null, "title": "Boosting llm reasoning: Push the limits of few-shot learning with reinforced in-context pruning"}, {"paperId": null, "title": "Ntk-aware scaled rope allows llama models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation"}]}