{"paperId": "2e6fa3095df1d1ed041dfb4f5a18e31d4b7bd7bb", "abstract": "Large pre-training language models (PLMs) have shown promising in-context learning abilities. However, due to the backbone transformer architecture, existing PLMs are bottlenecked by the memory and computational cost when scaling up to a large context size, leaving instruction tuning and in-context learning of many demonstration examples, as well as long-range language modeling under-explored. In this study, we propose a long-range language model EVALM based on an efficient transformer mechanism. EVALM is trained with 8k tokens per batch line and can test up to 256k-lengthed contexts with extrapolation, 128 times to the limit of existing PLMs (e.g. GPT3). Based on EVALM, we scale up the size of examples efficiently in both instruction tuning and in-context learning to explore the boundary of the benefits from more annotated data. Experimental results on a diverse set of tasks show that EVALM achieves 4.1% higher accuracy on average, and the average length of achieving the best accuracy score over tasks is around 12k. We find that in-context learning can achieve higher performance with more demonstrations under many-shot instruction tuning (8k), and further extending the length of instructions (16k) can further improve the upper bound of scaling in-context learning.", "venue": "arXiv.org", "year": 2023, "citationCount": 19, "influentialCitationCount": 2, "openAccessPdf": {"url": "http://arxiv.org/pdf/2302.04931", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "A long-range language model EVALM based on an efficient transformer mechanism that can achieve higher performance with more demonstrations under many-shot instruction tuning, and further extending the length of instructions can further improve the upper bound of scaling in-context learning."}, "embedding": {"model": "specter_v2", "vector": [0.21974129974842072, -0.10028772056102753, -0.14970138669013977, -0.3188575506210327, -0.2813878059387207, -0.3874356746673584, 0.7349898219108582, -0.2342449128627777, -0.7834480404853821, -0.07992342114448547, 0.558945894241333, -0.6465979218482971, 0.6069672107696533, 0.33270493149757385, -0.3069705069065094, 0.10664867609739304, -1.2075666189193726, 0.27990660071372986, -0.12826219201087952, -0.6702369451522827, -0.3058792054653168, -0.9510064721107483, -0.7417992353439331, 0.17976076900959015, 0.5984892249107361, 0.05442250519990921, 0.8648191094398499, 0.7713869214057922, -0.6744384765625, 0.211485356092453, 0.2617416977882385, -0.39393723011016846, 0.27931949496269226, 0.3922329246997833, -0.13669615983963013, -0.19011449813842773, 0.4840362071990967, -0.7147839665412903, -0.1868256777524948, 0.455836683511734, -0.08125703781843185, 0.3060152530670166, 0.227492555975914, -0.7905157804489136, -0.6021408438682556, 0.9992673993110657, 0.6310344934463501, 0.49729713797569275, -0.3025304973125458, -0.3426375985145569, 1.335745930671692, -1.771117925643921, 0.040181197226047516, 1.1714744567871094, 0.40042203664779663, 0.8007345199584961, -0.10962172597646713, -0.7284790277481079, 0.9531035423278809, 0.0715436264872551, -0.6974071264266968, -0.2484300583600998, 0.09359137713909149, 0.19584506750106812, 2.0606260299682617, -0.5715575218200684, 0.46654456853866577, 0.9215035438537598, -0.14614298939704895, 1.478655219078064, -0.16853822767734528, -0.9208483099937439, -0.5116642713546753, -0.04769492894411087, 0.3747996389865875, 0.7435572147369385, -0.4359680414199829, 0.6068384051322937, -0.7908993363380432, 0.2919612228870392, 0.6207660436630249, 0.12841260433197021, 0.14506155252456665, -0.036763280630111694, -0.7457436323165894, 0.5719843506813049, 0.12614567577838898, 1.1360379457473755, 0.236845925450325, 0.7448211312294006, 0.9744630455970764, 0.5677201151847839, -0.43356847763061523, 0.2459731101989746, -0.3495679795742035, 0.15732114017009735, -0.7467459440231323, 0.1432662457227707, -0.3390147387981415, 1.0594496726989746, -0.3092629313468933, 0.2735868990421295, -0.7329086065292358, 0.24662555754184723, 1.1788190603256226, 0.34938597679138184, 0.5517041087150574, -0.6944840550422668, 0.6522016525268555, -0.6202340722084045, 0.20174187421798706, 0.14917999505996704, -0.09747032076120377, -0.2609129250049591, -0.4422852694988251, -1.2063279151916504, -0.16570289433002472, -0.08920743316411972, -0.48829326033592224, 1.122083306312561, 0.22267861664295197, 0.40058085322380066, 0.46900707483291626, 0.19799812138080597, 0.5954697132110596, 0.743927538394928, 0.31698137521743774, -0.24069936573505402, 0.8211028575897217, -1.1532279253005981, -0.5613768696784973, -1.1156845092773438, 1.084823727607727, -0.09811418503522873, 0.9884461164474487, -0.2924121618270874, -0.796633243560791, -1.1627117395401, -1.0256694555282593, -0.2791103422641754, -0.6627380847930908, 0.07449473440647125, 0.9998829960823059, 0.5506369471549988, -1.06950044631958, 0.38045889139175415, -0.17147323489189148, 0.08774025738239288, -0.291492760181427, -0.0856253057718277, 0.20685666799545288, -0.8019280433654785, -1.723239541053772, 0.1657974272966385, 0.3379369378089905, -0.34647685289382935, -0.6243394613265991, -0.8302398920059204, -1.5898916721343994, -0.3274051547050476, 0.44918376207351685, -0.24689847230911255, 1.6509969234466553, -0.05808084085583687, -1.2103394269943237, 0.5148890614509583, -0.2414020150899887, 0.40143144130706787, 0.12801235914230347, -0.07789108902215958, -0.8188794255256653, -0.8811442255973816, -0.053556762635707855, 0.6898050308227539, 0.08758094906806946, -0.03881067410111427, -0.37863439321517944, 0.019341444596648216, 0.1109638586640358, 0.33520784974098206, -0.0997951552271843, 0.855596661567688, -0.2353065460920334, -0.20369930565357208, -0.03628011420369148, 0.6830660700798035, 0.03119494393467903, -0.43951866030693054, -0.04573846608400345, -1.1687042713165283, 1.1408883333206177, 0.13581278920173645, 0.9939031600952148, -0.9780523777008057, -1.1639349460601807, -0.44600170850753784, -0.6658893823623657, 0.19128985702991486, -1.0954018831253052, 0.9093604683876038, -0.005712833721190691, 0.21254418790340424, 0.24290327727794647, -1.1425174474716187, 0.2592877745628357, -0.03726295381784439, -0.7522802352905273, -0.7246657609939575, 0.02090221270918846, 1.1956052780151367, -1.3320863246917725, -0.023028213530778885, 0.20836202800273895, 0.37762370705604553, -0.9619987607002258, 1.1001331806182861, -0.5496935844421387, 0.5913141369819641, -0.07398824393749237, -0.3810095489025116, -0.42449820041656494, -0.11582314223051071, 0.4276079833507538, -0.1465250551700592, -0.10010604560375214, 0.6405211687088013, -0.5671875476837158, 1.7146220207214355, -1.1073269844055176, 0.4025211036205292, 0.0655871331691742, -0.5252825617790222, -0.09269089251756668, 0.6820894479751587, -0.5202382802963257, -0.421686589717865, 0.10897733271121979, 0.4840439558029175, -0.23705603182315826, 0.15920484066009521, 1.0058925151824951, 0.7363185286521912, -0.5079613327980042, 0.25407975912094116, 0.3375783860683441, -0.2927643954753876, 0.5405290722846985, 0.44363144040107727, 0.3216956555843353, 0.7250750064849854, 0.4343608617782593, 0.07499606907367706, 0.5960731506347656, -0.8393465876579285, -0.2959798574447632, 0.505151629447937, 0.3834880292415619, 0.32851365208625793, 0.06663312017917633, -0.6103608012199402, -0.24880103766918182, 0.08299478888511658, 0.7912750840187073, 2.1137900352478027, 0.014568441547453403, -0.290437787771225, -0.854954183101654, -0.36934956908226013, -0.6107486486434937, 0.6007980108261108, -0.16541911661624908, 0.18296775221824646, -0.9333192110061646, -0.2724910080432892, 0.6780387759208679, 0.6387695074081421, 1.2737510204315186, -0.8130324482917786, -0.24337521195411682, 0.013383765704929829, 0.012797350995242596, -1.0131515264511108, -1.0522286891937256, 0.2885303199291229, -0.6483280658721924, -0.2364381104707718, 0.21909166872501373, -0.5663737654685974, 0.004792944062501192, -0.537135124206543, 0.9284991025924683, -0.22457247972488403, -0.3159862160682678, 0.35015249252319336, 0.5580394864082336, -0.3440885543823242, -1.0118956565856934, 0.06381435692310333, 0.1999206691980362, -0.7314636707305908, 0.42933976650238037, 0.44445815682411194, 0.22140644490718842, 0.019199587404727936, -0.2121979296207428, 0.40637606382369995, 0.06864363700151443, 0.023758303374052048, 0.8448394536972046, -0.5074691772460938, 0.18237978219985962, -1.1747153997421265, 1.0140266418457031, 0.5275593996047974, -0.5934709310531616, 0.44019070267677307, -0.6620253920555115, -0.530845582485199, 0.8329817652702332, -0.9440889954566956, -0.30808883905410767, -0.9069510698318481, 0.2331383228302002, -0.2644520699977875, -0.35591715574264526, 0.2010965198278427, -0.009919026866555214, 0.4921519458293915, 0.14013974368572235, 0.8186205625534058, 0.13428060710430145, 0.19322378933429718, 0.9234498143196106, -0.8467628359794617, 0.11107867956161499, -0.15782414376735687, 0.017235765233635902, -0.6723327040672302, -0.3608444333076477, -0.7330087423324585, -0.23046253621578217, -0.3345223069190979, -0.3130072355270386, -0.3779515027999878, -0.12284333258867264, -0.5713264346122742, -0.8127717971801758, 0.03290750831365585, -0.9651704430580139, -0.8531798124313354, 0.13624976575374603, -0.41239944100379944, -0.27380725741386414, -0.9811357259750366, -1.0769758224487305, -0.45114317536354065, -0.5283711552619934, -1.2457542419433594, 0.5972030162811279, -0.16350647807121277, -0.15702705085277557, -0.8845652341842651, -0.01058907900005579, -0.32009920477867126, 1.0775542259216309, -0.9600589275360107, 0.7285531759262085, -0.17402809858322144, -0.2060113400220871, 0.1309320479631424, 0.6035031676292419, 0.5177147388458252, 0.07432768493890762, 0.10227689146995544, -0.7250428795814514, 0.03686732053756714, -0.2923208475112915, -0.6221581101417542, -0.06911426782608032, -0.053682632744312286, 0.5740306973457336, 0.1395459771156311, -0.6466769576072693, 0.03728028014302254, 1.3623144626617432, -0.2900327146053314, -0.016662491485476494, -0.07100370526313782, 0.9999884963035583, 0.08385008573532104, 0.282383531332016, 0.05065421015024185, 0.3731190860271454, 0.389013409614563, -0.0523197241127491, 0.37814608216285706, 0.20461176335811615, -0.560673177242279, 0.9839745759963989, 1.695767879486084, 0.2732822299003601, 0.31077733635902405, -1.0434178113937378, 0.7408964037895203, -1.0884785652160645, -0.5692234039306641, 0.9058769941329956, 0.9911506772041321, 0.8912028670310974, -0.4591882526874542, -0.40331846475601196, -0.21201191842556, 0.4611607789993286, 0.4264388978481293, -0.29824650287628174, -0.8976596593856812, 0.4979967176914215, 0.1812131106853485, -0.5216590166091919, 1.0193246603012085, -0.3651500940322876, 0.8429101705551147, 14.151564598083496, 1.004492998123169, -0.13442793488502502, 0.5976765751838684, 0.5660836100578308, 0.3129817247390747, -0.34532442688941956, -0.44588494300842285, -1.5553295612335205, -0.3784213364124298, 1.1756092309951782, 0.35462653636932373, 0.8958320617675781, 0.23805855214595795, 0.050597794353961945, 0.2744715213775635, -0.9521876573562622, 0.6041831374168396, 0.5728639960289001, -0.9287189245223999, 0.6068075895309448, -0.037993066012859344, 0.16927215456962585, 0.4523945152759552, 0.891503632068634, 1.5303704738616943, 0.3712158501148224, -0.2529938220977783, 0.3097795844078064, -0.3907053470611572, 1.332836389541626, -0.35390937328338623, 0.18082188069820404, 0.8640894293785095, -1.0030312538146973, -0.2553313076496124, -0.512484073638916, -1.288447380065918, 0.1752506047487259, -0.0823887288570404, -0.7963297963142395, -0.5653079748153687, -0.45589303970336914, 0.4843420386314392, 0.2758300006389618, 0.023360680788755417, -0.6999499797821045, 0.734242856502533, 0.15336741507053375, -0.4283057153224945, 0.45389142632484436, 0.17637450993061066, 0.272084504365921, 0.08064763993024826, 0.11282799392938614, 0.19365163147449493, 0.3773249089717865, 0.3640228509902954, -0.3666810095310211, 0.08987477421760559, -0.5226156115531921, -0.05138527229428291, 0.10427995771169662, 0.9621334671974182, 0.7441346049308777, 0.1965356320142746, -0.5781563520431519, 0.1056429073214531, 0.7964464426040649, 0.314800500869751, -0.36745554208755493, 0.17032143473625183, 0.3201456367969513, -0.5757262706756592, -0.0029591198544949293, 0.18227407336235046, 0.2415802925825119, -0.6130188703536987, -0.4801468253135681, -0.47177615761756897, -0.0757310539484024, -0.7678293585777283, -0.7999257445335388, 0.6711887717247009, -0.11978283524513245, -0.60302734375, -0.04150175675749779, -0.8913658857345581, -0.5810335278511047, 0.21110306680202484, -1.4034664630889893, -1.0532571077346802, 0.380562961101532, -0.019107140600681305, 0.0712781473994255, 0.25219789147377014, 1.3250139951705933, 0.19366592168807983, -0.4182874858379364, 0.2552911937236786, 0.26330500841140747, 0.16933920979499817, 0.01478660013526678, -1.1544462442398071, 0.9280874729156494, 0.21876469254493713, 0.1284041851758957, 0.36064115166664124, -0.10471139848232269, 0.3091100752353668, -0.7266990542411804, -0.3969461917877197, 0.7992451190948486, -0.8710851669311523, -0.38647109270095825, -1.1110867261886597, -0.7911085486412048, 0.677693247795105, 0.7969955801963806, -0.27781054377555847, 0.7104247212409973, 0.3830544650554657, -0.6079137921333313, -0.3135709762573242, -0.6748520135879517, 0.5874156951904297, 0.806551992893219, -0.525623083114624, -0.6333566308021545, -0.2525179386138916, 0.8469431400299072, -1.1704676151275635, -0.6018193960189819, -0.38373786211013794, 0.10311625897884369, 0.09420914947986603, 0.915594756603241, -0.17336079478263855, 0.6885554790496826, 0.9314765930175781, -0.21288597583770752, -1.0303841829299927, 0.1948232203722, -0.7043819427490234, 0.16398853063583374, 0.262429416179657, 0.8410199284553528, -0.394064337015152, -0.24263206124305725, 0.8219741582870483, 0.21090620756149292, -0.7063925266265869, -0.6300942301750183, -0.6353976726531982, 0.42363908886909485, -0.8294841051101685, 0.6514333486557007, 0.07747025042772293, 0.18871085345745087, 0.5701853036880493, 0.7780101299285889, 0.4193292260169983, -0.349796324968338, -0.7234401702880859, 0.5735287666320801, 0.49123644828796387, -0.3080199062824249, -0.3545053005218506, -0.20584529638290405, -1.4803780317306519, 0.14478446543216705, -1.3680070638656616, 0.2513274550437927, -0.6995049118995667, -0.313066303730011, -0.22427895665168762, -0.26267391443252563, 0.04946064576506615, -0.0013672617496922612, -0.6464624404907227, -0.43267011642456055, -0.8630871176719666, -0.7155960202217102, 0.7448663711547852, 1.1335029602050781, -0.6864680647850037, 0.20911122858524323, -0.21787558495998383, 0.3672903776168823, -0.00819889735430479, 0.37203335762023926, 0.04960539937019348, -1.2242310047149658, -1.395364761352539, 0.0993364006280899, -0.0850573480129242, -0.3263610303401947, -0.6450105309486389, 0.3961949050426483, 0.23060472309589386, -0.13655848801136017, -0.02931310050189495, 0.19597305357456207, -0.972362220287323, -0.691277265548706, 0.2793446481227875, -0.8368041515350342, 0.3700154423713684, 0.47633999586105347, -0.5288813710212708, -0.3592069745063782, 0.4649598002433777, -0.3874453902244568, -1.087593674659729, -1.4590643644332886, 0.3811098337173462, -0.48380735516548157, 0.41946715116500854, -0.19408972561359406, 0.1425994336605072, -1.1372687816619873, -0.3159663677215576, 0.18713060021400452, 0.6854665875434875, -0.3058377802371979, 0.9382237195968628, 0.6123464107513428, -1.2079170942306519, 0.09291653335094452, 0.480674684047699, 0.1788850575685501, 0.1919177919626236, 0.6139903664588928, 0.36920613050460815, -0.12677614390850067, 0.4032377600669861, 0.3183862864971161, 0.018704544752836227, -1.3463813066482544, 0.3434270918369293, 0.8638689517974854, -0.8326187133789062, -0.1599370241165161, 0.9874976873397827, -0.29459473490715027, -1.4885241985321045, 0.1502860188484192, -1.4195200204849243, -0.6717725396156311, -0.9785580635070801, 1.1649202108383179, -0.022927865386009216, -0.1649494767189026, 0.02405124343931675, -0.2594760060310364, 0.35185912251472473, -0.31205955147743225, -0.6636380553245544, 0.114864282310009, -0.19305239617824554, -0.12331835180521011, 1.0860222578048706, 0.8745866417884827, -0.4674677848815918, -0.8351295590400696, -0.5219616293907166, -0.8027441501617432, 0.14053764939308167, -0.1923288255929947, -0.6743139028549194, -0.308569997549057, 0.8904131650924683, 0.32369282841682434, 0.17618529498577118, -0.06583718955516815, -0.3175593912601471, 0.3443540930747986, 1.128669023513794, 0.563689112663269, -0.6028841733932495, -0.29589155316352844, 1.555219054222107, 1.4166767597198486, -1.318305492401123, -0.29701054096221924, -0.22923870384693146, -0.7306333780288696, 0.6891679763793945, 0.7764809131622314, -0.036273445934057236, 0.8017072677612305, -0.25773030519485474, 0.3535202443599701, 0.45719113945961, -1.1536164283752441, 0.1821446567773819, 0.3195466101169586, 1.2020260095596313, 0.9524007439613342, 0.5953928828239441, 0.1728399097919464, 0.9444499015808105, -0.03958487510681152, -0.039167944341897964, 0.4996103048324585, 0.43004000186920166, -0.3761516511440277, -0.2659635841846466, 0.18698523938655853, 0.4179268777370453, -0.3556554317474365, -1.0584999322891235, 0.5071520805358887, 0.9990195035934448, 0.21517401933670044, 0.6276501417160034, 0.5640096068382263, 0.3439454436302185, 0.5525087118148804, 0.6927057504653931, 0.8098666667938232, -0.6774616837501526, -0.39320021867752075, -0.43421614170074463, -0.8780015707015991, -0.2743496596813202, -0.10944926738739014, -0.25659626722335815, -0.5924168229103088, 0.08524762094020844, 0.18303602933883667, 0.07989682257175446, 0.23523546755313873, 1.3203425407409668, 0.39889758825302124, 0.35642045736312866, -0.542245090007782, -0.3786334991455078, -0.5930169224739075, -1.0578464269638062, 0.11063922941684723, -0.46413758397102356, -0.24480347335338593, -0.13562838733196259, 0.11789774894714355, -0.5151575207710266]}, "authors": [{"authorId": "2027599235", "name": "Mukai Li"}, {"authorId": "2165001433", "name": "Shansan Gong"}, {"authorId": "2093485", "name": "Jiangtao Feng"}, {"authorId": "3032611", "name": "Yiheng Xu"}, {"authorId": "27672597", "name": "Jinchao Zhang"}, {"authorId": "150358371", "name": "Zhiyong Wu"}, {"authorId": "47648549", "name": "Lingpeng Kong"}], "references": [{"paperId": "ac608a4a6b19b3208e560eee5daadb3cc18638a2", "title": "Efficient Attention via Control Variates"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "3d5922d71a370f32b7f232a596def914f67eebd1", "title": "Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "2d629fa3d687cfc453c6b61909c46983ebea0323", "title": "CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling"}, {"paperId": "8fbd7ddf1ea30c991f3b1152a245df77caa18e16", "title": "Learning by Distilling Context"}, {"paperId": "1c475acaa1060c8318a625f24bfd88c12f367516", "title": "Prompt Injection: Parameterization of Fixed Inputs"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "1944cebf4e41a10ea7bd02ce30404c18c9c4e04f", "title": "Linear Complexity Randomized Self-attention Mechanism"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "71e15a9a52dcafca57bff5f310b95e2c7d0cfc87", "title": "Diagonal State Spaces are as Effective as Structured State Spaces"}, {"paperId": "9d40837175577bb0009b138269b422f6d5820d00", "title": "Transformer Memory as a Differentiable Search Index"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "47df3fd32d00220c85c2c51a571254fd99b2ecc7", "title": "MetaICL: Learning to Learn In Context"}, {"paperId": "4b0541eccd8f98852d6807a14fbac17f775c7b40", "title": "Skyformer: Remodel Self-Attention with Gaussian Kernel and Nystr\u00f6m Method"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "2e644c67a697073d561da4f4dad35e5ad5316cfd", "title": "SOFT: Softmax-free Transformer with Linear Complexity"}, {"paperId": "e0cbbca02b332f398c6639b3bea0613f79166220", "title": "ABC: Attention with Bounded-memory Control"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "59641c10ed7431a3cf841f308367dc2dc0281b74", "title": "What Makes Good In-Context Examples for GPT-3?"}, {"paperId": "346081161bdc8f18e2a4c4af7f51d35452b5cb01", "title": "Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies"}, {"paperId": "85e7d63f75c0916bd350a229e040c5fbb1472e7a", "title": "Making Pre-trained Language Models Better Few-shot Learners"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "9770fff7379a7ab9006b48939462354dda9a2053", "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"}, {"paperId": "512b8ef0002e0bfd0ecb5ab17d533c1762eb9786", "title": "Set Transformer"}, {"paperId": "a925f818f787e142c5f6bcb7bbd7ede2deb34860", "title": "WiC: the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations"}, {"paperId": "99ad0533f84c110da2d0713d5798e6e14080b159", "title": "Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "51a55df1f023571a7e07e338ee45a3e3d66ef73e", "title": "Character-level Convolutional Networks for Text Classification"}, {"paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0", "title": "Effective Approaches to Attention-based Neural Machine Translation"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "5cfbbf3cdff0f905874589bcd21b2646340a5447", "title": "Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning"}, {"paperId": "128cb6b891aee1b5df099acb48e2efecfcff689f", "title": "The Winograd Schema Challenge"}, {"paperId": "75895ce98904e8afaaa248f081a1da501bd2dbe2", "title": "Toward Semantics-Based Answer Pinpointing"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "In-Context Learning with toolkit for sequence modeling"}, {"paperId": null, "title": "Demonstration Examples Human"}, {"paperId": null, "title": "Trivi-aQA: A large scale distantly supervised challenge dataset for reading comprehension"}, {"paperId": "0c0a778e6fdf7e36b1750c533dcc916f86608607", "title": "A Survey on Context Learning"}, {"paperId": null, "title": "fairseq: A fast, extensible"}]}