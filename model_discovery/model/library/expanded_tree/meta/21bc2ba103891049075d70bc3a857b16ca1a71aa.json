{"paperId": "21bc2ba103891049075d70bc3a857b16ca1a71aa", "abstract": "Textual style transfer is the task of transforming stylistic properties of text while preserving meaning. Target \"styles\" can be defined in numerous ways, ranging from single attributes (e.g. formality) to authorship (e.g. Shakespeare). Previous unsupervised style-transfer approaches generally rely on significant amounts of labeled data for only a fixed set of styles or require large language models. In contrast, we introduce a novel diffusion-based framework for general-purpose style transfer that can be flexibly adapted to arbitrary target styles at inference time. Our parameter-efficient approach, ParaGuide, leverages paraphrase-conditioned diffusion models alongside gradient-based guidance from both off-the-shelf classifiers and strong existing style embedders to transform the style of text while preserving semantic information. We validate the method on the Enron Email Corpus, with both human and automatic evaluations, and find that it outperforms strong baselines on formality, sentiment, and even authorship style transfer.", "venue": "AAAI Conference on Artificial Intelligence", "year": 2023, "citationCount": 2, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2308.15459", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces a novel diffusion-based framework for general-purpose style transfer that can be flexibly adapted to arbitrary target styles at inference time and validate the method on the Enron Email Corpus, finding that it outperforms strong baselines on formality, sentiment, and even authorship style transfer."}, "embedding": {"model": "specter_v2", "vector": [-0.00037164633977226913, 0.18259195983409882, -0.45590367913246155, -0.17033818364143372, 0.15575987100601196, -0.6900548338890076, 1.023553490638733, -0.4722329080104828, -0.27162179350852966, -0.0018353847553953528, 0.6927183270454407, -0.1845742017030716, -0.12998801469802856, 0.1682904213666916, -0.11170344054698944, 0.020538993179798126, -0.30334702134132385, 0.3634292781352997, -0.38022875785827637, -0.8300324082374573, 0.03696994110941887, -0.4523595869541168, -0.16211652755737305, 0.11320358514785767, 0.3749658465385437, 0.03630558401346207, -0.2405228316783905, 0.9895889759063721, -0.6725102663040161, 0.0739445686340332, 0.02655971422791481, -0.7102659344673157, 0.11551066488027573, -0.20866082608699799, -0.7134314179420471, 0.17668135464191437, -0.17689421772956848, -0.5825056433677673, -0.35079625248908997, 0.5013614296913147, -0.25791123509407043, -0.20757685601711273, 0.9764587879180908, -0.32489219307899475, -0.6317929625511169, 0.9102433919906616, 0.576447606086731, 0.6529986262321472, 0.2784498929977417, -0.9973915815353394, 0.9895086884498596, -1.0831323862075806, 0.6750049591064453, 1.1404180526733398, 0.3981357216835022, 0.8272337317466736, -0.43974769115448, -0.19566026329994202, 0.27496010065078735, -0.024149015545845032, -0.853801965713501, 0.1534685641527176, 0.47730061411857605, -0.3190538287162781, 1.1161046028137207, -0.23522000014781952, 0.0318184494972229, 0.7278040647506714, -0.1454147845506668, 1.5843381881713867, 0.2810298502445221, -0.6919245719909668, -0.3446660339832306, 0.33417782187461853, -0.18430258333683014, 0.45477235317230225, -0.9834626317024231, -0.017753740772604942, -1.0153559446334839, -0.08802171051502228, 0.4893847107887268, -0.03127157688140869, -0.5193989872932434, 0.0373980812728405, -0.035377878695726395, 0.39307349920272827, 0.3609955310821533, 1.015470266342163, -0.06966633349657059, 0.40581122040748596, 0.7025193572044373, 0.6467316150665283, 0.30519741773605347, 0.18104341626167297, 0.11832345277070999, -0.067012257874012, -1.0418572425842285, 0.43074750900268555, 0.3904321789741516, 0.873453676700592, 0.001417432096786797, -0.3541407287120819, -0.871022641658783, 0.6825013160705566, 1.0122144222259521, -0.1822376251220703, 0.7132302522659302, -0.6791165471076965, -0.13856810331344604, -0.5462273359298706, 0.5078104138374329, -0.6791906356811523, 0.21071206033229828, 0.0034134553279727697, -0.8720468878746033, -1.1389378309249878, -0.6535095572471619, -0.028644461184740067, -0.5688838958740234, 0.40736833214759827, -0.38169267773628235, -0.34369397163391113, -0.29096314311027527, 0.6374262571334839, 0.6068836450576782, 0.8287756443023682, 0.051317885518074036, -0.12003672868013382, 0.5722877383232117, -0.5828858017921448, -0.9175276160240173, -0.7291192412376404, 1.0018657445907593, -0.8239524960517883, 0.45095255970954895, -0.020547909662127495, -1.2457482814788818, -0.6725112795829773, -1.0903388261795044, 0.10454715043306351, -0.5230181217193604, 0.3351915180683136, 0.49444305896759033, 0.7756153345108032, -0.6728593111038208, 1.391385555267334, 0.24392125010490417, -0.3945263624191284, 0.5851604342460632, -0.31869766116142273, 0.4059257209300995, -0.3123989403247833, -1.180733323097229, 0.029350057244300842, -0.109810009598732, -0.6629670858383179, 0.46283841133117676, -0.9314433336257935, -0.3125295639038086, -0.6107929348945618, 0.15921705961227417, -0.883449137210846, 1.4318299293518066, -0.4299889802932739, -1.9361940622329712, 0.882789671421051, -0.35937321186065674, 0.6869239211082458, 0.9551295042037964, -0.7163504958152771, -0.2797844707965851, -0.49981752038002014, 0.03774607554078102, 0.45212188363075256, 0.7028162479400635, -0.22420020401477814, 0.09053066372871399, 0.41870906949043274, -0.39120638370513916, 0.14447090029716492, -0.6108489632606506, 0.8405893445014954, -0.6180090308189392, -0.9765312075614929, -0.44029203057289124, 0.47453734278678894, 0.5856809020042419, -0.2930453419685364, -0.3836181163787842, -1.2137815952301025, 1.292571783065796, -0.23412461578845978, 1.3678386211395264, -0.9587017893791199, 0.4136252999305725, -0.24838358163833618, -0.2711508870124817, -0.37216073274612427, -0.038611020892858505, 0.8104788661003113, -0.14396949112415314, 0.5263767242431641, -0.46332135796546936, -1.1502940654754639, 0.2561183273792267, 0.05532437190413475, -0.7862831354141235, -0.4712865352630615, -0.23617470264434814, 1.440183162689209, -0.5863946080207825, 0.5057306885719299, -0.2696455717086792, 0.21059547364711761, -0.5872286558151245, 1.2466322183609009, -0.3124193251132965, 0.44077926874160767, -0.014666963368654251, -0.48489809036254883, -0.12726612389087677, -0.5235207676887512, 0.00821621436625719, -0.4861728250980377, 0.08038078248500824, 0.031384922564029694, -0.4438345432281494, 1.7453824281692505, -0.4816049337387085, 0.29559004306793213, -0.10196365416049957, -0.48063063621520996, 0.40367257595062256, 0.4014779329299927, -0.07708358764648438, 0.17329540848731995, 0.37591543793678284, 0.7557238936424255, -0.9927520155906677, 0.5582568645477295, 0.8173354864120483, 0.23360653221607208, -0.49637386202812195, 0.45867064595222473, 0.15486592054367065, -0.5221520662307739, 0.7370778322219849, 0.8010688424110413, 0.6214274764060974, 0.8091285824775696, 0.07758735120296478, -0.19679905474185944, 0.4638558030128479, -0.7448999285697937, -0.4533389210700989, 0.16306647658348083, 1.0481137037277222, 0.6794036030769348, 0.13993676006793976, -0.42869627475738525, -0.5427647233009338, -0.2612364888191223, 0.8784114718437195, 1.4990164041519165, 0.2099132537841797, -0.7536383867263794, -0.7492935061454773, -0.6019664406776428, -0.24987159669399261, -0.04063244163990021, -0.6756351590156555, -0.26090794801712036, -0.6093602180480957, -0.7777506709098816, 0.9013826251029968, 0.4752008318901062, 1.2556838989257812, 0.09940005093812943, -0.17829567193984985, -0.11147769540548325, 0.04153093323111534, -0.13323400914669037, -0.9852415919303894, -0.19221454858779907, -0.2547984719276428, 0.4471229612827301, -0.9032776355743408, -0.16760434210300446, 0.011899871751666069, -0.9361215829849243, 0.8333947658538818, -0.13795942068099976, -0.36508265137672424, 0.3753320574760437, 0.36789077520370483, -0.472689151763916, -1.206083059310913, 0.2832799255847931, -0.03255237266421318, 0.02479476109147072, 0.07770904898643494, 0.24234193563461304, -0.14787721633911133, 0.47785550355911255, -0.6499425172805786, 0.3359997868537903, -0.37284597754478455, 0.35526397824287415, -0.17141352593898773, -0.44134292006492615, 0.06044963374733925, -1.0859556198120117, 1.510900616645813, 0.5912284255027771, 0.1003168523311615, 0.23905456066131592, -0.608245313167572, -0.6951707601547241, 0.47259536385536194, -0.6703335642814636, -0.8467782139778137, -1.5134817361831665, 0.3815304636955261, 0.09767808765172958, -0.14426368474960327, 0.3885427415370941, 0.25546401739120483, 0.5343768000602722, 0.5954031944274902, 0.4050500988960266, 0.26961028575897217, -0.3795800805091858, 1.0254064798355103, -0.20490145683288574, 0.42224591970443726, 0.0333695225417614, 0.4617159366607666, 0.14193029701709747, -0.3954465091228485, -0.4427412152290344, -0.3353208601474762, -0.22764965891838074, -0.34342506527900696, -0.7702692151069641, 0.13210636377334595, -0.11743798851966858, -0.45480403304100037, 0.13355980813503265, -1.2741270065307617, -0.2103518694639206, 0.16399921476840973, -1.0600429773330688, -0.30784478783607483, -0.5280219912528992, -1.600527048110962, -0.04960016533732414, -0.8381351828575134, -0.8590248227119446, 0.39756202697753906, 0.06170840188860893, -1.093516230583191, -0.9663373827934265, 0.12046116590499878, -0.30651363730430603, 0.7952658534049988, -0.9653640389442444, 0.9308443069458008, 0.6884868741035461, 0.31188657879829407, -0.0916721448302269, 0.4238261580467224, 0.6416307687759399, 0.2314877063035965, 0.16812169551849365, -0.2672629654407501, 0.008173070847988129, -0.37556636333465576, -0.15952688455581665, -0.3764304518699646, -0.0043130600824952126, 0.44889551401138306, -0.0627548098564148, -0.5602624416351318, 0.20350562036037445, 0.824105441570282, -0.7048285603523254, 0.07396848499774933, 0.5105775594711304, 0.8781176209449768, 0.5649899840354919, -0.5506989359855652, 0.831149160861969, 0.198049396276474, 0.6762409806251526, -0.9582528471946716, -0.35978609323501587, -0.20652875304222107, -0.8192533850669861, 0.614234209060669, 1.6574749946594238, 0.04956931248307228, -0.11253490298986435, -0.841286838054657, 0.3113146722316742, -1.4670830965042114, -0.6409050822257996, 0.7345328330993652, 0.2091132402420044, 0.657342255115509, -0.45229941606521606, -0.03631297126412392, 0.01179229374974966, 0.40677469968795776, 0.10319842398166656, -0.11339297890663147, -0.7533202171325684, -0.09055215120315552, 0.12582889199256897, 0.024644088000059128, 0.5312057733535767, 0.008415780030190945, 0.5784731507301331, 14.733729362487793, 0.9830629825592041, -0.11343586444854736, 0.5372531414031982, 0.5757278203964233, 0.30096355080604553, -0.6850987076759338, -0.22609397768974304, -0.8158984184265137, 0.013259769417345524, 0.4622311294078827, -0.624153196811676, 0.586852490901947, -0.35476604104042053, 0.17809543013572693, 0.4897538721561432, -0.5126718878746033, 0.8545789122581482, 0.6034332513809204, -1.6952073574066162, 0.5526560544967651, 0.0892896056175232, 0.6359002590179443, 0.010683594271540642, 1.0412240028381348, 0.5247589945793152, 0.19276297092437744, -0.41964298486709595, 0.6054065227508545, 0.28790509700775146, 0.6190441250801086, -0.13478954136371613, 0.2873246967792511, 0.557837963104248, -0.31276193261146545, -0.06311453878879547, -0.35737037658691406, -0.8107200860977173, 0.7325372099876404, 0.11284585297107697, -0.4217965304851532, 0.22328995168209076, 0.18885058164596558, 1.4647775888442993, 0.1624123752117157, -0.2307456135749817, -0.5486428737640381, 0.82454514503479, 0.17431676387786865, -0.272838830947876, 0.20552539825439453, 0.13775382936000824, 0.7161883115768433, 0.3747601807117462, 0.06319648772478104, -0.15093162655830383, -0.1142566129565239, 0.7965958714485168, -0.7881088256835938, 0.46186304092407227, -0.245782271027565, -0.2101110965013504, -0.1711743175983429, 0.6802845001220703, 0.4193021059036255, -0.02461382932960987, -0.10387636721134186, 1.2643252611160278, 0.34418612718582153, 0.43646714091300964, 0.04846058785915375, -0.5263988375663757, -0.16759097576141357, 0.14227734506130219, 0.02939179725944996, 0.3058030605316162, -0.508750855922699, -0.4916107654571533, -0.5157678127288818, -0.16835813224315643, 0.24886900186538696, -1.2343478202819824, -1.380338191986084, 0.6161956191062927, -0.0719476044178009, -0.4516936242580414, 0.19758643209934235, -0.779849112033844, -0.5623949766159058, 0.6621423363685608, -0.8334565758705139, -0.723403811454773, 0.3316252529621124, -0.5235762000083923, -0.21179577708244324, -0.03284686803817749, 0.855488121509552, -0.004471318330615759, -0.03799741342663765, 0.12586070597171783, 0.4955994486808777, -0.06171868368983269, 0.28735995292663574, -1.0215511322021484, 0.43959012627601624, -0.25052785873413086, -0.36751309037208557, 0.516262412071228, 0.4131956994533539, -0.1253734976053238, -0.7517142295837402, 0.04215877875685692, 0.42337659001350403, -0.8276302814483643, -0.0863814577460289, -0.6344110369682312, -1.1861110925674438, -0.09505187720060349, 1.0156804323196411, -1.140402913093567, 0.596572995185852, 0.08592384308576584, -0.365762859582901, 0.0022946668323129416, -0.6411849856376648, 0.5803494453430176, 0.72796630859375, -0.6978754997253418, -0.739165186882019, -0.1652102917432785, -0.17164510488510132, -0.7759677767753601, -0.9074658751487732, -0.2452867478132248, -0.09541181474924088, 0.10491027683019638, 0.5278458595275879, -0.16270287334918976, 0.7745904922485352, 0.6079837083816528, 0.21299906075000763, -1.2066563367843628, -0.3278728127479553, -1.6083121299743652, 0.6317970752716064, 0.7208338379859924, 0.5473754405975342, 0.06867603957653046, 0.1894490122795105, 0.8773550987243652, 0.6384230256080627, -0.38427841663360596, -0.2303595244884491, -0.14832326769828796, 0.9178245663642883, -0.26861652731895447, 0.15387490391731262, -0.14655882120132446, 0.2635143995285034, 0.670993447303772, 0.08474429696798325, -0.15796323120594025, -0.2515445947647095, -0.7247058749198914, 0.7862772941589355, -0.026030590757727623, -0.17112255096435547, -1.2058509588241577, -0.18583820760250092, -2.01436710357666, 0.12076070159673691, -1.3423433303833008, -0.2710323929786682, -1.110275387763977, -0.3006457984447479, 0.6144090890884399, 0.5564867258071899, -0.33966192603111267, 0.32955774664878845, -0.21405662596225739, -0.4112091362476349, -0.003290644846856594, -0.1845318078994751, 1.0547008514404297, 0.8442447781562805, -0.8441864252090454, -0.10452747344970703, -0.35907670855522156, 0.0007709853816777468, 0.18093344569206238, 0.3132866322994232, -0.11690206080675125, -0.6645520329475403, -1.1493616104125977, 0.5145319700241089, -0.36733418703079224, -0.01464982982724905, 0.09361116588115692, 0.2348131388425827, 0.4471883475780487, 0.0193612203001976, 0.13219493627548218, -0.06757431477308273, -0.45697078108787537, -0.12111572921276093, -0.0780409500002861, -0.881493866443634, 0.45344266295433044, 0.0029090484604239464, -0.486937016248703, 0.15120014548301697, 0.5579426288604736, 0.029356276616454124, -0.7639318108558655, -0.5494303703308105, 0.241133913397789, -1.072849154472351, 0.04538664221763611, -0.29064151644706726, -0.3226271867752075, -0.8152081370353699, -0.6987326741218567, -0.06977933645248413, -0.007055139634758234, 0.2442743182182312, 1.2403541803359985, 0.04816146194934845, -1.3463444709777832, -0.1399039328098297, 0.003883657744154334, -0.056059058755636215, -0.5818370580673218, 0.6757103800773621, 0.1518789529800415, -0.2911071479320526, -0.1310553252696991, 0.39342421293258667, -0.058186668902635574, -0.8986039757728577, -0.46076980233192444, 0.7712419629096985, -0.22117963433265686, -0.5783154368400574, 0.9594785571098328, -0.43057727813720703, -1.0474408864974976, -0.16096404194831848, -0.01272200420498848, -0.15506869554519653, -0.6238237619400024, 0.7774971723556519, 0.33738112449645996, -0.2067824751138687, -0.049162380397319794, -0.30051225423812866, 0.5185551643371582, -0.4156053960323334, -0.8441991806030273, 0.48245424032211304, -0.7196361422538757, -0.6209155917167664, 0.7157202363014221, 0.6996629238128662, -0.48326632380485535, -0.25641125440597534, -0.5583289265632629, -0.16405634582042694, -0.2700706422328949, 0.14640609920024872, -0.7217023372650146, 0.06688413769006729, 0.6552273631095886, 0.34203198552131653, 0.1835426241159439, 0.2739029824733734, 0.25705915689468384, 0.39323559403419495, 0.4123745858669281, -0.20258492231369019, -1.2386260032653809, -0.17694854736328125, 1.0873682498931885, 1.5517451763153076, -0.2713513672351837, 0.3257235586643219, -0.0018288439605385065, -0.9778788685798645, 1.187220811843872, -0.19932952523231506, 0.2812705338001251, 1.0837938785552979, -0.22620879113674164, 0.7221513986587524, 0.20004865527153015, -0.5788561105728149, 0.549241304397583, 0.9163721203804016, 0.9120436310768127, 1.0918344259262085, 0.2620971202850342, -0.6497257351875305, 0.6074249744415283, -0.10105499625205994, 0.6064707636833191, 0.8528657555580139, 0.9204968810081482, 0.2086578756570816, -0.5966271162033081, 0.03181109577417374, 0.14934861660003662, -0.571557343006134, 0.10537213832139969, -0.4683167040348053, 0.09423640370368958, -0.1635255217552185, 0.5112004280090332, 0.17712824046611786, -0.04183565825223923, 0.6610274314880371, 0.385227233171463, 0.6190709471702576, -0.14515483379364014, -0.5092331767082214, 0.2476961612701416, -0.7215098738670349, 0.40275517106056213, -0.48642000555992126, -0.47008007764816284, -0.343404084444046, -0.8275188207626343, 0.6090731024742126, 0.07304772734642029, 0.08170850574970245, 1.2068955898284912, 0.784133791923523, 0.1391364187002182, -0.07626868784427643, -0.47146371006965637, -0.23655104637145996, -0.9946156144142151, -0.2750430703163147, 0.42642831802368164, -0.6863983869552612, -0.2854914367198944, 0.06421595066785812, -0.0024296515621244907]}, "authors": [{"authorId": "2803574", "name": "Zachary Horvitz"}, {"authorId": "2109171018", "name": "Ajay Patel"}, {"authorId": "1763608", "name": "Chris Callison-Burch"}, {"authorId": "2116680369", "name": "Zhou Yu"}, {"authorId": "145590324", "name": "K. McKeown"}], "references": [{"paperId": "8834e8f3799ae759ee8a5bb5c8b939cf650b01cd", "title": "Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks"}, {"paperId": "d9ffb44ee3c8ec0b6692df8a90451384c1edd89b", "title": "Likelihood-Based Diffusion Language Models"}, {"paperId": "67cdecbcfed07b9a29d9e2a92da684604383afd7", "title": "TESS: Text-to-Text Self-Conditioned Simplex Diffusion"}, {"paperId": "a1186d7d9a9ef258c76afef1177e4f348061a537", "title": "SeqDiffuSeq: Text Diffusion with Encoder-Decoder Transformers"}, {"paperId": "2c6ac935c826002976722ca8d3319f691975687e", "title": "Self-conditioned Embedding Diffusion for Text Generation"}, {"paperId": "0b9770a377b3f96cef9f268cee1791d39a0d4893", "title": "SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control"}, {"paperId": "52fd344a921ee010f14259655330f712c3957b8d", "title": "More than a Feeling: Accuracy and Application of Sentiment Analysis"}, {"paperId": "1386b8a11929cf02da291c56aca353e33bbc22ed", "title": "Diffusion-LM Improves Controllable Text Generation"}, {"paperId": "01cc34196acf358cec0c4a79f92eec754dc91500", "title": "Same Author or Just Same Topic? Towards Content-Independent Style Representations"}, {"paperId": "a63e3a10d094ecce8d9021767537c30ee5aaaa9b", "title": "Mix and Match: Learning-free Controllable Text Generationusing Energy Language Models"}, {"paperId": "9370e2b4443066e6da52855fd5c443b236d8118b", "title": "Stylistic variation in email"}, {"paperId": "37c9c4e7648f639c0b36f150fc6c6c90b3682f4a", "title": "Palette: Image-to-Image Diffusion Models"}, {"paperId": "e6213b75d1d43009c1fc014af2c0f4bc705bc6cf", "title": "Text Detoxification using Large Pre-trained Neural Models"}, {"paperId": "7a79a3074e736bdd9e4ce1d46f1efe3abd6623fd", "title": "A Recipe for Arbitrary Text Style Transfer with Large Language Models"}, {"paperId": "cddf40e579a596d0110b260313adf43470617c4c", "title": "Datasets: A Community Library for Natural Language Processing"}, {"paperId": "3b02eb62f198449840334da26917e3610b283e25", "title": "Controlled Text Generation as Continuous Optimization with Multiple Constraints"}, {"paperId": "0a53be8d3af7b3e774e7a3b1208f2c9351758f8a", "title": "A Deep Metric Learning Approach to Account Linking"}, {"paperId": "b6c4a96e09b9f11e7c70e7f1fbe3f3971b92762d", "title": "FUDGE: Controlled Text Generation With Future Discriminators"}, {"paperId": "619b8c9752d615b115b6be89ea76eb037db1bf34", "title": "Ol\u00e1, Bonjour, Salve! XFORMAL: A Benchmark for Multilingual Formality Style Transfer"}, {"paperId": "de18baa4964804cf471d85a5a090498242d2e79f", "title": "Improved Denoising Diffusion Probabilistic Models"}, {"paperId": "42b8944b51be279ec12d06408e646a8d52d54b3d", "title": "Deep Learning for Text Style Transfer: A Survey"}, {"paperId": "e02c114d6269f4781b0fa92f4e2c9376e7462906", "title": "PowerTransformer: Unsupervised Controllable Revision for Biased Language Correction"}, {"paperId": "9ef33af1b2ebda2f2edd6c1394f314d7ac2f00f2", "title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification"}, {"paperId": "d9fefb72b904eb25220f063182e0825af56855ed", "title": "PySBD: Pragmatic Sentence Boundary Disambiguation"}, {"paperId": "ccad27088b9098de4eaca8dc449b18766db4b3ab", "title": "Reformulating Unsupervised Style Transfer as Paraphrase Generation"}, {"paperId": "ddf5ead09b8bdc3e1944acf69a5c40bd54f8a183", "title": "TextSETTR: Few-Shot Text Style Extraction and Tunable Targeted Restyling"}, {"paperId": "014576b866078524286802b1d0e18628520aa886", "title": "Denoising Diffusion Implicit Models"}, {"paperId": "07bcda1dff9bb696ea9cbc69303eee8bd3d85bd6", "title": "GeDi: Generative Discriminator Guided Sequence Generation"}, {"paperId": "5c126ae3421f05768d8edd97ecd44b1364e2c99a", "title": "Denoising Diffusion Probabilistic Models"}, {"paperId": "024a2c03be8e468e7c4fdf9bda36cdc0eaae85fb", "title": "Array programming with NumPy"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "c9b56cb026a38e39bb0228faac57accd6f65e6f7", "title": "TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "46b968d82c4709e74419828b2767a9218a3ebcc8", "title": "Learning Invariant Representations of Social Media Users"}, {"paperId": "e04a80263d252a3d8a382ba37a249b9345620570", "title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "cb0f3ee1e98faf92429d601cdcd76c69c1e484eb", "title": "Neural Network Acceptability Judgments"}, {"paperId": "2dcef55a07f8607a819c21fe84131ea269cc2e3c", "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"}, {"paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09", "title": "Efficient Estimation of Word Representations in Vector Space"}, {"paperId": "aad97a208b7979fc943e2c5363a5b08d1e1b9246", "title": "If I were a Rich Man \u2026"}, {"paperId": "ad890a3ac524282d54cfde9f2fb1fe37e7912ba7", "title": "Email Formality in the Workplace: A Case Study on the Enron Corpus"}, {"paperId": "98d7207066b61c15e007dac9758530b99ac06cb9", "title": "The Enron Corpus: A New Dataset for Email Classification Research"}, {"paperId": "68c03788224000794d5491ab459be0b2a2c38677", "title": "WordNet: A Lexical Database for English"}, {"paperId": null, "title": "kadarakos; Phatthiyaphaibun, W.; and Schero1994"}, {"paperId": null, "title": "\u2022 siebert/sentiment-roberta-large-english"}, {"paperId": "60e2daaf76a4259e2db955963a544e3a4328856f", "title": "Low-Resource Authorship Style Transfer with In-Context Learning"}, {"paperId": "da193732a710a678b1786c795814cfa82ca95c66", "title": "A large-scale computational study of content preservation measures for text style transfer and paraphrase generation"}, {"paperId": null, "title": "Accelerate: Training and inference at scale made simple, efficient and adaptable"}, {"paperId": "c71f40033cb0f8e76ef28e504240ae14317a5094", "title": "Learning Universal Authorship Representations"}, {"paperId": null, "title": "HuggingFace\u2019s Transformers: State"}, {"paperId": null, "title": "Experiment Tracking with Weights and Biases"}, {"paperId": null, "title": "2019) \u2022 Mutual Implication Score (Babakov et al. 2022) \u2022 textattack/roberta-base-CoLA"}, {"paperId": null, "title": "Original Text Thursday afternoon would be best for me. Enron North America Corp. me?? ParaGuide (\u03bb = 5e2) Thursday afternoon would work best for me"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "1a6099290afeb592d04b9ded83d4499e28924e03", "title": "Statsmodels: Econometric and Statistical Modeling with Python"}, {"paperId": null, "title": "2021) \u2022 Accelerate (Sylvain Gugger 2022) \u2022 Sentence-transformers (Reimers and Gurevych 2019) \u2022 spaCy"}, {"paperId": null, "title": "Natural Language Processing with Python"}, {"paperId": null, "title": "Report spawned stupid OUR VERY same argument int=/2 over GridFlorida ParaGuide (\u03bb = 1e3) FYIs???"}, {"paperId": null, "title": "ParaGuide (\u03bb = 2e2) Thu afternoon would be best with me!Says STRAP fine-tuned"}, {"paperId": null, "title": "M&M (Hamming) I think this expands your scope tremendously (Which is, of course, a good thing"}, {"paperId": null, "title": "or I'll call you Original Text It is not intended to be a negotiated rate"}, {"paperId": null, "title": ". 2023. explosion"}, {"paperId": null, "title": "explosion/spaCy: v3.6.1: Support for Pydantic v2, find-function CLI and more"}, {"paperId": null, "title": "ParaGuide (\u03bb = 5e2) So I welcome the Risk/reward and continue carrying charges on the Mitsubishis"}, {"paperId": null, "title": "ParaGuide (\u03bb = 1e3) too awful!!!!! I'm driving tomorrow. Probably would prefer later afternoon Frida"}, {"paperId": null, "title": "M&M (Hamming) B2 contains the same complaints that we made to FERC in GridFlorida (mentions Ca"}, {"paperId": null, "title": "Original Text Thanks, Tana! -MP = 1e3) Thanks, tana? ParaGuide (\u03bb = 5e2) Tana???"}, {"paperId": null, "title": "ParaGuide (\u03bb = 5e2) It's due monday morning, we make the same arguments in SECTION B02 in GridFlorid"}, {"paperId": null, "title": "OpenAI"}, {"paperId": null, "title": "ParaGuide (\u03bb = 5e3) May we continue delivering on risk/reward for our charges E Mitsubishis? Awesome"}, {"paperId": null, "title": "Chris Calger asked if we should continue wearing the risk/reward and carrying"}, {"paperId": null, "title": "ParaGuide (\u03bb = 5e3) Awesome!! I'm going to Chile next week. Just let me know!! thanks ParaGuide (\u03bb = 1e3) Just let me know this will help"}, {"paperId": null, "title": "ParaGuide (\u03bb = 5e3) ont get excited until you read it"}, {"paperId": null, "title": "M&M (Hamming) don't get too excited until you read it :) There's lots of stuff I just had to p"}, {"paperId": null, "title": "We validate our approach on formality and sentiment transfer, where it outperforms strong baselines on automatic evaluations"}, {"paperId": null, "title": "ParaGuide (\u03bb = 5e2) i think the expiration bars in GDT chart"}, {"paperId": null, "title": "2023. SSD-2: Scaling and Inference-time Fusion of Diffusion Language Models"}, {"paperId": null, "title": "= 2e2) I'm going over to South America this summer starting next week plus expecting so"}, {"paperId": null, "title": "ParaGuide (\u03bb = 1e3) don't get excited until you read it, I just put place holders on but we'll get i"}, {"paperId": null, "title": "= 2e2) This is the Loan deal for Friday and Saturday, we are definitely doing this week"}, {"paperId": null, "title": "\u2022 cardiffnlp/twitter-roberta-base-sentiment (Barbieri et al. 2020)"}, {"paperId": null, "title": "Here's the draft that Allegretti is sending. here you go Sounds pretty harmless to me. If you don't want to do it, let me know and I'll p"}, {"paperId": null, "title": "Generating an initial paraphrase of an input text with an autoregressive (AR) model"}, {"paperId": null, "title": "Original Text sorry...when did you get out of here yesterday? get out of here yesterday? I'm sorry"}, {"paperId": null, "title": "Well-formedness. Does the output look like a reasonable email? Is it coherent? ( 0 =Badly-Formed, 1 =Well-formed)"}, {"paperId": null, "title": "Original Text He's re-trading on the retainage. Let's discuss"}, {"paperId": null, "title": "Using a paraphrase-conditioned text diffusion model to iteratively reconstruct the input text from this paraphrase over a number of diffusion steps"}, {"paperId": null, "title": "M&M (Hamming) did you get out of here Original Text PLEASE DISREGARD THIS INFO. WE ARE NO LONGER DOING THE LENDING DEAL"}, {"paperId": null, "title": "Original Text I'm swamped at the moment and I'll be in South America next week. I then have va"}, {"paperId": null, "title": "ParaGuide (\u03bb = 5e2) I am on my way to South America next week. I am definitely around and could help"}, {"paperId": null, "title": "STRAP fine-tuned .. Thanks for the link. I'll look into it"}, {"paperId": null, "title": "ds look like the market opening date"}, {"paperId": null, "title": "ParaGuide (\u03bb = 5e2) Too busy!!!! I'd prefer something early afternoon Friday (may actually be drivin"}, {"paperId": null, "title": "ParaGuide (\u03bb = 1e3) got all -the bars in any GANTT chart end March 1, 2002-that appears as NEW mar"}, {"paperId": null, "title": "Target Author Examples Some very nice, and very appropriate thoughts about John Ambler. Wade continues"}, {"paperId": null, "title": "ParaGuide (\u03bb = 1e4) i just put place holders on but we will get it all filled out, don't get excited"}]}