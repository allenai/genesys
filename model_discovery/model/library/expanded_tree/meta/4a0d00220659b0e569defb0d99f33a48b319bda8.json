{"paperId": "4a0d00220659b0e569defb0d99f33a48b319bda8", "abstract": "Text-guided 3D visual grounding (T-3DVG), which aims to locate a specific object that semantically corresponds to a language query from a complicated 3D scene, has drawn increasing attention in the 3D research community over the past few years. Compared to 2D visual grounding, this task presents great potential and challenges due to its closer proximity to the real world and the complexity of data collection and 3D point cloud source processing. In this survey, we attempt to provide a comprehensive overview of the T-3DVG progress, including its fundamental elements, recent research advances, and future research directions. To the best of our knowledge, this is the first systematic survey on the T-3DVG task. Specifically, we first provide a general structure of the T-3DVG pipeline with detailed components in a tutorial style, presenting a complete background overview. Then, we summarize the existing T-3DVG approaches into different categories and analyze their strengths and weaknesses. We also present the benchmark datasets and evaluation metrics to assess their performances. Finally, we discuss the potential limitations of existing T-3DVG and share some insights on several promising research directions. The latest papers are continually collected at https://github.com/liudaizong/Awesome-3D-Visual-Grounding.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This survey attempts to provide a comprehensive overview of the T-3DVG progress, including its fundamental elements, recent research advances, and future research directions, by providing a general structure of the T-3DVG pipeline with detailed components in a tutorial style."}, "embedding": {"model": "specter_v2", "vector": [-0.273726224899292, -0.1347818821668625, -0.564128041267395, -0.19671019911766052, -0.07606060057878494, -0.3091217577457428, 0.69474196434021, -0.19973935186862946, -0.1970493644475937, -0.8870239853858948, 0.5278998017311096, 0.2832178473472595, 0.2805696129798889, -0.7280234694480896, -0.09220518171787262, 0.3597913086414337, -0.8710883259773254, 0.7498883605003357, 0.7338024973869324, -0.8049856424331665, 0.11728385835886002, 0.2005971074104309, -1.418511152267456, 0.30549055337905884, 0.25940313935279846, 0.8782232403755188, -0.002780088223516941, 0.8433384895324707, -0.7809661030769348, -0.39768338203430176, 0.5693153738975525, 0.055467408150434494, 0.6280210614204407, -0.09602973610162735, -0.1471361219882965, -0.041328251361846924, 0.7126107215881348, -0.5458677411079407, -0.5404502153396606, 0.5740593075752258, 0.20450237393379211, 0.37010759115219116, 0.7392644286155701, -1.0504363775253296, -0.2769720256328583, -0.1196424588561058, 0.2469683587551117, 0.010495501570403576, 0.5919356346130371, -0.9437195658683777, 1.3232054710388184, -1.459862232208252, 0.7055036425590515, 1.6012133359909058, 0.33994659781455994, 0.07236851006746292, 0.15564900636672974, -0.11985898017883301, 0.2836790382862091, -0.06523210555315018, -1.16457998752594, 0.1686086654663086, -0.0257266815751791, -0.6953349709510803, 1.0659949779510498, -0.45187756419181824, -0.12233680486679077, 0.5652433037757874, -0.5338816046714783, 0.9413789510726929, -0.49216997623443604, -1.0460355281829834, 0.14079274237155914, -0.581751823425293, -0.3110271096229553, 0.9066823124885559, -0.16468894481658936, 0.49798208475112915, -1.1580629348754883, -0.36844921112060547, 0.700209379196167, 0.008993257768452168, 0.18119490146636963, -0.9521281719207764, -0.4525471031665802, 0.7384240031242371, 0.9402904510498047, 0.3021463453769684, 0.04487544298171997, 0.6964446306228638, 0.12632478773593903, -0.16489316523075104, 0.17469926178455353, -0.29495322704315186, 0.46101266145706177, 0.6642890572547913, -1.0925360918045044, 0.6596647500991821, 0.1136605441570282, 1.2290377616882324, -0.25957635045051575, -0.2927103042602539, -0.3213514983654022, 0.28184592723846436, 1.2895238399505615, 0.4748401641845703, 0.12241461873054504, -0.37714576721191406, 0.6308228969573975, -0.3448725640773773, 0.7656802535057068, -1.1373552083969116, -0.0880126953125, 0.32572272419929504, -0.22194163501262665, -0.4948735237121582, -0.39409488439559937, 0.27020102739334106, -1.0204147100448608, -0.26366156339645386, 0.30047520995140076, -0.06879224628210068, -0.17370817065238953, 1.0246185064315796, 1.1085569858551025, 0.6757139563560486, -0.08247783035039902, 1.0115290880203247, 1.091786503791809, -0.8892035484313965, -0.3158240020275116, -0.601649820804596, 0.7196120023727417, -0.40674030780792236, 0.8195717930793762, -0.6315251588821411, -0.7436875104904175, -1.042650818824768, -1.0681287050247192, -0.29239776730537415, -0.9025633335113525, 0.333570659160614, 0.6380995512008667, -0.11430104821920395, -1.140079140663147, 0.4366213381290436, -0.03787067160010338, -0.8333849906921387, 0.3918024003505707, -0.39050206542015076, 0.04333924129605293, -0.595721423625946, -0.8625930547714233, 0.06810792535543442, -0.01276404969394207, -0.6007305383682251, -0.4319843351840973, 0.2027592808008194, -1.1132875680923462, -0.518679678440094, 0.44904735684394836, -1.0579711198806763, 0.8242060542106628, 0.6843850612640381, -0.8860546350479126, 0.884425163269043, -0.27800729870796204, 0.29201409220695496, 0.8467631340026855, -0.6235372424125671, -0.35345688462257385, -0.06334377080202103, 0.1696886122226715, 0.7234912514686584, 0.2275504618883133, -0.871078372001648, -0.15006546676158905, -0.07632444053888321, -0.25022849440574646, 0.25176793336868286, 0.11419820785522461, 1.1106699705123901, -1.0216280221939087, -0.4113015830516815, 1.1438103914260864, 0.7754460573196411, -0.2930203676223755, 0.793498158454895, -0.7773894667625427, -0.5531573295593262, 1.1652437448501587, 0.4179069399833679, 0.38711562752723694, -0.6826313138008118, -0.7617618441581726, 0.036928690969944, -0.05286113917827606, -0.7900679707527161, -0.8128150105476379, 0.9846915006637573, 0.14151403307914734, 0.5750760436058044, 0.13075852394104004, -0.9989782571792603, 0.1422319859266281, -0.3637883961200714, -0.7439784407615662, 0.11500727385282516, -0.2278224527835846, 1.000064492225647, -1.1306666135787964, -0.31668585538864136, 0.3209728002548218, 0.31701037287712097, -0.6003377437591553, 0.9649327993392944, -1.1040560007095337, 0.07549496740102768, -0.8054418563842773, 0.6583017110824585, 0.015653427690267563, 0.11555776745080948, -0.2061663568019867, -0.4978560209274292, -0.24361979961395264, 0.1889585256576538, -0.9269231557846069, 1.9678841829299927, 0.4459669888019562, 0.16388770937919617, -0.45851588249206543, -0.2729157507419586, 0.5890492796897888, 0.27266213297843933, 6.19058555457741e-05, -0.3237886428833008, 0.3286970555782318, 0.44704413414001465, -1.146509051322937, 0.16524888575077057, 0.9349464774131775, 1.1664161682128906, -0.2174079418182373, 0.02242126874625683, -0.2149730622768402, -0.656096875667572, 0.11712618917226791, 0.44109559059143066, 0.2584494948387146, 1.0091142654418945, 0.0025553929153829813, -0.1341257393360138, 0.026848075911402702, 0.05327403172850609, -0.6597009897232056, 0.7716186046600342, 1.1251107454299927, 1.606157660484314, 0.15291830897331238, -0.977277934551239, -0.19206278026103973, -0.11517833918333054, 0.785909116268158, 1.500846266746521, 0.8114737868309021, -0.7460413575172424, -0.49306291341781616, -0.7223466038703918, -0.17633238434791565, -0.4137888550758362, -0.5850227475166321, 0.9023586511611938, -0.16688229143619537, -0.38177022337913513, 0.9160191416740417, 0.4955004155635834, 1.2691773176193237, -0.35745835304260254, -0.8194964528083801, -0.6280375719070435, -0.004419825971126556, -0.8500618934631348, -0.5740270018577576, -0.1020905002951622, -0.34904566407203674, -0.4034986197948456, -0.3933517336845398, -0.19391334056854248, 0.4323717951774597, -0.2844202220439911, 0.9470669627189636, 0.17480112612247467, -0.25869694352149963, 0.07043520361185074, -0.20240572094917297, -1.141306757926941, -0.24322785437107086, 0.20032596588134766, 0.07825436443090439, -0.7377965450286865, 0.31556376814842224, 0.4883614778518677, -0.009761905297636986, 0.7189322113990784, -0.4722689092159271, 0.0574946403503418, -0.6402714848518372, -0.6884796023368835, 1.2884252071380615, -0.33562174439430237, -0.25001078844070435, -0.21747618913650513, 0.6170467734336853, 0.32610782980918884, -0.6668201088905334, -0.06471121311187744, -0.23280444741249084, -0.4403441846370697, -0.25625839829444885, -0.2900616228580475, 0.26583847403526306, -0.47658365964889526, 0.33895036578178406, -0.562242865562439, -0.9660361409187317, 0.17931553721427917, 0.07987794280052185, 0.028246495872735977, 0.9725680351257324, -0.025348279625177383, 0.16594597697257996, -0.6811314821243286, 1.219443917274475, -0.7481074929237366, 0.49149543046951294, -0.2180643379688263, 0.6959110498428345, 0.6207817196846008, 0.4315813183784485, -0.9829643964767456, -0.4234701991081238, -0.5771527290344238, -1.2114499807357788, -0.6041945815086365, 0.560630202293396, -0.1677100509405136, 0.14144326746463776, -0.35384461283683777, -1.3447986841201782, 0.00981195643544197, 0.31637653708457947, -0.50961834192276, -0.6779924035072327, -0.7850768566131592, -0.47574087977409363, -0.5917682647705078, -0.3890926241874695, -0.7926496863365173, 1.15359628200531, -0.3011596202850342, -0.055695611983537674, -0.3284360468387604, 0.19806531071662903, -0.9037622809410095, 0.35571804642677307, 0.5044333934783936, 0.8129640817642212, 0.017616285011172295, -0.373597115278244, -0.32800954580307007, 0.14457349479198456, -0.4081076383590698, 0.0802323967218399, 0.36359262466430664, -0.46844056248664856, 0.7578485608100891, -0.3283720016479492, 0.0035889074206352234, -0.10372919589281082, 0.4414273500442505, 0.3948855698108673, 0.6615083813667297, -1.0981310606002808, 0.4588357210159302, 1.6573829650878906, -0.26276013255119324, 0.06732727587223053, 0.3932601809501648, 1.0133048295974731, 0.6459160447120667, -0.09440874308347702, 0.6257538795471191, 0.327793687582016, 0.7263625860214233, 0.9882007241249084, -0.7111215591430664, -0.5649402737617493, -0.8591121435165405, 0.023463312536478043, 0.6619859933853149, -0.13527250289916992, -0.27968281507492065, -1.3639600276947021, 0.821422815322876, -1.3261669874191284, -0.3215642273426056, 0.090815469622612, 0.7630756497383118, -0.41652533411979675, -0.530160129070282, 0.40777403116226196, -0.635193943977356, 0.49423032999038696, 0.5428899526596069, 0.03751282021403313, 0.13411425054073334, -0.08347821980714798, 0.006293707527220249, -0.35595372319221497, 0.5590971112251282, -0.5659939646720886, 0.6720158457756042, 14.285872459411621, 0.7201576232910156, 0.014814605936408043, -0.19786569476127625, 0.38517606258392334, 0.3442256450653076, -0.11136321723461151, -0.13410566747188568, -1.0534347295761108, -0.5638113617897034, 0.4794691503047943, 0.18734079599380493, -0.022761883214116096, 0.7275862693786621, 0.4063921570777893, 0.09839124232530594, -0.72248774766922, 0.8558877110481262, 0.45931732654571533, -1.2475534677505493, 0.3478602170944214, 0.30323803424835205, 0.19682882726192474, 1.0246524810791016, 0.3513771891593933, 0.22567255795001984, 0.42279550433158875, -0.957046627998352, 0.8884117603302002, -0.2900172472000122, 1.0936870574951172, -0.12589049339294434, 0.2838728427886963, 0.7128254175186157, -1.3572560548782349, 0.319356232881546, -0.9390284419059753, -0.970160722732544, 0.3694716989994049, -0.07123708724975586, -0.7024376392364502, 0.3500403165817261, -0.07151971012353897, 0.4706570506095886, 0.14116443693637848, 0.7379106283187866, -0.26161032915115356, -0.41711682081222534, -0.602382481098175, -0.014205723069608212, 0.41716432571411133, 0.33607161045074463, 0.18564589321613312, -0.17246170341968536, 0.6564350724220276, 0.08669073134660721, 0.6058828234672546, 0.35264670848846436, -0.4599807858467102, 0.5536214709281921, -1.1640403270721436, 0.23267531394958496, -0.2732970416545868, 0.39245080947875977, -0.4564093053340912, 0.5707806348800659, -0.014865085482597351, 0.5305641293525696, 0.09090647101402283, 0.08621681481599808, -0.5423958897590637, -0.2830490171909332, 0.004781549330800772, 0.6337458491325378, 0.2540324330329895, -0.02240738458931446, -0.2760210335254669, -0.3314756751060486, -0.4497305452823639, 0.47486817836761475, 0.522795557975769, -1.018537163734436, -1.1762977838516235, 1.3777471780776978, 0.32014355063438416, -1.2129930257797241, 0.016109023243188858, -0.4616030156612396, -0.2083468735218048, 0.4735904335975647, -1.103176474571228, -1.1441354751586914, -0.34998413920402527, 0.3167097270488739, -0.063808873295784, 0.4295116662979126, 1.045470118522644, -0.19890068471431732, 0.31368252635002136, -0.631525993347168, 0.03769649565219879, 0.15609098970890045, -0.1586528718471527, -0.4385693073272705, 1.078262448310852, 0.1513918936252594, 0.5345768332481384, -0.026203908026218414, -0.22087375819683075, -0.5452896952629089, -0.4368826448917389, -0.21348051726818085, -0.08692122250795364, -1.006748914718628, -0.8219010233879089, -1.0541892051696777, -0.7414232492446899, -0.0648658499121666, 0.42389410734176636, -0.05578265339136124, -0.0960269421339035, -0.17260143160820007, -0.5535560250282288, 0.5816292762756348, -1.2385176420211792, 0.49595269560813904, 0.8118874430656433, -0.2699373960494995, -0.4905789792537689, 0.1777336299419403, 0.4694945216178894, -1.590155005455017, -0.2532397508621216, -0.034086279571056366, 0.15392380952835083, -0.24829165637493134, 1.327515721321106, -0.3516773581504822, 0.6103258728981018, 0.011879713274538517, -0.9064326882362366, -0.7264342308044434, 0.48097318410873413, -0.5436298251152039, -0.08821143209934235, -0.3433102071285248, 0.4971165359020233, 0.4406159520149231, 0.8165441155433655, 0.6671619415283203, 0.6656570434570312, -0.5213916301727295, -0.03532114624977112, -0.651763379573822, 0.04337179288268089, -0.7271336913108826, 0.5636857151985168, -0.24425305426120758, -0.3798796534538269, -0.18672411143779755, 0.5194138288497925, 0.9683914184570312, -0.18734560906887054, -0.4274265766143799, 1.0782214403152466, -0.40337926149368286, 0.4537111222743988, -0.2603919208049774, -0.7405113577842712, -1.882598638534546, -0.514866054058075, -0.9896493554115295, 0.0774914100766182, -1.9662737846374512, -1.2839497327804565, 0.04463502764701843, 0.1720438301563263, -0.2651689946651459, 0.9533678889274597, -0.33063605427742004, -0.23085881769657135, -0.1429845541715622, -0.29833364486694336, 0.7380610108375549, 0.8913431167602539, -0.4285474419593811, -0.19402898848056793, -0.11785395443439484, 0.3946734666824341, 0.8276666402816772, 0.2769760191440582, -0.6698159575462341, -1.0242812633514404, -1.3344714641571045, 0.11206680536270142, -0.22357137501239777, 0.15683922171592712, -0.8150182962417603, 0.7386099696159363, 0.05182073637843132, 0.11474429816007614, -1.0873403549194336, 0.7807881832122803, -0.8673833012580872, -0.6040955185890198, -0.03411924093961716, -0.228766530752182, 0.2012718915939331, 0.12008374184370041, -0.15915344655513763, -0.30933308601379395, 0.7482445240020752, -0.12253566086292267, -1.039780616760254, -0.7020758390426636, 0.6133286356925964, 0.07280082255601883, -0.17719781398773193, -0.08278442174196243, -0.673378586769104, -0.745544970035553, -0.6932106614112854, -0.40479716658592224, 0.2675587832927704, -0.005321909207850695, 1.2644016742706299, 0.9337561726570129, -1.610688328742981, -0.13982166349887848, -0.04510123282670975, 0.3450359106063843, 0.5134329795837402, 0.3101886510848999, 0.17971430718898773, -0.6491546630859375, 0.46671798825263977, 0.44223734736442566, -0.12249592691659927, -0.6457414031028748, -0.05660680681467056, 0.7122992873191833, 0.3984883427619934, -0.8236602544784546, 0.9588665962219238, -0.21410173177719116, -0.7274287939071655, 0.01978903077542782, -1.0571529865264893, -0.28416091203689575, -0.2576170265674591, 0.8087193369865417, 0.27136513590812683, 0.327801913022995, -0.5590330362319946, -0.724582314491272, 1.0550049543380737, 0.35388869047164917, -0.8738881945610046, 0.34010040760040283, -0.009600802324712276, 0.1596357375383377, 0.205743670463562, 0.4764528274536133, -0.22315837442874908, -0.6952163577079773, -0.4550815224647522, 0.0026461214292794466, -0.9074659943580627, -0.030474141240119934, -0.5490119457244873, -0.42686527967453003, 0.5681734085083008, 0.4200415313243866, 0.7235079407691956, -0.05728760361671448, 0.6490007638931274, 0.26450520753860474, 0.8081664443016052, 0.6619826555252075, -0.30066344141960144, -0.26852065324783325, 0.9314457774162292, 1.8858956098556519, -0.4867779612541199, 0.4921964108943939, -0.6515465974807739, -0.2884662449359894, 1.086427927017212, 0.2612883746623993, -0.04383334517478943, 0.8842505812644958, -0.17703679203987122, 0.24514532089233398, -0.5028395652770996, 0.07774991542100906, -0.1561272144317627, 0.7870697379112244, 1.8420653343200684, 0.07997674494981766, 0.03524705022573471, 0.48358893394470215, 0.2557643949985504, -0.05236702412366867, 0.04630346968770027, 0.21745961904525757, 0.7040852904319763, -0.43907004594802856, -0.14533911645412445, -0.46337515115737915, 0.41006121039390564, -0.1390201449394226, -0.3001413941383362, -0.49048927426338196, 0.9903564453125, 0.1676110476255417, 0.8360124230384827, 0.6593928933143616, -0.2569466531276703, 1.0441389083862305, 0.036186009645462036, 0.5287125706672668, -0.8235414624214172, 0.3124265968799591, 0.1875872164964676, -0.7205256223678589, -0.5214357376098633, -0.3014870882034302, -0.3882733881473541, -0.658577561378479, 0.019388515502214432, 0.3425256311893463, -0.4031546115875244, 0.6863423585891724, 0.49842000007629395, 0.8356622457504272, -0.27247369289398193, -0.5731147527694702, -0.7857831716537476, -0.04091352969408035, -0.5469112396240234, -0.04230214282870293, -0.5609561800956726, -0.3254607021808624, -0.6416986584663391, 0.15659478306770325, -0.0011632002424448729]}, "authors": [{"authorId": "2135646549", "name": "Daizong Liu"}, {"authorId": "2275219162", "name": "Yang Liu"}, {"authorId": "2238007314", "name": "Wencan Huang"}, {"authorId": "2238032186", "name": "Wei Hu"}], "references": [{"paperId": "214ff1d7afcd31477997805f0e6cfa517bc8f00c", "title": "Multi-branch Collaborative Learning Network for 3D Visual Grounding"}, {"paperId": "8309d909e859fac10d03fe1055f34dc34fbccc40", "title": "Dual Attribute-Spatial Relation Alignment for 3D Visual Grounding"}, {"paperId": "5796cafa3ab6e897762604d8af664e36d914b796", "title": "Talk to Parallel LiDARs: A Human-LiDAR Interaction Method Based on 3D Visual Grounding"}, {"paperId": "0774976a779bedb573a7a73a752ad229b0274dc0", "title": "Talk2Radar: Bridging Natural Language with 4D mmWave Radar for 3D Referring Expression Comprehension"}, {"paperId": "391369c2dad3010938a8cd4b643e3fac46700839", "title": "Unifying 3D Vision-Language Understanding via Promptable Queries"}, {"paperId": "ed70bd2d693dfdcd220eaead5f3e22678a94802f", "title": "MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors"}, {"paperId": "cd0dce4f29ed39ecb4bd9321bae7c36f319a71ca", "title": "Naturally Supervised 3D Visual Grounding with Language-Regularized Concept Learners"}, {"paperId": "6e39109d8c0df48896d1a512746eb418621b5fa1", "title": "PointCloud-Text Matching: Benchmark Datasets and a Baseline"}, {"paperId": "e3c2c4104ca8923fd58508ab6cb52f5c579a77c9", "title": "Scene-LLM: Extending Language Model for 3D Visual Understanding and Reasoning"}, {"paperId": "e788d5c6dc79f106296f8ad296bcbe512028d5f0", "title": "3D-VLA: A 3D Vision-Language-Action Generative World Model"}, {"paperId": "4eacce6b92d86390d1c4e863ee5562fd46368bbc", "title": "SeCG: Semantic-Enhanced 3D Visual Grounding via Cross-modal Graph Attention"}, {"paperId": "fc2afacd535c80aac7a2942de1128a0d771267c0", "title": "MiKASA: Multi-Key-Anchor & Scene-Aware Transformer for 3D Visual Grounding"}, {"paperId": "d20af65f2bf1de721949227a3229bec356adfc39", "title": "A survey of methods for addressing the challenges of referring image segmentation"}, {"paperId": "37cd213f8550cb52611de72740a70eb5e2a9cb8c", "title": "A Comprehensive Survey of 3D Dense Captioning: Localizing and Describing Objects in 3D Scenes"}, {"paperId": "4a7fe6455070ab650f3d5c256a0d9a9a7b746789", "title": "A Transformer-based Framework for Visual Grounding on 3D Point Clouds"}, {"paperId": "7360dc0e368bb7de312ee4abeaf5e8595781e103", "title": "Zero-Shot Video Grounding With Pseudo Query Lookup and Verification"}, {"paperId": "932414baad97de9c2d93cd299a81ad6441353816", "title": "SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding"}, {"paperId": "d9263ba30a16067c44884ad559802505acf2f82d", "title": "3DMIT: 3D Multi-modal Instruction Tuning for Scene Understanding"}, {"paperId": "55d184e7bcf467f2824cd9603194e523b206f8e7", "title": "EmbodiedScan: A Holistic Multi-Modal 3D Perception Suite Towards Embodied AI"}, {"paperId": "621505d30660e956d1410d20e44303775fc11c1e", "title": "Weakly-Supervised 3D Visual Grounding based on Visual Linguistic Alignment"}, {"paperId": "abfdcab6879729544410c8bdcd2c47387749c5ad", "title": "Mono3DVG: 3D Visual Grounding in Monocular Images"}, {"paperId": "1b63f17b82d3a5910d22b24d54d6d74a32fcdb4d", "title": "Reimagining 3D Visual Grounding: Instance Segmentation and Transformers for Fragmented Point Cloud Scenarios"}, {"paperId": "574d3ea2e24c1857fb2bec0a4cec9a925800cf36", "title": "Uni3DL: Unified Model for 3D and Language Understanding"}, {"paperId": "4ada01c0cc79ed4abe081bd59300247626501808", "title": "GPT4Point: A Unified Framework for Point-Language Understanding and Generation"}, {"paperId": "7b0a186b0140ee91fb13991c9c7187f3dc3b0670", "title": "Visual Programming for Zero-shot Open-Vocabulary 3D Visual Grounding"}, {"paperId": "ca51c8801e34a5a3d04b99313bb986c7b968b460", "title": "Language-guided Robot Grasping: CLIP-based Referring Grasp Synthesis in Clutter"}, {"paperId": "0307c481f3b125fd87bd7f93fb3c460adf8c7187", "title": "Recent Advances in Multi-modal 3D Scene Understanding: A Comprehensive Survey and Evaluation"}, {"paperId": "92b48adfddd6177618c4f7451c8ea593a794a1a1", "title": "CoT3DRef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding"}, {"paperId": "9db0247728950788a2b42097d81dc0e24eed6bb2", "title": "LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent"}, {"paperId": "a34232bcb1ba2fa534fb6795c085f6d2ef9059d0", "title": "Multi3DRefer: Grounding Text Description to Multiple 3D Objects"}, {"paperId": "0e3d2ad44bfadde66a63849ea85ee0f2ccb9a5e3", "title": "Four Ways to Improve Verbo-visual Fusion for Dense 3D Visual Grounding"}, {"paperId": "a6a7cda9eac019a91bcaccb6ef3b1c46630410f5", "title": "Dense Object Grounding in 3D Scenes"}, {"paperId": "1c509635c1c01e31c6d6e1c493d70ed0b1e8218d", "title": "3D-STMN: Dependency-Driven Superpoint-Text Matching Network for End-to-End 3D Referring Expression Segmentation"}, {"paperId": "83f6e8a34d9551df9a24a91e00ad70e9bd55f492", "title": "A Unified Framework for 3D Point Cloud Visual Grounding"}, {"paperId": "64a80a33018a0fdc182b06111e32b2e08e186f6a", "title": "3D-VisTA: Pre-trained Transformer for 3D Vision and Text Alignment"}, {"paperId": "e54c859515b68c5c7a56f66382b9e9605953df0b", "title": "3DRP-Net: 3D Relative Position-aware Network for 3D Visual Grounding"}, {"paperId": "b4ad20e79b324007b7f244d19cab95881c2c5c78", "title": "Distilling Coarse-to-Fine Semantic Matching Knowledge for Weakly Supervised 3D Visual Grounding"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "60e65666b923d2504ffe5dced07fb780ad3714cb", "title": "Hypergraph Representation for Detecting 3D Objects From Noisy Point Clouds"}, {"paperId": "a7fab5b0cc0bf96a1f987f9ebf18177e7915ba60", "title": "PATRON: Perspective-Aware Multitask Model for Referring Expression Grounding Using Embodied Multimodal Cues"}, {"paperId": "fd755dc7b5b206c17fd953db04e1c888d45b6e4e", "title": "LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark"}, {"paperId": "3b8871e4c25d3aaca2bee6606c07bc870337253c", "title": "Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions"}, {"paperId": "c0828c270bfa9d633f9727fcb0fdb1be703e362d", "title": "Context-aware Alignment and Mutual Masking for 3D-Language Pre-training"}, {"paperId": "86ea4aa29241149c3999301f0285d8cbb8542b11", "title": "Vision-Language Pre-training with Object Contrastive Learning for 3D Scene Understanding"}, {"paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd", "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"}, {"paperId": "8cf819f6ee33909484ece40d79944c9c37f01a89", "title": "A Brief Overview of ChatGPT: The History, Status Quo and Potential Future Development"}, {"paperId": "7e32aac43e9f1df49e116add03327ee6f365dbf3", "title": "mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality"}, {"paperId": "ca6a2bc279be5a3349a22bfd6866ed633d18734b", "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "17015d364204c4ac2d65f9b0d30f10d5f6f2cad5", "title": "CLIP-Guided Vision-Language Pre-training for Question Answering in 3D Scenes"}, {"paperId": "7db8daabafa2cba01206d5b6b5d4d0697cb0abdc", "title": "WildRefer: 3D Object Localization in Large-scale Dynamic Scenes with Multi-modal Visual Data and Natural Language"}, {"paperId": "380a4d6873736427886cd00ed9c137abe97b8da9", "title": "ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding"}, {"paperId": "d4a03a6e4920bf1ef6add32b58dfca63ae3643b9", "title": "ScanERU: Interactive 3D Visual Grounding based on Embodied Reference Understanding"}, {"paperId": "3c45fd32b56efaa009a3ecef963d233dc5814194", "title": "NS3D: Neuro-Symbolic Grounding of 3D Objects and Relations"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "53d128ea815bcc0526856eb5a9c42cc977cb36a7", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "eccf53e26fd92d09eede89c5345743442bb139f1", "title": "ScanEnts3D: Exploiting Phrase-to-3D-Object Correspondences for Improved Visio-Linguistic Models in 3D Scenes"}, {"paperId": "8abaaa14c7b2f089c081bf031cc4b144a60a6759", "title": "UniT3D: A Unified Transformer for 3D Dense Captioning and Visual Grounding"}, {"paperId": "bbd5288edbc0e1e4793471250fbf85cc1b40f4ab", "title": "Look Around and Refer: 2D Synthetic Semantics Knowledge Distillation for 3D Visual Grounding"}, {"paperId": "88c741be2c0200f0eff9877d99fbce612ba64d07", "title": "Language Conditioned Spatial Relation Reasoning for 3D Object Grounding"}, {"paperId": "6e17072e4cbfe47ffcccebe2baa3404ad3b42dda", "title": "Language-free Training for Zero-shot Video Grounding"}, {"paperId": "c4abd21df3ca0d7a7b59516fb7b6502c16edeec1", "title": "Learning Point-Language Hierarchical Alignment for 3D Visual Grounding"}, {"paperId": "bad645afceaa758fa7874c51d2c7925e87733ac5", "title": "Prompt-based Zero-shot Video Moment Retrieval"}, {"paperId": "7272153cbfe89a8581985919e5cbdc8e7b65a6ce", "title": "EDA: Explicit Text-Decoupling and Dense Alignment for 3D Visual Grounding"}, {"paperId": "c8b968491bddea0293d2714894d311af86a36a95", "title": "Heterogeneous Network Crawling: Reaching Target Nodes by Motif-Guided Navigation"}, {"paperId": "1c0fda88fbc4f9b03326ef54949d45b3609fab5b", "title": "A Survey on Video Moment Localization"}, {"paperId": "43a92d4c1a58ec34072b9f3f35e27bb45ae1cb7e", "title": "Toward Explainable and Fine-Grained 3D Grounding through Referring Textual Phrases"}, {"paperId": "fade0ef67bcad3369e83348111a73c0f9578786f", "title": "3DJCG: A Unified Framework for Joint Dense Captioning and Visual Grounding on 3D Point Clouds"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "c0634ed4e6531f637c6b2450ad7919e915737da2", "title": "3D-SPS: Single-Stage 3D Visual Grounding via Referred Point Progressive Selection"}, {"paperId": "c57293882b2561e1ba03017902df9fc2f289dea2", "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"}, {"paperId": "44d1b81911e35e2aa2c03a5347b88ae479602837", "title": "Multi-View Transformer for 3D Visual Grounding"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "31d457dd6f96a088236ca2eb3ffe00759ae4b373", "title": "Temporal Sentence Grounding in Videos: A Survey and Future Directions"}, {"paperId": "0550d6b18ab641bc61bb77d824aa8a0c939cc719", "title": "3DRefTransformer: Fine-Grained Object Identification in Real-World Scenes Using Natural Language"}, {"paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d", "title": "High-Resolution Image Synthesis with Latent Diffusion Models"}, {"paperId": "7002ae048e4b8c9133a55428441e8066070995cb", "title": "GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models"}, {"paperId": "7ec45c59e4fb19065e17967a350524c936cc7144", "title": "Bottom Up Top Down Detection Transformers for Language Grounding in Images and Point Clouds"}, {"paperId": "52706e21fea7a583e9d86798a67148ea877fe664", "title": "D3Net: A Unified Speaker-Listener Architecture for 3D Dense Captioning and Visual Grounding"}, {"paperId": "69ff4686b6517a0f9ae59503fedd8ed6e7be9983", "title": "3DVG-Transformer: Relation Modeling for Visual Grounding on Point Clouds"}, {"paperId": "db9b010f4fc448e0f29c23a45e1b66f5ad8812a1", "title": "CONQUER: Contextual Query-aware Ranking for Video Corpus Moment Retrieval"}, {"paperId": "191a8f11cbeaaeb2b21f1b0ef9d867d60a32d453", "title": "A Survey on Temporal Sentence Grounding in Videos"}, {"paperId": "539fae1a82947625bc2de80f14b7603233dedab3", "title": "Zero-shot Natural Language Video Localization"}, {"paperId": "0a4e7b3b98c1eea83bf253cb0bcb99e19e31659b", "title": "TransRefer3D: Entity-and-Relation Aware Transformer for Fine-Grained 3D Visual Grounding"}, {"paperId": "cb56ea2d4de29481e25df6c318afc217eb7e4a7d", "title": "LanguageRefer: Spatial-Language Model for 3D Visual Grounding"}, {"paperId": "01b5412f3d17e90e09226d7c40ad4d4468a1414d", "title": "Multimodal Few-Shot Learning with Frozen Language Models"}, {"paperId": "b784b2023593af98692b1d2063b53eca897512cd", "title": "SAT: 2D Semantics Assisted Training for 3D Visual Grounding"}, {"paperId": "5f1913828e30c3070f32c154d2d142ec17e91189", "title": "Text-Guided Graph Neural Networks for Referring 3D Instance Segmentation"}, {"paperId": "4935b3a6d4e01e7965faf66ba489fd7772d624fe", "title": "Dense Events Grounding in Video"}, {"paperId": "d2d7573cacc1881d858b413d95b33e2421b09308", "title": "Video Corpus Moment Retrieval with Contrastive Learning"}, {"paperId": "42ff662af5f1ebb2921af9e1105027fa19f2b573", "title": "Computer-Aided Design as Language"}, {"paperId": "7ba9c013988eaff5cd186d73704af329d027872d", "title": "MDETR - Modulated Detection for End-to-End Multi-Modal Understanding"}, {"paperId": "c2cf5e5f21cca7045be719afce6bf66cc2934370", "title": "Group-Free 3D Object Detection via Transformers"}, {"paperId": "27ed05b1354ebc2451653a5356702f8260c7f97b", "title": "Free-form Description Guided 3D Visual Graph Network for Object Grounding in Point Cloud"}, {"paperId": "d5dd3b6c662e836499b14d95428645cac40320ba", "title": "Refer-it-in-RGBD: A Bottom-up Approach for 3D Visual Grounding in RGBD Images"}, {"paperId": "249c069b1a25d0c49b3646efb132426dea80a312", "title": "InstanceRefer: Cooperative Holistic Understanding for Visual Grounding on Point Clouds through Instance Multi-level Contextual Referring"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "f8a0b3efd0068b0fb96f53ee11d58816610d6dc2", "title": "Continuous Trajectory Similarity Search for Online Outlier Detection"}, {"paperId": "53794499a3830c3ebb365ecc57f0e8c8a20a682d", "title": "ReferIt3D: Neural Listeners for Fine-Grained 3D Object Identification in Real-World Scenes"}, {"paperId": "9d8398d9c36d25ad1363d9a5dd922dbbfa7be3be", "title": "Referring Expression Comprehension: A Survey of Methods and Datasets"}, {"paperId": "ed77a2e787aa06308072f78c8b06265c0fa23d9e", "title": "EPNet: Enhancing Point Features with Image Semantics for 3D Object Detection"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "dafb602b6ab3166437e3a4833a6b233cd4601f8b", "title": "Detailed 2D-3D Joint Representation for Human-Object Interaction"}, {"paperId": "355403d7ce4b625307fd3ebb2beea269ecc15213", "title": "Dense Regression Network for Video Grounding"}, {"paperId": "9712cc6fc96f463842f9d41c565e3a8781bfba40", "title": "PointGroup: Dual-Set Point Grouping for 3D Instance Segmentation"}, {"paperId": "d846b06c98070ed1f9ffc4b5a10bd533640848ae", "title": "OccuSeg: Occupancy-Aware 3D Instance Segmentation"}, {"paperId": "ddb42aace56362ea9725a33815a64bb213d0329a", "title": "ImVoteNet: Boosting 3D Object Detection in Point Clouds With Image Votes"}, {"paperId": "0311ace1d499cadd1cc0c515a625d1d045f60d25", "title": "Deep Learning for 3D Point Clouds: A Survey"}, {"paperId": "6c161841cdb547f77930942e4ab46f4369751676", "title": "ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language"}, {"paperId": "8648f59b62dda3900d597e944abe8af51a18f665", "title": "PointPainting: Sequential Fusion for 3D Object Detection"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "9e08fff0a66020bc72bd48685f87d21d2ff78d66", "title": "Disentangling Monocular 3D Object Detection"}, {"paperId": "e60da8d3a79801a3ccbf1abcdd001bb6e001b267", "title": "Deep Hough Voting for 3D Object Detection in Point Clouds"}, {"paperId": "1954a5ef37030002574f1b000cc1192f3bd4cad1", "title": "4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks"}, {"paperId": "08a302f0bb8dc360ae3a0a20fa7b7555920380d4", "title": "Unified Visual-Semantic Embeddings: Bridging Vision and Language With Structured Meaning Representations"}, {"paperId": "c5a3711ac088d653d0c4bbd9ecdc6861e1afe093", "title": "Know What Your Neighbors Do: 3D Semantic Segmentation of Point Clouds"}, {"paperId": "dce916351ef589afa7a63452648dd8acba931e92", "title": "Panoptic Segmentation"}, {"paperId": "33998aff64ce51df8dee45989cdca4b6b1329ec4", "title": "Graph Attention Networks"}, {"paperId": "d734a8365f7dab731a698cf77a8588b44166b4b2", "title": "Exploring Spatial Context for 3D Semantic Segmentation of Point Clouds"}, {"paperId": "b3159fd22e19e24d7cde9d37b3e482b832d4fa58", "title": "Learning Representations and Generative Models for 3D Point Clouds"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "8674494bd7a076286b905912d26d47f7501c4046", "title": "PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"}, {"paperId": "6b7d6e6416343b2a122f8416e69059ce919026ef", "title": "Inductive Representation Learning on Large Graphs"}, {"paperId": "e52e37cd91366f07df1f98e88f87010f494dd16e", "title": "ScanNet: Richly-Annotated 3D Reconstructions of Indoor Scenes"}, {"paperId": "b8ecc8512ff231d6e90f7373584ef9d7e658dbd4", "title": "SceneNN: A Scene Meshes Dataset with aNNotations"}, {"paperId": "36eff562f65125511b5dfab68ce7f7a943c27478", "title": "Semi-Supervised Classification with Graph Convolutional Networks"}, {"paperId": "d821767b7c7315c69daa39fbb0f4a44426bfaf41", "title": "Monocular 3D Object Detection for Autonomous Driving"}, {"paperId": "9b686d76914befea66377ec79c1f9258d70ea7e3", "title": "ShapeNet: An Information-Rich 3D Model Repository"}, {"paperId": "dc0d60f6e8bb7a04ba8a77d51d10b6dba8117480", "title": "Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images"}, {"paperId": "2606e6a5759c030e259ebf3f4261b9c04a36a609", "title": "Generating Semantically Precise Scene Graphs from Textual Descriptions for Improved Image Retrieval"}, {"paperId": "ac3ee98020251797c2b401e1389461df88e52e62", "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"}, {"paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "title": "GloVe: Global Vectors for Word Representation"}, {"paperId": "7c8a51d04522496c43db68f2582efd45eaf59fea", "title": "3D ShapeNets: A deep representation for volumetric shapes"}, {"paperId": "723e52c0d0140df7a6e264f1042af89ce9277e6e", "title": "SUN3D: A Database of Big Spaces Reconstructed Using SfM and Object Labels"}, {"paperId": "00f2a152454db273b0d6831b6550beb37a135890", "title": "Scene Coordinate Regression Forests for Camera Relocalization in RGB-D Images"}, {"paperId": "5eb4c55740165defacf08329beaae5314d7fbfe6", "title": "A benchmark for the evaluation of RGB-D SLAM systems"}, {"paperId": "c1994ba5946456fc70948c549daf62363f13fa2d", "title": "Indoor Segmentation and Support Inference from RGBD Images"}, {"paperId": "e859a2d07dcbd16de8d1cdff58ae9cf4966d9688", "title": "Tree-Based Mining for Discovering Patterns of Human Interaction in Meetings"}, {"paperId": "159d316a33f6a25d783f74b2c9e0259b1e9a4605", "title": "Nonthreshold-Based Event Detection for 3D Environment Monitoring in Sensor Networks"}, {"paperId": "e971fc79616d43779247c17add209ee3490b27a7", "title": "A human-computer interactive method for projected clustering"}, {"paperId": "961bd958f22af7deae72e9cf9221def1f5f0dcd4", "title": "Feature Space Trajectory Methods for Active Computer Vision"}, {"paperId": "15a0b5ad64ef55d566213e9af57452651b6e5c6f", "title": "Vision for Mobile Robot Navigation: A Survey"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "77e2d0202e652dcbc0fbb7fb580fd7f27959859a", "title": "Cross-Modality Knowledge Calibration Network for Video Corpus Moment Retrieval"}, {"paperId": null, "title": "\u201cTowards clip-driven language-free 3d visual grounding via 2d-3d relational enhancement and consistency,\u201d"}, {"paperId": "1958f40f37e6d2876570ae7fd0be50ba9e94a0c5", "title": "Exploiting Contextual Objects and Relations for 3D Visual Grounding"}, {"paperId": "b706b230a912785a2ab16307ce3b61842d9c0e90", "title": "Video Corpus Moment Retrieval via Deformable Multigranularity Feature Fusion and Adversarial Training"}, {"paperId": "0efeef4c187059f9b676452482f2ba31c735b546", "title": "ARKitSceneRefer: Text-based Localization of Small Objects in Diverse Real-World 3D Indoor Scenes"}, {"paperId": "d929d1d5dcce662891fa26d1554d7e6a7422c7d9", "title": "Cross3DVG: Baseline and Dataset for Cross-Dataset 3D Visual Grounding on Different RGB-D Scans"}, {"paperId": "7637ed79d30d0139901175ae4abedd822c217ab4", "title": "3D-LLM: Injecting the 3D World into Large Language Models"}, {"paperId": "e1590861002466864a6a5bf51ee8657222d078ff", "title": "HAM: Hierarchical Attention Model with High Performance for 3D Visual Grounding"}, {"paperId": null, "title": "\u201cLinking points with labels in 3d: A review of point cloud semantic segmentation,\u201d"}, {"paperId": "81a4fd3004df0eb05d6c1cef96ad33d5407820df", "title": "A Comprehensive Survey on Graph Neural Networks"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "\u201cPigraphs: learning interaction snapshots from observations,\u201d"}, {"paperId": null, "title": "JOURNAL OF L"}, {"paperId": "aa2cc7322d5fee4164da6ae4d796bd88692de51c", "title": "Semi-Supervised Classification"}, {"paperId": null, "title": "\u201cDora: 3d visual grounding with order-aware referring,\u201d"}, {"paperId": null, "title": "\u201cTranscribe3d: Grounding llms using transcribed information for 3d referential reasoning with self-corrected finetuning,\u201d"}, {"paperId": "2f91ae9e841953814c188a213f362de3d33d3a5e", "title": "G 3 -LQ: Marrying Hyperbolic Alignment with Explicit Semantic-Geometric Modeling for 3D Visual Grounding"}, {"paperId": null, "title": "\u201cCross-task knowledge transfer for semi-supervised joint 3d grounding and captioning,\u201d"}, {"paperId": null, "title": "\u201c3d-grand: Towards better grounding and less hallucination for 3d-llms,\u201d"}]}