{"paperId": "d9d8aef662bb7a3730a62b1015c3ed99e4287523", "abstract": "Despite the general capabilities of pre-trained large language models (LLMs), they still need further adaptation to better serve practical applications. In this paper, we demonstrate the interchangeability of three popular and distinct adaptation tools: parameter updating, reward modeling, and in-context prompting. This interchangeability establishes a triangular framework with six transformation directions, each of which facilitates a variety of applications. Our work offers a holistic view that unifies numerous existing studies and suggests potential research directions. We envision our work as a useful roadmap for future research on LLMs.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper demonstrates the interchangeability of three popular and distinct adaptation tools: parameter updating, reward modeling, and in-context prompting, which establishes a triangular framework with six transformation directions, each of which facilitates a variety of applications."}, "embedding": {"model": "specter_v2", "vector": [0.2654094994068146, 0.6067543029785156, -0.547150194644928, -0.1582498848438263, -0.45835548639297485, -0.2970567047595978, 0.6821678876876831, -0.15879344940185547, -0.7262074947357178, -0.17104746401309967, 0.49594050645828247, 0.025901664048433304, 0.3868151903152466, 0.5834061503410339, -0.36110004782676697, 0.12803296744823456, -0.9508115649223328, 0.3301670253276825, -0.09626401215791702, -0.31095290184020996, -0.4107348620891571, -0.5961913466453552, -0.5199670791625977, -0.2739730179309845, 0.2028142660856247, 0.352061003446579, 0.4102928936481476, 0.8908097743988037, -0.25301626324653625, 0.047024648636579514, 0.5204477906227112, -0.3025541305541992, 0.4734637439250946, -0.1405872404575348, 0.08780070394277573, -0.04128599911928177, 0.2579915225505829, -0.6629795432090759, -0.33711105585098267, 0.8153011202812195, -0.3362739682197571, 0.2498255968093872, 0.36987608671188354, -0.4933094382286072, -0.5148465037345886, 0.8838724493980408, 0.6065210103988647, 0.9268075823783875, -0.00711365882307291, -0.4333648979663849, 1.5094627141952515, -1.3553367853164673, 0.34595441818237305, 1.505896806716919, 0.3291005492210388, 0.3578029274940491, -0.24546873569488525, -0.5247939825057983, 1.2888845205307007, -0.22715714573860168, -0.4448912739753723, -0.36761415004730225, 0.20617690682411194, -0.04292699694633484, 1.7155355215072632, -0.19742412865161896, 0.06487869471311569, 0.8356305956840515, -0.32475361227989197, 1.4000632762908936, -0.4575604796409607, -1.1084398031234741, -0.31601473689079285, 0.4384339153766632, 0.30360037088394165, 0.45418545603752136, -0.5747620463371277, 0.724877655506134, -0.8821443319320679, -0.26890718936920166, 0.7360200881958008, -0.49594801664352417, -0.05483769625425339, -0.07482343912124634, -0.42232751846313477, 0.8690997362136841, 0.12355966866016388, 0.9506548047065735, -0.07693761587142944, 0.740699052810669, 0.33523139357566833, 0.5302160978317261, 0.4757976830005646, 0.45373350381851196, -0.5130010843276978, 0.11094044893980026, -0.559235692024231, 0.13013769686222076, -0.11027036607265472, 0.7957366704940796, -0.5279679894447327, 0.17966368794441223, -0.8400999903678894, 0.820820689201355, 1.784978985786438, 0.08402672410011292, 0.6275509595870972, -0.7751272320747375, 0.4361015856266022, -0.92911696434021, 0.6554127335548401, -0.5917927622795105, -0.3423316478729248, -0.19397062063217163, -0.23411864042282104, -1.593531847000122, -0.31956273317337036, 0.22850486636161804, -0.24924099445343018, 1.3447813987731934, -0.05636635422706604, -0.1134038195014, -0.02785690873861313, 0.31124138832092285, 0.23742219805717468, 0.7494743466377258, 0.665422260761261, -0.3911222517490387, 0.5460560917854309, -0.833616316318512, -0.6247574687004089, -1.1869136095046997, 0.8744865655899048, -0.19190232455730438, 0.6550877094268799, -0.4003923237323761, -1.1294002532958984, -0.8267314434051514, -0.9608056545257568, -0.05402107909321785, -0.1381247341632843, 0.3429849445819855, 0.9306591749191284, 0.3660433888435364, -1.127416968345642, 0.6882904767990112, -0.2340659648180008, -0.4618702530860901, -0.16370020806789398, 0.02383526787161827, 0.22784018516540527, -0.285819411277771, -1.3078707456588745, 0.29161712527275085, 0.2834882438182831, -0.3502536714076996, 0.08536584675312042, -0.4160945415496826, -1.075077772140503, -0.152673602104187, 0.17555248737335205, -0.5798541307449341, 1.9006927013397217, -0.7997294664382935, -1.9817609786987305, 0.36118650436401367, 0.006565937772393227, 0.24968646466732025, 0.14802826941013336, -0.25351935625076294, -0.9256644248962402, -0.4137305021286011, -0.45518818497657776, 0.8320561051368713, 0.290380597114563, -0.1619647592306137, -0.41639238595962524, 0.06869488209486008, -0.1472431868314743, 0.31752681732177734, -0.4210602641105652, 0.9990235567092896, -0.4234665334224701, -0.1982729583978653, 0.29008543491363525, 0.7672615051269531, -0.30370548367500305, -0.23017123341560364, -0.08406605571508408, -1.1334284543991089, 0.6012323498725891, -0.1738133281469345, 1.110404372215271, -0.8093795776367188, -0.8107229471206665, 0.07991120964288712, -0.4868479371070862, -0.26487812399864197, -1.2632031440734863, 0.37722209095954895, -0.2764693796634674, 0.1352754831314087, -0.18261682987213135, -1.2035115957260132, 0.04822619631886482, -0.22238567471504211, -0.4485822021961212, -0.2608591616153717, 0.20428724586963654, 0.9606346487998962, -1.2852143049240112, 0.1508406549692154, -0.3560229241847992, -3.1958847102941945e-05, -1.0061142444610596, 1.2566696405410767, -0.4024428725242615, 0.5438279509544373, 0.0611606128513813, -0.22995682060718536, -0.2753313183784485, 0.0031561756040900946, 0.325244277715683, -0.18201054632663727, -0.11309601366519928, 0.26454371213912964, -0.34691447019577026, 1.3199797868728638, -0.3202759921550751, 0.40969318151474, -0.012166528962552547, -0.364880234003067, 0.05508784204721451, 0.640849769115448, -0.18131721019744873, -0.7288690209388733, 0.3324812054634094, 0.6087373495101929, -0.6312374472618103, 0.40702587366104126, 0.874470591545105, 0.7810465693473816, -0.4343990981578827, 0.20208114385604858, 0.4520314037799835, -0.19909271597862244, 0.5190017819404602, 0.23514819145202637, 0.24686378240585327, 0.45025816559791565, 0.6740873456001282, 0.11173750460147858, 0.23704290390014648, -0.9925358891487122, -0.05045223608613014, 0.47536125779151917, 0.5296510457992554, 0.5752356648445129, 0.21831050515174866, -0.45525556802749634, -0.14092710614204407, -0.0043005384504795074, 0.4472540616989136, 1.7265853881835938, -0.6399264931678772, 0.3274308145046234, -0.6980570554733276, -0.28539183735847473, -0.23979511857032776, 0.4742544889450073, -0.42582443356513977, -0.18712377548217773, -0.5808553099632263, -1.025741696357727, 0.5221053957939148, 0.22359873354434967, 0.4629071354866028, -0.6479110717773438, 0.10156126320362091, 0.30366250872612, 0.2599380612373352, -0.7223168611526489, -1.0456180572509766, 0.1591205894947052, -0.831262469291687, -0.11672269552946091, -0.15285202860832214, 0.034632109105587006, 0.1252882331609726, -0.790401041507721, 0.7524225115776062, -0.6873178482055664, 0.3124409317970276, 0.587495744228363, 0.5005729794502258, -0.5412018895149231, -1.2138936519622803, 0.09489152580499649, 0.32356521487236023, -0.10287944972515106, 0.05421719327569008, 0.6398943662643433, 0.2689908444881439, -0.019546765834093094, -0.3941456973552704, 0.08551816642284393, -0.09284152835607529, -0.11067983508110046, 0.895571231842041, -1.1075575351715088, 0.6257539987564087, -1.5310629606246948, 1.2914997339248657, -0.188345268368721, -0.8017445802688599, 0.3189253807067871, -0.9765130281448364, -0.44754576683044434, 0.4324537217617035, -0.7456912994384766, -0.5549992322921753, -0.6432214379310608, 0.17483389377593994, 0.18978197872638702, -0.23120860755443573, 0.2528972327709198, 0.4000493288040161, 0.3925321698188782, 0.30264899134635925, 0.05359414592385292, -0.048064880073070526, -0.42578813433647156, 0.9015708565711975, -0.49919044971466064, 0.6247113347053528, 0.08507278561592102, 0.14680837094783783, -0.6748272180557251, -0.5462570786476135, -0.45765581727027893, -0.3581295907497406, -0.3382766842842102, -0.299826979637146, -0.37345659732818604, -0.31001296639442444, -0.5232225656509399, -0.11580590903759003, 0.04026515781879425, -1.0996612310409546, -0.3596513271331787, -0.03676188364624977, -0.12281757593154907, -0.23955728113651276, -0.8177237510681152, -1.0853646993637085, -0.28664958477020264, -0.5492889285087585, -0.8068171739578247, 0.23293673992156982, 0.20482277870178223, -0.3852987587451935, -0.6745986342430115, 0.6178480982780457, -0.5381477475166321, 1.086694359779358, -1.0910459756851196, 1.042629599571228, -0.049657367169857025, 0.26983892917633057, -0.2871004641056061, 0.4463091492652893, 0.47177547216415405, -0.08321569859981537, 0.41210994124412537, -1.0323771238327026, 0.22245067358016968, -0.5444063544273376, -0.17024880647659302, -0.32109296321868896, 0.28342384099960327, 0.49608489871025085, -0.01310546975582838, -0.4261224567890167, 0.40938800573349, 0.8845446705818176, -0.383971631526947, -0.3370622992515564, 0.21391984820365906, 0.6495527029037476, 0.019150162115693092, 0.010587292723357677, 0.5744602680206299, 0.4436558187007904, 0.8466999530792236, 0.01224344503134489, -0.10917173326015472, -0.0031732425559312105, -0.7421240210533142, 0.7502313256263733, 1.935248613357544, 0.38997647166252136, -0.041994113475084305, -0.7225489020347595, 0.18614758551120758, -1.2964497804641724, -0.2781558930873871, 0.6428263783454895, 1.0745843648910522, 0.9313399195671082, -0.7525803446769714, -0.06641443818807602, -0.5525718331336975, 0.12223049998283386, 0.3144512176513672, -0.4827416241168976, -0.879266619682312, -0.011043906211853027, -0.20556767284870148, -0.14825350046157837, 0.9796827435493469, -0.2914717197418213, 0.9415149688720703, 14.745550155639648, 0.335193932056427, 0.12189135700464249, 0.7707913517951965, 0.8252107501029968, 0.2016981989145279, -0.588683009147644, -0.3107609152793884, -1.0578498840332031, -0.11520793288946152, 1.5518910884857178, 0.3122958838939667, 0.9125563502311707, 0.1574825495481491, 0.4412277340888977, -0.002631966955959797, -0.7745488286018372, 0.7274703979492188, 0.4453457295894623, -0.7690691351890564, 0.3371575176715851, -0.23181423544883728, 0.5837062001228333, 0.852565586566925, 0.6378995776176453, 0.9463426470756531, 0.5739285349845886, 0.1657145768404007, 0.6558806300163269, 0.32385456562042236, 0.934508204460144, 0.1700795739889145, 0.08444490283727646, 0.4165665805339813, -0.6034327745437622, -0.2752925753593445, -0.5040813088417053, -0.9049895405769348, 0.1127677708864212, -0.057642966508865356, -0.527826726436615, -0.7352568507194519, -0.25273868441581726, 0.7305881977081299, -0.2848193347454071, 0.3295776844024658, -0.3608283996582031, 1.0692927837371826, -0.3749149739742279, 0.24893063306808472, 0.06386107206344604, 0.15221725404262543, 0.3889005184173584, 0.13893218338489532, 0.16237464547157288, -0.024206088855862617, -0.07513321191072464, 0.3908925950527191, -0.6101179122924805, 0.28796929121017456, -0.17268066108226776, -0.13480061292648315, 0.2668938934803009, 0.6089968681335449, 0.6909253001213074, 0.11402519792318344, -0.3719162940979004, 0.41088059544563293, 0.7237714529037476, 0.6854596138000488, -0.13827259838581085, 0.45687544345855713, 0.3748430609703064, -0.7157283425331116, -0.48193439841270447, 0.5625305771827698, -0.013618062250316143, -0.4411206543445587, -0.6543633341789246, -0.2581069767475128, 0.258311003446579, -0.8182698488235474, -0.966594934463501, 0.6374380588531494, 0.02046528458595276, -0.3477085530757904, -0.009210803546011448, -0.43371009826660156, -0.20551636815071106, 0.1827004998922348, -1.6595267057418823, -0.3746834397315979, 0.5482141971588135, -0.1711999922990799, -0.3876848816871643, -0.039753492921590805, 1.3391438722610474, 0.20640330016613007, -0.9092215299606323, 0.552741289138794, 0.7814502120018005, -0.4749251902103424, 0.2141333967447281, -0.5561676025390625, 0.8434618711471558, 0.18636085093021393, 0.13562613725662231, 0.06311187893152237, -0.17835566401481628, 0.31150901317596436, -0.5786101222038269, -0.005775840487331152, 0.8646347522735596, -0.8964661359786987, -0.2551455795764923, -0.3096047639846802, -0.7091953158378601, 0.5095157027244568, 0.5198178291320801, -0.17661064863204956, 0.41248390078544617, 0.3590388894081116, -0.575335681438446, -0.21253125369548798, -0.5693746209144592, 0.135321706533432, 0.4629748463630676, -0.40386271476745605, -0.08896578848361969, 0.15277808904647827, 0.5929392576217651, -1.1150964498519897, -0.42501160502433777, -0.5052003860473633, -0.3514443337917328, 0.4810769557952881, 0.8547946810722351, -0.6496034860610962, -0.10633508116006851, 0.8148748874664307, -0.10833489894866943, -1.1100311279296875, -0.3036574125289917, -1.0036489963531494, 0.08328483253717422, 0.26656779646873474, 1.092063069343567, -0.7131875157356262, -0.2926345467567444, 1.0926587581634521, 0.013833350501954556, -0.26568394899368286, -1.027492642402649, -0.199537992477417, 0.06738723814487457, -0.6541900038719177, 0.5097061991691589, -0.25370004773139954, -0.10457421094179153, 0.1064973995089531, 0.4869990646839142, 0.583899199962616, -0.4130474328994751, -1.098767638206482, 0.31485697627067566, -0.2307094931602478, -0.304324746131897, -0.6262049078941345, 0.017302220687270164, -1.3922361135482788, -0.26963987946510315, -1.205018401145935, 0.17261575162410736, -0.811502993106842, -0.34720367193222046, -0.13979382812976837, -0.6024496555328369, 0.1180131584405899, 0.15728458762168884, -0.8097168207168579, -0.20173956453800201, -0.11243629455566406, -0.6572009325027466, 1.110618233680725, 0.8074392080307007, -0.4135495126247406, -0.2399916797876358, 0.15346172451972961, 0.16911248862743378, 0.2893412709236145, 0.6181437373161316, -0.5770829916000366, -0.7737958431243896, -1.5561940670013428, 0.4565471112728119, -0.06040825694799423, -0.23696644604206085, -0.37759193778038025, 0.29899606108665466, 0.044990699738264084, -0.16043810546398163, 0.49060019850730896, 0.17888253927230835, -1.1099823713302612, -0.47747278213500977, 0.046309951692819595, -0.86606365442276, 0.4631831645965576, 0.3404580354690552, -0.22396497428417206, -0.2517092227935791, 0.4079788327217102, -0.004789556376636028, -0.695750892162323, -0.756686806678772, 0.45699355006217957, -0.47555673122406006, 0.13766852021217346, -0.3304245173931122, -0.057018257677555084, -1.0153589248657227, -0.31375446915626526, 0.2211475819349289, 0.21423619985580444, -0.44654542207717896, 0.9593848586082458, 0.10147523880004883, -1.296104907989502, 0.06398938596248627, 0.4451039433479309, 0.10624958574771881, -0.1533297300338745, 0.27637654542922974, 0.34246373176574707, -0.06193595752120018, 0.6579625010490417, 0.45534995198249817, 0.34876158833503723, -0.7488019466400146, -0.4969485402107239, 0.8165216445922852, -0.7287634611129761, 0.019270701333880424, 1.2979811429977417, -0.3370015025138855, -1.3360373973846436, 0.232992023229599, -1.3242226839065552, -0.6523860096931458, -0.5171297192573547, 0.39891940355300903, 0.04840632900595665, -0.25015872716903687, 0.13242192566394806, -0.020477568730711937, 0.04588942602276802, -0.23764440417289734, -0.7384935617446899, 0.4139746427536011, -0.4885857105255127, -0.15932828187942505, 0.69008868932724, 0.5682012438774109, -0.6330850124359131, -1.251412034034729, -0.8808569312095642, -0.13528619706630707, 0.03558935970067978, 0.4128521680831909, -0.7691563367843628, -0.6356104612350464, 0.2869393527507782, 0.9495075941085815, -0.2914717495441437, -0.01789742149412632, 0.11605750024318695, -0.06558658182621002, 0.6257160305976868, 0.1498469114303589, -1.0560450553894043, -0.6543593406677246, 1.2835664749145508, 1.595042109489441, -1.1712628602981567, 0.08147706836462021, 0.1559371054172516, -0.6075437068939209, 0.8442978262901306, 0.501473605632782, 0.22895671427249908, 0.7518469095230103, -0.5527712106704712, 0.3341595232486725, 0.2561393082141876, -0.9209357500076294, 0.2981680929660797, 0.7518414855003357, 1.0673688650131226, 0.9584144949913025, 0.6519736051559448, 0.03521360084414482, 1.3372690677642822, 0.26402410864830017, 0.3531171381473541, 0.5466983318328857, 0.2815946042537689, -0.4120806157588959, -0.4691564440727234, -0.043582454323768616, 0.676061749458313, -0.07185101509094238, -0.7465884685516357, 0.020564915612339973, 0.7329186201095581, -0.04810173064470291, 0.4262492060661316, 0.6007257699966431, 0.38244402408599854, 0.767253041267395, 0.36619484424591064, 0.37783339619636536, -0.7202243804931641, -0.3422406017780304, -0.19165021181106567, -0.49056270718574524, -0.10406797379255295, 0.15859313309192657, -0.8266026973724365, -0.18353821337223053, 0.5825961828231812, 0.2238885909318924, -0.1895085722208023, 0.2778640687465668, 0.8740483522415161, 0.6380541920661926, 0.12703081965446472, -0.11518888175487518, -0.33284592628479004, -0.6646853089332581, -1.4035176038742065, -0.0001446580863557756, -0.684285581111908, -0.47954806685447693, -0.09825696051120758, -0.04989832639694214, -0.40445342659950256]}, "authors": [{"authorId": "2286236795", "name": "Deng Cai"}, {"authorId": "91956362", "name": "Huayang Li"}, {"authorId": "2156525869", "name": "Tingchen Fu"}, {"authorId": "2308126336", "name": "Siheng Li"}, {"authorId": "2218345185", "name": "Weiwen Xu"}, {"authorId": "2308037430", "name": "Shuaiyi Li"}, {"authorId": "2209367631", "name": "Bowen Cao"}, {"authorId": "2276313856", "name": "Zhisong Zhang"}, {"authorId": "14799547", "name": "Xinting Huang"}, {"authorId": "2279792419", "name": "Leyang Cui"}, {"authorId": "2286699222", "name": "Yan Wang"}, {"authorId": "2273767663", "name": "Lemao Liu"}, {"authorId": "2258911007", "name": "Taro Watanabe"}, {"authorId": "2257446263", "name": "Shuming Shi"}], "references": [{"paperId": "2d77b7203824e617206634277bce7eec2b71a2bd", "title": "Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"}, {"paperId": "53a803388e83ae89261624099d7be4287ace67cb", "title": "DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model"}, {"paperId": "8ba5d42e303b429ad3f160e2eb035635a0b18dbe", "title": "WildChat: 1M ChatGPT Interaction Logs in the Wild"}, {"paperId": "abdceff7d7983cdede9a5aabe6a476d4c72e41a3", "title": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"}, {"paperId": "d8b51d518f2dd62943762ceaa8961d3b1bfbcc1a", "title": "RULER: What's the Real Context Size of Your Long-Context Language Models?"}, {"paperId": "7709a9eefa9a67510111aef2877f2834a76c8829", "title": "Curry-DPO: Enhancing Alignment using Curriculum Learning & Ranked Preferences"}, {"paperId": "914d93e9b0d5a035f5cee473bd1e7d3fb6407e8c", "title": "Proxy-RLHF: Decoupling Generation and Alignment in Large Language Model with Proxy"}, {"paperId": "6fe7e6ce3cc0ebd038caa456d73fd7472e7d6c38", "title": "Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment"}, {"paperId": "02ca7c0a9938e7f5a6e2c8b4df8a92c5bdbc283c", "title": "Distillation Contrastive Decoding: Improving LLMs Reasoning with Contrastive Decoding and Distillation"}, {"paperId": "c3f079f9f59f255e032a1239aea02a2affe93be8", "title": "ROSE Doesn't Do That: Boosting the Safety of Instruction-Tuned Large Language Models with Reverse Prompt Contrastive Decoding"}, {"paperId": "de6ddb30b07f192f2be142062c4c6c817e508d96", "title": "Direct Large Language Model Alignment Through Self-Rewarding Contrastive Prompt Distillation"}, {"paperId": "89bc7f4df87ef36f28d048a8a9b8a7c1ac95b909", "title": "RLVF: Learning from Verbal Feedback without Overgeneralization"}, {"paperId": "0e8176ecced2a01ca3c7dc31e8a3f72d0a7d3767", "title": "Generative Representational Instruction Tuning"}, {"paperId": "9637ef9019671034912ea0f506ae67c3f2fc4689", "title": "Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment"}, {"paperId": "42ee90ce864f1cb2a865f554fc3c6531d0ea34d3", "title": "ODIN: Disentangled Reward Mitigates Hacking in RLHF"}, {"paperId": "4fe4f0f9d39d708a6c3d7b8dfbfa2616cd376e1e", "title": "V-STaR: Training Verifiers for Self-Taught Reasoners"}, {"paperId": "37a00c43bd1099a8bdef978ab0aa6d2566cefad0", "title": "Noise Contrastive Alignment of Language Models with Explicit Rewards"}, {"paperId": "44162aa2763c88a384d9c51d60eafcc59277a1c9", "title": "Decoding-time Realignment of Language Models"}, {"paperId": "c0d8e5ee66c279299012cc3b8d0519011b3f4998", "title": "KTO: Model Alignment as Prospect Theoretic Optimization"}, {"paperId": "f977dac98cc603bfccae6ea991cf4b1f83bf139c", "title": "LiPO: Listwise Preference Optimization through Learning-to-Rank"}, {"paperId": "be9f699c4bfa0f29c9a0a920a6310ec70f5580e6", "title": "Tradeoffs Between Alignment and Helpfulness in Language Models"}, {"paperId": "67f03ac399693393116076c0b8ec8ea05b910685", "title": "WARM: On the Benefits of Weight Averaged Reward Models"}, {"paperId": "67eab08db30e397e400e3b36b3afd7526df83314", "title": "Linear Alignment: A Closed-form Solution for Aligning Human Preferences without Tuning and Feedback"}, {"paperId": "5215a3cfd67fdc6eb0201822dd0004bd4b830f91", "title": "With Greater Text Comes Greater Necessity: Inference-Time Training Helps Long Text Generation"}, {"paperId": "7ca300c16abbd38382dec5b7ea6809fee570be54", "title": "ReFT: Reasoning with Reinforced Fine-Tuning"}, {"paperId": "ebd1c04c61f73f46def3305ca11d038c46665b65", "title": "Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation"}, {"paperId": "8dce168f723158b771b526401113064c36fc875e", "title": "State of What Art? A Call for Multi-Prompt LLM Evaluation"}, {"paperId": "3f915aab835cbfe69e7b2ea1c73b74ac8a2d384e", "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations"}, {"paperId": "485f8a429cf5f70c558181187f2d62e31784deaa", "title": "Reasons to Reject? Aligning Language Models with Judgments"}, {"paperId": "15b8b6a8028b2b6e75b67dfb6aebaede36826cf8", "title": "Language Model Alignment with Elastic Reset"}, {"paperId": "600d9287efc4703bdb99ce39b5e8b37da0baa6f6", "title": "The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning"}, {"paperId": "328eb183007bf4aefbf42437b42a15db375803e3", "title": "Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding"}, {"paperId": "0f9995ec08e95bea09d512c59e40d19f0f44d7bb", "title": "Data-Efficient Alignment of Large Language Models with Human Feedback Through Natural Language"}, {"paperId": "37680e5cb6030e01f1a44a5abe2257972196ae26", "title": "Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2"}, {"paperId": "a1cbe3e24cdcb49541ef5da4f82d9ebc45bb6261", "title": "StrategyLLM: Large Language Models as Strategy Generators, Executors, Optimizers, and Evaluators for Problem Solving"}, {"paperId": "6b631c1a7f24f8500e714ef3d89963ac62aca64b", "title": "Let's Reinforce Step by Step"}, {"paperId": "4411e6b32865933cab87696c2738cb7a204e4240", "title": "Implicit Chain of Thought Reasoning via Knowledge Distillation"}, {"paperId": "1eb1a8c7f88de27af224153f43ecdd41774600f2", "title": "PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization"}, {"paperId": "cdcf3f36866ef1e16eba26d57c2324362247ba84", "title": "Zephyr: Direct Distillation of LM Alignment"}, {"paperId": "f1019fe7918ee51cf16c91186e769a71a9d9fb42", "title": "An Emulator for Fine-Tuning Large Language Models using Small Language Models"}, {"paperId": "f3460dc3ae5cfd41099d576a3bb77411e1fc2e3f", "title": "A General Theoretical Paradigm to Understand Learning from Human Preferences"}, {"paperId": "17a6116e5bbd8b87082cbb2e795885567300c483", "title": "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting"}, {"paperId": "44b506d9619b5f957dc2b5588801138f343c0308", "title": "Let's reward step by step: Step-Level reward model as the Navigators for Reasoning"}, {"paperId": "94a5f96308729e31c1ffbc0f0618db87795092fe", "title": "SWE-bench: Can Language Models Resolve Real-World GitHub Issues?"}, {"paperId": "abdb0f9d1486dbb024c4bc9f8f9dc40464c58715", "title": "Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning"}, {"paperId": "af7669dc48c70d8cf6fccdf1322d6056a6b39dc8", "title": "Confronting Reward Model Overoptimization with Constrained RLHF"}, {"paperId": "0e0e706e13f160e74cac9556f28ab9a358c148d2", "title": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!"}, {"paperId": "59a2203ef6ea159bb41540bd282e29e80a8ad579", "title": "A Long Way to Go: Investigating Length Correlations in RLHF"}, {"paperId": "023d462ec6ff84cee0d0716a34d11efc7cde8534", "title": "Reward Model Ensembles Help Mitigate Overoptimization"}, {"paperId": "7fe071ea76e49bc3e573beb53f07721630954247", "title": "Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution"}, {"paperId": "1671d70a135b1e28b3a9cbc830feaa9b0c57df32", "title": "Don't throw away your value model! Generating more preferable text with Value-Guided Monte-Carlo Tree Search decoding"}, {"paperId": "84a36e19f9394f22b34f79756fa9628a795e02ea", "title": "LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"}, {"paperId": "8d17234680db76f99efd22fbcb169f45d2d79d93", "title": "Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers"}, {"paperId": "22ab4219371366a4e890382bc0ca606130840ca7", "title": "Statistical Rejection Sampling Improves Preference Optimization"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "cb587eaea753ee38013afb7e5b6bc8fba1248d04", "title": "RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback"}, {"paperId": "e730164e17975547564a1eaa70cea5884b16c89d", "title": "AlpaGasus: Training A Better Alpaca with Fewer Data"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "b0bac6aca93021105c8a4f165184a097a249fbce", "title": "Evaluating the Zero-shot Robustness of Instruction-tuned Language Models"}, {"paperId": "a5d3a865b71f3f424ba31e037848028f60161478", "title": "Propagating Knowledge Updates to LMs Through Distillation"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "be8db99310602d66bba64bcf41a572c45816fbfc", "title": "Let's Verify Step by Step"}, {"paperId": "385c74957858e7d6856d48e72b5a902b4c1aa28c", "title": "Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate"}, {"paperId": "0d1c76d45afa012ded7ab741194baf142117c495", "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"}, {"paperId": "984d4a1d41bfc8184fb77b8aa0eb8e96d536d048", "title": "Trusting Your Evidence: Hallucinate Less with Context-aware Decoding"}, {"paperId": "4780d0a027c5c5a8e01d7cf697f6296880ffc945", "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate"}, {"paperId": "546d0624adfc6e18fb87d8cc77e7705bb9ea7445", "title": "LIMA: Less Is More for Alignment"}, {"paperId": "58af2d4fcca54c14334d1efd975554b4eb78cd4d", "title": "SLiC-HF: Sequence Likelihood Calibration with Human Feedback"}, {"paperId": "c76dd4a70361c3afd2e19d046343e2dedd16ecc3", "title": "Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search"}, {"paperId": "154493f69d7db3d49da0e51df0192c6ad5f1724a", "title": "Larger language models do in-context learning differently"}, {"paperId": "c5120b546f1bd99df5bd2e2bf44db5c7c46d1545", "title": "Pretraining Language Models with Human Preferences"}, {"paperId": "d2170504c4ad9403bea118ae8debdfda95978546", "title": "The Wisdom of Hindsight Makes Language Models Better Instruction Followers"}, {"paperId": "cb3125e4f63f3d058a2a39270ecb585e86c3d1ff", "title": "Chain of Hindsight Aligns Language Models with Feedback"}, {"paperId": "3b16a709a5b18e52b0b6741cbc3c0e68a03ecd8e", "title": "The unreasonable effectiveness of few-shot learning for machine translation"}, {"paperId": "8bf77f3f14d20b36a0a4b96693e0a6480f17aac1", "title": "HINT: Hypernetwork Instruction Tuning for Efficient Zero- and Few-Shot Generalisation"}, {"paperId": "ab2aa46bbe305627113499ee57958e2e1f55bc25", "title": "Toward Human Readable Prompt Tuning: Kubrick's The Shining is a good movie, and a good prompt too?"}, {"paperId": "525d93a382f6e7873b5d8a2e0713eb3dff7fb250", "title": "Transformers learn in-context by gradient descent"}, {"paperId": "3936fd3c6187f606c6e4e2e20b196dbc41cc4654", "title": "Constitutional AI: Harmlessness from AI Feedback"}, {"paperId": "d03a9b2a0e090cc9fd2ba0a457ecea35372f1018", "title": "Demystifying Prompts in Language Models via Perplexity Estimation"}, {"paperId": "37255b091317aedc6854383104b3343e67ab5c80", "title": "Robustness of Learning from Task Instructions"}, {"paperId": "7aa801b907b59b8ee4cfb1296d9dac22c5164c5d", "title": "What learning algorithm is in-context learning? Investigations with linear models"}, {"paperId": "6d7b8a478801bd9d21df82d5f33ae6eced90da5e", "title": "Solving math word problems with process- and outcome-based feedback"}, {"paperId": "e89ed6bb1864558e3889f5f2fb8931643c633479", "title": "Human-level play in the game of Diplomacy by combining language models with strategic reasoning"}, {"paperId": "4610ffb1b016acaa82a2065ffd1a3adbae1ce722", "title": "Large Language Models Are Human-Level Prompt Engineers"}, {"paperId": "88b62496cbc52072bfa8f4b29d172b0477b701bc", "title": "Contrastive Decoding: Open-ended Text Generation as Optimization"}, {"paperId": "3fa70115248377c3d1517c9f978791a296fbc1dd", "title": "Large Language Models Can Self-Improve"}, {"paperId": "fb3dc5e20e0a71134ca916f0d6d8d41f01225b4b", "title": "Scaling Laws for Reward Model Overoptimization"}, {"paperId": "29acc890e521f7a6415666ab9eb3432c49b4587a", "title": "Self-critiquing models for assisting human evaluators"}, {"paperId": "1c475acaa1060c8318a625f24bfd88c12f367516", "title": "Prompt Injection: Parameterization of Fixed Inputs"}, {"paperId": "023edab4738690444e3924e224c2641017a0d794", "title": "Quark: Controllable Text Generation with Reinforced Unlearning"}, {"paperId": "07759a84f27e43cfa5bc8d579f8227c96e6ae1dc", "title": "RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning"}, {"paperId": "5f19ae1135a9500940978104ec15a5b8751bc7d2", "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "3dc7dc1bea9a4f70c02b6759a0bda7aca0005a9e", "title": "A General Language Assistant as a Laboratory for Alignment"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "02f033482b8045c687316ef81ba7aaae9f0a2e1c", "title": "DExperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "240b0caabb415578bdea4da7d0a32bdff2e8163f", "title": "Editing Factual Knowledge in Language Models"}, {"paperId": "209f9bde2dee7cf1677801586562ffe56d435d38", "title": "Learning How to Ask: Querying LMs with Mixtures of Soft Prompts"}, {"paperId": "3447a432f724aa36595643446acda5b78943db19", "title": "Knowledge-Grounded Dialogue Generation with Pre-trained Language Models"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "58ed1fbaabe027345f7bb3a6312d41c5aac63e22", "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"}, {"paperId": "298a68153859303ee70b3ef1525ee9c7031e32f5", "title": "You Impress Me: Dialogue Generation via Mutual Persona Perception"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "41b3180745068934bd9f7f2fbc2efc00c64d534b", "title": "Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting"}, {"paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b", "title": "Proximal Policy Optimization Algorithms"}, {"paperId": "563783de03452683a9206e85fe6d661714436686", "title": "HyperNetworks"}, {"paperId": "1298dae5751fb06184f6b067d1503bde8037bdb7", "title": "Deep Reinforcement Learning for Dialogue Generation"}, {"paperId": "9f2a8e923965b23c11066a2ead79658208f1fae1", "title": "Minimum Risk Training for Neural Machine Translation"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "9b129513de0da471a204b953528c437e4a4c30ef", "title": "Advances in prospect theory: Cumulative representation of uncertainty"}, {"paperId": "4b8df079495cbec21ae90d60ab84e8dd813ca7e6", "title": "Leveraging Large Language Models for NLG Evaluation: A Survey"}, {"paperId": "459fb039bf6f322f84d3c5c53fab88106881a195", "title": "PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Preference Alignment"}, {"paperId": "a9d460f8eb9001b1bed11b7fb2af555185c70fcf", "title": "Do pretrained Transformers Really Learn In-context by Gradient Descent?"}, {"paperId": "4c8cc2383cec93bd9ea0758692f01b98a035215b", "title": "UltraFeedback: Boosting Language Models with High-quality Feedback"}, {"paperId": "d86ca0894cb4d165eb5ef45b73526ca8b4cdd725", "title": "Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": null, "title": "Au-toPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "2022. Defining and characterizing reward gaming"}, {"paperId": null, "title": "2023. Rlcd: Re-inforcement learning from contrast distillation for language model alignment"}, {"paperId": null, "title": "2022. Learning by distilling context"}, {"paperId": null, "title": "2023a. The trickle-down impact of reward inconsistency on rlhf"}, {"paperId": null, "title": "2023c. Gpt understands, too"}, {"paperId": null, "title": "2023. LLM-eval: Unified multi-dimensional automatic evaluation for open-domain conversations with large language models"}, {"paperId": null, "title": "2023. Mistral 7b"}, {"paperId": null, "title": "2023a. Generative judge for evaluating alignment"}, {"paperId": null, "title": "2022. Fast model editing at scale"}, {"paperId": null, "title": "OpenAI. 2022."}, {"paperId": null, "title": "2024. A systematic survey of prompt engineering in large language models: Techniques and applications"}, {"paperId": null, "title": "2024b. Beyond one-preference-for-all: Multi-objective direct preference optimization"}, {"paperId": null, "title": "2024. Gemma: Open models based on"}, {"paperId": null, "title": "2023a Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing"}, {"paperId": null, "title": "2023. Distort, distract, de-code: Instruction-tuned model can refine its response from noisy instructions"}, {"paperId": null, "title": "2023. DUnE: Dataset for unified editing"}, {"paperId": null, "title": "2024. Alignment as reward-guided search"}, {"paperId": null, "title": "2023b. Alpacaeval: An automatic evaluator of instruction-following models"}, {"paperId": null, "title": "2023b. TEMPERA: Test-time prompt editing via reinforcement learning"}, {"paperId": null, "title": "2023. Qwen technical"}, {"paperId": null, "title": "2023. Dola: Decoding by contrasting layers improves factuality in large language models"}, {"paperId": null, "title": "2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"}, {"paperId": null, "title": "2023c. Remax: A simple, effective, and efficient method for aligning large language models"}, {"paperId": null, "title": "2022. Lora: Low-rank adaptation of large language models"}]}