{"paperId": "86589b6286ef3c55b8b4fccfb41a3b30b7afdf61", "abstract": "Transformers with linearised attention (''linear Transformers'') have demonstrated the practical scalability and effectiveness of outer product-based Fast Weight Programmers (FWPs) from the '90s. However, the original FWP formulation is more general than the one of linear Transformers: a slow neural network (NN) continually reprograms the weights of a fast NN with arbitrary architecture. In existing linear Transformers, both NNs are feedforward and consist of a single layer. Here we explore new variations by adding recurrence to the slow and fast nets. We evaluate our novel recurrent FWPs (RFWPs) on two synthetic algorithmic tasks (code execution and sequential ListOps), Wikitext-103 language models, and on the Atari 2600 2D game environment. Our models exhibit properties of Transformers and RNNs. In the reinforcement learning setting, we report large improvements over LSTM in several Atari games. Our code is public.", "venue": "Neural Information Processing Systems", "year": 2021, "citationCount": 44, "influentialCitationCount": 2, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The novel recurrent FWPs (RFWPs) are evaluated on two synthetic algorithmic tasks (code execution and sequential ListOps), Wikitext-103 language models, and on the Atari 2600 2D game environment and report large improvements over LSTM in several Atari games."}, "embedding": {"model": "specter_v2", "vector": [0.22271732985973358, 0.8928284645080566, -0.20247144997119904, 0.3858911991119385, 0.11047971993684769, -0.3410413861274719, 0.7433141469955444, -0.11723221838474274, -0.48159661889076233, -0.5069810152053833, 0.46384093165397644, -0.3126011788845062, 0.28105372190475464, 0.04228540509939194, -0.30865201354026794, 0.13648518919944763, -0.9639522433280945, 0.2643105089664459, 0.21987690031528473, -0.42314544320106506, 0.4513903260231018, -0.6143850088119507, -1.1636738777160645, 0.23034267127513885, 0.27732333540916443, 0.1981242299079895, -0.09784998744726181, 0.9058473706245422, -0.610639750957489, 1.3730593919754028, 0.7284643650054932, -0.4038616418838501, 0.4152267575263977, 0.22338150441646576, -0.4260810613632202, -0.5065566897392273, 0.1696772575378418, -0.15838603675365448, -0.34180039167404175, 0.6473572254180908, -0.20997193455696106, -0.06424635648727417, -0.0009799841791391373, -0.6697630286216736, -0.20965610444545746, 1.2292585372924805, 0.1756177842617035, 0.6593999862670898, -0.06895984709262848, -0.12139543890953064, 1.313370704650879, -1.3583292961120605, 0.1134047582745552, 1.1897107362747192, 0.825901985168457, 0.3623274862766266, -0.24825815856456757, -0.7349303364753723, 1.1162586212158203, 0.00561622204259038, -0.7613385915756226, -0.1899428814649582, -0.20168422162532806, 0.06176362559199333, 1.8319236040115356, -0.55012446641922, 0.21269303560256958, 0.18924808502197266, 0.0603385791182518, 1.5168858766555786, -0.16812589764595032, -0.5912992358207703, -0.4961961507797241, 0.07614682614803314, 0.2227444052696228, 1.0724115371704102, -0.2155568152666092, 0.46987438201904297, -0.9471572041511536, 0.027176572009921074, 0.49767589569091797, 0.08978169411420822, -0.15181975066661835, -0.6434203386306763, 0.10770522803068161, 0.5878406763076782, 0.512775719165802, 0.7107993960380554, -0.46816325187683105, 1.125908374786377, 0.6429412364959717, 0.7577100396156311, 0.01843581721186638, 0.5906100273132324, 0.31705039739608765, -0.1068042442202568, -0.24347345530986786, 0.3598237931728363, -0.1986934095621109, 0.7541436553001404, -0.183279886841774, 0.329103022813797, -0.45429590344429016, 0.1264660507440567, 1.278876543045044, -0.10111630707979202, 0.639767587184906, -0.7501894235610962, 0.03129677474498749, -0.453005850315094, -0.012975511141121387, -0.3988369405269623, -0.2531534731388092, -0.47178226709365845, -0.5975514054298401, -0.6536089181900024, -0.2988375127315521, 0.3264404535293579, -0.6003189086914062, 0.6608066558837891, -0.5985159873962402, -0.006053974386304617, -0.046769361943006516, 0.490660697221756, 0.35843977332115173, 0.6331738829612732, 0.36659443378448486, 0.3122842311859131, 0.3282724916934967, -0.9243146181106567, -0.6043809652328491, -1.1452369689941406, 0.8433305025100708, 0.04913855344057083, 0.2517129182815552, 0.3298507630825043, -1.6000137329101562, -0.8623415231704712, -0.6655158400535583, 0.23240156471729279, -0.19721153378486633, -0.10582064837217331, 1.4425959587097168, 0.3369908928871155, -1.154791235923767, 0.9072071313858032, -0.2706183195114136, 0.14894530177116394, 0.27077311277389526, 0.5525943040847778, 0.37709271907806396, -0.3673064708709717, -0.8683863282203674, 0.38462260365486145, -0.006750498898327351, -0.3412773311138153, -0.16175630688667297, -0.9075668454170227, -1.0073505640029907, -0.048987582325935364, 0.5513689517974854, -0.24213118851184845, 1.7504644393920898, -0.25401756167411804, -1.4706037044525146, 0.6136675477027893, 0.21227312088012695, -0.10548575967550278, 0.20263159275054932, -0.4588174521923065, 0.022261716425418854, -0.5514045357704163, -0.2708096206188202, 0.23063233494758606, 0.4213373363018036, -0.18763013184070587, -0.4777243435382843, 0.3597412407398224, 0.15392467379570007, -0.076845683157444, -0.1987769901752472, 0.8581498861312866, -0.1320752650499344, 0.48810306191444397, -0.06798891723155975, 0.6188008189201355, 0.04415985941886902, -0.06662921607494354, 0.06597910076379776, -1.3154888153076172, 0.2857220768928528, 0.2924569845199585, 1.2448842525482178, -1.117724895477295, -0.19298730790615082, -0.1783842146396637, 0.5002663135528564, 0.07132112234830856, -0.75497967004776, 0.4340617060661316, -0.7038639783859253, 0.24504883587360382, -0.0348026342689991, -0.9516570568084717, 0.06243596598505974, -0.23941977322101593, -0.5292401909828186, -0.11255283653736115, 0.12427695095539093, 1.0092581510543823, -1.3963289260864258, -0.0036747781559824944, 0.09220650792121887, -0.08110300451517105, -1.0479735136032104, 1.6159825325012207, 0.025396324694156647, -0.5257200598716736, 0.16693833470344543, -0.7307270765304565, -0.18662938475608826, -0.24453990161418915, 0.5845239162445068, -0.24096447229385376, -0.5304602980613708, 0.7397089600563049, -0.4038061499595642, 1.1905781030654907, -0.6213048100471497, 0.4277670383453369, 0.10528495162725449, -0.5874655842781067, 0.06953143328428268, 0.29815858602523804, -0.3421344459056854, -0.6183369755744934, -0.1032140776515007, 0.24198326468467712, -0.17273597419261932, 0.15458160638809204, 0.6002495288848877, 0.5032212138175964, -0.47648146748542786, 0.4847089648246765, 0.5485036969184875, -0.36430808901786804, 0.44605785608291626, 0.5791677832603455, 1.0651657581329346, 0.6752572059631348, 0.4448474645614624, -0.012810119427740574, 0.3575984537601471, -0.7570183277130127, -0.029454628005623817, 0.5376641750335693, 0.787075936794281, 0.8425760269165039, 0.6954829692840576, -1.1003443002700806, -0.3629056215286255, -0.18600694835186005, 0.9812027215957642, 1.7729181051254272, -0.28049224615097046, -0.18439461290836334, -0.25558021664619446, -0.09736490249633789, -0.3469398617744446, 0.3444042205810547, -0.4715540111064911, -0.6312757730484009, -1.1115710735321045, -0.823193371295929, 0.7445539236068726, 0.34936848282814026, 0.8634697198867798, -0.6688786745071411, -0.5899709463119507, -0.2366238534450531, 0.6924958825111389, -0.21208514273166656, -0.7556555271148682, 0.6069318652153015, -0.24717025458812714, -0.23733030259609222, 0.18232114613056183, -0.03778112307190895, 0.15476003289222717, -0.28779980540275574, 0.9517339468002319, 0.006846069823950529, -0.2167290300130844, 0.1728471964597702, 0.6835513114929199, -0.5473167300224304, -0.6709607243537903, 0.4450037181377411, 0.15113301575183868, -0.2232072353363037, -0.03397654742002487, 0.4656371474266052, -0.07189778983592987, -0.11532147228717804, -0.28673145174980164, 0.40945082902908325, 0.36880820989608765, 0.03947382792830467, -0.18827860057353973, -0.4628083407878876, -0.10981274396181107, -1.5238311290740967, 1.2147585153579712, 0.366749107837677, -0.4215898811817169, 0.19121237099170685, -0.7807474732398987, 0.01300718355923891, 0.6672670841217041, -0.784740686416626, -0.12722137570381165, -1.1363903284072876, 0.3383742868900299, -0.17184025049209595, 0.3913045823574066, 0.06119958683848381, 0.7197945713996887, -0.1599157452583313, 0.1579320728778839, 0.41584140062332153, 0.5965819358825684, 0.2218698114156723, 0.4589575529098511, -0.9067464470863342, 0.5167064070701599, 0.014257305301725864, 0.563645601272583, -0.574831485748291, -0.41828498244285583, -0.09096484631299973, -0.6615605354309082, -0.07536131143569946, 0.3638990521430969, -0.5035936236381531, -0.14207778871059418, -0.46093738079071045, -1.4927475452423096, 0.1914626657962799, -1.0155798196792603, -0.7276420593261719, -0.20725350081920624, -0.6807906627655029, -0.09627886116504669, -1.083962321281433, -1.345532774925232, -0.9572898745536804, -0.6182378530502319, -0.8255873918533325, -0.022753842175006866, 0.140376478433609, -0.598180890083313, -0.309304416179657, 0.21563085913658142, -0.7876328825950623, 1.3399072885513306, -0.9741931557655334, 0.8628008365631104, 0.22621281445026398, -0.18334326148033142, -0.14691586792469025, 0.32661792635917664, 0.23809300363063812, -0.3333413600921631, 0.26846954226493835, -0.43964144587516785, 0.40807217359542847, -0.4761509299278259, -0.6939775347709656, -0.04539400711655617, -0.05487774685025215, 0.6881177425384521, 0.12092102319002151, -0.21523985266685486, 0.11771754175424576, 1.1398144960403442, -0.5743053555488586, 0.32340124249458313, 0.29197388887405396, 1.0599775314331055, 0.4231173098087311, -0.20534633100032806, 0.3211950957775116, 0.4866545498371124, 0.4290071725845337, 0.2999458312988281, -0.16912977397441864, -0.14696134626865387, -0.7403303384780884, 0.7545631527900696, 1.4084068536758423, -0.1622784286737442, 0.33751606941223145, -0.9140193462371826, 0.41546830534935, -1.4003186225891113, -0.9250978231430054, 0.5727232694625854, 0.90592360496521, 0.5525951385498047, 0.040623992681503296, -0.2060403823852539, -0.018104974180459976, 0.5108948349952698, 0.3379618227481842, -0.23463930189609528, -1.1566866636276245, 0.39327919483184814, 0.6535452604293823, 0.3838214874267578, 0.774276614189148, 0.2163328230381012, 0.7453336119651794, 14.80616569519043, 0.6111032366752625, 0.09195058047771454, 0.6155822277069092, 0.32427290081977844, -0.12197171151638031, -0.5120618939399719, -0.2195136547088623, -0.8609560132026672, -0.37721946835517883, 1.0727458000183105, -0.03388475999236107, 0.7945208549499512, -0.08643879741430283, -0.2403317093849182, 0.11654060333967209, -0.4237689673900604, 0.39866143465042114, 0.20109960436820984, -1.1423885822296143, 0.2325877547264099, 0.0464429035782814, -0.03736663982272148, 0.5776028633117676, 1.0942692756652832, 1.118680477142334, 1.0568069219589233, -0.31604036688804626, 0.7577487826347351, 0.351370245218277, 1.069703459739685, -0.21555858850479126, 0.43966013193130493, 0.46437057852745056, -0.9083309769630432, -0.5340240001678467, -0.29225513339042664, -1.5999600887298584, 0.0569767951965332, -0.29861143231391907, -0.09681518375873566, -0.7622120380401611, -0.3603076934814453, 0.813704252243042, 0.33257049322128296, 0.34630829095840454, -0.5604099035263062, 0.2757740318775177, -0.2603650987148285, -0.13807052373886108, 0.2461940199136734, 0.6036266088485718, -0.35049107670783997, -0.31887462735176086, -0.11746416985988617, 0.24344991147518158, -0.24601824581623077, 0.6251355409622192, -0.38097083568573, -0.44508686661720276, -0.5195077061653137, -0.30998706817626953, -0.15360160171985626, 0.797841489315033, 0.8502095937728882, 0.4827348589897156, -0.23026157915592194, 0.03187862038612366, 1.1033644676208496, -0.10759834945201874, -0.3196508586406708, -0.1470988243818283, 0.6409105062484741, -0.09581518918275833, -0.36733633279800415, 0.24034875631332397, 0.000765042204875499, -0.35800597071647644, -1.0400466918945312, -0.5757747292518616, 0.04581303521990776, -0.8502030372619629, -0.2765273451805115, 0.7390015125274658, -0.3204568028450012, -0.42471185326576233, 0.11177808791399002, -0.6629619002342224, -0.511922299861908, -0.04345368593931198, -1.4034397602081299, -0.2831310033798218, 0.2356058657169342, -0.4994792342185974, -0.3915453553199768, -0.02817847579717636, 1.065206527709961, -0.02869044616818428, -0.31024667620658875, 0.08907368034124374, -0.45501670241355896, -0.18195964395999908, -0.36754345893859863, -1.0408776998519897, 0.9713000059127808, 0.15950025618076324, -0.13140426576137543, 0.3639104664325714, 0.27510547637939453, 0.4162471294403076, -1.092514991760254, 0.32951095700263977, 0.5195496678352356, -0.8566268682479858, 0.05485083907842636, -0.9126667976379395, -0.7058605551719666, 0.34592127799987793, 0.4575046896934509, -0.19022740423679352, 0.03674834594130516, 0.15960054099559784, -0.7573037147521973, -0.22180818021297455, -0.4615449011325836, 0.24489593505859375, 0.8603556752204895, -0.8145938515663147, -0.38575106859207153, -0.3369606137275696, 0.4283640682697296, -1.0299677848815918, -0.10674440860748291, -0.32465842366218567, 0.2784299850463867, -0.3555591106414795, 0.9430819749832153, -0.16802579164505005, 0.8210862278938293, 0.6794376373291016, 0.7588627338409424, -0.7129235863685608, -0.4860817492008209, -0.9949470162391663, 0.2348087877035141, -0.0459015890955925, 0.6146081686019897, -0.597752034664154, 0.2657856345176697, 0.9646729826927185, -0.08239854127168655, -0.4771275520324707, -0.4724433422088623, 0.28624817728996277, -0.05624964088201523, -0.7184405326843262, 0.2114337831735611, -0.4188973009586334, 0.29298797249794006, 0.06206623837351799, 0.31008434295654297, 0.15030358731746674, -0.1335000842809677, -0.7306433916091919, 0.1882789433002472, 0.10593339800834656, 0.013876575045287609, -0.8309077620506287, -0.40008774399757385, -1.3211580514907837, -0.13467168807983398, -1.1075305938720703, 0.2523466646671295, -0.872515082359314, -0.4603174924850464, 0.01598508656024933, -0.44671857357025146, 0.23626920580863953, 0.4434070885181427, -0.33531495928764343, -0.39513999223709106, -0.568755030632019, -1.08050537109375, 0.7792163491249084, 0.5417894124984741, -0.6400692462921143, 0.1712307631969452, 0.02194366045296192, -0.12626883387565613, 0.19306428730487823, 0.35152095556259155, -0.7839208245277405, -0.653810441493988, -1.2563098669052124, 1.1882518529891968, -0.24174544215202332, -0.27748802304267883, -0.7523068785667419, 0.9846959114074707, 0.40014374256134033, -0.4213870167732239, 0.39978909492492676, 0.01184660755097866, -0.8763523697853088, -0.5266915559768677, 0.6207714080810547, -1.0555307865142822, 0.6872220635414124, 0.4583359360694885, -0.8122885823249817, 0.08693502098321915, 0.44069042801856995, -0.27105385065078735, -1.090894341468811, -0.5607755184173584, 0.15871882438659668, -1.2316105365753174, 0.044844359159469604, -0.3161315321922302, -0.2448531985282898, -1.1272345781326294, -0.2742583453655243, 0.2510617971420288, 0.5951019525527954, -0.3457699120044708, 0.908313512802124, 0.5807188153266907, -1.0242403745651245, 0.3260386884212494, 0.3323275148868561, -0.04643437638878822, -0.06698915362358093, 0.15417830646038055, 0.31583261489868164, -0.5084732174873352, 0.3070269525051117, 0.14213542640209198, 0.5649370551109314, -0.7602128386497498, -0.06488467007875443, 0.9893416166305542, -0.7332226037979126, -0.38931989669799805, 1.1592707633972168, -0.26576709747314453, -1.3567430973052979, 0.19635039567947388, -1.06988525390625, -0.6776984930038452, -0.7238144874572754, 0.5364682078361511, -0.25439533591270447, -0.6332830190658569, 0.4803461730480194, -0.4323510229587555, 0.5721760392189026, -0.2921018898487091, -0.18664109706878662, 0.8456825017929077, 0.17047810554504395, -0.5146024823188782, 0.9039061069488525, 0.40183785557746887, -0.748952329158783, -0.6451414227485657, -0.7732719779014587, -0.27025341987609863, 0.01424149889498949, 0.27847668528556824, -0.12746277451515198, -0.7864277958869934, 0.8529625535011292, 0.36510375142097473, 0.3033064305782318, 0.030251434072852135, -0.3190036118030548, -0.3042522668838501, 0.41213366389274597, 0.5307492017745972, -0.5496777296066284, -0.26436394453048706, 1.3765908479690552, 1.324276328086853, -0.27041688561439514, 0.41015830636024475, -0.21638013422489166, -0.6877185702323914, 0.9424808621406555, 0.5162591934204102, -0.5515080094337463, 0.3647855222225189, 0.17827560007572174, -0.06460390985012054, -0.05228967219591141, -1.4089034795761108, -0.3976896405220032, 0.19195041060447693, 0.8622250556945801, 1.1318691968917847, 0.001398265827447176, 0.03009273111820221, 0.7948968410491943, 0.1837090700864792, 0.3716258704662323, 0.7714114785194397, 0.6087342500686646, -0.05988249555230141, -0.16460733115673065, 0.40793484449386597, 0.5544411540031433, -0.4729013741016388, -0.6216724514961243, 0.2701883912086487, 0.4350149631500244, 0.10096823424100876, 0.2869667112827301, 0.7977277636528015, -0.02976730465888977, 0.7080278992652893, 0.040901750326156616, 0.5973976850509644, -0.7154728770256042, -1.0598232746124268, -0.4320111870765686, -0.2734498679637909, -0.2741453945636749, -0.03388489410281181, -0.5045259594917297, -0.6589321494102478, -0.5356912016868591, 0.11077819764614105, 0.22448502480983734, 0.015515577048063278, 0.8997291326522827, 0.36223462224006653, 0.6902510523796082, -0.4192560017108917, -0.8554415106773376, -0.45890507102012634, -0.745509684085846, 0.21502691507339478, -0.6327563524246216, -0.41459280252456665, -0.31579118967056274, -0.2769058644771576, -0.8091801404953003]}, "authors": [{"authorId": "2350348", "name": "Kazuki Irie"}, {"authorId": "35328044", "name": "Imanol Schlag"}, {"authorId": "2258963332", "name": "R'obert Csord'as"}, {"authorId": "145341374", "name": "J. Schmidhuber"}], "references": [{"paperId": "6e065c80a4b9af45a43c035fd38b58193684b200", "title": "Training and Generating Neural Networks in Compressed Weight Space"}, {"paperId": "e528466e2aff981511d4ca6e063211297c0b4175", "title": "The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization"}, {"paperId": "ed535e93d5b5a8b689e861e9c6083a806d1535c2", "title": "The Devil is in the Detail: Simple Tricks Improve Systematic Generalization of Transformers"}, {"paperId": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500", "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"}, {"paperId": "cd37fee4da0d4483322d6fa3cc67af9ed8c07be6", "title": "Efficient Transformers in Reinforcement Learning using Actor-Learner Distillation"}, {"paperId": "3544650f12a05cf4ed3bf2f7e22fc5c02fcabf50", "title": "Pretrained Transformers as Universal Computation Engines"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "cec7872b194aadf54140578b9be52939eb1112e9", "title": "LambdaNetworks: Modeling Long-Range Interactions Without Attention"}, {"paperId": "5e11e806d24dd80ecf0f91e7aacedbba8d9fd6fc", "title": "Learning Associative Inference Using Fast Weight Memory"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "9651e1987a39d100dc0f6696a2077199e5075ea2", "title": "Agent57: Outperforming the Atari Human Benchmark"}, {"paperId": "b19729b27a1b4c24b52f87308c907653300afa7f", "title": "Dota 2 with Large Scale Deep Reinforcement Learning"}, {"paperId": "7a7a7847041e7b25febb1491d65d842a6c65927e", "title": "Training Agents using Upside-Down Reinforcement Learning"}, {"paperId": "72973e49f453f678eb0b79b5fa5311b158f3909d", "title": "Reinforcement Learning Upside Down: Don't Predict Rewards - Just Map Them to Actions"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "3507bd62a14bd0e8ead28cdedb1c33ba83c39c6b", "title": "Mastering Atari, Go, chess and shogi by planning with a learned model"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "361c00b22e29d0816ca896513d2c165e26399821", "title": "Grandmaster level in StarCraft II using multi-agent reinforcement learning"}, {"paperId": "59a916cdc943f0282908e6f3fa0360f4c5fb78d0", "title": "Stabilizing Transformers for Reinforcement Learning"}, {"paperId": "b81d6c9138a51e7e109ec59d04f22f7186b3b7dc", "title": "TorchBeast: A PyTorch Platform for Distributed RL"}, {"paperId": "dfba20af7aacd819e7b22cf2bf189cd7af9da0a1", "title": "Enhancing the Transformer with Explicit Relational Encoding for Math Problem Solving"}, {"paperId": "a513bb6e1967f5a31ad4f38954e66d4169b613e5", "title": "Metalearned Neural Memory"}, {"paperId": "b3564be8b79f25585acb035f3deaf4ae93c26d8f", "title": "Theoretical Limitations of Self-Attention in Neural Sequence Models"}, {"paperId": "a4a2d99d1c237d0818971ec9205e89128c57fb02", "title": "Towards Interpretable Reinforcement Learning Using Attention Augmented Agents"}, {"paperId": "3928b2177086532775fbf607ae3e05a0375a5061", "title": "Language Modeling with Deep Transformers"}, {"paperId": "afed6dc6900d3b37e528b9086661bba583d60bf6", "title": "Analysing Mathematical Reasoning Abilities of Neural Models"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "146c231532d4e38de95e63368dcd09d0f8cea291", "title": "Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity"}, {"paperId": "5b9578cb8ce928f09af765ddafda3235d140abf4", "title": "Dropout is a special case of the stochastic delta rule: faster and more accurate deep learning"}, {"paperId": "b9de9599d7241459db9213b5cdd7059696f5ef8d", "title": "Character-Level Language Modeling with Deeper Self-Attention"}, {"paperId": "06354570d5f6be803d4a79bf59ecbb097bca8755", "title": "On the Practical Computational Power of Finite Precision RNNs for Language Recognition"}, {"paperId": "249ac07c5b87f44b85500e2d26b68a7edb93e83d", "title": "Differentiable plasticity: training plastic neural networks with backpropagation"}, {"paperId": "8b354d76813bd5375e7e5c8d17f630bec5936a01", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning"}, {"paperId": "997c55547aeca733dfc5dfebd12412612ecba022", "title": "The Importance of Being Recurrent for Modeling Hierarchical Structure"}, {"paperId": "98447b6c5b04249fa08a81c4107f7ce99199e936", "title": "Fast Weight Long Short-Term Memory"}, {"paperId": "80196cdfcd0c6ce2953bf65a7f019971e2026386", "title": "IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures"}, {"paperId": "927d904d2aad002eb71e8c6ee45218f31a103100", "title": "Psychlab: A Psychology Laboratory for Deep Reinforcement Learning Agents"}, {"paperId": "3b290ffa1f4f8226e326f00984acecdfbe9e28bf", "title": "Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "c91ae35dbcb6d479580ecd235eabf98374acdb55", "title": "Using Fast Weights to Attend to the Recent Past"}, {"paperId": "784ee73d5363c711118f784428d1ab89f019daa5", "title": "Hybrid computing using a neural network with dynamic external memory"}, {"paperId": "563783de03452683a9206e85fe6d661714436686", "title": "HyperNetworks"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "aba48504f4f9563eafa44e0cfb22e1345d767c80", "title": "Dynamic Filter Networks"}, {"paperId": "77f0a39b8e02686fd85b01971f8feb7f60971f80", "title": "Identity Mappings in Deep Residual Networks"}, {"paperId": "69e76e16740ed69f4dc55361a3d319ac2f1293dd", "title": "Asynchronous Methods for Deep Reinforcement Learning"}, {"paperId": "f88a6f6fd6611543220482e6b3a5f379b7bf5049", "title": "Increasing the Action Gap: New Operators for Reinforcement Learning"}, {"paperId": "385c18cc4024a3b3206c508c512e037b9c00b8f3", "title": "Image Question Answering Using Convolutional Neural Network with Dynamic Parameter Prediction"}, {"paperId": "d5ed07113ddcd038062525a5a54550c012ac9a74", "title": "Massively Parallel Methods for Deep Reinforcement Learning"}, {"paperId": "4d674fc145bb30a09d3ec41aaed327cf6016becb", "title": "A Dynamic Convolutional Layer for short rangeweather prediction"}, {"paperId": "e0945081b5b87187a53d4329cf77cd8bff635795", "title": "Highway Networks"}, {"paperId": "340f48901f72278f6bf78a04ee5b01df208cc508", "title": "Human-level control through deep reinforcement learning"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "c1126fbffd6b8547a44c58b192b36b08b18299de", "title": "Neural Turing Machines"}, {"paperId": "0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a", "title": "Learning to Execute"}, {"paperId": "2319a491378867c7049b3da055c5df60e1671158", "title": "Playing Atari with Deep Reinforcement Learning"}, {"paperId": "b36f177b774a903e24e00a58270048fe657ee995", "title": "Recurrent policy gradients"}, {"paperId": "92d009217b100882376ae5c90217da2e92471ad7", "title": "Solving Deep Memory POMDPs with Recurrent Policy Gradients"}, {"paperId": "194b9ceaf7b4246eeb9123049304d26c779c2215", "title": "Information"}, {"paperId": "11540131eae85b2e11d53df7f1360eeb6476e7f4", "title": "Learning to Forget: Continual Prediction with LSTM"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "61639af1a89c69094bcc0ed40fad752832b037c3", "title": "Reducing the Ratio Between Learning Complexity and Number of Time Varying Variables in Fully Recurrent Nets"}, {"paperId": "bc22e87a26d020215afe91c751e5bdaddd8e4922", "title": "Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks"}, {"paperId": "7826ff60d2dfb24d2af18c5bc565c357ef9db4c1", "title": "A stochastic version of the delta rule"}, {"paperId": "9fccf16e5205eaa44aa084b785372df1a0b44255", "title": "Dynamic connections in neural networks"}, {"paperId": "cf5266b3ba94a322846e382a160aeb9a7d87e922", "title": "Putting Knowledge in its Place: A Scheme for Programming Parallel Processing Structures on the Fly"}, {"paperId": "d9610589189e0821500516994dcee543a558b70c", "title": "Learning advanced mathematical computations from examples"}, {"paperId": "f6264b11ec0dd9133f1d88a5288a3267a93182f8", "title": "What Matters for On-Policy Deep Actor-Critic Methods? A Large-Scale Study"}, {"paperId": "2068b4d5c95ea5c66c8a81e73337fc52466b8b18", "title": "Reinforcement Learning as One Big Sequence Modeling Problem"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "11503f8f1d94607b46f58ad4188facdadf257fe4", "title": "Gated Fast Weights for On-The-Fly Neural Program Generation"}, {"paperId": "85d346297ec37a451d4500afad53fed8f281af92", "title": "Adaptive Switching Circuits"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": null, "title": "Lecture 6.5-RMSProp: Divide the gradient by a running average of its recent magnitude"}, {"paperId": null, "title": "Addressing some limitations of Transformers with feedback memory"}, {"paperId": "e62f7643f616aaad65ffd47155a53bfa325e455d", "title": "The Correlation Theory of Brain Function"}, {"paperId": null, "title": "Making the world differentiable: On using fully recurrent self-supervised neural networks for dynamic reinforcement learning and planning in non-stationary environments"}]}