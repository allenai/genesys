{"paperId": "44aa16ed0f3e22c82b10fcc9d23459ecfb7fcdb3", "abstract": "In recent computer vision research, the advent of the Vision Transformer (ViT) has rapidly revolutionized various architectural design efforts: ViT achieved state-of-the-art image classification performance using self-attention found in natural language processing, and MLP-Mixer achieved competitive performance using simple multi-layer perceptrons. In contrast, several studies have also suggested that carefully redesigned convolutional neural networks (CNNs) can achieve advanced performance comparable to ViT without resorting to these new ideas. Against this background, there is growing interest in what inductive bias is suitable for computer vision. Here we propose Sequencer, a novel and competitive architecture alternative to ViT that provides a new perspective on these issues. Unlike ViTs, Sequencer models long-range dependencies using LSTMs rather than self-attention layers. We also propose a two-dimensional version of Sequencer module, where an LSTM is decomposed into vertical and horizontal LSTMs to enhance performance. Despite its simplicity, several experiments demonstrate that Sequencer performs impressively well: Sequencer2D-L, with 54M parameters, realizes 84.6% top-1 accuracy on only ImageNet-1K. Not only that, we show that it has good transferability and the robust resolution adaptability on double resolution-band.", "venue": "Neural Information Processing Systems", "year": 2022, "citationCount": 46, "influentialCitationCount": 5, "openAccessPdf": {"url": "http://arxiv.org/pdf/2205.01972", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes Sequencer, a novel and competitive architecture alternative to ViT that provides a new perspective on what inductive bias is suitable for computer vision, and proposes a two-dimensional version of Sequencer module, where an LSTM is decomposed into vertical and horizontal LSTMs to enhance performance."}, "embedding": {"model": "specter_v2", "vector": [0.6457735896110535, 0.47208550572395325, -0.163129985332489, -0.021770881488919258, -0.123771533370018, -0.06448834389448166, 0.796290397644043, -0.3108542263507843, -0.4028868079185486, -0.2720640301704407, 0.5491428971290588, 0.01927049830555916, 0.8231058716773987, 0.004490234423428774, -0.09469102323055267, 0.02555023692548275, -0.6109073758125305, -0.21551217138767242, 0.510999321937561, -0.5886386632919312, 0.3829807639122009, -0.5304625034332275, -1.1843234300613403, 0.3706025779247284, -0.135860413312912, 1.2367737293243408, 0.5046141147613525, 1.0829144716262817, -0.5364338755607605, 1.1654798984527588, 0.30941182374954224, -0.3968747556209564, 0.020377622917294502, -0.210905522108078, -0.8166256546974182, -0.23092105984687805, 0.9349024891853333, -0.1659902185201645, -0.5916305184364319, 0.8361088037490845, -0.08346660435199738, 0.03315216675400734, 0.451177179813385, -0.46056923270225525, -0.03991563618183136, 0.5457585453987122, 0.30706289410591125, 1.122594952583313, -0.42825058102607727, -0.5389092564582825, 1.4068771600723267, -1.0061604976654053, 0.06217141076922417, 1.3937289714813232, 0.7051771879196167, 0.6426478028297424, -0.2555467486381531, -0.7412202954292297, 0.6199766993522644, 0.11490540951490402, -0.39475488662719727, -0.11149474233388901, 0.24406537413597107, -0.25863316655158997, 1.5489437580108643, -0.5419309139251709, -0.06383518129587173, 0.9571464657783508, 0.252162903547287, 1.2296292781829834, 0.3545093536376953, -0.5623481273651123, -0.3823871910572052, 0.12435142695903778, 0.5408604741096497, 0.6659632921218872, -0.487522691488266, 0.02606884203851223, -0.8841630220413208, 0.2756783664226532, 0.7404601573944092, -0.027564384043216705, 0.23468956351280212, -0.14141394197940826, -0.2666897773742676, 0.6725409030914307, 0.8743204474449158, 0.8623329997062683, -0.18853546679019928, 0.8607175350189209, 0.5998072028160095, 0.28111737966537476, -0.25308674573898315, 0.43218740820884705, 0.31104084849357605, 0.960195004940033, -0.7386206984519958, -0.2675820589065552, -0.4226507842540741, 0.6277530789375305, 0.14558108150959015, 0.6195207834243774, -0.31149882078170776, 0.5070466995239258, 1.034631609916687, 0.046423930674791336, 0.5589600205421448, -0.5195851922035217, -0.05871199443936348, -0.7106766700744629, -0.5639285445213318, -1.0025746822357178, 0.1111365556716919, -0.7828160524368286, -1.1128628253936768, -0.7440851926803589, -0.7997031211853027, 0.6401781439781189, -0.9288416504859924, 0.6830478310585022, -0.862814724445343, 0.22125498950481415, 0.3193501830101013, 0.2697018086910248, 0.6537290811538696, 0.5832104682922363, 0.4443402588367462, 0.5191648006439209, 1.3169140815734863, -0.7463593482971191, -0.20147129893302917, -1.1180684566497803, -0.1341320127248764, -0.0029663576278835535, -0.08771932870149612, -0.2915877401828766, -0.5804994106292725, -1.3134794235229492, -1.0451546907424927, 0.027080439031124115, -0.40415820479393005, -0.005882210098206997, 0.8146131038665771, -0.005054808687418699, -1.1609838008880615, 1.0285111665725708, 0.10247853398323059, -0.5778532028198242, 0.575619637966156, 0.08170855045318604, 0.5685553550720215, 0.153778076171875, -1.1676512956619263, 0.39343178272247314, 0.23500004410743713, -0.7155197858810425, -0.35899117588996887, -0.4864899218082428, -1.0560152530670166, -0.18437142670154572, 0.03710957244038582, -0.635744035243988, 1.4299172163009644, -0.8404789566993713, -0.698012113571167, 1.0650092363357544, -0.26942557096481323, -0.27842333912849426, -0.06537139415740967, 0.08495691418647766, -0.3360479772090912, -0.20496249198913574, -0.16012755036354065, 0.5677546858787537, 0.7706692814826965, -0.46627697348594666, -0.547675609588623, 0.11622732877731323, -0.47360959649086, -0.4449942708015442, -0.6959373950958252, 0.7222851514816284, -0.2794647812843323, -0.4242781102657318, 0.37358662486076355, 0.7402434349060059, -0.062005069106817245, -0.3542914390563965, -0.2162022888660431, -0.9479444622993469, 0.6650989651679993, 0.26986944675445557, 0.3949047327041626, -1.025557518005371, -1.030280351638794, -0.28386837244033813, -0.06237125024199486, -0.16474905610084534, -0.8506380319595337, 0.18346361815929413, -0.6157349348068237, 0.2596273720264435, -0.14890740811824799, -0.5907314419746399, -0.5423060059547424, -0.22516007721424103, -1.0757460594177246, -0.1578175127506256, 0.38105496764183044, 0.9686480164527893, -0.8477765321731567, -0.35797998309135437, 0.05319324508309364, 0.2554123103618622, -0.6054323315620422, 1.241594672203064, -0.22886072099208832, 0.08223830908536911, -0.17296788096427917, -0.34174293279647827, 0.1516680270433426, -0.5716065764427185, 0.5126854777336121, -0.8743494749069214, -0.3858671486377716, 0.6157164573669434, 0.13792820274829865, 1.2853296995162964, -0.2595962584018707, 1.3107218742370605, -0.35681357979774475, -0.9204010367393494, 0.6250694990158081, 0.08061335980892181, -0.07507794350385666, -0.8502990007400513, 0.4242425560951233, -0.055114034563302994, -1.1890618801116943, 0.26782646775245667, 0.5096837878227234, 0.8097620010375977, -0.236632838845253, -0.1300206035375595, 0.9543106555938721, -0.3190079927444458, 0.05397776514291763, 0.6728852987289429, 0.6806816458702087, 0.31216490268707275, 0.20836713910102844, -0.37346112728118896, 0.4227837920188904, -0.6886174082756042, 0.04966729134321213, 0.6519835591316223, 0.620847761631012, 1.1826454401016235, 0.6724061369895935, -0.8343269228935242, -0.6648780107498169, -0.10966692119836807, 0.528250515460968, 0.9872668981552124, 0.15098778903484344, 0.19683590531349182, -0.5902396440505981, -0.4337445795536041, -0.4919975697994232, -0.22434312105178833, -0.2776823043823242, -0.15660405158996582, -0.42663201689720154, -0.8208296298980713, 0.7050352692604065, 0.3462008535861969, 1.4243916273117065, -0.5786133408546448, -0.5866726636886597, -0.44496017694473267, 0.07837764918804169, -1.0539313554763794, -0.46525803208351135, 0.502516508102417, -0.4541887640953064, -0.11894384771585464, -0.16052506864070892, -0.5973835587501526, 0.10650328546762466, -0.3035774528980255, 1.0055065155029297, -0.6449376940727234, -0.5095734000205994, 0.4177229404449463, 0.6731894612312317, -0.5397590398788452, -0.5341073274612427, 0.2544645071029663, 0.13827602565288544, 0.250264436006546, 0.13631375133991241, 0.3173952102661133, -0.2819344997406006, 0.08387700468301773, -0.25320175290107727, -0.032193731516599655, 0.12149152159690857, 0.1343013495206833, 0.42574140429496765, -0.1548902988433838, 0.08406557887792587, -0.960358202457428, 0.3938058316707611, 0.23243337869644165, -0.2267649918794632, 0.14402872323989868, -0.41995304822921753, -0.03291168436408043, 0.4596984386444092, -0.33010759949684143, -0.5616089105606079, -0.6992794275283813, 0.2900014817714691, -0.4385504126548767, -0.3171933889389038, -0.3190860152244568, 0.6708998084068298, -0.14575694501399994, 0.39800599217414856, 0.4751710891723633, 0.4288557171821594, 0.03258085623383522, -0.09017488360404968, -0.6555126905441284, 1.1307964324951172, 0.584843635559082, 0.26738211512565613, 0.044378552585840225, -0.06482196599245071, -0.9261144995689392, -0.8863865733146667, -0.6095446348190308, -0.1190183013677597, -0.46600639820098877, 0.40264466404914856, -0.7275171875953674, -1.1286041736602783, 0.3400053381919861, -0.8870168924331665, -0.10137999057769775, 0.057660844177007675, -0.31317710876464844, -0.11772530525922775, -0.9872382283210754, -0.9530953764915466, -0.5827625393867493, -0.4372503459453583, -0.6984068751335144, -0.20633547008037567, 0.4618401825428009, -0.2895134389400482, -0.42838045954704285, -0.2975700795650482, -0.55829918384552, 0.9192361831665039, -0.2522125542163849, 0.7151310443878174, -0.06275317072868347, -0.42439374327659607, 0.2082650065422058, -0.27740544080734253, 0.9390838146209717, -0.21391892433166504, 0.1303904950618744, -1.1217108964920044, 0.29423412680625916, -0.15503957867622375, -0.5894812345504761, 0.900939404964447, 0.2752254903316498, 0.739032506942749, 0.2379787415266037, -0.31006279587745667, 0.36840546131134033, 1.8670966625213623, -0.6220825910568237, 0.32190173864364624, 0.22313368320465088, 0.9247905015945435, 0.25347253680229187, -0.5910075306892395, 0.24831408262252808, 0.4552019536495209, 0.013582042418420315, 0.4521232545375824, -0.6724543571472168, -0.5752149820327759, -0.6676592826843262, 0.1988709270954132, 0.9352370500564575, 0.33993303775787354, 0.05456545948982239, -1.1138498783111572, 0.7573473453521729, -0.6971312761306763, -0.818539023399353, 0.5886119604110718, 0.554894208908081, 0.009476992301642895, -0.12953409552574158, -0.7067015171051025, 0.007216753903776407, 0.8121091723442078, 0.7018447518348694, -0.3165181875228882, -0.7046359181404114, -0.3708159029483795, 0.39718544483184814, 0.7057201862335205, 0.44812655448913574, -0.301273912191391, 0.6014266014099121, 14.948192596435547, 0.5615615844726562, -0.40336915850639343, 0.25904685258865356, 0.9246051907539368, 0.5620778799057007, -0.41824135184288025, -0.04559168219566345, -1.0848779678344727, -0.382755845785141, 0.774935781955719, 0.6697430610656738, 0.24705810844898224, 0.054821599274873734, -0.5042448043823242, 0.07761965692043304, -0.3168521523475647, 0.863745927810669, 0.8402764797210693, -1.2216254472732544, 0.3744456470012665, 0.012042528949677944, 0.2656342089176178, 0.4410918951034546, 0.9907195568084717, 0.6285936832427979, 0.4986342191696167, -0.0028250243049114943, 0.5090957880020142, 0.02419331856071949, 1.0512157678604126, -0.02261856012046337, 0.2157530039548874, 0.1490778625011444, -1.0371938943862915, -0.33969345688819885, -0.4947381615638733, -0.8275884389877319, -0.3252967298030853, -0.002487368881702423, -0.36782532930374146, -0.5227409601211548, 0.27270999550819397, 0.9283261299133301, 0.0562707744538784, 0.07484216243028641, -0.3080832064151764, 0.4456257224082947, 0.38010749220848083, -0.21001701056957245, 0.4132404625415802, 0.8895254135131836, 0.3037494122982025, 0.11302199959754944, -0.24542973935604095, 0.18080702424049377, -0.19766633212566376, 0.2736528813838959, -0.4864567518234253, -0.48375803232192993, -0.22881434857845306, -0.10945304483175278, -0.4052335023880005, 0.7155380249023438, 0.12470971792936325, 0.17053431272506714, 0.02705986239016056, 0.6816309690475464, 0.3475884199142456, 0.3613019287586212, -0.34821680188179016, -0.4554254114627838, 0.4250751733779907, -0.54538494348526, 0.2756079137325287, 0.4321490526199341, -0.3486519753932953, -0.5276588201522827, -1.0117119550704956, -0.13091647624969482, 0.5771847367286682, -0.8959524631500244, -0.5421025156974792, 1.3545256853103638, -0.6521339416503906, -0.22225601971149445, 0.5922075510025024, -1.0351616144180298, -0.24217182397842407, 0.30598413944244385, -1.8151817321777344, -0.3901456892490387, -0.24648858606815338, -0.15014849603176117, -0.21126338839530945, -0.34710511565208435, 0.758854329586029, -0.1598200798034668, -0.2668255865573883, -0.2254926711320877, -0.41888096928596497, 0.12891384959220886, -0.17502503097057343, -0.7502761483192444, 0.7876730561256409, 0.24491755664348602, -0.18170742690563202, -0.09932628273963928, 0.08365117758512497, 0.45655879378318787, -0.38117361068725586, 0.037459321320056915, 0.7742525935173035, -0.6963837146759033, -0.2613006830215454, -0.8867630958557129, -0.6976274847984314, 0.17585285007953644, 0.6555341482162476, -0.15135908126831055, -0.2505744695663452, 0.06614504009485245, -0.96860271692276, -0.5642871856689453, -0.6371069550514221, -0.06638743728399277, 0.34851157665252686, -1.0631521940231323, -0.3632483184337616, -0.5380116701126099, 0.22307972609996796, -0.3879450857639313, -0.25091251730918884, 0.0833287462592125, 0.09955212473869324, -0.6782590746879578, 1.2368206977844238, -0.16622991859912872, 0.946483314037323, 0.9053170680999756, -0.24900293350219727, -0.4742073118686676, -0.3104945421218872, -0.7571640014648438, 0.6467967629432678, 0.6004623770713806, 0.34556838870048523, -0.8784226775169373, 0.4057374596595764, 0.2657771706581116, 0.30704405903816223, -0.3052136301994324, -0.3686513900756836, -0.11795200407505035, -0.45346489548683167, -0.4793557822704315, 0.12577758729457855, 0.058925826102495193, -0.38275063037872314, 0.32194599509239197, 0.4924536943435669, 0.5642766356468201, 0.2604611814022064, -0.5705093145370483, -0.09159731864929199, -0.4276679754257202, 0.33589354157447815, -0.5751776099205017, -0.7894361615180969, -1.6602468490600586, 0.02124568074941635, -1.0276647806167603, -0.04230989143252373, -0.9585630297660828, -0.347181111574173, 0.21905317902565002, -0.8153259754180908, 0.03826528787612915, 0.5726804137229919, 0.0285678431391716, -0.17042987048625946, -0.37575843930244446, -0.31656700372695923, 0.6908956170082092, 0.7294254302978516, -0.786879301071167, 0.4584167003631592, -0.2069336175918579, -0.1608574390411377, 0.45164754986763, 0.3731022775173187, -0.3690958321094513, -0.7792501449584961, -1.1404294967651367, 0.24487169086933136, -0.16498050093650818, 0.23239660263061523, -1.2685424089431763, 0.9007341861724854, 0.5704938173294067, 0.17071212828159332, -0.05575473979115486, 0.39638668298721313, -0.8017821311950684, -0.7188816666603088, 0.546891987323761, -1.0597065687179565, -0.2229255586862564, 0.15334118902683258, -0.5334698557853699, -0.2648865878582001, 0.7455346584320068, 0.4368989169597626, -1.2434202432632446, -1.2949497699737549, 0.3642407953739166, -0.8239855170249939, 0.052586499601602554, -0.20761731266975403, -0.5734972953796387, -1.090088963508606, -0.13755743205547333, 0.2963796555995941, 0.4183434247970581, -0.7784930467605591, 1.1764413118362427, 0.630866527557373, -0.9692845940589905, 0.029307691380381584, 0.4293397068977356, 0.007176931481808424, -0.26844072341918945, 0.5211671590805054, -0.03191476687788963, -0.14335612952709198, 0.48650288581848145, -0.09913039952516556, 0.043787162750959396, -0.8088060617446899, 0.067817322909832, 1.0229649543762207, -0.18960624933242798, -0.004942667204886675, 1.1430940628051758, 0.17146040499210358, -0.8116371035575867, 0.21943232417106628, -0.8960766196250916, -0.8953997492790222, 0.2043285071849823, 0.5147875547409058, -0.07799018174409866, -0.3144664764404297, -0.04849492013454437, -0.5265951752662659, 0.533174991607666, 0.012811411172151566, -0.6151643991470337, 0.380791574716568, -0.3032142221927643, -0.19848282635211945, 0.8973954916000366, 1.0487785339355469, -1.2060965299606323, -0.9487015604972839, -1.058566689491272, -0.389268696308136, 0.021620456129312515, 0.39922717213630676, -0.02303314581513405, -0.8621838688850403, 0.8382669687271118, 0.8169897794723511, 0.2488158494234085, 0.45948129892349243, -0.2007015496492386, 0.12366659939289093, 0.40514904260635376, -0.018039915710687637, -0.448003351688385, 0.08061704784631729, 1.617277979850769, 1.1510047912597656, -0.7567550539970398, -0.15528610348701477, -0.20907728374004364, -0.8405652046203613, 0.8192474842071533, 0.557831346988678, -0.2678149342536926, 0.6503859162330627, -0.256341814994812, 0.21497073769569397, 0.22743557393550873, -1.0100980997085571, -0.5847916007041931, 0.5274978876113892, 1.0043048858642578, 0.8713302612304688, -0.13916069269180298, 0.6069189310073853, 0.45752188563346863, -0.03034917451441288, -0.08495759963989258, 0.39529597759246826, 0.243565171957016, -0.37363746762275696, 0.4662707448005676, 0.06096566841006279, 0.24810893833637238, -0.7048541903495789, -0.3732460141181946, 0.21560610830783844, 0.20456136763095856, -0.04595539718866348, 0.5341312289237976, 1.4329438209533691, -0.31420326232910156, 0.7354511618614197, -0.08582933992147446, 0.5440629124641418, -0.26466628909111023, -0.3679873049259186, -0.589026153087616, -0.6588711142539978, 0.14559109508991241, -0.38393521308898926, -0.702159583568573, -0.4716546833515167, -0.045166995376348495, 0.40600594878196716, -0.08940105140209198, 0.6378509998321533, 0.7351824641227722, 0.11528703570365906, 0.8966554999351501, 0.32944175601005554, -0.3377879858016968, -0.37423834204673767, -0.7317402958869934, 0.08649692684412003, -0.5084038972854614, 0.5871427059173584, 0.06255632638931274, 0.009813175536692142, -0.052787814289331436]}, "authors": [{"authorId": "2122961034", "name": "Yuki Tatsunami"}, {"authorId": "1381928106", "name": "M. Taki"}], "references": [{"paperId": "9f1b0e4c42a5a85d4c023030557ade4419f82ecf", "title": "Scaling Up Your Kernels to 31\u00d731: Revisiting Large Kernel Design in CNNs"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "730a34374384f8abb886e464758b1a145edef938", "title": "RepMLPNet: Hierarchical Vision MLP with Re-parameterized Locality"}, {"paperId": "87e6f235c7a1fdeceb41605db64419fa11f7b98b", "title": "Couplformer: Rethinking Vision Transformer with Coupling Attention Map"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "485c08025157973bb52a935c6aa3bee74f990c01", "title": "Sparse MLP for Image Recognition: Is Self-Attention Really Necessary?"}, {"paperId": "58970a426b687bb080b7fed3b4b78ab1ebaa56f4", "title": "Hire-MLP: Vision MLP via Hierarchical Rearrangement"}, {"paperId": "d820174fe91e7d384eeacede3a43fd1b6ff9afc9", "title": "RaftMLP: How Much Can Be Done Without Attention and with Less Spatial Locality?"}, {"paperId": "fd547648ded5dd4c45a3594b398844876d93c339", "title": "S2-MLPv2: Improved Spatial-Shift MLP Architecture for Vision"}, {"paperId": "f75cddf2d42ed01b34686704eb3504becef67442", "title": "CycleMLP: A MLP-like Architecture for Dense Prediction"}, {"paperId": "71363797140647ebb3f540584de0a8758d2f7aa2", "title": "AS-MLP: An Axial Shifted MLP Architecture for Vision"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "9b6af0e358e76d22f209c75b1702c3e6ea7815b1", "title": "Global Filter Networks for Image Classification"}, {"paperId": "2435ffb8ed3212156d6b6f19f633a861399cf30e", "title": "Vision Permutator: A Permutable MLP-Like Architecture for Visual Recognition"}, {"paperId": "60707f6d2bffeab09e8f1d073fce4fc06ab89ec1", "title": "S2-MLP: Spatial-Shift MLP Architecture for Vision"}, {"paperId": "8602fd5b0ac73bb422f238b265479f363c0ffe61", "title": "Refiner: Refining Self-attention for Vision Transformers"}, {"paperId": "b8cee43a51c44f8f4448e78e41ecf081987707cf", "title": "Towards Robust Vision Transformer"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5", "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "0eff37167876356da2163b2e396df2719adf7de9", "title": "CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification"}, {"paperId": "054e307c1edf4b28137ffcbce980fe81f0647d20", "title": "Finetuning Pretrained Transformers into RNNs"}, {"paperId": "96da196d6f8c947db03d13759f030642f8234abf", "title": "DeepViT: Towards Deeper Vision Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "022622e024890d6e044ac50e2da6b44c59bdf418", "title": "The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "f5c8464032a936451b222be1984cabf42d6adfa8", "title": "Are we done with ImageNet?"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "45557cc70cd6989ab6b03e5aeb787e34299099f7", "title": "Natural Adversarial Examples"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "4ae0c4a511697e960c477ea3e37b3e11bf3e0e02", "title": "Learning Robust Global Representations by Penalizing Local Predictive Power"}, {"paperId": "49b64383fe36268410c430352637ed23b16820c5", "title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations"}, {"paperId": "4e0bb8c1c683b43357c5d5216f6b74ff2cb32434", "title": "Do ImageNet Classifiers Generalize to ImageNet?"}, {"paperId": "a84906dbd4d6640f918d0b6ed2a7313dda0d55f1", "title": "Panoptic Feature Pyramid Networks"}, {"paperId": "5132500b23d2da47129b3f4f68dd30947a29e502", "title": "CCNet: Criss-Cross Attention for Semantic Segmentation"}, {"paperId": "b5c03413b37f06bd94144ebfae5b2e0632ca604e", "title": "SqueezeNext: Hardware-Aware Neural Network Design"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "eb35fdc11a325f21a8ce0ca65058f7480a2fc91f", "title": "Improved Regularization of Convolutional Neural Networks with Cutout"}, {"paperId": "1a857da1a8ce47b2aa185b91b5cb215ddef24de7", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "7aa38b85fa8cba64d6a4010543f6695dbf5f1386", "title": "Towards Deep Learning Models Resistant to Adversarial Attacks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "01a4f33da8ad94ced3cf58548b28dbbb44148571", "title": "Understanding the Effective Receptive Field in Deep Convolutional Neural Networks"}, {"paperId": "5b6ec746d309b165f9f9def873a2375b6fb40f3d", "title": "Xception: Deep Learning with Depthwise Separable Convolutions"}, {"paperId": "5694e46284460a648fe29117cbc55f6c9be3fa3c", "title": "Densely Connected Convolutional Networks"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "41f1d50c85d3180476c4c7b3eea121278b0d8474", "title": "Pixel Recurrent Neural Networks"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "e2449e7a57f3f18ef58203c155ead421b5c72850", "title": "ReSeg: A Recurrent Neural Network-Based Model for Semantic Segmentation"}, {"paperId": "7304c3155ee9ac37348ced0d71f3cb03434b252d", "title": "Semantic Object Parsing with Local-Global Long Short-Term Memory"}, {"paperId": "5b791cd374c7109693aaddee2c12d659ae4e3ec0", "title": "Grid Long Short-Term Memory"}, {"paperId": "96d288df7ca67dafe1642c427a4d9f4901267c8b", "title": "Scene labeling with LSTM recurrent neural networks"}, {"paperId": "7e463877264e70d53c844cf4b1bf3b15baec8cfb", "title": "ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks"}, {"paperId": "bee044c8e8903fb67523c1f8c105ab4718600cdb", "title": "Explaining and Harnessing Adversarial Examples"}, {"paperId": "e15cf50aa89fee8535703b9f9512fca5bfc43327", "title": "Going deeper with convolutions"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "1eb09fecd75eb27825dce4f964b97f4f5cc399d7", "title": "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "a83cec6a91701bd8500f8c43ad731d4353c71d55", "title": "3D Object Representations for Fine-Grained Categorization"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "02b28f3b71138a06e40dbd614abf8568420ae183", "title": "Automated Flower Classification over a Large Number of Classes"}, {"paperId": "f70ae50828e3b6166628f5e8edb239b1cca6b471", "title": "Multi-dimensional Recurrent Neural Networks"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "e23c34414e66118ecd9b08cf0cd4d016f59b0b85", "title": "Bidirectional recurrent neural networks"}, {"paperId": "0e6beb95b5150ce99b108acdefabf70ccd3fee30", "title": "An algorithm for the machine calculation of complex Fourier series"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "b00dc5743fb6e57e3024cb9826f909f8b795f758", "title": "MorphMLP: A Self-Attention Free, MLP-Like Backbone for Image and Video"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Pytorch image models"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "02227c94dd41fe0b439e050d377b0beb5d427cda", "title": "Reading Digits in Natural Images with Unsupervised Feature Learning"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "c08d0525bd42fa1c24f9f5df72f4c8fcf7063b22", "title": "Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}]}