{"paperId": "964da38f24d3a2e65474728eef05f3de9e47666d", "abstract": "Evaluating aligned large language models' (LLMs) ability to recognize and reject unsafe user requests is crucial for safe, policy-compliant deployments. Existing evaluation efforts, however, face three limitations that we address with SORRY-Bench, our proposed benchmark. First, existing methods often use coarse-grained taxonomies of unsafe topics, and are over-representing some fine-grained topics. For example, among the ten existing datasets that we evaluated, tests for refusals of self-harm instructions are over 3x less represented than tests for fraudulent activities. SORRY-Bench improves on this by using a fine-grained taxonomy of 45 potentially unsafe topics, and 450 class-balanced unsafe instructions, compiled through human-in-the-loop methods. Second, linguistic characteristics and formatting of prompts are often overlooked, like different languages, dialects, and more -- which are only implicitly considered in many evaluations. We supplement SORRY-Bench with 20 diverse linguistic augmentations to systematically examine these effects. Third, existing evaluations rely on large LLMs (e.g., GPT-4) for evaluation, which can be computationally expensive. We investigate design choices for creating a fast, accurate automated safety evaluator. By collecting 7K+ human annotations and conducting a meta-evaluation of diverse LLM-as-a-judge designs, we show that fine-tuned 7B LLMs can achieve accuracy comparable to GPT-4 scale LLMs, with lower computational cost. Putting these together, we evaluate over 40 proprietary and open-source LLMs on SORRY-Bench, analyzing their distinctive refusal behaviors. We hope our effort provides a building block for systematic evaluations of LLMs' safety refusal capabilities, in a balanced, granular, and efficient manner.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "It is shown that fine-tuned 7B LLMs can achieve accuracy comparable to GPT-4 scale LLMs, with lower computational cost, and investigates design choices for creating a fast, accurate automated safety evaluator."}, "embedding": {"model": "specter_v2", "vector": [0.021113406866788864, 0.6001537442207336, -0.8523123860359192, -0.18220344185829163, -0.5319384336471558, -0.5369489789009094, 0.5835291147232056, 0.15470385551452637, -0.2523975968360901, 0.143575057387352, 0.4021309018135071, -0.8848474621772766, 0.3789977729320526, 0.33236950635910034, -0.21041350066661835, 0.46850910782814026, -0.723259687423706, 0.23121726512908936, -0.13722820580005646, -0.1688452512025833, -0.14184391498565674, -0.3639548718929291, -0.4607670307159424, 0.12737293541431427, 0.6990031003952026, 0.028216354548931122, -0.8774895668029785, 0.5149602293968201, -0.010684319771826267, 0.4331377148628235, 0.26915493607521057, -0.34115540981292725, 0.18648982048034668, 0.2232593595981598, -0.2637300193309784, -0.05385831743478775, 0.3731539845466614, -0.788608968257904, -0.35805585980415344, 0.8637375831604004, -0.11313966661691666, 0.07259050011634827, 0.37434476613998413, -0.6555427312850952, -0.5171420574188232, 0.6546332240104675, 0.5070943832397461, 0.6485182046890259, 0.5183122158050537, -0.12595824897289276, 0.954135537147522, -0.9474199414253235, 0.3047400414943695, 1.375796914100647, 0.24063700437545776, 0.622620701789856, -0.44117698073387146, -0.5997621417045593, 0.36915266513824463, -0.3645411729812622, -0.7274602055549622, -0.26474663615226746, -0.5849496722221375, -0.4929582178592682, 1.425511360168457, -0.04832400754094124, -0.6309950351715088, 0.9577056765556335, -0.04712032526731491, 1.3084344863891602, 0.28536152839660645, -0.7281368374824524, 0.31050950288772583, 0.37965428829193115, 0.8591369390487671, 0.6932069659233093, -0.04317823052406311, 0.535522997379303, -0.4327709376811981, -0.8624570369720459, 0.08258674293756485, -0.10605377703905106, -0.1813812255859375, -0.056052468717098236, 0.03302713483572006, 0.688004195690155, -0.22478404641151428, 1.013879656791687, 0.08258640766143799, 0.14100606739521027, 0.5211135745048523, 0.21043501794338226, -0.06400111317634583, 0.2500440180301666, -0.22274674475193024, 0.18250539898872375, -0.6899891495704651, 0.24277888238430023, 0.18471257388591766, 0.8501114249229431, -0.4811086356639862, 0.41503843665122986, -1.3046875, -0.14646585285663605, 1.3490471839904785, 0.36815372109413147, 0.24930556118488312, -0.5850712656974792, 0.16164807975292206, -0.45047953724861145, 0.8449466228485107, -0.2657056748867035, -0.1840599626302719, 0.032816123217344284, -0.39003410935401917, -0.9898881316184998, -0.4034252166748047, -0.14615730941295624, -0.6425712704658508, 0.5560853481292725, -0.2451338768005371, -0.1274407058954239, 0.011928495950996876, 0.519332766532898, 0.3056354224681854, 0.31134361028671265, 0.46556350588798523, -0.2866283059120178, 0.6480376720428467, -0.028407568112015724, -0.4700976610183716, -1.0466880798339844, 0.9558048844337463, -0.18488426506519318, 0.18475262820720673, -0.17983990907669067, -1.131753921508789, -0.426551878452301, -0.6449730396270752, 0.36428308486938477, -0.22061879932880402, 0.2674179971218109, 0.7630587816238403, 0.9322326183319092, -0.9169299602508545, 0.29911354184150696, 0.03097405470907688, -0.2814424932003021, 0.30349165201187134, 0.0054895514622330666, 0.23661622405052185, -0.4163198173046112, -1.3267004489898682, 0.20598886907100677, 0.3244243860244751, -0.829856276512146, -0.3332241475582123, -0.10122314840555191, -1.6427907943725586, -0.3264509439468384, 0.5721523761749268, 0.07454554736614227, 1.4425666332244873, 0.4004676938056946, -0.8341200947761536, 0.660148561000824, -0.130962073802948, 0.1709078848361969, 0.4238387644290924, -0.24737463891506195, -1.094706654548645, -0.41103312373161316, -0.004849558230489492, 0.18300513923168182, 0.4116468131542206, -0.5355382561683655, -0.04588586837053299, 0.5494324564933777, -0.042748719453811646, -0.5122144222259521, -0.05923409387469292, 1.4096333980560303, 0.0477202832698822, -0.00901256687939167, -0.3719688057899475, 0.7876150608062744, -0.29569104313850403, -0.3541232943534851, -0.8111670017242432, -0.7735336422920227, 0.6593857407569885, -0.3358533978462219, 1.3475441932678223, -0.8864487409591675, -1.2421565055847168, 0.0587146170437336, -0.4187173545360565, 0.4252612292766571, -0.546959638595581, 0.4332658350467682, -0.4317481517791748, 0.9654968976974487, -0.5171109437942505, -0.6453853249549866, 0.0973203033208847, -0.47331398725509644, -1.0017874240875244, 0.06773240119218826, -0.04281521216034889, 0.8826069235801697, -0.6936896443367004, -0.03358801454305649, 0.22720715403556824, 0.03738725930452347, -0.8779792785644531, 1.200774073600769, -0.5397443771362305, 0.36778149008750916, -0.26622751355171204, 0.32259032130241394, 0.3030328154563904, -0.055472224950790405, 0.1377650797367096, 0.15606817603111267, -0.27460044622421265, 0.29729655385017395, 0.006003945134580135, 0.967980146408081, -0.10007765144109726, 0.03336002677679062, 0.12929879128932953, -0.16180285811424255, 0.002182961907237768, 0.8549467921257019, -0.056989673525094986, -0.5476324558258057, 0.24169021844863892, 0.3830447793006897, -0.7784807682037354, -0.21835198998451233, 0.4631552994251251, 0.8517246842384338, -0.5918018221855164, 0.5124906897544861, 0.014900446869432926, -0.047290731221437454, 0.5029692649841309, 0.27425578236579895, 0.9440344572067261, 0.34588733315467834, 0.5977917909622192, -0.13480988144874573, 0.45605969429016113, -0.6994162201881409, 0.0761326476931572, 0.6960687041282654, 0.19935539364814758, 0.48621493577957153, 0.3836027979850769, -0.7904819250106812, 0.18847452104091644, -0.10385680198669434, 0.41554197669029236, 1.1961584091186523, -0.11216557025909424, -0.17579208314418793, -0.7800284624099731, -1.0860735177993774, -0.12089458853006363, 0.762603759765625, -0.09919426590204239, -0.11917434632778168, -0.748791515827179, -0.8536854982376099, 0.8034317493438721, -0.012051357887685299, 0.4834102392196655, -0.7732593417167664, -0.31225863099098206, -0.44980746507644653, 0.2515621483325958, -0.9783210754394531, -0.5593090653419495, -0.15315373241901398, -0.11761325597763062, -0.27184557914733887, 0.3157040476799011, 0.33716249465942383, 0.4346619248390198, -0.6886957883834839, 0.7854031324386597, -0.079953134059906, -0.4362040162086487, 0.5278584361076355, 0.3273220360279083, -0.06684742867946625, -1.0665152072906494, -0.32601669430732727, 0.14860713481903076, -0.36773377656936646, 0.5585816502571106, 0.8326985239982605, 0.24148029088974, 0.3985230326652527, -0.9194633960723877, -0.5343299508094788, 0.15287867188453674, -0.11168726533651352, -0.11853749305009842, -0.554612398147583, -0.11043710261583328, -1.2909295558929443, 1.2552186250686646, -0.1326187551021576, -0.660112738609314, 0.41401514410972595, -0.7806499004364014, -0.3741408586502075, 0.5173998475074768, -0.42322972416877747, -0.29448559880256653, -1.2296762466430664, 0.2217816561460495, 0.3787320852279663, -0.7404188513755798, 0.13774709403514862, 0.3627539575099945, 0.18543797731399536, 0.5589229464530945, 0.4624756872653961, -0.09595930576324463, -0.06291470676660538, 0.44948577880859375, -0.24154214560985565, 0.17730921506881714, -0.1247948706150055, 0.22324949502944946, -0.2347068041563034, -0.7942178845405579, -0.6435570120811462, -0.24118290841579437, -0.020474949851632118, 0.49444901943206787, -0.010316907428205013, -0.043442707508802414, -0.2264244109392166, -0.8393875360488892, -0.2848760783672333, -1.2061727046966553, -0.2777576148509979, 0.19459423422813416, -0.32733267545700073, 0.06891066581010818, -0.5419037938117981, -1.3101017475128174, -1.131803274154663, -0.46519914269447327, -0.9681221842765808, 0.8402241468429565, -0.3352433443069458, -0.876117467880249, -0.19825825095176697, -0.010454385541379452, -0.288627564907074, 0.6153028011322021, -0.4851326048374176, 1.056993007659912, -0.21501852571964264, -0.13846836984157562, -0.44868817925453186, 0.16838736832141876, 0.20483696460723877, -0.14055807888507843, 0.4891326129436493, -0.6882659792900085, -0.2070550173521042, -0.07985735684633255, -0.36550799012184143, -0.249843567609787, 0.20519649982452393, 0.541583776473999, -0.2115783840417862, -0.5545781254768372, -0.10716076195240021, 0.9453272819519043, -0.37921079993247986, 0.06715582311153412, 0.06565463542938232, 0.6311303377151489, 0.588463306427002, 0.17422309517860413, 0.7345020771026611, -0.14865358173847198, 0.454967737197876, -0.062470000237226486, -0.04064767435193062, 0.49481070041656494, -0.25930437445640564, 0.9052416086196899, 0.6350587010383606, 0.7224587798118591, -0.2602398097515106, -1.0916491746902466, 0.42482826113700867, -1.2474108934402466, -0.3059218227863312, 0.5810461640357971, 0.9527759552001953, 0.23855498433113098, -0.11446180194616318, -0.3011183738708496, -0.07682093232870102, 0.5846989750862122, 0.18436351418495178, 0.024562014266848564, -0.7827231287956238, 0.13175037503242493, 0.08960133790969849, -0.03861837834119797, 0.8582333922386169, -0.6278228163719177, 0.5389038324356079, 15.472884178161621, 0.6295448541641235, -0.10240600258111954, 0.5721399784088135, 0.85165935754776, 0.5380933880805969, -0.6346999406814575, -0.0863630622625351, -1.1661628484725952, 0.08575647324323654, 1.2894620895385742, 0.29428309202194214, 0.30408042669296265, 0.052118778228759766, 0.1422298103570938, -0.04790337756276131, -0.4566003084182739, 0.23418453335762024, 0.5138782262802124, -0.7235140800476074, 0.38392406702041626, 0.19687314331531525, 0.12312470376491547, 0.21795280277729034, 0.8175467848777771, 0.8993271589279175, 0.7761359810829163, -0.49608054757118225, 0.7830453515052795, -0.33630797266960144, 1.1184697151184082, 0.05744082108139992, 0.48386475443840027, 0.7584492564201355, -0.14281249046325684, -0.22044183313846588, -0.4301675260066986, -0.9074733257293701, 0.38116762042045593, 0.261910617351532, -0.7473544478416443, -0.21676072478294373, -0.48782727122306824, 0.32916808128356934, 0.22902609407901764, 0.26286470890045166, -0.48602160811424255, 1.0327125787734985, 0.0732228234410286, 0.14240074157714844, 0.007300466299057007, 0.5987245440483093, 0.48346126079559326, 0.11316973716020584, 0.020128857344388962, -0.014556463807821274, 0.4953992962837219, 0.42327263951301575, -0.2685905396938324, -0.07426176220178604, -0.7333515286445618, -0.3002875745296478, 0.03710487112402916, 0.5544941425323486, 0.5913513898849487, 0.2857278287410736, -0.4352317154407501, 0.14649872481822968, 0.4206830859184265, 0.451552152633667, -0.30128782987594604, 0.45810607075691223, 0.5559682846069336, -0.11592559516429901, -0.703953206539154, 0.39926621317863464, -0.22622531652450562, -0.6545265316963196, -0.5732970237731934, -0.5711098909378052, 0.6728590726852417, -0.5151958465576172, -0.7743269801139832, 0.8631095290184021, -0.1516718715429306, -0.7609958052635193, -0.05432663857936859, -0.7373989224433899, -0.048709772527217865, 0.14748691022396088, -1.2173304557800293, -0.8581363558769226, 0.7088099718093872, -0.47909480333328247, -0.5718037486076355, -0.053872548043727875, 1.56035578250885, 0.1548743098974228, -0.7130232453346252, 0.15632887184619904, -0.11933552473783493, -0.15651246905326843, 0.30989494919776917, -0.5336140394210815, 0.9287401437759399, 0.697765052318573, -0.4112667441368103, 0.525867760181427, 0.24233607947826385, -0.5108602643013, -0.5167425870895386, -0.37114807963371277, 0.5708221793174744, -1.4065247774124146, -0.28929564356803894, -0.9375342726707458, -0.7444009780883789, 0.3984079360961914, 0.2542096972465515, 0.06772015243768692, 0.5921093225479126, 0.01726226881146431, -0.5381726026535034, 0.33597251772880554, -1.264931321144104, 0.23704653978347778, 0.47083044052124023, -0.9448920488357544, -0.21314510703086853, 0.14168065786361694, 0.4178217053413391, -0.9784333109855652, -0.21865765750408173, 0.16579079627990723, -0.14886148273944855, -0.1605248898267746, 0.4456745982170105, -0.818534791469574, 0.4340471029281616, 0.643055260181427, -0.022957371547818184, -0.6170748472213745, -0.13987788558006287, -1.2249951362609863, -0.042689595371484756, 0.1287950724363327, 0.9233174324035645, -0.6605048179626465, -0.07621431350708008, 1.6743955612182617, 0.24430647492408752, -0.21517258882522583, -0.7706805467605591, -0.16855314373970032, 0.014997140504419804, -0.5579678416252136, 0.48151588439941406, 0.1386903077363968, 0.4198310673236847, -0.2569771707057953, 0.13067597150802612, 0.8495011329650879, -0.377512663602829, -0.6897166967391968, 0.1562608927488327, 0.040231116116046906, -0.004409770015627146, -0.47867175936698914, -0.29486843943595886, -1.0726979970932007, 0.2734808623790741, -0.7297443747520447, 0.22878029942512512, -0.513204038143158, -0.47380223870277405, 0.18483500182628632, -0.05782958120107651, 0.24821841716766357, 0.344097375869751, -0.6231887936592102, -0.8825270533561707, -0.47037994861602783, -0.5897042751312256, 0.5570767521858215, 0.21068856120109558, -0.8113346099853516, 0.13024432957172394, -0.05875198170542717, -0.24361556768417358, 0.07895537465810776, 0.23978228867053986, -0.5846120119094849, -0.455013245344162, -1.220266580581665, 0.0971355214715004, 0.009763428010046482, -0.025338809937238693, -0.34419819712638855, 0.20321732759475708, -0.06860098242759705, -0.4076533913612366, 0.44425201416015625, -0.10593517124652863, -1.1424474716186523, -0.6895450949668884, 0.4468534588813782, -0.8017892837524414, -0.10441462695598602, 0.5173243284225464, -0.7266478538513184, -0.18724589049816132, 0.5579933524131775, -0.2502122223377228, -0.7215951681137085, -0.2183564007282257, 0.4946894645690918, -0.8845816850662231, -0.05659440904855728, 0.16123725473880768, 0.215469628572464, -1.4143412113189697, -0.17296138405799866, 0.19931133091449738, 0.48829028010368347, -0.20405380427837372, 1.1780264377593994, 0.362933486700058, -0.8930850625038147, -0.15183518826961517, 0.5593184232711792, -0.0030840530525892973, -0.4579908549785614, 0.2044302225112915, 0.24630619585514069, -0.3354799747467041, 0.6322420239448547, 0.40864992141723633, 0.4368756413459778, -0.6343005299568176, 0.20984937250614166, 0.3782854378223419, -0.28647392988204956, 0.005195179022848606, 0.7501838803291321, -0.06814933568239212, -0.9350578188896179, 0.14332160353660583, -1.2422503232955933, -0.46377694606781006, -1.121598243713379, 0.7302242517471313, 0.17724314332008362, 0.12779581546783447, -0.247113436460495, -0.6467803716659546, -0.19154635071754456, -0.2136722058057785, -0.760904848575592, 0.07191736996173859, 0.11109233647584915, -0.3993702828884125, 0.03719712793827057, 0.29237207770347595, -0.033503878861665726, -0.19152061641216278, -0.005545681808143854, 0.07436371594667435, -0.3386225700378418, 0.11851068586111069, -0.6245493292808533, -0.23355592787265778, 0.3981979489326477, 0.5233126878738403, 0.579265296459198, -0.13495710492134094, -0.27673742175102234, 0.19216269254684448, 0.4501389265060425, 0.6266347169876099, -0.3894527554512024, -1.007580041885376, 0.8195978403091431, 1.1811120510101318, -1.2026727199554443, 0.2137192040681839, -0.5762272477149963, -0.4499965310096741, 0.3673938512802124, 0.6672006249427795, 0.39809921383857727, 0.6937206983566284, 0.048118706792593, 0.32756802439689636, 0.12624578177928925, -0.4193223714828491, 0.06651195138692856, 0.6394675970077515, 0.7131496071815491, 1.1305408477783203, 0.7710027694702148, -0.4772053360939026, 0.8128141760826111, 0.5974317193031311, 0.36788657307624817, 0.8375300765037537, 0.8622228503227234, -0.25922611355781555, -0.5196492075920105, -0.30778250098228455, 0.5903313755989075, -0.647828221321106, -0.5275214910507202, -0.29406994581222534, 0.519729495048523, 0.0947687178850174, 0.6280928254127502, 0.246199369430542, -0.021826980635523796, 0.7097197771072388, 0.3823445439338684, 0.0752127394080162, -0.9082308411598206, -0.2780737578868866, -0.17995978891849518, -0.23580315709114075, -0.36952853202819824, 0.3051495850086212, -0.48825132846832275, -0.29447141289711, -0.1522880345582962, 0.5200265645980835, 0.09366555511951447, -0.18563921749591827, 1.0616600513458252, 0.6300032734870911, -0.10907381027936935, -0.43342629075050354, -0.0278805959969759, -0.7158673405647278, -0.8277933597564697, -0.10832008719444275, -0.4866241216659546, -0.03769447281956673, -0.146632120013237, -0.01084834709763527, -0.6660005450248718]}, "authors": [{"authorId": "2144071564", "name": "Tinghao Xie"}, {"authorId": "2111683101", "name": "Xiangyu Qi"}, {"authorId": "2297444637", "name": "Yi Zeng"}, {"authorId": "2283305597", "name": "Yangsibo Huang"}, {"authorId": "2307917108", "name": "Udari Madhushani Sehwag"}, {"authorId": "2242535459", "name": "Kaixuan Huang"}, {"authorId": "2294507804", "name": "Luxi He"}, {"authorId": "2283309803", "name": "Boyi Wei"}, {"authorId": "2265517766", "name": "Dacheng Li"}, {"authorId": "2307918402", "name": "Ying Sheng"}, {"authorId": "2254249161", "name": "Ruoxi Jia"}, {"authorId": "2304013785", "name": "Bo Li"}, {"authorId": "2307916744", "name": "Kai Li"}, {"authorId": "50536468", "name": "Danqi Chen"}, {"authorId": "2254262712", "name": "Peter Henderson"}, {"authorId": "2254282852", "name": "Prateek Mittal"}], "references": [{"paperId": "c3f1fae241a3c2449e675ab750873d800f95513c", "title": "SimPO: Simple Preference Optimization with a Reference-Free Reward"}, {"paperId": "dfc9bb24627d1dd61c8d495cd86a874a2a1130ad", "title": "ALERT: A Comprehensive Benchmark for Assessing Large Language Models' Safety through Red Teaming"}, {"paperId": "88d5634a52645f6b05a03536be1f26a2b9bba232", "title": "Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks"}, {"paperId": "c9c0324fcdc92cf7e24f9c4230864851a552f953", "title": "JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models"}, {"paperId": "b26602dd5ec777659ce46fec86da132ac680d2ee", "title": "Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?"}, {"paperId": "7ea5e86bbbcc445eca1a765deb314eefc06067b8", "title": "Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts"}, {"paperId": "f2e88c26bc1ebdd4adc5f83ab56cb4276120745d", "title": "A StrongREJECT for Empty Jailbreaks"}, {"paperId": "868fcbc6127e9cf79990e92116ec482051d470f3", "title": "SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models"}, {"paperId": "b82ccc66c14f531a444c74d2a9a9d86a86a8be99", "title": "HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal"}, {"paperId": "732ce53c573475f2691a7cfc716cf4f568d17360", "title": "How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs"}, {"paperId": "e762f92273cd96f63b7788c0173b9b6450adedd7", "title": "Defending ChatGPT against jailbreak attack via self-reminders"}, {"paperId": "c11ac248290acf6bba414cd6d6be25df6c7eacf4", "title": "SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in Large Language Models"}, {"paperId": "a7741b2753134653861ec0b82f617875c0ebd96e", "title": "ToxicChat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-AI Conversation"}, {"paperId": "ac27dd71af3ee93e1129482ceececbae7dd0d0e8", "title": "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation"}, {"paperId": "1a9f394b5b7f5bcdecee487174a3f4fc65d30e33", "title": "Multilingual Jailbreak Challenges in Large Language Models"}, {"paperId": "0e0e706e13f160e74cac9556f28ab9a358c148d2", "title": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!"}, {"paperId": "a4c921bdef167ae54cc3a40643e6e3ed13d49a61", "title": "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions"}, {"paperId": "9b9a4fa3ed510fc6eb1bf831979235f3d9f8b556", "title": "SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions"}, {"paperId": "288063323dddad9bea7eb1230a2048546435687e", "title": "Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs"}, {"paperId": "897940fb5dd4d739b88c4659c4565d05f48d06b8", "title": "GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher"}, {"paperId": "b67eb8213a63be8a4b0274728ffdc50bfa109e10", "title": "XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models"}, {"paperId": "47030369e97cc44d4b2e3cf1be85da0fd134904a", "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "0d1c76d45afa012ded7ab741194baf142117c495", "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"}, {"paperId": "fc50a6202e2f675604543c1ae4ef22ec74f61ad5", "title": "Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study"}, {"paperId": "b1b8c3e47f44158d22fb70bb453d2494ed013b70", "title": "On Second Thought, Let\u2019s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "7d5c661fa9a4255ee087e861f820564ea2e2bd6b", "title": "BBQ: A hand-built bias benchmark for question answering"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "399e7d8129c60818ee208f236c8dda17e876d21f", "title": "RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "b91c4edd30b63cd1cb1b86cbeefb33a461535e09", "title": "Build it Break it Fix it for Dialogue Safety: Robustness from Adversarial Human Attack"}, {"paperId": "9e463eefadbcd336c69270a299666e4104d50159", "title": "A Coefficient of Agreement for Nominal Scales"}, {"paperId": null, "title": "do anything now"}, {"paperId": null, "title": "Towards harmlessness evaluation and analysis for"}, {"paperId": null, "title": "Gemini: A family of highly capable multimodal models"}, {"paperId": null, "title": "Llama Team"}, {"paperId": null, "title": "second"}]}