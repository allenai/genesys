{"paperId": "dd1139cfc609c2f3263d02e97176d5275caebc0a", "abstract": "Vision Transformers (ViT) have shown rapid progress in computer vision tasks, achieving promising results on various benchmarks. However, due to the massive number of parameters and model design, \\textit{e.g.}, attention mechanism, ViT-based models are generally times slower than lightweight convolutional networks. Therefore, the deployment of ViT for real-time applications is particularly challenging, especially on resource-constrained hardware such as mobile devices. Recent efforts try to reduce the computation complexity of ViT through network architecture search or hybrid design with MobileNet block, yet the inference speed is still unsatisfactory. This leads to an important question: can transformers run as fast as MobileNet while obtaining high performance? To answer this, we first revisit the network architecture and operators used in ViT-based models and identify inefficient designs. Then we introduce a dimension-consistent pure transformer (without MobileNet blocks) as a design paradigm. Finally, we perform latency-driven slimming to get a series of final models dubbed EfficientFormer. Extensive experiments show the superiority of EfficientFormer in performance and speed on mobile devices. Our fastest model, EfficientFormer-L1, achieves $79.2\\%$ top-1 accuracy on ImageNet-1K with only $1.6$ ms inference latency on iPhone 12 (compiled with CoreML), which runs as fast as MobileNetV2$\\times 1.4$ ($1.6$ ms, $74.7\\%$ top-1), and our largest model, EfficientFormer-L7, obtains $83.3\\%$ accuracy with only $7.0$ ms latency. Our work proves that properly designed transformers can reach extremely low latency on mobile devices while maintaining high performance.", "venue": "Neural Information Processing Systems", "year": 2022, "citationCount": 214, "influentialCitationCount": 31, "openAccessPdf": {"url": "http://arxiv.org/pdf/2206.01191", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work proves that properly designed transformers can reach extremely low latency on mobile devices while maintaining high performance."}, "embedding": {"model": "specter_v2", "vector": [0.6447206735610962, 0.5906105637550354, -0.6002752184867859, 0.35267046093940735, 0.12561194598674774, -0.0886603519320488, 0.5619397759437561, -0.6574104428291321, -0.478511780500412, -0.9741701483726501, 0.2305339276790619, -0.048480886965990067, 0.7035659551620483, -0.013543559238314629, -0.0822388082742691, 0.1929033249616623, -0.6450856924057007, -0.18413636088371277, 0.3570134937763214, 0.025221941992640495, 0.2593533992767334, -0.3660464286804199, -1.5076546669006348, 0.07878755033016205, 0.05384073033928871, 1.383162021636963, 0.20620854198932648, 1.1985872983932495, -0.19056054949760437, 0.6736926436424255, 0.5941291451454163, -0.5329294204711914, 0.44593381881713867, 0.2154051512479782, -0.10953420400619507, -0.10328436642885208, 0.841221809387207, -0.5128797292709351, -0.5290742516517639, 1.0493409633636475, 0.014491258189082146, -0.10751745849847794, 0.04554826766252518, -0.9729365110397339, 0.09845469892024994, 0.2962874174118042, 0.40357518196105957, 0.7744853496551514, -1.0169734954833984, -0.11420009285211563, 1.3214995861053467, -1.2003496885299683, 0.04227002337574959, 1.5241788625717163, 0.5474044680595398, 0.32681435346603394, -0.1739221066236496, -0.6513897776603699, 0.8888868689537048, 0.33506202697753906, -0.5411810278892517, -0.8436664342880249, -0.034559380263090134, -0.002109955996274948, 1.8268262147903442, -0.6775119304656982, 0.20193009078502655, 0.7062988877296448, 0.3398474454879761, 1.0674974918365479, -0.10425977408885956, -0.5037190318107605, 0.1066407710313797, -0.3593269884586334, 0.05431103706359863, 0.9430788159370422, 0.16655603051185608, 0.2334636002779007, -0.985481321811676, 0.19339653849601746, 0.6426914930343628, -0.045631714165210724, 0.2748253643512726, -0.5155699849128723, -0.2469390332698822, 0.6988351941108704, 0.5729637742042542, 0.4038536548614502, -0.2910718321800232, 1.2750626802444458, 0.6110315322875977, 0.16869789361953735, -0.26136907935142517, 0.30095475912094116, -0.21446053683757782, 0.5887887477874756, -0.5776060223579407, -0.1627403348684311, -0.29478445649147034, 0.9195664525032043, -0.4398896396160126, 0.527579665184021, -0.37841734290122986, 0.014831868931651115, 1.364508867263794, 0.5607603788375854, -0.020835138857364655, -0.7575698494911194, 0.0408795028924942, -0.8197363018989563, -0.07626239955425262, -0.7805572152137756, 0.03282824903726578, -0.250053733587265, -1.1446162462234497, -0.5592542290687561, -0.6577385663986206, 0.41688212752342224, -1.10796058177948, 0.45539024472236633, -0.49867790937423706, 0.6286219954490662, -0.1983102411031723, 0.2994919419288635, 0.5097917914390564, 0.4288026988506317, 0.1372700184583664, 0.18078608810901642, 1.2390575408935547, -1.0382380485534668, -0.4646672308444977, -1.2256622314453125, -0.037038132548332214, -0.10666768997907639, 0.14902198314666748, 0.2514488697052002, -1.007129430770874, -1.3589043617248535, -1.0494945049285889, 0.09731272608041763, -0.2999931275844574, 0.06595565378665924, 1.1678985357284546, 0.5540416836738586, -1.4813309907913208, 0.42287805676460266, -0.40345367789268494, -0.14663204550743103, 0.4923451840877533, 0.23351620137691498, 0.5913596153259277, -0.19683954119682312, -0.4568255841732025, 0.2973964810371399, -0.1876583844423294, -0.446165531873703, -0.7176555395126343, -0.5591792464256287, -1.0319989919662476, 0.09855353832244873, 0.3642187714576721, -0.8340460062026978, 1.314206838607788, -0.18682028353214264, -0.9453617930412292, 0.573155403137207, -0.4561921954154968, -0.26933252811431885, -0.24985072016716003, -0.06323447823524475, -0.1343589574098587, 0.05772785842418671, -0.4121784269809723, 0.7066962122917175, 1.292601466178894, 0.01852877251803875, -0.5752809047698975, 0.4817754328250885, -0.05590347945690155, -0.5090619325637817, -0.1950284242630005, 1.0022927522659302, -0.9602780342102051, -0.11025740951299667, 0.5338383316993713, 0.7223097085952759, -0.4306042194366455, 0.3872203230857849, -0.025002188980579376, -0.5201486945152283, 0.6635738611221313, 0.22745218873023987, 0.8236785531044006, -0.9040734171867371, -0.8489365577697754, 0.1125088483095169, 0.44563373923301697, 0.03575781360268593, -0.9455088376998901, 0.044043559581041336, -0.36597946286201477, 0.09442321211099625, 0.440845251083374, -1.0146175622940063, 0.2196628898382187, -0.48464253544807434, -0.7168113589286804, 0.07403097301721573, 0.07143587619066238, 1.248831868171692, -0.6389981508255005, -0.2669064402580261, 0.25862905383110046, 0.4170900285243988, -1.1706331968307495, 0.947263777256012, -0.1738823801279068, -0.14267227053642273, -0.013391410000622272, 0.2536841928958893, 0.16440936923027039, -0.6142409443855286, 0.6704085469245911, -1.037333369255066, -0.07567424327135086, 0.39076027274131775, -0.37037691473960876, 1.358536958694458, -0.40824809670448303, 0.871561586856842, 0.06428004801273346, -0.903920590877533, 0.4251716732978821, 0.1480986773967743, -0.22596706449985504, -1.0076563358306885, 0.7453494668006897, 0.03686600178480148, -0.708375096321106, 0.4697798490524292, 0.6006730794906616, 1.4754667282104492, -0.13498921692371368, -0.17788808047771454, 0.635371744632721, -0.21284446120262146, -0.10320942103862762, 0.28557297587394714, 0.9588514566421509, 0.0801052674651146, 0.2673676908016205, -0.20159198343753815, 0.10367947816848755, -1.2661547660827637, 0.14240019023418427, 0.8091094493865967, 0.294960081577301, 0.7653513550758362, 0.7376998662948608, -0.9050264954566956, -0.35852402448654175, -0.23497813940048218, 0.68349689245224, 0.9492806196212769, 0.05788961425423622, -0.2308848649263382, -0.5475226044654846, -0.275572806596756, -0.8575056195259094, -0.5093643069267273, -0.15376874804496765, -0.12697401642799377, -0.21931658685207367, -0.7338120937347412, 0.8921251893043518, 0.18821832537651062, 1.401892066001892, -0.4382951557636261, -0.8952098488807678, -0.5283517837524414, 0.20524339377880096, -1.0648216009140015, -0.4500216245651245, 0.2131507694721222, -0.677008867263794, -0.5617456436157227, 0.15888474881649017, -0.2827916443347931, 0.1139708012342453, -0.3745865821838379, 1.0357815027236938, -0.2908816933631897, -0.4820311665534973, 0.307513952255249, 0.5137370228767395, -0.6619754433631897, -0.06516167521476746, -0.04788576439023018, -0.012964627705514431, -0.016027651727199554, -0.07690194994211197, 0.13781164586544037, -0.3243444561958313, -0.040835972875356674, -0.08684508502483368, 0.14683668315410614, 0.16730919480323792, -0.03749741613864899, 0.8027858734130859, -0.3633714020252228, -0.30927175283432007, -0.6757833361625671, 0.319452166557312, 0.5850887298583984, -0.874127984046936, 0.08650919049978256, -0.8968396186828613, -0.022549916058778763, 0.0245819054543972, -0.5954605340957642, 0.2026520073413849, -0.7223497629165649, 0.19899560511112213, -0.8220483660697937, 0.15594270825386047, -0.44819730520248413, 0.18082132935523987, -0.3483673632144928, 0.26517048478126526, 0.273629367351532, 0.132747083902359, 0.13232754170894623, 0.32604146003723145, -1.0410232543945312, 0.7720392346382141, 0.37758463621139526, 0.14373721182346344, 0.10746443271636963, 0.030997373163700104, -0.6721663475036621, -0.28210413455963135, -0.2370917797088623, 0.15928225219249725, -0.5352731347084045, 0.2510661780834198, -0.773957371711731, -1.180504560470581, 0.2155672162771225, -1.0660690069198608, -0.1700378656387329, 0.13733138144016266, -0.21320568025112152, -0.15070225298404694, -1.0852097272872925, -0.774631679058075, -0.4427465796470642, -1.0510133504867554, -1.4137367010116577, 0.39052850008010864, 0.356896311044693, -0.11344143748283386, -0.2741716504096985, -0.22924081981182098, -0.754820704460144, 1.0217632055282593, -0.4097437560558319, 0.709082305431366, 0.2506001591682434, -0.7460744380950928, 0.34199216961860657, -0.2647886574268341, 0.27719464898109436, -0.6608747243881226, 0.3616424798965454, -1.2984145879745483, 0.3306359350681305, -0.4072411358356476, -0.20848742127418518, 0.4004659652709961, 0.7714983820915222, 0.6092075705528259, 0.17543810606002808, -0.3264966309070587, 0.9846132397651672, 1.6384556293487549, -0.5584760308265686, 0.6203631162643433, 0.2070603221654892, 1.0254062414169312, -0.26663216948509216, -0.21724000573158264, 0.6512343287467957, 0.31740957498550415, 0.15507403016090393, 0.7797075510025024, -0.4510897696018219, -0.40179380774497986, -0.6097267270088196, 0.3239746689796448, 1.014915108680725, 0.5129454135894775, 0.06302092969417572, -0.7431384325027466, 0.806652843952179, -1.139093279838562, -0.5232051014900208, 0.7518397569656372, 0.5607491135597229, -0.1573135107755661, 0.10271649062633514, -0.40907424688339233, 0.012206916697323322, 0.5231264233589172, 0.8755016326904297, -0.44373178482055664, -0.9960048794746399, 0.18198087811470032, 0.9872023463249207, 0.8051910400390625, 0.4805969297885895, -0.20473456382751465, 0.623446524143219, 14.654648780822754, 0.7933377623558044, -0.3521638810634613, 0.47241511940956116, 0.5158072113990784, 0.457099586725235, -0.3876475691795349, 0.36335277557373047, -1.1027097702026367, -0.31760597229003906, 1.0093125104904175, 0.4110393226146698, 0.367813378572464, 0.3392360508441925, -0.17084574699401855, 0.05893881618976593, -0.39142918586730957, 1.197872519493103, 0.5549067854881287, -1.6431313753128052, 0.16578617691993713, 0.1793878972530365, -0.010411389172077179, 0.5148457288742065, 0.8861650228500366, 0.5669410228729248, 0.40260469913482666, -0.2718150317668915, 0.6955986022949219, 0.11774634569883347, 1.432379961013794, -0.07006875425577164, 0.21531948447227478, 0.04990082606673241, -1.4576940536499023, 0.1446513533592224, -0.7858225703239441, -1.1122996807098389, -0.026674071326851845, 0.02831828035414219, -0.16793906688690186, -0.783006489276886, 0.27030059695243835, 0.9198459386825562, -0.10007794946432114, 0.6553516983985901, -0.3852201998233795, 0.48998895287513733, -0.31235045194625854, 0.1301771104335785, 0.08801160752773285, 0.6825854182243347, -0.2060869336128235, -0.33312416076660156, -0.18862129747867584, -0.28652331233024597, -0.0504581481218338, 0.34096559882164, -0.43815627694129944, -0.7987000346183777, -0.4882369637489319, -0.14252233505249023, -0.007456143852323294, 0.83571857213974, -0.2110535353422165, 0.5088176131248474, -0.15814611315727234, 0.13679873943328857, 0.07349500060081482, 0.033564433455467224, -0.7003893256187439, -0.02645755186676979, 0.6653292179107666, -0.8182799220085144, 0.38407617807388306, 0.48970553278923035, -0.3203798234462738, -0.7505477070808411, -0.9026007056236267, -0.7691414952278137, 0.39134564995765686, -0.8506582975387573, 0.09488915652036667, 0.8153616189956665, -0.27787458896636963, -0.3628171384334564, 0.5724408626556396, -0.9779776334762573, -0.26600712537765503, 0.05153606832027435, -1.6026548147201538, -0.9500255584716797, 0.22600075602531433, -0.08122134953737259, -0.05354053154587746, -0.08828689903020859, 1.1355810165405273, 0.07802913337945938, -0.1593855917453766, 0.30157914757728577, -0.5047798156738281, -0.16962061822414398, -0.3747953772544861, -0.34998923540115356, 1.3186458349227905, 0.9242545366287231, 0.18575911223888397, -0.1179228276014328, 0.12370645999908447, 0.5051537156105042, -0.9609435796737671, 0.16670915484428406, 0.5767767429351807, -0.5588679909706116, -0.22981099784374237, -0.7556609511375427, -0.08376201242208481, 0.386971652507782, 0.6188006401062012, -0.0017004607943817973, -0.20764108002185822, 0.09791760891675949, -0.9940540194511414, -0.4466618597507477, -0.5419901609420776, 0.26162979006767273, 0.5166692137718201, -0.7925950884819031, -0.0020096800290048122, -0.6517434120178223, 0.30409547686576843, -0.9323309063911438, -0.26146894693374634, -0.035614073276519775, 0.41597044467926025, -0.5220722556114197, 1.339629888534546, 0.19694605469703674, 0.39218586683273315, 0.8127824068069458, -0.05747257173061371, -0.49263474345207214, 0.04864047095179558, -1.0880578756332397, 0.10016526281833649, 0.004304887261241674, 0.32446038722991943, -0.5474507808685303, 0.3898075520992279, 0.30010125041007996, 0.3165864050388336, -0.32812532782554626, -0.5804396271705627, 0.05236784368753433, -0.6460316777229309, -0.8731112480163574, 0.1901428997516632, -0.486701637506485, -0.4506058394908905, 0.13161063194274902, 0.2264833003282547, 0.6398065090179443, 0.2797435224056244, -0.5805802941322327, 0.4600033760070801, 0.02167201228439808, -0.2955872714519501, -0.3437997102737427, -0.9492778182029724, -1.5562776327133179, -0.29005733132362366, -0.5936131477355957, 0.0541071817278862, -0.9635950922966003, -0.8672136664390564, 0.13496291637420654, -0.1534881740808487, 0.03164805471897125, 0.5917787551879883, -0.05626225471496582, 0.004146427847445011, -0.743406355381012, -0.8007799983024597, 0.6023651957511902, 0.8192857503890991, -0.7813172340393066, 0.36595115065574646, -0.19734501838684082, -0.04522836580872536, 0.6769995093345642, 0.23290136456489563, -0.24682433903217316, -1.1579549312591553, -1.330711841583252, 0.6257303953170776, -0.3133104145526886, 0.0474986657500267, -1.0160417556762695, 1.0205349922180176, 0.4313265383243561, -0.24170422554016113, 0.024223996326327324, 0.3802936375141144, -1.006759762763977, -0.557428240776062, 0.6628325581550598, -0.41126349568367004, 0.24943025410175323, 0.4630573093891144, -0.5214471817016602, 0.044660504907369614, 0.8956855535507202, 0.28785815834999084, -0.8597389459609985, -1.4968897104263306, 0.4158746004104614, -0.5912758708000183, 0.1893012672662735, -0.5458772778511047, -0.3831665515899658, -1.3801411390304565, -0.32691308856010437, 0.20796552300453186, 0.1963358074426651, -0.4509141445159912, 0.8349016308784485, 0.9451056718826294, -0.718148946762085, 0.46432173252105713, 0.6141098141670227, -0.13406474888324738, -0.034669868648052216, 0.27848201990127563, 0.5086259841918945, -0.7599839568138123, 0.262906014919281, -0.14210377633571625, -0.1289931684732437, -0.732191264629364, 0.18959273397922516, 0.8086225986480713, -0.39811742305755615, -0.26785990595817566, 1.2577780485153198, -0.19657233357429504, -0.4081650674343109, 0.5623106360435486, -1.6418310403823853, -0.35168930888175964, -0.20985756814479828, 0.6001248359680176, -0.11326653510332108, 0.06839029490947723, 0.5061150789260864, -0.7408729791641235, 0.5089005827903748, 0.11102403700351715, -0.4501093626022339, 0.29927346110343933, -0.0507030226290226, -0.1564193218946457, 0.14488345384597778, 0.6157024502754211, -0.935967743396759, -0.9503605961799622, -0.8051936030387878, -0.6327875852584839, -0.23193643987178802, 0.6616106033325195, 0.0508929118514061, -1.1145377159118652, 1.03971266746521, 0.9862766861915588, -0.08683976531028748, 0.691314160823822, -0.27302852272987366, 0.12955132126808167, 0.621401846408844, 0.4660588502883911, -0.385799378156662, -0.3534044325351715, 1.1329467296600342, 0.839310348033905, -0.38960424065589905, 0.31325051188468933, -0.20308905839920044, -0.5000996589660645, 0.41587570309638977, 0.2990405559539795, -0.38686805963516235, 1.0536497831344604, 0.24436262249946594, 0.03796539828181267, 0.04797297716140747, -1.052674651145935, -0.6188108921051025, 0.6723815202713013, 1.2960606813430786, 0.14301469922065735, -0.26095861196517944, 0.5444806218147278, 0.5924214124679565, 0.3773998022079468, 0.042834099382162094, 0.24264337122440338, 0.5119763016700745, -0.17715251445770264, 0.23906929790973663, -0.15909744799137115, 0.49975165724754333, -0.568655252456665, -0.8413519859313965, 0.30973538756370544, 0.5360575318336487, 0.4233734905719757, 0.7340080142021179, 1.107958197593689, -0.3149200975894928, 0.9049049019813538, -0.42761242389678955, 0.6585513949394226, -0.31959068775177, -0.20225636661052704, 0.19084729254245758, -0.6942722797393799, -0.670724093914032, -0.2735135555267334, -0.17048299312591553, 0.1427692323923111, -0.6245735287666321, 0.23855946958065033, -0.40201810002326965, 0.2742745876312256, 0.725020706653595, 0.5305148959159851, 0.8883115649223328, -0.32874390482902527, -0.8167079091072083, -0.19090931117534637, -0.4221811294555664, 0.3107334077358246, -1.0524424314498901, -0.0021211111452430487, -0.2248351275920868, -0.23715434968471527, 0.13883115351200104]}, "authors": [{"authorId": "1527091497", "name": "Yanyu Li"}, {"authorId": "9347641", "name": "Geng Yuan"}, {"authorId": "2167854921", "name": "Yang Wen"}, {"authorId": "2167582358", "name": "Eric Hu"}, {"authorId": "143998839", "name": "Georgios Evangelidis"}, {"authorId": "145582202", "name": "S. Tulyakov"}, {"authorId": "2136922252", "name": "Yanzhi Wang"}, {"authorId": "2111473627", "name": "Jian Ren"}], "references": [{"paperId": "4247f45a5730e3bda5836e2bc7941e30f5b91cb7", "title": "Board"}, {"paperId": "4ce36fb3e0abfe5260d8cb70b5a83fdfbfdfa428", "title": "CrossFormer++: A Versatile Vision Transformer Hinging on Cross-Scale Attention"}, {"paperId": "d2f63b56fc6bc373f5c023454c2b253326962865", "title": "DeiT III: Revenge of the ViT"}, {"paperId": "f634a09747e4ca11754a9bfdccf7485c884f9f86", "title": "TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation"}, {"paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc", "title": "MaxViT: Multi-Axis Vision Transformer"}, {"paperId": "dae903091d2c5f82c4595e53e8144ccce93f8fb9", "title": "SepViT: Separable Vision Transformer"}, {"paperId": "28ed0086dd0f51a8965f7e952b6ee933cdf44179", "title": "Training-free Transformer Architecture Search"}, {"paperId": "75c642ebdcfbd4c16d6c3161130b72ff9af5c311", "title": "Three things everyone should know about Vision Transformers"}, {"paperId": "08b06339d025324171ab7fb8d764155cefa70409", "title": "Towards efficient vision transformer inference: a first study of transformers on mobile devices"}, {"paperId": "202967f77c4384bce80eaf2fa5737259008267d3", "title": "Learning to Merge Tokens in Vision Transformers"}, {"paperId": "3425495ee3b6ead009f35aeb70edeac4e6eb2d10", "title": "Patches Are All You Need?"}, {"paperId": "5ab70d95ca49702a3dd49b39d9396d8136b52311", "title": "Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space"}, {"paperId": "164e41a60120917d13fb69e183ee3c996b6c9414", "title": "Vision Transformer for Small-Size Datasets"}, {"paperId": "658a017302d29e4acf4ca789cb5d9f27983717ff", "title": "Masked-attention Mask Transformer for Universal Image Segmentation"}, {"paperId": "9137efc758f80dd22bb56f82cca5c94f78a5db3e", "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and Detection"}, {"paperId": "38212997a6e8c55141574c329bb58d2eadcb0db5", "title": "AdaViT: Adaptive Vision Transformers for Efficient Image Recognition"}, {"paperId": "e0d272e01929024f28f0f7cacf26177cd60b3ee7", "title": "Sparse DETR: Efficient End-to-End Object Detection with Learnable Sparsity"}, {"paperId": "da0d38cf2ac7e2a6908e0d9e1fff07058daab2ed", "title": "Sparse is Enough in Scaling Transformers"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "be0fbb810583930c071d0b9b2c5187fe260783f5", "title": "Swin Transformer V2: Scaling Up Capacity and Resolution"}, {"paperId": "aa8198b922216645c4be46408524f431ad571e78", "title": "Improving Visual Quality of Image Synthesis by A Token-based Generator with Transformers"}, {"paperId": "da74a10824193be9d3889ce0d6ed4c6f8ee48b9e", "title": "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer"}, {"paperId": "35992a67762af8897ea741b955718ab731004f2d", "title": "Smart Bird: Learnable Sparse Attention for Efficient and Effective Transformer"}, {"paperId": "a66686e60a3eda0c606e036403cf0a07a5962595", "title": "Mobile-Former: Bridging MobileNet and Transformer"}, {"paperId": "a5c41f188b0eb0acb444cb4899bf6af378ee9ede", "title": "CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention"}, {"paperId": "f75cddf2d42ed01b34686704eb3504becef67442", "title": "CycleMLP: A MLP-like Architecture for Dense Prediction"}, {"paperId": "0b036cd5dfc49d835d0c759c8ca31d89f2410e65", "title": "CMT: Convolutional Neural Networks Meet Vision Transformers"}, {"paperId": "bd163f27b409a4d903632009d38df77cfd70a437", "title": "ViTGAN: Training GANs with Vision Transformers"}, {"paperId": "d645bd08fc19d52164695f9cd5ae863345459a06", "title": "AutoFormer: Searching Transformers for Visual Recognition"}, {"paperId": "94eae578e6af3382f6449506965639f18aab3fa0", "title": "Video Swin Transformer"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "6b6ffb94626e672caffafc77097491d9ee7a8682", "title": "On the Connection between Local Attention and Dynamic Depth-wise Convolution"}, {"paperId": "2e8149dafb864ec3675087c99bf5572fcf4eb170", "title": "RegionViT: Regional-to-Local Attention for Vision Transformers"}, {"paperId": "dbdcabd0444ad50b68ee09e30f39b66e9068f5d2", "title": "DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "f80775a79d42a1ddfc0df808ea760c57af4949d0", "title": "Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding"}, {"paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5", "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "ad4a0938c48e61b7827869e4ac3baffd0aefab35", "title": "Emerging Properties in Self-Supervised Vision Transformers"}, {"paperId": "14c52ffa7ea9c1971d5d82ea369c946c98d056a9", "title": "LocalViT: Bringing Locality to Vision Transformers"}, {"paperId": "4b06c7e29280b1c6bc05c9df39023b48fef02c93", "title": "Escaping the Big Data Paradigm with Compact Transformers"}, {"paperId": "003326a15fc4a8833785a47a741d7712474fa256", "title": "LeViT: a Vision Transformer in ConvNet\u2019s Clothing for Faster Inference"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "40f4d7fe800810288a80f84cdb357a8f4c28e880", "title": "Rethinking Spatial Dimensions of Vision Transformers"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "0eff37167876356da2163b2e396df2719adf7de9", "title": "CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification"}, {"paperId": "96da196d6f8c947db03d13759f030642f8234abf", "title": "DeepViT: Towards Deeper Vision Transformer"}, {"paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0", "title": "Incorporating Convolution Designs into Visual Transformers"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "47f7ec3d0a5e6e83b6768ece35206a94dc81919c", "title": "Taming Transformers for High-Resolution Image Synthesis"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7", "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language Processing"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "5e19eba1e6644f7c83f607383d256deea71f87ae", "title": "Searching for MobileNetV3"}, {"paperId": "a84906dbd4d6640f918d0b6ed2a7313dda0d55f1", "title": "Panoptic Feature Pyramid Networks"}, {"paperId": "693c97ecedb0a84539b7162c95e89fa3cd84ca73", "title": "MnasNet: Platform-Aware Neural Architecture Search for Mobile"}, {"paperId": "c02b909a514af6b9255315e2d50112845ca5ed0e", "title": "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"}, {"paperId": "c1f457e31b611da727f9aef76c283a18157dfa83", "title": "DARTS: Differentiable Architecture Search"}, {"paperId": "d16b21f3e99171c86365679435f9f03766750639", "title": "NetAdapt: Platform-Aware Neural Network Adaptation for Mobile Applications"}, {"paperId": "317b886336e3f5b599ab21795f4a4fef56f727f4", "title": "Efficient Sparse-Winograd Convolutional Neural Networks"}, {"paperId": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4", "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "88512be44744615f4baa8e14f600f036db4c2433", "title": "Semantic Understanding of Scenes Through the ADE20K Dataset"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "b8a919f4a2aaa97bef19aa43e01f8bc347693b73", "title": "NASViT: Neural Architecture Search for Efficient Vision Transformers with Gradient Conflict aware Supernet Training"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "f715d91fc59131eb4236ad8630a761d669a0e2ba", "title": "ATS: Adaptive Token Sampling For Efficient Vision Transformers"}, {"paperId": "03ce51e5e854faa614e79afe4dab8baeb5f73980", "title": "Twins: Revisiting Spatial Attention Design in Vision Transformers"}, {"paperId": "9af62668cb87f11fffb53a194588c8158fde6b00", "title": "DynamicViT: Ef\ufb01cient Vision Transformers with Dynamic Token Sparsi\ufb01cation"}, {"paperId": null, "title": "Use coremltools to convert models from third-party libraries to core ml"}, {"paperId": null, "title": "Pytorch image models"}, {"paperId": null, "title": "Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?"}, {"paperId": null, "title": "b) Did you describe any potential participant risks, with links to Institutional Review"}, {"paperId": null, "title": "If you used crowdsourcing or conducted research with human subjects."}]}