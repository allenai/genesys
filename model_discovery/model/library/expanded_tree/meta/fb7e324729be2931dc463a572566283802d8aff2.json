{"paperId": "fb7e324729be2931dc463a572566283802d8aff2", "abstract": "Transformer-based architectures are the model of choice for natural language understanding, but they come at a significant cost, as they have quadratic complexity in the input length, require a lot of training data, and can be difficult to tune. In the pursuit of lower costs, we investigate simple MLP-based architectures. We find that existing architectures such as MLPMixer, which achieves token mixing through a static MLP applied to each feature independently, are too detached from the inductive biases required for natural language understanding. In this paper, we propose a simple variant, HyperMixer, which forms the token mixing MLP dynamically using hypernetworks. Empirically, we demonstrate that our model performs better than alternative MLP-based models, and on par with Transformers. In contrast to Transformers, HyperMixer achieves these results at substantially lower costs in terms of processing time, training data, and hyperparameter tuning.", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2022, "citationCount": 7, "influentialCitationCount": 2, "openAccessPdf": {"url": "https://aclanthology.org/2023.acl-long.871.pdf", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes a simple variant, HyperMixer, which forms the token mixing MLP dynamically using hypernetworks, and demonstrates that this model performs better than alternative MLP-based models, and on par with Transformers."}, "embedding": {"model": "specter_v2", "vector": [0.06909675151109695, 0.8816543221473694, -0.34237557649612427, -0.03807680681347847, -0.7079631090164185, -0.5820611715316772, 0.7149075865745544, -0.08704183250665665, -0.13524509966373444, -0.5322319269180298, 0.7284144759178162, -0.18079397082328796, 0.4826679229736328, 0.09021150320768356, -0.1780349314212799, -0.07880409061908722, -0.6530144214630127, 0.19827063381671906, -0.47300565242767334, -0.28182297945022583, -0.30512309074401855, -0.6330825686454773, -1.0471500158309937, 0.306985467672348, 0.4696821868419647, 0.6372107267379761, 0.0807516947388649, 0.86067134141922, -0.9461163878440857, 0.5194278359413147, 0.5213866233825684, -0.4351884424686432, 0.3593474328517914, 0.15407595038414001, -0.4610702097415924, -0.10680342465639114, 0.35689762234687805, -0.10999533534049988, -0.44340917468070984, 0.7455150485038757, -0.306257039308548, 0.02062852680683136, 0.21582883596420288, -0.9312014579772949, 0.14222502708435059, 1.8005410432815552, 0.8935349583625793, 0.5048709511756897, -0.40716883540153503, -0.3413589596748352, 1.5234969854354858, -0.8365001082420349, -0.17450004816055298, 1.8214102983474731, 0.5551308989524841, 0.27911806106567383, -0.3691895604133606, -0.9302636384963989, 0.8809903860092163, 0.0713743269443512, -0.6264557242393494, -0.7078980803489685, 0.09743283689022064, -0.02724931761622429, 1.8325275182724, -0.39515236020088196, 0.2235598862171173, 0.380506306886673, -0.3134642541408539, 1.7859574556350708, 0.19815832376480103, -0.8351696729660034, -0.5730488896369934, 0.3980335295200348, 0.33701959252357483, 0.5380040407180786, -0.8040491938591003, -7.732534140814096e-05, -1.0303263664245605, -0.16005071997642517, 0.13522355258464813, -0.22200670838356018, 0.10683959722518921, 0.16149428486824036, -0.32055234909057617, 0.6567378640174866, 0.42556047439575195, 1.0138270854949951, -0.5194980502128601, 0.7826166152954102, 0.6138074398040771, 0.482326477766037, -0.11925177276134491, 0.815078616142273, -0.11214412748813629, 0.1640053540468216, -0.9113381505012512, 0.17579545080661774, 0.1579432487487793, 0.759072482585907, 0.030783958733081818, 0.532729983329773, -0.5250167846679688, 0.5810714364051819, 1.525985598564148, 0.18113556504249573, 0.5582315325737, -1.1465204954147339, 0.4561788737773895, -0.5761152505874634, -0.16199377179145813, -0.4091423451900482, -0.1281941533088684, -0.4359429180622101, -0.4848634898662567, -1.2461071014404297, -0.30561763048171997, 0.09572026878595352, -0.9210373759269714, 0.8863939046859741, -0.5516418814659119, 0.08054033666849136, 0.49366283416748047, -0.29866528511047363, 0.6184679269790649, 0.9585281014442444, 0.6702954173088074, -0.011643221601843834, 1.0845866203308105, -0.7372881174087524, -0.7595739364624023, -0.9491584897041321, 0.5141635537147522, -0.2555783689022064, 0.20045827329158783, -0.11954819411039352, -1.284502387046814, -0.7560890913009644, -0.7082677483558655, 0.15871796011924744, -0.5378648638725281, 0.0016547376289963722, 1.0561972856521606, 0.6693719625473022, -0.9166148900985718, 0.5972244143486023, -0.19603019952774048, -0.07752469927072525, 0.4825587570667267, 0.1875009387731552, 0.5379462242126465, -0.14087314903736115, -1.3693127632141113, 0.5701038837432861, 0.6594590544700623, -0.41097599267959595, -0.15169021487236023, -0.93541020154953, -1.1595313549041748, 0.15174292027950287, 0.1074250191450119, -0.3850287199020386, 1.4403420686721802, -0.3973985016345978, -1.5570414066314697, 0.39240655303001404, -0.4012630581855774, 0.2567322254180908, 0.010708657093346119, 0.004033653996884823, -0.6029099225997925, -0.509695291519165, -0.3571702241897583, 0.8179401159286499, 0.1191902682185173, -0.5253289341926575, -0.2738736867904663, 0.4635257124900818, -0.06614717096090317, 0.14708247780799866, -0.43650802969932556, 0.6859437227249146, -0.028254710137844086, -0.27431660890579224, 0.3541950583457947, 0.6747990846633911, 0.03821709379553795, -0.5530153512954712, -0.7843275666236877, -1.007148027420044, 0.5680999755859375, -0.1332544982433319, 0.6774203777313232, -0.8857505321502686, -0.6168227195739746, 0.11657875776290894, -0.20296069979667664, -0.009724253788590431, -0.8925008773803711, 0.8580613732337952, -0.4485350549221039, 0.3519507944583893, -0.37290075421333313, -1.142833948135376, 0.1607920378446579, -0.10631246864795685, -0.8046112060546875, -0.658576250076294, 0.10152378678321838, 1.1160787343978882, -0.8699607253074646, -0.047483477741479874, 0.3326016664505005, 0.35438698530197144, -0.7427497506141663, 1.2351902723312378, -0.30181077122688293, 0.03768453374505043, 0.16040383279323578, -0.0254374910145998, 0.22879940271377563, -0.014506636187434196, 0.6113211512565613, -0.6317962408065796, -0.15216095745563507, 0.8190804123878479, -0.4191417098045349, 1.469746470451355, -0.7270509600639343, 0.6866032481193542, -0.005058159586042166, -0.7808458805084229, 0.06639159470796585, 0.7240303158760071, -0.12442492693662643, -0.30762240290641785, 0.5155813694000244, 0.5726346373558044, -0.5919127464294434, 0.29623943567276, 0.4498235285282135, 0.43411335349082947, -0.2192705273628235, 0.058526892215013504, 0.9183974266052246, -0.4383573532104492, 0.2786780595779419, 0.2922572195529938, 0.6462000012397766, 0.04876245558261871, 0.15812063217163086, -0.1564594805240631, 0.17933492362499237, -0.6928324103355408, -0.11359868943691254, 0.3089197874069214, 0.9739190340042114, 0.45635080337524414, 0.5444962382316589, -0.523521363735199, -0.26292508840560913, -0.34682467579841614, 0.5022844076156616, 1.3951698541641235, -0.477204293012619, -0.21668140590190887, -0.7579825520515442, -0.2734726667404175, -0.4011225402355194, 0.39977386593818665, -0.010015917010605335, 0.1619616001844406, -0.5871337056159973, -0.9475512504577637, 1.1027700901031494, 0.28451478481292725, 1.14786958694458, -0.5722100734710693, -0.047772474586963654, -0.08293751627206802, -0.1003304198384285, -0.559253454208374, -0.3363208472728729, 0.5386496186256409, -0.6209068298339844, -0.24024097621440887, 0.11546391993761063, -0.1800423413515091, -0.05468869209289551, -0.8858091831207275, 0.8834651112556458, -0.5671840906143188, 0.09964019805192947, 0.10394150763750076, 0.7699005603790283, -0.6737513542175293, -1.092189073562622, 0.4363497793674469, 0.03770247474312782, -0.10399850457906723, 0.27545419335365295, 0.29940304160118103, 0.31669750809669495, -0.18407848477363586, -0.37365734577178955, -0.00866957101970911, 0.20464853942394257, -0.04899084195494652, 0.326423704624176, -0.1069975271821022, 0.003058875445276499, -1.2330503463745117, 0.9154434204101562, 0.09964531660079956, -0.17382675409317017, 0.5176258683204651, -0.4255569577217102, -0.06310305744409561, 0.28615933656692505, -0.5872642993927002, -0.6027719378471375, -0.7539688944816589, 0.04354925453662872, -0.030711106956005096, -0.3152797222137451, 0.3832869529724121, -0.11905014514923096, 0.06290151178836823, -0.0018643129151314497, 0.4977521300315857, 0.3684433400630951, -0.21393311023712158, 1.0341730117797852, -0.40166935324668884, 0.5462421178817749, 0.3968360126018524, 0.16826309263706207, -0.2500515580177307, -0.5674117803573608, -0.9372817873954773, -0.24812476336956024, -0.3401614725589752, 0.09165343642234802, -0.24227990210056305, 0.03926880285143852, -0.63133305311203, -1.0692272186279297, 0.44664934277534485, -1.1427955627441406, -0.12817348539829254, -0.07508072257041931, -0.08907312154769897, -0.19518712162971497, -1.1899923086166382, -1.4564353227615356, -0.5356640815734863, -0.41636478900909424, -1.0571517944335938, -0.0785888135433197, 0.182940274477005, -0.46555235981941223, -0.6824459433555603, 0.07248415052890778, -0.2859439551830292, 1.2776269912719727, -0.6543247103691101, 0.8721025586128235, -0.0946618989109993, -0.20896320044994354, 0.029699226841330528, 0.3649684190750122, 0.8038966655731201, -0.08415845781564713, 0.36703261733055115, -1.360541820526123, 0.4317868649959564, -0.24406811594963074, -0.4635002911090851, 0.021651018410921097, 0.5212933421134949, 0.5331392288208008, -0.2285260409116745, -0.4851086735725403, 0.3607693612575531, 1.3763511180877686, -0.5967106223106384, 0.20822976529598236, 0.2638280391693115, 1.1103003025054932, 0.6846547722816467, -0.9548925161361694, 0.11618193984031677, 0.7059995532035828, 0.22022978961467743, 0.07041479647159576, -0.16299188137054443, -0.1479492038488388, -0.4517432749271393, 0.5220209956169128, 1.7984713315963745, 0.29796135425567627, -0.1577254682779312, -1.112411379814148, 0.6217578649520874, -1.1638898849487305, -0.49530723690986633, 0.8489677906036377, 0.30185216665267944, 0.4114178419113159, -0.5773894786834717, -0.30823618173599243, 0.26210564374923706, 0.43815740942955017, 0.3540983498096466, -0.2759719789028168, -0.8166734576225281, 0.0008686513174325228, 0.2857070863246918, 0.16011075675487518, 0.8148877024650574, -0.1250525861978531, 0.5404828190803528, 14.856934547424316, 0.9298138618469238, 0.019431106746196747, 0.37754231691360474, 0.5973886251449585, 0.2549794018268585, -0.8450193405151367, -0.028545472770929337, -0.9443016648292542, -0.11645141243934631, 1.2235256433486938, 0.43306753039360046, 1.1067237854003906, -0.06932403892278671, -0.30032509565353394, 0.39192551374435425, -0.3011876940727234, 0.7258986830711365, 0.42112448811531067, -1.2670978307724, 0.5376338958740234, 0.03200418874621391, 0.26563432812690735, 0.49369916319847107, 0.514177680015564, 0.8695220351219177, 0.7835395336151123, -0.4754798114299774, 0.5165054798126221, 0.16251829266548157, 0.5165320634841919, -0.4124959707260132, 0.3302342891693115, 0.2112463265657425, -1.1144546270370483, -0.5944384336471558, 0.04215423762798309, -0.7405494451522827, 0.475487619638443, 0.1525818109512329, -0.2772238850593567, -0.6736688613891602, -0.015702521428465843, 0.5717199444770813, 0.3314054608345032, 0.34691929817199707, -0.3876948952674866, 0.8902429342269897, -0.38719993829727173, 0.38298100233078003, 0.41630345582962036, 0.7760581374168396, 0.14234121143817902, 0.30325111746788025, -0.10616818070411682, -0.09775599092245102, 0.12188880145549774, 0.29702338576316833, -0.747915506362915, -0.08081008493900299, -0.28717756271362305, -0.6043403148651123, 0.3212871849536896, 0.913053035736084, 0.2834535241127014, 0.030870219692587852, -0.18540489673614502, -0.17207194864749908, 0.46716898679733276, 0.20119649171829224, 0.1326785832643509, -0.4012284576892853, 0.376017302274704, -0.563399076461792, -0.11376996338367462, 0.7760651111602783, -0.29739460349082947, -0.30365100502967834, -0.8449152708053589, -0.7471828460693359, 0.2109273076057434, -0.45048582553863525, -0.8379158973693848, 0.92793869972229, -0.005415943451225758, -0.03906700760126114, 0.29160964488983154, -0.5581662654876709, -0.5824108719825745, 0.42847687005996704, -1.527497410774231, -1.0823653936386108, 0.3087300658226013, -0.3998614549636841, -0.5337703824043274, -0.12429915368556976, 1.2254788875579834, -0.1757635772228241, -0.2530243992805481, -0.06203071027994156, 0.062318772077560425, 0.17833516001701355, -0.41264572739601135, -0.8628812432289124, 0.9440874457359314, 0.09474998712539673, -0.03548792004585266, 0.19049325585365295, 0.04915791377425194, 0.45698556303977966, -0.40606385469436646, 0.2034902125597, 1.000983476638794, -0.6732707023620605, -0.40443527698516846, -0.7154548764228821, -0.962708055973053, 0.3595861494541168, 1.0293232202529907, -0.556084394454956, 0.5639311671257019, 0.22718586027622223, -0.7865957617759705, -0.3550921380519867, -1.0181902647018433, 0.04436906427145004, 0.11127469688653946, -1.009721040725708, -0.6103214025497437, -0.14447201788425446, 0.4569874703884125, -0.7117653489112854, -0.8622267246246338, -0.45781975984573364, 0.29154056310653687, 0.2194809466600418, 0.9504229426383972, -0.2710839807987213, 0.23055101931095123, 0.775520920753479, -0.12462321668863297, -1.2446430921554565, 0.1367170512676239, -1.0019590854644775, 0.22980502247810364, 0.5695815086364746, 0.7174186110496521, -0.5229047536849976, 0.12632480263710022, 0.650574266910553, 0.12303164601325989, -0.20426294207572937, -0.5403698682785034, -0.1497908979654312, 0.07109615951776505, -0.5823005437850952, 0.7210487127304077, 0.3189578056335449, 0.3070017695426941, -0.06240305304527283, 0.8109979033470154, 0.46898892521858215, 0.08200850337743759, -0.9533275365829468, -0.1133289709687233, -0.14055322110652924, -0.1527927964925766, -0.7701687812805176, -0.41241997480392456, -1.0682278871536255, 0.29796576499938965, -1.1833813190460205, 0.4917290508747101, -0.9993070363998413, -0.5573741793632507, -0.2641241252422333, -0.23753514885902405, 0.4124034345149994, 0.27839455008506775, -0.5144810080528259, -0.14561207592487335, -0.6924242973327637, -0.08674336969852448, 0.577912449836731, 0.4021708369255066, -1.049131155014038, -0.0740254744887352, -0.13138455152511597, -0.2061137706041336, 0.281462162733078, 0.5073413848876953, -0.463360458612442, -0.748816967010498, -1.2554311752319336, 0.18420684337615967, -0.12858130037784576, -0.4338056147098541, -0.635703980922699, 0.6563464999198914, 0.6086645722389221, -0.3929173946380615, 0.31870296597480774, 0.27994269132614136, -0.7099995017051697, -0.2720765769481659, 0.3387593924999237, -0.8812268972396851, 0.14308367669582367, 0.2888447940349579, -0.7876858711242676, -0.31530994176864624, 0.5952194929122925, 0.07044331729412079, -1.2682610750198364, -0.434893399477005, 0.15872631967067719, -1.0745733976364136, 0.2171114981174469, -0.4191248416900635, -0.11221764981746674, -1.1633893251419067, -0.16593889892101288, 0.020000264048576355, 0.5052255392074585, -0.43833863735198975, 0.901780903339386, 0.14678339660167694, -1.0699008703231812, -0.06472068279981613, 0.28114399313926697, -0.03528455272316933, -0.10361330211162567, 0.3432080149650574, 0.24591800570487976, -0.3124436140060425, 0.3167033791542053, -0.0038198509719222784, 0.1488720178604126, -0.641821563243866, -0.4877025783061981, 0.8974428772926331, -0.43790164589881897, 0.18457454442977905, 1.1143049001693726, -0.5363982319831848, -1.3991332054138184, 0.4721533954143524, -1.4670387506484985, -0.7385172843933105, 0.009622697718441486, 0.6106632351875305, 0.47029322385787964, -0.30761197209358215, -0.07320498675107956, -0.2788596749305725, 0.27371907234191895, 0.09784290939569473, -0.6201426386833191, 0.5336030125617981, -0.3081897497177124, -0.4771761894226074, 0.8759866952896118, 0.5370671153068542, -0.9404134750366211, -0.5286822319030762, -0.729576826095581, -0.4184805452823639, 0.16227270662784576, 0.4861087501049042, -0.3470863401889801, -0.8798011541366577, 0.8947826623916626, 0.44330722093582153, 0.3696678876876831, -0.055616699159145355, -0.16966010630130768, 0.18758554756641388, 0.8186919093132019, -0.24165378510951996, -0.7132753133773804, -0.6218227744102478, 1.1211687326431274, 0.9799695014953613, -0.7547717094421387, -0.08674181997776031, -0.16603276133537292, -0.7399592995643616, 0.8611359000205994, 0.06979387253522873, 0.2837202250957489, 0.9210405349731445, -0.07175780832767487, 0.6424557566642761, 0.07028649747371674, -0.8492110371589661, -0.3030592203140259, 0.38149508833885193, 1.0967499017715454, 0.7415309548377991, 0.43067386746406555, 0.5365697145462036, 0.5066590309143066, 0.021303405985236168, -0.07275428622961044, 0.34879276156425476, 0.6669902205467224, -0.3105261027812958, -0.4112984836101532, 0.0895228162407875, 0.7622272372245789, -0.5681527256965637, -0.5957528948783875, 0.12108840048313141, 0.4262341260910034, 0.5930643081665039, 0.8747830390930176, 0.8157005906105042, 0.13136732578277588, 0.567872941493988, 0.3677181005477905, 0.48030975461006165, -0.39516207575798035, -0.6597126126289368, -0.36410531401634216, -0.42476826906204224, -0.15009257197380066, -0.5591426491737366, -0.3409709334373474, -0.33570143580436707, -0.32020652294158936, 0.13177980482578278, 0.21267880499362946, 0.6770603656768799, 1.3080772161483765, 0.24992918968200684, 0.39325639605522156, -0.18097302317619324, -0.6612712740898132, -0.4600038528442383, -1.0283982753753662, -0.047839436680078506, -0.748297393321991, -0.1855466663837433, 0.06796808540821075, -0.3803545832633972, -0.33235129714012146]}, "authors": [{"authorId": "38777433", "name": "Florian Mai"}, {"authorId": "2146378423", "name": "Arnaud Pannatier"}, {"authorId": "2158116081", "name": "Fabio Fehr"}, {"authorId": "2028634871", "name": "Haolin Chen"}, {"authorId": "115669262", "name": "Fran\u00e7ois Marelli"}, {"authorId": "2721983", "name": "F. Fleuret"}, {"authorId": "46712043", "name": "J. Henderson"}], "references": [{"paperId": "6702329634ed6876fc03bcc8ea68bdbf34c254e4", "title": "HyperConformer: Multi-head HyperMixer for Efficient Speech Recognition"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "b77cb53e9a0d9fbe77b4b6d0982ed6fc9ad6f1a8", "title": "pNLP-Mixer: an Efficient all-MLP Architecture for Language"}, {"paperId": "48e84128b0f288f544176138805a97fbe592a1dd", "title": "DynaMixer: A Vision MLP Architecture with Dynamic Mixing"}, {"paperId": "c3112a62284b1f7b699b5aad3adb2d837f7f4e12", "title": "HyperTransformer: Model Generation for Supervised and Semi-Supervised Few-Shot Learning"}, {"paperId": "fbf68eb0cf8237cef59ebdb301569c79b9676ff9", "title": "MAXIM: Multi-Axis MLP for Image Processing"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "caab15c456ba5d8e58e6be14af9c28d03b578331", "title": "Expected Validation Performance and Estimation of a Random Variable's Maximum"}, {"paperId": "485c08025157973bb52a935c6aa3bee74f990c01", "title": "Sparse MLP for Image Recognition: Is Self-Attention Really Necessary?"}, {"paperId": "cddf40e579a596d0110b260313adf43470617c4c", "title": "Datasets: A Community Library for Natural Language Processing"}, {"paperId": "58970a426b687bb080b7fed3b4b78ab1ebaa56f4", "title": "Hire-MLP: Vision MLP via Hierarchical Rearrangement"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "d820174fe91e7d384eeacede3a43fd1b6ff9afc9", "title": "RaftMLP: How Much Can Be Done Without Attention and with Less Spatial Locality?"}, {"paperId": "71363797140647ebb3f540584de0a8758d2f7aa2", "title": "AS-MLP: An Axial Shifted MLP Architecture for Vision"}, {"paperId": "013eb12ce5468f79d58bf859653f4929c5a2bd14", "title": "An Empirical Survey of Data Augmentation for Limited Data Learning in NLP"}, {"paperId": "60707f6d2bffeab09e8f1d073fce4fc06ab89ec1", "title": "S2-MLP: Spatial-Shift MLP Architecture for Vision"}, {"paperId": "bb3425318de7eed5641cda147d61c9a057b9d054", "title": "Parameter-efficient Multi-task Fine-tuning for Transformers via Shared Hypernetworks"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "title": "FNet: Mixing Tokens with Fourier Transforms"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "cec7872b194aadf54140578b9be52939eb1112e9", "title": "LambdaNetworks: Modeling Long-Range Interactions Without Attention"}, {"paperId": "455cdafd55a5b5ddefa029bf97801327e142646d", "title": "A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios"}, {"paperId": "f30444fbb6ad806168e2564db4815cd27faa7fd9", "title": "It\u2019s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "9ae116139ae77ca6d78e162e9639681adef5761c", "title": "The Unstoppable Rise of Computational Linguistics in Deep Learning"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "e52051204cb1179584f3b008c9d38848b52c1f28", "title": "ReZero is All You Need: Fast Convergence at Large Depth"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "0e4cd6bae6ac1017e7b1b9bd644375aee65b8372", "title": "Show Your Work: Improved Reporting of Experimental Results"}, {"paperId": "3c5f1ab37f70db503636075e15b3173f86eea00b", "title": "Green AI"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "a39398f68ae7e042f2ef5009e31b4e6a20fd5736", "title": "Learning Deep Transformer Models for Machine Translation"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "563783de03452683a9206e85fe6d661714436686", "title": "HyperNetworks"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "f04df4e20a18358ea2f689b4c129781628ef7fc1", "title": "A large annotated corpus for learning natural language inference"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71", "title": "Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "188e247506ad992b8bc62d6c74789e89891a984f", "title": "Random Search for Hyper-Parameter Optimization"}, {"paperId": "668087f0ae7ce1de6e0bd0965dbb480c08103260", "title": "Finding Structure in Time"}, {"paperId": "56cbfcbfffd8c54bd8477d10b6e0e17e097b97c7", "title": "Connectionism and cognitive architecture: A critical analysis"}, {"paperId": "1f5d6b808de8e5edba13e7eff2bceb234dbe2414", "title": "BQ-NCO: Bisimulation Quotienting for Generalizable Neural Combinatorial Optimization"}, {"paperId": null, "title": "Several methods try to overcome the lack of adaptivity to size by introducing shifting operations and local windows"}, {"paperId": null, "title": "2022) call the following the \"standard serialized\" formulation: x1 = x+ token_mixing(LayerNorm(x)) x = x+ feature_mixing(LayerNorm(x1))"}, {"paperId": "942aec6e9dddcaa6700e14a2f6e1b77164a092cb", "title": "HyperGrid Transformers: Towards A Single Model for Multiple Tasks"}, {"paperId": null, "title": "Gpt-j-6b: A 6 billion parameter autoregressive language model"}, {"paperId": null, "title": "2021) applied hypernetworks to Transformers to allow for parameter sharing in multitask learning"}, {"paperId": null, "title": "A global receptive field in MLP-based models is achieved through token mixing and a weighted summation of the inputs, similar to self-attention"}, {"paperId": null, "title": "2021) observe that a speed-up can be obtained by parallelizing the two components"}, {"paperId": null, "title": "2021) proposes the \"ReZero\" normalization, which introduces a learnable scalar \u03b1 \u2208 R, initialized to zero: x1"}, {"paperId": null, "title": "2020) propose a count of the floating point operations (FPOs) required"}, {"paperId": null, "title": "The metric Cost(R) \u221d E \u00b7D \u00b7H , is proposed and discussed in Section 1. However, reporting a single metric Cost(R) is often ambiguous"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "2021), which computes the validation performance one would yield in expectation after k hyperparameter trials"}, {"paperId": null, "title": "2019) estimated the monetary and environmental cost of large model pretraining"}, {"paperId": null, "title": "2019) proposes the \"pre-norm\" layout: x1 = x+ token_mixing(LayerNorm(x)) x = x1"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "First quora dataset release: Question pairs"}, {"paperId": "19fbe977aa3e061ffe3592a7273eb960f81bcbe0", "title": "Attention , mechanisms of"}, {"paperId": null, "title": "Simran Arora, Sydney von Arx, Layout MNLI SNLI QQP QNLI SST Average Multi-head self-attention"}, {"paperId": null, "title": "Best validation set results on natural language understanding tasks after tuning the learning rate on a grid"}]}