{"paperId": "95e522b207443e61f6fc472b553c89eafb7daf22", "abstract": "Recently, mixture of experts (MoE) has become a popular paradigm for achieving the trade-off between modal capacity and efficiency of multi-modal large language models (MLLMs). Different from previous efforts, we are dedicated to exploring the dynamic expert path in an already exist MLLM and show that a standard MLLM can be also a mixture of experts. To approach this target, we propose a novel dynamic expert scheme for MLLMs, termed Routing Experts (RoE), which can achieve example-dependent optimal path routing without obvious structure tweaks. Meanwhile, a new regularization of structure sparsity is also introduced to enforce MLLMs to learn more short-cut inference, ensuring the efficiency. In addition, we also realize the first attempt of aligning the training and inference schemes of MLLMs in terms of network routing. To validate RoE, we apply it to a set of latest MLLMs, including LLaVA-1.5, LLaVA-HR and VILA, and conduct extensive experiments on a bunch of VL benchmarks. The experiment results not only show the great advantages of our RoE in improving MLLMs' efficiency, but also yield obvious advantages than MoE-LLaVA in both performance and speed, e.g., an average performance gain of 3.3% on 5 benchmarks while being faster.", "venue": "", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work proposes a novel dynamic expert scheme for MLLMs, termed Routing Experts (RoE), which can achieve example-dependent optimal path routing without obvious structure tweaks and realizes the first attempt of aligning the training and inference schemes of MLLMs in terms of network routing."}, "embedding": {"model": "specter_v2", "vector": [-0.303921103477478, 0.8199803233146667, -0.616680383682251, -0.4653973877429962, -0.7226438522338867, -0.4426005482673645, 0.4712955951690674, -0.55002760887146, -0.34324386715888977, -0.19107937812805176, 0.8454629778862, 0.11152797192335129, 0.4163508117198944, 0.5034410953521729, 0.09766656160354614, 0.33687207102775574, -1.029141902923584, 0.5078845024108887, -0.06023843586444855, -0.48610860109329224, -0.4956377446651459, -0.6840656399726868, -0.5305519104003906, 0.5485838055610657, 0.29860541224479675, 0.3356422781944275, 0.07470088452100754, 0.7424205541610718, -0.48540207743644714, 0.3931471109390259, 0.8029005527496338, -0.42560097575187683, 0.31578537821769714, 0.13406966626644135, -0.24976888298988342, 0.1640503704547882, 0.09604959934949875, -0.5720426440238953, -0.597599446773529, 0.5432636141777039, -0.30947646498680115, 0.4494101405143738, 0.763158917427063, -0.8314967155456543, -0.2597353458404541, 1.3641687631607056, 0.4514496922492981, 0.4118672311306, -0.23495686054229736, -0.6206800937652588, 1.6402400732040405, -1.7093740701675415, 0.32562175393104553, 2.0084190368652344, 0.22164878249168396, 0.8704162240028381, -0.39419594407081604, -0.6579541563987732, 1.036688208580017, 0.2617899179458618, -0.8791894316673279, -0.7255876660346985, -0.1582253873348236, -0.24147804081439972, 1.7913322448730469, -0.8560441136360168, -0.608451783657074, 0.5979084968566895, -0.2959853410720825, 1.6006903648376465, -0.26678135991096497, -0.37835371494293213, -0.35295718908309937, 0.3321915566921234, 0.15296469628810883, 1.0225799083709717, -0.8410979509353638, 0.48439326882362366, -0.8450978398323059, -0.18413817882537842, -0.07271547615528107, -0.36029013991355896, -0.1676187813282013, -0.0699409693479538, -0.26493701338768005, 1.2352670431137085, 0.30612027645111084, 0.6624844074249268, -0.1119043231010437, 0.4685346782207489, 0.7356624603271484, 0.35260656476020813, -0.03453541547060013, 0.25318989157676697, -0.4888118803501129, 0.8413887023925781, -0.6239542961120605, 0.12772566080093384, 0.23919346928596497, 0.6864338517189026, -0.402558296918869, 0.23276877403259277, -0.6278650760650635, 0.2706925868988037, 1.9563100337982178, -0.2703581154346466, 0.3998425006866455, -1.0701777935028076, 0.30296561121940613, -0.4803749918937683, 0.0860075131058693, -0.5953132510185242, -0.3272593021392822, -0.19017936289310455, -0.900118887424469, -1.0276216268539429, -0.21209223568439484, 0.15500226616859436, -0.5964000225067139, 1.0929285287857056, -0.1096881777048111, 0.01723494566977024, 0.4927939474582672, 0.38544556498527527, 0.7508867979049683, 1.2712515592575073, 0.466629296541214, 0.012515832670032978, 0.7996115684509277, -1.1796847581863403, -0.5029984712600708, -1.230221152305603, 1.1026989221572876, 0.03622296452522278, 0.07766596972942352, -0.12471909821033478, -0.8251802921295166, -0.8002017140388489, -0.7601461410522461, 0.0671149492263794, -0.4069046378135681, 0.9373801350593567, 0.775937557220459, 0.19243918359279633, -1.0371270179748535, 0.31928199529647827, -0.01177311409264803, 0.11867412179708481, 0.15110914409160614, 0.07907215505838394, -0.08277103304862976, -0.6342463493347168, -1.666622519493103, 0.3330736756324768, 0.633868932723999, -0.19997911155223846, -0.5434786081314087, -0.3543471693992615, -1.4912501573562622, -0.07858020067214966, 0.30126598477363586, -0.5004556775093079, 1.3059930801391602, 0.016987387090921402, -1.4728018045425415, 0.6597890853881836, -0.35259804129600525, 0.3263711929321289, 0.0734935998916626, 0.09586456418037415, -0.7764349579811096, -0.6982150673866272, -0.3750942051410675, 0.9613933563232422, 0.49791547656059265, -0.4006858766078949, -0.35503479838371277, 0.1775577962398529, 0.09770858287811279, -0.006560467183589935, -0.35742849111557007, 0.9914006590843201, -0.35230833292007446, 0.06536901742219925, 0.20910440385341644, 0.7206408977508545, -0.38933852314949036, 0.10096118599176407, -0.5728182792663574, -1.3940763473510742, 0.7568047046661377, -0.22235757112503052, 1.0102641582489014, -0.8380753397941589, -0.2434636503458023, -0.33810678124427795, -0.007948782294988632, -0.1183985248208046, -1.2865790128707886, 0.757611870765686, -0.2726461589336395, 0.09477853029966354, -0.4578065872192383, -1.7528396844863892, 0.3126498758792877, -0.26681336760520935, -0.6403505206108093, -0.2716580033302307, -0.0629541352391243, 0.8878076076507568, -0.9487178325653076, -0.08476670831441879, -0.118914894759655, 0.29306942224502563, -0.9333899617195129, 1.024532437324524, -0.875571072101593, 0.27718260884284973, -0.0635109692811966, -0.2732672095298767, -0.18457849323749542, -0.37124142050743103, 0.48320165276527405, -0.5844186544418335, 0.3091636300086975, 0.38688719272613525, -0.8851415514945984, 1.5457680225372314, -0.3460022211074829, 0.4345376193523407, 0.13786888122558594, -0.7409539222717285, -0.23526924848556519, 0.6927292943000793, -0.3610617220401764, -0.06325109302997589, 0.2928822934627533, 0.5378090739250183, -0.5834952592849731, 0.1353558450937271, 0.6475889086723328, 0.752600371837616, -0.30303990840911865, 0.46749162673950195, 0.4284164309501648, 0.2629483938217163, 0.6808184385299683, 0.7415618896484375, 0.39339038729667664, 0.1306942105293274, 0.466071754693985, 0.051125653088092804, 0.9224734306335449, -0.9185159802436829, -0.13675415515899658, -0.11302206665277481, 0.5935426354408264, 0.39864248037338257, 0.35858264565467834, -0.5847575664520264, -0.12174128741025925, 0.23379066586494446, 0.7988342046737671, 1.7989823818206787, -0.46880167722702026, -0.24254874885082245, -0.36968374252319336, -0.48825618624687195, -0.3221350312232971, 0.1493270993232727, -0.2011765092611313, 0.13517726957798004, -0.5195456743240356, -1.089470386505127, 0.6839971542358398, 0.4065711200237274, 0.5122578740119934, -0.5387178063392639, 0.006672901567071676, -0.21511758863925934, -0.10593026876449585, -0.8517830967903137, -0.6944651007652283, -0.012559027411043644, -0.4340408146381378, -0.11110106855630875, 0.0567367821931839, -0.040735311806201935, 0.19875240325927734, -1.1316190958023071, 1.0671149492263794, -1.1581110954284668, -0.22846896946430206, 0.05642213672399521, 0.3652731776237488, -0.06841738522052765, -1.1646392345428467, 0.20100805163383484, 0.30996277928352356, 0.10035888105630875, 0.17332905530929565, 0.6875005960464478, 0.15608720481395721, 0.17040692269802094, -0.3203561305999756, 0.09912287443876266, 0.22394469380378723, -0.25221818685531616, 0.6911864876747131, 0.012481211684644222, 0.16782617568969727, -1.6356000900268555, 0.904570460319519, -0.354786217212677, -0.5290760397911072, 0.22568576037883759, -0.46729034185409546, -0.2833626866340637, 0.7005026936531067, -0.8041423559188843, -0.3473033010959625, -0.4903554320335388, 0.2821623980998993, -0.316985547542572, -0.2780241370201111, 0.47376230359077454, 0.008847709745168686, 0.46491703391075134, 0.4320770800113678, 0.3456383943557739, 0.04627663642168045, -0.19978803396224976, 1.0852773189544678, -0.7960129976272583, 0.47674450278282166, 0.38543105125427246, 0.320483535528183, -0.10727685689926147, -0.46081870794296265, -0.4884682595729828, -0.35281944274902344, -0.7699143886566162, -0.07702351361513138, -0.0758400708436966, 0.04545231908559799, -0.752396821975708, -0.6185245513916016, 0.170136496424675, -1.3806121349334717, -0.02445930801331997, 0.6198720932006836, -0.2515295147895813, 0.14311645925045013, -1.184046983718872, -1.591456413269043, -0.5313836336135864, -0.4322202801704407, -1.0423567295074463, 0.4306395649909973, -0.08116081357002258, -0.49578365683555603, -0.8864836692810059, 0.021101806312799454, -0.3027334213256836, 1.1874685287475586, -0.8055558204650879, 1.256683588027954, -0.2510542869567871, -0.34492799639701843, -0.388854056596756, 0.17585793137550354, 0.5253284573554993, -0.265889048576355, 0.25276631116867065, -1.0155456066131592, 0.05503948777914047, -0.2804691791534424, -0.5963211059570312, 0.1324542611837387, 0.685067892074585, 0.5662810206413269, -0.2872368395328522, -0.6977826356887817, 0.2737012803554535, 1.5988861322402954, -0.7084259390830994, -0.08969870209693909, -0.42371460795402527, 1.1523889303207397, 0.8502563238143921, -0.527336061000824, 0.46110859513282776, 0.6281437277793884, 0.2019425630569458, 0.3737947642803192, 0.19445087015628815, 0.4787988066673279, -0.3260748088359833, 0.9154113531112671, 1.6966919898986816, 0.7903687953948975, -0.22299304604530334, -0.8971270322799683, 0.6378055214881897, -1.329185128211975, -0.5881621837615967, 0.5867860913276672, 0.3183744549751282, 0.22640717029571533, -0.5788692235946655, -0.09018882364034653, -0.4323042035102844, 0.40445709228515625, 0.6756278276443481, -0.6048440337181091, -0.5419053435325623, 0.18750838935375214, -0.30767902731895447, -0.27328208088874817, 0.8334587216377258, -0.5298189520835876, 0.619560956954956, 14.097472190856934, 0.9366594552993774, 0.3084862530231476, 0.7530478239059448, 0.8215533494949341, 0.4572654962539673, -0.6386105418205261, -0.2607850134372711, -1.6302632093429565, -0.16482369601726532, 1.4322999715805054, 0.40872177481651306, 0.6814958453178406, 0.2855573892593384, 0.06271608918905258, 0.20778051018714905, -0.9029642939567566, 0.6837108731269836, 0.4790501594543457, -1.1249823570251465, 0.4847029447555542, -0.01819254644215107, 0.5297425389289856, 0.5686072707176208, 0.5352421402931213, 0.9491803050041199, 0.7456138730049133, -0.7401409149169922, 0.2472444325685501, 0.22065800428390503, 0.861754298210144, -0.039938315749168396, 0.2548014521598816, 0.8878525495529175, -1.4641236066818237, -0.6308529376983643, -0.6132616996765137, -0.7198441624641418, 0.6242095828056335, 0.17401163280010223, -0.09977018088102341, -0.5759444236755371, -0.23196189105510712, 0.968427836894989, 0.39363232254981995, 0.29500001668930054, -0.18960347771644592, 0.38309961557388306, -0.10450450330972672, 0.5464710593223572, 0.329467236995697, 0.43379294872283936, 0.48515504598617554, -0.23549391329288483, 0.03498375043272972, -0.14134764671325684, 0.26866415143013, 0.6145679950714111, -0.5813665390014648, -0.08036167919635773, -0.2719195783138275, -0.5540420413017273, 0.1892806738615036, 1.0620487928390503, 0.6508451700210571, 0.27061280608177185, -0.340453565120697, 0.3433544933795929, 0.6309153437614441, 0.3102886378765106, 0.011047912761569023, 0.2082919180393219, 0.16865316033363342, -0.6217667460441589, -0.13144129514694214, 0.9067668318748474, 0.14701451361179352, -0.34479209780693054, -0.7404257655143738, -0.7048012614250183, 0.6756922006607056, -0.6250941753387451, -1.1607303619384766, 1.0275468826293945, -0.08937037736177444, -0.5588077306747437, -0.15967068076133728, -0.7837527990341187, -0.265959769487381, 0.4939190447330475, -1.1494187116622925, -0.9723243713378906, 0.8869454264640808, -0.304002970457077, -0.1250733584165573, -0.2691206932067871, 1.421953797340393, 0.4097689688205719, -0.5042096376419067, 0.14642009139060974, 0.20539133250713348, 0.14747098088264465, -0.276394248008728, -0.6809757947921753, 0.8448748588562012, 0.28945526480674744, -0.28788501024246216, 0.13130511343479156, -0.2108699232339859, 0.3673047125339508, -0.3907946050167084, -0.201324462890625, 0.7898797392845154, -1.038529872894287, -0.43555495142936707, -0.6563578844070435, -0.9299704432487488, 0.4209994077682495, 0.4244946539402008, -0.42963433265686035, 0.3888106346130371, -0.008213100023567677, -0.8907320499420166, -0.022947238758206367, -0.688124418258667, -0.20193137228488922, 0.29740333557128906, -0.9346738457679749, -0.06012747809290886, 0.12027724087238312, 0.48164787888526917, -0.9879295825958252, -0.3090016841888428, -0.16833147406578064, 0.22141620516777039, 0.2075507789850235, 1.0875751972198486, -0.5327726602554321, 0.7462589740753174, 0.4738754332065582, -0.32096290588378906, -1.090200662612915, 0.15108783543109894, -0.7167532444000244, -0.36116376519203186, 0.30602166056632996, 0.989303469657898, -0.42604488134384155, 0.033180251717567444, 0.7397124767303467, 0.33983689546585083, -0.639569103717804, -0.42442816495895386, 0.04516264796257019, 0.08149035274982452, -0.5294370055198669, -0.03194558992981911, -0.24396583437919617, -0.16062594950199127, 0.33333584666252136, 0.11670797318220139, 0.9650818109512329, -0.06652893126010895, -0.8652827739715576, 0.06804724782705307, -0.22954154014587402, -0.5083084106445312, -0.41516053676605225, 0.017073146998882294, -1.459574580192566, 0.5472092032432556, -1.2406322956085205, 0.2711770832538605, -1.2976174354553223, -0.2544076144695282, 0.14296065270900726, -0.059043437242507935, 0.07793089002370834, 0.34486931562423706, -0.5343765616416931, -0.6342001557350159, -0.5561389327049255, -0.36249059438705444, 0.8817053437232971, 0.6965820789337158, -0.6912130117416382, 0.027915343642234802, 0.3758281171321869, 0.08017025142908096, 0.37114518880844116, 0.3005567193031311, -0.4113875925540924, -1.1713793277740479, -1.5260295867919922, 0.8030734062194824, 0.12159481644630432, -0.28644534945487976, -0.34280121326446533, 0.7972798347473145, 0.5367016196250916, -0.49978509545326233, 0.01045797299593687, 0.4826142191886902, -1.087524652481079, -0.39437392354011536, 0.2550963759422302, -0.8930671811103821, 0.12801960110664368, 0.06940408051013947, -0.2232099324464798, -0.49840882420539856, 0.7015275359153748, 0.30199867486953735, -1.3723307847976685, -1.0690361261367798, 0.7177764773368835, -0.616509735584259, 0.20469412207603455, -0.313923180103302, 0.18457847833633423, -1.2141836881637573, -0.5667494535446167, -0.011250779964029789, 0.7520327568054199, -0.4984312057495117, 0.6068713665008545, 0.615997314453125, -1.0799225568771362, -0.3965030908584595, 0.17517748475074768, 0.15176337957382202, 0.20304058492183685, 1.0593574047088623, 0.2596670985221863, -0.008839303627610207, 0.7076014876365662, 0.5930678248405457, 0.3026687204837799, -0.7023010849952698, 0.01228668075054884, 1.2824918031692505, -0.8882964253425598, -0.024410823360085487, 1.694773554801941, -0.1641284078359604, -1.7584314346313477, 0.5760703086853027, -0.8818814754486084, -0.9654217958450317, -0.033888962119817734, 0.970817506313324, 0.3657275438308716, -0.5392929911613464, -0.4468914270401001, -0.5833203792572021, 0.2882152497768402, -0.017198264598846436, -0.6684207916259766, 0.3850302994251251, -0.5022487044334412, -0.7346934676170349, 0.7061627507209778, 0.9782052040100098, -0.6160790324211121, -0.531353235244751, -0.9197180271148682, -0.5862953066825867, 0.19165541231632233, 0.13700585067272186, -0.47650623321533203, -0.7633197903633118, 0.8302335143089294, 0.4779171645641327, 0.01539207249879837, 0.10745697468519211, 0.225992351770401, 0.5818003416061401, 0.6943762898445129, -0.13404710590839386, -0.5846739411354065, -0.48914197087287903, 1.3687626123428345, 1.2582221031188965, -1.199238896369934, -0.21998050808906555, -0.2813010513782501, -0.8706526756286621, 0.6955536007881165, 0.5423662662506104, 0.13618378341197968, 1.0372540950775146, -0.35371527075767517, 0.2450600117444992, 0.1081031933426857, -1.3504278659820557, -0.21934300661087036, 1.278871774673462, 0.8418505191802979, 0.5637843608856201, 0.31617945432662964, 0.12735417485237122, 0.8346821069717407, 0.47456496953964233, -0.1837167888879776, 0.35582828521728516, -0.11720940470695496, -0.3595924377441406, -0.3366655111312866, 0.3262161314487457, 0.6023055911064148, -0.5610424876213074, -0.6334307789802551, 0.18289609253406525, 0.12286041676998138, 0.22399689257144928, 0.8370622992515564, 0.3895803689956665, 0.021753845736384392, 0.10980287939310074, 0.4710976779460907, 0.1151769608259201, -0.7357101440429688, 0.4146384000778198, -0.331249475479126, -0.6191055774688721, -0.2605535089969635, -0.32101914286613464, 0.06775085628032684, -0.504014790058136, -0.342675119638443, 0.6284910440444946, -0.31373342871665955, 0.32177093625068665, 1.4235827922821045, 0.46177613735198975, 0.43550679087638855, -0.12011198699474335, -0.3945096433162689, -0.768703818321228, -0.991766095161438, -0.29520338773727417, -0.770837128162384, -0.20578274130821228, 0.19146692752838135, -0.546835720539093, -0.2473105639219284]}, "authors": [{"authorId": "2112260110", "name": "Qiong Wu"}, {"authorId": "2312209906", "name": "Zhaoxi Ke"}, {"authorId": "2110191063", "name": "Yiyi Zhou"}, {"authorId": "2056100172", "name": "Gen Luo"}, {"authorId": "2227806539", "name": "Xiaoshuai Sun"}, {"authorId": "2232781359", "name": "Rongrong Ji"}], "references": [{"paperId": "f999de5f9d354c262e21438ac6ec9a72a561cb5b", "title": "Radial Networks: Dynamic Layer Routing for High-Performance Large Language Models"}, {"paperId": "96c3a6156546d0447fa2b3327e55bc5973e01d57", "title": "FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping"}, {"paperId": "a1f23f04421cdc62e80fe9f04c1ce60f4a6af9f0", "title": "Mixture-of-Depths: Dynamically allocating compute in transformer-based language models"}, {"paperId": "a379d387a48b079286bd0bf0264166a6cc254ef5", "title": "Feast Your Eyes: Mixture-of-Resolution Adaptation for Multimodal Large Language Models"}, {"paperId": "6a6751f59c5dbc80823b3cf47c3aaae063991b86", "title": "TinyLLaVA: A Framework of Small-scale Large Multimodal Models"}, {"paperId": "ca00f4056f9039d3c1a4c3a113f5ee0527149b66", "title": "Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs"}, {"paperId": "560c6f24c335c2dd27be0cfa50dbdbb50a9e4bfd", "title": "TinyLlama: An Open-Source Small Language Model"}, {"paperId": "ece33ee67d74c29cd2a83c505e5bf0b818f9c2a1", "title": "LLaVA-Phi: Efficient Multi-Modal Assistant with Small Language Model"}, {"paperId": "6a33e58ef961a3a0a5657518b2be86395eb7c8d0", "title": "InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks"}, {"paperId": "2d4a853affeb0b164fc1134df612aea658f36459", "title": "Mixture of Cluster-conditional LoRA Experts for Vision-language Instruction Tuning"}, {"paperId": "2141ed804636a1cf339d606cd03fd3b3e9582133", "title": "VILA: On Pre-training for Visual Language Models"}, {"paperId": "9fb75a6b88122147e21a2d08ae5c04fe9556dd96", "title": "DAMEX: Dataset-aware Mixture-of-Experts for visual understanding of mixture-of-datasets"}, {"paperId": "68e0e789b5147b1e7d028c7a825650075f4e26bf", "title": "PaLI-3 Vision Language Models: Smaller, Faster, Stronger"}, {"paperId": "124d4d374fbef2016fa9880489871a58a7450644", "title": "Improved Baselines with Visual Instruction Tuning"}, {"paperId": "5ab8337d6c594c4cec1ae67428a21dbfca1aff15", "title": "MultiWay-Adapater: Adapting large-scale multi-modal models for scalable image-text retrieval"}, {"paperId": "98083235def2555675b17379b09f58066977058c", "title": "Parameter and Computation Efficient Transfer Learning for Vision-Language Pre-trained Models"}, {"paperId": "94972e30504017156ef5b5debc419bf6edc67384", "title": "MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities"}, {"paperId": "4309d572a37d655779f9dce6a2c98c66334132de", "title": "SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension"}, {"paperId": "b37b1dc72b1882858f5120f2cd6883134089a6ed", "title": "MMBench: Is Your Multi-modal Model an All-around Player?"}, {"paperId": "e2a58fd18961c3941102989e3a3d0d27c615e015", "title": "Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic"}, {"paperId": "3b6179c293df29e31d31cea46476f104ab6950f2", "title": "Kosmos-2: Grounding Multimodal Large Language Models to the World"}, {"paperId": "697e0add95e880bd42e00bef838181e105f91981", "title": "MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models"}, {"paperId": "6fb5c0eff3696ef252aca9638e10176ecce7cecb", "title": "Generating Images with Multimodal Language Models"}, {"paperId": "d7fb8ecc2cf19687d5a56b93c19e0669961e7791", "title": "PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and Compositional Experts"}, {"paperId": "9c3a9b4821daa03cb5369041d59d2714329a3811", "title": "Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models"}, {"paperId": "206400aba5f12f734cdd2e4ab48ef6014ea60773", "title": "Evaluating Object Hallucination in Large Vision-Language Models"}, {"paperId": "0c7ce5898dab92da540457b754254d72b8592fc2", "title": "Parameter-efficient Tuning of Large-scale Multimodal Foundation Model"}, {"paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd", "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"}, {"paperId": "0d043b0bd4a981f7e6135a79dac6d71a809af8cb", "title": "Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings"}, {"paperId": "570079bbdd8758dfe865097e05719313c9c1301a", "title": "LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model"}, {"paperId": "ca6a2bc279be5a3349a22bfd6866ed633d18734b", "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"}, {"paperId": "2bc22b50f2a517fa57ae48135f42b18ba3da1cb4", "title": "CoT-MoTE: Exploring ConTextual Masked Auto-Encoder Pre-training with Mixture-of-Textual-Experts for Passage Retrieval"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "a757999ed260d7bc45484dc6b4456bf33fe6f679", "title": "LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention"}, {"paperId": "27d391d65ab42c30dc35595213ba6585633afa5d", "title": "CoLT5: Faster Long-Range Transformers with Conditional Computation"}, {"paperId": "9d12916dd46df7a6446cbec0bc4d054f7dafcdab", "title": "Scaling Vision-Language Models with Sparse Mixture of Experts"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "d3135733aa39dec20ce72aa138589dda27c8406d", "title": "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering"}, {"paperId": "02251886950770e82b3d68564d60cdfe15e73199", "title": "Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks"}, {"paperId": "1629ad1cbbc7887e89276dacc7f30e215885e0ff", "title": "RoME: Role-aware Mixture-of-Expert Transformer for Text-to-Video Retrieval"}, {"paperId": "bedf0d6e0623ab48349e3d2a493e7fbb79ca5ef5", "title": "Uni-Perceiver-MoE: Learning Sparse Generalist Models with Conditional MoEs"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "d2ef4c6b2799aec4b0fb933459abbfecb8d90fbd", "title": "A Survivor in the Era of Large-Scale Pretraining: An Empirical Study of One-Stage Referring Expression Comprehension"}, {"paperId": "55a19318cc93714802c7ac59e07651789749b20c", "title": "VL-ADAPTER: Parameter-Efficient Transfer Learning for Vision-and-Language Tasks"}, {"paperId": "cf7c2e0e4fb2af689aaf4b7a7cddf7b1f4d5e3f0", "title": "VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts"}, {"paperId": "94ff111c4d81bd03f159321728ceec8b4711c89d", "title": "An Empirical Study of Training End-to-End Vision-and-Language Transformers"}, {"paperId": "8ae292cbd9144acbf4b42b7ead82b079faf33192", "title": "Beyond Distillation: Task-level Mixture-of-Experts for Efficient Inference"}, {"paperId": "0839722fb5369c0abaff8515bfc08299efc790a1", "title": "ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "5e5fbc41106db9acaaf3a365801051e477f0e984", "title": "UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning"}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "c3afcd7e57c3e04b03b0b5001a3854482fa39441", "title": "In Defense of Grid Features for Visual Question Answering"}, {"paperId": "5aec474c31a2f4b74703c6f786c0a8ff85c450da", "title": "VisualBERT: A Simple and Performant Baseline for Vision and Language"}, {"paperId": "65a9c7b0800c86a196bc14e7621ff895cc6ab287", "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"}, {"paperId": "af1f7739283bdbd2b7a94903041f6d6afd991907", "title": "Towards VQA Models That Can Read"}, {"paperId": "a7ac99d7cf3f568ab1a741392144b646b856ae0c", "title": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering"}, {"paperId": "a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c", "title": "VizWiz Grand Challenge: Answering Visual Questions from Blind People"}, {"paperId": "7e232313a59d735ef7c8a9f4cc7bc980a29deb5e", "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"}, {"paperId": "44ddac48353ead135eef4096859956eaa31be2a5", "title": "Learning Factored Representations in a Deep Mixture of Experts"}, {"paperId": "c8d90974c3f3b40fa05e322df2905fc16204aa56", "title": "Adaptive Mixtures of Local Experts"}, {"paperId": "5ddb51ae85deca14dc7fc8adc07305c22a1ebe0a", "title": "Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Moe-llava"}, {"paperId": null, "title": "If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully"}, {"paperId": null, "title": "guidelines for their institution. \u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review"}]}