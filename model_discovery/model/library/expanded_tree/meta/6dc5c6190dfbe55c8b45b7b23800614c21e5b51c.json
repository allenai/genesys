{"paperId": "6dc5c6190dfbe55c8b45b7b23800614c21e5b51c", "abstract": "We present the design, implementation and engineering experience in building and deploying MegaScale, a production system for training large language models (LLMs) at the scale of more than 10,000 GPUs. Training LLMs at this scale brings unprecedented challenges to training efficiency and stability. We take a full-stack approach that co-designs the algorithmic and system components across model block and optimizer design, computation and communication overlapping, operator optimization, data pipeline, and network performance tuning. Maintaining high efficiency throughout the training process (i.e., stability) is an important consideration in production given the long extent of LLM training jobs. Many hard stability issues only emerge at large scale, and in-depth observability is the key to address them. We develop a set of diagnosis tools to monitor system components and events deep in the stack, identify root causes, and derive effective techniques to achieve fault tolerance and mitigate stragglers. MegaScale achieves 55.2% Model FLOPs Utilization (MFU) when training a 175B LLM model on 12,288 GPUs, improving the MFU by 1.34x compared to Megatron-LM. We share our operational experience in identifying and fixing failures and stragglers. We hope by articulating the problems and sharing our experience from a systems perspective, this work can inspire future LLM systems research.", "venue": "Symposium on Networked Systems Design and Implementation", "year": 2024, "citationCount": 16, "influentialCitationCount": 2, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A set of diagnosis tools to monitor system components and events deep in the stack, identify root causes, and derive effective techniques to achieve fault tolerance and mitigate stragglers are developed."}, "embedding": {"model": "specter_v2", "vector": [0.12102638930082321, 0.1417538970708847, -0.4632101356983185, 0.00891937967389822, -0.3734574615955353, 0.14745943248271942, 0.33369749784469604, -0.35021013021469116, -0.3938870429992676, -0.45781928300857544, 0.031958792358636856, -0.42688921093940735, 0.6098639369010925, 0.09900301694869995, -0.3139845132827759, 0.17368727922439575, -1.1585776805877686, 0.37153059244155884, -0.08008063584566116, -0.16976912319660187, -0.35523805022239685, -0.09642007946968079, -1.4931584596633911, 0.43279170989990234, 0.5320462584495544, 0.6929896473884583, -0.29271069169044495, 1.1159658432006836, -0.3305897116661072, 0.5838568806648254, 0.5599152445793152, 0.4627477824687958, 0.0733560174703598, -0.017534466460347176, -0.28384900093078613, 0.17516912519931793, 0.15214329957962036, -0.23866687715053558, -0.4757908284664154, 0.555008590221405, -0.0923319086432457, 0.3371446132659912, -0.056489378213882446, -0.9743273258209229, 0.1834477335214615, 0.22675710916519165, 0.08322713524103165, 0.8365448117256165, -0.8021904826164246, -0.37077605724334717, 0.7391511797904968, -1.4769245386123657, 0.0624811016023159, 1.2762247323989868, 0.7681429386138916, 0.20610229671001434, -0.35879114270210266, -0.5632854700088501, 0.32568082213401794, -0.4687141180038452, -0.7190282344818115, -0.49339035153388977, -0.8148024082183838, -0.39391618967056274, 2.0062689781188965, -0.2798781394958496, -0.23395901918411255, 0.22229883074760437, 0.09885649383068085, 1.177775502204895, -0.06795604526996613, -1.017037034034729, -0.01917458325624466, 0.032222930341959, 0.6232853531837463, 0.9796699285507202, -0.30518871545791626, 0.4623832106590271, -1.201429843902588, -0.49483877420425415, 0.2881653904914856, -0.40530940890312195, 0.35615354776382446, -0.2786123752593994, 0.209291011095047, 0.704699695110321, 0.10119683295488358, 0.718852162361145, 0.16750724613666534, 0.8223127722740173, 0.7585644721984863, 0.3912305235862732, 0.39176860451698303, -0.052495118230581284, 0.07272695004940033, 0.034955210983753204, -1.088748574256897, -0.157045379281044, 0.13078580796718597, 0.9692786931991577, -0.1280052214860916, 0.5196049809455872, -0.649581789970398, 0.1703420728445053, 1.145678997039795, 0.04595912620425224, 0.2754994034767151, -0.4509861171245575, 0.42528629302978516, -0.6634983420372009, -0.061604470014572144, -0.08073090761899948, -0.5105859637260437, -0.5996391177177429, -0.900447428226471, -0.6444960832595825, -0.6197842955589294, -0.35790714621543884, -0.8604256510734558, 0.41328632831573486, -0.07419580221176147, 0.4222080111503601, 0.012749123387038708, 0.6065487861633301, 0.5774201154708862, 0.5084190964698792, 0.20222893357276917, 0.2400408536195755, 0.8607367873191833, -1.343422770500183, -0.008085452951490879, -1.1041676998138428, 0.8428916335105896, -0.6098904609680176, -0.06373216956853867, -0.3585767149925232, -1.5178431272506714, -0.9445137977600098, -0.8211379051208496, 0.08057790249586105, -0.1519133448600769, 0.32836031913757324, 1.3348615169525146, 0.5753679275512695, -1.1907814741134644, 0.8853889107704163, -0.811448872089386, 0.008076622150838375, 0.30172330141067505, 0.48340243101119995, 0.5414966344833374, -0.5505775809288025, -1.017334222793579, -0.045361265540122986, 0.17003601789474487, -0.7057024836540222, -0.043163325637578964, -0.8121968507766724, -0.8531364798545837, -0.1507750153541565, -0.0828251913189888, -0.45502278208732605, 1.2063020467758179, -0.14853738248348236, -1.0336363315582275, 0.5926560759544373, -0.2794032394886017, 0.254239946603775, 0.521422266960144, 0.31767597794532776, -0.8196829557418823, -0.35848796367645264, -0.49078643321990967, 0.3446812927722931, 0.5556050539016724, -0.08408495038747787, -0.17646759748458862, 0.3994256854057312, -0.4935261607170105, 0.08273853361606598, -0.22013486921787262, 1.1070886850357056, -0.6829996705055237, 0.151513934135437, 0.4849855899810791, 0.3408679664134979, -0.1629197746515274, -0.1973322331905365, -0.17559237778186798, -0.39624711871147156, 0.6746428608894348, 0.04020354524254799, 0.8379377126693726, -0.9784159064292908, -0.8996789455413818, 0.3238030672073364, -0.19231420755386353, -0.07063572108745575, -0.49561217427253723, 0.7382408976554871, -0.5156068205833435, 0.11196199804544449, -0.10822761058807373, -1.2401199340820312, 0.03277308866381645, -0.1960020214319229, -0.5988969206809998, -0.24971280992031097, -0.07662313431501389, 0.8028929233551025, -0.5786926746368408, 0.016650555655360222, -0.2621270716190338, 0.3401326835155487, -1.206284523010254, 1.071566104888916, -0.32534000277519226, 0.17656438052654266, 0.22131241858005524, 0.02528109960258007, 0.41625213623046875, -0.552340567111969, 0.5603504776954651, -0.48979735374450684, -0.21811160445213318, -0.02654321677982807, -0.20723456144332886, 1.2568986415863037, -0.5738124847412109, 0.32593658566474915, 0.4697655141353607, -0.6015471816062927, -0.4249923825263977, 0.40921252965927124, -0.06864750385284424, -0.45354458689689636, 0.49745485186576843, 0.5378836989402771, -0.27949216961860657, 0.44445133209228516, 1.1084250211715698, 0.7492409944534302, -0.31544744968414307, 0.5819934606552124, 0.3968553841114044, -0.17739956080913544, 0.5109778642654419, 0.5084629058837891, 0.7331671714782715, 0.2333107441663742, -0.34239882230758667, -0.32762444019317627, 0.022724445909261703, -0.7643408179283142, -0.2846425771713257, 0.8518964648246765, 0.4854483902454376, 0.7053921222686768, 0.6094986200332642, -0.6482701301574707, -0.676966667175293, 0.221426323056221, 0.44139015674591064, 1.6985119581222534, -0.40103861689567566, 0.11617516726255417, -0.7609535455703735, -0.1647759974002838, -0.1017056256532669, -0.26314300298690796, 0.03333615884184837, -0.09753109514713287, -0.573667585849762, -1.4618958234786987, 0.7547166347503662, 0.18043743073940277, 0.6317464709281921, -0.5424171090126038, -0.4176436960697174, -0.604653537273407, 0.8477892279624939, -0.9495919346809387, -0.48375508189201355, 0.3929886817932129, -0.6400917172431946, 0.0066208504140377045, 0.22605621814727783, -0.10663606226444244, 0.5490697026252747, -0.28675612807273865, 1.0611424446105957, 0.1829027235507965, -0.7105000019073486, 0.17928272485733032, 0.6073101162910461, 0.013402089476585388, -1.1879158020019531, 0.13675397634506226, 0.37463903427124023, -0.3104192614555359, -0.2923218011856079, 0.20375269651412964, 0.20927643775939941, 0.04434720799326897, -0.32280370593070984, 0.33885905146598816, 0.17446006834506989, 0.06682660430669785, 0.49320319294929504, -0.1283111274242401, -0.16984309256076813, -1.426866054534912, 1.0205532312393188, -0.03593479469418526, -0.5552581548690796, 0.25768592953681946, -0.6999916434288025, -0.32450026273727417, 0.45861852169036865, -0.49041128158569336, -0.08477012813091278, -1.1896445751190186, 0.0019118675263598561, -0.4177871644496918, -0.021034805104136467, 0.0714731365442276, 0.6580078601837158, -0.48356616497039795, 0.24483415484428406, 0.5037521123886108, 0.5634965896606445, 0.07387053966522217, 0.467052698135376, -0.8109833002090454, 0.07169391214847565, -0.1448419988155365, -0.08799270540475845, -0.10105866938829422, -0.16574352979660034, -0.93779456615448, -0.2789475619792938, -0.17680369317531586, -0.014677920378744602, -0.27149730920791626, 0.10414719581604004, -0.7627710700035095, -0.7713112235069275, 0.10258545726537704, -0.818060040473938, -0.5751447081565857, 0.5606873631477356, -0.2799461781978607, 0.04738670960068703, -0.9824574589729309, -1.6497000455856323, -0.6132554411888123, -0.8710080981254578, -1.3927911520004272, 0.5805066227912903, 0.018556229770183563, -0.4348222315311432, -0.5022913217544556, -0.450838565826416, -0.28097060322761536, 1.133478045463562, -0.5022162199020386, 0.7618705630302429, 0.35182759165763855, -0.21188810467720032, -0.04808139055967331, -0.23570466041564941, 0.18782617151737213, -0.6753050088882446, 0.5552933216094971, -0.9047361612319946, -0.2738026976585388, -0.62056964635849, -0.6718029975891113, 0.18850475549697876, 0.14521533250808716, 0.7576695680618286, 0.4804646670818329, -0.606903612613678, 0.5375500917434692, 1.219760537147522, -0.7622305750846863, -0.1636461317539215, -0.31047192215919495, 1.0936461687088013, -0.33493533730506897, -0.38483405113220215, 0.493709534406662, -0.42139291763305664, 0.3992176651954651, -0.1435471475124359, -0.432311087846756, 0.022275080904364586, 0.0030021406710147858, 0.42251428961753845, 1.6698516607284546, 0.8802012205123901, -0.003967433702200651, -0.9693726897239685, 0.26906856894493103, -1.2107309103012085, -0.17746713757514954, 0.35362744331359863, 0.6366019248962402, 0.18372893333435059, 0.08580673485994339, -0.23974207043647766, -0.26160359382629395, 0.4438583254814148, 0.28251901268959045, -0.5357414484024048, -1.043654203414917, 0.27332302927970886, 0.592531144618988, 0.37185540795326233, 0.804023265838623, -0.1261512190103531, 0.5296780467033386, 14.965300559997559, 1.2610900402069092, -0.06602650135755539, 0.8790764212608337, 0.8284160494804382, 0.14358247816562653, -0.2574593424797058, -0.3079299330711365, -1.11429762840271, 0.012565616518259048, 1.4327465295791626, 0.4861272871494293, 0.6403017640113831, 0.3101613521575928, 0.16995997726917267, -0.13908874988555908, -0.17443780601024628, 0.4856056571006775, 0.4365626573562622, -1.3751732110977173, 0.20299510657787323, 0.0907360315322876, 0.6356369256973267, 1.0147370100021362, 0.6517495512962341, 0.8326370120048523, 0.5338755249977112, -0.6167199611663818, 0.48471927642822266, -0.08659982681274414, 1.0733391046524048, -0.521850049495697, 0.26180171966552734, 0.8330932259559631, -0.8154619336128235, 0.3469809293746948, -0.19950821995735168, -1.270898461341858, 0.20643912255764008, 0.30925253033638, -0.5374122262001038, -0.3014729917049408, -0.43456411361694336, 0.26766112446784973, 0.3202509582042694, 0.19601544737815857, 0.360708087682724, 0.6386697292327881, -0.38887766003608704, 0.30424150824546814, 0.1124148741364479, 0.37441402673721313, -0.15013618767261505, 0.04184892401099205, -0.05652759596705437, -0.11773665249347687, 0.4985235631465912, 0.29672718048095703, -0.4512026011943817, -0.4152863919734955, -0.02669784054160118, -0.29586687684059143, -0.17866741120815277, 0.9762730598449707, -0.19802774488925934, 0.2657105624675751, -0.4722571074962616, 0.3697158992290497, 0.9416261911392212, -0.007618272677063942, -0.447268009185791, 0.6238604784011841, 0.5060948729515076, -0.8556534051895142, -0.22146610915660858, 0.2739873230457306, -0.30178987979888916, -0.5249454975128174, -0.8479443788528442, -0.5498451590538025, 0.260726660490036, -0.3714255392551422, -0.5799044966697693, 0.8089888095855713, -0.5004481673240662, -0.1306183934211731, 0.5314139723777771, -0.722764253616333, -0.3039017617702484, 0.7728307247161865, -1.1587841510772705, -0.7792186141014099, 0.4037875831127167, -0.6193223595619202, -0.675596296787262, -0.07040952891111374, 1.428117036819458, 0.5740804076194763, -0.5810430645942688, 0.20379860699176788, 0.23976436257362366, -0.1537841111421585, -0.4026564955711365, -0.33751946687698364, 1.4641532897949219, 0.6959101557731628, -0.1681399643421173, 0.10792752355337143, 0.0764586478471756, 0.026971621438860893, -0.9145759344100952, -0.31428566575050354, 0.46204835176467896, -0.7400937676429749, -0.05674183741211891, -1.0308700799942017, -0.7700381278991699, 0.26534032821655273, 0.16818517446517944, 0.20573826134204865, 0.5171621441841125, 0.06519444286823273, -0.3324134349822998, 0.1205102875828743, -0.59344083070755, -0.15920941531658173, 0.6176531314849854, -1.0000581741333008, 0.3579862415790558, 0.3196788728237152, 0.40383100509643555, -1.7563765048980713, -0.41674551367759705, -0.3119579553604126, 0.0062981173396110535, -0.4184682369232178, 0.6793140172958374, -0.3219810724258423, 0.7682891488075256, 0.8646348118782043, -0.015122354961931705, -0.6231251955032349, 0.36543968319892883, -0.798808217048645, -0.09657856822013855, 0.02917981892824173, 0.6463081240653992, -0.33102351427078247, 0.6904951930046082, 1.0395034551620483, -0.15063385665416718, -0.6090952754020691, -0.6412041187286377, -0.04267968609929085, -0.11826010793447495, -0.7760412693023682, 0.09726323932409286, -0.07575829327106476, 0.08876067399978638, -0.22433529794216156, 0.2168218195438385, 0.8199004530906677, -0.22117988765239716, -0.31769677996635437, 0.2865426242351532, 0.38666704297065735, -0.5116875171661377, -0.6365838646888733, -0.18688535690307617, -0.9625868201255798, 0.02525337040424347, -1.2887624502182007, 0.020811138674616814, -0.5242710709571838, -0.5676704049110413, -0.433681458234787, 0.16893741488456726, 0.01457992848008871, 0.5412899851799011, -0.031156564131379128, -0.6499747633934021, -0.5624399781227112, -0.6982303261756897, 0.5801942348480225, 0.6845324039459229, -0.3112935423851013, 0.2878302335739136, -0.10029226541519165, 0.31118106842041016, 0.273987740278244, 0.31911659240722656, -0.19129548966884613, -0.8524879217147827, -1.4597457647323608, 0.28208282589912415, 0.017224948853254318, -0.34351369738578796, -0.9532678723335266, 0.6372079253196716, 0.45558324456214905, -0.14166031777858734, 0.436937540769577, 0.07571905851364136, -0.7682097554206848, -0.36180031299591064, 0.44418561458587646, -0.4658404588699341, 0.3333643078804016, 0.8482180237770081, -0.9502018094062805, -0.0488412044942379, 0.6440393924713135, 0.09156879782676697, -0.720780611038208, -0.9336299300193787, 0.4412590265274048, -0.443378210067749, 0.36510759592056274, -0.20427164435386658, 0.3563068211078644, -1.0452083349227905, 0.003317189635708928, -0.12260730564594269, 0.6754637360572815, -0.101045623421669, 0.9306712746620178, 0.12547153234481812, -0.9972124695777893, 0.18469060957431793, 0.6574844717979431, -0.48744678497314453, -0.05367839336395264, 1.030590295791626, 0.40846720337867737, -1.065760612487793, 0.16692698001861572, 0.3489704132080078, 0.09275351464748383, -1.015114188194275, -0.19257448613643646, 0.9469345211982727, -0.48494699597358704, -0.11167288571596146, 1.5121299028396606, -0.40756475925445557, -1.0546950101852417, -0.049337323755025864, -1.0478235483169556, -0.03367180377244949, -0.566242516040802, 0.5904573202133179, 0.04087408632040024, 0.5314623117446899, -0.01573149859905243, -0.615054190158844, -0.07675151526927948, -0.015348508954048157, -0.6137967705726624, 0.01831609010696411, -0.04479673132300377, -0.5047101974487305, 0.5138946175575256, 0.7792484164237976, -0.5481821894645691, -0.6132118105888367, -0.45039403438568115, -0.4475475549697876, 0.181975319981575, 0.4332093894481659, -0.2224707305431366, -0.8791276216506958, 0.8677127957344055, 0.46696555614471436, 0.2936830520629883, -0.03446156159043312, -0.5349403619766235, 0.3224008083343506, 0.25490081310272217, 0.3314720392227173, -0.6923967003822327, -1.0058716535568237, 1.275180459022522, 0.6537662744522095, -0.9804520010948181, 0.3245218098163605, -0.308756947517395, -0.5657941102981567, 0.6715278625488281, 0.6759771704673767, 0.0704072117805481, 0.9631765484809875, 0.4025435149669647, 0.22357001900672913, 0.144452765583992, -0.8708354830741882, -0.11870674043893814, 0.7495476603507996, 0.20172518491744995, 0.9480821490287781, 0.38754647970199585, 0.17129860818386078, 0.5498425364494324, 0.1800181269645691, 0.2806375324726105, 0.3665750026702881, 0.7202968001365662, 0.0063115572556853294, -0.16495314240455627, 0.05552662909030914, 0.671677827835083, -0.2604431211948395, -0.7556584477424622, 0.5009198188781738, 0.5361658930778503, 0.42814886569976807, 0.4540587067604065, 1.0846973657608032, 0.009526887908577919, 0.39454352855682373, 0.1899537593126297, 0.5712236762046814, -0.6500564813613892, -0.24799498915672302, -0.0644172728061676, -0.3153086304664612, -0.11896255612373352, 0.14128123223781586, -0.12165634334087372, -0.8847580552101135, -0.7480320334434509, 0.5796392560005188, 0.319494366645813, 0.07425051927566528, 1.1517695188522339, 0.9876549243927002, 1.0829514265060425, -0.36001846194267273, -0.7876929640769958, -0.3218006193637848, -0.5115389823913574, -0.24404145777225494, -0.6189085841178894, -0.4248017966747284, 0.10717032104730606, 0.04349740594625473, -0.7139073014259338]}, "authors": [{"authorId": "2287104163", "name": "Ziheng Jiang"}, {"authorId": "2257447831", "name": "Haibin Lin"}, {"authorId": "2203414303", "name": "Yinmin Zhong"}, {"authorId": "2286915972", "name": "Qi Huang"}, {"authorId": "40930325", "name": "Yangrui Chen"}, {"authorId": "2287236091", "name": "Zhi Zhang"}, {"authorId": "9561490", "name": "Yanghua Peng"}, {"authorId": "2286959876", "name": "Xiang Li"}, {"authorId": "2288872668", "name": "Cong Xie"}, {"authorId": "2286880567", "name": "Shibiao Nong"}, {"authorId": "2289606426", "name": "Yulu Jia"}, {"authorId": "2290008572", "name": "Sun He"}, {"authorId": "2287301967", "name": "Hongmin Chen"}, {"authorId": "66318775", "name": "Zhihao Bai"}, {"authorId": "2286882255", "name": "Qi Hou"}, {"authorId": "2287697563", "name": "Shipeng Yan"}, {"authorId": "2280044667", "name": "Ding Zhou"}, {"authorId": "2286882026", "name": "Yiyao Sheng"}, {"authorId": "2175189294", "name": "Zhuo Jiang"}, {"authorId": "2286984126", "name": "Haohan Xu"}, {"authorId": "2247920779", "name": "Haoran Wei"}, {"authorId": "2287810042", "name": "Zhang Zhang"}, {"authorId": "2195852454", "name": "Pengfei Nie"}, {"authorId": "2286881314", "name": "Leqi Zou"}, {"authorId": "2111005284", "name": "Sida Zhao"}, {"authorId": "2286890573", "name": "Liang Xiang"}, {"authorId": "2287258718", "name": "Zherui Liu"}, {"authorId": "2265944653", "name": "Zhe Li"}, {"authorId": "2112828847", "name": "X. Jia"}, {"authorId": "2269130869", "name": "Jia-jun Ye"}, {"authorId": "2290431017", "name": "Xin Jin"}, {"authorId": "2249608212", "name": "Xin Liu"}], "references": [{"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "240103933ffe3dac2179cc160a2bd91299357a53", "title": "Retentive Network: A Successor to Transformer for Large Language Models"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "a0e7c31d723608e03f30fc92ffc2a604a7a039da", "title": "PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "2c994fadbb84fb960d8306ee138dbeef41a5b323", "title": "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6", "title": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers"}, {"paperId": "d219d971b16c708b8debc731e0c541ae218c7caf", "title": "WeLM: A Well-Read Pre-trained Language Model for Chinese"}, {"paperId": "4be7d1524edb0137599a5cc95f72844b85a52fe1", "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"}, {"paperId": "bc8b82e8eb0b0714892e4ec7a54ebdf47c4fde96", "title": "Reducing Activation Recomputation in Large Transformer Models"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "3dc7dc1bea9a4f70c02b6759a0bda7aca0005a9e", "title": "A General Language Assistant as a Laboratory for Alignment"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "774591fdd988eaaff3917e7c5171d044b0843e63", "title": "Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM"}, {"paperId": "b103e87c7727134927d3ffb06934a95c10c02fc0", "title": "GPT-3: Its Nature, Scope, Limits, and Consequences"}, {"paperId": "e535542a539f44dc284bd35ffe609010c6be68eb", "title": "Elastic parameter server load distribution in deep learning clusters"}, {"paperId": "5b1809dce04d222900cc64f39f31e45f65bef6f3", "title": "Swift: Delay is Simple and Effective for Congestion Control in the Datacenter"}, {"paperId": "f46c562229c5bc419bbbfb63239431590e4b340a", "title": "Train Big, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers"}, {"paperId": "488128bc81bb96ecdfdff8ca79fb793308d05285", "title": "Preemptive All-reduce Scheduling for Expediting Distributed DNN Training"}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "3fd7c9ba742dd2b435afa75217847e5087e2f2a8", "title": "PipeDream: generalized pipeline parallelism for DNN training"}, {"paperId": "76c929af6735cdff2c4badc9a9c8f39d15ea3e70", "title": "A generic communication scheduler for distributed DNN training acceleration"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "90cbe7f340a8de92143e5b464e6e963bb95f6129", "title": "Priority-based Parameter Propagation for Distributed DNN Training"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "bc789aef715498e79a74f857fa090ece9e383bf1", "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes"}, {"paperId": "dad9d034daf67a137cab06d943eb0cc587ba2025", "title": "Proceedings of the 14th International Conference on emerging Networking EXperiments and Technologies"}, {"paperId": "d79a26226393f687ddbc375e32055b40b8ad8d38", "title": "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"}, {"paperId": "7aeae28124c322ded336e753c016488cd7305562", "title": "Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training"}, {"paperId": "93a06eb066fe58ed7d036e46e4cee53483e16bb8", "title": "Optimus: an efficient dynamic resource scheduler for deep learning clusters"}, {"paperId": "2229ac756f89c3db017293918548555734d2f891", "title": "TicTac: Accelerating Distributed Deep Learning with Communication Scheduling"}, {"paperId": "e7fd6848cb29ca221a7e17d823e06fb566f1f135", "title": "Mixed Precision Training"}, {"paperId": "d110cd6af0894e691a905f01b15f53ef3b32746d", "title": "LossRadar: Fast Detection of Lost Packets in Data Center Networks"}, {"paperId": "c9d64aaa2007b60ef7814acc895dd90f15578a20", "title": "QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding"}, {"paperId": "4954fa180728932959997a4768411ff9136aac81", "title": "TensorFlow: A system for large-scale machine learning"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "65da29a03c8905cbc0614612d1632864336c4786", "title": "Pingmesh: A Large-Scale System for Data Center Network Latency Measurement and Analysis"}, {"paperId": "07367703f587dbc3313cc613289c4330cebe5c8c", "title": "Congestion Control for Large-Scale RDMA Deployments"}, {"paperId": "4f0344780b323013f72aec039afc58f7b953bcee", "title": "Packet-Level Telemetry in Large Datacenter Networks"}, {"paperId": "a4f1295b42b8f80c1a83fa3f5930dd1c5ec6a560", "title": "Performance modelling and analysis of mobile grid computing systems"}, {"paperId": "ea67ad1dae7c4b3671c04fd792327d881b625409", "title": "Proactive Fault Tolerance in MPI Applications Via Task Migration"}, {"paperId": "6d118ffad45fcb33beba7ee556ffdbc8fa78241d", "title": "Hostping: Diagnosing Intra-host Network Bottlenecks in RDMA Servers"}, {"paperId": null, "title": "\u201cKoala: A dialogue model for academic research.\u201d"}, {"paperId": "d0feda74906536cc30cdfd037f63f5ec7bf5ffd5", "title": "SAPipe: Staleness-Aware Pipeline for Data Parallel DNN Training"}, {"paperId": null, "title": "\u201cGPT-J-6B: A 6 Billion Parameter Autoregressive Language Model.\u201d"}, {"paperId": null, "title": "\u201cPytorch distributed: Experiences on accelerating data parallel training,\u201d"}, {"paperId": "9bc6133d846631728844f6ba77dc74eace0f4219", "title": "NetBouncer: Active Device and Link Failure Localization in Data Center Networks"}, {"paperId": null, "title": "\u201cIeee 802.1 qbb - priority-based flow control.\u201d"}, {"paperId": "5c08373287fafeb145e7ee1ff3acdac9538a3cfe", "title": "Proactive Fault Tolerance in Large Systems"}, {"paperId": "df81503641114f32149917e6f84b9c44d8d1f606", "title": "Distributed systems: Principles and Paradigms"}, {"paperId": "0142fbf89f58ddb940a7f5cfd8a3ccd290fb2db5", "title": "Fault Tolerance in Distributed Paradigms"}, {"paperId": null, "title": "\u201cStanford al-paca: An instruction-following llama model.\u201d"}, {"paperId": null, "title": "\u201cIntroducing chatgpt.\u201d"}, {"paperId": null, "title": "\u201cVicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality,\u201d"}, {"paperId": null, "title": "\u201cBelle: Be everyone\u2019s large language model engine.\u201d"}]}