{"paperId": "40ca4fcfffa7ca9aa9b7ff06ecf3cd0436712d78", "abstract": "Transformer networks use pairwise attention to compute contextual embeddings of inputs, and have redefined the state of the art in many NLP tasks. However, these models suffer from quadratic computational cost in the input sequence length $n$ to compute attention in each layer. This has prompted recent research into faster attention models, with a predominant approach involving sparsifying the connections in the attention layers. While empirically promising for long sequences, fundamental questions remain unanswered: Can sparse transformers approximate any arbitrary sequence-to-sequence function, similar to their dense counterparts? How does the sparsity pattern and the sparsity level affect their performance? In this paper, we address these questions and provide a unifying framework that captures existing sparse attention models. Our analysis proposes sufficient conditions under which we prove that a sparse attention model can universally approximate any sequence-to-sequence function. Surprisingly, our results show the existence of models with only $O(n)$ connections per attention layer that can approximate the same function class as the dense model with $n^2$ connections. Lastly, we present experiments comparing different patterns/levels of sparsity on standard NLP tasks.", "venue": "Neural Information Processing Systems", "year": 2020, "citationCount": 62, "influentialCitationCount": 4, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes sufficient conditions under which to prove that a sparse attention model can universally approximate any sequence-to-sequence function, and shows the existence of models with only $O(n)$ connections per attention layer that can approximate the same function class as the dense model with $n^2$ connections."}, "embedding": {"model": "specter_v2", "vector": [0.5958276391029358, 0.8107394576072693, -0.44527825713157654, 0.03586230054497719, -0.3170425295829773, -0.3934783637523651, 0.5695364475250244, 0.1736716479063034, -0.22229184210300446, 0.26945263147354126, 0.5490404367446899, 0.05625074729323387, 0.25873398780822754, -0.05130792781710625, -0.5568013787269592, 0.12127361446619034, -0.6171525120735168, 0.41191884875297546, 0.19474412500858307, -0.2922133505344391, -0.19831812381744385, -0.8380253314971924, -1.0164377689361572, 0.26737016439437866, 0.2950141429901123, 0.691483736038208, 0.313466340303421, 0.7251933217048645, -0.4830084443092346, 0.5029093027114868, 0.5616940259933472, -0.6413297057151794, 0.30971911549568176, 0.02738524042069912, -0.4998091757297516, -0.7902882099151611, 0.34053754806518555, -0.13464803993701935, -0.7045948505401611, 0.9665568470954895, -0.6510286331176758, 0.20496898889541626, 0.453546941280365, -0.7648753523826599, -0.5898053050041199, 1.2771568298339844, 0.7307829856872559, 0.7704441547393799, 0.13359662890434265, -0.8591408133506775, 2.2617928981781006, -1.1348930597305298, 0.3856627941131592, 1.4951883554458618, 0.5444126725196838, 0.3901248574256897, -0.24397599697113037, -0.4694991409778595, 0.7561635971069336, 0.4949643313884735, -0.6739615201950073, -0.1382286548614502, -0.15484295785427094, 0.3416704833507538, 2.006608486175537, -0.3522905707359314, 0.19004672765731812, 0.4115631878376007, -0.35797885060310364, 1.4937729835510254, -0.2514674663543701, -0.9618855118751526, -0.45855239033699036, 0.09693041443824768, 0.1570420116186142, 0.8189005255699158, -0.42327025532722473, 0.20455819368362427, -1.0228145122528076, -0.3593609631061554, 0.4892616271972656, 0.35249319672584534, -0.08140897750854492, -0.07596803456544876, -0.06621471047401428, 0.4951418936252594, 0.6585224270820618, 0.9406470060348511, -0.39298537373542786, 0.8285506367683411, 0.536770761013031, 0.48461806774139404, -0.3744669258594513, 0.6160529851913452, -0.23737536370754242, 0.3653572201728821, -0.4900214374065399, 0.039003919810056686, 0.27836179733276367, 0.9331054091453552, 0.024331629276275635, 0.02547297067940235, -0.2443811297416687, 0.11812577396631241, 1.150456190109253, -0.024291276931762695, 0.32254254817962646, -0.6535525321960449, 0.10764501988887787, -0.4017178416252136, 0.14700382947921753, -0.9171730875968933, 0.16671545803546906, -0.02675134316086769, -0.5491164922714233, -1.4434700012207031, -0.24278250336647034, 0.29970991611480713, -0.31204307079315186, 0.9219781756401062, -0.37760889530181885, 0.15700359642505646, -0.2892037630081177, 0.4265650510787964, 0.275039404630661, 0.9143838882446289, 0.27508094906806946, 0.0394313707947731, 1.0222636461257935, -0.3227688670158386, -0.6829630732536316, -0.9621521830558777, 0.7249225378036499, -0.19218787550926208, 0.362296998500824, -0.22384630143642426, -1.2382018566131592, -0.7652753591537476, -0.7318271398544312, -0.14458335936069489, -0.6342196464538574, 0.04774095118045807, 1.0376378297805786, 0.2220202535390854, -1.1539114713668823, 0.7160201072692871, -0.3147267699241638, -0.36369258165359497, 0.5409954190254211, 0.43168872594833374, -0.0307686198502779, -0.518299400806427, -1.434211015701294, 0.5916475653648376, 0.2955097258090973, -0.561278760433197, -0.3568013906478882, -0.7972543835639954, -1.4713304042816162, 0.4522448480129242, 0.4441470503807068, -0.7387698292732239, 1.2154426574707031, -0.4032699167728424, -0.8787593245506287, 0.5993702411651611, -0.7268308401107788, -0.25517737865448, -0.1791944056749344, -0.42949774861335754, -0.335181325674057, -0.07742135226726532, -0.03792650252580643, 0.42494237422943115, 0.15052515268325806, -0.3714310824871063, -0.2850569188594818, 0.23194828629493713, -0.14813929796218872, -0.33906733989715576, -0.36258968710899353, 0.9626330733299255, -0.022090788930654526, -0.10340086370706558, -0.0814141258597374, 0.9018305540084839, -0.09477581828832626, -0.04615647718310356, -0.45434314012527466, -1.2579702138900757, 0.6905011534690857, 0.1411825269460678, 0.9852500557899475, -0.8089711666107178, -0.4408023953437805, -0.062495049089193344, 0.11899124085903168, -0.08594723790884018, -0.9026064276695251, 0.8045236468315125, -0.66567063331604, 0.6621472239494324, -0.5984248518943787, -0.9355002641677856, 0.046591393649578094, 0.2047356367111206, -0.7462999224662781, -0.29114964604377747, 0.11252464354038239, 1.1612269878387451, -1.11884343624115, -0.029204394668340683, 0.13093435764312744, 0.25669050216674805, -1.0313148498535156, 1.209538221359253, -0.6435800194740295, -0.3877682387828827, -0.08991221338510513, -0.10823475569486618, -0.39997440576553345, -0.46429261565208435, 0.2907354533672333, -0.3938595652580261, 0.21375346183776855, 0.6915600895881653, -0.022299302741885185, 1.2714413404464722, -0.4369753301143646, 0.6193764805793762, -0.06492172181606293, -1.075080394744873, 0.21632950007915497, 0.5868484377861023, -0.10062604397535324, -0.3561549484729767, 0.12266095727682114, 0.4651472866535187, -0.6548130512237549, -0.053133200854063034, 0.590762197971344, 0.5260342955589294, -0.2051015943288803, 0.2677653133869171, 0.589741051197052, -0.17234963178634644, 0.3155360519886017, 0.6527180671691895, 0.997855544090271, 0.2243560254573822, 0.8021250367164612, 0.15485802292823792, 0.2681332230567932, -0.7644041180610657, -0.02663968876004219, 0.5202312469482422, 0.9992022514343262, 0.4183672070503235, 0.7121168971061707, -0.8666808605194092, -0.6943672895431519, 0.27334126830101013, 0.6575051546096802, 1.2648940086364746, -0.12626050412654877, -0.5469675660133362, -0.5947977900505066, -0.5283206105232239, -0.32124805450439453, 0.2000768631696701, -0.6512696146965027, -0.17362840473651886, -0.6243706941604614, -0.784965991973877, 0.815763533115387, 0.6699393391609192, 0.5727909207344055, -0.7665948867797852, -0.13561345636844635, -0.31357917189598083, 0.1163526177406311, -0.9826467037200928, -0.45263105630874634, 0.5458982586860657, -0.4957980811595917, -0.38834577798843384, 0.35239914059638977, -0.44188058376312256, 0.3390549421310425, -0.9311838746070862, 0.9499788284301758, -0.4525175392627716, -0.2583905756473541, 0.46904370188713074, 0.6129869222640991, -0.494783878326416, -0.25291571021080017, 0.3124140799045563, -0.11549147963523865, -0.23251527547836304, 0.6234225034713745, 0.09374053031206131, 0.11309857666492462, 0.11321236193180084, -0.6098579168319702, -0.30119356513023376, -0.0864047184586525, 0.3083123564720154, 0.851886510848999, -0.3103749752044678, 0.19976314902305603, -1.371463656425476, 0.4389798939228058, -0.23929494619369507, -0.4161624014377594, 0.231070876121521, -0.42052701115608215, -0.35828375816345215, 0.8662447333335876, -0.7377460598945618, -0.10845823585987091, -0.42925214767456055, 0.20730087161064148, -0.3877175748348236, -0.3063138425350189, 0.45748525857925415, 0.02375834807753563, 0.12238647043704987, 0.2918277680873871, 0.375853955745697, 0.2756270468235016, 0.0437660738825798, 0.48186415433883667, -1.0755233764648438, 0.45415255427360535, 0.17552688717842102, 0.18936985731124878, -0.17220008373260498, 0.010035173036158085, -0.7650766372680664, -0.6171041131019592, -0.3181154727935791, 0.13217030465602875, 0.236191526055336, -0.06353747099637985, -0.1239878460764885, -1.1908317804336548, -0.5058580040931702, -1.282125473022461, -0.2742367684841156, -0.22068119049072266, -0.4180498719215393, -0.24732059240341187, -0.9374987483024597, -1.2987210750579834, -0.6281908750534058, -0.3629315197467804, -0.5261535048484802, 0.380923867225647, 0.15524181723594666, -0.606694221496582, -0.8805385828018188, 0.024532053619623184, -0.5546214580535889, 0.8796452879905701, -0.4481901526451111, 1.0444813966751099, -0.4027508795261383, -0.6208522915840149, -0.41766461730003357, 0.20951037108898163, 0.4392596483230591, -0.2010662704706192, 0.14384762942790985, -0.7674965858459473, 0.608056366443634, -0.3482918441295624, -0.36821773648262024, 0.08320483565330505, 0.5461146831512451, 0.9042516946792603, -0.35727831721305847, -0.759823203086853, 0.2630276679992676, 1.638198733329773, -0.5430828928947449, 0.3330483138561249, 0.18222175538539886, 0.917756974697113, 0.19250981509685516, -0.30047762393951416, 0.405468225479126, 0.41871148347854614, 0.2836722433567047, 0.5454616546630859, 0.24683256447315216, 0.05796629562973976, -0.9212324619293213, 0.4562850892543793, 1.2599515914916992, 0.3329406976699829, -0.09516245126724243, -0.8988757133483887, 0.9675375819206238, -1.415083646774292, -1.0179239511489868, 0.8663709759712219, 0.5629428625106812, 0.3110186457633972, -0.519394040107727, -0.3009551167488098, -0.028095653280615807, 0.49767860770225525, 0.2832363247871399, -0.32875287532806396, -0.48844248056411743, -0.21627920866012573, 0.7738609910011292, 0.21704740822315216, 0.7285288572311401, 0.022965330630540848, 0.6111636757850647, 14.8304443359375, 0.7242706418037415, 0.4078931510448456, 0.4181060492992401, 0.4796469807624817, 0.019357185810804367, -0.9100297689437866, 0.06900808960199356, -1.284921646118164, -0.07895778119564056, 0.8672583699226379, 0.21546459197998047, 0.5914944410324097, -0.09063524007797241, -0.15190456807613373, 0.36329349875450134, -0.9347759485244751, 0.691612184047699, 0.4097113609313965, -1.383684515953064, 0.4400309920310974, 0.0838426947593689, 0.24853649735450745, 0.0724167451262474, 0.5728715658187866, 0.5044232606887817, 0.7740914225578308, -0.7531116008758545, 0.20585942268371582, 0.5418828129768372, 0.9623158574104309, 0.11030100286006927, 0.49185025691986084, 0.31389614939689636, -1.1264714002609253, -0.3947792053222656, -0.7784296870231628, -1.2255842685699463, 0.434886634349823, 0.22211319208145142, -0.5531231760978699, -0.5347480773925781, -0.15368732810020447, 1.36430823802948, 0.6213415861129761, 0.5793541073799133, -0.6954563856124878, 0.5392101407051086, -0.40259844064712524, -0.20346300303936005, 0.26223087310791016, 0.6777395606040955, 0.299651563167572, -0.0033652745187282562, 0.2934902310371399, 0.31914156675338745, 0.06687387824058533, 0.6063387393951416, -0.5931593179702759, -0.1053866520524025, -0.7188289761543274, -0.4749857187271118, 0.22757934033870697, 0.7092421054840088, 0.8409121036529541, 0.30055782198905945, -0.3162803649902344, 0.11892236024141312, 0.6276571154594421, 0.2911985218524933, 0.12473143637180328, -0.38186371326446533, 0.4178105294704437, -0.22818955779075623, 0.23879767954349518, 0.8401041030883789, -0.44613733887672424, -0.22758278250694275, -0.6656801700592041, -0.43780717253685, 0.8708203434944153, -0.8647702932357788, -1.0800156593322754, 0.7368935346603394, -0.4859130382537842, -0.18865196406841278, 0.3579256534576416, -0.7275062799453735, -0.22416697442531586, 0.31322723627090454, -1.4221210479736328, -0.6719458103179932, 0.47632092237472534, -0.03911340609192848, -0.4186738133430481, 0.11560118198394775, 1.4396462440490723, 0.039431747049093246, -0.12983325123786926, 0.03819064050912857, -0.37918177247047424, 0.02039390429854393, -0.35111382603645325, -1.1077756881713867, 0.543545126914978, 0.21515856683254242, 0.18278662860393524, 0.5431526899337769, 0.024800192564725876, 0.08613073825836182, -0.4984237551689148, 0.2927567958831787, 1.2140122652053833, -1.2027299404144287, -0.06855612248182297, -0.3047202229499817, -0.9376658201217651, 0.8992388248443604, 0.5922634601593018, -0.17485712468624115, 0.5151413679122925, 0.2505030930042267, -0.8581439256668091, -0.22145579755306244, -0.7774246335029602, -0.06049557402729988, 0.6800776720046997, -1.0985199213027954, -0.5788180828094482, -0.31717970967292786, 0.42687803506851196, -0.7327980399131775, -0.6684972643852234, -0.25868847966194153, 0.21812045574188232, 0.19255083799362183, 0.9729408621788025, -0.76711505651474, 1.0995104312896729, 0.5831236839294434, -0.1758379489183426, -0.7120588421821594, 0.002315060468390584, -1.1546036005020142, -0.45082297921180725, 0.06410394608974457, 0.8002166748046875, -0.7076677083969116, 0.10923013836145401, 0.6558293700218201, 0.1328662782907486, -0.44045397639274597, -0.6500638127326965, 0.030009077861905098, -0.33731359243392944, -0.3140687942504883, 0.3024393916130066, 0.1422504186630249, 0.2217169851064682, 0.006199175026267767, 0.2985698878765106, 0.745973527431488, -0.3538918197154999, -0.7100144028663635, -0.08963475376367569, -0.17051461338996887, -0.056014284491539, -0.6960150003433228, -0.6804540753364563, -1.5652949810028076, 0.2949686348438263, -1.2707480192184448, -0.012411060743033886, -1.1866761445999146, -0.5170358419418335, 0.024315251037478447, -0.1674620658159256, 0.485867440700531, 0.2386995404958725, -0.41745662689208984, -0.5437094569206238, -0.7598631381988525, -0.36644241213798523, 0.6413365006446838, 0.7159849405288696, -0.5617372989654541, 0.38531020283699036, 0.11879656463861465, -0.3257107436656952, 0.2251547873020172, 0.3506847023963928, -0.7134882211685181, -0.577807605266571, -1.304612636566162, 0.8582742214202881, -0.10770464688539505, 0.1646885722875595, -0.030865535140037537, 0.8924325704574585, 0.6692206859588623, -0.3062003254890442, 0.241233691573143, 0.546040952205658, -1.3550405502319336, -0.5701175928115845, 0.22614899277687073, -1.0395234823226929, 0.24272973835468292, 0.14818306267261505, -0.2477278709411621, -0.5276846289634705, 0.5508837103843689, -0.15633048117160797, -1.1530239582061768, -0.1903747320175171, 0.6051090955734253, -0.43800845742225647, 0.13997851312160492, -0.24712668359279633, -0.20987704396247864, -1.1397494077682495, -0.3524428606033325, -0.08876875787973404, 0.3954813480377197, -0.3109835684299469, 0.45464053750038147, 0.45141512155532837, -1.064718246459961, 0.34651172161102295, 0.0059786695055663586, -0.13164062798023224, 0.2402588576078415, 0.2604050934314728, 0.24734921753406525, -0.012916588224470615, 0.541815459728241, 0.23727817833423615, 0.3420952558517456, -0.8720657825469971, 0.09413773566484451, 0.7453070878982544, -0.46036872267723083, -0.3842785954475403, 1.0039719343185425, -0.37748876214027405, -0.9133502840995789, 0.388570636510849, -1.2993719577789307, -0.5343201160430908, -0.30802008509635925, 0.676331102848053, 0.019223442301154137, -0.5703346133232117, 0.19391478598117828, -0.4529532492160797, 0.4364691972732544, 0.04116065427660942, -0.125900000333786, 0.7703536748886108, 0.042040932923555374, -0.7739708423614502, 0.472883403301239, 0.5974096059799194, -0.7052234411239624, -0.3381442725658417, -1.0599350929260254, -0.2355852574110031, -0.3533593714237213, 0.030416008085012436, -0.259185254573822, -0.6230364441871643, 0.9826853275299072, -0.028565775603055954, 0.8363809585571289, 0.12426034361124039, 0.27928611636161804, 0.3721902668476105, 0.7460018396377563, -0.10464653372764587, -0.0619778111577034, -0.5043041706085205, 1.2414418458938599, 1.2938628196716309, -0.4916602075099945, -0.13134559988975525, -0.5698210597038269, -0.5511300563812256, 0.8736616373062134, 0.3033493757247925, -0.03894941136240959, 0.6734095811843872, -0.09128126502037048, -0.3973739743232727, -0.027157455682754517, -1.1505827903747559, -0.1757146716117859, 0.5824686884880066, 1.3004083633422852, 0.4313161373138428, 0.005677013657987118, 0.23826934397220612, 1.0035752058029175, -0.08861131221055984, 0.11848025768995285, 0.31853431463241577, 0.25058022141456604, -0.25236964225769043, -0.13102316856384277, 0.3956688642501831, 0.6005790829658508, -0.8324859738349915, -0.7051957249641418, -0.24895690381526947, 0.4010174572467804, -0.015698358416557312, 0.45102211833000183, 0.586768627166748, 0.25120943784713745, 0.6121701598167419, 0.15538129210472107, 0.5662475228309631, -0.6924427151679993, -0.40198996663093567, -0.7414199709892273, -0.49057915806770325, -0.13302850723266602, -0.42922142148017883, -0.590484619140625, -0.3790074586868286, -0.20101507008075714, 0.23002229630947113, 0.17727459967136383, 0.14168468117713928, 1.2570295333862305, 0.4977034628391266, 0.26855674386024475, -0.39827871322631836, -0.03406325355172157, -0.250406950712204, -0.894769012928009, 0.11178739368915558, -0.6959936022758484, 0.03618859872221947, 0.04380687326192856, -0.22239035367965698, -0.163774311542511]}, "authors": [{"authorId": "2674870", "name": "Chulhee Yun"}, {"authorId": "2504795", "name": "Yin-Wen Chang"}, {"authorId": "1798880", "name": "Srinadh Bhojanapalli"}, {"authorId": "2241094", "name": "A. Rawat"}, {"authorId": "1981186", "name": "Sashank J. Reddi"}, {"authorId": "152663162", "name": "Sanjiv Kumar"}], "references": [{"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "f63405f53db3b1016f565f555fc8fa409f02fdbd", "title": "Minimum Width for Universal Approximation"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "016a3ba7adcae71f5a23ed2663d8062ae1da63e6", "title": "SAC: Accelerating and Structuring Self-Attention via Sparse Adaptive Connection"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "b1c39d042fdf8f00a407b0df734764beb6c3b062", "title": "Low-Rank Bottleneck in Multi-head Attention Models"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "b03cf6324ecf7a295a4aeae5970c88d1a1c3f336", "title": "Explicit Sparse Transformer: Concentrated Attention Through Explicit Selection"}, {"paperId": "509b4661ed74a24c2ffdbf131f9e1c6a1783752d", "title": "Are Transformers universal approximators of sequence-to-sequence functions?"}, {"paperId": "2e14e84ccec924ed770b58108ad1d9de6f0ca295", "title": "BP-Transformer: Modelling Long-Range Context via Binary Partitioning"}, {"paperId": "2cf3bd0cc1382f35384e259d99e4f9744eeaed28", "title": "Blockwise Self-Attention for Long Document Understanding"}, {"paperId": "a3ef6ee560e93e6f58be2b28f27aed0eb86dc463", "title": "Fine-tune BERT with Sparse Self-Attention Mechanism"}, {"paperId": "1fe62a928bf5cfac0f373728f3a4de3cefe0951d", "title": "On Identifiability in Transformers"}, {"paperId": "f6390beca54411b06f3bde424fb983a451789733", "title": "Adaptively Sparse Transformers"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "b3564be8b79f25585acb035f3deaf4ae93c26d8f", "title": "Theoretical Limitations of Self-Attention in Neural Sequence Models"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "afd110eace912c2b273e64851c6b4df2658622eb", "title": "Visualizing and Measuring the Geometry of BERT"}, {"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "3cee801d10f410f0feb1a2390776a01ba2765001", "title": "Sparse Sequence-to-Sequence Models"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "2a31319e73d4486716168b65cdf7559baeda18ce", "title": "Star-Transformer"}, {"paperId": "3694381e74445a8b9f8cb8d373e39626e47191b5", "title": "On the Turing Completeness of Modern Neural Network Architectures"}, {"paperId": "0a77aefc43614afd0f89829d87d582525ffc06c7", "title": "On Controllable Sparse Alternatives to Softmax"}, {"paperId": "6b7c16120ef3324bdca4b8433fb1f89c761e4dfc", "title": "Deep, Skinny Neural Networks are not Universal Approximators"}, {"paperId": "1c3112ef8a346b9817382ed34a8c146c53d5bcf5", "title": "XNLI: Evaluating Cross-lingual Sentence Representations"}, {"paperId": "642c1b4a9da95ea4239708afc5929a5007a1870d", "title": "Tensor2Tensor for Neural Machine Translation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "5d833331b0e22ff359db05c62a8bca18c4f04b68", "title": "One billion word benchmark for measuring progress in statistical language modeling"}, {"paperId": "bc6dff14a130c57a91d5a21339c23471faf1d46f", "title": "Et al"}, {"paperId": "7cd316505f52aa337ef8a2aff10bc6bf1df561d0", "title": "and s"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Manning . Effective approaches to attention - based neural machine translation"}]}