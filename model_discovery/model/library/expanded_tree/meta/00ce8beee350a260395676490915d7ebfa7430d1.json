{"paperId": "00ce8beee350a260395676490915d7ebfa7430d1", "abstract": "Data-to-text (D2T) generation aims to generate human-readable text from semi-structured data, such as tables and graphs. The recent success of D2T is largely attributed to advancements in LLMs. Despite the success of LLMs, no research has been conducted to illustrate the impact of model size on the performance of fine-tuned LLMs for D2T tasks. D2T model performance is typically assessed based on three key qualities: \\textit{readability} (indicates fluency and coherence), \\textit{informativeness} (measures content similarity), and \\textit{faithfulness} (assesses consistency of factual information). It is currently uncertain whether increasing the size of LLMs effectively improves performance in D2T tasks across these three qualities. The objective of this study is to investigate the performance of fine-tuned LLMs in D2T tasks in terms of model size. Through extensive comparative analysis, we aim to elucidate both the advantages and limitations of scaling model sizes across five widely used D2T datasets (E2E, ViGGo, WikiTableText, DART, and WebNLG) and twelve state-of-the-art LLMs with varying sizes from five different LLM families (T5, BART, OPT, BLOOM, and Llama 2). To comprehensively cover all the three essential qualities of D2T models, we incorporate six widely recognized automatic metrics -- \\textsc{BLEU}, \\textsc{METEOR}, \\textsc{BERTScore}, \\textsc{MoverScore}, \\textsc{Parent}, and \\textsc{BARTScore}. We also provide an in-depth analysis of LLM performance concerning model size in the presence of source-reference divergence, a critical aspect of D2T tasks. Our investigation reveals that increasing LLM size enhances \\textit{readability} and \\textit{informativeness} in D2T tasks, but larger (in terms of size) LLMs may sacrifice \\textit{faithfulness}. Moreover, small-sized LLMs show more resilience than larger ones when source-reference divergence is present.", "venue": "", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Investigation of fine-tuned LLMs in D2T tasks in terms of model size reveals that increasing LLM size enhances readability andformativeness in D2T tasks, but larger LLMs may sacrifice \\textit{faithfulness}."}, "embedding": {"model": "specter_v2", "vector": [0.23210807144641876, 0.8668417930603027, -0.3334961235523224, 0.22820977866649628, -0.6036003232002258, -0.5889469981193542, 0.8989772796630859, 0.16639159619808197, 0.07462843507528305, 0.2416543960571289, 0.330920547246933, -0.03406994417309761, -0.07985536754131317, -0.2208552211523056, -0.09063318371772766, 0.33682844042778015, -0.6365858316421509, 1.0153614282608032, -0.18696105480194092, -0.374936044216156, 0.06856827437877655, -0.7736150622367859, -0.9297234416007996, -0.031500816345214844, 1.1469430923461914, 0.5915307402610779, 0.24204422533512115, 0.8473367691040039, -0.7661812901496887, 0.15338470041751862, 0.12471766024827957, -0.6252999305725098, 0.061080124229192734, -0.6262667775154114, -0.4222339987754822, 0.06721699237823486, 0.3446979522705078, 0.04098425805568695, -0.20232777297496796, 0.3876664638519287, 0.08460485190153122, 0.1619163602590561, 0.8315674066543579, -0.7626886963844299, -0.48955589532852173, 1.0171666145324707, 0.6330103278160095, 0.5058366060256958, 0.272286981344223, -0.4116758108139038, 1.2948516607284546, -1.0914720296859741, 0.6651437282562256, 1.493802547454834, 0.44589293003082275, 0.44462868571281433, -0.5449489951133728, -0.1697237640619278, -0.1607271134853363, -0.32945990562438965, -0.9364579916000366, -0.23765228688716888, -0.2041344791650772, -0.3458021581172943, 1.6013283729553223, -0.07582762092351913, -0.44212767481803894, 0.6083633303642273, -0.1508469134569168, 1.1881475448608398, -0.13961148262023926, -0.7833757996559143, -0.13166609406471252, 0.029458047822117805, -0.24592585861682892, 0.9623059630393982, -0.08773849159479141, -0.07089583575725555, -1.1402164697647095, -0.2627839744091034, 0.3546460270881653, -0.8063791990280151, -0.0681285485625267, -0.18529146909713745, -0.4444849491119385, 0.706873893737793, 0.10835076868534088, 0.7806099057197571, -0.1890793889760971, 0.4557616710662842, 0.18313446640968323, 0.28448042273521423, 0.23041942715644836, 0.3588075339794159, -0.17046114802360535, -0.012224188074469566, -0.9343539476394653, 0.40312352776527405, 0.38411664962768555, 1.035792589187622, -0.2891315221786499, -0.018208056688308716, -1.0794262886047363, 0.3653385639190674, 0.9522123336791992, -0.05883777141571045, 0.9800264239311218, -0.5528270602226257, 0.8557243347167969, -0.15771804749965668, 0.39071136713027954, -0.43700873851776123, -0.4412692189216614, 0.1079922616481781, -0.9125583171844482, -1.1220990419387817, -0.3101733922958374, -0.3462793231010437, -0.8051880598068237, 0.45081475377082825, -0.11681737750768661, -0.28856736421585083, 0.0944935604929924, 0.5503183007240295, 0.9705279469490051, 0.5073524713516235, -0.2817533314228058, 0.08085327595472336, 0.477090060710907, -0.5805882215499878, -0.4591403305530548, -0.8973478674888611, 0.9009495377540588, -0.20738385617733002, 0.2962004542350769, -0.41499489545822144, -1.670866847038269, -1.026383638381958, -0.623198926448822, 0.019341450184583664, -0.3578420877456665, 0.8388581871986389, 0.8851603269577026, 0.3464517593383789, -0.7780690789222717, 0.9104931950569153, -0.051257696002721786, -0.612959623336792, 0.2555862069129944, -0.30594417452812195, 0.10336874425411224, -0.3696921467781067, -1.3094781637191772, 0.12089448422193527, 0.4595566987991333, -0.9565235376358032, -0.27435287833213806, -0.49839574098587036, -1.0109606981277466, -0.35324859619140625, 0.364727258682251, -0.7266882658004761, 1.2976775169372559, 0.2782864272594452, -1.0212584733963013, 0.6207595467567444, -0.22071993350982666, -0.016146594658493996, 0.8454998135566711, 0.3761232793331146, -0.2478315532207489, -0.3134198784828186, -0.07574958354234695, 0.5893744230270386, 0.15325765311717987, -0.12754493951797485, -0.3040591776371002, 0.5953064560890198, -0.29297542572021484, -0.09751692414283752, -0.3090026080608368, 0.4410185217857361, -0.6533911824226379, -0.6446189880371094, 0.24474355578422546, 0.5239539742469788, 0.12308109551668167, 0.13944204151630402, -0.6371213793754578, -1.1304036378860474, 0.28502219915390015, 0.010459001176059246, 1.2249712944030762, -0.3373197913169861, -0.5316151976585388, -0.45916035771369934, 0.0019549811258912086, -0.30582764744758606, -0.6477764248847961, 1.1872292757034302, -0.22813470661640167, 0.9447064399719238, -0.35586094856262207, -0.8839608430862427, 0.3547436594963074, -0.4274885356426239, -0.25755563378334045, -0.4388670325279236, 0.16323983669281006, 0.9740193486213684, -0.6426038146018982, -0.1964736431837082, -0.2551683783531189, -0.24787431955337524, -0.5632508993148804, 1.0068845748901367, -0.8031588792800903, -0.10642148554325104, -0.43312662839889526, -0.4236932694911957, 0.20305995643138885, -0.38527390360832214, 0.2955957353115082, -0.18680736422538757, -0.05503622815012932, 0.7193772792816162, -0.6896145939826965, 1.8612492084503174, -0.1608451008796692, 0.15794573724269867, -0.5600683689117432, -0.18909408152103424, 0.623599112033844, 0.4775237441062927, -0.1411057710647583, -0.2527342736721039, -0.1645902395248413, 0.4557114839553833, -0.552758514881134, -0.06491803377866745, 0.6391341090202332, 0.8816770911216736, -0.39750149846076965, 0.6646898984909058, 0.44227108359336853, -0.7022377252578735, 1.6723473072052002, 0.5987114310264587, 0.8393762111663818, 0.5418875217437744, 0.1516994833946228, -0.1846412569284439, 0.38270503282546997, -0.2365821897983551, -0.21597805619239807, 0.44632187485694885, 1.1595218181610107, 1.03916335105896, 0.5012789368629456, -0.5594744086265564, -0.2070326954126358, 0.047318194061517715, 0.9349225163459778, 1.2744475603103638, -0.18367236852645874, -0.8128378391265869, -0.9749979972839355, -0.8260399103164673, -0.12388385832309723, 0.7587490081787109, -0.7315617203712463, -0.19249983131885529, -0.005639359354972839, -1.2732996940612793, 0.8374253511428833, 0.0801200121641159, 0.8824871778488159, -0.560599684715271, -0.4051913022994995, -0.267581582069397, -0.2741928994655609, -0.500029444694519, -0.696747362613678, 0.1890667825937271, -0.5382257103919983, -0.3860577642917633, -0.005683727562427521, 0.053419820964336395, 0.25093287229537964, -0.6062003374099731, 1.2175384759902954, -0.2868693172931671, -0.5102843642234802, -0.11616664379835129, 0.07308218628168106, -0.618272066116333, -0.9830561280250549, 0.2801828682422638, -0.13250897824764252, -0.718334972858429, 0.05070136487483978, 0.6853646039962769, 0.5047930479049683, 0.47842496633529663, -0.8242555856704712, 0.4198033809661865, -0.04830700531601906, 0.05982252210378647, 0.40892550349235535, 0.40349993109703064, -0.25517499446868896, -0.9632047414779663, 1.3084535598754883, 0.21649381518363953, -0.44681912660598755, 0.5252180695533752, -0.6174416542053223, -0.14299601316452026, 0.3999740183353424, -0.319254070520401, -0.5476453304290771, -1.2585875988006592, 0.74515700340271, 0.3479440212249756, -0.23078717291355133, 0.49610602855682373, 0.27848121523857117, 0.2814035415649414, 0.7429419159889221, 0.42766520380973816, 0.23563863337039948, -0.4917067289352417, 0.7931417226791382, -0.7303338646888733, 0.13525539636611938, 0.05597882345318794, 0.5531431436538696, -0.4620889723300934, -0.1296558827161789, -0.382760226726532, -0.40297308564186096, 0.43857669830322266, -0.5314055681228638, 0.09707019478082657, 0.1266339272260666, -0.23404112458229065, -0.40683886408805847, -0.2707065939903259, -1.0300252437591553, -0.38559600710868835, 0.07857882231473923, -0.5426086187362671, -0.21676014363765717, -0.9917457699775696, -0.9314505457878113, -0.2531849443912506, -0.6494781970977783, -0.8009704351425171, 0.4891195297241211, 0.051828984171152115, -0.5452702641487122, -0.6990857720375061, 0.29957643151283264, -0.3332763612270355, 0.34424516558647156, -0.06736709922552109, 1.1350167989730835, 0.002529390621930361, 0.16640439629554749, -0.26895031332969666, 0.22290465235710144, -0.14762292802333832, 0.22477716207504272, 0.5762950778007507, -0.2927943170070648, 0.25707748532295227, -0.2955210208892822, -0.5962787866592407, 0.04239371791481972, 0.16979484260082245, 0.5603547692298889, 0.004779302515089512, -0.6548013091087341, 0.17634150385856628, 1.1891100406646729, -0.8486518263816833, -0.27357831597328186, -0.04762229323387146, 0.8572016954421997, 0.8279369473457336, 0.1999073177576065, 0.8330445885658264, 0.5056408643722534, 0.42422324419021606, 0.02354986034333706, -0.23223227262496948, -0.4576259255409241, -0.858410120010376, 0.2760538160800934, 1.2516878843307495, 0.30396661162376404, -1.0030653476715088, -1.2251492738723755, 0.5061833262443542, -1.1746689081192017, -0.43110454082489014, 0.19330668449401855, 0.693877637386322, 0.6860449314117432, -0.29423585534095764, -0.37348616123199463, 9.276539640268311e-05, 0.45190712809562683, 0.07222295552492142, -0.2549617290496826, -0.11158032715320587, -0.2604624927043915, 0.13921810686588287, -0.13010714948177338, 0.04564240574836731, -0.1011396273970604, 0.2622024416923523, 14.867342948913574, 1.4436876773834229, 0.5656564831733704, 0.09742037206888199, 0.7839663624763489, -0.015882572159171104, -0.6139140129089355, -0.3415718078613281, -0.97977614402771, 0.10338421165943146, 1.208837628364563, -0.6986424922943115, 0.3306027948856354, 0.06704509258270264, 0.4300669729709625, -0.10451964288949966, -0.6749384999275208, 0.42283496260643005, 0.5001344680786133, -1.4987034797668457, 0.8367671966552734, 0.4417148530483246, 0.43103066086769104, 0.15407489240169525, 0.5474976301193237, 0.6850261688232422, 0.5392004251480103, -0.5891191959381104, 0.7209925651550293, 0.03550449013710022, 1.0777974128723145, -0.24591733515262604, 0.4153301417827606, 0.821273148059845, -0.8947126269340515, -0.07930644601583481, -0.889986515045166, -0.7339006662368774, 0.23715074360370636, 0.3713133633136749, -0.9203944802284241, 0.0637321025133133, -0.23531800508499146, 0.6471537351608276, -0.38728904724121094, 0.24430005252361298, -0.33521226048469543, 0.3108770251274109, 0.08533550053834915, -0.19017325341701508, 0.09139171242713928, 0.37102553248405457, 0.1704268455505371, -0.14355213940143585, 0.7480969429016113, -0.35209301114082336, 0.02348184399306774, 0.6038655638694763, -0.7217027544975281, -0.028253447264432907, -0.6526777148246765, -0.3337663412094116, 0.21290501952171326, 0.933375895023346, 0.38453975319862366, 0.42144548892974854, -0.22233247756958008, 0.40801796317100525, 0.7061417698860168, -0.20929844677448273, -0.2693004906177521, -0.24624724686145782, 0.08645271509885788, -0.0990629717707634, -0.05400874465703964, 0.6218391060829163, -0.1481725126504898, -0.12262356281280518, -0.7328982353210449, -0.5474361777305603, 0.6870577335357666, -1.023573875427246, -1.0760172605514526, 1.0892143249511719, -0.07413484901189804, -0.9248546361923218, -0.2803882360458374, -0.5216125249862671, -0.4316484034061432, 0.6451951265335083, -1.1562016010284424, -0.8509718775749207, 0.010108021087944508, -0.40842074155807495, -0.03192843124270439, -0.23343223333358765, 1.3341095447540283, -0.4581397473812103, -0.4871208965778351, 0.17093972861766815, 0.40936586260795593, -0.1887630820274353, 0.01645648293197155, -1.0263588428497314, 1.5898321866989136, 0.35661929845809937, 0.03326675295829773, 0.10903049260377884, -0.22062309086322784, -0.3178008496761322, -0.6972475647926331, -0.5633695721626282, 0.7611529231071472, -1.0543984174728394, -0.36056095361709595, -0.8747745752334595, -0.5738084316253662, -0.1401667445898056, 0.6730335354804993, -0.6827114820480347, 0.32166165113449097, -0.1821170151233673, -0.07100607454776764, 0.12273941189050674, -1.0393494367599487, 0.08737128227949142, 0.6133589148521423, -0.18096889555454254, -0.24291343986988068, 0.3371810019016266, 0.31005340814590454, -1.170462965965271, -0.7307811975479126, -0.4872104227542877, -0.4528307318687439, -0.36919042468070984, 0.4817824065685272, -0.12961003184318542, 0.9716680645942688, 0.734338104724884, 0.1819419264793396, -1.1696866750717163, -0.12323706597089767, -1.3981118202209473, 0.21138989925384521, 0.48742958903312683, 1.3783260583877563, -0.052286408841609955, 0.4437697231769562, 1.1995233297348022, 0.5171350240707397, -0.14074642956256866, -0.3320983350276947, -0.19999247789382935, 0.08053223788738251, -0.29715093970298767, 0.7139017581939697, -0.2092238813638687, 0.0702352300286293, 0.17152473330497742, 0.616508960723877, 0.3030945658683777, -0.23720517754554749, -0.5360361337661743, 0.7350031733512878, -0.41084223985671997, 0.13634608685970306, -0.5609905123710632, 0.2512422204017639, -1.1542458534240723, -0.37298229336738586, -1.2183228731155396, 0.13673512637615204, -1.4811639785766602, -0.6029196381568909, -0.02069772779941559, 0.34378933906555176, -0.02918914705514908, 0.4256749749183655, -0.5354851484298706, -0.6952242851257324, -0.6851552724838257, -0.16969215869903564, 0.742831826210022, 1.0006963014602661, -0.6283815503120422, -0.010219220072031021, -0.3080112636089325, -0.022323859855532646, 0.2057463526725769, 0.5176711678504944, -0.7192537188529968, -1.1560332775115967, -1.5716956853866577, 0.3794165849685669, 0.07887427508831024, -0.14118346571922302, -0.5975273847579956, 0.5806624293327332, 0.3374679684638977, -0.04178261756896973, -0.11149507015943527, -0.028011031448841095, -0.40834471583366394, -0.22445227205753326, 0.17116178572177887, -0.9645482897758484, 0.15432319045066833, 0.21541300415992737, -0.6966525316238403, -0.28186511993408203, 0.0777396559715271, -0.27143391966819763, -1.1525394916534424, -0.09128423780202866, 0.3675450086593628, -0.48372337222099304, 0.491342157125473, -0.25511634349823, -0.25832319259643555, -1.0808889865875244, -0.3347308933734894, 0.46571362018585205, 0.48081880807876587, -0.1413981318473816, 1.043662667274475, 0.27954229712486267, -1.197387456893921, -0.2175064980983734, 0.07304569333791733, 0.16085700690746307, -0.020617838948965073, 0.37643587589263916, 0.22480471432209015, -0.4981923997402191, 0.4846879243850708, 0.37060800194740295, 0.5123381614685059, -0.5755084156990051, -0.18022581934928894, 0.5015918016433716, -0.590523362159729, -0.1281912624835968, 1.3023133277893066, -0.7013440728187561, -1.2217121124267578, -0.01416208315640688, -1.012209415435791, -0.48832613229751587, -0.13902589678764343, 0.6893911361694336, 0.5132172107696533, 0.0922541543841362, 0.18016096949577332, -0.27454665303230286, 0.1621643453836441, 0.07255342602729797, -0.6385660171508789, 0.5813466906547546, -0.28223854303359985, -0.36836597323417664, 0.29181981086730957, 0.2430354356765747, -0.7472339868545532, -0.7302773594856262, -0.13132788240909576, 0.029640763998031616, -0.23785929381847382, 0.2894481420516968, -0.9668322205543518, -0.28452134132385254, 0.5946581363677979, -0.0005858702352270484, 0.8849902749061584, 0.07239984720945358, -0.38256922364234924, 0.348874568939209, 0.615814745426178, 0.08998914062976837, -0.6305689811706543, -0.5545859336853027, 0.6998757719993591, 1.3758810758590698, -0.8761338591575623, 0.3670753538608551, 0.017787838354706764, -1.209930181503296, 1.071335792541504, 0.5287803411483765, 0.7067276239395142, 0.34140852093696594, -0.3169615864753723, 0.0033966314513236284, 0.0023570554330945015, -1.3585854768753052, -0.10521169006824493, 1.105355143547058, 1.433185338973999, 1.0280635356903076, -0.24894104897975922, -0.026934035122394562, 0.7875860333442688, -0.16909363865852356, 0.11031971126794815, 0.8470833897590637, 0.3248080611228943, -0.2368590086698532, -0.36614856123924255, 0.15354564785957336, 0.8188295364379883, -0.3167942762374878, -0.398046612739563, -0.39858153462409973, 0.7056469321250916, 0.2991194725036621, 1.151253342628479, 0.3141457736492157, 0.1288355439901352, 0.416212797164917, -0.02090548165142536, 0.4680294990539551, -0.6351602077484131, -0.23424457013607025, -0.2195780873298645, -0.2060677409172058, 0.07418769598007202, 0.018350187689065933, -0.45289021730422974, -0.3739798367023468, -0.3697412312030792, 0.31723061203956604, 0.4894530773162842, 0.29011693596839905, 0.8202328085899353, 0.664025068283081, 0.30036354064941406, -0.28247159719467163, -0.3519684970378876, -0.1937914341688156, -1.3272669315338135, -0.034734226763248444, -0.48617908358573914, -0.8213194608688354, -0.1128312423825264, -0.04435362666845322, 0.12071093916893005]}, "authors": [{"authorId": "2261081027", "name": "Joy Mahapatra"}, {"authorId": "2312204876", "name": "Utpal Garain"}], "references": [{"paperId": "685283fce76d53b55f1e0d54168c634d66031e26", "title": "A Survey on Neural Data-to-Text Generation"}, {"paperId": "8d63fdce0e72223e8adbf8e73c33d17a1c960f86", "title": "Preventing the Immense Increase in the Life-Cycle Energy and Carbon Footprints of LLM-Powered Intelligent Chatbots"}, {"paperId": "b246f2616df8348e488c27576fdeb4e1564e381b", "title": "Toward Sustainable GenAI using Generation Directives for Carbon-Friendly Large Language Model Inference"}, {"paperId": "6edf144fb397afde80d9acf9472dfaffd22c8072", "title": "Unveiling the Generalization Power of Fine-Tuned Large Language Models"}, {"paperId": "fe6856896195052b0b20a450ec375a9b7c1c6cf8", "title": "High-quality Data-to-Text Generation for Severely Under-Resourced Languages with Out-of-the-box Large Language Models"}, {"paperId": "5b65975d2c561d91e4d9806356f3c11d465192e2", "title": "Unifying Structured Data as Graph for Data-to-Text Pre-Training"}, {"paperId": "378f828f992458cd0b2eb2fd66adb979297534be", "title": "Can LLM find the green circle? Investigation and Human-guided tool manipulation for compositional generalization"}, {"paperId": "5160224f7daf64fd490ed6d517bef316e383a311", "title": "An Empirical Study of Instruction-tuning Large Language Models in Chinese"}, {"paperId": "32479758dc9ff9820828a12aa7f3d066f187dc1c", "title": "LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models"}, {"paperId": "f0950a3f27c0fefffba60ae1c9a8ee360d5eb55f", "title": "Instruction Tuning for Large Language Models: A Survey"}, {"paperId": "5e4597eb21a393b23e473cf66cb5ae8b27cab03e", "title": "ExpeL: LLM Agents Are Experiential Learners"}, {"paperId": "c1da40df79d5ec14c9ffac83d7bcedf543daa91c", "title": "Tackling Hallucinations in Neural Chart Summarization"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "7ace46ab8e71c4304682ab126b1212deb54b9b03", "title": "Style Over Substance: Evaluation Biases for Large Language Models"}, {"paperId": "a5fab19553e623e8787383cb3da76b8a3c42a8f4", "title": "Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts"}, {"paperId": "32ac52069e562d4f900afee70bdca63f53461481", "title": "QLoRA: Efficient Finetuning of Quantized LLMs"}, {"paperId": "57e90f4fae211f23e2c2d437e344a40ee9da87a0", "title": "Response Length Perception and Sequence Scheduling: An LLM-Empowered LLM Inference Pipeline"}, {"paperId": "6973b76f1aafd8cdf25867ed9b25a01fdacd5eae", "title": "Stylized Data-to-text Generation: A Case Study in the E-Commerce Domain"}, {"paperId": "74b05bba46db21e589a2cc0f916f81069b0368ef", "title": "Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation"}, {"paperId": "ec9a0c307090e57828e3b6e92685a13930dd5851", "title": "Data-to-text Generation with Data Control and Multi-loss Fusion"}, {"paperId": "38179848e2d6a3ad373b1793848816111428ac36", "title": "OpenAGI: When LLM Meets Domain Experts"}, {"paperId": "386f30238bb790cdc3f1a806f666e427b04324b0", "title": "TabGenie: A Toolkit for Table-to-Text Generation"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "bd8412c233bf3815d8e905911b58e12bd6f279da", "title": "Estimating the Carbon Footprint of BLOOM, a 176B Parameter Language Model"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "fc14091bbd7d1eb2c9f23ff9c75a4222f2604143", "title": "Neural Natural Language Generation: A Survey on Multilinguality, Multimodality, Controllability and Learning"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "be4396f87d49102256eb1cdd6475f7247d82329c", "title": "Faithfulness in Natural Language Generation: A Systematic Survey of Analysis, Evaluation and Optimization Methods"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "3def68bd0f856886d34272840a7f81588f2bc082", "title": "Survey of Hallucination in Natural Language Generation"}, {"paperId": "b6a1e3c81e0fbeb72071701e2557090901a2022c", "title": "Biomedical Data-to-Text Generation via Fine-Tuning Transformers"}, {"paperId": "946f28b30c0aede54eed7787c717dfd2e2c59bdd", "title": "Plan-then-Generate: Controlled Data-to-Text Generation via Planning"}, {"paperId": "a6a7724763d8adba466519489b0b9d209e7f2d15", "title": "BARTScore: Evaluating Generated Text as Text Generation"}, {"paperId": "476d79d1f5650c5361104ed468e75bfc4732622d", "title": "Experts, Errors, and Context: A Large-Scale Study of Human Evaluation for Machine Translation"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "1631a6e3b5235a4a2b0d71dca22a9614acca2ce3", "title": "Data-to-text Generation with Macro Planning"}, {"paperId": "e54ffc76d805c48660bb0fd20019ca82ac94ba0d", "title": "Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning"}, {"paperId": "cc676db9eb4deb247159fb69999203318d206c00", "title": "Disentangling the Properties of Human Evaluation Methods: A Classification System to Support Comparability, Meta-Evaluation and Reproducibility Testing"}, {"paperId": "f39d7195ee43a5eececf801ed0543cec1461a577", "title": "Reinforcement Learning with Imbalanced Dataset for Data-to-Text Medical Report Generation"}, {"paperId": "23e41de8b36c9bdf20d9de931f05510bb1885c25", "title": "Controllable Meaning Representation to Text Generation: Linearization and Data Augmentation Strategies"}, {"paperId": null, "title": "Transformers: State-of-the-Art Natural Language Processing"}, {"paperId": "51ae2c451a1a05293334a509b71c9c9e0377d35c", "title": "Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries"}, {"paperId": "6e3f8187f8fef3e11578a73f32da07d33dbf8235", "title": "DART: Open-Domain Structured Data Record to Text Generation"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "29e86cbeacf1e2235cc320ad240956012b294646", "title": "Towards Faithful Neural Table-to-Text Generation with Content-Matching Constraints"}, {"paperId": "c807a8c169925412d74a995ecf8ba898fd78f7d1", "title": "Logic2Text: High-Fidelity Natural Language Generation from Logical Forms"}, {"paperId": "80376bdec5f534be78ba82821f540590ebce5559", "title": "How Much Knowledge Can You Pack into the Parameters of a Language Model?"}, {"paperId": "54b64cb034f86c25c9ce877be62ee90fa426cbb4", "title": "Variational Template Machine for Data-to-Text Generation"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "f06d725ccd33bfea7937b756d47f506aea362f6a", "title": "ViGGO: A Video Game Corpus for Data-To-Text Generation in Open-Domain Conversation"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "80c65cac35a43f7e88917cb6d517554c7b175259", "title": "Sticking to the Facts: Confident Decoding for Faithful Data-to-Text Generation"}, {"paperId": "d0086b86103a620a86bc918746df0aa642e2a8a3", "title": "Language Models as Knowledge Bases?"}, {"paperId": "635cb6fb865e86c108c5d1d895aeac0e759eb199", "title": "MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "8aa12409bc8ca1c18016c77d756ea2eae9ef9968", "title": "A Simple Recipe towards Reducing Hallucination in Neural Surface Realisation"}, {"paperId": "02cbb0db288af2c83b48a023f245812bd22a2408", "title": "Handling Divergent Reference Texts when Evaluating Table-to-Text Generation"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "743d1aae44a12fb37b743ec947fad41cba9831b8", "title": "Pragmatically Informative Text Generation"}, {"paperId": "92cfd6d2eb957805aaf4786dacb484081a469e80", "title": "Findings of the E2E NLG Challenge"}, {"paperId": "f24cb415f5364dd3875266ce8b85ca92bdb69ec0", "title": "Data-to-Text Generation with Content Selection and Planning"}, {"paperId": "814db99ccf6b88d6af5b406b0c344b64c0a710b7", "title": "A Structured Review of the Validity of BLEU"}, {"paperId": "f4a5503783487eba5c5e34b1d02c09016b244b1d", "title": "MultiWOZ - A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling"}, {"paperId": "276905d8ef8d7813cc1cd8c11ef7b87d311dc389", "title": "Making effective use of healthcare data using data-to-text technology"}, {"paperId": "d10df96b3fb0ab5c6b1d0cc22c7400d0acccc3cc", "title": "The Hitchhiker\u2019s Guide to Testing Statistical Significance in Natural Language Processing"}, {"paperId": "5293778b5139599368dab36f6fa4e49e4c25df45", "title": "A Deep Ensemble Model with Slot Alignment for Sequence-to-Sequence Natural Language Generation"}, {"paperId": "29de7c0fb3c09eaf55b20619bceaeafe72fd87a6", "title": "Hierarchical Neural Story Generation"}, {"paperId": "6db2b93a2d4007371030644173f1001c959214d2", "title": "Learning to Write with Cooperative Discriminators"}, {"paperId": "8a52151e7c852d09c0dea9dc354c3a564169908e", "title": "Table-to-Text: Describing Table Region With Natural Language"}, {"paperId": "b4bfadfca9742bb3ee98a0cd322d5ce4e59a3ceb", "title": "A Call for Clarity in Reporting BLEU Scores"}, {"paperId": "e0260b36302e1e1a6927a10ebf18b16b2b6441e8", "title": "Generating Descriptions from Structured Data Using a Bifocal Attention Mechanism and Gated Orthogonalization"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "3580d8a5e7584e98d547ebfed900749d347f6714", "title": "Table-to-text Generation by Structure-aware Seq2seq Learning"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "1b6ebe9e5b34f0b8ce39c08cc938295be1293582", "title": "Order-Planning Neural Text Generation From Structured Data"}, {"paperId": "a4c40532e68728fbeab5d9415f6ad8e9530db360", "title": "The WebNLG Challenge: Generating Text from RDF Data"}, {"paperId": "13395213d47f78672ab4e81573f2b0fa0cfc8c6d", "title": "Challenges in Data-to-Document Generation"}, {"paperId": "531a7f2c659787165df4fd5b4580590b953448e4", "title": "The E2E Dataset: New Challenges For End-to-End Generation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "f60114c1b4df3ba58d3e0520531413385d4b4337", "title": "Analysing Data-To-Text Generation Benchmarks"}, {"paperId": "668db48c6a79826456341680ee1175dfc4cced71", "title": "Get To The Point: Summarization with Pointer-Generator Networks"}, {"paperId": "d13bb317e87f3f6da10da11059ebf4350b754814", "title": "Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation"}, {"paperId": "9c403f7b66dbdbe5289aad9980fae039dc63605c", "title": "Content Selection in Data-to-Text Systems: A Survey"}, {"paperId": "604764133befe7a0aaa692919545846197e6e065", "title": "Neural Text Generation from Structured Data with Application to the Biography Domain"}, {"paperId": "d01379ebb53c66a4ccf5f4959d904dcf9e161e41", "title": "Order Matters: Sequence to sequence for sets"}, {"paperId": "f273adbfe0e6ba39a583b9669d94cc8d828d8c25", "title": "What to talk about and how? Selective Generation using LSTMs with Coarse-to-Fine Alignment"}, {"paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0", "title": "Effective Approaches to Attention-based Neural Machine Translation"}, {"paperId": "4d4b46e545e1a3f6871b49cc69640ef2eb1a4654", "title": "Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems"}, {"paperId": "ba49d3823d43515e447296ca4e1e55d3f1fd8c4d", "title": "Neural Responding Machine for Short-Text Conversation"}, {"paperId": "4d8f2d14af5991d4f0d050d22216825cac3157bd", "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"}, {"paperId": "55e022fb7581bb9e1fce678d21fb25ffbb3fbb88", "title": "Deep visual-semantic alignments for generating image descriptions"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d", "title": "Speech recognition with deep recurrent neural networks"}, {"paperId": "f152db85455116eb674d65f63407497564901512", "title": "A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions"}, {"paperId": "2bb1df67e235015d867bc2d3fdbf12028976a299", "title": "Faster and Smaller N-Gram Language Models"}, {"paperId": "a5424051ab04689fc8bc175ff015c6f7cdc46014", "title": "A Simple Domain-Independent Probabilistic Approach to Generation"}, {"paperId": "1a6b7cf5e1a3e069338498d1c17aa7d46c1ac7e9", "title": "Automatic generation of weather forecast texts using comprehensive probabilistic generation-space models"}, {"paperId": "0008076a1968d9fb590c9013ab27b824849a4e80", "title": "Learning to sportscast: a test of grounded language acquisition"}, {"paperId": "10b005f48cf23cb66a82d016300f6960e4f035c6", "title": "Predicting Sentences using N-Gram Language Models"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "32622973ea102abb5f0dea32e2944b7656cd4798", "title": "Building applied natural language generation systems"}, {"paperId": "3de5d40b60742e3dfa86b19e7f660962298492af", "title": "Class-Based n-gram Models of Natural Language"}, {"paperId": "766ce989b8b8b984f7a4691fd8c9af4bdb2b74cd", "title": "\u201cCloze Procedure\u201d: A New Tool for Measuring Readability"}, {"paperId": "05aa63683f7d027c18f560d4472ac87c1ea754fe", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data Only"}, {"paperId": "f33e7316f264b4148460f3ccd73aae32bea112d1", "title": "CBR Assisted Context-Aware Surface Realisation for Data-to-Text Generation"}, {"paperId": "ec936b808e0fab9281c050ad4010cddec92c8cbe", "title": "P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "4061cd4df81d16f3e08789d1dd797e45123a7ad5", "title": "An Encoder with non-Sequential Dependency for Neural Data-to-Text Generation"}, {"paperId": "748c74fcd3658aa180b6c9db0b17814fb89409ea", "title": "Table-to-Text Generation with Effective Hierarchical Encoder on Three Dimensions (Row, Column and Time)"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "f2f1b1a98e603ff61163c4533f5ed37af178dbe5", "title": "A Personalized Data-to-Text Support Tool for Cancer Patients"}, {"paperId": null, "title": "Neural text generation: Past, present and beyond"}, {"paperId": null, "title": "A method for stochastic optimization"}, {"paperId": "9819b600a828a57e1cde047bbe710d3446b30da5", "title": "Recurrent neural network based language model"}, {"paperId": "a70e48c119742cb69b1cdbd62e58a8a8d0d28a8e", "title": "Comparing Automatic and Human Evaluation of NLG Systems"}, {"paperId": null, "title": "Beyond reference-based metrics: Analyzing behaviors of open llms on data-to-text generation"}, {"paperId": null, "title": "Do larger LLM families (such as OPT, BLOOM, Llama 2, etc.) convincingly outperform smaller LLM families (such as BART, T5, etc.) in terms of D2T task performance?"}, {"paperId": null, "title": "Stanford alpaca: An instruction-following llama model"}]}