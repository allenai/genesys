{"paperId": "ef8854a62e05c8e741894166689a9cd8352a1df0", "abstract": "Neural networks are often over-parameterized and hence benefit from aggressive regularization. Conventional regularization methods, such as dropout or weight decay, do not leverage the structures of the network's inputs and hidden states. As a result, these conventional methods are less effective than methods that leverage the structures, such as SpatialDropout and DropBlock, which randomly drop the values at certain contiguous areas in the hidden states and setting them to zero. Although the locations of dropping areas random, the patterns of SpatialDropout and DropBlock are manually designed and fixed. Here we propose to learn the dropping patterns. In our method, a controller learns to generate a dropping pattern at every channel and layer of a target network, such as a ConvNet or a Transformer. The target network is then trained with the dropping pattern, and its resulting validation performance is used as a signal for the controller to learn from. We show that this method works well for both image recognition on CIFAR-10 and ImageNet, as well as language modeling on Penn Treebank and WikiText-2. The learned dropping patterns also transfers to different tasks and datasets, such as from language model on Penn Treebank to Engligh-French translation on WMT 2014. Our code will be available at: https://github.com/googleresearch/google-research/tree/master/auto_dropout.", "venue": "AAAI Conference on Artificial Intelligence", "year": 2021, "citationCount": 48, "influentialCitationCount": 5, "openAccessPdf": {"url": "https://ojs.aaai.org/index.php/AAAI/article/download/17127/16934", "status": "GOLD"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes to learn the dropping patterns of a target network, and shows that this method works well for both image recognition on CIFAR-10 and ImageNet, as well as language modeling on Penn Treebank and WikiText-2."}, "embedding": {"model": "specter_v2", "vector": [0.062352485954761505, 0.714451253414154, -0.5242601037025452, -0.0313212051987648, -0.21047702431678772, -0.11461307108402252, 0.6705928444862366, -0.5650865435600281, -0.31491175293922424, 0.06166066974401474, 0.634432315826416, 0.28476399183273315, 0.9120808243751526, -0.08113378286361694, -0.5323747992515564, -0.05248890072107315, -0.5298131704330444, -0.25439098477363586, 0.367923766374588, -0.2870144248008728, -0.24981743097305298, -0.427688330411911, -0.6900529861450195, 0.5711818933486938, 0.10993365943431854, 0.6908137202262878, -0.3250613808631897, 0.6279223561286926, -0.2416882961988449, 0.9848431348800659, 0.15644551813602448, -0.5196471214294434, 0.4301462769508362, -0.29597559571266174, -0.1362653374671936, 0.17219328880310059, 0.5082505941390991, -0.4032958149909973, -0.8251102566719055, 1.1663990020751953, -0.4443179666996002, 0.2605145573616028, 0.14581504464149475, -0.6770358681678772, -0.23424258828163147, 0.44963017106056213, 0.6325092911720276, 0.7537374496459961, -0.47547879815101624, -0.444017231464386, 1.0339113473892212, -1.181039571762085, 0.39441123604774475, 1.405954122543335, 0.43259572982788086, 0.5322103500366211, -0.34484508633613586, -0.9749509692192078, 0.9121032953262329, 0.08158370852470398, -0.7369747757911682, -0.036888256669044495, 0.2581232488155365, -0.5031704902648926, 1.3245488405227661, -0.9386655688285828, -0.03576628491282463, 1.0705206394195557, 0.23598366975784302, 1.2270920276641846, -0.02691047638654709, -0.358195960521698, -0.37029996514320374, 0.4183463752269745, 0.4546980857849121, 0.88431715965271, -0.2353927493095398, 0.5288242697715759, -0.9377323389053345, 0.005234220996499062, 0.49229517579078674, 0.1548197716474533, 0.09484557062387466, -0.2128491848707199, 0.33800220489501953, 0.9158692955970764, 0.6679251194000244, 0.4611321687698364, -0.20070691406726837, 0.7936545014381409, 0.3994334042072296, 0.6697100400924683, 0.15796758234500885, 0.18018245697021484, 0.012951149605214596, 0.8093353509902954, -0.5782589316368103, 0.04296627268195152, -0.2632370889186859, 1.1689095497131348, 0.019891679286956787, 0.42675548791885376, -0.7713858485221863, 0.13345877826213837, 1.084801435470581, -0.2307230830192566, 0.34589508175849915, -0.6127573847770691, 0.08437085896730423, -0.70709627866745, -0.05539558827877045, -0.8417692184448242, -0.05291437730193138, -0.5325905084609985, -1.0671454668045044, -0.24809275567531586, -0.12678250670433044, -0.10376596450805664, -0.8663607239723206, 0.9221212863922119, -0.6634178757667542, 0.09083030372858047, -0.09343802183866501, 0.3515603244304657, 0.1470009982585907, 0.6331490874290466, 0.09516306966543198, 0.3038645386695862, 0.6660349369049072, -0.6694673299789429, -0.7669790387153625, -0.748124361038208, 0.34818074107170105, -0.13342532515525818, 0.26762524247169495, 0.15782597661018372, -1.0111231803894043, -0.7650139927864075, -0.9019254446029663, 0.2170039415359497, -0.6447941660881042, 0.11147182434797287, 0.7487584948539734, 0.4357225298881531, -0.4490341544151306, 1.1314663887023926, -0.5154056549072266, 0.2569805383682251, 1.0420547723770142, 0.242323637008667, 0.1170775294303894, -0.11905970424413681, -0.9737655520439148, 0.30947229266166687, 0.27348852157592773, -0.44426730275154114, -0.4230998456478119, -1.1131887435913086, -0.7608455419540405, -0.3711157739162445, -0.12472235411405563, -0.32083743810653687, 0.7877436280250549, -0.7017833590507507, -1.0630183219909668, 1.0305253267288208, -0.33610624074935913, -0.2163419872522354, 0.42190220952033997, -0.5379700660705566, -0.20967862010002136, -0.4580090641975403, -0.4067961275577545, 0.20187097787857056, 0.5905699133872986, -0.3869488835334778, -0.11323996633291245, 0.3138706684112549, -0.35379859805107117, -0.4979422390460968, -0.33328109979629517, 0.7376429438591003, -0.41756004095077515, -0.3283727467060089, -0.06533976644277573, 1.0694736242294312, 0.39554068446159363, -0.08968040347099304, -0.573408305644989, -0.8940529823303223, 0.8806754946708679, 0.02807530015707016, 0.805841326713562, -1.112713098526001, -0.563380241394043, -0.16916804015636444, -0.0166154894977808, -0.10798206925392151, -0.517134428024292, 0.18661029636859894, -0.3753323256969452, 0.5238588452339172, 0.01491484884172678, -1.0272784233093262, -0.2849932610988617, -0.22574082016944885, -0.7233613729476929, 0.19378675520420074, 0.5954745411872864, 0.7387228608131409, -0.8381560444831848, 0.22099119424819946, -0.133669912815094, 0.5422298908233643, -1.4157161712646484, 1.5134357213974, -0.2612631022930145, 0.3013208508491516, -0.10208641737699509, -0.19446223974227905, 0.22322124242782593, -0.20654639601707458, 0.05277517810463905, -0.28720471262931824, 0.14136531949043274, 0.5011053681373596, -0.30819758772850037, 1.0102534294128418, -0.29374179244041443, 0.5789933800697327, 0.23908482491970062, -0.7486386895179749, 0.25636419653892517, 0.23946073651313782, -0.2667315900325775, -0.3747657537460327, 0.3598763346672058, 0.19738639891147614, -0.8695457577705383, 0.42149943113327026, 0.22344659268856049, 0.5201331973075867, -0.1382451355457306, -0.04495193809270859, 1.0757462978363037, -0.17513175308704376, 0.1823488026857376, 0.5324283242225647, 0.8304557204246521, 0.4381689727306366, 0.2490045577287674, 0.06603465974330902, 0.03834459185600281, -0.824004054069519, 0.2682122588157654, 0.6739839911460876, 0.687114953994751, 1.2918181419372559, 0.956313967704773, -0.8270480632781982, -0.46219274401664734, -0.4406815469264984, 0.7038294672966003, 1.0733544826507568, -0.34704819321632385, 0.19005560874938965, -0.4042644500732422, -0.46424609422683716, -0.22004850208759308, -0.14974133670330048, -0.38893187046051025, -0.5484132170677185, -0.5945996046066284, -1.2532607316970825, 0.7235676050186157, -0.046165551990270615, 1.1754035949707031, -0.737660825252533, 0.33707505464553833, -0.3723992109298706, 0.7119399905204773, -0.9201551079750061, -0.7657214403152466, 0.36359119415283203, -0.5394613742828369, -0.23440062999725342, 0.13595640659332275, -0.09871254116296768, 0.25081533193588257, -0.9307335019111633, 1.2362768650054932, -0.26911643147468567, -0.07848571240901947, -0.04247472435235977, 0.39435142278671265, -0.6954150795936584, -0.5896021127700806, 0.4457716643810272, 0.1087343841791153, 0.4735240936279297, 0.04740791767835617, 0.0515177957713604, -0.07872963696718216, -0.11969446390867233, -0.7623109817504883, -0.34325116872787476, -0.04144088923931122, 0.3220131993293762, 0.5722171664237976, -0.20237144827842712, 0.14017713069915771, -1.5862168073654175, 1.013030767440796, -0.11539854109287262, -0.756266176700592, -0.20405304431915283, -0.23243820667266846, -0.21631716191768646, 0.642870306968689, -0.6135320067405701, -0.015193963423371315, -0.8544802069664001, 0.1546574831008911, -0.8029634952545166, -0.24498364329338074, -0.01309215184301138, 0.1980493813753128, 0.30880942940711975, 0.41559264063835144, -0.01393616572022438, 0.2725704610347748, -0.1888532042503357, 0.42867711186408997, -1.3516939878463745, 0.5334670543670654, 0.43075039982795715, 0.5667122602462769, 0.2943064272403717, -0.3949224352836609, -0.7200179100036621, -1.1893330812454224, -0.2710293233394623, -0.2070900946855545, -0.2864113450050354, 0.08981114625930786, -0.6509444117546082, -0.779371976852417, 0.08684401959180832, -0.9433545470237732, -0.6497583389282227, -0.30085471272468567, -0.08319390565156937, -0.11552760750055313, -1.5812679529190063, -1.0371739864349365, -0.6028671264648438, -0.25144827365875244, -0.8593158721923828, -0.1184140294790268, 0.2685817778110504, -0.2819189727306366, -0.8980400562286377, -0.402387410402298, -0.7895623445510864, 0.8490416407585144, -0.15636299550533295, 0.7673947811126709, -0.027078034356236458, -0.6341512799263, -0.1520160436630249, 0.08150242269039154, 1.045396089553833, -0.24207475781440735, -0.1933535933494568, -0.9311882257461548, 0.3286818563938141, -0.35166260600090027, -0.8303331732749939, 0.3582548499107361, 0.3815179467201233, 0.6250929832458496, 0.05320955067873001, 0.003985886927694082, 0.9266036748886108, 1.5119906663894653, -0.7259666323661804, 0.31481871008872986, 0.2823481559753418, 0.7615615725517273, 0.10828083753585815, -0.7397333979606628, 0.3441043794155121, -0.23988944292068481, 0.11210606247186661, 0.3726663291454315, -0.2120475471019745, -0.4896920621395111, -0.9410160779953003, 0.3766615092754364, 1.0486292839050293, 0.7279067039489746, 0.2506280541419983, -0.6465935707092285, 0.7078403830528259, -0.7754466533660889, -0.7643542885780334, 0.808178186416626, 0.7871885895729065, 0.6262693405151367, -0.17954140901565552, -0.3450812101364136, -0.23321238160133362, 0.47833195328712463, 0.432822048664093, -0.22412340342998505, -0.583354115486145, -0.0772065818309784, 0.4877108335494995, 0.5495420098304749, 1.0540200471878052, -0.37396734952926636, 0.6683831214904785, 14.827004432678223, 0.5463359355926514, -0.05363329127430916, 0.7134836316108704, 0.5185149312019348, -0.02733604609966278, -0.10880228877067566, -0.19102345407009125, -1.630458950996399, -0.005253847688436508, 0.6773777008056641, 0.4121442139148712, 0.7634583115577698, -0.17119412124156952, 0.05591682344675064, 0.41607949137687683, -0.29731014370918274, 0.7878356575965881, 0.5751317739486694, -1.3975807428359985, 0.3531745672225952, 0.027718879282474518, 0.5492809414863586, 0.7492946982383728, 0.8869338035583496, 0.8050060272216797, 0.6984228491783142, -0.32883620262145996, 0.6037969589233398, 0.6133722066879272, 0.7574318051338196, 0.13754647970199585, 0.3548826575279236, 0.28140634298324585, -0.40331441164016724, 0.0027434600051492453, -0.8334448337554932, -0.8808553218841553, 0.3096308708190918, 0.47520965337753296, 0.2718219459056854, -0.7201665639877319, -0.04219425469636917, 1.043426752090454, 0.07541977614164352, 0.46733033657073975, -0.4909484386444092, 0.8407690525054932, -0.3118368983268738, 0.13634885847568512, 0.45101967453956604, 0.26069149374961853, 0.6119958758354187, 0.028187118470668793, -0.2532474100589752, -0.12043796479701996, 0.18335263431072235, 1.0078781843185425, -1.1956684589385986, -0.26246848702430725, -0.5529496669769287, -0.09872202575206757, -0.3140130937099457, 0.5072513818740845, 0.6024348139762878, 0.26659274101257324, -0.4783269762992859, 0.4501124322414398, 0.6194747090339661, 0.5479099750518799, -0.2860945761203766, -0.3023942708969116, 0.6941560506820679, 0.006713606417179108, -0.017820652574300766, 0.4690263271331787, -0.3851208984851837, -0.8497936129570007, -0.5350746512413025, -0.19819797575473785, 0.41628944873809814, -0.8652766346931458, -0.9015465378761292, 1.0354127883911133, -0.3209364414215088, -0.3494374454021454, 0.6925399303436279, -0.9113834500312805, -0.30835244059562683, 0.51064532995224, -1.7706722021102905, -0.37537068128585815, 0.07751035690307617, 0.13946639001369476, -0.4262012541294098, -0.4905271530151367, 0.8110930919647217, 0.2896600067615509, -0.5867446660995483, 0.0638437420129776, -0.14354558289051056, 0.445747971534729, -0.22578181326389313, -0.8307477235794067, 0.4096950590610504, 0.21445193886756897, -0.11571469157934189, 0.0524979792535305, -0.07389561831951141, 0.1547180861234665, -0.2365829199552536, -0.5285512208938599, 0.33345699310302734, -0.8614799380302429, -0.04010220989584923, -0.7498018145561218, -0.9410985708236694, 0.5638397336006165, 0.6435792446136475, 0.3683190643787384, 0.12601543962955475, 0.35990211367607117, -0.918398380279541, -0.19525715708732605, -0.5481763482093811, -0.23910574615001678, 0.18141981959342957, -0.7487000226974487, -0.3028389811515808, -0.003571657231077552, 0.21664945781230927, -1.0206995010375977, -0.298891544342041, -0.4332018494606018, -0.27511900663375854, -0.5886082053184509, 0.8329722285270691, -0.7845478057861328, 0.5232740640640259, 0.8854987621307373, -0.058710020035505295, -0.8616518974304199, -0.011353076435625553, -1.2391183376312256, 0.2581440508365631, 0.4328775107860565, 0.5609699487686157, -0.6848828196525574, 0.7851602435112, 0.39243456721305847, 0.12426386773586273, -0.06805212795734406, -0.5580158829689026, -0.504348635673523, 0.5843523740768433, -0.525233805179596, -0.20265398919582367, -0.1688145250082016, -0.6530559062957764, 0.17422860860824585, 0.2815762460231781, 0.5906556248664856, 0.2687949240207672, -1.1060867309570312, 0.15147392451763153, -0.056454017758369446, 0.16966913640499115, -0.5455932021141052, -0.8302115797996521, -1.4481842517852783, 0.18478746712207794, -1.3800148963928223, -0.49597981572151184, -0.4919709861278534, -0.5301740765571594, 0.34436801075935364, -0.42289072275161743, -0.015182845294475555, 0.4127192199230194, -0.17054419219493866, -0.24820064008235931, -0.5154752731323242, -0.30118727684020996, 0.9426905512809753, 0.5303789973258972, -0.5960296988487244, -0.37341073155403137, 0.07484891265630722, -0.1308223456144333, 0.6610568165779114, 0.6176730990409851, -0.8467040657997131, -0.4917559325695038, -1.363568902015686, 0.28190624713897705, -0.5223103761672974, 0.30062705278396606, -0.9253591895103455, 0.6132084131240845, 0.6914330720901489, -0.020268965512514114, 0.12284620106220245, 0.28402823209762573, -1.0814132690429688, -0.878945529460907, 0.15006834268569946, -0.47405341267585754, 0.008970314636826515, 0.24629326164722443, -0.4802975356578827, -0.7072635293006897, 0.8018348217010498, 0.6069355010986328, -0.8953529596328735, -0.4124895930290222, 0.40386611223220825, -0.6575635671615601, 0.6652915477752686, -0.4225189685821533, 0.05379520356655121, -1.0945804119110107, -0.4507937431335449, -0.3140278160572052, 0.34847885370254517, -0.44276684522628784, 0.7701994180679321, 0.4214622676372528, -1.3074939250946045, 0.23244625329971313, 0.6890692710876465, -0.37448012828826904, -0.05075109004974365, 0.2969156801700592, 0.35616081953048706, -0.5791590809822083, 0.09958966076374054, 0.17486630380153656, 0.275786817073822, -0.4419895112514496, -0.07884319871664047, 1.419681191444397, -0.4413706064224243, -0.4796048700809479, 1.05142343044281, -0.18979158997535706, -0.9381743669509888, 0.6625956296920776, -1.0190598964691162, -0.2770095467567444, -0.13583669066429138, 0.747926652431488, -0.05512186512351036, 0.08437879383563995, 0.23907189071178436, -0.03125149756669998, 0.04404324293136597, -0.07421513646841049, -0.27362877130508423, 0.46760672330856323, -0.10730874538421631, 0.009373107925057411, 0.9243699908256531, 1.167433261871338, -0.7831144332885742, -1.1590802669525146, -0.9973596930503845, -0.38610661029815674, -0.0005514764925464988, 0.33737924695014954, -0.05153774470090866, -1.344843864440918, 0.9433902502059937, 0.4237760305404663, 0.054108381271362305, 0.18337886035442352, -0.28561636805534363, -0.18627403676509857, 0.5209067463874817, 0.022565508261322975, -0.7080154418945312, 0.1072750836610794, 1.5808799266815186, 1.4904580116271973, -0.7106515765190125, 0.33693039417266846, -0.4340457618236542, -0.7476142644882202, 0.6549148559570312, 0.25684013962745667, -0.9160947203636169, 1.373837947845459, -0.11716485768556595, 0.3174586594104767, 0.1269550770521164, -0.9575478434562683, -0.5747449994087219, 0.36282670497894287, 1.0046976804733276, 0.7093483805656433, -0.3327164053916931, 0.48954471945762634, 0.7253969311714172, 0.20403654873371124, -0.002614622935652733, 0.8332520127296448, 0.39209577441215515, 0.00867234356701374, -0.28322505950927734, -0.15464988350868225, 0.7211150527000427, -1.3060342073440552, -0.2926606833934784, -0.05315680429339409, 1.042535662651062, 0.1884641945362091, 0.5132187604904175, 0.7552315592765808, 0.07087413966655731, 1.1958171129226685, 0.3791680932044983, 0.27620241045951843, -0.6398890018463135, -0.5836225748062134, -0.18309736251831055, -0.9945297241210938, -0.49835067987442017, -0.24242740869522095, -0.725165605545044, -0.03220578283071518, -0.31125807762145996, 0.5533841848373413, -0.3060286343097687, -0.19296987354755402, 0.8166157603263855, 0.3026483654975891, 0.954980731010437, -0.08132090419530869, -0.4146844744682312, -0.24595323204994202, -0.9574227333068848, -0.2206600159406662, 0.006449847482144833, 0.30012309551239014, -0.2801949083805084, -0.43254125118255615, -0.0486837774515152]}, "authors": [{"authorId": "143950636", "name": "Hieu Pham"}, {"authorId": "2827616", "name": "Quoc V. Le"}], "references": [{"paperId": "a2cd073b57be744533152202989228cb4122270a", "title": "Sharpness-Aware Minimization for Efficiently Improving Generalization"}, {"paperId": "5f69762f2ec3eecb6011d14f024ef0dec3eba23c", "title": "TResNet: High Performance GPU-Dedicated Architecture"}, {"paperId": "46803220e5f6b636b65ef0ff87c0c9c4b95dec31", "title": "On Feature Normalization and Data Augmentation"}, {"paperId": "7af72a461ed7cda180e7eab878efd5f35d79bbf4", "title": "A Simple Framework for Contrastive Learning of Visual Representations"}, {"paperId": "299847adf3ee558a760475ffa364facac3ebbb16", "title": "FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence"}, {"paperId": "69599593f93023e2f91ef6673ee9860f85777d98", "title": "NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search"}, {"paperId": "1148ecf3734486e234869262ae8e8daf309fc0b2", "title": "AutoML for Architecting Efficient and Specialized Neural Networks"}, {"paperId": "ea415809bf87ef4b99966c6c50de6cb996a02a97", "title": "Deep double descent: where bigger models and more data hurt"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "068eb2019cbb91421b7746af38da5e4c82f5e89c", "title": "ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring"}, {"paperId": "41c67d04be2d1632c0d3b0880c21c9fe797cdab8", "title": "EfficientDet: Scalable and Efficient Object Detection"}, {"paperId": "20ba55ee3229db5cb190a00e788c59f08d2a767d", "title": "Self-Training With Noisy Student Improves ImageNet Classification"}, {"paperId": "dfa553707b215910f028d2a58ab79116626cc94a", "title": "RandAugment: Practical data augmentation with no separate search"}, {"paperId": "11babff42b5bf9841ebb87781bfc21f74acb3d28", "title": "Implicit Semantic Data Augmentation for Deep Networks"}, {"paperId": "7b48a1cbd2bfbb5045269626f3303e68d7e63a05", "title": "Learning Data Augmentation Strategies for Object Detection"}, {"paperId": "c0aaee2337e5af680e5dca1bfc349a737dfec573", "title": "Fixing the train-test resolution discrepancy"}, {"paperId": "3ec4e35f8d3d1bd8c89eb0c4d7626ad48ea3641d", "title": "Local Label Propagation for Large-Scale Semi-Supervised Learning"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "c42816f497d663c681df20d48a6e66a5632600d8", "title": "MixMatch: A Holistic Approach to Semi-Supervised Learning"}, {"paperId": "e808cac4b64a8c73ada719f76ad885454c71a74c", "title": "Fast AutoAugment"}, {"paperId": "0feea94f89d395436bf41bd10c797447eecbc128", "title": "Unsupervised Data Augmentation for Consistency Training"}, {"paperId": "b0fae9fbb4e580d92395eabafe73e317ae6510e3", "title": "SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition"}, {"paperId": "743ce0d2c9d86caa5a570fec36e8d2378d031b3f", "title": "Interpolation Consistency Training for Semi-Supervised Learning"}, {"paperId": "6e4fd9b4b2b673c981cda528d8039a221ad35225", "title": "NAS-Bench-101: Towards Reproducible Neural Architecture Search"}, {"paperId": "35a59bd09974c7fc78cf681f77f7301e180fd23c", "title": "Random Search and Reproducibility for Neural Architecture Search"}, {"paperId": "37d4a89250ce1ed99e27201cbffc2ca43fc364ee", "title": "Semi-Supervised Learning by Label Gradient Alignment"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "e4b64a75d321311447e11c363b45cc07bb74acc2", "title": "DropBlock: A regularization method for convolutional networks"}, {"paperId": "f323407464c4cd492d3fc1afd7170eab08f44d9b", "title": "ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "c1f457e31b611da727f9aef76c283a18157dfa83", "title": "DARTS: Differentiable Architecture Search"}, {"paperId": "1b59eea8ec4684381a885b59acd09c9151a49487", "title": "Manifold Mixup: Better Representations by Interpolating Hidden States"}, {"paperId": "f723eb3e7159f07b97464c8d947d15e78612abe4", "title": "AutoAugment: Learning Augmentation Policies from Data"}, {"paperId": "fe9b8aac9fa3bfd9724db5a881a578e471e612d7", "title": "Efficient Neural Architecture Search via Parameter Sharing"}, {"paperId": "50bdda28de3dcf82a0e10f9ec13eea248b19edb5", "title": "Regularized Evolution for Image Classifier Architecture Search"}, {"paperId": "5f79398057bf0bbda9ff50067bc1f2950c2a2266", "title": "Progressive Neural Architecture Search"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "eb35fdc11a325f21a8ce0ca65058f7480a2fc91f", "title": "Improved Regularization of Convolutional Neural Networks with Cutout"}, {"paperId": "58c6f890a1ae372958b7decf56132fe258152722", "title": "Regularizing and Optimizing LSTM Language Models"}, {"paperId": "168b7d0ab57a331a228ce21ffd1becbb93066f79", "title": "Neural Optimizer Search with Reinforcement Learning"}, {"paperId": "d0611891b9e8a7c5731146097b6f201578f47b2f", "title": "Learning Transferable Architectures for Scalable Image Recognition"}, {"paperId": "bfbd10ebffc9494423770a5bd30ebd0f9cbce66d", "title": "Device Placement Optimization with Reinforcement Learning"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "4b1c6f6521da545892f3f5dc39461584d4a27ec0", "title": "Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning"}, {"paperId": "f108b65fe0003e387e1cd7e50f537af0531818e4", "title": "Large-Scale Evolution of Image Classifiers"}, {"paperId": "7493389667058116dbc7e808987f129325ee60d7", "title": "Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results"}, {"paperId": "d7878c2044fb699e0ce0cad83e411824b1499dc8", "title": "Neural Combinatorial Optimization with Reinforcement Learning"}, {"paperId": "67d968c7450878190e45ac7886746de867bf673d", "title": "Neural Architecture Search with Reinforcement Learning"}, {"paperId": "5bdf07c9897ca70788fff61dec56178a2bd0c29c", "title": "Deep Pyramidal Residual Networks"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "e3ce71a26872c7755e6d8b8fc45bf00c8be64193", "title": "Edinburgh Neural Machine Translation Systems for WMT 16"}, {"paperId": "4954fa180728932959997a4768411ff9136aac81", "title": "TensorFlow: A system for large-scale machine learning"}, {"paperId": "d0156126edbfc524c8d108bdc0cf811cfe3129aa", "title": "FractalNet: Ultra-Deep Neural Networks without Residuals"}, {"paperId": "1c4e9156ca07705531e45960b7a919dc473abb51", "title": "Wide Residual Networks"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "0c1f9ca23f4f09ecfc44bcc8ca1c2736624f4652", "title": "A Theoretically Grounded Application of Dropout in Recurrent Neural Networks"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6", "title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "ebcea2d842d3d4e320500086aff0deb4cb4412ff", "title": "Efficient object localization using Convolutional Networks"}, {"paperId": "f264e8b33c0d49a692a6ce2c4bcb28588aeb7d97", "title": "Recurrent Neural Network Regularization"}, {"paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd", "title": "ImageNet Large Scale Visual Recognition Challenge"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "59ce9cdbde13affc05a6c1f48a51ee7b0fcb154b", "title": "The Penn Treebank: Annotating Predicate Argument Structure"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": "798d9840d2439a0e5d47bcf5d164aa46d5e7dc26", "title": "Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "4c915c1eecb217c123a36dc6d3ce52d12c742614", "title": "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning"}]}