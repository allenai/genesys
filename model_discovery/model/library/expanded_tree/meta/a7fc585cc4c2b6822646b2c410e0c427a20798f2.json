{"paperId": "a7fc585cc4c2b6822646b2c410e0c427a20798f2", "abstract": "Today\u2019s large language models (LLMs) typically train on short text segments (e.g., <4K tokens) due to the quadratic complexity of their Transformer architectures. As a result, their performance suffers drastically on inputs longer than those encountered during training, substantially limiting their applications in real-world tasks involving long contexts such as encod- ing scientific articles, code repositories, or long dialogues. Through both theoretical analysis and empirical investigation, this work identifies three major factors contributing to this length generalization failure. Our theoretical analysis reveals that commonly used techniques like using a sliding-window attention pattern or relative positional encodings are inadequate to address them. Answering these challenges, we propose LM-Infinite, a simple and effective method for enhancing LLMs\u2019 capabilities of handling long contexts. LM-Infinite is highly flexible and can be used with most modern LLMs off-the-shelf. Without any parameter updates, it allows LLMs pre-trained with 2K or 4K-long segments to generalize to up to 200M length inputs while retaining perplexity. It also improves performance on downstream tasks such as Passkey Retrieval and Qasper in the zero-shot setting. LM-Infinite brings substantial efficiency improvements: it achieves 2.7\u00d7 decoding speed up and 7.5\u00d7 memory saving over the original model. Our code will be publicly available upon publication.", "venue": "North American Chapter of the Association for Computational Linguistics", "year": 2023, "citationCount": 6, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "LM-Infinite is a simple and effective method for enhancing LLMs\u2019 capabilities of handling long contexts, which allows LLMs pre-trained with 2K or 4K-long segments to generalize to up to 200M length inputs while retaining perplexity."}, "embedding": {"model": "specter_v2", "vector": [0.15830816328525543, 0.8682209849357605, -0.2166067510843277, -0.011794623918831348, -0.332762748003006, -0.33613359928131104, 0.7112597227096558, -0.11212915927171707, -0.46054595708847046, -0.27436187863349915, 0.4829064905643463, -0.29669472575187683, 0.4750458598136902, 0.3558919131755829, -0.2423410415649414, 0.25321120023727417, -0.998380720615387, 0.05018473416566849, -0.034019630402326584, -0.3191494941711426, -0.24593910574913025, -0.8582848906517029, -0.8105083107948303, 0.1948223114013672, 0.41694775223731995, -0.020228371024131775, 0.2254183143377304, 0.8013495206832886, -0.5564360618591309, 0.37562304735183716, 0.2663014531135559, -0.5987731218338013, 0.005862370133399963, -0.21842680871486664, -0.5286809802055359, -0.16959507763385773, 0.24459542334079742, -0.32295680046081543, -0.486211359500885, 0.5223860740661621, -0.3105461895465851, 0.3566427528858185, 0.3744029402732849, -0.5111340880393982, -0.45609328150749207, 1.28928804397583, 0.8113199472427368, 0.3865393400192261, -0.13048356771469116, -0.4015897214412689, 1.4567536115646362, -1.5865949392318726, 0.5876598358154297, 1.4179871082305908, 0.4759356379508972, 0.6118679642677307, 0.021530548110604286, -0.4191194474697113, 0.7254048585891724, 0.1016162633895874, -0.9988372921943665, -0.5087390542030334, -0.19723354279994965, 0.1176905632019043, 1.9306379556655884, -0.4024204611778259, 0.000976273906417191, 0.4583132266998291, -0.24085094034671783, 1.4481337070465088, -0.5306553244590759, -1.0114089250564575, -0.2702379822731018, -0.14702928066253662, 0.22651903331279755, 0.5642450451850891, -0.6806554794311523, -0.3183269798755646, -0.6140475273132324, -0.059663690626621246, 0.004842089023441076, -0.01541750505566597, -0.14183872938156128, 0.2787044048309326, -0.2176779806613922, 0.45635077357292175, 0.20914621651172638, 0.6820446848869324, 0.2515859007835388, 0.3246847093105316, 0.5250236392021179, 0.7316566109657288, 0.3076357841491699, 0.26367759704589844, -0.15367096662521362, 0.31519773602485657, -1.0153177976608276, 0.39852166175842285, 0.22919069230556488, 1.1417553424835205, -0.4217623770236969, 0.17705437541007996, -0.7114030122756958, 0.35701584815979004, 1.1477854251861572, -0.1269790679216385, 0.4692760705947876, -0.6636226177215576, 0.32615283131599426, -0.5195062160491943, 0.22875921428203583, -0.2677533030509949, -0.17974013090133667, -0.19329291582107544, -0.560489296913147, -1.579930305480957, -0.3150734007358551, 0.21965616941452026, -0.5218935012817383, 0.8001343011856079, -0.3291483223438263, 0.07770346850156784, 0.31590262055397034, 0.25033533573150635, 0.9322470426559448, 0.9056165218353271, 0.5204213261604309, -0.053636882454156876, 0.5970507264137268, -0.8028336763381958, -0.49724656343460083, -1.1929945945739746, 1.1599173545837402, -0.31464171409606934, 0.616790235042572, -0.25514280796051025, -1.3049101829528809, -0.6573417782783508, -0.8870775103569031, -0.02051469311118126, -0.6335919499397278, 0.4928377866744995, 0.4861740469932556, 0.19746290147304535, -0.8275502324104309, 0.9364646673202515, 0.101741261780262, -0.26208966970443726, 0.12927189469337463, 0.04152308776974678, 0.2815263569355011, -0.7114914655685425, -1.6646640300750732, 0.12544067203998566, 0.1709533929824829, -0.5525026917457581, -0.11184944212436676, -0.5318630933761597, -1.4029537439346313, -0.034480538219213486, 0.2697180211544037, -0.11250879615545273, 1.3802913427352905, -0.24269038438796997, -1.3410975933074951, 0.7162362337112427, -0.3439754545688629, 0.1786174774169922, 0.06741060316562653, -0.2219574749469757, -0.613670289516449, -0.4840455651283264, -0.35175055265426636, 0.33607637882232666, 0.2483908087015152, 0.25220876932144165, 0.21662139892578125, 0.336699515581131, -0.23452815413475037, -0.06988075375556946, -0.24400104582309723, 0.898992121219635, -0.6163345575332642, -0.09101462364196777, 0.25238025188446045, 0.47546908259391785, 0.07355902343988419, -0.5033813118934631, -0.4664516746997833, -1.334457516670227, 0.4765651524066925, -0.06546849757432938, 1.362619400024414, -1.0462156534194946, -0.5684371590614319, -0.6455453038215637, -0.3906775116920471, 0.03924131020903587, -0.680915355682373, 0.9791794419288635, -0.09551671147346497, 0.6133534908294678, -0.17361345887184143, -1.3357863426208496, 0.1201014295220375, -0.29671862721443176, -0.6522247791290283, 0.1324804425239563, -0.0019316835096105933, 1.27169668674469, -1.1189072132110596, 0.09809219092130661, -0.2746991515159607, 0.1543274223804474, -0.7555875182151794, 1.1811105012893677, -0.4987378418445587, -0.10148491710424423, 0.03131021559238434, -0.15200680494308472, -0.023431824520230293, -0.49024778604507446, 0.41520148515701294, -0.06205425038933754, -0.36646318435668945, 0.395328551530838, -0.016951901838183403, 1.5145946741104126, -0.2617802619934082, 0.5846697092056274, -0.2996152639389038, -0.5227568745613098, -0.08522569388151169, 0.6638786196708679, -0.3162100315093994, -0.24787704646587372, 0.3103007376194, 0.41296616196632385, -0.6572312712669373, 0.054948627948760986, 0.6526683568954468, 0.8863332271575928, -0.6608538627624512, 0.26283273100852966, 0.7620679140090942, 0.08606915175914764, 0.4649380147457123, 0.7466390132904053, 0.5562564730644226, 0.44350889325141907, 0.3104778826236725, -0.13179808855056763, 0.5379717946052551, -0.7931559681892395, -0.20421874523162842, 0.498104453086853, 0.7204844355583191, 0.790504515171051, 0.3962840139865875, -0.6270751357078552, -0.5722639560699463, 0.24697905778884888, 0.74537193775177, 1.7149261236190796, 0.11238318681716919, -0.48784303665161133, -0.7866030335426331, 0.018846040591597557, -0.4973563253879547, 0.2796958088874817, -0.18340298533439636, -0.1961355358362198, -0.5356907248497009, -0.7114437818527222, 1.0258569717407227, -0.18612943589687347, 0.4432776868343353, -0.5524929165840149, -0.3586685359477997, -0.09375083446502686, 0.07745937258005142, -0.8306180238723755, -0.6933355927467346, -0.05186786130070686, -0.3677724301815033, 0.0021471246145665646, -0.3956149220466614, -0.1342180222272873, 0.13340942561626434, -0.5772788524627686, 1.0399501323699951, -0.6832056641578674, -0.585898756980896, 0.3732271194458008, 0.2390836924314499, -0.7046595215797424, -0.9840947985649109, 0.22207963466644287, 0.06143208593130112, -0.22837695479393005, 0.5036417841911316, 0.7167364954948425, -0.18090984225273132, -0.17199333012104034, -0.4893498718738556, 0.015134100802242756, 0.16304875910282135, -0.15235885977745056, 0.38075464963912964, -0.7216631770133972, 0.4223610758781433, -0.9799823760986328, 1.038974404335022, 0.015561960637569427, -0.19596843421459198, 0.5779972076416016, -0.5619263648986816, -0.47675904631614685, 0.8838719129562378, -0.9051102995872498, -0.249810129404068, -1.0667214393615723, 0.2286616712808609, -0.1844222992658615, -0.09285541623830795, 0.31758710741996765, 0.09447857737541199, 0.5832245349884033, 0.01605631597340107, 0.6611349582672119, 0.3724811375141144, -0.40333330631256104, 0.7144070267677307, -0.35059481859207153, 0.37408024072647095, 0.42528727650642395, -0.2904270589351654, -0.1879909187555313, -0.29675614833831787, -0.9680336117744446, -0.2730928659439087, -0.6519553661346436, -0.3233514428138733, -0.4336872100830078, -0.10884281992912292, -0.7375968098640442, -0.5819143056869507, 0.1999935358762741, -1.1960055828094482, -0.2263442575931549, 0.3001123368740082, -0.3666820228099823, -0.12930399179458618, -0.6703209280967712, -1.2871736288070679, -0.35320383310317993, -0.7525575757026672, -0.7339701652526855, 0.3789304792881012, 0.09577330201864243, -0.6834782361984253, -0.4375394880771637, 0.06135370582342148, -0.7793717980384827, 0.7239915728569031, -0.8544221520423889, 0.8173626661300659, -0.2695501446723938, -0.07520009577274323, -0.49329495429992676, 0.4857168197631836, 0.4160679578781128, -0.42174196243286133, 0.12812626361846924, -0.5512989163398743, -0.001369548263028264, -0.5734447836875916, -0.39760610461235046, 0.11484594643115997, 0.2851632833480835, 0.4455523192882538, -0.24847829341888428, -0.5999352931976318, 0.190394327044487, 1.2741183042526245, -0.814228355884552, -0.04992276057600975, 0.0557590015232563, 0.6653252840042114, 0.3883557915687561, -0.21381080150604248, 0.8783815503120422, 0.27199628949165344, 0.13075098395347595, 0.1869128793478012, -0.027691485360264778, 0.05107822269201279, -0.5790881514549255, 0.8228909373283386, 1.5889501571655273, 0.39204835891723633, -0.4044268727302551, -1.0144158601760864, 0.9980438351631165, -1.0743430852890015, -0.8278384208679199, 0.5382925271987915, 0.8687995076179504, 0.2701348066329956, -0.6296310424804688, -0.5921585559844971, -0.7627498507499695, 0.2547391951084137, 0.4418773353099823, -0.31846731901168823, -0.84912109375, -0.1731872409582138, 0.04926183447241783, 0.08426970988512039, 0.4731028378009796, -0.31332823634147644, 0.8602421283721924, 14.92287826538086, 0.7599970698356628, -0.03376813977956772, 0.553658664226532, 0.6310067772865295, 0.031942788511514664, -0.3264710009098053, -0.16314087808132172, -1.2772789001464844, -0.17195311188697815, 1.5297784805297852, -0.2801176905632019, 0.45098069310188293, 0.16781659424304962, 0.2363322377204895, 0.43609699606895447, -0.5258033275604248, 0.5544672012329102, 0.6153767108917236, -1.1808947324752808, 0.4262016713619232, -0.017009710893034935, 0.34888678789138794, 0.7374058365821838, 0.7799378633499146, 1.0512381792068481, 0.4028942584991455, -0.5727367401123047, 0.4895721971988678, 0.13682647049427032, 0.8989914655685425, -0.18972714245319366, 0.27704179286956787, 1.0032155513763428, -0.7493771910667419, -0.30586889386177063, -0.9827227592468262, -1.0037386417388916, 0.20570625364780426, -0.03308027610182762, -0.6564177870750427, -0.3825675845146179, -0.4069713056087494, 0.8509976863861084, 0.08509024977684021, 0.32479509711265564, -0.021196398884058, 0.726555585861206, -0.11001268029212952, -0.09769484400749207, 0.6633506417274475, 0.43867015838623047, 0.3931658864021301, 0.192823588848114, 0.30263105034828186, 0.016155701130628586, 0.08469279110431671, 0.4836696982383728, -0.6426364779472351, 0.3403964638710022, -0.4547055661678314, -0.28210681676864624, 0.015207119286060333, 0.29289430379867554, 0.7178677320480347, 0.027317795902490616, -0.6527272462844849, 0.573913037776947, 0.6168084740638733, 0.45789802074432373, -0.02285044826567173, -0.317993700504303, 0.17021286487579346, -0.3946518898010254, -0.004803820047527552, 0.5849862098693848, 0.32927483320236206, -0.6382542252540588, -0.6367672085762024, -0.17565277218818665, 0.2636619508266449, -0.5138534307479858, -0.5278606414794922, 0.8736330270767212, -0.1932143270969391, -0.7942702174186707, 0.059515200555324554, -0.4557487368583679, -0.2654695510864258, 0.6369453072547913, -1.2360907793045044, -0.9785423874855042, 0.5237277150154114, -0.42326420545578003, 0.1581343412399292, 0.1356828361749649, 1.3630867004394531, 0.16429243981838226, -0.3017573356628418, 0.18960903584957123, 0.7731941342353821, 0.0028807735070586205, -0.1776888370513916, -0.4087761640548706, 0.6846946477890015, 0.3390490710735321, -0.4698684811592102, 0.5134866237640381, 0.08143611997365952, 0.3827948570251465, -0.870159387588501, -0.18363147974014282, 1.106801152229309, -0.9027939438819885, -0.5400685667991638, -0.7503821849822998, -0.9596344828605652, 0.3298089802265167, 0.5786032676696777, -0.22056855261325836, 0.45089325308799744, 0.2393021136522293, -0.42634251713752747, 0.0430421307682991, -0.34676364064216614, 0.11920784413814545, 0.45070821046829224, -0.9487197399139404, -0.35022780299186707, -0.07595789432525635, 0.44456204771995544, -0.6742175817489624, -0.5489325523376465, -0.21830405294895172, 0.2761521339416504, 0.18035893142223358, 0.8009669184684753, -0.7005393505096436, 0.6314236521720886, 1.113366961479187, 0.1321043223142624, -0.6815398335456848, 0.08107452094554901, -1.015868902206421, -0.07604086399078369, 0.15440620481967926, 0.6642153859138489, -0.021372487768530846, -0.20720620453357697, 0.9015190005302429, 0.1533212959766388, -0.715157687664032, -0.8603447079658508, -0.5759595036506653, 0.5261903405189514, -0.5283723473548889, 0.2977510392665863, -0.15304788947105408, 0.48966285586357117, 0.10251278430223465, 0.24246570467948914, 0.7112990617752075, -0.12608467042446136, -0.6148186922073364, 0.22309079766273499, -0.1149931401014328, 0.007578027900308371, -0.6547116041183472, -0.28999239206314087, -1.8372589349746704, 0.23934781551361084, -1.0389660596847534, 0.07747722417116165, -0.8489302396774292, -0.441630482673645, 0.4857257604598999, -0.13150647282600403, -0.18125414848327637, 0.5418198704719543, -0.4067463278770447, -0.5135725736618042, -0.3217936158180237, -0.8453009128570557, 0.793871283531189, 0.7284255027770996, -0.9520635604858398, -0.10416003316640854, 0.13253764808177948, 0.48003536462783813, 0.1565495878458023, 0.3451883792877197, -0.32432204484939575, -0.9460862874984741, -1.400686502456665, 0.640387773513794, -0.08339913934469223, -0.05762664973735809, -0.4706697463989258, 0.5440975427627563, 0.38714495301246643, -0.5581491589546204, -0.07746435701847076, 0.17233088612556458, -0.5384688973426819, -0.5175224542617798, 0.24919144809246063, -1.098387360572815, -0.08898995071649551, 0.015017001889646053, -0.5410665273666382, -0.3605033755302429, 0.39570701122283936, -0.29642483592033386, -1.3999069929122925, -0.7317373752593994, 0.48792582750320435, -0.7994420528411865, 0.20596295595169067, -0.27036169171333313, -0.029073921963572502, -0.76615309715271, -0.4015434682369232, -0.3079086244106293, 0.3798760175704956, -0.17150643467903137, 1.110392689704895, 0.4423568546772003, -0.7266315221786499, -0.2654249370098114, 0.1843145191669464, 0.19174069166183472, -0.022209499031305313, 0.7729979157447815, 0.33124083280563354, -0.1786971092224121, 0.8466857075691223, 0.721031904220581, 0.378304123878479, -1.273171305656433, -0.00464432081207633, 0.6074879765510559, -0.41755884885787964, -0.4565501809120178, 1.318806529045105, -0.3415050804615021, -1.0711666345596313, 0.03079000487923622, -1.0447856187820435, -0.48968616127967834, -0.3303498923778534, 0.850808322429657, 0.15716151893138885, -0.14480477571487427, -0.400728315114975, -0.4946490526199341, -0.034626055508852005, -0.11729317903518677, -0.3838738799095154, 0.6286210417747498, -0.4319870173931122, -0.3806035816669464, 0.9125711917877197, 1.1325058937072754, -0.7606664299964905, -0.44776013493537903, -0.7007842659950256, -0.43533390760421753, 0.2876533269882202, 0.09069912880659103, -0.15980660915374756, 0.22503897547721863, 0.976003885269165, 0.09941605478525162, 0.30529314279556274, -0.13567006587982178, 0.23079714179039001, 0.11140993237495422, 0.7981985807418823, 0.01854514516890049, -0.7121114134788513, -0.701177716255188, 1.466950535774231, 1.2929126024246216, -0.8386408686637878, 0.19356456398963928, 0.0770789384841919, -0.6768506169319153, 0.8476945161819458, 0.14714935421943665, 0.3497280478477478, 0.8603020310401917, -0.5813992619514465, 0.058438491076231, 0.14839336276054382, -1.2643616199493408, 0.047932885587215424, 0.9857189655303955, 0.4471333920955658, 0.9859375357627869, 0.24866366386413574, -0.3080536723136902, 1.0329080820083618, 0.24887512624263763, 0.15978127717971802, 0.6739645600318909, 0.40118759870529175, -0.3296087086200714, 0.06010627746582031, 0.414650022983551, 0.4052373468875885, -0.8433849811553955, -0.7273994088172913, -0.05396667495369911, 0.2951729893684387, 0.061175841838121414, 0.558892548084259, 0.8319892883300781, 0.3178727924823761, 0.31853705644607544, 0.657889723777771, 0.32159629464149475, -0.6512540578842163, -0.08656731992959976, -0.32973581552505493, -0.6686608791351318, 0.09495147317647934, -0.021793218329548836, -0.43532463908195496, -0.3077079951763153, -0.11507204920053482, 0.2583047151565552, 0.008135048672556877, -0.0005354374879971147, 1.3746896982192993, 0.6664287447929382, 0.18170182406902313, -0.31606385111808777, -0.12882906198501587, -0.6934036016464233, -1.0033340454101562, -0.16866524517536163, -0.1421603411436081, -0.08830448240041733, 0.3948644995689392, -0.2267448455095291, 0.0054619829170405865]}, "authors": [{"authorId": "2118642562", "name": "Chi Han"}, {"authorId": "2290856179", "name": "Qifan Wang"}, {"authorId": "2288239343", "name": "Hao Peng"}, {"authorId": "2290750668", "name": "Wenhan Xiong"}, {"authorId": "2181535101", "name": "Yu Chen"}, {"authorId": "2290907632", "name": "Heng Ji"}, {"authorId": "2237101143", "name": "Sinong Wang"}], "references": [{"paperId": "275b005c33a315ad603f236cd5766efe07ef6a54", "title": "Found in the Middle: How Language Models Use Long Contexts Better via Plug-and-Play Positional Encoding"}, {"paperId": "f05e84702562cb693dd68d3d1c88072519a7bd71", "title": "\u221eBench: Extending Long Context Evaluation Beyond 100K Tokens"}, {"paperId": "ce0d07a82ec152258d9ebf2496a16a6737cf89f6", "title": "A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts"}, {"paperId": "ef1b02dc1b82f9955fc4760fcefd92c0fff9f227", "title": "Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference"}, {"paperId": "f395f022548d1d1f11e231f42d4852dbff5e9376", "title": "On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference"}, {"paperId": "03edb4f89aeb59a8ce056ec6b75a3e259350593f", "title": "LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K"}, {"paperId": "82ba78d1520fbdca6f6e23fca1f555f25c8f86d4", "title": "Flexibly Scaling Large Language Models Contexts Through Extensible Tokenization"}, {"paperId": "6ac92ad74a4f41f2479da7edb2b483dbf57f10b7", "title": "Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing"}, {"paperId": "2b8439f319dfa73df62ca8957ff6d0c1f3c7a73c", "title": "Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon"}, {"paperId": "d7612d0a85fe0bee697635019d14b3b50de1366a", "title": "GPT Rotational Position Embedding for Length Extrapolation"}, {"paperId": "36697944858ab17ca23b23ae2043aa6c0b2e3d5d", "title": "Zebra: Extending Context Window with Layerwise Grouped Local-Global Attention"}, {"paperId": "539fadfb615ef84c240f4741061c44eeda540091", "title": "Scaling Laws of RoPE-based Extrapolation"}, {"paperId": "fdc53c2c10742464087c0525f77e32604827a21d", "title": "Efficient Streaming Language Models with Attention Sinks"}, {"paperId": "ff01d3dab60dd4b7426c884b009dda83540c0c1e", "title": "Attention Sorting Combats Recency Bias In Long Context Language Models"}, {"paperId": "73290ecbec2f38d1d647ddef1ada69cee41725b3", "title": "PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training"}, {"paperId": "b31a5884a8ebe96b6300839b28608b97f8f8ef76", "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "6f6e2e0311589a9af045f6acd00b7dee6d19fce4", "title": "The Impact of Positional Encoding on Length Generalization in Transformers"}, {"paperId": "60b35c6d68acced19b0c66edcfc0ee0a2c11efed", "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers"}, {"paperId": "d9964ab436eefd21f923a4bc833c6b66692c7f00", "title": "RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text"}, {"paperId": "c8dd0fe00f9a71ea68b6856b36590b8daa316139", "title": "A Frustratingly Easy Improvement for Position Embeddings via Random Padding"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "980e55d9226cac302d0fae7732da4e67b8bc952c", "title": "Parallel Context Windows for Large Language Models"}, {"paperId": "5735e49e501c8e51e9be4079592e46e047747b03", "title": "Dissecting Transformer Length Extrapolation via the Lens of Receptive Field Analysis"}, {"paperId": "0e802c0739771acf70e60d59c2df51cd7e8c50c0", "title": "Memorizing Transformers"}, {"paperId": "a68ab49816d5729435c3d994b434c75c6f162da0", "title": "Sketching as a Tool for Understanding and Accelerating Self-attention for Long Sequences"}, {"paperId": "002c256d30d6be4b23d365a8de8ae0e67e4c9641", "title": "Improving language models by retrieving from trillions of tokens"}, {"paperId": "4b0541eccd8f98852d6807a14fbac17f775c7b40", "title": "Skyformer: Remodel Self-Attention with Gaussian Kernel and Nystr\u00f6m Method"}, {"paperId": "64522a5b3476e9f201f6a5b3e312ef0005c562f1", "title": "SHAPE: Shifted Absolute Position Embedding for Transformers"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "7509c66a666e2e3f14bc8676b969b945ee6e136f", "title": "CAPE: Encoding Relative Positions with Continuous Augmented Positional Embeddings"}, {"paperId": "4e3935ef7da6bcbb202ec7f8b285c313cadcd044", "title": "A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "46c585ee9abf76779ea4b863d2da4358efd0d1d3", "title": "Adaptive Semiparametric Language Models"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "725264948d7b6946259af5b8d966e996b9570f99", "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"}, {"paperId": "8256f48f759cf85044db251cc512f965834945b3", "title": "Rethinking Positional Encoding in Language Pre-training"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "832fff14d2ed50eb7969c4c4b976c35776548f56", "title": "REALM: Retrieval-Augmented Language Model Pre-Training"}, {"paperId": "7be8c119dbe065c52125ee7716601751f3116844", "title": "Generalization through Memorization: Nearest Neighbor Language Models"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "29092f0deaac3898e43b3f094bf15d82b6a99afd", "title": "Learning to Remember Rare Events"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "fedfc9fbcfe46d50b81078560bce724678f90176", "title": "Decision Theoretic Generalizations of the PAC Model for Neural Net and Other Learning Applications"}, {"paperId": "6e76e29188ae8f5ff86f85945d4784b8c598b01e", "title": "DOC: Improving Long Story Coherence With Detailed Outline Control"}, {"paperId": null, "title": ". Things i \u00b4 m learning while training superhot"}, {"paperId": null, "title": "GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "d298ce81fa8f6d73689f84535efce90dfcb4bf78", "title": "Empirical Processes: Theory and Applications"}, {"paperId": null, "title": "2023. Introducing mpt-7b: A new standard for open-source, commercially usable llms"}, {"paperId": null, "title": "2023. Longnet: Scaling transformers to 1,000,000,000 to-kens"}, {"paperId": null, "title": "markup tokens enable extrapolation in large language models"}, {"paperId": null, "title": "2023. How long can open-source llms truly promise on context length?"}, {"paperId": null, "title": "2024. Transformers are multi-state rnns"}, {"paperId": null, "title": "2024d. H2o: Heavy-hitter oracle for efficient generative inference of large language models"}, {"paperId": null, "title": "2023b. Lon-glora: Efficient fine-tuning of long-context large language models"}, {"paperId": null, "title": "2023. Boosting llm reasoning: Push the limits of few-shot learning with reinforced in-context pruning"}, {"paperId": null, "title": "2022. A length-extrapolatable transformer"}, {"paperId": null, "title": "2023. Focused transformer: Con-trastive training for context scaling"}, {"paperId": null, "title": "2024. Longwan-juan: Towards systematic measurement for long text quality"}, {"paperId": null, "title": "2024. Bge landmark embedding: A chunking-free embedding method for retrieval augmented long-context large language models"}, {"paperId": null, "title": "2024. Novelqa: A benchmark for long-range novel question answering"}]}