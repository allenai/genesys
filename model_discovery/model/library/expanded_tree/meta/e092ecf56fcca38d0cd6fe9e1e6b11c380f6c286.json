{"paperId": "e092ecf56fcca38d0cd6fe9e1e6b11c380f6c286", "abstract": "Contextual embeddings, such as ELMo and BERT, move beyond global word representations like Word2Vec and achieve ground-breaking performance on a wide range of natural language processing tasks. Contextual embeddings assign each word a representation based on its context, thereby capturing uses of words across varied contexts and encoding knowledge that transfers across languages. In this survey, we review existing contextual embedding models, cross-lingual polyglot pre-training, the application of contextual embeddings in downstream tasks, model compression, and model analyses.", "venue": "arXiv.org", "year": 2020, "citationCount": 131, "influentialCitationCount": 8, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "In this survey, existing contextual embedding models, cross-lingual polyglot pre-training, the application of contextual embeddings in downstream tasks, model compression, and model analyses are reviewed."}, "embedding": {"model": "specter_v2", "vector": [-0.23237347602844238, 0.07233411073684692, -0.6420186758041382, -0.31399789452552795, -0.21677331626415253, -0.14938710629940033, 0.6533389091491699, 0.11879371851682663, -0.7671729326248169, -0.22286579012870789, 1.2099934816360474, 0.1369655877351761, 0.565991997718811, 0.12026026099920273, 0.038213469088077545, -0.11766879260540009, -0.7748218774795532, 0.02134401723742485, -0.1916808784008026, -0.43583378195762634, -0.34920868277549744, -0.9500863552093506, -0.6878969073295593, 0.321643590927124, 0.012143658474087715, 0.1742226630449295, 0.41581109166145325, 0.8232915997505188, -0.6526246666908264, -0.22425857186317444, 0.49760445952415466, -0.3510602116584778, 0.1468077301979065, -0.06935866177082062, 0.18345819413661957, -0.5044648051261902, 0.30265286564826965, -0.5421068072319031, -0.5445989966392517, 0.5504208207130432, -0.18669532239437103, 0.37919241189956665, 0.5860150456428528, -0.3912617564201355, -0.5609790086746216, 0.9837339520454407, 0.9015268683433533, 0.44366171956062317, -0.10370361059904099, -0.7674363255500793, 2.0297327041625977, -1.5077446699142456, 0.518310010433197, 1.2771319150924683, 0.6008812189102173, 0.2446112334728241, -0.7275745272636414, -0.25400468707084656, 0.7612237930297852, 0.5141751170158386, -0.6038139462471008, -0.17340824007987976, 0.21485759317874908, 0.02441515401005745, 2.001142978668213, -0.39173904061317444, 0.5205717086791992, 0.8530676960945129, 0.01296409871429205, 1.3015061616897583, 0.1450548768043518, -1.2198458909988403, -0.3455449342727661, 0.2707723379135132, 0.854403018951416, 0.4501398205757141, -0.3149682581424713, 0.48728859424591064, -0.8287961483001709, -0.05786857381463051, 0.1466829776763916, 0.15695436298847198, 0.10563124716281891, 0.08088453859090805, -0.5545296669006348, 0.8234421610832214, 0.47097131609916687, 0.9351356029510498, -0.2831595540046692, 1.0288010835647583, 0.5197361707687378, 0.03384527564048767, -0.3002703785896301, 0.28591474890708923, -0.2828198969364166, 0.2624375820159912, -0.7364239692687988, 0.2863747477531433, 0.035334233194589615, 0.6394678950309753, 0.15894950926303864, 0.137840136885643, -0.5256087183952332, 0.2579943835735321, 1.519095778465271, 0.0431227907538414, 0.683689534664154, -0.5164850354194641, -0.06427232921123505, -0.501348614692688, 0.019315799698233604, -1.192968726158142, 0.017186645418405533, -0.013159160502254963, -0.14861233532428741, -1.518203854560852, -0.7012804746627808, 0.07822080701589584, -0.40440845489501953, 0.9943339824676514, -0.1550002098083496, 0.2889673113822937, 0.07289797812700272, 0.3509890139102936, 0.4044196605682373, 0.8872307538986206, 0.47452157735824585, 0.4083821475505829, 1.1080596446990967, -0.7591909766197205, -1.0208755731582642, -1.3747001886367798, 1.058489203453064, -0.2467697560787201, 0.34456732869148254, -0.4756307601928711, -0.4841351807117462, -0.9455618858337402, -1.1826738119125366, -0.05961187183856964, -1.2512693405151367, 0.5303521752357483, 0.9817437529563904, 0.8077906370162964, -0.6793692708015442, 0.6998921632766724, -0.6580834984779358, -0.13455121219158173, -0.04727184772491455, -0.044845547527074814, 0.045451875776052475, -0.45263245701789856, -1.6864824295043945, 0.5721886157989502, 0.6942139267921448, -0.48368754982948303, -0.18478263914585114, -0.35161274671554565, -1.7493830919265747, -0.38643720746040344, -0.007517398800700903, -0.1626124531030655, 0.5914115309715271, 0.11104006320238113, -1.0687469244003296, 0.3933122754096985, -0.6765182614326477, 0.2782539129257202, -0.3104976713657379, -0.6756113767623901, -0.9912312626838684, -0.6974928975105286, -0.015598340891301632, 0.34403008222579956, 0.21926292777061462, -0.35048893094062805, 0.22710491716861725, -0.13666808605194092, -0.5632547736167908, 0.03656109422445297, -0.7843848466873169, 0.8065587282180786, -0.18079347908496857, -0.5124727487564087, 0.012579863891005516, 0.7876424789428711, 0.029602764174342155, -0.48169875144958496, -0.3333956003189087, -0.7248604893684387, 0.8887596130371094, -0.10448487102985382, 1.463690996170044, -1.0630439519882202, -0.6545860171318054, -0.15102067589759827, -0.3726934492588043, -0.09653864055871964, -1.1735113859176636, 1.055519938468933, -0.4042291045188904, 0.35377001762390137, 0.032036613672971725, -1.4967385530471802, 0.3972811698913574, 0.16908232867717743, -0.6055246591567993, -0.31407445669174194, -0.10792393237352371, 1.088089108467102, -0.8783122897148132, 0.0366898849606514, 0.31069934368133545, 0.65365070104599, -0.9509428143501282, 0.9232684373855591, -0.29690122604370117, -0.44382086396217346, 0.06914930045604706, -0.31052470207214355, -0.10562857985496521, 0.040486495941877365, 0.6994457244873047, -0.38133084774017334, 0.2142050564289093, 0.8055181503295898, -0.9532032012939453, 1.2785358428955078, -0.49409720301628113, 0.6956988573074341, -0.21623776853084564, -0.33901965618133545, 0.025368409231305122, 0.3355904221534729, -0.294600248336792, -0.12710922956466675, 0.21753159165382385, 0.5747592449188232, -0.9654449224472046, 0.26377540826797485, 1.1807860136032104, 0.5898988842964172, -0.3775239586830139, 0.2813396751880646, 0.4795229732990265, -0.1734151989221573, 0.24366213381290436, 0.38227537274360657, 0.6571410894393921, 0.6925213932991028, 0.7104775905609131, -0.08273206651210785, 0.025426477193832397, -0.7703116536140442, 0.05450032651424408, -0.06509410589933395, 0.5575737357139587, 0.5086408853530884, 0.35137560963630676, -0.5567411780357361, -0.2446703463792801, 0.03586214408278465, 0.47145387530326843, 1.5251905918121338, -0.10202339291572571, -1.0890463590621948, -0.4234035313129425, -0.5781662464141846, -0.15803280472755432, 0.5254127979278564, -0.7159101963043213, -0.19805270433425903, -0.8084533214569092, -1.0150775909423828, 0.3801766633987427, 0.8034897446632385, 0.5550298094749451, -0.6898854970932007, -0.30010986328125, -0.15003275871276855, 0.15807487070560455, -0.810583233833313, -0.6551638841629028, 0.6929210424423218, -0.361334890127182, -0.08302178233861923, 0.6259244680404663, -0.19372975826263428, 0.021981624886393547, -0.7259512543678284, 1.2598007917404175, -0.39812371134757996, -0.2767782211303711, 0.00999743677675724, 0.08188153803348541, -0.3045033812522888, -0.10676207393407822, 0.25672996044158936, 0.30054551362991333, -0.3238089978694916, 0.9637775421142578, 0.6317049860954285, -0.12425746023654938, 0.09089265763759613, -0.498715877532959, -0.05356054753065109, -0.29692453145980835, 0.458678275346756, 0.7886126041412354, -0.1342972368001938, 0.19673052430152893, -1.0990115404129028, 0.5694151520729065, -0.07622085511684418, -0.06217694655060768, -0.03449416533112526, -0.4896319508552551, -0.5149111747741699, 0.5908033847808838, -0.4963715076446533, -0.12223262339830399, -0.7338841557502747, 0.3351496458053589, 0.11924194544553757, -0.3286617398262024, 0.6193079948425293, -0.12406592071056366, 0.7546728253364563, 0.35853487253189087, 0.17606225609779358, -0.1343708336353302, 0.0035543134436011314, 0.94634610414505, -0.632148265838623, 0.1182236298918724, 0.18924593925476074, -0.040843408554792404, -0.43407759070396423, -0.3190818428993225, -0.902787983417511, -0.17574086785316467, -0.4920286238193512, -0.5037369728088379, -0.13978035748004913, 0.42691195011138916, -0.4198036789894104, -0.19611415266990662, -0.4119327962398529, -1.0604203939437866, -0.10647238790988922, 0.24974168837070465, -0.25110724568367004, 0.0020192107185721397, -1.0165667533874512, -0.9447658658027649, -0.505882740020752, -0.030534280464053154, -0.9658676981925964, 0.5755879282951355, -0.17700231075286865, -0.5604387521743774, -1.3688421249389648, 0.32444390654563904, -0.5521553754806519, 0.8980888724327087, -0.04052702337503433, 0.914254903793335, -0.14279165863990784, 0.04000610485672951, -0.7060047388076782, 0.5543569326400757, 0.8902892470359802, 0.030374890193343163, 0.32330450415611267, -0.7597562074661255, 0.28378406167030334, -0.30825066566467285, -0.19766183197498322, 0.13480766117572784, 0.24265539646148682, 0.2893127202987671, 0.10198232531547546, -0.8661624193191528, 0.42925727367401123, 1.7653833627700806, -0.7367624640464783, -0.051912643015384674, 0.057274606078863144, 0.8138847947120667, 0.16310259699821472, -0.1451776921749115, 0.34483909606933594, 0.4139814078807831, 0.5538060665130615, 0.17343120276927948, 0.2956286072731018, -0.14339643716812134, -0.8518025279045105, 0.8581460118293762, 1.8586640357971191, 0.5709258913993835, 0.051856741309165955, -1.12443208694458, 1.1281343698501587, -1.261892318725586, -0.37044137716293335, 0.572222113609314, 0.6195187568664551, 0.5342235565185547, -0.7357453107833862, -0.44497907161712646, -0.23286883533000946, 0.44883790612220764, 0.7900140285491943, -0.23090015351772308, -0.5306569337844849, -0.15122941136360168, 0.5561538338661194, 0.043791960924863815, 0.8981319069862366, -0.6812043786048889, 0.8249513506889343, 14.44564437866211, 0.7196922898292542, 0.36895784735679626, 0.4022683799266815, 0.5148602724075317, 0.22591693699359894, -0.7047539949417114, -0.009343811310827732, -1.5821539163589478, 0.13426436483860016, 1.326216697692871, 0.5673589110374451, 0.3561434745788574, 0.16583724319934845, -0.2136237919330597, 0.24793130159378052, -1.0020725727081299, 0.4441107511520386, 0.7439273595809937, -0.895732045173645, 0.15929777920246124, 0.22450228035449982, 0.3611195385456085, 0.31220555305480957, 0.9053163528442383, 0.717557966709137, 0.6804209351539612, -0.5500848293304443, 0.25432088971138, 0.18197251856327057, 0.8912603855133057, -0.18951261043548584, 0.6466954946517944, 0.29361408948898315, -1.0927956104278564, -0.21656259894371033, -0.837133526802063, -0.9403329491615295, 0.34095433354377747, 0.10050056129693985, -0.29129108786582947, -0.36656808853149414, -0.4541178345680237, 1.3172192573547363, -0.07930666208267212, -0.197272390127182, -0.49752965569496155, 0.5019434094429016, -0.09858202189207077, -0.3250184655189514, 0.625231146812439, 0.2405032366514206, 0.3354921340942383, 0.5569546222686768, 0.0848618671298027, 0.035311076790094376, 0.08303853869438171, 0.16452820599079132, -0.263305127620697, 0.4071691036224365, -0.6077991127967834, -0.6994367241859436, -0.02715650014579296, 0.8708177804946899, 0.6387384533882141, 0.2619127929210663, -0.4862944185733795, 0.42624929547309875, 0.3762074112892151, 0.2912181317806244, -0.3507055342197418, -0.396022766828537, 0.713153064250946, -0.3707886338233948, -0.008577738888561726, 0.21978788077831268, -0.4158894121646881, -0.4912475645542145, -0.6952243447303772, 0.019061265513300896, 0.40383380651474, -0.6682795882225037, -1.0272331237792969, 0.8940953612327576, -0.3536675274372101, -0.37258604168891907, -0.14926645159721375, -1.6093305349349976, -0.07256559282541275, 0.4318941533565521, -1.41668701171875, -0.46859753131866455, 0.23777741193771362, -0.3510269522666931, -0.6629340648651123, -0.186113178730011, 1.6780798435211182, 0.011828401125967503, -0.36413389444351196, 0.01713981106877327, 0.3259755074977875, 0.11953846365213394, 0.21161557734012604, -1.250669240951538, 0.7010670304298401, 0.27072256803512573, 0.21752791106700897, 0.664571225643158, -0.05358783155679703, -0.1192803755402565, -0.607965350151062, -0.1578991562128067, 0.9431513547897339, -1.1907939910888672, -0.20585794746875763, -0.8284541964530945, -0.6120949387550354, 0.5298640131950378, 0.9784661531448364, -0.27169743180274963, 1.197346806526184, 0.3902323246002197, -0.7853406071662903, -0.04086397588253021, -0.5905970931053162, 0.5500856637954712, 0.35563650727272034, -0.702264130115509, -0.6698834896087646, -0.10146194696426392, 0.27160313725471497, -0.3757840096950531, -0.5391554832458496, -0.24406521022319794, 0.10009165853261948, -0.03951770067214966, 1.2264163494110107, -0.7894287109375, 1.1664862632751465, 0.7161963582038879, -0.89459228515625, -1.3835816383361816, -0.04344125837087631, -0.6676324605941772, -0.22197888791561127, 0.003702871035784483, 0.8204595446586609, -0.2180870622396469, 0.12698671221733093, 0.7511377334594727, 0.2616501450538635, -0.7231110334396362, -0.4344174265861511, -0.29886654019355774, 0.20233900845050812, -0.647724986076355, 0.46703484654426575, 0.18452855944633484, 0.18406660854816437, 0.11902123689651489, 0.4768448770046234, 0.35982298851013184, -0.3076764643192291, -0.8429334759712219, 0.11075973510742188, 0.3751792907714844, -0.15304073691368103, -0.6137245893478394, -0.7860215306282043, -1.3089455366134644, 0.3752080500125885, -1.3944398164749146, -0.09868470579385757, -1.0478401184082031, -0.6060889959335327, 0.1957755982875824, -0.5672434568405151, 0.259565144777298, -0.23191741108894348, -0.14991037547588348, -0.5256699919700623, -0.9859908819198608, -0.3326772451400757, 0.8055056929588318, 0.6453741788864136, -0.3517046868801117, 0.1816622018814087, -0.5320523381233215, 0.07231679558753967, 0.255501925945282, 0.42808547616004944, -0.15628467500209808, -0.584074854850769, -1.6699591875076294, 0.5701237320899963, -0.5212828516960144, -0.18770137429237366, -0.20142626762390137, 0.5157403349876404, 0.4187357723712921, 0.21269738674163818, -0.03588356450200081, 0.7918482422828674, -1.226149559020996, -0.43078556656837463, 0.03589657321572304, -0.7402986884117126, 0.5265007019042969, -0.02731706202030182, -0.06525979936122894, -0.5494216680526733, 0.6213211417198181, -0.16530168056488037, -0.7940791249275208, -0.7838125824928284, 0.20882868766784668, -0.4049662947654724, 0.000760708178859204, 0.03312830626964569, -0.3551424741744995, -1.195976972579956, -0.2475573569536209, -0.12877054512500763, 0.23809510469436646, -0.2593173384666443, 0.8550610542297363, 0.6020461320877075, -1.7848292589187622, 0.1705138385295868, 0.5689303874969482, 0.23670397698879242, -0.5421982407569885, 0.18907111883163452, 0.09643828868865967, -0.25486990809440613, 0.48964881896972656, 0.3537138104438782, 0.3762750029563904, -0.8775879740715027, -0.10209628939628601, 0.457325279712677, -0.214326873421669, -0.25164520740509033, 0.9411805272102356, -0.5211102366447449, -0.9792830944061279, -0.12197832018136978, -1.0196658372879028, -0.53666090965271, 0.07297447323799133, 0.7412309646606445, 0.269221693277359, -0.19926664233207703, -0.3489130437374115, -0.42063605785369873, 0.37972262501716614, -0.09989763796329498, -0.6176310777664185, 0.9639447331428528, 0.10254748910665512, -0.543608546257019, 0.8844666481018066, 1.210753321647644, -0.5833370685577393, -0.7187989354133606, -0.7634377479553223, -0.3706849217414856, -0.7597399950027466, 0.428779274225235, -0.5884463787078857, -0.48745372891426086, 0.7634496688842773, 0.21655796468257904, 0.4770828187465668, 0.1277676820755005, -0.2788701355457306, 0.4908992350101471, 0.6077808737754822, -0.17959867417812347, -0.9645041823387146, -0.43765202164649963, 1.626917839050293, 1.209428071975708, -0.7615447044372559, 0.186942458152771, 0.00041444881935603917, -0.663998544216156, 0.9029097557067871, 0.12345874309539795, -0.15485015511512756, 1.5363978147506714, -0.0956215038895607, 0.1685616374015808, 0.30733874440193176, -1.0098567008972168, 0.11168413609266281, 0.7819384932518005, 1.1017553806304932, 0.8619534373283386, 0.79623943567276, -0.011750278994441032, 1.1185989379882812, -0.15901800990104675, -0.6263535618782043, 0.24280376732349396, 0.4363383650779724, -0.04286731779575348, -0.5690094828605652, 0.2541303336620331, 0.4321790039539337, -0.39578577876091003, -0.7989490032196045, -0.13770133256912231, 0.6698696613311768, 0.15528370440006256, 0.53770512342453, 0.5571696758270264, -0.01994095928966999, 0.2286701202392578, 0.6862248182296753, 0.08103486895561218, -0.7171645760536194, -0.3464367687702179, -0.2247667759656906, -0.3232336938381195, -0.23213639855384827, -0.2813152074813843, -0.6601274013519287, -0.17252708971500397, -0.07445879280567169, 0.4586627781391144, -0.32797855138778687, 0.8150453567504883, 0.9677911400794983, 0.6167870759963989, 0.3202618360519409, -0.4610503315925598, -0.16088970005512238, -0.1202772706747055, -1.0184885263442993, -0.23858138918876648, -0.5711571574211121, -0.1889251470565796, -0.23684729635715485, -0.23863159120082855, -0.38122689723968506]}, "authors": [{"authorId": "11149237", "name": "Qi Liu"}, {"authorId": "1940272", "name": "Matt J. Kusner"}, {"authorId": "1685771", "name": "Phil Blunsom"}], "references": [{"paperId": "6191a5122d67dfbab421bc89540d264822dd8173", "title": "ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation"}, {"paperId": "6fec3e579c7cd4f13bdabbee2b6ac2e8ff5941c6", "title": "Unsupervised Cross-lingual Representation Learning at Scale"}, {"paperId": "cfe8ec7a183ed548db1a862e38908343cefb94c7", "title": "Emerging Cross-lingual Structure in Pretrained Language Models"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "9e9d919c1de684ca42c8b581ec62c7aa685f431e", "title": "On the Cross-lingual Transferability of Monolingual Representations"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"}, {"paperId": "75acc731bdd2b626edc74672a30da3bc51010ae8", "title": "CTRL: A Conditional Transformer Language Model for Controllable Generation"}, {"paperId": "199ff73d2f728e997f860b62a2322823d3e3d9e8", "title": "Designing and Interpreting Probes with Control Tasks"}, {"paperId": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf", "title": "Patient Knowledge Distillation for BERT Model Compression"}, {"paperId": "d78aed1dac6656affa4a04cbf225ced11a83d103", "title": "Revealing the Dark Secrets of BERT"}, {"paperId": "33b0a849138062b3806bc72f9769bc8dfe434193", "title": "Universal Adversarial Triggers for NLP"}, {"paperId": "3caf34532597683c980134579b156cd0d7db2f40", "title": "Universal Adversarial Triggers for Attacking and Analyzing NLP"}, {"paperId": "d56c1fc337fb07ec004dc846f80582c327af717c", "title": "StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding"}, {"paperId": "d3cacb4806886eb2fe59c90d4b6f822c24ff1822", "title": "Visualizing and Understanding the Effectiveness of BERT"}, {"paperId": "80f9f109d1564cb8f82aa440a5f6f3fbe220c9ef", "title": "ERNIE 2.0: A Continual Pre-training Framework for Language Understanding"}, {"paperId": "335613303ebc5eac98de757ed02a56377d99e03a", "title": "What Does BERT Learn about the Structure of Language?"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "81f5810fbbab9b7203b9556f4ce3c741875407bc", "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "afd110eace912c2b273e64851c6b4df2658622eb", "title": "Visualizing and Measuring the Geometry of BERT"}, {"paperId": "94e43de5dca9355a60a225565aa26bd1cc065c3e", "title": "Episodic Memory in Lifelong Language Learning"}, {"paperId": "455a8838cde44f288d456d01c76ede95b56dc675", "title": "A Structural Probe for Finding Syntax in Word Representations"}, {"paperId": "ad7129af0644dbcafa9aa2f111cb76526ea444a1", "title": "Defending Against Neural Fake News"}, {"paperId": "5f994dc8cae24ca9d1ed629e517fcc652660ddde", "title": "ERNIE: Enhanced Language Representation with Informative Entities"}, {"paperId": "e2587eddd57bc4ba286d91b27c185083f16f40ee", "title": "What do you learn from context? Probing for sentence structure in contextualized word representations"}, {"paperId": "97906df07855b029b7aae7c2a1c6c5e8df1d531c", "title": "BERT Rediscovers the Classical NLP Pipeline"}, {"paperId": "1c71771c701aadfd72c5866170a9f5d71464bb88", "title": "Unified Language Model Pre-training for Natural Language Understanding and Generation"}, {"paperId": "145b8b5d99a2beba6029418ca043585b90138d12", "title": "MASS: Masked Sequence to Sequence Pre-training for Language Generation"}, {"paperId": "031e4e43aaffd7a479738dcea69a2d5be7957aa3", "title": "ERNIE: Enhanced Representation through Knowledge Integration"}, {"paperId": "a08293b2c9c5bcddb023cc7eb3354d4d86bfae89", "title": "Distilling Task-Specific Knowledge from BERT into Simple Neural Networks"}, {"paperId": "f6fbb6809374ca57205bd2cf1421d4f4fa04f975", "title": "Linguistic Knowledge and Transferability of Contextual Representations"}, {"paperId": "578e050d6e007797d032a07e712142035f2666dc", "title": "An Embarrassingly Simple Approach for Transfer Learning from Pretrained Language Models"}, {"paperId": "06979d126d8286866624f20907e57e8e8aa7df52", "title": "Polyglot Contextual Representations Improve Crosslingual Transfer"}, {"paperId": "658721bc13b0fa97366d38c05a96bf0a9f4bb0ac", "title": "Multi-Task Deep Neural Networks for Natural Language Understanding"}, {"paperId": "ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc", "title": "Cross-lingual Language Model Pretraining"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "06a1bf4a7333bbc78dbd7470666b33bd9e26882b", "title": "Can You Tell Me How to Get Past Sesame Street? Sentence-Level Pretraining Beyond Language Modeling"}, {"paperId": "160563abbd75265b19afc8b4169bab9e1eb33d97", "title": "Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond"}, {"paperId": "990a7b4eceedb6e053e6386269481bdfc42a1094", "title": "CoQA: A Conversational Question Answering Challenge"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "afc2850945a871e72c245818f9bc141bd659b453", "title": "Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "8dd85e38445a5ddb5dd71cabc3c4246de30c014f", "title": "A Survey of Model Compression and Acceleration for Deep Neural Networks"}, {"paperId": "bc8fa64625d9189f5801837e7b133e7fe3c581f7", "title": "Learned in Translation: Contextualized Word Vectors"}, {"paperId": "2a8b6f990a5ddf0122aae82a46359b03031f302b", "title": "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm"}, {"paperId": "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096", "title": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "4c16a6fd7b4aad8c1331e4753b30701fdf6d12f4", "title": "Neural Domain Adaptation for Biomedical Question Answering"}, {"paperId": "d89ee98810039d2061ed42ee8026da49c503d16b", "title": "Learning multiple visual domains with residual adapters"}, {"paperId": "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c", "title": "Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"}, {"paperId": "2e55ba6c97ce5eb55abd959909403fe8da7e9fe9", "title": "Overcoming catastrophic forgetting in neural networks"}, {"paperId": "85f94d8098322f8130512b4c6c4627548ce4a6cc", "title": "Unsupervised Pretraining for Sequence to Sequence Learning"}, {"paperId": "5ed791f810da580c78df6a052c6b9f2e258f6b0a", "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context"}, {"paperId": "3cccc93064dae265eeb7bc76d02cdc67c942f0a5", "title": "Neural Autoregressive Distribution Estimation"}, {"paperId": "2f2d8f8072e5cc9b296fad551f65f183bdbff7aa", "title": "Exploring the Limits of Language Modeling"}, {"paperId": "35b91b365ceb016fb3e022577cec96fb9b445dc5", "title": "The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations"}, {"paperId": "4aa9f5150b46320f534de4747a2dd0cd7f3fe292", "title": "Semi-supervised Sequence Learning"}, {"paperId": "2846e83d405cbe3bf2f0f3b5f635dd8b3c680c45", "title": "Reasoning about Entailment with Neural Attention"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "6e795c6e9916174ae12349f5dc3f516570c17ce8", "title": "Skip-Thought Vectors"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "7340f090f8a0df5b109682e9f6d57e4b8ca1a2f7", "title": "Learning Transferable Features with Deep Adaptation Networks"}, {"paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "title": "GloVe: Global Vectors for Word Representation"}, {"paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09", "title": "Efficient Estimation of Word Representations in Vector Space"}, {"paperId": "8492070dc4031ed825e95e4803781752bb5e909f", "title": "Word Representations: A Simple and General Method for Semi-Supervised Learning"}, {"paperId": "8978cf7574ceb35f4c3096be768c7547b28a35d0", "title": "A Fast Learning Algorithm for Deep Belief Nets"}, {"paperId": "6c2b28f9354f667cd5bd07afc0471d8334430da7", "title": "A Neural Probabilistic Language Model"}, {"paperId": "ce9a21b93ba29d4145a8ef6bf401e77f261848de", "title": "A Learning Algorithm for Continually Running Fully Recurrent Neural Networks"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Electra: Pre-training text encoders as discriminators rather than generators"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Bert and pals: Projected attention layers for efficient adaptation in multi-task learning"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "c213af6582c0d518a6e8e14217611c733eeb1ef1", "title": "Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem"}, {"paperId": "decd9bc0385612bdf936928206d83730718e737e", "title": "Distributional Structure"}]}