{"paperId": "5616cd91c5134d3ceaa578fd3c5521aed20c8f82", "abstract": "Transformer-based large language models (LLM) have been widely used in language processing applications. However, most of them restrict the context window that permits the model to attend to every token in the inputs. Previous works in recurrent models can memorize past tokens to enable unlimited context and maintain effectiveness. However, they have\"flat\"memory architectures, which have limitations in selecting and filtering information. Since humans are good at learning and self-adjustment, we speculate that imitating brain memory hierarchy is beneficial for model memorization. We propose the Hierarchical Memory Transformer (HMT), a novel framework that enables and improves models' long-context processing ability by imitating human memorization behavior. Leveraging memory-augmented segment-level recurrence, we organize the memory hierarchy by preserving tokens from early input token segments, passing memory embeddings along the sequence, and recalling relevant information from history. Evaluating general language modeling (Wikitext-103, PG-19) and question-answering tasks (PubMedQA), we show that HMT steadily improves the long-context processing ability of context-constrained and long-context models. With an additional 0.5% - 2% of parameters, HMT can easily plug in and augment future LLMs to handle long context effectively. Our code is open-sourced on Github: https://github.com/OswaldHe/HMT-pytorch.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The Hierarchical Memory Transformer is proposed, a novel framework that enables and improves models' long-context processing ability by imitating human memorization behavior and steadily improves the long-context processing ability of context-constrained and long-context models."}, "embedding": {"model": "specter_v2", "vector": [-0.0022329234052449465, 0.4369933009147644, -0.08016319572925568, -0.13455303013324738, -0.26857566833496094, -0.020433390513062477, 0.965867817401886, 0.030919523909687996, -0.8107755780220032, -0.27963143587112427, 0.7897766828536987, -0.2358824759721756, 0.4936197102069855, 0.07488266378641129, -0.012127641588449478, -0.003808450885117054, -1.0387187004089355, 0.14181995391845703, 0.10234523564577103, -0.09876980632543564, 0.1458195447921753, -0.5170179605484009, -0.8694800734519958, 0.2781507074832916, 0.18789677321910858, 0.3038969337940216, 0.5570235848426819, 0.8874370455741882, -0.2524406909942627, 0.7974246740341187, 0.8476423025131226, -0.19598110020160675, -0.07204905152320862, -0.04663378745317459, -0.7022637128829956, -0.2707717716693878, 0.16802851855754852, -0.23860450088977814, -0.6229019165039062, 0.22377820312976837, -0.1598927080631256, 0.5364035964012146, 0.21550104022026062, -0.09628842771053314, -0.11956293135881424, 1.0320204496383667, 0.6775030493736267, 0.8336578011512756, -0.3840731084346771, -0.872267484664917, 1.3590086698532104, -1.7481886148452759, 0.4354761838912964, 1.1928082704544067, 0.4895504117012024, 0.4955344498157501, -0.09084422141313553, -0.5801556706428528, 1.22671639919281, 0.1585756242275238, -0.8804765343666077, -0.36839860677719116, -0.06644105166196823, -0.032403867691755295, 2.1229279041290283, -0.40718159079551697, 0.49368762969970703, 0.5573354363441467, 0.4148489236831665, 1.5210238695144653, -0.0011725916992872953, -0.7848852276802063, -0.5949776768684387, 0.018267707899212837, 0.8513087034225464, 0.957208514213562, -0.4704746603965759, 0.6482624411582947, -0.9020649194717407, -0.0893002450466156, 0.6793113350868225, 0.09508147090673447, 0.015489072538912296, 0.2014300674200058, -0.4897701144218445, 0.6438999176025391, 0.4642360210418701, 1.1647847890853882, -0.29725366830825806, 0.4041691720485687, 0.19032275676727295, 0.3539125919342041, 0.14315512776374817, 0.29759395122528076, -0.0949445366859436, 0.6185961365699768, -1.068028211593628, 0.38563042879104614, -0.20197708904743195, 0.661873996257782, 0.2047477662563324, 0.06934899836778641, -0.7568277716636658, 0.45639029145240784, 1.4890328645706177, -0.24729755520820618, 0.8819154500961304, -0.4302278459072113, -0.12863323092460632, -0.7408084273338318, 0.04145956039428711, -0.49420103430747986, -0.47909194231033325, -0.5884411334991455, -0.5133156180381775, -1.5916897058486938, -0.5556756258010864, 0.5129393935203552, -0.6480832695960999, 0.9393249154090881, -0.16962622106075287, 0.3768669366836548, -0.014214842580258846, 0.18828259408473969, 0.4114876687526703, 0.5889995694160461, 0.6242029070854187, -0.11456464231014252, 0.982562780380249, -1.0379363298416138, -0.5770906805992126, -1.3392895460128784, 0.8184514045715332, 0.017139732837677002, 0.23318469524383545, -0.4307756721973419, -1.2670421600341797, -1.023890495300293, -0.9318494200706482, -0.18112950026988983, -0.6910062432289124, -0.1893400251865387, 1.0358242988586426, 0.09533797949552536, -1.0438772439956665, 0.9005916118621826, -0.3006184995174408, -0.21802248060703278, -0.019910361617803574, -0.15462589263916016, 0.25585949420928955, -0.4844418168067932, -1.5669853687286377, 0.49080583453178406, 0.2139088213443756, -0.10013669729232788, -0.38124310970306396, -0.5642799139022827, -1.1148368120193481, -0.05735838785767555, 0.1881445348262787, -0.6868801116943359, 1.3485463857650757, 0.05074058845639229, -0.8904444575309753, 0.8268409371376038, -0.6469119191169739, -0.053771864622831345, 0.0238425862044096, -0.2511884868144989, -0.6031859517097473, -0.4897831082344055, -0.2820848822593689, 0.3501240611076355, 0.28003278374671936, -0.17936690151691437, -0.3237043023109436, -0.34911611676216125, -0.7047798037528992, 0.024096855893731117, 0.16244728863239288, 0.6552395820617676, -0.1690083146095276, -0.3005918860435486, 0.26447367668151855, 0.566909909248352, -0.09485018253326416, -0.7113304734230042, 0.17215730249881744, -1.1356595754623413, 0.29031607508659363, -0.10292930901050568, 1.4915940761566162, -0.8127109408378601, -1.0666860342025757, -0.098074771463871, -0.07740729302167892, -0.21005845069885254, -0.9039212465286255, 0.6447996497154236, -0.348769873380661, 0.34307271242141724, -0.2004653960466385, -1.1910691261291504, 0.053828220814466476, -0.16602662205696106, -0.87807697057724, -0.3352959454059601, 0.12623119354248047, 1.2357345819473267, -1.1417595148086548, -0.1643488109111786, -0.23096846044063568, 0.34138184785842896, -0.7689099907875061, 1.3598228693008423, -0.317452609539032, 0.0565047524869442, 0.15278199315071106, -0.45704200863838196, -0.09011265635490417, -0.4665971100330353, 0.3354061245918274, 0.018392950296401978, -0.382875919342041, 0.6854909062385559, -0.31203824281692505, 1.112131953239441, -0.4331301152706146, 0.5695817470550537, -0.23400092124938965, -0.2997145354747772, -0.1192699745297432, 0.299001544713974, -0.416836142539978, -0.6073509454727173, 0.03619399666786194, 0.2111484855413437, -0.8374526500701904, 0.3624279797077179, 1.1231106519699097, 0.432929128408432, -0.36377838253974915, 0.2763332426548004, 0.38528817892074585, -0.02781570516526699, 0.3660351037979126, 0.47178590297698975, 0.4462420344352722, 0.19491250813007355, 0.3396533727645874, -0.030493438243865967, 0.10938621312379837, -1.1115025281906128, 0.034964852035045624, 0.7140958905220032, 0.7165022492408752, 0.709351658821106, 0.13968949019908905, -0.5509458780288696, -0.18588405847549438, -0.0047544254921376705, 0.42138099670410156, 1.6684925556182861, -0.4956609904766083, -0.24435581266880035, -0.5341569781303406, 0.19857095181941986, -0.5975438952445984, 0.28884387016296387, -0.6040213704109192, -0.3149881362915039, -0.8030669689178467, -0.9089058041572571, 0.6921585202217102, 0.400145947933197, 1.1084970235824585, -0.9855697751045227, -0.3602136969566345, 0.014586484991014004, 0.2655490040779114, -0.5991437435150146, -0.8541290760040283, 0.20749257504940033, -0.8470472693443298, -0.08220256865024567, 0.03945918753743172, -0.3806593120098114, -0.10741005837917328, -0.4382893145084381, 1.3101119995117188, -0.08398836106061935, -0.26545295119285583, 0.5325099229812622, 0.7378697395324707, -0.29326194524765015, -0.4776380658149719, 0.13805101811885834, 0.11524376273155212, -0.11345494538545609, 0.13549430668354034, 0.7545678615570068, -0.45178353786468506, -0.09361822158098221, -0.5104207396507263, 0.2056017518043518, 0.24901390075683594, 0.33390510082244873, 0.8100820183753967, -0.23403194546699524, 0.2335338592529297, -1.3859338760375977, 0.8362798094749451, 0.10457383096218109, -0.20541740953922272, 0.6676747798919678, -1.0371670722961426, -0.295095831155777, 0.06886915117502213, -0.6969742774963379, -0.41020268201828003, -1.2652560472488403, 0.47975999116897583, -0.06238425895571709, 0.10869105160236359, 0.5235631465911865, 0.31065401434898376, 0.5717692375183105, -0.13984154164791107, 0.5596098303794861, 0.040443334728479385, -0.010108993388712406, 0.4233608543872833, -0.8909938931465149, 0.32957059144973755, 0.42392879724502563, -0.2472555935382843, -0.449638307094574, -0.3293951451778412, -0.9793111085891724, -0.5155763626098633, -0.5895078182220459, -0.11051313579082489, -0.2217101752758026, -0.032848525792360306, -0.6098499298095703, -0.8534711599349976, 0.2527994215488434, -0.7987741231918335, -0.6465216279029846, 0.3381029963493347, -0.3140517473220825, -0.07161906361579895, -1.0618789196014404, -1.468632698059082, -0.6719968914985657, -0.6056895852088928, -0.35146334767341614, 0.04123643785715103, 0.013473095372319221, -0.4045131206512451, -1.0118077993392944, 0.20862272381782532, -0.37768444418907166, 1.081125259399414, -0.7614443302154541, 0.958723247051239, 0.12279185652732849, -0.4878745377063751, -0.12258686870336533, 0.24580714106559753, 0.37791478633880615, -0.4651005268096924, -0.01354920957237482, -1.0028791427612305, 0.010477414354681969, -0.08006621897220612, 0.1347983330488205, 0.6087169051170349, 0.21407122910022736, 0.5906226634979248, -0.021335117518901825, -0.7560678124427795, -0.1297600120306015, 1.1862536668777466, -0.6350485682487488, 0.2528018355369568, 0.0014475843636319041, 0.6127451658248901, 0.23577629029750824, -0.11602192372083664, 0.3200702667236328, 0.5797732472419739, -0.1609075516462326, -0.20196665823459625, -0.04836036637425423, -0.05914833024144173, -0.9685678482055664, 0.4294126033782959, 1.8117002248764038, 0.32471007108688354, 0.25897252559661865, -0.9588284492492676, 0.8138667345046997, -1.0968652963638306, -0.7858211994171143, 0.9140526056289673, 1.0694314241409302, 0.5128985643386841, -0.5108739137649536, -0.39717715978622437, -0.348676860332489, 0.15918511152267456, 0.5080987215042114, -0.3952237069606781, -0.45178908109664917, 0.008555611595511436, 0.3387302756309509, -0.07828567177057266, 0.926860511302948, -0.14686381816864014, 0.8804692029953003, 14.695291519165039, 0.40964362025260925, 0.015729686245322227, 0.5707702040672302, 0.6045092940330505, 0.16891855001449585, -0.38585808873176575, 0.07284507155418396, -1.3172705173492432, -0.5092832446098328, 1.433287501335144, 0.08546271175146103, 0.6663197875022888, -0.3083236515522003, 0.006320707034319639, 0.018150515854358673, -0.6182407736778259, 0.591412365436554, 0.49923238158226013, -1.0895811319351196, 0.5857136845588684, 0.06967917829751968, 0.014413113705813885, 0.5893986821174622, 1.0499067306518555, 1.0552796125411987, 0.25871264934539795, -0.3460323214530945, 0.3832440674304962, 0.7163739800453186, 0.4224861264228821, -0.14215902984142303, 0.11574821919202805, 0.5162214636802673, -0.9461597204208374, -0.43337953090667725, -0.7034820914268494, -0.8137620091438293, 0.07370851933956146, 0.05506216362118721, -0.5775659680366516, -0.7391892671585083, -0.36584630608558655, 0.7237077355384827, -0.36686208844184875, 0.2926222085952759, -0.13111692667007446, 0.6852490305900574, 0.30983150005340576, 0.07881689816713333, 0.4110933244228363, 0.5620274543762207, 0.34734612703323364, 0.19353145360946655, 0.164520263671875, 0.2604765295982361, -0.0671597570180893, 0.22011464834213257, -0.49351033568382263, 0.07885152101516724, -0.44863516092300415, -0.3109872043132782, 0.12703633308410645, 0.5510503053665161, 0.44019636511802673, 0.1963302046060562, -0.16006527841091156, 0.21351560950279236, 0.8020349144935608, 0.2732123136520386, 0.019712209701538086, 0.22875015437602997, 0.2541704773902893, -0.14063245058059692, -0.05854482203722, 0.19985060393810272, 0.021911857649683952, -0.6215450167655945, -0.8181723356246948, -0.016486359760165215, 0.5019157528877258, -0.8672465085983276, -0.3861415982246399, 1.2212978601455688, -0.32657700777053833, -0.17840197682380676, -0.10486260056495667, -0.8074768781661987, -0.3257131278514862, 0.28265300393104553, -1.5962167978286743, -0.8026311993598938, 0.3980119824409485, 0.033062003552913666, -0.4033251106739044, 0.24118968844413757, 1.3003768920898438, -0.0016160834347829223, -0.6617651581764221, 0.05112618952989578, -0.08237099647521973, -0.12073860317468643, -0.236247256398201, -0.7838025093078613, 0.47202569246292114, 0.13740874826908112, 0.15179915726184845, 1.032481074333191, 0.011090000160038471, 0.17800383269786835, -0.6341397762298584, -0.21167708933353424, 1.3222585916519165, -1.1691222190856934, -0.3738160729408264, -0.7663740515708923, -1.0833308696746826, 0.6539676189422607, 0.6599586009979248, -0.3129766881465912, 0.524960458278656, 0.39609262347221375, -0.5814105868339539, -0.2755754888057709, -0.5609491467475891, 0.3312974274158478, 0.6046362519264221, -1.1038626432418823, -0.5732830762863159, -0.3145159184932709, 0.42321598529815674, -0.6849915385246277, -0.5179935693740845, -0.37103986740112305, 0.38065165281295776, -0.13383935391902924, 0.7150546312332153, -0.40927568078041077, 0.16045255959033966, 0.9278327822685242, -0.10707563906908035, -0.8283228874206543, -0.3525587022304535, -0.8101222515106201, 0.14021210372447968, 0.25071343779563904, 0.7566924691200256, -0.7388312816619873, -0.33627739548683167, 1.154954433441162, 0.2879292368888855, -0.5987535119056702, -0.6668967008590698, -0.006066915113478899, 0.2553878426551819, -0.5075330138206482, 0.3317527770996094, -0.044929057359695435, -0.06574495881795883, 0.3844335079193115, 0.6221274733543396, 0.5532693862915039, -0.25928792357444763, -0.32350724935531616, -0.12808717787265778, -0.16289836168289185, 0.22699832916259766, -0.6045612096786499, -0.14515413343906403, -1.275706171989441, -0.12786392867565155, -1.321537971496582, -0.09448808431625366, -0.8951776623725891, -0.3265278935432434, -0.04317585378885269, -0.8688498735427856, -0.05930613726377487, 0.003013216657564044, -0.7181038856506348, -0.5069643259048462, -0.6881930828094482, -0.7889195084571838, 0.7436331510543823, 0.8572497367858887, -0.4402317404747009, 0.14725445210933685, -0.14401240646839142, -0.017522627487778664, -0.05321753770112991, 0.3614979684352875, -0.3738315999507904, -0.8188886642456055, -1.2485299110412598, 0.5718059539794922, 0.03220073878765106, -0.0026653551030904055, -0.5105804800987244, 0.8604555726051331, 0.611409604549408, 0.029405033215880394, -0.2658369839191437, 0.2841648459434509, -0.5654439926147461, -0.24407239258289337, 0.22837385535240173, -0.9318814277648926, 0.5975546836853027, 0.3123188614845276, -0.47262731194496155, -0.35874584317207336, 0.7933515310287476, -0.07926657050848007, -1.3855863809585571, -0.675270140171051, 0.6589648723602295, -0.9197847843170166, 0.0385647751390934, -0.7317231893539429, 0.062330637127161026, -0.8591492176055908, -0.0798967257142067, -0.1266760230064392, 0.6495238542556763, -0.3228662312030792, 1.1596719026565552, 0.7479920387268066, -1.0497194528579712, 0.14503997564315796, 0.483529269695282, -0.04541107639670372, -0.08257150650024414, 0.8675635457038879, 0.3074072003364563, 0.2900679409503937, 0.6379993557929993, 0.6311064958572388, 0.46210363507270813, -0.9567002654075623, 0.09770679473876953, 0.8878324031829834, -0.8333371877670288, -0.131779283285141, 0.777714192867279, -0.10636891424655914, -1.0943177938461304, 0.0040831733494997025, -1.318835735321045, -0.8715496063232422, 0.03134046122431755, 0.8939743638038635, 0.1488255113363266, -0.315180242061615, 0.06661403179168701, -0.2720476984977722, 0.35213416814804077, -0.38646379113197327, -0.5979514718055725, 0.6007480025291443, -0.4301457703113556, -0.5634661316871643, 1.2388286590576172, 0.8192833065986633, -0.8059440851211548, -0.5538275241851807, -0.8668421506881714, -0.011033529415726662, 0.10318578034639359, 0.5505255460739136, -0.36830514669418335, -0.36381232738494873, 0.8036647439002991, 0.5667044520378113, 0.3118627965450287, -0.07541868090629578, -0.21345722675323486, 0.20945239067077637, 0.7101422548294067, 0.3244794011116028, -0.7493011951446533, -0.5392526984214783, 1.6283174753189087, 1.5401201248168945, -0.6311516761779785, 0.06262696534395218, 0.45178693532943726, -0.656328558921814, 0.6844296455383301, 0.2573118209838867, -0.001278767711482942, 1.2887743711471558, -0.545961320400238, 0.35378387570381165, 0.0034396962728351355, -1.5551341772079468, -0.12658165395259857, 0.5870229601860046, 0.5453134775161743, 1.018083930015564, 0.42234742641448975, 0.17621305584907532, 1.0359621047973633, 0.2341710329055786, -0.04007754102349281, 0.3296797573566437, 0.5279641151428223, -0.38963764905929565, 0.07026411592960358, 0.3495079576969147, 0.4717271625995636, -0.4770823121070862, -0.7661896347999573, 0.2364344745874405, 0.5564233660697937, -0.22831016778945923, 0.6622611880302429, 0.828132152557373, 0.4513014554977417, 0.5217811465263367, 0.7423099875450134, 0.6244727373123169, -0.44720005989074707, -0.5863751769065857, -0.2714037001132965, -0.6206337809562683, -0.15565906465053558, -0.2407955676317215, -0.6835127472877502, -0.37129873037338257, 0.1702423095703125, 0.32463306188583374, 0.23939882218837738, -0.0006892384844832122, 0.8902395963668823, 0.5592493414878845, 0.22506001591682434, -0.10706601291894913, -0.14935393631458282, -0.3357478380203247, -1.1094870567321777, -0.11791826039552689, -0.5572686791419983, 0.24723003804683685, -0.19661225378513336, -0.08277706801891327, -0.6048804521560669]}, "authors": [{"authorId": "2294936058", "name": "Zifan He"}, {"authorId": "1419556433", "name": "Zongyue Qin"}, {"authorId": "2090207616", "name": "Neha Prakriya"}, {"authorId": "2266846937", "name": "Yizhou Sun"}, {"authorId": "2257233300", "name": "Jason Cong"}], "references": [{"paperId": "c0b454e0a6aa51ff3ba56778787d0c43932ef6ba", "title": "Yi: Open Foundation Models by 01.AI"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "db633c6b1c286c0386f0078d8a2e6224e03a6227", "title": "Mistral 7B"}, {"paperId": "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0", "title": "Qwen Technical Report"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "80980cd10d19f021c14a6b7eee871b6a5d328024", "title": "Augmenting Language Models with Long-Term Memory"}, {"paperId": "a22f3398ea865426c89ee66f4824ec626e56a864", "title": "RET-LLM: Towards a General Read-Write Memory for Large Language Models"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "dbc368bc8b49347dd27679894524fa62f88492c9", "title": "Unlimiformer: Long-Range Transformers with Unlimited Length Input"}, {"paperId": "e1325b35533282876f5793748b00d316a048cccf", "title": "Efficient Memory-Enhanced Transformer for Long-Document Summarization in Low-Resource Regimes"}, {"paperId": "3d68522abfadfc8ee6b7ec9edaaf91f1b2f38e5e", "title": "Large Language Models Can Be Easily Distracted by Irrelevant Context"}, {"paperId": "d2ef7fa75124d0f892681ebd8071c9e354c38425", "title": "TAPA: A Scalable Task-parallel Dataflow Programming Framework for Modern FPGAs with Co-optimization of HLS and Physical Design"}, {"paperId": "51748c37124adc20780b278151eb294798a2a38e", "title": "Demystifying the Nvidia Ampere Architecture through Microbenchmarking and Instruction-level Analysis"}, {"paperId": "a8cf0f7a20f886acfb332071c2daaf58ba86a5ca", "title": "Recurrent Memory Transformer"}, {"paperId": "efb0536c97ee740618b4b49ffa972b1465e0bc2b", "title": "Ultra-low latency recurrent neural network inference on FPGAs for physics applications with hls4ml"}, {"paperId": "3329029fb12472b4cb0e08bc688e6287ca6bce79", "title": "Streaming Overlay Architecture for Lightweight LSTM Computation on FPGA SoCs"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "d5e999aae76d5270ef272076979c809817458212", "title": "An Attention Free Transformer"}, {"paperId": "e32a12b14e212506115cc6804667b3d8297917e1", "title": "Poolingformer: Long Document Modeling with Pooling Attention"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "67ee20536c30a225b86902af2f091e28e5e19b40", "title": "Memformer: A Memory-Augmented Transformer for Sequence Modeling"}, {"paperId": "725264948d7b6946259af5b8d966e996b9570f99", "title": "DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "00c957711b12468cb38424caccdf5291bb354033", "title": "ZeRO: Memory optimizations Toward Training Trillion Parameter Models"}, {"paperId": "3161e2b6787d304c29dddb7d5fc188ca41be7bda", "title": "LAMOL: LAnguage MOdeling for Lifelong Language Learning"}, {"paperId": "0c3c4c88c7b07596221ac640c7b7102686e3eae3", "title": "PubMedQA: A Dataset for Biomedical Research Question Answering"}, {"paperId": "d78aed1dac6656affa4a04cbf225ced11a83d103", "title": "Revealing the Dark Secrets of BERT"}, {"paperId": "1c71771c701aadfd72c5866170a9f5d71464bb88", "title": "Unified Language Model Pre-training for Natural Language Understanding and Generation"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "3a32fcc73b6f03dc793e510823d9dd2c22cf617b", "title": "Hardware accelerators for recurrent neural networks on FPGA"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "5b1136a2135eaccb8c980fb61113f083ceca95e3", "title": "Recurrent Neural Networks Hardware Implementation on FPGA"}, {"paperId": "3273bd7422d26f6501c090bdff6abab780c32b22", "title": "Big data for Natural Language Processing: A streaming approach"}, {"paperId": "ac3ee98020251797c2b401e1389461df88e52e62", "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"}, {"paperId": "ab7ab88a4b8d4d8809f8d71bcd27b9d4ec56b7a7", "title": "Performance modeling in CUDA streams \u2014 A means for high-throughput data processing"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "84069287da0a6b488b8c933f3cb5be759cb6237e", "title": "On the difficulty of training recurrent neural networks"}, {"paperId": "a82517251c10465350c402c4dd1ef24f071fb72d", "title": "Epistemic Information in Stratified M-Spaces"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "b04a2d101532fc7f8cdb1db0e94f408afec990ae", "title": "Lifelong Learning for Question Answering with Hierarchical Prompts"}, {"paperId": "7fb4d10f6d2ee3133135958aefd50bf22dcced9d", "title": "A Focused Backpropagation Algorithm for Temporal Pattern Recognition"}, {"paperId": null, "title": "Openllama: An open reproduction of llama,"}, {"paperId": null, "title": "Programming and automation support for scalable task-parallel hls programs on modern multi-die fp-gas"}, {"paperId": null, "title": "HMT: Hierarchical Memory Transformer for Long Context"}]}