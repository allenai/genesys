{"paperId": "6bfafb32b423c3f0456a10984814f89046def489", "abstract": "Self-supervised learning, dubbed the dark matter of intelligence, is a promising path to advance machine learning. Yet, much like cooking, training SSL methods is a delicate art with a high barrier to entry. While many components are familiar, successfully training a SSL method involves a dizzying set of choices from the pretext tasks to training hyper-parameters. Our goal is to lower the barrier to entry into SSL research by laying the foundations and latest SSL recipes in the style of a cookbook. We hope to empower the curious researcher to navigate the terrain of methods, understand the role of the various knobs, and gain the know-how required to explore how delicious SSL can be.", "venue": "arXiv.org", "year": 2023, "citationCount": 186, "influentialCitationCount": 12, "openAccessPdf": {"url": "http://arxiv.org/pdf/2304.12210", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "The curious researcher is empowered to navigate the terrain of methods, understand the role of the various knobs, and gain the know-how required to explore how delicious SSL can be by laying the foundations and latest SSL recipes in the style of a cookbook."}, "embedding": {"model": "specter_v2", "vector": [0.23114179074764252, 0.6412830948829651, -0.6155930757522583, -0.21467691659927368, 0.08049469441175461, -0.48595142364501953, 0.45724213123321533, -0.24908682703971863, -0.1329723447561264, 0.08069411665201187, -0.015290153212845325, 0.10551422089338303, 0.33318519592285156, 0.2936464250087738, -0.2716829478740692, 0.04537126049399376, -0.8557935357093811, -0.10206373780965805, -0.23203283548355103, -0.22643397748470306, 0.21277892589569092, -0.7727494239807129, -0.9558169841766357, 0.024619389325380325, 0.6876557469367981, 0.4266848564147949, -0.2077319175004959, 0.6744157671928406, -0.5010555982589722, 0.2278006225824356, 0.34871482849121094, -0.5940289497375488, 0.143498957157135, 0.00020911906904075295, -0.6505881547927856, -0.024067921563982964, 0.7465671896934509, -0.003796353004872799, -0.3382794260978699, 0.612686812877655, -0.14058615267276764, 0.2549528479576111, 0.6703823208808899, -1.0255348682403564, -0.23243092000484467, 0.7995566129684448, 0.5165993571281433, 0.4313187003135681, 0.1687185913324356, -0.45138120651245117, 1.704012155532837, -0.6797717809677124, 0.20233549177646637, 1.0405094623565674, 0.538928210735321, 0.48968061804771423, -0.9228312969207764, -0.7511271238327026, 0.1808057725429535, -0.08038733154535294, -0.6054096817970276, -0.1700209379196167, -0.049755584448575974, -0.05580822378396988, 1.1389211416244507, -0.545100212097168, -0.41711628437042236, 0.797838568687439, -0.3977520167827606, 2.0223729610443115, 0.8849545121192932, -0.683291494846344, 0.22223706543445587, 0.8785362839698792, 0.5253440141677856, 0.879578709602356, -0.4008680284023285, 0.41052937507629395, -1.1498397588729858, -0.03355837240815163, 0.4541037380695343, -0.11902759969234467, -0.11724615842103958, -0.821447491645813, 0.08193103224039078, 1.0798615217208862, 0.2762223780155182, 0.8787723183631897, 0.13334517180919647, 0.5942670106887817, 0.5967642664909363, 0.36561906337738037, 0.0950503870844841, 0.6291741132736206, -0.5123864412307739, 0.4646157920360565, -0.8266844153404236, -0.11968214809894562, 0.6347289681434631, 0.8887892961502075, 0.1449456810951233, 0.12145379185676575, -0.4829636216163635, 0.7981025576591492, 1.3389451503753662, -0.13500505685806274, 0.39245134592056274, -0.9325535297393799, 0.051616936922073364, -0.2595755457878113, 0.040019597858190536, -0.6462613344192505, -0.30558061599731445, -0.3813904821872711, -0.8370543122291565, -0.4314306974411011, -0.21798785030841827, -0.5004223585128784, -0.6149753332138062, 0.3690272867679596, -0.2981742024421692, 0.20778633654117584, 0.35616785287857056, 0.8703112006187439, 0.5777472853660583, 0.5141748189926147, 0.5941072106361389, 0.13980025053024292, 0.6400676965713501, -0.7331182360649109, -0.6770008206367493, -0.7380135655403137, 0.6414228677749634, -0.0005285642691887915, 0.527646541595459, 0.2919771075248718, -0.9831674098968506, -0.8864620923995972, -1.2728254795074463, 0.3428787887096405, -0.6009048223495483, 0.3971419632434845, 1.679431676864624, 0.6892609000205994, -0.3925577998161316, 1.3991609811782837, 0.21466949582099915, -0.26509523391723633, 0.7222827672958374, 0.3906433880329132, 0.16468048095703125, -0.4815269708633423, -1.317038655281067, -0.10259569436311722, 0.49659618735313416, -0.9090527296066284, -0.22421787679195404, -0.5714721083641052, -1.115941047668457, -0.23089972138404846, 0.8128872513771057, -0.274038702249527, 1.198854684829712, -0.6197972297668457, -1.242792010307312, 0.9192354083061218, 0.14116355776786804, 0.2825045585632324, 0.5734025239944458, -0.050852108746767044, -0.7263386845588684, -0.2909999191761017, 0.044674649834632874, 0.38626790046691895, 0.6820905804634094, -0.8407334089279175, -0.09543659538030624, 0.13819319009780884, 0.01116042397916317, -0.2256283015012741, -0.3287602365016937, 0.4593413174152374, -0.13242153823375702, -0.37980955839157104, 0.28235068917274475, 0.420392781496048, -0.1946086883544922, -0.05744439736008644, -0.46316060423851013, -1.4797478914260864, 0.5688385367393494, 0.7261731624603271, 0.7644925117492676, -1.1273102760314941, -0.846142590045929, 0.09399079531431198, -0.11618458479642868, 0.11379572749137878, -0.6580825448036194, 0.426451712846756, -0.4334075450897217, 0.5747560262680054, -0.44663140177726746, -0.8600728511810303, 0.5492259860038757, -0.1447678804397583, -0.06571219861507416, -0.2640378773212433, -0.01344141736626625, 0.423345685005188, -1.047166347503662, -0.05591029301285744, -0.1366717368364334, 0.329806387424469, -0.618241548538208, 1.1550447940826416, -0.7344769835472107, -0.1763780564069748, -0.10822957009077072, -0.23731683194637299, 0.3935483396053314, -0.3797100782394409, 0.37680181860923767, -0.48625972867012024, 0.09191033989191055, 0.16898991167545319, -1.2039591073989868, 1.8481724262237549, -0.418529748916626, 0.23822103440761566, 0.07735570520162582, -0.33597221970558167, -0.10035043954849243, 0.4035271108150482, 0.0741550475358963, -0.0444648414850235, -0.12606775760650635, 0.3363942503929138, -1.135292649269104, 0.2635151743888855, 0.16923043131828308, 0.8832972049713135, 0.1032046526670456, 0.6231554746627808, 0.6887818574905396, -0.40182799100875854, 0.6245298385620117, 0.575134813785553, 0.6062543988227844, 0.879351019859314, 0.2243955135345459, -0.11535117775201797, 0.3977195620536804, -0.4752204716205597, -0.21068935096263885, 0.4719471335411072, 0.6160300374031067, 0.6317161321640015, 0.23676107823848724, -0.6167925596237183, 0.07349835336208344, -0.11218564957380295, 0.5971937775611877, 2.0169036388397217, -0.09581627696752548, -0.5987202525138855, -0.5594943165779114, -1.315298080444336, 0.002976223360747099, 0.5184162259101868, -0.5586143732070923, 0.0004174290515948087, -0.1148051768541336, -1.1988272666931152, 0.5165649056434631, 0.09421204775571823, 1.345895528793335, -0.5096191763877869, 0.005578380078077316, -0.4408617913722992, 0.6610041856765747, -0.1710713803768158, -0.9083842039108276, 0.9968670606613159, -0.3747014105319977, -0.5126084089279175, -0.13787543773651123, -0.26121413707733154, 0.18409986793994904, -0.31328144669532776, 0.938528299331665, -0.2278892546892166, -0.20968550443649292, 0.44531604647636414, 0.4583742022514343, -0.5538794994354248, -0.5788152813911438, 0.27829989790916443, -0.08967490494251251, -0.17873184382915497, 0.25152960419654846, 0.2791674733161926, 0.06829781085252762, 0.5096220374107361, -0.43707042932510376, -0.28992700576782227, 0.22215858101844788, -0.025641750544309616, 0.2850031554698944, 0.21700052917003632, -0.0773736909031868, -1.7642172574996948, 0.6378874182701111, -0.11040950566530228, -0.05411837249994278, 0.1586199849843979, -1.315136432647705, -0.17917366325855255, 0.22171150147914886, -0.7136635780334473, -0.38917112350463867, -0.3381997346878052, 0.8085034489631653, 0.3054738938808441, -0.5665909647941589, 0.11138983070850372, 0.2768018841743469, -0.233271986246109, 0.9136865735054016, 0.18930752575397491, 0.5071237087249756, -0.18571659922599792, 0.7777165174484253, -1.0451072454452515, 0.1454685479402542, 0.12194181978702545, 0.5463563799858093, -0.5107276439666748, -0.1979740709066391, -0.460516095161438, -0.9741253852844238, -0.458014577627182, -0.2534770369529724, 0.006117124110460281, 0.02513839676976204, -0.3041772246360779, -1.1888223886489868, -0.1660243719816208, -0.5066346526145935, -0.5562114119529724, -0.14748422801494598, -0.37653848528862, -0.3618815839290619, -0.951221764087677, -0.9893665909767151, -0.3770374357700348, -0.34761834144592285, -0.539032518863678, 0.15954360365867615, 0.28688114881515503, -0.3492918610572815, -0.6580107808113098, -0.13597442209720612, -0.00829973816871643, 0.8650789856910706, -0.6390679478645325, 0.5303918123245239, 0.08306708931922913, -0.0952335074543953, -0.1112227514386177, -0.16561108827590942, 0.7544876337051392, -0.23368936777114868, 0.09391825646162033, -0.8378284573554993, 0.31330081820487976, -0.34440943598747253, -0.8448426723480225, 0.3351539969444275, 0.1818917691707611, 0.6158631443977356, -0.16644783318042755, -0.3800065219402313, 0.45898425579071045, 1.5930347442626953, -0.8837683200836182, 0.04443532973527908, 0.3728438913822174, 1.1845744848251343, 0.42122921347618103, -0.514553964138031, 0.3998638391494751, 0.12392054498195648, 0.2506950795650482, -0.07505021244287491, -0.33133241534233093, -0.056441765278577805, -0.442164808511734, 0.624723494052887, 0.33536580204963684, 0.4081897735595703, 0.15499168634414673, -0.9195106625556946, 0.10890813171863556, -1.048056721687317, -0.5932974219322205, 0.4191029369831085, 0.6715966463088989, 0.6415160894393921, -0.24036329984664917, 0.16619917750358582, 0.32805928587913513, -0.05234009400010109, 0.24719256162643433, -0.5352643728256226, -0.3685886561870575, -0.09832640737295151, 0.6396992802619934, 0.5024200081825256, 0.3777994215488434, -0.8027083873748779, 0.46315014362335205, 15.049818992614746, 1.0246952772140503, 0.4724171459674835, 0.32614773511886597, 0.5337849259376526, 0.6219800710678101, -0.32778722047805786, -0.1353757381439209, -1.025811791419983, -0.317641943693161, 0.9823107123374939, 0.5082764029502869, 0.9127338528633118, 0.45662519335746765, -0.19022060930728912, -0.25599798560142517, -0.24100656807422638, 0.5799072980880737, 0.7078313231468201, -1.0784929990768433, -0.0942191407084465, 0.101962149143219, 0.4956783652305603, 0.03789954259991646, 0.6404209733009338, 0.9484436511993408, 0.9114733338356018, -0.44257646799087524, -0.05724455788731575, -0.06069927662611008, 0.9918633699417114, -0.28084781765937805, 0.5256171822547913, 0.2465744912624359, -0.39859309792518616, -0.09198851883411407, -0.17807333171367645, -0.4724162518978119, -0.2626406252384186, 0.08935336768627167, -0.759824275970459, -0.5022341012954712, -0.04292982816696167, 0.8925781846046448, -0.3479248881340027, 0.07068869471549988, -0.48452505469322205, 0.9350346326828003, -0.145675390958786, 0.0494842566549778, 0.1170327365398407, 0.41970786452293396, 0.0971783846616745, 0.18911917507648468, -0.4942036271095276, 0.2264433652162552, 0.32929152250289917, 0.4169825315475464, -0.33673804998397827, 0.41192248463630676, -0.2573128640651703, -0.45501604676246643, -0.8500425219535828, 1.0384327173233032, 0.615175187587738, 0.4431872069835663, -0.264484703540802, 0.7192955613136292, 0.20172026753425598, 0.2657433748245239, 0.19959650933742523, -0.31553035974502563, 0.15639278292655945, -0.3625970482826233, -0.20919162034988403, 0.2947341799736023, -0.6340269446372986, -0.43477392196655273, -1.067676067352295, -0.319845050573349, 0.7563055753707886, -0.9155672192573547, -1.5115892887115479, 0.450326532125473, -0.7384284734725952, -0.44487306475639343, 0.44575342535972595, -0.7610076665878296, -0.16179615259170532, 0.3002271056175232, -1.252449631690979, -0.5252236723899841, 0.1576930284500122, -0.390279084444046, -0.5861380100250244, -0.4462988078594208, 1.300158143043518, -0.26376283168792725, -0.5445671677589417, 0.20809724926948547, 0.11888325214385986, -0.22597070038318634, 0.17884889245033264, -1.5488375425338745, 0.4052163064479828, -0.4327991008758545, -0.139629527926445, 0.4175601005554199, 0.10710956901311874, 0.05788331851363182, -0.6045088768005371, 0.2237735390663147, 0.41717496514320374, -0.9404576420783997, -0.0452725775539875, -0.40427184104919434, -0.9561976194381714, -0.3511711359024048, 0.4721115827560425, -0.3495398759841919, 0.8545766472816467, 0.4530954360961914, -0.87831050157547, -0.2329033464193344, -1.0882354974746704, 0.13512007892131805, 0.7735562920570374, -0.5367962718009949, -0.0586613304913044, 0.34640857577323914, 0.16268502175807953, -0.37228283286094666, -0.7848886847496033, -0.35628756880760193, -0.05635792016983032, -0.14894282817840576, 0.7839865684509277, -0.5841288566589355, 0.6085554361343384, 0.6571952700614929, -0.12801383435726166, -1.0091168880462646, -0.022041471675038338, -1.2134770154953003, 0.2782048285007477, 0.46038952469825745, 0.8659812211990356, -0.23081348836421967, 1.0739775896072388, 1.05698823928833, 0.7497809529304504, -0.11707989871501923, 0.07264336198568344, -0.34129372239112854, -0.3614802658557892, -0.27234554290771484, -0.15425994992256165, 0.6622560620307922, -0.026125233620405197, 0.5094519257545471, 0.6460167169570923, 0.08436967432498932, 0.5999270081520081, -0.8369303941726685, 0.41103488206863403, -0.5087203979492188, -0.04723656177520752, -0.4265907406806946, 0.07877294719219208, -1.130631446838379, 0.1959969699382782, -1.4572136402130127, 0.06433042883872986, -0.8733378648757935, -0.4420282542705536, -0.13750985264778137, -0.27403995394706726, 0.27669084072113037, 0.17649920284748077, -0.27343952655792236, -0.492953360080719, -0.6425033211708069, -0.5535286068916321, 0.2302776724100113, 0.8611196875572205, -0.622573971748352, -0.30697646737098694, 0.3832307457923889, -0.5255299210548401, 0.317547470331192, 0.6982499957084656, -0.6407367587089539, -1.000776767730713, -0.5418685674667358, 0.3735172748565674, -0.35190969705581665, 0.023967936635017395, -0.8331031203269958, 0.5330909490585327, 0.2002793401479721, 0.13272792100906372, 0.28472355008125305, 0.03838302567601204, -1.2913062572479248, -0.4677167236804962, -0.1682669073343277, -0.9926170706748962, -0.27900034189224243, -0.09813416004180908, -0.32452473044395447, 0.29350876808166504, 0.017155062407255173, 0.1399058848619461, -1.1183228492736816, -0.5857596397399902, 0.15081675350666046, -0.3328353762626648, 0.14186438918113708, -0.41378024220466614, -0.29644253849983215, -0.9178979396820068, 0.08004755526781082, -0.33421945571899414, 0.6673685312271118, -0.14555735886096954, 0.5954217910766602, 0.023201173171401024, -1.0886578559875488, 0.16432054340839386, 0.27090373635292053, 0.022180922329425812, -0.30810806155204773, 0.4238628149032593, -0.12201204150915146, -0.13444262742996216, -0.15220093727111816, 0.09525211900472641, 0.3509371280670166, -0.7860232591629028, -0.046308815479278564, 0.5676600933074951, -0.2860651910305023, 0.053181350231170654, 0.7990499138832092, -0.44560545682907104, -0.9309371113777161, 0.6802952289581299, -0.4065239429473877, -0.8231402039527893, -0.2772986590862274, 0.5543390512466431, 0.4450875222682953, -0.5387279391288757, 0.20227409899234772, -0.19752299785614014, 0.3777802884578705, -0.13695776462554932, -0.4687533378601074, 1.0345898866653442, 0.008868103846907616, -0.11799794435501099, 0.7323187589645386, 0.836262583732605, -0.7265850901603699, -1.148870825767517, -0.7301149964332581, 0.008775798603892326, -0.1971311718225479, 0.4088495671749115, -1.1545863151550293, -0.5841922163963318, 0.37263333797454834, 0.8272625207901001, 0.35655608773231506, 0.020976172760128975, -0.2454768419265747, 0.023868924006819725, 0.6639562845230103, -0.08421097695827484, -0.9571419954299927, -0.08278734236955643, 0.683849036693573, 1.0792343616485596, -1.3989876508712769, 0.6212186217308044, -0.493966668844223, -1.3380014896392822, 1.0039161443710327, 0.27971747517585754, 0.12716670334339142, 0.905563473701477, -0.658383846282959, -0.05097508057951927, -0.14711721241474152, -0.5547010898590088, -0.658781111240387, 1.0709428787231445, 1.1373271942138672, 0.9260826706886292, 0.044244442135095596, 0.2409754991531372, 0.8543320894241333, 0.09140155464410782, 0.4010894298553467, 0.48834365606307983, 0.7003867030143738, -0.23365570604801178, -0.20919552445411682, 0.4479636251926422, 0.6159364581108093, -0.6955320239067078, -0.16998828947544098, 0.003716598730534315, 0.6066640615463257, 0.5751234292984009, 0.6404702067375183, -0.3063192665576935, -0.2081453651189804, 0.8023117184638977, 0.3237537741661072, 0.32210516929626465, -0.6819096207618713, -0.6126343607902527, -0.21203188598155975, -0.3349328339099884, -0.12663251161575317, -0.5097952485084534, -0.686353862285614, -0.6148430109024048, -0.3211710453033447, 0.1795945018529892, 0.14705322682857513, 0.570554792881012, 0.921677827835083, 0.3634130358695984, -0.05834135785698891, 0.16391867399215698, -0.5096586346626282, -0.3400806784629822, -0.6598500609397888, -0.38274917006492615, -0.5779232978820801, -0.4016861617565155, -0.43429556488990784, -0.8067973256111145, -0.07349494099617004]}, "authors": [{"authorId": "3201463", "name": "Randall Balestriero"}, {"authorId": "3407874", "name": "Mark Ibrahim"}, {"authorId": "2162736903", "name": "Vlad Sobal"}, {"authorId": "4690624", "name": "Ari S. Morcos"}, {"authorId": "144675956", "name": "Shashank Shekhar"}, {"authorId": "1962083", "name": "T. Goldstein"}, {"authorId": "34651419", "name": "Florian Bordes"}, {"authorId": "1453740540", "name": "Adrien Bardes"}, {"authorId": "51888120", "name": "Gr\u00e9goire Mialon"}, {"authorId": "1932187449", "name": "Yuandong Tian"}, {"authorId": "102604362", "name": "Avi Schwarzschild"}, {"authorId": "145771261", "name": "A. Wilson"}, {"authorId": "8284185", "name": "Jonas Geiping"}, {"authorId": "2048163343", "name": "Q. Garrido"}, {"authorId": "2147013351", "name": "Pierre Fernandez"}, {"authorId": "2063958674", "name": "Amir Bar"}, {"authorId": "2367683", "name": "H. Pirsiavash"}, {"authorId": "1688882", "name": "Yann LeCun"}, {"authorId": "121592562", "name": "Micah Goldblum"}], "references": [{"paperId": "13ec42ad568a73e48c29e9977155a980bb102a52", "title": "ScaleNet: An Unsupervised Representation Learning Method for Limited Information"}, {"paperId": "5a9cb1b3dc4655218b3deeaf4a2417a9a8cd0891", "title": "DINOv2: Learning Robust Visual Features without Supervision"}, {"paperId": "4096ea6d3c6ff8bebaadcfdafafafeb99a0c6c8e", "title": "A surprisingly simple technique to control the pretraining bias for better transfer: Expand or Narrow your representation"}, {"paperId": "dae9be0f0d815b53b46974377a0edf9169a99f3f", "title": "Dexterity from Touch: Self-Supervised Pre-Training of Tactile Representations with Robotic Play"}, {"paperId": "0388fd88770d60c6ddddb5117863e2b24b1f725e", "title": "Towards Democratizing Joint-Embedding Self-Supervised Learning"}, {"paperId": "10923e416d15ab36161f4ab9ad40aa15bb91f541", "title": "Self-supervised learning of Split Invariant Equivariant representations"}, {"paperId": "3e3d0e2935301a58fdbe520dbeed84d3e0098e7f", "title": "Searching Large Neighborhoods for Integer Linear Programs with Contrastive Learning"}, {"paperId": "ee57e4d7a125f4ca8916284a857c3760d7d378d3", "title": "Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture"}, {"paperId": "2218f1713d7f721ab76801063416ec9b11c7646f", "title": "ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders"}, {"paperId": "2a3213cb3c755f036d5dfec7261d726a819c78c1", "title": "Muse: Text-To-Image Generation via Masked Generative Transformers"}, {"paperId": "d8496775f90ca21735decc238855550c11efd85a", "title": "Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language"}, {"paperId": "41d3b9617772fda44cd81a3a11eead7236a0c01b", "title": "What do Vision Transformers Learn? A Visual Exploration"}, {"paperId": "8fdb23e99b90e09412ff7660b428fc4104533d59", "title": "Implicit variance regularization in non-contrastive SSL"}, {"paperId": "ed009b7423dcfec47708fb5817ec4955e4265757", "title": "Joint Embedding Predictive Architectures Focus on Slow Features"}, {"paperId": "915f52bfbbb813bf50a1824282c0b490a6c30dd1", "title": "Curiosity in hindsight"}, {"paperId": "78281482c1fdad8e167bab39cc9955c73d58ae8f", "title": "EVA: Exploring the Limits of Masked Visual Representation Learning at Scale"}, {"paperId": "021f3124cd5eaf1a500a34f5614003b66b13ff59", "title": "Robust Self-Supervised Learning with Lie Groups"}, {"paperId": "9b5f4aab169fba588e214c010345232053f8ae76", "title": "From Play to Policy: Conditional Behavior Generation from Uncurated Robot Data"}, {"paperId": "38e16cc5c5af9b625c128d283d59a672eae66ce7", "title": "Self-Supervised Learning Through Efference Copies"}, {"paperId": "e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9", "title": "LAION-5B: An open large-scale dataset for training next generation image-text models"}, {"paperId": "8be831a07abe8c5475c2bd91cc41bf4c1c2be771", "title": "The Hidden Uniform Cluster Prior in Self-Supervised Learning"}, {"paperId": "127ebdb7b87fe5c8c8ff1bb9173584b75eec8f47", "title": "RankMe: Assessing the downstream performance of pretrained self-supervised representations by their rank"}, {"paperId": "3fbe2e8413df0207c26ff393c9aaa8488e3ca4c3", "title": "VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training"}, {"paperId": "ac134b312d64b0bf01ccf15e60be4fa3016ee101", "title": "Does Zero-Shot Reinforcement Learning Exist?"}, {"paperId": "95c729ce4469ba0513380759b82d3a50d648bd9b", "title": "Variance Covariance Regularization Enforces Pairwise Independence in Self-Supervised Representations"}, {"paperId": "568e80ac7555266516e24830b0d325daab6fc595", "title": "Understanding Collapse in Non-contrastive Siamese Representation Learning"}, {"paperId": "bd1eb081b9e88857bf0f62ac5b51969004e5593f", "title": "Improving Self-Supervised Learning by Characterizing Idealized Representations"}, {"paperId": "301e396abf449e9a7f6ec21cd84494adf026e0cd", "title": "Exploring Target Representations for Masked Autoencoders"}, {"paperId": "b62f6f765f033c1f023c4a424a20571564e61d97", "title": "Light-weight probing of unsupervised representations for Reinforcement Learning"}, {"paperId": "062cfd5cbafa47950a5ebbd306cd0059dfd79f75", "title": "CLOWER: A Pre-trained Language Model with Contrastive Learning over Word and Character Representations"}, {"paperId": "02251886950770e82b3d68564d60cdfe15e73199", "title": "Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks"}, {"paperId": "599be9043ef3571f65758cf36e184c9dc1781baf", "title": "BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers"}, {"paperId": "2f399c4e23e540342e3ff6002be900833e96c8d6", "title": "On the Pros and Cons of Momentum Encoder in Self-Supervised Visual Representation Learning"}, {"paperId": "f566a4d584907adbb2691981bced2b079948d10f", "title": "Self-supervised learning in medicine and healthcare"}, {"paperId": "36ee474d55d08465f9df76d290bf5a190d74db65", "title": "Expanding Language-Image Pretrained Models for General Video Recognition"}, {"paperId": "b83fc5d7de2cc6a5ce6e44b8a1dd9169eec62720", "title": "What Do We Maximize in Self-Supervised Learning?"}, {"paperId": "9c31128524849f433a1d58e5bfbc02199fb65649", "title": "Equivariant Representation Learning via Class-Pose Decomposition"}, {"paperId": "7f851841e6420004312942ef5ffc2f875a574c13", "title": "Revisiting Pretraining Objectives for Tabular Deep Learning"}, {"paperId": "96e22af70f9ca575ebfe648677aced03c6c8803d", "title": "Transfer Learning with Deep Tabular Models"}, {"paperId": "1243e13254bb4ea1f71b4be8a3e4e54ffd02d2fe", "title": "Scaling Autoregressive Models for Content-Rich Text-to-Image Generation"}, {"paperId": "b2847d1b6d569022ffd2f50cbfbd6a22797eccf6", "title": "Self-Supervised Learning for Videos: A Survey"}, {"paperId": "d2425b430fbf5b8ddf9cf2309c36a80a71e5a449", "title": "OmniMAE: Single Model Masked Pretraining on Images and Videos"}, {"paperId": "2fd346e7edf0ec9de793c96acb0a1e3f2f8a2718", "title": "BYOL-Explore: Exploration by Bootstrapped Prediction"}, {"paperId": "11c16254f7b61687b5d9b7637de032461a6ebb5f", "title": "On the duality between contrastive and non-contrastive self-supervised learning"}, {"paperId": "f5db3b0a99e9ab7777b2fecf8b5d237715a3464d", "title": "Understanding the Role of Nonlinearity in Training Dynamics of Contrastive Learning"}, {"paperId": "6eece39036fe90ecc92725b9380edd165f6290c4", "title": "Patch-level Representation Learning for Self-supervised Vision Transformers"}, {"paperId": "5c4f8de98525eebd762773093d149ba459cef290", "title": "Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "8ce9b1e527c4d9d15239621ec4e3ef3fbbe32202", "title": "On the Role of Bidirectionality in Language Model Pre-Training"}, {"paperId": "b845c9d7f3fa05f56e7394f273c0c7536ee0e671", "title": "Contrastive and Non-Contrastive Self-Supervised Learning Recover Global and Local Spectral Embedding Methods"}, {"paperId": "1e9fbd0e9d047c192d7e2a75f0034400c5c403c7", "title": "Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative Priors"}, {"paperId": "d28fed119d9293af31776205150b3c34f3adc82b", "title": "Uniform Masking: Enabling MAE Pre-training for Pyramid-based Vision Transformers with Locality"}, {"paperId": "004b97aea43f9f62cc49dec20f449abfbae28811", "title": "Masked Autoencoders As Spatiotemporal Learners"}, {"paperId": "8db9410f6325975d7f31686b7aeb814725b1e775", "title": "Toward a Geometrical Understanding of Self-supervised Contrastive Learning"}, {"paperId": "9dae204dad41633188022002a04c8aa67c79a4e1", "title": "Simple Open-Vocabulary Object Detection with Vision Transformers"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "23c13584e1549e88b20b8c1f8d601646958e4471", "title": "Self-Supervised Learning of Object Parts for Semantic Segmentation"}, {"paperId": "9efa93e2228266fb1a9faa1b55270813f3ad6c5c", "title": "Learning Symmetric Embeddings for Equivariant World Models"}, {"paperId": "d2f63b56fc6bc373f5c023454c2b253326962865", "title": "DeiT III: Revenge of the ViT"}, {"paperId": "a6e231db70a6774abc995afc0201671e0dab4d3a", "title": "Masked Siamese Networks for Label-Efficient Learning"}, {"paperId": "15190e8b459bd85d546286f7d7da61b4f4f3f58a", "title": "What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?"}, {"paperId": "cc9df11e321206664cc1c6a873c615b0bb3260b3", "title": "On the Importance of Asymmetry for Siamese Representation Learning"}, {"paperId": "ce90dd9e33d8e246f9632aa1c582ab80ed50ce51", "title": "Dual Temperature Helps Contrastive Learning Without Many Negative Samples: Towards Understanding and Simplifying MoCo"}, {"paperId": "2b9455fceb0ff58f28a46aebfb8df6f7003e9e40", "title": "How Does SimSiam Avoid Collapse Without Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning"}, {"paperId": "0b28ed4853de3f8cc75c782b8ac1e9e8432d6592", "title": "Mugs: A Multi-Granular Self-Supervised Learning Framework"}, {"paperId": "c9bdc9ad2c3cf3230ba9aac7b5783ab411f0d204", "title": "R3M: A Universal Visual Representation for Robot Manipulation"}, {"paperId": "4990f7542f0600e0501a7e7a931b32eb7cb804d5", "title": "VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training"}, {"paperId": "523acd658742fb9c978e3f7638c09d7ce78af719", "title": "Masked Visual Pre-training for Motor Control"}, {"paperId": "7b3d26bd1d65ed5937c76043b5cd058260d8469f", "title": "The Unsurprising Effectiveness of Pre-Trained Vision Models for Control"}, {"paperId": "904fd897a47e2713257334f17c1ce09114e7973d", "title": "Audio self-supervised learning: A survey"}, {"paperId": "cfebfd27c0dfb53c3596a313db5890487b96a7fd", "title": "A Self-Supervised Descriptor for Image Copy Detection"}, {"paperId": "07c6a2ccb65913f2478234e96dd50c9593989c5c", "title": "Vision Models Are More Robust And Fair When Pretrained On Uncurated Images Without Supervision"}, {"paperId": "b68ec0d46c16c6357157950b4e440474b82efd22", "title": "Investigating Power laws in Deep Representation Learning"}, {"paperId": "7c597874535c1537d7ddff3b3723015b4dc79d30", "title": "MaskGIT: Masked Generative Image Transformer"}, {"paperId": "6296aa7cab06eaf058f7291040b320b5a83c0091", "title": "Generative Adversarial Networks"}, {"paperId": "7f36d87c89afa1eb39554bc21d125b4b2609262b", "title": "Mixing Up Contrastive Learning: Self-Supervised Representation Learning for Time Series"}, {"paperId": "3d3521b3fe6341befc9dd98ce96e091bc7b855da", "title": "Understanding Deep Contrastive Learning via Coordinate-wise Optimization"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "6044fade70d6d8dc53a6f2c8bb0d9b157b4cfe25", "title": "Pushing the limits of self-supervised ResNets: Can we outperform supervised learning without labels on ImageNet?"}, {"paperId": "e9581d9758062f76e029bd19a58c4ae976cfb414", "title": "SLIP: Self-supervision meets Language-Image Pre-training"}, {"paperId": "7002ae048e4b8c9133a55428441e8066070995cb", "title": "GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models"}, {"paperId": "7d0dfbddbf5b824e7048b2d40fa5945afd18ac9c", "title": "Are Large-scale Datasets Necessary for Self-Supervised Pre-training?"}, {"paperId": "4d7c2de7a0de802f0fbfafcd9a4b4ec19e62e49d", "title": "High Fidelity Visualization of What Your Self-Supervised Representation Knows About"}, {"paperId": "5fab44b185fa2148a57f299ed1c96b2d7c3af048", "title": "Exploring the Equivalence of Siamese Self-Supervised Learning via A Unified Gradient Framework"}, {"paperId": "2fd6f77540c1cc8e70b96208ccf9971b4251fc02", "title": "FLAVA: A Foundational Language And Vision Alignment Model"}, {"paperId": "6d1ef4436904de111c8b1975bbf25d3fe2f165f7", "title": "DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting"}, {"paperId": "5e39c030eb7e3ad516cbe1bdcd7b8c4a9e51a6a9", "title": "The Surprising Effectiveness of Representation Learning for Visual Imitation"}, {"paperId": "3e38f4b4055abecbac2e618df2ecb33554073e08", "title": "PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers"}, {"paperId": "f8da4ef15673cb8ff39492cb4c827847c9b70fe8", "title": "Why Do Self-Supervised Models Transfer? On the Impact of Invariance on Downstream Tasks"}, {"paperId": "21ec90872abd986c12afe39bebe807732ffa70c9", "title": "Florence: A New Foundation Model for Computer Vision"}, {"paperId": "9c4753ef43d2928866dc5bf6cec53d03373ec2fa", "title": "SimMIM: a Simple Framework for Masked Image Modeling"}, {"paperId": "197d5867a45a2988f4dd159063cdfbfe90164962", "title": "LiT: Zero-Shot Transfer with Locked-image text Tuning"}, {"paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7", "title": "Masked Autoencoders Are Scalable Vision Learners"}, {"paperId": "94ff111c4d81bd03f159321728ceec8b4711c89d", "title": "An Empirical Study of Training End-to-End Vision-and-Language Transformers"}, {"paperId": "c23d9d44e8bc68408cea9f305d1f24d915bc0d0d", "title": "Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey"}, {"paperId": "3ed2b5a9c8e42f3bf93dfd40426e4df205420ac7", "title": "Towards the Generalization of Contrastive Self-Supervised Learning"}, {"paperId": "3b3d7adb9047d01af6dfa2975ad8addd69715e96", "title": "Mastering Atari Games with Limited Data"}, {"paperId": "d2a7c29f302aaef87e2fe5bf3cfff3aba20915e0", "title": "Equivariant Contrastive Learning"}, {"paperId": "5f895e84c1fea75de07b4f90da518273c2e57291", "title": "Scatterbrain: Unifying Sparse and Low-rank Attention Approximation"}, {"paperId": "28c17db217f2d7af12482a087d197851f0a97db0", "title": "Understanding Dimensional Collapse in Contrastive Self-supervised Learning"}, {"paperId": "40b68df4635298c32725891bc46ee0201dac56c1", "title": "Decoupled Contrastive Learning"}, {"paperId": "848eb8367785910c2fe31372605954ad8f9dfe6c", "title": "Ego4D: Around the World in 3,000 Hours of Egocentric Video"}, {"paperId": "8746e08cd315dcfbed09d62a32b489d3c20fdbe4", "title": "Towards Demystifying Representation Learning with Non-contrastive Self-supervision"}, {"paperId": "a3bfcdfa063c329152c36f69f76d41fd790be19a", "title": "SubTab: Subsetting Features of Tabular Data for Self-Supervised Representation Learning"}, {"paperId": "d20266067e984e79a1e7b8f444a275ad368cea49", "title": "The Power of Contrast for Feature Learning: A Theoretical Analysis"}, {"paperId": "5e00596fa946670d894b1bdaeff5a98e3867ef13", "title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision"}, {"paperId": "8f167ec1149921fac63b1ea855443de109bb013a", "title": "How Much Can CLIP Benefit Vision-and-Language Tasks?"}, {"paperId": "64877624f342d16f9273e5c2470b459b60bbdee9", "title": "Tight Mutual Information Estimation With Contrastive Fenchel-Legendre Optimization"}, {"paperId": "08bd0ebcf5e0cd08a9748683692678c36dee9c07", "title": "SCARF: Self-Supervised Contrastive Learning using Random Feature Corruption"}, {"paperId": "cf5e6e3c50a798d87033e0e108e88b3647738bbe", "title": "How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers"}, {"paperId": "b70bb1855e217edffb5dfa0632e8216860821870", "title": "Efficient Self-supervised Vision Transformers for Representation Learning"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "1a3d5d6cec457f8f3b088cb3636a1a197bd248f6", "title": "Self-Supervised Learning with Kernel Dependence Maximization"}, {"paperId": "36b9d0f8610a82fd25854889d9327a04da4ff8fd", "title": "MST: Masked Self-Supervised Transformer for Visual Representation"}, {"paperId": "0f1382cb004b4834cc3ca7824a61d0d6b86a5763", "title": "Pretraining Representations for Data-Efficient Reinforcement Learning"}, {"paperId": "2a805d0e1b067444a554c5169d189fa1f649f411", "title": "Scaling Vision Transformers"}, {"paperId": "90bd7648bf2e4dc8644e67c427e374a2bcabbe5e", "title": "DETReg: Unsupervised Pretraining with Region Priors for Object Detection"}, {"paperId": "3f1774d91c7c219f063f40b894e837e6c48b2bb2", "title": "Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss"}, {"paperId": "bcc97c41d7fc25b669dd8cf15147d706fde38832", "title": "PASS: An ImageNet replacement for self-supervised pretraining without humans"}, {"paperId": "5fa2103e36b3e76e49edb8433a1206a6b25e3ead", "title": "SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training"}, {"paperId": "1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa", "title": "CogView: Mastering Text-to-Image Generation via Transformers"}, {"paperId": "3a223a5174717a193bb7e22c825d801273ad7cb2", "title": "Unsupervised Speech Recognition"}, {"paperId": "c0e35aa7fa2e1ce5886be3601d416b6603102c68", "title": "Mean Shift for Self-Supervised Learning"}, {"paperId": "0d0cf5f64c052aa7edc5bb638203616a620557f6", "title": "VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning"}, {"paperId": "386bfd0e411dee4f512a8737c55dd84846981182", "title": "TABBIE: Pretrained Representations of Tabular Data"}, {"paperId": "8653cbe908c64c0e4a3591fe652d239ab7cf98c1", "title": "On Feature Decorrelation in Self-Supervised Learning"}, {"paperId": "ad4a0938c48e61b7827869e4ac3baffd0aefab35", "title": "Emerging Properties in Self-Supervised Vision Transformers"}, {"paperId": "2d67415394aba2c834be722f7de02519842155d7", "title": "With a Little Help from My Friends: Nearest-Neighbor Contrastive Learning of Visual Representations"}, {"paperId": "6ed5a7fb19d0fae0b7c8b47b007db194e43c2592", "title": "A Large-Scale Study on Unsupervised Spatiotemporal Representation Learning"}, {"paperId": "cf9b8da26d9b92e75ba49616ed2a1033f59fce14", "title": "Open-vocabulary Object Detection via Vision and Language Knowledge Distillation"}, {"paperId": "7ba9c013988eaff5cd186d73704af329d027872d", "title": "MDETR - Modulated Detection for End-to-End Multi-Modal Understanding"}, {"paperId": "8e90de490be759e15987168225f4add8e16810f8", "title": "Solving Inefficiency of Self-supervised Representation Learning"}, {"paperId": "c26759e6c701201af2f62f7ee4eb68742b5bf085", "title": "SimCSE: Simple Contrastive Learning of Sentence Embeddings"}, {"paperId": "739ceacfafb1c4eaa17509351b647c773270b3ae", "title": "An Empirical Study of Training Self-Supervised Vision Transformers"}, {"paperId": "b364cdb02d18b9d9a3c097f5ea446f7e9ab10325", "title": "Going deeper with Image Transformers"}, {"paperId": "b6382a7351c0c595f91472ac71d3b2d87b3c4844", "title": "ViViT: A Video Vision Transformer"}, {"paperId": "8a9d84d86ac0d76e63914802f9738325c3bece9c", "title": "Barlow Twins: Self-Supervised Learning via Redundancy Reduction"}, {"paperId": "0f8aa47ff8c6c49a347e192debe20ce4e5a4caea", "title": "Self-supervised Pretraining of Visual Features in the Wild"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "19537be34dbadbcaa4fffcf028a8ada5095b1b5c", "title": "COCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining"}, {"paperId": "4f7a77d04e7e1cff1f6e306f082217be78203643", "title": "Instance Localization for Self-supervised Detection Pretraining"}, {"paperId": "2bceaa105b3d31c7d539f4a316f013a062ae7c15", "title": "Understanding self-supervised Learning Dynamics without Contrastive Pairs"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "552343c3bace2b5c1ac6a8a1110d724b31205b51", "title": "ISD: Self-Supervised Learning by Iterative Similarity Distillation"}, {"paperId": "086dfa02dca8dd8cac68bf59719a60ffcb0f144b", "title": "Self supervised contrastive learning for digital histopathology"}, {"paperId": "00969b4dcf8f9b21895bd038a51a038018da84f0", "title": "How Well Do Self-Supervised Models Transfer?"}, {"paperId": "1fda1fd713070763324646380f0ad206adea6422", "title": "Run Away From your Teacher: Understanding BYOL by a Novel Self-Supervised Approach"}, {"paperId": "0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d", "title": "Exploring Simple Siamese Representation Learning"}, {"paperId": "497d765b1eccbc9e99a37592a1860744559695db", "title": "Open-Vocabulary Object Detection Using Captions"}, {"paperId": "6f92dcefc5f6b4346f619ae7546a8bd2d6decade", "title": "Dense Contrastive Learning for Self-Supervised Visual Pre-Training"}, {"paperId": "c13a8f9edb933e60c7a989244aee56283a54ce37", "title": "UP-DETR: Unsupervised Pre-training for Object Detection with Transformers"}, {"paperId": "57835c5ad5424f94ee75901c3113730f3900e656", "title": "Representation Learning via Invariant Causal Mechanisms"}, {"paperId": "7097137596f6755675f6aafcdd80969a747322ae", "title": "Contrastive Learning with Hard Negative Samples"}, {"paperId": "87b008a6289fa22c72e1726a8929e815dfbbc65f", "title": "Hard Negative Mixing for Contrastive Learning"}, {"paperId": "5d50c955e4db594983167572f3cb033d7b8d98ef", "title": "Understanding Self-supervised Learning with Dual Deep Networks"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7c4dbc479c6f123947687a1e9ab0fa03d6369146", "title": "SelfAugment: Automatic Augmentation Policies for Self-Supervised Learning"}, {"paperId": "2bb861fc09912a56aed0c652e9b764edba56bb0c", "title": "Transforming machine translation: a deep learning system reaches news translation quality comparable to human professionals"}, {"paperId": "c3a0059e69a10c8fe70efab423761e378fdab74b", "title": "What Should Not Be Contrastive in Contrastive Learning"}, {"paperId": "10569a326b860e87f6ebb7bf569af9ea59cc252a", "title": "Demystifying Contrastive Self-Supervised Learning: Invariances, Augmentations and Dataset Biases"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "4effd0f6b51b73335c3a2b7b880d168fbbe09298", "title": "Whitening for Self-Supervised Representation Learning"}, {"paperId": "7c4356ec0dca6e6df0af7a882e2cd1571c8bf3dc", "title": "Data-Efficient Reinforcement Learning with Self-Predictive Representations"}, {"paperId": "bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8", "title": "Generative Pretraining From Pixels"}, {"paperId": "3836ccb33191799e748e8e96f85a813eaf650ff8", "title": "Data Movement Is All You Need: A Case Study on Optimizing Transformers"}, {"paperId": "518b827e340c26582b5093401283a4f5cff605b9", "title": "Learning Invariant Representations for Reinforcement Learning without Reconstruction"}, {"paperId": "1e1e10d75c4ebabdbfb7912ca4cc06a27ffa85af", "title": "Unsupervised Learning of Visual Features by Contrasting Cluster Assignments"}, {"paperId": "3e7f5f4382ac6f9c4fef6197dd21abf74456acd1", "title": "Big Self-Supervised Models are Strong Semi-Supervised Learners"}, {"paperId": "38f93092ece8eee9771e61c1edaf11b1293cae1b", "title": "Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "32d281a1e7a0a2d4e2b3f34e0f71780c987e1374", "title": "DeCLUTR: Deep Contrastive Learning for Unsupervised Textual Representations"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "9a56ab8b1aba50dc2fea3cf4b531d30891a88ba9", "title": "Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere"}, {"paperId": "8bf6c69bae0956db13aa9129fedc69fdc1256dce", "title": "Prototypical Contrastive Learning of Unsupervised Representations"}, {"paperId": "f9e9ddec468c1c240a1a8c192e74d485d97205bd", "title": "Distilling Localization for Self-Supervised Representation Learning"}, {"paperId": "9efb64f20ab1f157ca9f4050d4aaacf6c3f9b2b2", "title": "CURL: Contrastive Unsupervised Representations for Reinforcement Learning"}, {"paperId": "47f6e6a8cb8b95b307f428fd2e267376c3e68033", "title": "A Comparison of Metric Learning Loss Functions for End-To-End Speaker Verification"}, {"paperId": "a1b8a8df281bbaec148a897927a49ea47ea31515", "title": "Improved Baselines with Momentum Contrastive Learning"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "7af72a461ed7cda180e7eab878efd5f35d79bbf4", "title": "A Simple Framework for Contrastive Learning of Visual Representations"}, {"paperId": "c2ee571fe9c29f6e59a5910b7b8278f9c3adfc99", "title": "Unsupervised Pre-Training of Bidirectional Speech Encoders via Masked Reconstruction"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "0170bb0b524df2c81b5adc3062c6001a2eb34c96", "title": "Self-Supervised Learning of Pretext-Invariant Representations"}, {"paperId": "4fed2133f467b8ef43d15eb3dc3916605beacdca", "title": "Self-Supervised Learning by Cross-Modal Audio-Video Clustering"}, {"paperId": "3507bd62a14bd0e8ead28cdedb1c33ba83c39c6b", "title": "Mastering Atari, Go, chess and shogi by planning with a learned model"}, {"paperId": "add2f205338d70e10ce5e686df4a690e2851bdfc", "title": "Momentum Contrast for Unsupervised Visual Representation Learning"}, {"paperId": "87045bfc6f8036d032ab6ad1ebeb0377db05da9a", "title": "Self-labelling via simultaneous clustering and representation learning"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "86b7e26018eb1dac51d1067ecf236b35b0a41cda", "title": "Deep Metric Learning With Tuplet Margin Loss"}, {"paperId": "41fcef711faca9013fd0980a9f6ec1d23c9c76c8", "title": "On Mutual Information Maximization for Representation Learning"}, {"paperId": "d89fb6a6dae278c4f5cc21086493b6c2e0bed972", "title": "Learning Disentangled Representation with Pairwise Independence"}, {"paperId": "2604797ff947ba554980344a81fa91d5323abdf7", "title": "Variational Autoencoders and Nonlinear ICA: A Unifying Framework"}, {"paperId": "db787640c9b42416ff8d7015546e667e58267177", "title": "Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty"}, {"paperId": "97f4d09175705be4677d675fa27e55defac44800", "title": "Contrastive Multiview Coding"}, {"paperId": "9b09d296059909490096e34e9df2d95314787ad5", "title": "Learning Representations by Maximizing Mutual Information Across Views"}, {"paperId": "1cae417456711c4da184f5efcd1b7464a7a0661a", "title": "Data-Efficient Image Recognition with Contrastive Predictive Coding"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "c42816f497d663c681df20d48a6e66a5632600d8", "title": "MixMatch: A Holistic Approach to Semi-Supervised Learning"}, {"paperId": "19975936b7ae315e3ca04330f22a7cb0e127a309", "title": "Scaling and Benchmarking Self-Supervised Visual Representation Learning"}, {"paperId": "4ae0c4a511697e960c477ea3e37b3e11bf3e0e02", "title": "Learning Robust Global Representations by Penalizing Local Predictive Power"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "1fd4694e7c2d9c872a427d50e81b5475056de6bc", "title": "Model-Based Reinforcement Learning for Atari"}, {"paperId": "6dae703128d9caff2623eb8dfe2526dc6ad7aff5", "title": "A Theoretical Analysis of Deep Q-Learning"}, {"paperId": "8d2eebab1b343c5eebf04215c272eb22660a1591", "title": "Nonlinear Canonical Correlation Analysis:A Compressed Representation Approach"}, {"paperId": "a364a2b6bb97fcb4207468e6500cf3042bbf8d07", "title": "Speech Recognition"}, {"paperId": "ac61568c081c03730c58bd34c023a6952803da13", "title": "Noise Contrastive Estimation and Negative Sampling for Conditional Models: Consistency and Statistical Efficiency"}, {"paperId": "af3825437b627db1a99f946f7aa773ba8b03befd", "title": "Learning deep representations by mutual information estimation and maximization"}, {"paperId": "360ef12906a531733b66e7e15c3d51771e7126d3", "title": "Tracking Emerges by Colorizing Videos"}, {"paperId": "bd3f21856f64dbfeb1be4723d75122e534f8b5e8", "title": "Conditional Noise-Contrastive Estimation of Unnormalised Models"}, {"paperId": "6ac386b9f77c3e4d84c06ec8b66475b1a6eada67", "title": "Spreading vectors for similarity search"}, {"paperId": "b2472bf4962749b85184dfa64596a8f3fa84c747", "title": "Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces"}, {"paperId": "2444be7584d1f5a7e2aa9f65078de09154f14ea1", "title": "Born Again Neural Networks"}, {"paperId": "155b7782dbd713982a4133df3aee7adfd0b6b304", "title": "Unsupervised Feature Learning via Non-parametric Instance Discrimination"}, {"paperId": "2a1f38e4451e826e01c9874954ba7c6f32ff79f4", "title": "Boosting Self-Supervised Learning via Knowledge Transfer"}, {"paperId": "fe018f22600d07cbd0452a070e03708886470015", "title": "The Sound of Pixels"}, {"paperId": "aab368284210c1bb917ec2d31b84588e3d2d7eb4", "title": "Unsupervised Representation Learning by Predicting Image Rotations"}, {"paperId": "6b73775f40467aed52784ff355b9bb7168e9078c", "title": "Mutual Information Neural Estimation"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "6a25e474075e26ddd18a24cd80deeb1d2ab33b42", "title": "Representation Learning by Learning to Count"}, {"paperId": "1e3d18beaf3921f561e1b999780f29f2b23f3b7d", "title": "Large Batch Training of Convolutional Networks"}, {"paperId": "05eb6eb4ea7d2b332295dfa5aeb64d5f47c1e628", "title": "The iNaturalist Species Classification and Detection Dataset"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "0d57ba12a6d958e178d83be4c84513f7e42b24e5", "title": "Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour"}, {"paperId": "3c57a1aa483d8bffe1339914b80d2913f2dc8376", "title": "Good Semi-supervised Learning That Requires a Bad GAN"}, {"paperId": "3abf64d10a5d9a426d864bcfd68daed370d6904c", "title": "Unsupervised Learning of Depth and Ego-Motion from Video"}, {"paperId": "2adae2da173b9dd720c8bcac0250a90a7f1ec697", "title": "Time-Contrastive Networks: Self-Supervised Learning from Video"}, {"paperId": "575a0e97702edcb0621a47b574949bac50e34200", "title": "Unsupervised Learning by Predicting Noise"}, {"paperId": "4b1c6f6521da545892f3f5dc39461584d4a27ec0", "title": "Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "1342c1e1684620c019972e2679d5131f1e8a4a13", "title": "Weight-averaged consistency targets improve semi-supervised deep learning results"}, {"paperId": "8423cc50c18d68f797adaa4f571f5e4efbe325a5", "title": "A Laplacian Framework for Option Discovery in Reinforcement Learning"}, {"paperId": "35d181da0b939bdf3bdf579969e5fe69e277e03e", "title": "Learning Features by Watching Objects Move"}, {"paperId": "78a11b7d2d7e1b19d92d2afd51bd3624eca86c3c", "title": "Improved Deep Metric Learning with Multi-class N-pair Loss Objective"}, {"paperId": "62f3d3015cee122bd147d7d878c85f70cc15680d", "title": "Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction"}, {"paperId": "df0402517a7338ae28bc54acaac400de6b456a46", "title": "WaveNet: A Generative Model for Raw Audio"}, {"paperId": "571b0750085ae3d939525e62af510ee2cee9d5ea", "title": "Improved Techniques for Training GANs"}, {"paperId": "1db6e3078597386ac4222ba6c3f4f61b61f53539", "title": "Adversarial Feature Learning"}, {"paperId": "3ad068ebde8f1d3a450a8c7e64a3428507bc2f51", "title": "Unsupervised Feature Extraction by Time-Contrastive Learning and Nonlinear ICA"}, {"paperId": "7d0effebfa4bed19b6ba41f3af5b7e5b6890de87", "title": "Context Encoders: Feature Learning by Inpainting"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "2ec8f7e0257a07d3914322b36072d1bbcd58a1e0", "title": "Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles"}, {"paperId": "8201e6e687f2de477258e9be53ba7b73ee30d7de", "title": "Colorful Image Colorization"}, {"paperId": "8e63784bd5a24d5e3035e2a11753e65e6e56625d", "title": "Learning Representations for Automatic Colorization"}, {"paperId": "543f21d81bbea89f901dfcc01f4e332a9af6682d", "title": "Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks"}, {"paperId": "884750937bb97e82c41316d80e5d104e0c0e4795", "title": "Deep Metric Learning via Lifted Structured Feature Embedding"}, {"paperId": "f401d7e4f371b0a635f5c89a34f84b12bbd45d0a", "title": "An efficient algorithm for information decomposition and extraction"}, {"paperId": "754dbc09783980f383e16b8728fb9c21a39bfff0", "title": "On Deep Multi-View Representation Learning"}, {"paperId": "fc1b1c9364c58ec406f494dd944b609a6a038ba6", "title": "Unsupervised Visual Representation Learning by Context Prediction"}, {"paperId": "dfbfaaec46d38392f61d683c340ee92a0a66e5d9", "title": "Learning to See by Moving"}, {"paperId": "5aa26299435bdf7db874ef1640a6c3b5a4a2c394", "title": "FaceNet: A unified embedding for face recognition and clustering"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "9667f8264745b626c6173b1310e2ff0298b09cfc", "title": "Learning Deep Features for Scene Recognition using Places Database"}, {"paperId": "1938624bb9b0f999536dcc8d8f519810bb4e1b3b", "title": "On Using Very Large Target Vocabulary for Neural Machine Translation"}, {"paperId": "081651b38ff7533550a3adfc1c00da333a8fe86c", "title": "How transferable are features in deep neural networks?"}, {"paperId": "82a8210b4c46cb5d4b03aa9c975a4376425fb8cd", "title": "Notes on Noise Contrastive Estimation and Negative Sampling"}, {"paperId": "a6fd96a900d4130940b488863b71fd09ad41ccb9", "title": "Discriminative Unsupervised Feature Learning with Convolutional Neural Networks"}, {"paperId": "dd2cf76ae78a3262a094ac865aa9f60c55472c5d", "title": "Depth Map Prediction from a Single Image using a Multi-Scale Deep Network"}, {"paperId": "5f5dc5b9a2ba710937e2c413b37b053cd673df02", "title": "Auto-Encoding Variational Bayes"}, {"paperId": "2319a491378867c7049b3da055c5df60e1671158", "title": "Playing Atari with Deep Reinforcement Learning"}, {"paperId": "53ca064b9f1b92951c1997e90b776e95b0880e52", "title": "Learning word embeddings efficiently with noise-contrastive estimation"}, {"paperId": "87f40e6f3022adbc1f1905e3e506abad05a9964f", "title": "Distributed Representations of Words and Phrases and their Compositionality"}, {"paperId": "e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6", "title": "Deep Canonical Correlation Analysis"}, {"paperId": "5b0d644f5c4b9880cbaf79932c0a4fa98996f068", "title": "A fast and simple algorithm for training neural probabilistic language models"}, {"paperId": "1d385429e7d8e0552824366d1f70d13781ef789f", "title": "Discriminative clustering for image co-segmentation"}, {"paperId": "e3ce36b9deb47aa6bb2aa19c4bfa71283b505025", "title": "Noise-contrastive estimation: A new estimation principle for unnormalized statistical models"}, {"paperId": "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd", "title": "Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "13b3a1e7e0bd80bf38b444ce1568213ebe98d0df", "title": "Large Scale Online Learning of Image Similarity Through Ranking"}, {"paperId": "843959ffdccf31c6694d135fad07425924f785b1", "title": "Extracting and composing robust features with denoising autoencoders"}, {"paperId": "699d5ab38deee78b1fd17cc8ad233c74196d16e9", "title": "Adaptive Importance Sampling to Accelerate Training of a Neural Probabilistic Language Model"}, {"paperId": "355d44f53428b1ac4fb2ab468d593c720640e5bd", "title": "Greedy Layer-Wise Training of Deep Networks"}, {"paperId": "8978cf7574ceb35f4c3096be768c7547b28a35d0", "title": "A Fast Learning Algorithm for Deep Belief Nets"}, {"paperId": "46f30e94dd3d5902141c5fbe58d0bc9189545c76", "title": "Dimensionality Reduction by Learning an Invariant Mapping"}, {"paperId": "78947497cbbffc691aac3f590d972130259af9ce", "title": "Distance Metric Learning for Large Margin Nearest Neighbor Classification"}, {"paperId": "cfaae9b6857b834043606df3342d8dc97524aa9d", "title": "Learning a similarity metric discriminatively, with application to face verification"}, {"paperId": "5f93423c41914639a147ad8dd589967daf2ea877", "title": "Maximum Margin Clustering"}, {"paperId": "24c287d97982216c8f35c8d326dc2ec2d2475f3e", "title": "Neighbourhood Components Analysis"}, {"paperId": "2ce5ed20ab67209cbaa4205a56e0dcd2f2a823e4", "title": "Nonlinear canonical correlation analysis by neural networks"}, {"paperId": "997dc5d9a058753f034422afe7bd0cc0b8ad808b", "title": "Signature Verification Using A \"Siamese\" Time Delay Neural Network"}, {"paperId": "7de372cae64dea5263076b5139c6b79df9e3157b", "title": "Estimating Optimal Transformations for Multiple Regression and Correlation."}, {"paperId": "90d47ab24f7db639e0fb0bc2087c10a3987117ed", "title": "Visual Learning"}, {"paperId": "45db76270416a42517a21c63a77e9c4260fa979a", "title": "Relations Between Two Sets of Variates"}, {"paperId": "6e76e29188ae8f5ff86f85945d4784b8c598b01e", "title": "DOC: Improving Long Story Coherence With Detailed Outline Control"}, {"paperId": "a61e8fdff0e1bec61f4fa15503b16425717a8cb5", "title": "Improving the Generalization of Supervised Models"}, {"paperId": "5942115e923dcd5b3eae63865a59c05160ad1ad7", "title": "The Close Relationship Between Contrastive Learning and Meta-Learning"}, {"paperId": "75b589d3f7199154b77d6680866366a38f0608a6", "title": "Exploring the Gap between Collapsed & Whitened Features in Self-Supervised Learning"}, {"paperId": "b65daf36711e458696e91613fd65ea35d09c85c8", "title": "Guillotine Regularization: Improving Deep Networks Generalization by Removing their Head"}, {"paperId": "f40aeae3e522ada1f6a9f326841b01ef5c8657b6", "title": "Unifying Language Learning Paradigms"}, {"paperId": "bac5eaf383ca247479ca12f98bddd1e4c2d2e7c2", "title": "Unifying Visual Contrastive Learning for Object Recognition from a Graph Perspective"}, {"paperId": "219b1a41676d6117b35e21e12a89d307f9b84101", "title": "$\\alpha$-ReQ : Assessing Representation Quality in Self-Supervised Learning by measuring eigenspectrum decay"}, {"paperId": null, "title": "ffcv. https: //github.com/libffcv/ffcv/, 2022"}, {"paperId": null, "title": "xformers: A modular and hackable transformer modelling library"}, {"paperId": "6a3f1c69901a6568badf1a5a9930283f83f5bc0e", "title": "Beyond Target Networks: Improving Deep Q-learning with Functional Regularization"}, {"paperId": "fca84e07d2bd15f3ba235903f49a438df5500a20", "title": "InfoNCE is a variational autoencoder"}, {"paperId": null, "title": "Data augmentation for metalearning"}, {"paperId": "1be6ddac2e262ff915c9fc2eacbf615082240219", "title": "VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain"}, {"paperId": null, "title": "Electra: Pre-training text encoders as discriminators rather than generators"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Deep graph infomax, 2018"}, {"paperId": "6c11626ae08706e6185fceff0a6d05e4bfd6bd06", "title": "Unsupervised Learning of Visual Representations using Videos"}, {"paperId": null, "title": "Proximal algorithms. Foundations and trends\u00ae in Optimization"}, {"paperId": "798d9840d2439a0e5d47bcf5d164aa46d5e7dc26", "title": "Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks"}, {"paperId": "6b388f0151ab37adb3d57738b8f52a3f943f86c8", "title": "Quick Training of Probabilistic Neural Nets by Importance Sampling"}, {"paperId": "e112eac922a50b200c768e1bc769705a9da49af1", "title": "Overview of Supervised Learning"}, {"paperId": "bcaf73e6389261da6f2fdf88b20b17f4fc2add90", "title": "Ieee Transactions on Pattern Analysis and Machine Intelligence 1 Discriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks"}, {"paperId": null, "title": "Where are we in the search for"}, {"paperId": null, "title": "Fairscale: A general purpose modular pytorch library for high performance and large scale training"}]}