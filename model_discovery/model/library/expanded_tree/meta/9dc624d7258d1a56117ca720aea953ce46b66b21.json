{"paperId": "9dc624d7258d1a56117ca720aea953ce46b66b21", "abstract": "The quadratic computational and memory complexities of large Transformers have limited their scalability for long document summarization. In this paper, we propose Hepos, a novel efficient encoder-decoder attention with head-wise positional strides to effectively pinpoint salient information from the source. We further conduct a systematic study of existing efficient self-attentions. Combined with Hepos, we are able to process ten times more tokens than existing models that use full attentions. For evaluation, we present a new dataset, GovReport, with significantly longer documents and summaries. Results show that our models produce significantly higher ROUGE scores than competitive comparisons, including new state-of-the-art results on PubMed. Human evaluation also shows that our models generate more informative summaries with fewer unfaithful errors.", "venue": "North American Chapter of the Association for Computational Linguistics", "year": 2021, "citationCount": 180, "influentialCitationCount": 34, "openAccessPdf": {"url": "https://aclanthology.org/2021.naacl-main.112.pdf", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "Hepos, a novel efficient encoder-decoder attention with head-wise positional strides to effectively pinpoint salient information from the source is proposed, able to process ten times more tokens than existing models that use full attentions."}, "embedding": {"model": "specter_v2", "vector": [-0.05769922584295273, 0.5921586155891418, -0.6806893348693848, 0.13046596944332123, -0.731205940246582, -0.19223356246948242, 0.6282667517662048, 0.6280056238174438, -0.3640078604221344, 0.12050510197877884, 1.3629980087280273, 0.49714115262031555, 0.04474824294447899, 0.3196364939212799, -0.04238295182585716, 0.01824336126446724, -0.7927801012992859, 0.16772454977035522, 0.06933815777301788, -0.05608569458127022, 0.6705836057662964, -0.9508512616157532, -0.6361020803451538, 0.09586209058761597, 0.9012843370437622, -0.0634431391954422, 0.11400711536407471, 0.9859630465507507, -0.41620054841041565, 0.448973149061203, 0.1450958400964737, -0.2247362583875656, -0.3934427797794342, -0.331642210483551, -0.7828646302223206, -0.5084913969039917, 0.46901583671569824, -0.2880344092845917, -0.04278478026390076, 0.8193925023078918, -0.006124509032815695, -0.060850296169519424, 0.656840980052948, -0.18631762266159058, -0.5679833292961121, 1.3451406955718994, 0.44327110052108765, 0.8193565011024475, 0.4809887707233429, -0.7301598787307739, 1.5979909896850586, -1.3928890228271484, 0.5753263831138611, 1.2996225357055664, 0.4531403183937073, 0.10610677301883698, 0.08030451834201813, -0.23326294124126434, 0.697433590888977, 0.3874419927597046, -0.9038535356521606, -0.7310752272605896, 0.14353707432746887, -0.09134524315595627, 1.9374709129333496, -0.24630342423915863, -0.11202118545770645, 0.07704398036003113, 0.13080383837223053, 1.6505773067474365, -0.6278798580169678, -0.6531315445899963, -0.203579381108284, -0.0742042064666748, 0.7794128060340881, 0.6209014058113098, -0.19097185134887695, -0.34704428911209106, -0.9144744873046875, -0.04676106944680214, -0.10538669675588608, -0.22519972920417786, -0.31821686029434204, 0.036719780415296555, -0.41300109028816223, 0.3732444643974304, 0.42716366052627563, 0.747564971446991, -0.7978494763374329, 0.4311026334762573, 0.5990392565727234, 0.05501590669155121, 0.029281076043844223, 0.6056662201881409, 0.3625403940677643, 0.27789306640625, -0.9617294073104858, 0.4078698754310608, -0.10442572087049484, 1.1186023950576782, -0.23992256820201874, 0.26253509521484375, -1.1430997848510742, 0.10631801933050156, 1.0013880729675293, -0.031326405704021454, 0.3582702577114105, -0.6607482433319092, 0.002203086856752634, -0.3706984519958496, 0.3596974313259125, -0.8581076860427856, -0.3552844822406769, -0.22789333760738373, -0.7557953596115112, -1.1975864171981812, -0.6502524614334106, 0.3275488615036011, -0.24057912826538086, 0.4770708382129669, -0.13957825303077698, -0.1912430226802826, 0.05056147649884224, 0.35980451107025146, 1.0876878499984741, 0.7158182263374329, 0.34455448389053345, -0.496130108833313, 1.1346588134765625, -0.8826073408126831, -1.0904996395111084, -0.825812041759491, 0.8162583708763123, -0.28715381026268005, -0.11407916992902756, -0.10673166066408157, -1.50032377243042, -0.6931093335151672, -0.8689894080162048, -0.4288300573825836, -0.45368462800979614, 0.2466379553079605, 0.48810526728630066, -0.18025535345077515, -0.9149063229560852, 0.8455222845077515, -0.10088004916906357, -0.4318787455558777, 0.46982473134994507, -0.10448332130908966, 0.4033433198928833, -0.2376774400472641, -1.0365803241729736, 0.20414376258850098, 0.08918598294258118, -0.7449868321418762, -0.0013307689223438501, -0.6130698323249817, -1.1400812864303589, 0.27075982093811035, 0.5025221109390259, -0.7987212538719177, 1.1015995740890503, 0.29299598932266235, -1.0429223775863647, 0.25353723764419556, -0.689182698726654, 0.012053863145411015, 0.033569883555173874, -0.5833874344825745, -0.2881469130516052, 0.14872537553310394, 0.40927746891975403, 0.40387779474258423, 0.2595985233783722, 0.11982361972332001, -0.2687791883945465, 0.037976279854774475, -0.42754343152046204, -0.16872906684875488, -0.28526774048805237, 1.2726176977157593, -0.48361337184906006, -0.2034182995557785, 0.14409971237182617, 1.0875749588012695, 0.1036142110824585, -0.7188534736633301, -0.8664717078208923, -1.376846194267273, 0.4175429046154022, -0.015225952491164207, 1.5207306146621704, -0.561919093132019, -0.48127689957618713, -0.6395320296287537, 0.11074128746986389, 0.13071279227733612, -0.617918074131012, 0.5924071073532104, -0.3996467590332031, 0.5389739871025085, -0.1504473239183426, -0.8207706809043884, 0.006455063819885254, -0.6685695648193359, -0.49335020780563354, -0.05235140025615692, 0.17904125154018402, 1.2633881568908691, -1.2488622665405273, -0.22266781330108643, -0.28087979555130005, 0.19830511510372162, -0.8288249969482422, 0.9296540021896362, -0.2703227698802948, 0.03724396228790283, -0.39967235922813416, -0.07445231825113297, 0.162863090634346, -0.2794019877910614, -0.014320328831672668, -0.46774905920028687, -0.5989431142807007, 0.6277761459350586, -0.3368111848831177, 1.156280755996704, 0.41988056898117065, 0.5277550220489502, -0.09726472198963165, -0.5067991614341736, -0.013501212932169437, 0.4484827220439911, 0.028319936245679855, -0.4424384534358978, 0.21868884563446045, 0.05410705879330635, -1.250262975692749, -0.15021122992038727, 0.9886326789855957, 1.3123706579208374, -0.6329808831214905, 0.19102951884269714, 0.4173021912574768, 0.01614646427333355, 0.8796166777610779, 0.9075648188591003, 0.8386231064796448, 0.2542703449726105, 0.9048863053321838, -0.2098020315170288, 0.3769778907299042, -0.14933113753795624, 0.16273139417171478, 0.4711478650569916, 0.6990554332733154, 0.9222338795661926, 0.582453191280365, -0.6188631653785706, -0.4930684268474579, 0.4345196783542633, 0.7473407983779907, 1.1694153547286987, -0.009573720395565033, -0.7151932120323181, -0.9436395168304443, -0.38978779315948486, -0.551085889339447, 0.3255510628223419, -0.3366280496120453, -0.28637900948524475, -0.6246640086174011, -0.7510801553726196, 0.9005080461502075, 0.6003069281578064, 0.7868025302886963, -0.5365489721298218, -0.6395143866539001, -0.03389734774827957, -0.17685316503047943, -0.5006436109542847, -0.8681294918060303, 0.18454629182815552, -0.28797948360443115, -0.3707193434238434, -0.38109827041625977, -0.1627720594406128, 0.1585218608379364, -0.40959620475769043, 1.210145354270935, -0.45610907673835754, -0.21981345117092133, 0.20114636421203613, 0.4021078646183014, -0.9983119368553162, -0.38486021757125854, 0.18805968761444092, 0.13420070707798004, -0.5504186749458313, 0.4667254686355591, 0.7680886387825012, -0.23867899179458618, 0.003367775585502386, -0.3494090437889099, -0.14684225618839264, 0.08515452593564987, 0.26994454860687256, 0.6263976097106934, -0.04572472721338272, 0.4840821623802185, -1.0084419250488281, 1.0875587463378906, -0.037673186510801315, -0.06135586276650429, 0.14449207484722137, -0.7666341662406921, -0.3576023578643799, 0.4016799330711365, -0.20268675684928894, -0.41379067301750183, -1.1860343217849731, 0.45011621713638306, 0.1880248785018921, -0.09966723620891571, 0.6066160202026367, 0.1373254358768463, 0.6067959666252136, 0.3709008991718292, 0.33829763531684875, 0.033997029066085815, -0.20946460962295532, 0.42838025093078613, -0.36789414286613464, 1.0270594358444214, 0.749123215675354, -0.21608054637908936, -0.31309494376182556, -0.2912779152393341, -0.9742909073829651, -0.3200879991054535, -0.6387361884117126, -0.2914646863937378, 0.019579153507947922, 0.158004492521286, -0.5091761350631714, -0.6327129602432251, -0.1710767298936844, -1.514370083808899, 0.05398625507950783, -0.251596599817276, -0.307489275932312, 0.006322998553514481, -0.6810743808746338, -0.8305010795593262, -0.5211321115493774, -1.0440210103988647, -0.6293071508407593, 0.5523771643638611, 0.360208123922348, -1.0128235816955566, -0.11071968823671341, 0.3563137948513031, -0.7327587604522705, 0.6958498358726501, -0.2361062616109848, 0.36264780163764954, -0.06077034771442413, -0.21038295328617096, -0.49652019143104553, 0.020830776542425156, 0.06810925900936127, -0.2519344091415405, 0.14882048964500427, -0.21315644681453705, 0.3017154037952423, -0.2550317347049713, 0.05305090174078941, 0.6208421587944031, 0.7541561722755432, 0.3889329433441162, -0.2983275353908539, -0.7417947053909302, -0.1636558175086975, 0.9328461289405823, -0.7182213068008423, 0.19042204320430756, 0.22732184827327728, 0.9166433215141296, 0.35778722167015076, 0.2395387589931488, 0.6956794261932373, 0.5009225606918335, 0.23122119903564453, 0.22396747767925262, -0.25967878103256226, -0.31963759660720825, -0.3593946099281311, 0.44750916957855225, 1.3508846759796143, 0.07009340077638626, -0.38024696707725525, -0.712807297706604, 1.0441533327102661, -1.1848169565200806, -0.9717484712600708, 0.08832836151123047, 0.5983447432518005, 0.2101956307888031, -0.7168317437171936, -0.16815675795078278, -0.10877185314893723, 0.4703082740306854, 0.21708831191062927, -0.3726775348186493, -0.5544939041137695, -0.0988992229104042, 0.08552226424217224, 0.28248679637908936, 0.5585618019104004, -0.32511457800865173, 0.6968111395835876, 15.0111083984375, 0.290578693151474, 0.2873243987560272, 0.2244160771369934, 0.27812421321868896, 0.07001512497663498, -0.2481565624475479, -0.049556929618120193, -1.0841178894042969, -0.11096750199794769, 1.077501654624939, -0.30598723888397217, -0.040255796164274216, -0.03613334149122238, 0.45666491985321045, -0.0609842874109745, -0.6636376976966858, 0.4603535234928131, 0.7276416420936584, -1.2089591026306152, 0.32613250613212585, 0.1846444308757782, 0.20459844172000885, 0.29094067215919495, 0.5845587253570557, 0.5417218208312988, 0.31313374638557434, -0.05705156549811363, 0.36162838339805603, 0.5269078016281128, 0.6952675580978394, -0.4315190613269806, 0.6818023324012756, 0.1772805154323578, -0.5671016573905945, -0.36229047179222107, -0.7575744986534119, -0.788381814956665, 0.555904746055603, 0.315578818321228, -0.6596020460128784, -0.11916989088058472, -0.15063151717185974, 0.8873628377914429, -0.12644056975841522, 0.88133305311203, -0.3294578194618225, 0.4441767632961273, 0.2772127687931061, -0.2896779775619507, 0.28591597080230713, 0.7476714253425598, 0.6825510859489441, 0.4396272897720337, 0.1688109040260315, 0.29467248916625977, -0.21447792649269104, 0.35270899534225464, -0.41394907236099243, 0.18699204921722412, -0.4169769883155823, -0.3440665900707245, 0.13013848662376404, 0.5559516549110413, 0.6541702747344971, -0.09539028257131577, 0.03277409076690674, 0.2745160758495331, 0.26815545558929443, 0.016852954402565956, -0.055675018578767776, -0.8449052572250366, 0.0021264723036438227, -0.17535220086574554, -0.05994640290737152, 0.7239370346069336, -0.2742253243923187, -0.3338385224342346, -0.8575582504272461, -0.07605574280023575, 0.7065258026123047, -0.7983519434928894, -0.25207915902137756, 0.7352956533432007, -0.16017630696296692, -0.6055082678794861, 0.03463587164878845, -0.3000926077365875, -0.7451854348182678, 0.22885678708553314, -1.236141324043274, -0.4789718985557556, 0.06459572166204453, -0.6211259961128235, -0.1609273999929428, 0.14805838465690613, 1.2125282287597656, -0.12942376732826233, -0.5458789467811584, -0.12346884608268738, 0.13851027190685272, -0.4626520574092865, 0.31107696890830994, -1.0304697751998901, 0.42684659361839294, 0.5744665265083313, -0.5378789305686951, 0.5663713216781616, 0.3923904001712799, -0.14269672334194183, -0.955639660358429, -0.0301195178180933, 1.0574771165847778, -1.083186388015747, -0.835528552532196, -0.24253365397453308, -1.21670401096344, 0.12169431149959564, 0.9748129844665527, -0.536973774433136, 0.23406533896923065, 0.16869746148586273, 0.15643136203289032, 0.21100778877735138, -0.8516002297401428, -0.11267267167568207, 0.40248680114746094, -0.3667474687099457, -0.6887808442115784, -0.14530804753303528, 0.5096716284751892, -0.8287652730941772, -0.23933884501457214, -0.5067818760871887, -0.035953179001808167, 0.14696577191352844, 0.9260088205337524, -0.37600991129875183, 0.8730416893959045, 0.5921415686607361, 0.5210815072059631, -1.0213412046432495, -0.5882179141044617, -0.9641736149787903, -0.3186277449131012, 0.6729633808135986, 0.39939162135124207, -0.08329876512289047, -0.06657609343528748, 0.8648249506950378, -0.10937706381082535, -0.21498724818229675, -0.4502771198749542, -0.054542358964681625, 0.050895486027002335, 0.1260015070438385, 0.4429803490638733, -0.04379979521036148, 0.6310856342315674, 0.37777042388916016, 0.5496435761451721, 0.5585634112358093, 0.036582957953214645, -0.6962174773216248, 0.5478010177612305, -0.4258732497692108, 0.7996149063110352, -1.0446555614471436, -0.2799781560897827, -1.3211053609848022, -0.2064990997314453, -0.7409719228744507, 0.1384948492050171, -1.6469569206237793, -0.1749705970287323, 0.7074551582336426, -0.2251976728439331, 0.08974526822566986, -0.11845779418945312, -0.5466723442077637, -0.9671608209609985, -0.5916634798049927, -1.2800830602645874, 0.6697248816490173, 0.7663884162902832, -1.04832124710083, -0.2951148450374603, -0.5143623352050781, -0.7561923265457153, 0.32542651891708374, 0.26877713203430176, -0.5430935621261597, -0.21196460723876953, -1.298497200012207, 0.3604881763458252, -0.2398197054862976, -0.1300661563873291, -0.3966187834739685, 1.0019843578338623, 0.5907557606697083, 0.05989842489361763, -0.6853052377700806, -0.2911061644554138, -0.34081581234931946, -0.6931251287460327, 0.12373537570238113, -0.8806694149971008, 0.18856456875801086, 0.12303729355335236, -0.46457111835479736, -0.3026466369628906, 0.5737854242324829, -0.1824987530708313, -1.1045138835906982, -0.5850985050201416, 0.2028031349182129, -0.6346693634986877, 0.17524194717407227, -0.454208105802536, -0.16341160237789154, -1.2453056573867798, -0.3180306851863861, 0.3001237213611603, 0.8399966359138489, -0.3789474070072174, 0.9339501857757568, 0.3543858826160431, -1.024689793586731, -0.28765952587127686, 0.12095481157302856, 0.017150791361927986, 0.08982574194669724, 0.6875537633895874, 0.40814265608787537, -0.08297816663980484, 0.7617791891098022, 0.3751579523086548, 0.15565693378448486, -0.9207801818847656, 0.2853027880191803, 0.051835909485816956, -0.4436362087726593, -0.41688552498817444, 0.7664304971694946, -0.41147199273109436, -0.3663055896759033, 0.030254680663347244, -1.0478061437606812, -1.1054165363311768, 0.25865355134010315, 1.384605050086975, 0.7696750164031982, -0.21897973120212555, -0.35325905680656433, -0.784450888633728, 0.2744147777557373, -0.30763155221939087, -0.23322385549545288, 0.9770311117172241, -0.5203738212585449, -0.4211581349372864, 0.1360219269990921, 0.5858128666877747, -0.34621959924697876, -0.08631192892789841, -0.5566281676292419, -0.10616987198591232, 0.07950913906097412, 0.7351858615875244, -0.415331095457077, -0.019288964569568634, 0.7253634333610535, 0.2586110234260559, 0.5358718037605286, 0.19727186858654022, 0.053918298333883286, 0.05920710042119026, 0.544373631477356, -0.3143657445907593, -0.8603593707084656, -0.5369329452514648, 1.2082600593566895, 1.6261873245239258, -0.7182349562644958, 0.5784273147583008, 0.1714814305305481, -0.8562044501304626, 0.8361384272575378, 0.013416844420135021, 0.1841752678155899, 0.32288533449172974, -0.4509465992450714, -0.15730158984661102, -0.2994175851345062, -0.8163127303123474, -0.061488114297389984, 0.6930926442146301, 0.9507193565368652, 0.8597480654716492, 0.038167886435985565, -0.24616892635822296, 1.1454026699066162, 0.4048195481300354, 0.44259071350097656, 0.8288870453834534, 0.3120359480381012, -0.3149641752243042, 0.10504275560379028, 0.08052342385053635, 0.29208216071128845, -0.7925901412963867, -0.34000107645988464, -0.22768814861774445, 0.14478065073490143, -0.13570989668369293, 0.7082973718643188, 0.6673968434333801, 0.5987443327903748, 0.6868481040000916, 0.19786560535430908, 0.06384436786174774, -0.6322526931762695, -0.2637147009372711, 0.06590384989976883, -0.2893281579017639, -0.20001237094402313, -0.2413780689239502, -0.9165520668029785, -0.567296028137207, 0.015980899333953857, -0.06333336234092712, 0.29782360792160034, 0.3101775348186493, 0.9394888281822205, 1.059921145439148, 0.8572520017623901, -0.42375293374061584, -0.5300213694572449, -0.3228231966495514, -1.16170334815979, -0.05403038486838341, -0.661146879196167, 0.17810748517513275, -0.21456053853034973, 0.05471566691994667, -0.22604316473007202]}, "authors": [{"authorId": "2111132245", "name": "L. Huang"}, {"authorId": "6333082", "name": "Shuyang Cao"}, {"authorId": "147697560", "name": "Nikolaus Nova Parulian"}, {"authorId": "2113323573", "name": "Heng Ji"}, {"authorId": "2153516659", "name": "Lu Wang"}], "references": [{"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "222dcbf5ee19fdfc9cfbd9c75af168a5c2122a4a", "title": "A Joint Neural Model for Information Extraction with Global Features"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "ca7c9542d74e842610c208ddee6bbe659b1f13c9", "title": "SEAL: Segment-wise Extractive-Abstractive Long-form Text Summarization"}, {"paperId": "11b6d1fee0f47a8f9f892ab0d86f370c449097aa", "title": "FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization"}, {"paperId": "dbeeca8466e0c177ec67c60d529899232415ca87", "title": "On Faithfulness and Factuality in Abstractive Summarization"}, {"paperId": "20a3ab365ad179dcb0dc19c5dbcdede772a2bcb8", "title": "HipoRank: Incorporating Hierarchical and Positional Information into Graph-based Unsupervised Long Document Extractive Summarization"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "d36e39aedd802aea4be1ea303c70dc56e97dbc3c", "title": "Asking and Answering Questions to Evaluate the Factual Consistency of Summaries"}, {"paperId": "01b15017ac59b8d6f2ce3598c4a7d6358c211426", "title": "A Divide-and-Conquer Approach to the Summarization of Long Documents"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f4061bd225b3be5b3f5b18eb1a229ce991efefeb", "title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "0c5598424cc96d8fb500eb553cb7969f86a0ede0", "title": "Evaluating the Factual Consistency of Abstractive Text Summarization"}, {"paperId": "edc90c96bc3b18ad73815db01795be92d0300417", "title": "BillSum: A Corpus for Automatic Summarization of US Legislation"}, {"paperId": "193b92b2c703dff93fbb0d58070fd2b7651ab3f3", "title": "Extractive Summarization of Long Documents by Combining Global and Local Context"}, {"paperId": "63748e59f4e106cbda6b65939b77589f40e48fcb", "title": "Text Summarization with Pretrained Encoders"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "40345901fd28cbf65791c34671db6548b1089ed4", "title": "BIGPATENT: A Large-Scale Dataset for Abstractive and Coherent Summarization"}, {"paperId": "d5fdc7aa21ec15d6cb6d7b0798d4f5191642297c", "title": "Question Answering as an Automatic Evaluation Metric for News Article Summarization"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "918d668556938b8cb45f257773b01d50eaba0586", "title": "PubTator central: automated concept annotation for biomedical full text articles"}, {"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "512b8ef0002e0bfd0ecb5ab17d533c1762eb9786", "title": "Set Transformer"}, {"paperId": "7af89df3691d8c33aaf1858f7cc51da1bc9549a9", "title": "Bottom-Up Abstractive Summarization"}, {"paperId": "4e346eb1628df6a12c1a121f862fb3a16c6fec60", "title": "Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies"}, {"paperId": "54a13bcc9613dcaa76fb25fbe96572f376cfcca9", "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost"}, {"paperId": "853d4d94651c6d9f8ed4d114e1eb21f15f786daa", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents"}, {"paperId": "05b1127ee39504516009b25384ca2bd7f2e1b9d9", "title": "Deep Communicating Agents for Abstractive Summarization"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "87fd3b3ff82efa6cc5fb8be78d95624f6aefad4e", "title": "Automatic patent document summarization for collaborative knowledge systems and services"}, {"paperId": "036c70cd07e4a2024eb71b2b1e0c1bc872cff107", "title": "Scientific Paper Summarization Using Citation Summary Networks"}, {"paperId": "7895109f3ed4b005a5dab2770c67cd13cbc6c72f", "title": "Explorations in Automatic Book Summarization"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "70bd5db2677a60bf14b4808d8319fd6022d2c78e", "title": "Regression Analysis"}, {"paperId": null, "title": "2020b. Cord-19: The covid-19 open research dataset. ArXiv"}, {"paperId": null, "title": "Linformer: Selfattention with linear complexity"}, {"paperId": "5665805becad6c87b194b260f2270d86d560bd3f", "title": "On Extractive and Abstractive Neural Document Summarization with Transformer Language Models"}, {"paperId": null, "title": "Experiment Details FactCC Training Data Construction. Kryscinski et al. (2020) generate training data by applying rule-based transformations to sentences"}, {"paperId": null, "title": "Ef\ufb01cient"}, {"paperId": null, "title": "Rethinking attention with per-formers"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing"}, {"paperId": "230b3e73b581704986a404510bcc3c91826f4e03", "title": "Movie Script Summarization as Graph-based Scene Extraction"}, {"paperId": null, "title": "Genia event extraction (genia)"}, {"paperId": "6f446441441ce26bb410be56e4cdf99e57d84bf2", "title": "48th Annual Meeting of the Association for Computational Linguistics"}, {"paperId": null, "title": "multilingual"}, {"paperId": "3508f24d073c6eb068c740bbc1cfd65b61dd9b6e", "title": "Applied Regression Analysis"}, {"paperId": null, "title": "Model with truncated input generates fabricated facts. Our HEPOS encoder-decoder attention with LSH encoder attention are more faithful for the aspect of \"results"}, {"paperId": null, "title": "10% of the shortest reports"}, {"paperId": null, "title": "remove the reports that do not have cover pages, as our rules are constructed for documents with then. We"}, {"paperId": null, "title": "the PDF \ufb01les to HTML using PDFMiner 6 . We then parse the HTML into text into sections and paragraphs with handcrafted parsing rules"}, {"paperId": null, "title": "section, since these are common patterns of incorrectly parsed documents"}]}