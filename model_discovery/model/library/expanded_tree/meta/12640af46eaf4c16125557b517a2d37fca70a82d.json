{"paperId": "12640af46eaf4c16125557b517a2d37fca70a82d", "abstract": "Transformer architectures are now central to sequence modeling tasks. At its heart is the attention mechanism, which enables effective modeling of long-term dependencies in a sequence. Recently, transformers have been successfully applied in the computer vision domain, where 2D images are first segmented into patches and then treated as 1D sequences. Such linearization, however, impairs the notion of spatial locality in images, which bears important visual clues. To bridge the gap, we propose ripple attention, a sub-quadratic attention mechanism for vision transformers. Built upon the recent kernel-based efficient attention mechanisms, we design a novel dynamic programming algorithm that weights contributions of different tokens to a query with respect to their relative spatial distances in the 2D space in linear observed time. Extensive experiments and analyses demonstrate the effectiveness of ripple attention on various visual tasks.", "venue": "International Conference on Machine Learning", "year": 2021, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work designs a novel dynamic programming algorithm that weights contributions of different tokens to a query with respect to their relative spatial distances in the 2D space in linear observed time, and demonstrates the effectiveness of ripple attention on various visual tasks."}, "embedding": {"model": "specter_v2", "vector": [0.0526592992246151, 0.33802658319473267, -0.4704238772392273, -0.06451790034770966, -0.2510501742362976, 0.5148285031318665, 0.3983740508556366, 0.029693085700273514, -0.4494543969631195, -0.9557995200157166, 0.37301233410835266, 0.6688830852508545, 0.2287464439868927, -0.002960640238597989, -0.19571244716644287, 0.131062313914299, -1.2042522430419922, 0.2427069991827011, 0.8419193625450134, -0.2214767336845398, 0.063991978764534, -0.29610729217529297, -1.6235030889511108, 0.6395852565765381, 0.15279921889305115, 1.0239754915237427, 0.6145641207695007, 1.0844591856002808, -0.21895922720432281, 0.437281996011734, 0.6470158696174622, 0.17832955718040466, 0.33600541949272156, 0.23208384215831757, -0.2727188766002655, -0.039543118327856064, 0.7648933529853821, -0.34920090436935425, -0.8569067716598511, 0.7468752861022949, -0.11787562072277069, 0.47412049770355225, 0.49533721804618835, -0.5469024181365967, -0.6003965139389038, 0.12031760811805725, 0.29241034388542175, 0.908258318901062, -0.08985228836536407, -0.7280203700065613, 1.3844549655914307, -1.3471686840057373, 0.39383313059806824, 1.6713910102844238, 0.4356035888195038, 0.17004820704460144, -0.2589985430240631, 0.06360757350921631, 1.0272821187973022, 0.8323714137077332, -0.9158192873001099, -0.21879789233207703, -0.08563505113124847, -0.4431694746017456, 1.5497511625289917, -0.4378499686717987, 0.18568956851959229, 0.08987407386302948, 0.26239630579948425, 1.5115858316421509, 0.0732070803642273, -1.059443473815918, -0.16846436262130737, -0.09967867285013199, 0.2853926420211792, 0.9245327711105347, -0.561389684677124, 0.47970929741859436, -1.4030932188034058, 0.2651136517524719, 0.4342435598373413, -0.08513779938220978, 0.1713070273399353, -0.5069339871406555, 0.08591237664222717, 0.4046642482280731, 0.7820238471031189, 0.31400513648986816, -0.51015704870224, 0.9778774380683899, 0.4874075651168823, 0.052037015557289124, -0.2510012090206146, 0.004482930060476065, 0.4728219509124756, 0.4709058403968811, -0.2831685245037079, 0.2003282606601715, -0.3257597088813782, 0.8987603783607483, 0.054330773651599884, -0.07008729130029678, -0.5246362686157227, 0.37540873885154724, 1.3286081552505493, 0.04007976874709129, 0.2223203033208847, -0.24278685450553894, -0.33743539452552795, -0.710595428943634, 0.2549954950809479, -1.4512519836425781, -0.06524647027254105, 0.19944806396961212, -0.3882873058319092, -0.39831259846687317, -0.5202276706695557, 1.0023435354232788, -1.0825793743133545, 0.1477961540222168, -0.3004434406757355, -0.0826244056224823, -0.7496278882026672, 0.7390884757041931, 0.12251176685094833, 0.5207859873771667, 0.426852285861969, 0.4602932035923004, 1.2033119201660156, -0.9479478001594543, -0.3346695601940155, -0.5589125156402588, -0.01828395575284958, -0.08592277020215988, 0.4993191361427307, -0.3018762171268463, -0.9752544164657593, -1.371954083442688, -0.8212704062461853, -0.006971360649913549, -0.753509521484375, 0.023754728958010674, 0.867706298828125, -0.06423968076705933, -1.1452432870864868, 0.7798730134963989, -0.6253511309623718, -0.2634526491165161, 0.8062620162963867, 0.11839807033538818, 0.2844586670398712, -0.4762648046016693, -0.959610104560852, 0.43125244975090027, 0.09047264605760574, -0.6485369801521301, -0.6094703078269958, -0.6750466823577881, -1.196485161781311, 0.020093074068427086, 0.14978809654712677, -0.4266679883003235, 0.9512172341346741, -0.3038654327392578, -0.6849703192710876, 0.7861567735671997, -0.4477033019065857, -0.0007715110550634563, 0.0013968850253149867, -0.29833945631980896, -0.21371176838874817, -0.06448786705732346, -0.2535059452056885, 0.6275926828384399, 0.6275085806846619, -0.2815525531768799, -0.5626914501190186, -0.013086352497339249, -0.2683618664741516, -0.05471496656537056, -0.41462478041648865, 0.9151222705841064, -0.5659407377243042, -0.36280256509780884, 0.1997767835855484, 0.5731045007705688, -0.1318068951368332, 0.11209778487682343, 0.025468911975622177, -1.047295331954956, 0.8715904951095581, 0.15942597389221191, 0.6748555898666382, -0.9707520008087158, -0.6462914347648621, -0.189658984541893, 0.0965672954916954, -0.2198360562324524, -0.8601201772689819, 0.5965372323989868, -0.2950691878795624, 0.2495480626821518, 0.03018631413578987, -0.905108630657196, 0.16071751713752747, -0.42097556591033936, -0.5825396180152893, 0.021797990426421165, 0.07825575768947601, 1.1368167400360107, -1.12148916721344, 0.014457815326750278, 0.011907600797712803, 0.09312865138053894, -0.6044454574584961, 1.1927025318145752, -0.5110822319984436, -0.3274429738521576, 0.06775671243667603, 0.21171188354492188, 0.3751961886882782, -0.2825770676136017, 0.20185312628746033, -0.6849303841590881, 0.00033968326169997454, 0.2538922131061554, -0.014978072606027126, 1.1206226348876953, 0.027861280366778374, 1.0348445177078247, -0.4016939103603363, -0.7442536354064941, 0.2516435384750366, -0.029371684417128563, -0.023083139210939407, -0.8773882985115051, -0.1429128348827362, -0.15478767454624176, -0.9518564939498901, -0.05573718249797821, 0.7862966060638428, 1.1269546747207642, -0.40760982036590576, -0.009978927671909332, 0.24211546778678894, -0.22187422215938568, 0.1617642045021057, 0.3199087679386139, 0.48910531401634216, 0.5270693898200989, 0.2755165994167328, -0.23323377966880798, -0.13575635850429535, -0.5035638809204102, -0.10720731317996979, 0.835265576839447, 0.3271334171295166, 0.8801305890083313, 0.39384034276008606, -1.3193727731704712, -0.5659855008125305, -0.11973745375871658, 0.7890362739562988, 1.761276125907898, 0.44884249567985535, -0.2618871331214905, -0.30435383319854736, -0.30020079016685486, -0.28253594040870667, -0.5222895741462708, -0.7285973429679871, -0.2427787035703659, -0.43991518020629883, -1.034897804260254, 0.6105470061302185, 0.6701846718788147, 0.8829890489578247, -0.6799136996269226, -0.8729420900344849, -0.3842681050300598, 0.6016867160797119, -0.6569324135780334, -0.9672255516052246, 0.2820124328136444, 0.10368525981903076, -0.22012947499752045, 0.2679188549518585, -0.6244500279426575, 0.3049450218677521, -0.1744871586561203, 0.8493281006813049, -0.5997098684310913, -1.0006568431854248, 0.37689319252967834, 0.23557023704051971, -1.08668053150177, -0.12612146139144897, -0.18075522780418396, 0.16927368938922882, -0.11089280992746353, 0.656531810760498, 0.3631032109260559, -0.1983892321586609, 0.38612017035484314, -0.4567829966545105, 0.0012417890829965472, 0.1837664395570755, 0.09068433195352554, 1.158767580986023, -0.29435282945632935, 0.03288356587290764, -0.7102498412132263, 0.7758554220199585, 0.39876872301101685, -0.6005513072013855, 0.18592135608196259, -0.6301365494728088, -0.3322010040283203, 0.3419484794139862, -0.8616632223129272, -0.14367829263210297, -0.28726983070373535, 0.6796668767929077, -0.8971837162971497, -0.2960458993911743, 0.21890614926815033, 0.4388795495033264, -0.41397881507873535, 0.5232749581336975, 0.39908045530319214, 0.26373836398124695, 0.15238159894943237, 0.36343133449554443, -1.005340576171875, 0.675628662109375, 0.2288346141576767, -0.11975845694541931, 0.3809967637062073, 0.02049843780696392, -1.029333472251892, -0.3019390404224396, -0.7298214435577393, -0.5187723636627197, -0.47947216033935547, 0.26379790902137756, -0.3339402675628662, -1.0811024904251099, 0.21137310564517975, -1.1405634880065918, -0.2804449796676636, -0.15308159589767456, -0.22386322915554047, -0.5334131717681885, -0.9603576064109802, -0.9125316739082336, -0.4278974235057831, -0.2765008807182312, -0.8105725049972534, 0.12372119724750519, 0.39567509293556213, -0.1344323307275772, -0.4388258755207062, 0.16282518208026886, -0.8510341048240662, 0.944821834564209, -0.14169839024543762, 0.9861055612564087, 0.12505772709846497, -0.7918757796287537, -0.354751855134964, 0.06722564995288849, 0.36783263087272644, 0.0590561144053936, 0.02192787081003189, -0.7039883136749268, 0.5105977058410645, -0.4686536490917206, -0.23015931248664856, 0.4979306757450104, 0.6493988037109375, 0.6968468427658081, 0.12510289251804352, -0.6624078154563904, 0.1226249560713768, 1.497710108757019, -0.3122221529483795, 0.14927221834659576, 0.04846945405006409, 1.0714720487594604, 0.6539239287376404, -0.014833775348961353, 0.6522939801216125, 0.648460865020752, 0.5471615195274353, 0.5338024497032166, -0.43319883942604065, -0.7900063991546631, -0.5426854491233826, 0.01949366182088852, 1.1993048191070557, 0.16913411021232605, 0.40056943893432617, -1.225812554359436, 1.0976653099060059, -1.378733515739441, -1.1212501525878906, 0.8649172186851501, 0.7806095480918884, -0.2705947756767273, -0.4417558014392853, 0.0942745953798294, -0.8820751905441284, 0.7237155437469482, 0.5674980282783508, -0.46984386444091797, -0.3570334017276764, -0.1270798146724701, 0.1388164460659027, 0.16129429638385773, 0.720125138759613, -0.6260625720024109, 0.5227049589157104, 14.89074420928955, 0.6957839131355286, -0.25870442390441895, 0.29157745838165283, 0.5971783995628357, 0.4080737233161926, -0.3564651310443878, 0.12213163077831268, -0.9465935230255127, -0.1775556057691574, 0.7386265993118286, -0.018959298729896545, 0.35031744837760925, 0.29429683089256287, 0.028443090617656708, 0.03984721004962921, -0.6253224611282349, 0.9222543239593506, 0.7340240478515625, -1.2289999723434448, 0.36220574378967285, 0.17108820378780365, 0.13236737251281738, 0.2808866798877716, 0.8450150489807129, 0.3393527865409851, 0.2836887836456299, -0.7452486157417297, 0.590222954750061, 0.5538359880447388, 0.7552546858787537, -0.027334488928318024, -0.12737275660037994, 0.19442200660705566, -1.4157005548477173, -0.09956609457731247, -1.0555881261825562, -0.701688826084137, 0.343727707862854, -0.13429763913154602, -0.7441927194595337, -0.506348192691803, 0.12045237421989441, 0.7354836463928223, 0.072796531021595, 0.7529275417327881, 0.11197692155838013, -0.1784995049238205, -0.024814853444695473, -0.1564793735742569, 0.10747119784355164, 0.839783787727356, 0.1551721692085266, 0.25477442145347595, -0.34860357642173767, 0.19336920976638794, 0.3898891806602478, 0.11335767060518265, -0.4205174148082733, -0.1789831668138504, -0.3381953239440918, 0.03842002898454666, -0.028463736176490784, 0.468295156955719, 0.4171340763568878, 0.22474268078804016, -0.1814909428358078, 0.15149852633476257, 0.5548815131187439, -0.0813770517706871, -0.11990120261907578, -0.5200881958007812, 0.41445785760879517, -0.10543400794267654, 0.4589216411113739, 0.37087517976760864, -0.2211160659790039, -0.006405264604836702, -0.4698024392127991, -0.05981875956058502, 0.5806706547737122, -0.7272871136665344, -0.8174557089805603, 1.2850559949874878, 0.04844515770673752, -0.25199246406555176, 0.5853828191757202, -1.0005419254302979, -0.025126075372099876, 0.309973806142807, -1.1679242849349976, -0.7022342085838318, -0.2887031137943268, -0.2757687568664551, 0.07625684142112732, 0.2842440903186798, 1.224293828010559, -0.018683282658457756, 0.35679104924201965, 0.08007226139307022, -0.33949726819992065, -0.26181861758232117, -0.017120158299803734, -0.713663637638092, 0.7793891429901123, 0.16212190687656403, -0.04058648645877838, -0.12605401873588562, 0.02574107237160206, 0.23449566960334778, -0.521553635597229, 0.3292523920536041, 0.4023306667804718, -0.832316517829895, -0.596245288848877, -0.5761717557907104, -1.1482678651809692, -0.03428062051534653, 0.5230073928833008, 0.16287492215633392, 0.15744973719120026, 0.12800756096839905, -0.7363152503967285, -0.38560858368873596, -0.40860700607299805, -0.011126797646284103, 0.30102768540382385, -1.1634557247161865, -0.5234255194664001, -0.2924402356147766, 0.23696917295455933, -0.9854252934455872, -0.480208158493042, -0.2794955372810364, 0.6808330416679382, -0.3324040174484253, 1.2484675645828247, -0.7671300172805786, 0.4938093423843384, 0.42226433753967285, -0.13863027095794678, -0.6631169319152832, -0.3873586356639862, -0.7243679761886597, 0.026966480538249016, -0.2497302144765854, -0.02718309499323368, 0.08506941050291061, 0.09409990906715393, 0.6535152792930603, 0.31627967953681946, -0.6061858534812927, -0.3190181255340576, 0.026260841637849808, -0.46233588457107544, -0.6296186447143555, -0.040701065212488174, -0.28388506174087524, 0.03466698154807091, -0.16175895929336548, 0.2138059139251709, 0.7762985229492188, -0.04626554623246193, -0.3815927803516388, 0.12255638837814331, 0.03584975376725197, 0.19618329405784607, -0.6312767863273621, -1.0209293365478516, -1.7677291631698608, -0.22558996081352234, -0.6828247904777527, 0.4275769889354706, -1.0513806343078613, -0.7825993299484253, -0.021344421431422234, -0.5326113104820251, 0.10649160295724869, 0.2690143585205078, -0.4384816288948059, -0.19277836382389069, -0.3126790523529053, -0.757359504699707, 0.8758007884025574, 0.89090496301651, -0.8910489678382874, -0.06600924581289291, -0.07084595412015915, 0.05707817152142525, 0.3720998466014862, 0.12693902850151062, -0.5351085066795349, -0.6697704195976257, -1.0942294597625732, -0.0028615721967071295, -0.27914148569107056, 0.005095896311104298, -0.8657013177871704, 1.2596180438995361, 0.16063091158866882, -0.0928209200501442, -0.23901356756687164, 0.6662724614143372, -0.8044042587280273, -0.7056412696838379, 0.4200117886066437, -1.0062804222106934, 0.210255429148674, 0.2690488398075104, -0.03641542047262192, -0.48247721791267395, 0.996222198009491, 0.1889318823814392, -1.145891547203064, -1.3391278982162476, 0.7132949829101562, -0.46782386302948, -0.09468689560890198, 0.09387688338756561, -0.17565301060676575, -1.134428858757019, -0.2855566442012787, -0.25308161973953247, 0.34254568815231323, -0.33716538548469543, 0.9574477076530457, 1.074891209602356, -1.3343660831451416, 0.2213611751794815, 0.18384112417697906, 0.21517811715602875, 0.20250222086906433, 0.9669252634048462, 0.5061981081962585, -0.1935410350561142, 0.5249162912368774, -0.3247471749782562, 0.24043619632720947, -0.9620148539543152, 0.6105071306228638, 0.7092036604881287, -0.14026328921318054, -0.298090398311615, 1.0165205001831055, 0.10888908058404922, -0.3192770779132843, 0.39161497354507446, -0.8781007528305054, -0.4466000199317932, 0.05621616914868355, 1.0674854516983032, 0.2419915348291397, -0.2673468589782715, -0.09000440686941147, -0.9731939435005188, 0.552503764629364, -0.4864705204963684, -0.22069014608860016, 0.48506587743759155, -0.2012917846441269, -0.35082799196243286, 0.6174249053001404, 0.7577160000801086, -0.6240931153297424, -1.1611790657043457, -0.8865406513214111, -0.30095985531806946, -0.8447931408882141, -0.15020820498466492, 0.0697455033659935, -0.23110055923461914, 0.9060112237930298, 0.9242560863494873, 0.5296744704246521, 0.43019935488700867, 0.3676428496837616, -0.24099339544773102, 0.36762186884880066, 0.004597384948283434, -0.6027511954307556, -0.04955245926976204, 1.0129495859146118, 1.506309151649475, -0.5012871026992798, 0.2067660093307495, -0.3572418689727783, -0.7615520358085632, 1.036931037902832, 0.46137815713882446, -0.5332146286964417, 1.134725570678711, -0.30089473724365234, 0.18230465054512024, -0.03943123295903206, -1.0251259803771973, -0.45478346943855286, 1.2790652513504028, 1.8049300909042358, 0.05130346119403839, 0.260868638753891, 0.46254196763038635, 0.46025803685188293, 0.7283332943916321, -0.014384360983967781, 0.46231234073638916, 0.5324690937995911, -0.4552638530731201, 0.053797632455825806, 0.10247804969549179, 0.32800328731536865, -0.36327460408210754, -0.40242859721183777, 0.36247509717941284, 0.4486207962036133, -0.028985606506466866, 0.14826437830924988, 1.099711298942566, -0.3206016719341278, 0.8101025819778442, -0.2338288426399231, 0.5455009341239929, -0.5276816487312317, 0.09094784408807755, -0.3433719873428345, -0.8354638814926147, -0.23282946646213531, -0.6758628487586975, -0.619533896446228, -0.14765751361846924, 0.03702888637781143, 0.3564733564853668, -0.22219766676425934, 0.23293153941631317, 0.5111152529716492, 0.8735920190811157, 0.608065664768219, -0.2869279384613037, -0.595596194267273, -0.30422651767730713, -0.49298763275146484, 0.1344752162694931, -0.5258550643920898, 0.20301739871501923, -0.45215660333633423, 0.2113332599401474, 0.23934999108314514]}, "authors": [{"authorId": "1633166807", "name": "Lin Zheng"}, {"authorId": "2113794004", "name": "Huijie Pan"}, {"authorId": "47648549", "name": "Lingpeng Kong"}], "references": [{"paperId": "bb363c8c5bc1c473f0801c647c88d0c071792858", "title": "PermuteFormer: Efficient Relative Position Encoding for Long Sequences"}, {"paperId": "1cd6b0f41d62aca38ba5a69db10e79c05e618c21", "title": "Conditional DETR for Fast Training Convergence"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "7b664a306b7d2f68dd816ea1d6586cf3472d75c1", "title": "Early Convolutions Help Transformers See Better"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "94eae578e6af3382f6449506965639f18aab3fa0", "title": "Video Swin Transformer"}, {"paperId": "0d508600d77d8a7e6a655cdb6d139779732f649f", "title": "Stable, Fast and Accurate: Kernelized Attention with Relative Positional Encoding"}, {"paperId": "576c462dbc1f3d732b919ef1daac37a817123e52", "title": "ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias"}, {"paperId": "2e8149dafb864ec3675087c99bf5572fcf4eb170", "title": "RegionViT: Regional-to-Local Attention for Vision Transformers"}, {"paperId": "08ffdec40291a2ccb5f8a6cc048b01247fb34b96", "title": "Relative Positional Encoding for Transformers with Linear Complexity"}, {"paperId": "68f080e0ac836ea230cb5316fbed273c70422d75", "title": "Segmenter: Transformer for Semantic Segmentation"}, {"paperId": "2c9fdba6bf846e0986cbbf30d56b467d9e334333", "title": "ConTNet: Why not use convolution and transformer at the same time?"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "14c52ffa7ea9c1971d5d82ea369c946c98d056a9", "title": "LocalViT: Bringing Locality to Vision Transformers"}, {"paperId": "40f4d7fe800810288a80f84cdb357a8f4c28e880", "title": "Rethinking Spatial Dimensions of Vision Transformers"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "054e307c1edf4b28137ffcbce980fe81f0647d20", "title": "Finetuning Pretrained Transformers into RNNs"}, {"paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0", "title": "Incorporating Convolution Designs into Visual Transformers"}, {"paperId": "610b302950a19acef1c45456111dcd495f638c18", "title": "ConViT: improving vision transformers with soft convolutional inductive biases"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "fa08b41ccdfc5d8771adfbc34c176fa237d4646c", "title": "Is Space-Time Attention All You Need for Video Understanding?"}, {"paperId": "69621df0df837d345d764525696899e0570194b6", "title": "Fast Convergence of DETR with Spatially Modulated Co-Attention"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "6f6f73e69ee0d9d5d7d088bb882db1851d98175a", "title": "Pre-Trained Image Processing Transformer"}, {"paperId": "2ac7999cce9f415ee87643f56631b55ed26aa10e", "title": "End-to-End Video Instance Segmentation with Transformers"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "13da774fe604027bff2951ba82f4c3d9be7e415e", "title": "Augment Your Batch: Improving Generalization Through Instance Repetition"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "d14e56568dc5f57ccdae899d84f91e34ad847670", "title": "How Much Position Information Do Convolutional Neural Networks Encode?"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "1e7678467b1807777dcd9be557b79328ce9419a8", "title": "MultiGrain: a unified image embedding for classes and instances"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649", "title": "Understanding the difficulty of training deep feedforward neural networks"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "0eb36599c7e976b6e52a3693bbe30995cdbbb330", "title": "All of Nonparametric Statistics"}, {"paperId": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27", "title": "Backpropagation Applied to Handwritten Zip Code Recognition"}, {"paperId": "8b22e1751f75be137b7b210981baccc1b9ab9222", "title": "Summed-area tables for texture mapping"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "5a9bc55f6332e38f62eb509b684147a1d4f10fd9", "title": "Focal Attention for Long-Range Interactions in Vision Transformers"}, {"paperId": null, "title": "Pytorch image models"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "4cb4d685b47001652b29dc41c1b3e786277e7647", "title": "Robust Real-time Object Detection"}, {"paperId": "d5ad1fdd277219257c38df86770c9fd68f4c74f0", "title": "Natural image statistics and neural representation."}, {"paperId": "9b2541b8d8ca872149b4dabd2ccdc0cacc46ebf5", "title": "Neocognitron: A Self-Organizing Neural Network Model for a Mechanism of Visual Pattern Recognition"}]}