{"paperId": "adc61e21eafecfbf6ebecc570f9f913659a2bfb2", "abstract": "Deep learning--based models have surpassed classical machine learning--based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this article, we provide a comprehensive review of more than 150 deep learning--based models for text classification developed in recent years, and we discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and we discuss future research directions.", "venue": "ACM Computing Surveys", "year": 2020, "citationCount": 901, "influentialCitationCount": 21, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A comprehensive review of more than 150 deep learning--based models for text classification developed in recent years is provided, and their technical contributions, similarities, and strengths are discussed."}, "embedding": {"model": "specter_v2", "vector": [-0.19111287593841553, 0.5652570128440857, -0.5519812107086182, -0.5009646415710449, -0.06579525023698807, 0.06211376562714577, 0.8221984505653381, 0.19688405096530914, -0.6334723234176636, 0.023193085566163063, 0.7297825813293457, -0.008995551615953445, 0.7504966855049133, -0.26373112201690674, 0.47304463386535645, -0.06156955659389496, -0.40816161036491394, 0.3852047324180603, -0.27612826228141785, -0.6389297842979431, 0.30987223982810974, -1.0691461563110352, -0.7127286195755005, 0.4149806499481201, -0.13455338776111603, 0.8662027716636658, -0.5248860120773315, 0.7135056853294373, -1.0287187099456787, 0.8797193765640259, 0.14390216767787933, -0.875537633895874, -0.13896581530570984, -0.05936295539140701, -0.9631493091583252, 0.015998637303709984, 0.16356085240840912, -0.4716986119747162, -0.6216943264007568, 0.6469476222991943, -0.4654020071029663, 0.2245567888021469, 0.7474894523620605, -0.5542499423027039, 0.046577733010053635, 0.6855210065841675, 0.47943446040153503, 0.5670934915542603, 0.013654911890625954, -0.9987937211990356, 1.5431807041168213, -1.1233323812484741, 0.06132777780294418, 1.391645073890686, 0.8075560331344604, 0.6391711235046387, -0.2803105413913727, -0.7323870658874512, 0.6082643866539001, 0.10649779438972473, -0.650444746017456, 0.16350573301315308, 0.18353497982025146, -0.6029149293899536, 1.9623304605484009, -0.3729121685028076, -0.42296096682548523, 0.3679192066192627, 0.48674890398979187, 1.4596383571624756, 0.23693236708641052, -0.6477867364883423, -0.3044385015964508, -0.12594705820083618, 0.8427509665489197, 0.7013916969299316, -0.4806225597858429, -0.30598682165145874, -0.9894527792930603, -0.37082618474960327, -0.37037232518196106, 0.2297818511724472, -0.21928323805332184, 0.44545552134513855, -0.3075087368488312, 1.0545076131820679, 0.2147931158542633, 0.878872811794281, -0.2558918297290802, 0.4165588915348053, 0.6839780807495117, 0.5279636383056641, 0.24833370745182037, 0.5944393277168274, -0.2885928750038147, 0.5977824330329895, -0.4572151005268097, 0.41697993874549866, 0.16474226117134094, 0.49583879113197327, -0.39111724495887756, 0.13272184133529663, -0.9604960083961487, 0.6018246412277222, 0.7637842297554016, -0.35832858085632324, 0.622987687587738, -0.22297489643096924, 0.46605154871940613, -0.01794910617172718, 0.07155515253543854, -0.6835312247276306, -0.4426545202732086, -0.3180743157863617, -1.0098894834518433, -0.783610999584198, -0.4007159471511841, -0.4116571545600891, -0.619941234588623, 0.3302224278450012, -0.45451346039772034, -0.6403065323829651, 0.30892133712768555, 0.34574195742607117, 0.948523759841919, 0.9033257365226746, 0.4398699402809143, 0.2494683712720871, 1.579836130142212, -0.8553951382637024, -0.8472974896430969, -0.8696525692939758, 0.928388237953186, -0.25343257188796997, 0.06888039410114288, -0.001514317817054689, -0.3045233488082886, -0.5638836026191711, -0.6155845522880554, -0.13360917568206787, -0.5054658651351929, 0.3546684682369232, 0.940089762210846, 0.3509218990802765, -0.6451013088226318, 0.7888524532318115, 0.6548995971679688, -0.3098009526729584, 0.276867538690567, -0.11412632465362549, 0.21099135279655457, -0.3064771592617035, -1.2116057872772217, 0.386918842792511, 0.10774645209312439, -1.0628502368927002, -0.25326499342918396, -0.0022268909960985184, -0.8255770206451416, -0.20602117478847504, -0.027301102876663208, -0.6548407077789307, 1.6533554792404175, -0.49212753772735596, -1.1701794862747192, 0.9036968350410461, -0.3416083753108978, -0.016717562451958656, 0.3414081931114197, 0.0034054210409522057, -0.598696231842041, -0.6119138598442078, -0.15644408762454987, 0.4187541902065277, 0.5083630681037903, 0.48341089487075806, -0.602272629737854, 0.21419018507003784, -0.013339176774024963, 0.08147934824228287, -1.0463743209838867, 0.9640810489654541, -0.24204905331134796, -0.8282990455627441, 0.4451689124107361, 0.9578035473823547, 0.17970657348632812, -0.15270943939685822, -0.16305801272392273, -1.5619546175003052, 0.7290492653846741, 0.18025335669517517, 0.8773902058601379, -0.7972350716590881, -0.7787115573883057, -0.6129151582717896, 0.06961522251367569, -0.30046212673187256, -0.5504361391067505, 0.6738182306289673, -0.421978622674942, 0.09607376903295517, 0.15220317244529724, -1.3610326051712036, -0.14004535973072052, -0.13564708828926086, -0.9082232117652893, 0.08295714110136032, 0.05282802879810333, 0.8207089304924011, -0.3957926332950592, 0.26702749729156494, -0.4825512170791626, -0.03374507278203964, -0.598479151725769, 0.9358190894126892, -0.46454936265945435, -0.3813822567462921, -0.4260985255241394, -0.029374854639172554, 0.267043799161911, -0.3354116380214691, 0.20739270746707916, -0.4546731412410736, -0.26987525820732117, 0.6633027195930481, -0.07772836089134216, 0.8509010076522827, -0.24459891021251678, 0.7203283309936523, -0.16598014533519745, -0.6741935610771179, 0.1909574717283249, 0.7069060802459717, -0.18830373883247375, -0.14994417130947113, 0.7691048383712769, 0.10289396345615387, -1.1563115119934082, 0.20666559040546417, 0.7451146841049194, 0.4831555187702179, -0.4804007112979889, 0.47077372670173645, 0.43209001421928406, -0.064310222864151, 0.4400102496147156, 0.16250844299793243, 0.7134476900100708, -0.017022093757987022, -0.04432491213083267, 0.034340571612119675, 0.7230520248413086, -0.06294409185647964, -0.05143370479345322, 0.6503171324729919, 0.9219196438789368, 0.7990719079971313, 0.8613110780715942, -0.9621318578720093, 0.028971228748559952, 0.56523197889328, 0.6631503105163574, 1.9428749084472656, -0.37602803111076355, -0.3085404932498932, -0.41982948780059814, -1.1096004247665405, -0.10102120041847229, 0.290120005607605, -0.6970040202140808, 0.19935980439186096, -0.10584103316068649, -1.7845942974090576, 0.7716864347457886, 0.4377548098564148, 0.7989132404327393, -0.21999093890190125, 0.2000117152929306, -0.34937891364097595, -0.14761491119861603, -0.5787769556045532, -0.46725884079933167, 0.8210530877113342, -0.9092283248901367, -0.2273745983839035, -0.03840773552656174, -0.36813127994537354, 0.7673696279525757, -0.4607963263988495, 1.0017207860946655, -0.5624547600746155, 0.2728709578514099, -0.21900494396686554, 0.23655684292316437, -0.7056620121002197, -0.38777419924736023, 0.12105688452720642, 0.19631262123584747, 0.2021586000919342, 0.9659560918807983, 0.993064820766449, 0.22901245951652527, 0.5604410171508789, -0.4660661220550537, 0.31334471702575684, -0.03121313452720642, 0.5672435164451599, 0.2610666751861572, 0.3337737023830414, 0.470219224691391, -1.1078124046325684, 1.1719622611999512, 0.14799007773399353, -0.2153375893831253, 0.0688723772764206, -0.5783067941665649, -0.261502206325531, 0.7225523591041565, -0.5833950638771057, -0.6989269852638245, -0.9447060227394104, -0.10486284643411636, 0.3333299160003662, -0.2791002690792084, 0.8141543865203857, 0.5977354645729065, 0.1222594603896141, 0.5160667300224304, 0.3148365616798401, 0.2888515889644623, -0.14822076261043549, -0.07285083830356598, 0.027362506836652756, 0.151340052485466, 0.5370827317237854, 0.14113742113113403, -0.15724298357963562, -0.6449521780014038, -0.44312769174575806, -1.033791184425354, -0.43788814544677734, 0.36165204644203186, -0.2499544322490692, 0.028753958642482758, -0.5216591358184814, -0.6093651652336121, 0.3594062030315399, -0.9192675948143005, 0.25693321228027344, 0.3121245205402374, -0.31520596146583557, 0.40286678075790405, -1.3026481866836548, -1.4871596097946167, -0.48972195386886597, -1.0004427433013916, -0.5821588039398193, 0.04786846786737442, 0.18286296725273132, -0.36153262853622437, -0.5942350029945374, -0.3855372667312622, -0.019310230389237404, 0.6951987743377686, -0.6734223365783691, 1.1906510591506958, -0.2918343245983124, 0.6480588912963867, -0.9002416133880615, 0.18126004934310913, 0.6314759254455566, -0.3535737097263336, -0.062468938529491425, -0.796899139881134, 0.28862571716308594, 0.3952558934688568, -0.3386527895927429, 0.3728578984737396, 0.0919894427061081, 1.0370712280273438, 0.3027961254119873, -0.34022626280784607, 0.019632847979664803, 1.3947380781173706, -0.8443686366081238, -0.702962338924408, 0.00797164998948574, 0.5196117758750916, 0.4811148941516876, -0.10317216068506241, 0.6566770672798157, 0.5763278007507324, 0.2141253799200058, 0.028415540233254433, -0.3549438714981079, -0.11111997812986374, -0.3160332441329956, 0.3739960491657257, 1.0933502912521362, 0.338338702917099, -0.5800572633743286, -1.4222139120101929, 0.5200914144515991, -0.958738386631012, -0.2691567540168762, -0.1031733974814415, 0.2386796474456787, 0.3704734146595001, 0.21567779779434204, -0.5464315414428711, 0.4775600731372833, 0.4304865598678589, 0.23680490255355835, -0.10486231744289398, -0.6439247727394104, -0.3108835816383362, 0.19649262726306915, 0.379203200340271, 0.17060436308383942, -0.9818097352981567, 0.2982209026813507, 14.350077629089355, 0.6056581139564514, -0.13713747262954712, 0.5445936322212219, 0.7385403513908386, 0.31325364112854004, -0.22496464848518372, -0.4479122459888458, -1.1901638507843018, -0.2743964195251465, 0.38471755385398865, 0.007960684597492218, 0.059786129742860794, 0.4045461416244507, -0.20563974976539612, -0.03684251382946968, -0.6276839971542358, 0.8197672367095947, 0.7730785012245178, -1.4834707975387573, 0.5213785767555237, 0.17278531193733215, 0.40986368060112, 0.5750898718833923, 0.7073810696601868, 1.355592131614685, 0.12207319587469101, -0.3155156672000885, 0.4877609312534332, -0.22666864097118378, 0.33793818950653076, 0.17775799334049225, 1.2925091981887817, 0.7418969869613647, -0.5901042222976685, -0.9332403540611267, -0.530701756477356, -1.3041943311691284, -0.14620433747768402, 0.31529372930526733, -0.5620938539505005, -0.2797938287258148, -0.2824689745903015, 0.9109978079795837, 0.20093309879302979, -0.11888056248426437, -0.6854102611541748, 0.8502323627471924, 0.2599416673183441, -0.6411259770393372, 0.325786828994751, 0.8423762917518616, 0.31121498346328735, 0.2311956286430359, -0.13395856320858002, 0.2422669529914856, -0.10777299851179123, -0.16466113924980164, -1.0412615537643433, 0.3276127576828003, 0.07357583940029144, -0.32204025983810425, -0.7730379104614258, 0.9722939133644104, 0.40929409861564636, 0.02257947064936161, -0.7019340991973877, 0.17512696981430054, 0.26924851536750793, 0.3248719274997711, -0.1683192253112793, -0.582531750202179, 0.3576085865497589, 0.03468432277441025, -0.06895910203456879, 0.7238098978996277, -0.585567057132721, -0.9976863265037537, -1.0193746089935303, -0.29798176884651184, 1.0649933815002441, -0.7035976052284241, -1.3612600564956665, 1.1171948909759521, -0.877554714679718, -0.5197126269340515, 0.4355846643447876, -1.302429437637329, -0.5706015825271606, 0.8096106648445129, -1.6338696479797363, -0.27515578269958496, -0.09194475412368774, -0.241314098238945, -0.19897222518920898, -0.4985940456390381, 1.2494244575500488, 0.04541624337434769, -0.590034544467926, -0.18200087547302246, 0.19052991271018982, 0.5801494717597961, -0.28772860765457153, -0.857342004776001, 0.5813043713569641, -0.010002302005887032, -0.5466596484184265, -0.08778350800275803, -0.03146633505821228, 0.3297443687915802, -0.6975888609886169, -0.406538188457489, 1.3461658954620361, -0.4899328351020813, -0.3318713903427124, -0.8094221353530884, -0.9745115637779236, -0.0978497862815857, 0.5821593999862671, -0.7577807903289795, 0.8560057282447815, 0.6284976601600647, -0.6655446887016296, -0.19478736817836761, -0.8683258295059204, 0.15759457647800446, -0.14217185974121094, -0.5775772929191589, -0.8676297068595886, 0.3658791780471802, -0.43488991260528564, -0.4345502257347107, -0.27151113748550415, -0.3021833002567291, -0.2823176681995392, 0.4179963767528534, 0.5960759520530701, -0.7499111294746399, 1.2960009574890137, 0.5210137963294983, -0.1493769735097885, -0.7540309429168701, -0.2582855820655823, -0.18045414984226227, 0.1927051544189453, 0.025034015998244286, 0.7099788188934326, -0.6592351198196411, 0.6769704818725586, 0.7490601539611816, 0.4041012227535248, -0.6824252605438232, -0.4056851863861084, 0.26304271817207336, 0.15616554021835327, -0.3961547613143921, 0.14406204223632812, 0.44111067056655884, 0.3171634376049042, 0.07409390807151794, 0.7421545386314392, 0.21342583000659943, -0.377797394990921, -0.15259096026420593, 0.36284321546554565, -0.7538958191871643, 0.2786736786365509, -0.8511552214622498, -0.17893563210964203, -1.850408911705017, 0.2956891655921936, -1.2875975370407104, -0.1507311761379242, -1.4037457704544067, -0.3499712347984314, 0.4944589138031006, -0.17750447988510132, 0.8199667930603027, 0.2520495355129242, -0.39424777030944824, -0.8902228474617004, -0.471647709608078, -0.2837453782558441, 0.6617920994758606, 0.7183215618133545, -0.9209316372871399, 0.47434207797050476, 0.021592574194073677, -0.09622359275817871, 0.6571438908576965, 0.6520081162452698, -0.6260099411010742, -0.5986153483390808, -1.3755048513412476, 0.43234556913375854, -0.12335741519927979, -0.26863014698028564, -0.44664642214775085, 0.6505018472671509, 0.16884218156337738, 0.23444242775440216, -0.10992536693811417, 0.2630622088909149, -0.46946069598197937, -0.8198269009590149, 0.3675990700721741, -1.0694526433944702, -0.15785299241542816, 0.04357700049877167, -0.5820998549461365, -0.7116891741752625, 0.05587469041347504, -0.18391792476177216, -0.6378175616264343, -0.3592703342437744, 0.36353588104248047, -1.3413585424423218, 0.17249424755573273, -0.05616053566336632, -0.21543915569782257, -1.2675422430038452, -0.3794071674346924, 0.25582632422447205, 0.6368733644485474, -0.6035978198051453, 1.1771976947784424, 0.1265462040901184, -1.1283149719238281, -0.2931913435459137, 0.3419061005115509, 0.27886807918548584, -0.5031762719154358, 0.37654492259025574, 0.44009217619895935, -0.3229423761367798, 0.38628682494163513, 0.3936339318752289, 0.1505919247865677, -1.01546049118042, -0.5020396709442139, 1.0519717931747437, -0.31783321499824524, -0.23226739466190338, 1.1735371351242065, -0.12952470779418945, -1.0906862020492554, 0.22170031070709229, -1.1937901973724365, -1.0790899991989136, 0.3040843605995178, 0.7639715671539307, -0.23613741993904114, 0.41855815052986145, 0.05857428163290024, -0.38065090775489807, -0.05656786262989044, -0.14740397036075592, -0.42532774806022644, 0.61996990442276, 0.06072905287146568, -0.5339187383651733, 0.6813318133354187, 0.8143221139907837, -0.9335156083106995, -0.2489355206489563, -0.6939321756362915, 0.039697423577308655, -0.07721531391143799, 0.854454755783081, -0.6123301982879639, -0.8243098258972168, 0.5650793313980103, 0.19659659266471863, 0.6898192167282104, 0.4195789396762848, -0.6555026769638062, 0.03356883302330971, 0.7635889649391174, -0.08734913170337677, -0.7535625696182251, -0.3732501268386841, 2.0771548748016357, 1.306279182434082, -1.1135365962982178, -0.006211940199136734, -0.08965305238962173, -0.8477915525436401, 1.359206199645996, 0.26611965894699097, 0.4850161373615265, 1.2603670358657837, -0.38290420174598694, 0.31508955359458923, 0.23212748765945435, -1.332275629043579, 0.08221679925918579, 0.8052685260772705, 0.5833151340484619, 1.300803780555725, 0.06367523223161697, -0.26843297481536865, 1.5218358039855957, -0.000631967035587877, 0.13296827673912048, 0.7333482503890991, 0.47107553482055664, -0.050598062574863434, 0.038912493735551834, 0.021608317270874977, 0.9629570245742798, -1.0699011087417603, 0.020384028553962708, -0.12213757634162903, 0.32373419404029846, 0.43480756878852844, 0.903581976890564, 0.3746137022972107, -0.34304162859916687, 0.3991698622703552, 0.46292659640312195, -0.08958124369382858, -0.5648655295372009, -1.1578936576843262, -0.5770854353904724, -0.25271376967430115, 0.4275769889354706, -0.07293511182069778, -0.4052145481109619, -0.059502266347408295, -0.36601442098617554, 0.4546635150909424, 0.21059976518154144, 0.4128076434135437, 1.010073184967041, 0.18627393245697021, 0.4249474108219147, -0.35373711585998535, 0.25692248344421387, -0.5558289289474487, -1.2463716268539429, -0.26413899660110474, -0.5790128707885742, -0.1509999930858612, -0.1684180349111557, -0.4544307291507721, -0.27651047706604004]}, "authors": [{"authorId": "2164604", "name": "Shervin Minaee"}, {"authorId": "49943757", "name": "E. Cambria"}, {"authorId": "48441311", "name": "Jianfeng Gao"}], "references": [{"paperId": "5a88b8f1ffd87fd900de225f3d7e87c9f53af7df", "title": "ABCDM: An Attention-based Bidirectional CNN-RNN Deep Model for sentiment analysis"}, {"paperId": "b1b26858b61a0ca2d885b691064739f87b698f37", "title": "Robust Conversational AI with Grounded Text Generation"}, {"paperId": "a2f38d03fd363e920494ad65a5f0ad8bd18cd60b", "title": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing"}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "ae2c03cbe6162dadf65edd2ff7dfc5333524dca5", "title": "MixText: Linguistically-Informed Interpolation of Hidden Space for Semi-Supervised Text Classification"}, {"paperId": "2ffcf8352223c95ae8cef4daaec995525ecc926b", "title": "Adversarial Training for Large Neural Language Models"}, {"paperId": "9c5a239b75bade55c830b164e2fadc424e879137", "title": "XtremeDistil: Multi-stage Distillation for Massive Multilingual Models"}, {"paperId": "3bcb17559ce96eb20fa79af8194f4af0380d194a", "title": "Pre-trained models for natural language processing: A survey"}, {"paperId": "f64e1d6bc13aae99aab5449fc9ae742a9ba7761e", "title": "UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training"}, {"paperId": "c6c734e16f66fbfcefac7625cc64599e83292c1e", "title": "MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers"}, {"paperId": "97d69e7e8c04714bf58dcbe5ae7454db69b657a7", "title": "The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence"}, {"paperId": "704a1a4ff7b6fed65b0c49ef87b6845d60755fa7", "title": "TwinBERT: Distilling Knowledge to Twin-Structured BERT Models for Efficient Retrieval"}, {"paperId": "712e32e2da67428ba6c6add1605410e1c3792883", "title": "Image Segmentation Using Deep Learning: A Survey"}, {"paperId": "075c98c0b3bbd0bce2b27341d0df8ef8233c0102", "title": "Finding decision jumps in text classification"}, {"paperId": "95b71e3dd9ed4077f2cd16a37c9d1dfdfc9abddd", "title": "Biometric Recognition Using Deep Learning: A Survey"}, {"paperId": "c12e6c65e1de5d3993c5b65d0e234ae1f60c85ae", "title": "TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection"}, {"paperId": "207da6d2c07289bf72a2b5974bb3f011ebb5dd0d", "title": "Adversarial NLI: A New Benchmark for Natural Language Understanding"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "4bdaae501c70e8f6e0b5426931e114f5fad90cf3", "title": "Improving text classification with weighted word embeddings via a multi-channel TextCNN model"}, {"paperId": "231b6807767249c04d73c7c6f6295625d4e52591", "title": "Text Level Graph Neural Network for Text Classification"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "dfba20af7aacd819e7b22cf2bf189cd7af9da0a1", "title": "Enhancing the Transformer with Explicit Relational Encoding for Math Problem Solving"}, {"paperId": "5744f56d3253bd7c4341d36de40a93fceaa266b3", "title": "Semantics-aware BERT for Language Understanding"}, {"paperId": "92978d5c31ea53e6979662cb4879dda19bdf8683", "title": "Neural Attentive Bag-of-Entities Model for Text Classification"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "80f9f109d1564cb8f82aa440a5f6f3fbe220c9ef", "title": "ERNIE 2.0: A Continual Pre-training Framework for Language Understanding"}, {"paperId": "ae04f3d011511ad8ed7ffdf9fcfb7f11e6899ca2", "title": "Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment"}, {"paperId": "ecd96ef4586a48826ffc2430ea26df66437657ac", "title": "Is BERT Really Robust? Natural Language Attack on Text Classification and Entailment"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "81f5810fbbab9b7203b9556f4ce3c741875407bc", "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans"}, {"paperId": "c3f89364aecd661eb032840d2fe3efd0f6d1698c", "title": "Revisiting LSTM Networks for Semi-Supervised Text Classification via Mixed Objective Function"}, {"paperId": "378bb2e80e03a12c8be549576a16936001f77a5b", "title": "Investigating the transferring capability of capsule networks for text classification"}, {"paperId": "58203813610b866483ffc2bd1181f616ae38107c", "title": "Hierarchical Multi-label Classification of Text with Capsule Networks"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "97eb41cb7ca3419d297fd402ff239de17d7b2ee8", "title": "Hierarchical Taxonomy-Aware and Attentional Graph Capsule RCNNs for Large-Scale Multi-Label Text Classification"}, {"paperId": "3b3f47170ec5c4fabac510585b33aeb87b384396", "title": "Variational Pretraining for Semi-supervised Text Classification"}, {"paperId": "8e93a072ac0324a7d012fbba6aa314d5b4b59b64", "title": "Towards Scalable and Reliable Capsule Networks for Challenging NLP Applications"}, {"paperId": "a022bda79947d1f656a1164003c1b3ae9a843df9", "title": "How to Fine-Tune BERT for Text Classification?"}, {"paperId": "1c71771c701aadfd72c5866170a9f5d71464bb88", "title": "Unified Language Model Pre-training for Natural Language Understanding and Generation"}, {"paperId": "0feea94f89d395436bf41bd10c797447eecbc128", "title": "Unsupervised Data Augmentation for Consistency Training"}, {"paperId": "3562fefb64cd63ac1a6a0adbaa83ae73dd674243", "title": "Unsupervised Data Augmentation"}, {"paperId": "031e4e43aaffd7a479738dcea69a2d5be7957aa3", "title": "ERNIE: Enhanced Representation through Knowledge Integration"}, {"paperId": "ba10b8f9ee40b68053af9e6c2383aa2c6e39e9be", "title": "Text Classification Algorithms: A Survey"}, {"paperId": "a08293b2c9c5bcddb023cc7eb3354d4d86bfae89", "title": "Distilling Task-Specific Knowledge from BERT into Simple Neural Networks"}, {"paperId": "7e71eedb078181873a56f2adcfef9dddaeb95602", "title": "Simplifying Graph Convolutional Networks"}, {"paperId": "658721bc13b0fa97366d38c05a96bf0a9f4bb0ac", "title": "Multi-Task Deep Neural Networks for Natural Language Understanding"}, {"paperId": "2ead783089fc757052abb908287a2fb743a4ebef", "title": "Squeezed Very Deep Convolutional Neural Networks for Text Classification"}, {"paperId": "9a57d9234eeb5570255910b29c187b9ce43d64e1", "title": "Contextualized Non-local Neural Networks for Sequence Learning"}, {"paperId": "ac3e8d038695e0f3d5e68621b18f051823344f2a", "title": "Compositional coding capsule network with k-means routing for text classification"}, {"paperId": "9d6e0827b1364bf9ec7c128b450fa76820b2ba0c", "title": "Training Complex Models with Multi-Task Weak Supervision"}, {"paperId": "1fed705d42846c005b68207c2f94cb0842d062ac", "title": "Learning Universal Sentence Representations with Mean-Max Attention Autoencoder"}, {"paperId": "6017e81c5ede6c38b306a3df9738aeb04baa7619", "title": "Graph Convolutional Networks for Text Classification"}, {"paperId": "89644d9869df2df4d26500ccdd46f6326856534d", "title": "Weakly-Supervised Neural Text Classification"}, {"paperId": "af5c4b80fbf847f69a202ba5a780a3dd18c1a027", "title": "SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference"}, {"paperId": "08a02a449cd9d94d869f124c670045fd3630bc7d", "title": "Text Classification using Capsules"}, {"paperId": "48758697a493e9a970c51a6198fbb20133d7ae97", "title": "Discourse Marker Augmented Network with Reinforcement Learning for Natural Language Inference"}, {"paperId": "35f0b854901dc6c5a69b271637d302f7db49b79a", "title": "Densely Connected CNN with Multi-scale Feature Attention for Text Classification"}, {"paperId": "2b32b4fa1e28c256745f1573b5444b1b2c8df30e", "title": "Multiway Attention Networks for Modeling Sentence Pairs"}, {"paperId": "83e567c2822aeda91006096a5d7ac0b34721d2a5", "title": "Neural Approaches to Conversational AI"}, {"paperId": "5f38a07add820c82a2b13a17d891f08cdcaef500", "title": "Enhancing Sentence Embedding with Generalized Pooling"}, {"paperId": "4d1c856275744c0284312a3a50efb6ca9dc4cd4c", "title": "Know What You Don\u2019t Know: Unanswerable Questions for SQuAD"}, {"paperId": "f5e78eb72c3da3f1f6ed1afdd4686927518f85a2", "title": "A Generative Model for category text generation"}, {"paperId": "b5388cfc06688fe3c6937c65025442fdf9a1e6b9", "title": "Semantic Sentence Matching with Densely-connected Recurrent and Co-attentive Information"}, {"paperId": "4cfd53606ee76aedc2cf1ae39a64223adc25e4c8", "title": "Joint Embedding of Words and Labels for Text Classification"}, {"paperId": "e73bd7f9bdc262b9b7fb60ca0d5230d3ab0fad5e", "title": "Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates"}, {"paperId": "cf8c493079702ec420ab4fc9c0fabb56b2a16c84", "title": "SciTaiL: A Textual Entailment Dataset from Science Question Answering"}, {"paperId": "fb2734de76d9713f97d1156aed4c8eca8fc4d542", "title": "Targeted Aspect-Based Sentiment Analysis via Embedding Commonsense Knowledge into an Attentive LSTM"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "a1a197449aeca81a39cb2213b41cef4831d6983e", "title": "Large-Scale Hierarchical Text Classification with Recursively Regularized Deep Graph-CNN"}, {"paperId": "6a377115d0026bca3f67ed34ea03543880f6a2e3", "title": "Investigating Capsule Networks with Dynamic Routing for Text Classification"}, {"paperId": "603caed9430283db6c7f43169555c8d18e97a281", "title": "Matrix capsules with EM routing"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "3913d2e0a51657a5fe11305b1bcc8bf3624471c0", "title": "Learning Structured Representation for Text Classification via Reinforcement Learning"}, {"paperId": "5d727286a59d7e2681b6fac5fa269e782849f007", "title": "Reinforced Self-Attention Network: a Hybrid of Hard and Soft Attention for Sequence Modeling"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "8490431f3a76fbd165d108eba938ead212a2a639", "title": "Stochastic Answer Networks for Machine Reading Comprehension"}, {"paperId": "efbac99adf8628aae7f070e5b4388a295956f9d2", "title": "CondenseNet: An Efficient DenseNet Using Learned Group Convolutions"}, {"paperId": "1fe6bee85774244d8674cbb20a25e8d153cecb17", "title": "FusionNet: Fusing via Fully-Aware Attention with Application to Machine Comprehension"}, {"paperId": "33998aff64ce51df8dee45989cdca4b6b1329ec4", "title": "Graph Attention Networks"}, {"paperId": "c4c06578f4870e4b126e6837907929f3c900b99f", "title": "Dynamic Routing Between Capsules"}, {"paperId": "937e55826b0fe64e42a43121681e5e4a62ddcc40", "title": "PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts"}, {"paperId": "9dfacffdae4527d01563814c804e410e4ca885e1", "title": "HDLTex: Hierarchical Deep Learning for Text Classification"}, {"paperId": "adc276e6eae7051a027a4c269fb21dae43cadfed", "title": "DiSAN: Directional Self-Attention Network for RNN/CNN-free Language Understanding"}, {"paperId": "1a0365567850837931d04126714ae6e2cbfc6270", "title": "Deep Learning for Extreme Multi-label Text Classification"}, {"paperId": "975f1fc0ab58a05fa7a36387a32ffa4999759bc5", "title": "Automatic question-answering using a deep similarity neural network"}, {"paperId": "ceb7dddbd0c51f511c4ba97d328b48fd10d2a7fc", "title": "Recurrent Neural Network-Based Sentence Encoder with Gated Attention for Natural Language Inference"}, {"paperId": "20676c91ce10b6b2de510510f48d28612eed76d1", "title": "Combining Knowledge with Deep Convolutional Neural Networks for Short Text Classification"}, {"paperId": "bc8fa64625d9189f5801837e7b133e7fe3c581f7", "title": "Learned in Translation: Contextualized Word Vectors"}, {"paperId": "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096", "title": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"}, {"paperId": "a90179a880a34c70cb916133f931be7a97fec2d5", "title": "Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering"}, {"paperId": "c73d507abd4f4f917e1e020df6ff0750eb5be6d8", "title": "Do Convolutional Networks need to be Deep for Text Classification ?"}, {"paperId": "718e1b453fe9dce79458e0db035091db603775fb", "title": "Deep Pyramid Convolutional Neural Networks for Text Categorization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "6b7d6e6416343b2a122f8416e69059ce919026ef", "title": "Inductive Representation Learning on Large Graphs"}, {"paperId": "62d79628fd0c111a471813145d261b0373d3e5e5", "title": "Ensemble application of convolutional and recurrent neural networks for multi-label text categorization"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "8ff54aa8045b1e30c348cf2ca42259c946cd7a9e", "title": "Search-based Neural Structured Learning for Sequential Question Answering"}, {"paperId": "d5c67808fe08f15c3e54acbfd206c41f1e8e8e03", "title": "Medical Text Classification using Convolutional Neural Networks"}, {"paperId": "9151f229e7b4e318b0b12afe99993da0ee5e0e34", "title": "Adversarial Multi-task Learning for Text Classification"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "2320f49ecaf56f4c4bea279cda783892f0906b31", "title": "Improving sentiment analysis via sentence type classification using BiLSTM-CRF and CNN"}, {"paperId": "204a4a70428f3938d2c538a4d74c7ae0416306d8", "title": "A Structured Self-attentive Sentence Embedding"}, {"paperId": "a9df777e4d8100e52e90fa4bd2d783d25a2fd173", "title": "Bilateral Multi-Perspective Matching for Natural Language Sentences"}, {"paperId": "5feb32a73dd1bd9e13f84a7b3344497a5545106b", "title": "FastText.zip: Compressing text classification models"}, {"paperId": "ae32e911a080eeeb3ac08e483f99e3daa649065f", "title": "SenticNet 4: A Semantic Resource for Sentiment Analysis Based on Conceptual Primitives"}, {"paperId": "8d574fde3e46ad766fac26094e3bb1cf55a08226", "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset"}, {"paperId": "786f95cada23d4639aa1a8b922cdb9fb9a9c03fa", "title": "Text Classification Improved by Integrating Bidirectional LSTM with Two-dimensional Max Pooling"}, {"paperId": "7ab2166f6cdb1737e000df66d29c6538afc6811d", "title": "TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency"}, {"paperId": "dd95f96e3322dcaee9b1e3f7871ecc3ebcd51bfe", "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset"}, {"paperId": "b31a60f21dae6adfc66e6c1c04bc74b57638b000", "title": "Attention-based LSTM Network for Cross-Lingual Sentiment Classification"}, {"paperId": "9cc4ff9f1791ddac670bbc4aa45280262e7eb400", "title": "aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching Model"}, {"paperId": "063ad0349f05c8aacbbb653ffcf01047a293fa30", "title": "SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods"}, {"paperId": "c636a2dd242908fe2e598a1077c0c57bfdea8633", "title": "ReasoNet: Learning to Stop Reading in Machine Comprehension"}, {"paperId": "36eff562f65125511b5dfab68ce7f7a943c27478", "title": "Semi-Supervised Classification with Graph Convolutional Networks"}, {"paperId": "2167f9ffd36af6c723d3527eab60c731e13d3a90", "title": "Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling"}, {"paperId": "5694e46284460a648fe29117cbc55f6c9be3fa3c", "title": "Densely Connected Convolutional Networks"}, {"paperId": "1261fe9bfde319abcc5d011bc70f7e7547b5258f", "title": "Improved Representation Learning for Question Answer Matching"}, {"paperId": "62a97ac04e742ad1513cf164760e4d6a25d93203", "title": "Together we stand: Siamese Networks for Similar Question Retrieval"}, {"paperId": "35b11ac652646c70a559f7ae29295e1d5de09a80", "title": "Learning Text Similarity with Siamese Recurrent Networks"}, {"paperId": "9fb6cea96b54131a8938913bbb71f301559d8ece", "title": "Designing a Better Data Representation for Deep Neural Networks and Text Classification"}, {"paperId": "cff79255a94b9b05a4ce893eb403a522e0923f04", "title": "Neural Semantic Encoders"}, {"paperId": "7dba53e72c182e25e98e8f73a99d75ff69dda0c2", "title": "Recurrent Highway Networks"}, {"paperId": "3fa5d00318d6618b33cd152f444d087894a0ba39", "title": "SelQA: A New Benchmark for Selection-Based Question Answering"}, {"paperId": "10e337d762de7bb08d093469d5e2157f8598eaa6", "title": "Learning text representation using recurrent convolutional neural network with highway layers"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "455afd748e8834ef521e4b67c7c056d3c33429e2", "title": "Hierarchical Attention Networks for Document Classification"}, {"paperId": "fe1818e57cbd3823c7fbfaa577b21a232a43dbd5", "title": "DeepMeSH: deep semantic representation for improving large-scale MeSH indexing"}, {"paperId": "f797fd44b9ddd5845611eb7a705ca9464a8819d1", "title": "Very Deep Convolutional Networks for Text Classification"}, {"paperId": "2cd8e8f510c89c7c18268e8ad51c061e459ad321", "title": "A Decomposable Attention Model for Natural Language Inference"}, {"paperId": "84ca430856a92000e90cd728445ca2241c10ddc3", "title": "Very Deep Convolutional Networks for Natural Language Processing"}, {"paperId": "0f5d5a74572f272b919ca383ee47cb6663d38d62", "title": "Siamese CBOW: Optimizing Word Embeddings for Sentence Representations"}, {"paperId": "ec64f650fea9b49cbf7d8bddf458388c4b362475", "title": "Dependency Sensitive Convolutional Neural Networks for Modeling Sentences and Documents"}, {"paperId": "dd7bfb6632612e680cc11b4f8570c96ead12942d", "title": "SemEval-2016 Task 5: Aspect Based Sentiment Analysis"}, {"paperId": "f93a0a3e8a3e6001b4482430254595cf737697fa", "title": "Learning Natural Language Inference using Bidirectional LSTM model and Inner-Attention"}, {"paperId": "2cd55ded95d5d13430edfa223ba591b514ebe8a5", "title": "Adversarial Training Methods for Semi-Supervised Text Classification"}, {"paperId": "10d89efc96beb45676149c8a3237a86a72a2116e", "title": "Modelling Interaction of Sentence Pair with Coupled-LSTMs"}, {"paperId": "e28ab7c3b994dd4e30baac1eb67c7f87e40c2b7b", "title": "Recurrent Neural Network for Text Classification with Multi-Task Learning"}, {"paperId": "f96898d15a1bf1fa8925b1280d0e07a7a8e72194", "title": "Dynamic Memory Networks for Visual and Textual Question Answering"}, {"paperId": "72b89e45e8ad8b44bdcab524b959dc09bf63eb1e", "title": "Siamese Recurrent Architectures for Learning Sentence Similarity"}, {"paperId": "b9e505fad7ffbb35bd30b7a2b63226291bfd857f", "title": "Text Matching as Image Recognition"}, {"paperId": "a2dc06c8da0ff9344dc558d6df571fc704b81ae7", "title": "Attentive Pooling Networks"}, {"paperId": "d7db74be6cda0ec2bd28ec187563def85ccef78f", "title": "Supervised and Semi-Supervised Text Categorization using LSTM for Region Embeddings"}, {"paperId": "573f0e60493e26558dd71f4c2ecc8d3b4784cbbd", "title": "Efficient Character-level Document Classification by Combining Convolution and Recurrent Layers"}, {"paperId": "13fe71da009484f240c46f14d9330e932f8de210", "title": "Long Short-Term Memory-Networks for Machine Reading"}, {"paperId": "98ea4abc9bf0e30eb020db2075c9c8a039a848a3", "title": "Learning to Compose Neural Networks for Question Answering"}, {"paperId": "ea407573bfcd39f9a478fe33cf6ce0ee1780a5f0", "title": "Natural Language Inference by Tree-Based Convolution and Heuristic Matching"}, {"paperId": "7f3ae283243e15e05f188a05779ccfae9a3567f4", "title": "ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "10f62af29c3fc5e2572baddca559ffbfd6be8787", "title": "A C-LSTM Neural Network for Text Classification"}, {"paperId": "bf76690e93fd06ba1f86cf029fd62ae3ac770968", "title": "A Deep Architecture for Semantic Matching with Multiple Positional Sentence Representations"}, {"paperId": "73e8633886dc380a46fc02f2e1ec5bf68dba0734", "title": "Neural Variational Inference for Text Processing"}, {"paperId": "d82b55c35c8673774a708353838918346f6c006f", "title": "Generating Sentences from a Continuous Space"}, {"paperId": "bfccb2d6e3d9f9b6bd8b14b2d4c6efa36c79341b", "title": "LSTM-based Deep Learning Models for non-factoid answer selection"}, {"paperId": "4aa9f5150b46320f534de4747a2dd0cd7f3fe292", "title": "Semi-supervised Sequence Learning"}, {"paperId": "06b919f865d0a0c3adbc10b3c34cbfc35fb98d43", "title": "A Sensitivity Analysis of (and Practitioners\u2019 Guide to) Convolutional Neural Networks for Sentence Classification"}, {"paperId": "f53e2ae46470b89cd1ce6e3bf1d60d9c59722ce1", "title": "WikiQA: A Challenge Dataset for Open-Domain Question Answering"}, {"paperId": "28669e91f56ac52ab4978150093c2b2662283986", "title": "Convolutional neural networks for biomedical text classification: application in indexing biomedical articles"}, {"paperId": "51a55df1f023571a7e07e338ee45a3e3d66ef73e", "title": "Character-level Convolutional Networks for Text Classification"}, {"paperId": "ecb5336bf7b54a62109f325e7152bb74c4c7f527", "title": "Document Modeling with Gated Recurrent Neural Network for Sentiment Classification"}, {"paperId": "cdd2906f29d8103632dba24484571a8a05c09076", "title": "Multi-Timescale Long Short-Term Memory Neural Network for Modelling Sentences and Documents"}, {"paperId": "1cc405a70b35129ce387ced5144298d09d07c3cf", "title": "Multi-Perspective Sentence Similarity Modeling with Convolutional Neural Networks"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "891ce1687e2befddd19f54e4eef1d3f39c8dbaf7", "title": "Character-Aware Neural Language Models"}, {"paperId": "f04df4e20a18358ea2f689b4c129781628ef7fc1", "title": "A large annotated corpus for learning natural language inference"}, {"paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0", "title": "Effective Approaches to Attention-based Neural Machine Translation"}, {"paperId": "84d2e6eb7772e2fa4fc0b14c28446d00370a45d2", "title": "Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks"}, {"paperId": "b92aa7024b87f50737b372e5df31ef091ab54e62", "title": "Training Very Deep Networks"}, {"paperId": "1f600f213dbbd70f06093438855f39022957b4bf", "title": "Long Short-Term Memory Over Recursive Structures"}, {"paperId": "66021a920001bc3e6258bffe7076d647614147b7", "title": "From Word Embeddings To Document Distances"}, {"paperId": "d450b0f12ae0437048e4047a630c31d902002d0c", "title": "Distributional Smoothing with Virtual Adversarial Training"}, {"paperId": "80a624b9327d9050244dfebac96f7f6cf806880f", "title": "Deep Unordered Composition Rivals Syntactic Methods for Text Classification"}, {"paperId": "452059171226626718eb677358836328f884298e", "title": "Ask Me Anything: Dynamic Memory Networks for Natural Language Processing"}, {"paperId": "6e795c6e9916174ae12349f5dc3f516570c17ce8", "title": "Skip-Thought Vectors"}, {"paperId": "4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e", "title": "End-To-End Memory Networks"}, {"paperId": "32de44f01a96d4473d21099d15e25bc2b9f08e2f", "title": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"}, {"paperId": "eba36ac75bf22edf9a1bfd33244d459c75b98305", "title": "Recurrent Convolutional Neural Networks for Text Classification"}, {"paperId": "bee044c8e8903fb67523c1f8c105ab4718600cdb", "title": "Explaining and Harnessing Adversarial Examples"}, {"paperId": "fbf417c83ae5b895fc645346e4efbf3a0aabeac9", "title": "Effective Use of Word Order for Text Categorization with Convolutional Neural Networks"}, {"paperId": "0a73487b85e6b603c74525b308e848212f6be199", "title": "Concept-based Short Text Classification and Ranking"}, {"paperId": "7e8d5a108c28cdfb92f419ce919fbf7993dfebfc", "title": "A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval"}, {"paperId": "71ae756c75ac89e2d731c9c79649562b5768ff39", "title": "Memory Networks"}, {"paperId": "86efe7769f2b8a0e15ca213ab09881e6705caeb0", "title": "Convolutional Neural Networks for Speech Recognition"}, {"paperId": "f37e1b62a767a307c046404ca96bc140b3e68cb5", "title": "GloVe: Global Vectors for Word Representation"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba", "title": "Convolutional Neural Networks for Sentence Classification"}, {"paperId": "11ec56898a9e7f401a2affe776b5297bd4e25025", "title": "SemEval-2014 Task 1: Evaluation of Compositional Distributional Semantic Models on Full Sentences through Semantic Relatedness and Textual Entailment"}, {"paperId": "06e122f475a21d92dba137609c40f35690217475", "title": "Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification"}, {"paperId": "f3de86aeb442216a8391befcacb49e58b478f512", "title": "Distributed Representations of Sentences and Documents"}, {"paperId": "27725a2d2a8cee9bf9fffc6c2167017103aba0fa", "title": "A Convolutional Neural Network for Modelling Sentences"}, {"paperId": "484ad17c926292fbe0d5211540832a8c8a8e958b", "title": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models"}, {"paperId": "5f5dc5b9a2ba710937e2c413b37b053cd673df02", "title": "Auto-Encoding Variational Bayes"}, {"paperId": "fdb813d8b927bdd21ae1858cafa6c34b66a36268", "title": "Learning deep structured semantic models for web search using clickthrough data"}, {"paperId": "87f40e6f3022adbc1f1905e3e506abad05a9964f", "title": "Distributed Representations of Words and Phrases and their Compositionality"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "564257469fa44cdb57e4272f85253efb9acfd69d", "title": "MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text"}, {"paperId": "f6b51c8753a871dc94ff32152c00c01e94f90f09", "title": "Efficient Estimation of Word Representations in Vector Space"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "5e9fa46f231c59e6573f9a116f77f53703347659", "title": "Baselines and Bigrams: Simple, Good Sentiment and Topic Classification"}, {"paperId": "ed6262b569c0a62c51d941228c54f34e563af022", "title": "Japanese and Korean voice search"}, {"paperId": "d5b034176d6021bc965fca9aa02f17864d1ccf67", "title": "Learning Discriminative Projections for Text Similarity Measures"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "20f0357688876fa4662f806f985779dce6e24f3c", "title": "Transforming Auto-Encoders"}, {"paperId": "bc1022b031dc6c7019696492e8116598097a8c12", "title": "Natural Language Processing (Almost) from Scratch"}, {"paperId": "bd2062eb413816144bcfc1c8511f73712c67ac74", "title": "PubMed and beyond: a survey of web tools for searching biomedical literature"}, {"paperId": "5ef2edfe51d3d768b1d89ad7e74e4ce8e55d1d49", "title": "Delta TFIDF: An Improved Feature Space for Sentiment Analysis"}, {"paperId": "550e619748eb2fc4e92cf0aa030d1307da876ab3", "title": "Efficient Pairwise Multilabel Classification for Large-Scale Problems in the Legal Domain"}, {"paperId": "19e8869f4c29353de0d9b52542c1fe9def4cbc7d", "title": "Introduction to Information Retrieval"}, {"paperId": "7e104b1968b9ec09af0f6b480a46fc1ce884c3bc", "title": "Google news personalization: scalable online collaborative filtering"}, {"paperId": "4bc1678b9d2ffc9af22a6c3b786ad79a941f0b86", "title": "Practical solutions to the problem of diagonal dominance in kernel document clustering"}, {"paperId": "7acfdc905f734abf966aed58abb983bc015ff7fe", "title": "Unsupervised Construction of Large Paraphrase Corpora: Exploiting Massively Parallel News Sources"}, {"paperId": "7b95d389bc6affe6a127d53b04bcfd68138f1a1a", "title": "TextRank: Bringing Order into Text"}, {"paperId": "28209ce8d0ac1cf4ceea3eeddf4630e1032fa0ef", "title": "A neural probabilistic language model"}, {"paperId": "12d0353ce8b41b7e5409e5a4a611110aee33c7bc", "title": "Thumbs up? Sentiment Classification using Machine Learning Techniques"}, {"paperId": "997dc5d9a058753f034422afe7bd0cc0b8ad808b", "title": "Signature Verification Using A \"Siamese\" Time Delay Neural Network"}, {"paperId": "164125a65d42a791d2c1e108559344caef96d08b", "title": "Indexing by Latent Semantic Analysis"}, {"paperId": "052b1d8ce63b07fec3de9dbb583772d860b7c769", "title": "Learning representations by back-propagating errors"}, {"paperId": "319f22bd5abfd67ac15988aa5c7f705f018c3ccd", "title": "Learning internal representations by error propagation"}, {"paperId": "69e68bfaadf2dccff800158749f5a50fe82d173b", "title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position"}, {"paperId": "243e2140a14022531461c5f169ebbe14930efccc", "title": "Two Cheers for Rebooting AI: Building Artificial Intelligence We Can Trust"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "81a4fd3004df0eb05d6c1cef96ad33d5407820df", "title": "A Comprehensive Survey on Graph Neural Networks"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "a07609c2ed39d049d3e59b61408fb600c6ab0950", "title": "GPU Kernels for Block-Sparse Weights"}, {"paperId": "06353147b2eaa8ff50a872c67c43665286cafcb9", "title": "Automatic Diagnosis Coding of Radiology Reports: A Comparison of Deep Learning and Conventional Classification Methods"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": "3bc2a6cf602c3f4e6ef950db95613393941a507a", "title": "MPQA 3.0: An Entity/Event-Level Sentiment Corpus"}, {"paperId": "d2946a868682e4141beabc288d79253ae254c6e1", "title": "DBpedia - A large-scale, multilingual knowledge base extracted from Wikipedia"}, {"paperId": "503c507407301c7055bccc162f4fb143c64b3e5c", "title": "Humans Require Context to Infer Ironic Intent (so Computers Probably do, too)"}, {"paperId": "3d4c709be74c6926b220f4cf7d8adf50082f3886", "title": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)"}, {"paperId": "e808f28d411a958c5db81ceb111beb2638698f47", "title": "The PASCAL Recognising Textual Entailment Challenge"}, {"paperId": "1cff7cc15555c38607016aaba24059e76b160adb", "title": "Annotating Expressions of Opinions and Emotions in Language"}, {"paperId": null, "title": "Electra: Pre-training text encoders as discriminators rather than generators"}, {"paperId": "b54bcfca3fddc26b8889739a247a25e445818149", "title": "Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition"}, {"paperId": "ef5ea7214480e63635ff24fd21019fc92b03b739", "title": "Speech and language processing: an introduction to natural language processing"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": "97efafdb4a3942ab3efba53ded7413199f79c054", "title": "Reinforcement Learning: An Introduction"}]}