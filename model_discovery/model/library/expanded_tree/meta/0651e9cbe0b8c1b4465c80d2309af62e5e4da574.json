{"paperId": "0651e9cbe0b8c1b4465c80d2309af62e5e4da574", "abstract": "Many real-world problems are inherently multimodal, from spoken language, gestures, and paralinguistics humans use to communicate, to force, proprioception, and visual sensors on robots. While there has been an explosion of interest in multimodal learning, these methods are focused on a small set of modalities primarily in language, vision, and audio. In order to accelerate generalization towards diverse and understudied modalities, this paper studies efficient representation learning for high-modality scenarios involving a large set of diverse modalities. Since adding new models for every new modality becomes prohibitively expensive, a critical technical challenge is heterogeneity quantification: how can we measure which modalities encode similar information and interactions in order to permit parameter sharing with previous modalities? This paper proposes two new information theoretic metrics for heterogeneity quantification: (1) modality heterogeneity studies how similar 2 modalities {X1,X2} are by measuring how much information can be transferred from X1 to X2, while (2) interaction heterogeneity studies how similarly pairs of modalities {X1,X2}, {X3,X4} interact by measuring how much information can be transferred from fusing {X1,X2} to {X3,X4}. We show the importance of these 2 proposed metrics as a way to automatically prioritize the fusion of modalities that contain unique information or interactions. The result is a single model, HighMMT, that scales up to 10 modalities (text, image, audio, video, sensors, proprioception, speech, time-series, sets, and tables) and 15 tasks from 5 research areas. Not only does HighMMT outperform prior methods on the tradeoff between performance and efficiency, it also demonstrates a crucial scaling behavior: performance continues to improve with each modality added, and it transfers to entirely new modalities and tasks during fine-tuning.", "venue": "", "year": 2022, "citationCount": 17, "influentialCitationCount": 2, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The result is a single model, HighMMT, that scales up to 10 modalities (text, image, audio, video, sensors, proprioception, speech, time-series, sets, and tables) and 15 tasks from 5 research areas and demonstrates a crucial scaling behavior."}, "embedding": {"model": "specter_v2", "vector": [0.4692371189594269, 0.39777716994285583, -0.2726289927959442, -0.34734055399894714, -1.01398766040802, 0.132695734500885, 0.5730085372924805, -0.23722025752067566, -0.33393311500549316, -0.11356593668460846, 0.6481590867042542, 0.6408377289772034, 0.011775556020438671, 0.27649736404418945, -0.02218952402472496, 0.1592504233121872, -1.0519565343856812, 0.425801545381546, -0.27446502447128296, -0.4966752529144287, -0.3339942693710327, -0.6280715465545654, -1.30716872215271, 0.20310619473457336, 0.002787333447486162, 1.1037760972976685, 0.12923353910446167, 0.9726014733314514, -0.2677499055862427, 0.2990889251232147, 0.564297080039978, -0.0799240842461586, 0.34166064858436584, -0.16217119991779327, -0.35869383811950684, -0.02370741218328476, 0.4308789372444153, -0.20898425579071045, -0.666895866394043, 0.4404129385948181, -0.3297029435634613, 0.35948777198791504, 0.9468473792076111, -0.9331900477409363, 0.2711135745048523, 0.6467206478118896, 0.6648438572883606, 0.2680239677429199, 0.3573894500732422, -0.7867090702056885, 1.4867020845413208, -1.2799359560012817, 0.12265032529830933, 1.920156478881836, 0.48654860258102417, 0.7093884348869324, -0.4467506408691406, -0.7021082043647766, 0.2556350529193878, -0.0836629793047905, -0.2716156542301178, 0.0981505885720253, -0.09482882916927338, -0.30823323130607605, 1.0217281579971313, -0.31467655301094055, -0.2603137791156769, 1.0338225364685059, 0.12464997172355652, 1.4975625276565552, 0.19473996758460999, -0.6104174852371216, -0.16087952256202698, -0.029877306893467903, 0.3999180495738983, 0.6498196721076965, -0.740727424621582, 0.46949511766433716, -1.5900999307632446, -0.07665037363767624, 0.2882358133792877, 0.122540682554245, -0.16877590119838715, 0.0069133746437728405, -0.9073887467384338, 0.4940859079360962, 0.403039813041687, 0.6470365524291992, -0.2086254507303238, 0.7305033802986145, 0.8469213843345642, 0.8389822244644165, -0.4986608922481537, 0.4713677167892456, -0.05468963459134102, -0.18193049728870392, -0.1305191069841385, -0.045079201459884644, 0.168364018201828, 0.8832488059997559, -0.11733964830636978, -0.03535529971122742, -0.31951674818992615, 0.47499001026153564, 1.4202258586883545, 0.10881960391998291, 0.4350454807281494, -0.7916885018348694, 0.7051227688789368, -0.518113374710083, -0.015718717128038406, -0.650356650352478, -0.408680260181427, 0.24382130801677704, -0.6416708827018738, -1.01564621925354, -0.4619297385215759, 0.3127639591693878, -0.8839457631111145, 0.8678231239318848, -0.6501284241676331, -0.3638345003128052, 0.16990068554878235, 0.5141078233718872, 0.6542814373970032, 0.5631024241447449, 0.21140216290950775, 0.37978750467300415, 0.7391260862350464, -0.5554708242416382, -0.6664223670959473, -0.746073842048645, 0.324386328458786, 0.023231975734233856, 0.23260889947414398, -0.20860451459884644, -1.3155313730239868, -0.9785366654396057, -0.6787502765655518, 0.21181681752204895, -0.38932114839553833, 0.11166824400424957, 1.0715068578720093, 0.06469937413930893, -0.47124433517456055, 0.7427092790603638, -0.5058169364929199, -0.28325366973876953, 0.06455222517251968, 0.4541861116886139, -0.5454383492469788, -0.5144398212432861, -1.1582261323928833, 0.5826606154441833, 0.5785681009292603, -0.6654687523841858, -0.49669522047042847, -0.21527251601219177, -1.4745160341262817, -0.2204454094171524, 0.01022234745323658, -0.7372974753379822, 0.8493316173553467, 0.00035109970485791564, -1.2210451364517212, 0.0668892115354538, 0.00010194841888733208, 0.7153708338737488, 0.3515338599681854, -0.09363234043121338, -0.43255168199539185, -0.2321871966123581, -0.2911669611930847, 0.800363302230835, 0.04954289644956589, -0.6114458441734314, -0.37381646037101746, 0.0699506625533104, -0.28018754720687866, 0.5762506127357483, -0.4586414098739624, 0.5772194862365723, 0.05313757807016373, -0.32965394854545593, 0.5278782248497009, 0.5331452488899231, 0.10795223712921143, -0.06257008016109467, -0.3978425860404968, -0.7337655425071716, 0.832103967666626, 0.1732567995786667, 0.1818387657403946, -1.0257729291915894, 0.06540276855230331, -0.05025237053632736, 0.02336818538606167, -0.749954342842102, -1.1707953214645386, 1.0170131921768188, -0.15198451280593872, 0.22139258682727814, -0.5234293937683105, -1.4553008079528809, 0.2452581822872162, 0.17885401844978333, -0.3095722794532776, -0.29909637570381165, 0.015172881074249744, 0.6330320835113525, -0.6985432505607605, 0.03749087080359459, 0.28279778361320496, 0.05758964642882347, -0.4351678192615509, 1.347746729850769, -0.0009988982928916812, 0.3234720230102539, 0.32694801688194275, 0.19036278128623962, -0.09553501754999161, -0.06986924260854721, 0.16301916539669037, -0.7976988554000854, 0.4390305280685425, 0.46862539649009705, -0.5652487277984619, 2.168391227722168, -0.3159707188606262, 0.5757739543914795, -0.28225862979888916, -0.707366943359375, 0.023627404123544693, 0.4796300530433655, 0.3351234197616577, -0.35711780190467834, 0.47340527176856995, 0.32337063550949097, -0.5382422804832458, 0.05503484979271889, 0.4655136466026306, 0.5690401792526245, -0.5565938353538513, 0.07468236982822418, 1.1455469131469727, -0.46863889694213867, 0.38989782333374023, 0.2820076644420624, 0.7408572435379028, 0.2126958966255188, 0.12910600006580353, 0.31090179085731506, -0.03752675652503967, -1.0169777870178223, -0.38916823267936707, 0.520745038986206, 0.48929786682128906, 0.9772767424583435, 0.025323990732431412, -0.28141462802886963, -0.07891102880239487, -0.659327507019043, 0.7228859066963196, 1.5778394937515259, 0.34601926803588867, -0.3103434145450592, -0.0638076588511467, -0.17855559289455414, -0.14449675381183624, -0.3263755738735199, -0.763418972492218, -0.41814854741096497, -0.0459715873003006, -0.8536496162414551, 0.6947763562202454, 0.646108090877533, 0.9777961373329163, -0.4020805358886719, -0.29546424746513367, -0.5642517805099487, -0.15620599687099457, -0.6145803928375244, -0.4161779284477234, 0.43148818612098694, -0.378074049949646, -0.14502394199371338, -0.14714953303337097, 0.05037223920226097, -0.2168021947145462, -0.8050261735916138, 0.631561279296875, -1.1682071685791016, -0.4245159924030304, 0.8606181740760803, 0.4398544132709503, -0.7217313647270203, -0.8593368530273438, -0.2913152873516083, 0.15538272261619568, -0.30615031719207764, -0.17979693412780762, 0.34470540285110474, 0.44264671206474304, 0.18319790065288544, -0.6542541980743408, 0.23543955385684967, 0.121348537504673, 0.5575913786888123, 0.44025489687919617, -0.2535741925239563, 0.007809698116034269, -0.36551764607429504, 0.9884971380233765, -0.12102271616458893, 0.3380126655101776, 0.367258220911026, -0.05689576640725136, -0.40288880467414856, 0.005994514096528292, -0.792617678642273, -0.12054652720689774, -0.6617551445960999, 0.4088512659072876, -0.3210773169994354, -0.4666389226913452, 0.6497555375099182, 0.33141860365867615, -0.11899521946907043, 0.3697676658630371, 0.412754088640213, 0.6734627485275269, 0.07731087505817413, 0.42884036898612976, -0.6919076442718506, 0.4598809778690338, 0.06731785088777542, 0.21378782391548157, -0.15602029860019684, 0.16284514963626862, -0.778907060623169, -0.2371324598789215, -0.46469739079475403, -0.34998100996017456, -0.3580401539802551, 0.05622320622205734, -0.43706536293029785, -0.985405445098877, -0.01110544428229332, -0.9897711277008057, 0.33564746379852295, -0.004183441400527954, 0.45954564213752747, -0.6138315200805664, -0.8759326338768005, -1.13656747341156, -0.7755883932113647, -0.21410270035266876, -1.151583194732666, 0.41314563155174255, 0.013325322419404984, -0.3880794644355774, -0.6333550214767456, -0.07430054992437363, -0.1870509386062622, 0.6475014090538025, -0.3256489038467407, 0.5991301536560059, -0.0933288037776947, 0.11173999309539795, -0.33248692750930786, 0.07666805386543274, 0.5463511943817139, 0.3087449073791504, -0.05980069935321808, -1.013114333152771, 0.39513376355171204, -0.43547704815864563, -0.7736666798591614, 0.3312157690525055, 0.10127537697553635, 0.5775371789932251, 0.5596082210540771, -0.17632237076759338, -0.16030874848365784, 1.1327754259109497, -0.1875804364681244, -0.38792452216148376, -0.08885932713747025, 1.2067928314208984, 0.6636669039726257, -0.3620794713497162, 0.6089711785316467, 0.6387447714805603, 0.4369604289531708, 0.3150843679904938, -0.09280670434236526, -0.22154515981674194, -0.4155036211013794, 0.36028239130973816, 1.387690782546997, -0.18863503634929657, -0.12065097689628601, -1.0110329389572144, 0.38221997022628784, -1.447371244430542, -0.564927875995636, 1.1308562755584717, 0.8000608682632446, 0.31364768743515015, -0.7528222799301147, -0.02371682971715927, 0.07825352251529694, 0.3342607915401459, -0.1356692910194397, -0.2859034538269043, -0.06877592951059341, -0.10523898154497147, 0.1259411722421646, -0.32172366976737976, 0.336210697889328, -0.46635982394218445, -0.3572247326374054, 14.901601791381836, 0.6448327898979187, -0.06468559801578522, 0.400002121925354, 0.20740830898284912, 0.5709948539733887, -0.592915415763855, -0.4552496671676636, -0.5512772798538208, 0.13212935626506805, 1.0978991985321045, 0.43916064500808716, 0.6570695042610168, -0.27884119749069214, -0.5170040726661682, 0.3550240993499756, -1.3015501499176025, 1.119787335395813, 0.4341370761394501, -0.8952227234840393, 0.3822026550769806, -0.012503175064921379, 0.06640774756669998, 0.512096107006073, 0.8311552405357361, 0.7047654390335083, 0.13665643334388733, -0.6690919995307922, 0.49974486231803894, 0.44892656803131104, 1.0041677951812744, 0.07661595195531845, 0.26493120193481445, 0.43789568543434143, -1.1724857091903687, -0.604483425617218, -0.00995678547769785, -0.7361339330673218, 0.2703959047794342, -0.34086042642593384, -0.508888304233551, 0.10922706127166748, -0.08447103202342987, 1.0774872303009033, 0.40182730555534363, 0.3532315194606781, 0.35960280895233154, 0.3645431399345398, -0.33613353967666626, 0.07344117760658264, -0.10197456926107407, 0.7712250351905823, 0.5897098779678345, -0.002013147808611393, 0.021237816661596298, -0.505894660949707, 0.49023279547691345, 0.10300765931606293, -0.3759116232395172, -0.08740853518247604, -0.6553791761398315, -0.4513302743434906, -0.02634119801223278, 0.41161760687828064, 0.8891680836677551, 0.41449806094169617, -0.4428219199180603, 0.16627806425094604, 0.281461238861084, 0.253947913646698, 0.009621923789381981, -0.06242049112915993, 0.31855231523513794, -0.9248258471488953, -0.5680230259895325, 0.5997928977012634, -0.2884761393070221, -0.6320484280586243, -0.4296315908432007, -0.3503393828868866, 0.7961435317993164, -0.8145700693130493, -1.6283271312713623, 0.8912009596824646, 0.2823264002799988, -0.9372518658638, 0.16321474313735962, -0.7562136054039001, 0.14423154294490814, 0.5505651235580444, -0.9864842295646667, -0.9267057180404663, -0.04599907249212265, 0.12856939435005188, -0.18982069194316864, -0.3526739478111267, 1.4884792566299438, 0.10853735357522964, 0.05828484892845154, 0.14198905229568481, -0.2719387114048004, -0.3476877510547638, -0.07051683962345123, -0.8361900448799133, -0.027047106996178627, -0.37282148003578186, -0.1567605584859848, 0.28264716267585754, -0.14650946855545044, 0.3604937791824341, -0.8003634810447693, 0.27665501832962036, 0.21264560520648956, -0.6568081974983215, -0.20292876660823822, -0.4278576672077179, -0.7192896008491516, 0.23490886390209198, 0.4456375241279602, -0.3733842372894287, 0.7514199614524841, 0.3953871428966522, -0.9383130669593811, -0.058876603841781616, -0.9214113354682922, 0.051918238401412964, 0.3934969902038574, -1.1012431383132935, -0.7107364535331726, -0.1375507265329361, 0.05270639806985855, -1.1373800039291382, -1.0721112489700317, 0.42791086435317993, 0.5049051642417908, 0.21496988832950592, 0.8819147944450378, -0.5110863447189331, 0.7857392430305481, 0.797886312007904, -0.8942902684211731, -1.0062731504440308, 0.2262037694454193, -0.5861926674842834, -0.012238376773893833, -0.40229910612106323, 0.5216658711433411, -0.4204041659832001, -0.26434534788131714, 0.7759682536125183, 0.005246304906904697, -0.49170199036598206, -0.8573189973831177, -0.06399191915988922, -0.4233170449733734, -0.36660251021385193, 0.08819025754928589, -0.12845955789089203, 0.206943541765213, 0.321380078792572, 0.31345751881599426, 0.486724853515625, -0.1353381872177124, -0.6836015582084656, 0.20551413297653198, -0.3083081543445587, -0.3028428554534912, -0.5433443188667297, -0.9527789354324341, -1.1203795671463013, -0.05710674449801445, -1.1329106092453003, 0.18748146295547485, -0.8525311350822449, -0.14525938034057617, 0.31587475538253784, -0.4176603853702545, 0.411802738904953, 0.5213429927825928, -0.3824397623538971, 0.057285718619823456, -0.40566450357437134, -0.3239865005016327, 1.0637356042861938, 1.1186543703079224, -1.0758135318756104, 0.019438646733760834, -0.06733676791191101, 0.13187554478645325, 0.14853721857070923, 0.13928277790546417, -0.1953117400407791, -1.008903980255127, -0.942642092704773, -0.07321108132600784, 0.4062482714653015, 0.052492957562208176, -1.08063542842865, 0.49768006801605225, 0.2362934947013855, -0.22271005809307098, 0.10723672062158585, 1.4086562395095825, -1.2535736560821533, -0.12700022757053375, 0.48685044050216675, -1.4250757694244385, 0.005414657294750214, 0.17183780670166016, -0.36515647172927856, -0.6028000116348267, 0.7664564847946167, -0.29697534441947937, -0.7834440469741821, -0.5285179018974304, 0.4023062586784363, -0.27381500601768494, -0.08196523785591125, -0.12323744595050812, 0.0028225742280483246, -1.1037462949752808, -0.45003363490104675, -0.5175824761390686, 0.3565208315849304, -0.7017579078674316, 0.8429170250892639, 0.77511066198349, -1.218591570854187, -0.016032343730330467, 0.2137044370174408, 0.5846524238586426, -0.2443183958530426, 0.6799300312995911, 0.3686618208885193, 0.3059125542640686, -0.0930708646774292, -0.30209457874298096, -0.09033625572919846, -0.8738232254981995, -0.7120676040649414, 0.9009497165679932, -0.0045057786628603935, -0.09684427082538605, 1.2962476015090942, -0.14110566675662994, -1.2764616012573242, 0.4886261224746704, -0.8396360278129578, -0.4222654104232788, -0.2653990387916565, 0.40067440271377563, 0.308734655380249, -0.44061246514320374, -0.1064271479845047, -0.5317088961601257, 0.2494315356016159, -0.2856373190879822, -0.9528132677078247, 0.11700872331857681, -0.1931115686893463, -0.11517031490802765, 1.314535140991211, 1.1339949369430542, -1.0891278982162476, -0.547217071056366, -0.3961412310600281, -0.627814769744873, -0.1090444028377533, -0.22193396091461182, -0.7076631188392639, -0.5405504703521729, 0.752872109413147, 0.8730834126472473, 0.46674051880836487, 0.09989385306835175, 0.309136301279068, 0.13905228674411774, 1.0144106149673462, 0.23212909698486328, -0.39109233021736145, -0.09517321735620499, 1.0813164710998535, 1.7030848264694214, -1.228937029838562, 0.0008417130447924137, -0.4507691264152527, -0.8909868001937866, 0.8323711156845093, 0.37356501817703247, 0.2631043493747711, 1.0095374584197998, -0.304327130317688, -0.0632101446390152, 0.02420513518154621, -0.9412115812301636, -0.10577162355184555, 1.4297391176223755, 1.4627511501312256, 0.3626638650894165, 0.6659981608390808, 0.10042627155780792, 0.5699912905693054, -0.002718160394579172, 0.01983056031167507, 0.4759677052497864, 0.6763272881507874, 0.120449498295784, 0.06832918524742126, 0.25572171807289124, 0.8115215301513672, -0.15875650942325592, 0.18588104844093323, 0.32369405031204224, 0.34114062786102295, -0.052053302526474, 0.7174100875854492, 0.42150813341140747, -0.5353129506111145, 0.5868083238601685, -0.2858210504055023, 0.8519038558006287, -0.6048011183738708, 0.11108420044183731, -0.32728302478790283, -0.4707646369934082, -0.21652348339557648, -0.9235819578170776, -0.4556948244571686, -0.6467695236206055, 0.40511950850486755, 0.44313356280326843, -0.045535262674093246, 0.5819873213768005, 1.179052472114563, 0.5420035123825073, 0.5267626643180847, -0.03203374892473221, -0.8382446765899658, -0.44225552678108215, -1.0710480213165283, -0.04515451937913895, -0.1512698531150818, 0.08282046765089035, -0.9510492086410522, -0.35789161920547485, -0.23836369812488556]}, "authors": [{"authorId": "28130078", "name": "P. Liang"}, {"authorId": "2066413750", "name": "Yiwei Lyu"}, {"authorId": "2152774190", "name": "Xiang Fan"}, {"authorId": "2196529480", "name": "Jeffrey Tsaw"}, {"authorId": "2144409312", "name": "Yudong Liu"}, {"authorId": "2066123456", "name": "Shentong Mo"}, {"authorId": "1755465", "name": "Dani Yogatama"}, {"authorId": "49933077", "name": "Louis-Philippe Morency"}, {"authorId": "145124475", "name": "R. Salakhutdinov"}], "references": [{"paperId": "da741827ab6f5bf9762d30b91fd2409ac9e0e272", "title": "World models and predictive coding for cognitive and developmental robotics: frontiers and challenges"}, {"paperId": "6baade7201f0bbf079d21f862d3e6d42da85e649", "title": "Disentangled Representation Learning for Multimodal Emotion Recognition"}, {"paperId": "c0d44b05a042cb3d13eb2bbf5f79f3f6d3b6cc83", "title": "An Information-Theoretic Analysis for Transfer Learning: Error Bounds and Applications"}, {"paperId": "5922f437512158970c417f4413bface021df5f78", "title": "A Generalist Agent"}, {"paperId": "6fca4e69d8d7fec0b1fe118e769017b3610d1bd5", "title": "A survey of multimodal deep generative models"}, {"paperId": "ca77478b66de1dbf4d8112b8731eb7bdb31cd3ca", "title": "A multimodal fusion method for sarcasm detection based on late fusion"}, {"paperId": "e9e04d4a6f84276229ab9dadf705f055484f7c7a", "title": "Computing"}, {"paperId": "c8f92e2033630bec76d4e3d3c02b11088e30dda9", "title": "Towards a Unified Foundation Model: Jointly Pre-Training Transformers on Unpaired Images and Text"}, {"paperId": "2fd6f77540c1cc8e70b96208ccf9971b4251fc02", "title": "FLAVA: A Foundational Language And Vision Alignment Model"}, {"paperId": "00d7dfde1cd69d2247e8c36d10807b0dee9656d7", "title": "PolyViT: Co-training Vision Transformers on Images, Videos and Audio"}, {"paperId": "9933a5af7895354087baf6c96b64dc8a8973eaed", "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs"}, {"paperId": "af86df6a0af3226a1b4b5eb27c17c9e45367f896", "title": "MultiBench: Multiscale Benchmarks for Multimodal Representation Learning"}, {"paperId": "cc760dd9f909db13a1725e3c1f4975f47be358ef", "title": "Learning Language and Multimodal Privacy-Preserving Markers of Mood from Mobile Data"}, {"paperId": "f0524b3005720bcff886bcb0227f7f0dd924ff07", "title": "VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text"}, {"paperId": "3544650f12a05cf4ed3bf2f7e22fc5c02fcabf50", "title": "Pretrained Transformers as Universal Computation Engines"}, {"paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812", "title": "Perceiver: General Perception with Iterative Attention"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "d0584ccef45ad5472259a42e791030aba9953687", "title": "Sensor and Sensor Fusion Technology in Autonomous Vehicles: A Review"}, {"paperId": "cb596bffc5c5042c254058b62317a57fa156fea4", "title": "Unifying Vision-and-Language Tasks via Text Generation"}, {"paperId": "81002fbb777f860f9aac2bbc24467a62345af279", "title": "Decoupling the Role of Data, Attention, and Losses in Multimodal Transformers"}, {"paperId": "aed0f85b14e2c52e0c1850c93503bd637ff8119b", "title": "Parameter Efficient Multimodal Transformers for Video Representation Learning"}, {"paperId": "d718b1279a31d8a676f974b469dec20f376b2e7d", "title": "Cross-Modal Generalization: Learning in Low Resource Modalities via Meta-Alignment"}, {"paperId": "757782a0524d6d23f430d6d8f924c6212d6afeac", "title": "Foundations of Multimodal Co-learning"}, {"paperId": "21b6abc0f8ec0ac997893e06c31225a5e5ac016d", "title": "Multimodal Sensor Fusion with Differentiable Filters"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "c5bc58af782f4207ad2ec4a174ebd4efd0cda1f3", "title": "Enrico: A Dataset for Topic Modeling of Mobile UI Designs"}, {"paperId": "692ea9770c42bb3b4f9ddb075ce157dd1064e75c", "title": "Early vs Late Fusion in Multimodal Convolutional Neural Networks"}, {"paperId": "64a0c241095faffdba00cbab90ce385b6db41b06", "title": "Multimodal Transformer for Multimodal Machine Translation"}, {"paperId": "0696ad8beb0d765973aa5cdbc6e118889d3583b0", "title": "Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions"}, {"paperId": "caa31faab39d34ecbb8100911640dfaec76f9ee9", "title": "Multiplicative Interactions and Where to Find Them"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "6a9d69fb35414b8461573df333dba800f254519f", "title": "Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting"}, {"paperId": "dfc7b58b67c31932b48586b3e23a43cc94695290", "title": "UNITER: UNiversal Image-TExt Representation Learning"}, {"paperId": "0a7620afb12870a5df0e178dd175d37a5cbc8c0c", "title": "Supervised Multimodal Bitransformers for Classifying Images and Text"}, {"paperId": "4aa6298b606941a282d735fa3143da293199d2ca", "title": "VL-BERT: Pre-training of Generic Visual-Linguistic Representations"}, {"paperId": "79c93274429d6355959f1e4374c2147bb81ea649", "title": "LXMERT: Learning Cross-Modality Encoder Representations from Transformers"}, {"paperId": "5aec474c31a2f4b74703c6f786c0a8ff85c450da", "title": "VisualBERT: A Simple and Performant Baseline for Vision and Language"}, {"paperId": "65a9c7b0800c86a196bc14e7621ff895cc6ab287", "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"}, {"paperId": "1be579f4c120a8bf15c4df78d622549913b4d8f7", "title": "Making Sense of Vision and Touch: Learning Multimodal Representations for Contact-Rich Tasks"}, {"paperId": "efcfb79f4cd92db09dbb21e9e8cd25dbcccd5460", "title": "Overview of artificial intelligence in medicine"}, {"paperId": "949fef650da4c41afe6049a183b504b3cc91f4bd", "title": "Multimodal Transformer for Unaligned Multimodal Language Sequences"}, {"paperId": "02f55b398ff8c4d03314e99da7e815d190794471", "title": "What Makes Training Multi-Modal Classification Networks Hard?"}, {"paperId": "356941da708c6d5b06bce17463aca309fd33151a", "title": "Which Tasks Should Be Learned Together in Multi-task Learning?"}, {"paperId": "296e8ceeba6550d7ec9b9ee727e0c17420ebb926", "title": "UR-FUNNY: A Multimodal Language Dataset for Understanding Humor"}, {"paperId": "c41a11c0e9b8b92b4faaf97749841170b760760a", "title": "VideoBERT: A Joint Model for Video and Language Representation Learning"}, {"paperId": "2698e3fc3b13cdd79b5a62c47b78759cd991c470", "title": "Cross-Modal Data Programming Enables Rapid Medical Machine Learning"}, {"paperId": "e5cd45ee1e91ba7a68d2a18d0735a75ed021766a", "title": "MFAS: Multimodal Fusion Architecture Search"}, {"paperId": "7d113621ab50a8b875a12cea3ad5b0263e9520ac", "title": "Adaptive Cross-Modal Few-Shot Learning"}, {"paperId": "57eedf785fd9e3ea28b4cd30539cb0fa374f9e74", "title": "Characterizing and Avoiding Negative Transfer"}, {"paperId": "e8e7b0b23e70624fbc3bc5ab74ae01e39c6750a5", "title": "Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks"}, {"paperId": "45a41d539fd2e6803c31cfa5d9ba3683d2935046", "title": "CentralNet: a Multilayer Approach for Multimodal Fusion"}, {"paperId": "96f65ecdf1d991cbfd1b3722df662ac6bd071cb2", "title": "Social robots for education: A review"}, {"paperId": "006fdeff6e1a81c404317ee4056d6cc72f9c0e50", "title": "Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph"}, {"paperId": "2fe2cfd98e232f1396f01881853ed6b3d5e37d65", "title": "Taskonomy: Disentangling Task Transfer Learning"}, {"paperId": "775f7845e4df2576762960943294bd28733e2046", "title": "Rico: A Mobile App Dataset for Building Data-Driven Design Applications"}, {"paperId": "7ad66cba3b7e3abae7ef33122588512a146f7f77", "title": "A Survey on Multi-Task Learning"}, {"paperId": "5a96f2bfa2deae2bc35b250251d5fbe82ef4932b", "title": "Tensor Fusion Network for Multimodal Sentiment Analysis"}, {"paperId": "9ae0a24f0928cab1554a6ac880f6b350f85be698", "title": "One Model To Learn Them All"}, {"paperId": "6d431f835c06afdea45dff6b24486bf301ebdef0", "title": "An Overview of Multi-Task Learning in Deep Neural Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91", "title": "Multimodal Machine Learning: A Survey and Taxonomy"}, {"paperId": "95cd83603a0d2b6918a8e34a5637a8f382da96f5", "title": "MIMIC-III, a freely accessible critical care database"}, {"paperId": "d079a2f877f554e00f71a6975435d8325987bdf5", "title": "Return of Frustratingly Easy Domain Adaptation"}, {"paperId": "99e6f700d374e34c8376f1f43af994b278924f28", "title": "ESC: Dataset for Environmental Sound Classification"}, {"paperId": "97ad70a9fa3f99adf18030e5e38ebe3d90daa2db", "title": "VQA: Visual Question Answering"}, {"paperId": "5e80e7131e77fecfc1cf6648f0f6b25e364c7e4d", "title": "Human Computer Interaction"}, {"paperId": "755e9f43ce398ae8737366720c5f82685b0c253e", "title": "Zero-Shot Learning Through Cross-Modal Transfer"}, {"paperId": "30e957aa84080fee448c36d8bb3070a1c43b5990", "title": "On the Classification of Emotional Biosignals Evoked While Viewing Affective Pictures: An Integrated Data-Mining-Based Approach for Healthcare Applications"}, {"paperId": "9f62067945d991cd78a62cf647de17f01d1b54d3", "title": "Frustratingly Easy Domain Adaptation"}, {"paperId": "161ffb54a3fdf0715b198bb57bd22f910242eb49", "title": "Multitask Learning"}, {"paperId": "1bd6e929ed8384ea2212d50ab3c103ec018cc9fd", "title": "A Bayesian/Information Theoretic Model of Learning to Learn via Multiple Task Sampling"}, {"paperId": "68c03788224000794d5491ab459be0b2a2c38677", "title": "WordNet: A Lexical Database for English"}, {"paperId": "dde6314d038523180dea071d6db6469455621762", "title": "On negative transfer: Effects of testing one list on the recall of another"}, {"paperId": "63bb664f377d801f21e6b626a1a8574074ef78e6", "title": "Multimodal Core Tensor Factorization and its Applications to Low-Rank Tensor Completion"}, {"paperId": "63f93a6d9c38d656933706acfc720684470bc108", "title": "Foundations and Recent Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions"}, {"paperId": "ede4ed9442c3688783c0411370dd9e19e32d6c80", "title": "Transformer is All You Need: Multimodal Multitask Learning with a Unified Transformer"}, {"paperId": "ea3b3683b4e6879ab34cdbd322fd5e9c1240b512", "title": "A comprehensive survey on multimodal medical signals fusion for smart healthcare systems"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Md Iftekhar Tanveer, Louis-Philippe Morency, and Mohammed Ehsan Hoque"}, {"paperId": "cd49acefc8d51e324aa562e5337e1c2aff067053", "title": "An Overview of Multi-task Learning"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "459839e00be022205fa8cffd051d42ffd2959f81", "title": "An Information Theoretic Framework for Multi-view Learning"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": null, "title": "Tidigits speech corpus"}, {"paperId": null, "title": "Shared Modality Encoding N/A"}, {"paperId": null, "title": "Perceiver Input Channel Size Colorless Image: 16 (cut into 4x4 squares) Audio Spectogram: 256 (cut into 16x16 squares"}, {"paperId": null, "title": "Co-training vision transformers"}]}