{"paperId": "bfe6fd05f09647b001c7eb6e333a95c881c88344", "abstract": "Foundation models have shown impressive adaptation and scalability in supervised and self-supervised learning problems, but so far these successes have not fully translated to reinforcement learning (RL). In this work, we demonstrate that training an RL agent at scale leads to a general in-context learning algorithm that can adapt to open-ended novel embodied 3D problems as quickly as humans. In a vast space of held-out environment dynamics, our adaptive agent (AdA) displays on-the-fly hypothesis-driven exploration, efficient exploitation of acquired knowledge, and can successfully be prompted with first-person demonstrations. Adaptation emerges from three ingredients: (1) meta-reinforcement learning across a vast, smooth and diverse task distribution, (2) a policy parameterised as a large-scale attention-based memory architecture, and (3) an effective automated curriculum that prioritises tasks at the frontier of an agent's capabilities. We demonstrate characteristic scaling laws with respect to network size, memory length, and richness of the training task distribution. We believe our results lay the foundation for increasingly general and adaptive RL agents that perform well across ever-larger open-ended domains.", "venue": "International Conference on Machine Learning", "year": 2023, "citationCount": 82, "influentialCitationCount": 8, "openAccessPdf": {"url": "http://arxiv.org/pdf/2301.07608", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is demonstrated that training an RL agent at scale leads to a general in-context learning algorithm that can adapt to open-ended novel embodied 3D problems as quickly as humans."}, "embedding": {"model": "specter_v2", "vector": [0.10534534603357315, 0.4811902642250061, 0.01524010393768549, 0.19500190019607544, 0.28562435507774353, 0.19940419495105743, 0.38925281167030334, -0.28281721472740173, -0.5451247692108154, 0.3396795988082886, 0.03695441782474518, -0.04468512907624245, -0.27189570665359497, 0.19739778339862823, -0.3786364495754242, 0.08461141586303711, -1.5189849138259888, 0.5646295547485352, 0.09554387629032135, -0.6461667418479919, -0.35816213488578796, -0.5046280026435852, -1.2263449430465698, -0.36404651403427124, 0.4947841167449951, 0.21556149423122406, 0.4288962185382843, 1.3573050498962402, 0.4433813691139221, 0.25333571434020996, 0.4670780599117279, 0.40111202001571655, 0.5045670866966248, -0.09625282138586044, -0.48845112323760986, 0.043515317142009735, 0.21375377476215363, -0.4273066520690918, -0.8311762809753418, 0.3224153518676758, -0.0027344494592398405, 0.3995322585105896, 0.6712989211082458, -0.4578973352909088, -0.2452750951051712, -0.051082953810691833, 0.7987921237945557, 0.870620846748352, 0.27289944887161255, -0.1514049470424652, 1.1325578689575195, -0.9573468565940857, 0.5610316395759583, 1.52602219581604, 0.42514708638191223, 0.8929700255393982, -0.448354035615921, -0.26410973072052, 0.8902710676193237, -0.034275878220796585, -0.2477131336927414, 0.3151201903820038, -0.015062102116644382, -0.034468796104192734, 1.3030836582183838, -0.9760456681251526, 0.7483342289924622, 1.0445926189422607, 0.40385136008262634, 1.415650725364685, 0.2640526294708252, -1.4285935163497925, 0.35131552815437317, 0.30059534311294556, -0.10090477764606476, 0.6571845412254333, -0.2373470813035965, 0.956875205039978, -1.142737865447998, 0.15954068303108215, 0.9561070799827576, -0.4204639196395874, 0.1925479769706726, -0.8355314135551453, -0.36108851432800293, 0.48015856742858887, 0.588723361492157, 0.4875679314136505, -0.6674829721450806, 0.8475502729415894, 0.2645582854747772, 0.7322414517402649, -0.07267910987138748, 0.3557741045951843, 0.008284848183393478, 0.2928749620914459, -0.1469816416501999, 0.522335946559906, 0.22665105760097504, 0.7271946668624878, 0.24204078316688538, 0.080774687230587, -0.3293321430683136, 0.21052739024162292, 1.2632161378860474, 0.0014325830852612853, 0.7087107300758362, -0.6976848840713501, 0.19058705866336823, -0.44447997212409973, 0.8540354371070862, -0.5794534683227539, -0.7939473986625671, -0.4289630055427551, -0.1655762493610382, -0.27463436126708984, -0.3426995873451233, 0.03144359216094017, -0.3806324303150177, 0.8262258172035217, 0.7535331845283508, -0.266308069229126, 0.009139622561633587, 1.1357030868530273, -0.19777633249759674, 0.09475311636924744, 0.28292375802993774, 0.41425690054893494, 0.5560092329978943, -0.8702648878097534, -0.41675087809562683, -1.132153034210205, 0.1329260915517807, 0.5203253030776978, 0.6449942588806152, -0.3227022886276245, -1.3371928930282593, -1.206426739692688, -1.2880209684371948, 0.36354315280914307, -0.5913839936256409, -0.12022634595632553, 1.5365819931030273, 0.266214519739151, -0.603813648223877, 0.9297428727149963, -0.2206980288028717, -0.5902628302574158, 0.3177335262298584, 0.4267130494117737, 0.05462545156478882, -0.30557969212532043, -1.0350114107131958, 0.7650797963142395, 0.6286224126815796, -0.3649441599845886, -0.9064996242523193, 0.1686592698097229, -1.1281431913375854, -0.7024476528167725, 0.3201925754547119, -1.251434564590454, 1.3380324840545654, -0.7539606094360352, -1.5344215631484985, 0.26260900497436523, 0.12486012279987335, -0.020890286192297935, 0.5435894131660461, -0.2811655104160309, -0.7004868984222412, -0.028440631926059723, -0.4643925428390503, 0.9218151569366455, 0.40796902775764465, -0.5769961476325989, -0.28409573435783386, -0.16136305034160614, -0.03512157127261162, 0.4061400890350342, -0.33307522535324097, 0.3396221101284027, -0.04205513000488281, -0.24236860871315002, 0.04250793531537056, 0.16069328784942627, -0.20788025856018066, -0.13559463620185852, 0.24956583976745605, -1.028295874595642, 0.48832085728645325, 0.4836038649082184, 0.7398074865341187, -0.733849048614502, -0.12100276350975037, 0.048703569918870926, -0.03976321965456009, -0.5254526734352112, -1.1444299221038818, 0.538909912109375, -0.19042930006980896, -0.17906677722930908, -0.12783978879451752, -0.8996925354003906, 0.2104511857032776, 0.08218099176883698, -0.14827486872673035, -0.04573274403810501, -0.060223471373319626, 0.9478375315666199, -1.524957537651062, -0.08870868384838104, 0.08879327774047852, 0.11797097325325012, -0.8574993014335632, 1.3514083623886108, -0.6760094165802002, 0.41201382875442505, -0.3225465416908264, -0.39546674489974976, -0.3190878927707672, -0.13090987503528595, 0.5206863284111023, 0.1295369267463684, 0.2762281894683838, 0.19297544658184052, -0.46588853001594543, 1.9395244121551514, -0.5076509118080139, 0.6908536553382874, 0.06170514225959778, 0.05675768479704857, 0.03551483154296875, 0.37953707575798035, -0.2824527323246002, -0.5881093144416809, 0.29229119420051575, 0.37732651829719543, -0.2855272889137268, -0.35861486196517944, 0.6364294290542603, 0.8416322469711304, -0.375265508890152, 0.3311988413333893, 0.5951458811759949, -0.32437700033187866, 0.32503607869148254, 0.15966790914535522, 0.5607761740684509, 1.142845630645752, 0.4018145799636841, -0.30630987882614136, 0.0023144620936363935, -0.9161818623542786, -0.3287515938282013, 0.6978648900985718, 0.35276731848716736, 0.3377995491027832, -0.26039695739746094, -1.4561121463775635, -0.33566078543663025, -0.2655182480812073, 0.6069943904876709, 1.597063422203064, 0.1291361302137375, 0.29976925253868103, -0.8793148994445801, -0.407693475484848, -0.24550336599349976, 0.43002116680145264, -1.1322370767593384, -0.0667257010936737, -0.7720500826835632, -0.6840899586677551, 0.37596845626831055, 0.32301416993141174, 1.1091688871383667, -1.1561815738677979, -1.0263088941574097, 0.21500904858112335, 0.8023311495780945, -0.33023467659950256, -0.7686460614204407, 0.3906472623348236, -0.21924543380737305, -0.3850242793560028, -0.12246815860271454, -0.3225955665111542, 0.27229639887809753, -0.4414324462413788, 0.853897750377655, -0.4563611149787903, -0.44633057713508606, 0.8725616931915283, 0.7903004884719849, -0.7385643720626831, -0.6149671673774719, 0.08421823382377625, 0.4563444256782532, -0.41320154070854187, -0.1404881775379181, 0.1477423459291458, -0.38375556468963623, 0.46017906069755554, -0.3701755106449127, 0.09035275131464005, 0.24212968349456787, 0.23563489317893982, 0.36443716287612915, -0.4168652296066284, 0.4961489737033844, -0.6463564038276672, 1.3776885271072388, 0.22675618529319763, -0.42910683155059814, 0.1697288155555725, -0.9119743704795837, -0.26768338680267334, 0.26664847135543823, -1.1511082649230957, -0.5317278504371643, -0.7273847460746765, 0.9583208560943604, -0.09401989728212357, -0.6904333233833313, 0.14141736924648285, 0.5679207444190979, -0.2989804148674011, 0.9937731623649597, 0.2523430585861206, 0.3605380952358246, 0.1865379512310028, 0.6541934013366699, -1.0421466827392578, 0.5956982970237732, -0.3713599443435669, 0.15961413085460663, -0.23686879873275757, 0.023487336933612823, -0.5847731232643127, -0.5107381939888, 0.15631449222564697, -0.5784245133399963, -0.9362751841545105, 0.3168996274471283, -0.6054607033729553, -1.0056445598602295, -0.24418146908283234, -0.779035210609436, -1.2317216396331787, 0.09303424507379532, -0.18074128031730652, -0.769047200679779, -1.0803391933441162, -0.7218889594078064, -0.6637982130050659, -0.20071196556091309, -0.7175516486167908, -0.0765257179737091, 0.25927719473838806, -0.8956395983695984, -0.9018285870552063, 0.7037898898124695, -0.5196190476417542, 0.9081243276596069, -0.41838741302490234, 0.431782066822052, 0.42985913157463074, -0.19396689534187317, 0.023101000115275383, 0.7214701771736145, -0.2172539085149765, -0.3326435387134552, -0.2757994830608368, -0.5344697833061218, -0.02206372283399105, -0.6935051679611206, -1.0509529113769531, -0.07671194523572922, -0.14466492831707, 0.5696716904640198, 0.21470358967781067, -0.14942656457424164, -0.09224335104227066, 0.8610122799873352, -0.5514665246009827, -0.18462778627872467, 0.9559276103973389, 0.38755109906196594, 0.3617405295372009, 0.034770503640174866, 0.6507681608200073, 0.8081774115562439, 0.616197943687439, 0.26252514123916626, -0.029662905260920525, -0.4346681237220764, -1.013677954673767, 0.44466400146484375, 0.7294064164161682, 0.07887759804725647, 0.15305577218532562, -0.7809688448905945, 0.4929986596107483, -1.4680631160736084, -0.46785011887550354, 1.3303519487380981, 0.9506842494010925, 0.2876277267932892, -0.1279767006635666, 0.32294416427612305, -0.5241907835006714, 0.5108826160430908, -0.11176882684230804, -0.6832908391952515, -0.25449883937835693, 0.04000544175505638, -0.01222742348909378, -0.4821445345878601, 0.6982419490814209, -0.450894832611084, 0.4246199131011963, 14.581762313842773, 0.40486958622932434, 0.606411874294281, 0.5639094710350037, 0.5349299907684326, 0.2660718262195587, -0.36879751086235046, -0.35974472761154175, -0.5063033699989319, -0.24901020526885986, 1.0447547435760498, 0.68235182762146, 1.226019263267517, 0.09639596194028854, -0.1442537009716034, -0.15476614236831665, -0.901196300983429, 0.2884015440940857, 0.42230281233787537, -0.7810136079788208, 0.2053154706954956, 0.09019068628549576, 0.33047419786453247, 0.38994404673576355, 0.8088721036911011, 1.0702836513519287, 0.6348201036453247, -0.18124093115329742, 0.9955177307128906, 0.1349068433046341, 0.8744348883628845, -0.18694894015789032, -0.15295715630054474, 0.7030652165412903, -0.8448476791381836, -0.639847993850708, -0.4583742916584015, -0.9108016490936279, 0.2943572998046875, -0.6869515776634216, -0.5953167676925659, -0.7813851237297058, -0.15966029465198517, 0.02651887759566307, 0.293159157037735, 0.1676693707704544, -0.5309391021728516, -0.09213995933532715, -0.2516399323940277, -0.49967291951179504, 0.10435764491558075, 0.6015303134918213, 0.32794690132141113, -0.20343531668186188, -0.30223602056503296, 0.32542258501052856, 0.07597900182008743, 0.5244371294975281, -0.03901396691799164, -0.5273621678352356, -0.3474523723125458, 0.2689182460308075, 0.23609958589076996, 0.4882311224937439, 0.8321315050125122, 0.6928624510765076, 0.1629754602909088, 0.4602656960487366, 0.9368890523910522, 0.4061321020126343, -0.09749182313680649, 0.05857636779546738, 0.11524699628353119, -0.7298704385757446, -0.12107919901609421, 0.1987370252609253, 0.03144458308815956, -0.30515721440315247, -0.8122149109840393, -0.525773823261261, 0.18484367430210114, -0.8599980473518372, -0.7414492964744568, 1.1033484935760498, -0.06079147756099701, -0.40192827582359314, 0.3627433180809021, -0.8626825213432312, -0.4479394257068634, -0.25632593035697937, -1.3359057903289795, -0.8572856783866882, 0.1132860779762268, 0.06284651905298233, -0.2891656160354614, -0.275545209646225, 1.350113034248352, -0.274737149477005, -0.7076030969619751, 0.22915206849575043, -0.09349475800991058, -0.7497491240501404, -0.1618380844593048, -1.0129212141036987, 0.594780683517456, -0.4387872517108917, -0.15096206963062286, 0.15904824435710907, 0.21539705991744995, 0.16167877614498138, -0.9467634558677673, 0.4142131209373474, -0.21991468966007233, -1.1888266801834106, -0.23110388219356537, -0.5886463522911072, -0.7102023959159851, 0.2911636531352997, 0.5672397017478943, 0.02163773961365223, 0.26367947459220886, 0.17767342925071716, -0.4461730718612671, -0.2837814688682556, -0.9417534470558167, 0.420395165681839, 0.5433647036552429, -0.5059879422187805, -0.7281600832939148, -0.26805567741394043, 0.40146130323410034, -1.2105480432510376, -0.23885086178779602, -0.5416629910469055, 0.6048822402954102, -0.269039511680603, 0.9877688884735107, -0.6572884321212769, -0.011159959249198437, 0.49002301692962646, 0.2361067831516266, -1.0835576057434082, -0.41101178526878357, -1.1708320379257202, -0.1212766095995903, -0.36936938762664795, 0.5843759775161743, -0.7028540372848511, 0.08297650516033173, 0.8851235508918762, 0.3802655339241028, -0.33897075057029724, -0.8857691884040833, 0.06299018859863281, -0.10946552455425262, -0.46520429849624634, 0.3474729061126709, -0.5417091250419617, 0.22925880551338196, 0.1853339821100235, 0.4737376272678375, 0.8741283416748047, 0.0799415186047554, -0.7802801728248596, 0.7075307965278625, 0.26101019978523254, -0.40989693999290466, -0.3991701304912567, -0.2035239040851593, -1.5384684801101685, -0.26490432024002075, -0.9070107936859131, 0.14872927963733673, -0.658764660358429, -0.6423618197441101, -0.22292928397655487, -0.5200510025024414, -0.4323306977748871, 0.6075016260147095, -0.9709091186523438, -0.0965489000082016, -0.4354798197746277, -1.0416109561920166, 1.2407166957855225, 1.1259326934814453, -0.5057656764984131, -0.04498795047402382, -0.029620159417390823, 0.43745356798171997, 0.5240566730499268, 0.5776331424713135, -0.422476589679718, -0.6912901997566223, -1.276853084564209, 0.6020344495773315, -0.21499021351337433, 0.08477026969194412, -1.3938603401184082, 0.8961537480354309, 0.19529804587364197, 0.48685702681541443, 0.2913888096809387, 0.6395359039306641, -1.2566962242126465, -0.485474169254303, 0.31967267394065857, -0.9214394092559814, 0.21218743920326233, 0.5431836247444153, 0.3738883435726166, 0.16840393841266632, 0.9613003134727478, -0.34423136711120605, -1.0027520656585693, -0.7942736148834229, 0.21204178035259247, -0.8494217991828918, -0.07280857861042023, 0.03504902869462967, -0.27049723267555237, -1.0105633735656738, -0.2467813789844513, -0.3061859607696533, 0.6937631368637085, -0.2448613941669464, 0.7596743106842041, 0.8770279884338379, -1.2788020372390747, 0.05871349573135376, 0.34238994121551514, -0.06766416877508163, 0.45834797620773315, 0.6950711607933044, 0.027710402384400368, -0.05681439861655235, 0.1368071287870407, -0.1667776107788086, 0.4891430735588074, -0.31352853775024414, 0.005596562288701534, 1.0382542610168457, -0.2699415683746338, 0.015497950837016106, 0.7780410647392273, -0.052760589867830276, -1.3905872106552124, 0.33825206756591797, -0.47829243540763855, -0.5032309293746948, -0.8164052367210388, 0.556470513343811, 0.2167889028787613, -0.8622045516967773, 0.36892545223236084, -0.1449197679758072, 0.6853759288787842, -0.2006026804447174, -0.42828822135925293, 0.41974785923957825, -0.5682293772697449, 0.2929786741733551, 0.6575757265090942, 0.24113141000270844, -0.8566842079162598, -1.48857843875885, -0.3520704209804535, -0.4850021302700043, -0.0021744724363088608, 0.027693890035152435, -0.6940208077430725, -0.09382927417755127, 0.4984543025493622, 1.0038973093032837, 0.03165511414408684, -0.04512452706694603, 0.21685871481895447, -0.3263294994831085, 0.9862866997718811, 0.49101123213768005, -0.8889746069908142, 0.48880594968795776, 0.8049102425575256, 1.6275014877319336, -1.011107087135315, 0.5425096154212952, 0.3949056565761566, -0.5935652852058411, 1.3579941987991333, 1.1024101972579956, -0.19034914672374725, 0.4550510346889496, -0.7582582831382751, -0.09621196985244751, -0.07713944464921951, -1.0855786800384521, -0.04271668940782547, 0.8794026970863342, 1.5242562294006348, 0.001758491387590766, 0.6538413763046265, 0.40599706768989563, 0.42898404598236084, 0.12855207920074463, 0.2813510596752167, 0.53522789478302, 0.39297160506248474, -0.4905339777469635, 0.24458014965057373, 0.10755342245101929, -0.04506193846464157, 0.0908016487956047, 0.312877893447876, 0.2681397497653961, 0.7539195418357849, 0.253371000289917, 0.25724726915359497, 0.5010511875152588, 0.2888883054256439, 0.5118581652641296, -0.444437175989151, 1.2228344678878784, -0.2734045386314392, -0.00046007437049411237, -0.1043047085404396, -0.4211844205856323, -0.16210851073265076, -0.48185619711875916, -0.6810687184333801, -0.4671883285045624, 0.34442412853240967, 0.1402967870235443, -0.09195747971534729, 0.20377708971500397, 0.8037056922912598, 0.6112011075019836, 0.42599812150001526, -0.2878437936306, -1.204146385192871, -0.6289278864860535, -0.8550506830215454, 0.437094122171402, -0.7216711640357971, 0.03100684843957424, -0.8297935128211975, -0.2985422909259796, -0.7759550213813782]}, "authors": [{"authorId": "2202022003", "name": "Adaptive Agent Team"}, {"authorId": "2067935448", "name": "Jakob Bauer"}, {"authorId": "1734809439", "name": "Kate Baumli"}, {"authorId": "70336016", "name": "Satinder Baveja"}, {"authorId": "145124447", "name": "Feryal M. P. Behbahani"}, {"authorId": "7567594", "name": "Avishkar Bhoopchand"}, {"authorId": "1440707913", "name": "N. Bradley-Schmieg"}, {"authorId": "47235561", "name": "Michael Chang"}, {"authorId": "2201776471", "name": "Natalie Clay"}, {"authorId": "69041729", "name": "Adrian Collister"}, {"authorId": "2871171", "name": "Vibhavari Dasagi"}, {"authorId": "2202047544", "name": "Lucy Gonzalez"}, {"authorId": "144717963", "name": "Karol Gregor"}, {"authorId": "37591038", "name": "Edward Hughes"}, {"authorId": "80976942", "name": "Sheleem Kashem"}, {"authorId": "2202022196", "name": "Maria Loks-Thompson"}, {"authorId": "2085293302", "name": "Hannah Openshaw"}, {"authorId": "1410302742", "name": "Jack Parker-Holder"}, {"authorId": "1987123565", "name": "Shreyaan Pathak"}, {"authorId": "1999879303", "name": "Nicolas Perez Nieves"}, {"authorId": "3287144", "name": "Nemanja Rakicevic"}, {"authorId": "2620211", "name": "Tim Rockt\u00e4schel"}, {"authorId": "3403061", "name": "Yannick Schroecker"}, {"authorId": "3407592", "name": "Jakub Sygnowski"}, {"authorId": "2274623", "name": "K. Tuyls"}, {"authorId": "143981350", "name": "Sarah York"}, {"authorId": "2156928090", "name": "Alexander Zacherl"}, {"authorId": "2152836492", "name": "Lei M. Zhang"}], "references": [{"paperId": "84a0c5ee814b88d8f422e928c004658a981bd373", "title": "MAESTRO: Open-Ended Environment Design for Multi-Agent Reinforcement Learning"}, {"paperId": "93fdf5cf598aefb0335f001039e83494dc721c3a", "title": "General-Purpose In-Context Learning by Meta-Learning Transformers"}, {"paperId": "860bc4f071f35d6d8529a52c2c1858d030779a6a", "title": "In-context Reinforcement Learning with Algorithm Distillation"}, {"paperId": "81885c913ad8d0b86ee52e0d85f025f9d99052e0", "title": "Avalon: A Benchmark for RL Generalization Using Procedurally Generated Worlds"}, {"paperId": "e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9", "title": "LAION-5B: An open large-scale dataset for training next generation image-text models"}, {"paperId": "975d272c3122891f8fcf69847d1ddc21ff134528", "title": "Pareto Actor-Critic for Equilibrium Selection in Multi-Agent Reinforcement Learning"}, {"paperId": "21e0c487a5327c72edc72f170ae22e48bd05e040", "title": "An Investigation of the Bias-Variance Tradeoff in Meta-Gradients"}, {"paperId": "6edccbd83a9aae204785d4821f97855677c33866", "title": "Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?"}, {"paperId": "02d9dc238ae825e45e728607c3c83b77d07f4017", "title": "Stabilizing Off-Policy Deep Reinforcement Learning from Pixels"}, {"paperId": "32c9b3859086d15184989454eb878638659e64c6", "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge"}, {"paperId": "90cd70aef56e83c8888004fc738e0f5f3f68c620", "title": "Transformers are Meta-Reinforcement Learners"}, {"paperId": "d7bca917b753b996074203cc77ba45935b7c62d7", "title": "ProcTHOR: Large-Scale Embodied AI Using Procedural Generation"}, {"paperId": "f515a23a8ad4bd184b681aa2c776f0604dc3b46b", "title": "Deep Surrogate Assisted Generation of Environments"}, {"paperId": "1be5064847c7a5e9a7e516e4c21aa8f4f8ab2eb5", "title": "Multi-Game Decision Transformers"}, {"paperId": "943cd7cf7ba21911561d03228dc2dd3f397168c9", "title": "Towards Learning Universal Hyperparameter Optimizers with Transformers"}, {"paperId": "69b80ce5ab6c2263b145b1eaa23664145938f351", "title": "The Primacy Bias in Deep Reinforcement Learning"}, {"paperId": "5922f437512158970c417f4413bface021df5f78", "title": "A Generalist Agent"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "e016b35c422e94b302f9f6d0508b47469aa0b189", "title": "Evolving Curricula with Regret-Based Environment Design"}, {"paperId": "1bb82660573bbaf01572041da16842ee2398ae39", "title": "Learning Robust Real-Time Cultural Transmission without Human Data"}, {"paperId": "ba9b7f2998002529061532486226496883e86e30", "title": "Improving Intrinsic Exploration with Language Abstractions"}, {"paperId": "6b7bf6cf5d0e1004d4468edfac4e8f81c0d0c50d", "title": "MineRL Diamond 2021 Competition: Overview, Results, and Lessons Learned"}, {"paperId": "266cc7ff4856b6a2ce9cc0a3e5f6c155ecc448a2", "title": "Can Wikipedia Help Offline Reinforcement Learning?"}, {"paperId": "545493813b7f9cc1ce9511edd4fda798a31c3aa6", "title": "Model-Value Inconsistency as a Signal for Epistemic Uncertainty"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "49a2fdc95d24e81a1913138620e47f3070d55a9a", "title": "Gradients are Not All You Need"}, {"paperId": "de7fdfe7145d9b5564d114e4304708150924e6d0", "title": "Self-Consistent Models and Values"}, {"paperId": "9a8f8ad72678fc61b8fcb416103df0a344b24bc9", "title": "Collaborating with Humans without Human Data"}, {"paperId": "fdb8ccebef9f544f44cd9b88085d8ec5458b38ab", "title": "Replay-Guided Adversarial Environment Design"}, {"paperId": "43ea4f5d999d35d4fc6c544eedbc100d8c3a5e00", "title": "MiniHack the Planet: A Sandbox for Open-Ended Reinforcement Learning Research"}, {"paperId": "8e128a1b2efb0ddf688902ade4405d22d5b61eec", "title": "Benchmarking the Spectrum of Agent Capabilities"}, {"paperId": "f8befa0bc3442979ff19e070f7c6b16d66a776c5", "title": "Bootstrapped Meta-Learning"}, {"paperId": "558ca2e8c7eb56edd77a52b084e6cc24dffe5bcd", "title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice"}, {"paperId": "cfabb20df17109036a82934cc12b5c8e92223f6c", "title": "When should agents explore?"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "1ca5ff6555d9fc634d3858d1fda9b3de2a91b13a", "title": "RMA: Rapid Motor Adaptation for Legged Robots"}, {"paperId": "9fa7fa9006884c9386cbb306e6c2d6e6ad4282b0", "title": "On the Importance of Environments in Human-Robot Coordination"}, {"paperId": "2a805d0e1b067444a554c5169d189fa1f649f411", "title": "Scaling Vision Transformers"}, {"paperId": "f864d4d2267abba15eb43db54f58286aef78292b", "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem"}, {"paperId": "c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500", "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling"}, {"paperId": "98cb29c03a0882fde368db28ade214c57c3239d6", "title": "Multi-agent deep reinforcement learning: a survey"}, {"paperId": "d4042b369e92c827a26dc62fdb047e00af332467", "title": "Muesli: Combining Improvements in Policy Optimization"}, {"paperId": "489666f4c11787b679b36238dee95b63248ed60a", "title": "Training Larger Networks for Deep Reinforcement Learning"}, {"paperId": "665f363ce1b5670fe4298cc255a2958286705bc3", "title": "A practical guide for studying human behavior in the lab"}, {"paperId": "12ce3a14da5a7e22bcb3b14452dd9d3bb8f5cf36", "title": "Asymmetric self-play for automatic goal discovery in robotic manipulation"}, {"paperId": "2a1573cfa29a426c695e2caf6de0167a12b788ef", "title": "Open Problems in Cooperative AI"}, {"paperId": "d620b63abe26a81d517d0802ab65e66d49faec9b", "title": "EvoCraft: A New Challenge for Open-Endedness"}, {"paperId": "93b2788fb1f2aed0e545d9f9d7dca1c05a63208a", "title": "Emergent Complexity and Zero-shot Transfer via Unsupervised Environment Design"}, {"paperId": "05bf1ca3a8a1366970bef3cd9275859e7430ef56", "title": "Meta-trained agents implement Bayes-optimal agents"}, {"paperId": "6999fd72868c4044e852c43a040a87a43d03ab3a", "title": "Prioritized Level Replay"}, {"paperId": "e423c07b36936ddce137bce009b318f2c2741be5", "title": "Adaptive Procedural Task Generation for Hard-Exploration Problems"}, {"paperId": "df8a0bed6d685fee9c5ad418f4834e9537878de2", "title": "Learning with AMIGo: Adversarially Motivated Intrinsic Goals"}, {"paperId": "5dc6ed2b4d588f1e5f3296c465af35d7f6e2ddb3", "title": "Learning to Incentivize Other Learning Agents"}, {"paperId": "822bdb6e8c39e272ebfee127666e032bd3aa0107", "title": "The NetHack Learning Environment"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "04bd5cf9096f9a28a3505a171959a0bde4feb85e", "title": "RTFM: Generalising to New Environment Dynamics via Reading"}, {"paperId": "917d30b3e3a5358c2553fe76aabe5a3796689dc1", "title": "Enhanced POET: Open-Ended Reinforcement Learning through Unbounded Invention of Learning Challenges and their Solutions"}, {"paperId": "5e8350467d7d19e1d5f991be23f7b4826a9303a8", "title": "ROMA: Multi-Agent Reinforcement Learning with Emergent Roles"}, {"paperId": "1b6ed62002979ae366854deb475b3413667e3f2b", "title": "\"Other-Play\" for Zero-Shot Coordination"}, {"paperId": "bebe8ffb0c357ac0c7eea2556f817b03ee22b570", "title": "RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "b19729b27a1b4c24b52f87308c907653300afa7f", "title": "Dota 2 with Large Scale Deep Reinforcement Learning"}, {"paperId": "a6302f8051071b709f55570bd1dd4c4e9f9ae4b4", "title": "What Can Learned Intrinsic Rewards Capture?"}, {"paperId": "8d814620a1ca77e745bc8a33b96b86148f2804fe", "title": "Leveraging Procedural Generation to Benchmark Reinforcement Learning"}, {"paperId": "71207632839723b51368fa5221c66dc75325bf58", "title": "Increasing generality in machine learning through procedural content generation"}, {"paperId": "361c00b22e29d0816ca896513d2c165e26399821", "title": "Grandmaster level in StarCraft II using multi-agent reinforcement learning"}, {"paperId": "361e953f792a585496834ee14216b94d0ce9ae74", "title": "VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning"}, {"paperId": "20b9c2ea1a49ed7789b99ae4c84b1b517b65bff5", "title": "Teacher algorithms for curriculum learning of Deep RL in continuously parameterized environments"}, {"paperId": "320b227027030fc291de2896fc3c6da49d7614be", "title": "Solving Rubik's Cube with a Robot Hand"}, {"paperId": "59a916cdc943f0282908e6f3fa0360f4c5fb78d0", "title": "Stabilizing Transformers for Reinforcement Learning"}, {"paperId": "eb41a0cffa84d3d6035e6f5f420806ddc962b1e6", "title": "On the Utility of Learning about Humans for Human-AI Coordination"}, {"paperId": "05d57ef604913b8a1b12537fafd53799d65b10db", "title": "Learning Fast Adaptation With Meta Strategy Optimization"}, {"paperId": "27e124cc9d630e3a88ef5ca862efa2b982b8d9ef", "title": "Single Episode Policy Transfer in Reinforcement Learning"}, {"paperId": "33a2c0f3b9a0adc452a13d53f950c0c3c4abb11b", "title": "Emergent Tool Use From Multi-Agent Autocurricula"}, {"paperId": "42525a5143c6a87d3ab466684dfa471dc43a5bd0", "title": "AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence"}, {"paperId": "9a3c9a0ac460c7891d03d56146f2d566c7e0fb08", "title": "Meta reinforcement learning as task inference"}, {"paperId": "aa55677fa86bb05e3cb8bf403a0317f4bb1d36c1", "title": "Meta-learning of Sequential Strategies"}, {"paperId": "4625628163a2ee0e6cd320cd7a14b4ccded2a631", "title": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables"}, {"paperId": "8a5c62f9c49a943b66fb1ae379442497609c8596", "title": "Emergent Coordination Through Competition"}, {"paperId": "ff84c46d4653782218549bd99631130df2d2859e", "title": "Distilling Policy Distillation"}, {"paperId": "16da857c08186f2a923da1cfaf88a8a16507d3f9", "title": "Obstacle Tower: A Generalization Challenge in Vision, Control, and Planning"}, {"paperId": "b8c0071c74e04ea1598ed2a208cbc255656f50b0", "title": "A Meta-MDP Approach to Exploration for Lifelong Reinforcement Learning"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "c48ca266c1e16f9adc5fb7770afd95a0feec8753", "title": "Paired Open-Ended Trailblazer (POET): Endlessly Generating Increasingly Complex and Diverse Learning Environments and Their Solutions"}, {"paperId": "ef2bc452812d6005ab0a66af6c3f97b6b0ba837e", "title": "Quantifying Generalization in Reinforcement Learning"}, {"paperId": "ea64dbd29ab90d8944bcc6a05680aeaacc86fc0a", "title": "Human-level performance in 3D multiplayer games with population-based reinforcement learning"}, {"paperId": "ff3f23189c3a7fed677a868ddfc22a02bb6e4ef8", "title": "Procedural Level Generation Improves Generality of Deep Reinforcement Learning"}, {"paperId": "38e2f851b705faa0d0a698ed9885bd6834440073", "title": "Probabilistic Model-Agnostic Meta-Learning"}, {"paperId": "f17ad18fae97e40b2cd09fadf1baa8bb56dd0d5f", "title": "Re-evaluating evaluation"}, {"paperId": "2a49a71c9d40051a03c4445fe49025bc75d9eeb6", "title": "Meta-Gradient Reinforcement Learning"}, {"paperId": "0f885fd46064d271d4404cf9bb3d758e1a6f8d55", "title": "Exploring the Limits of Weakly Supervised Pretraining"}, {"paperId": "30de3c20bbe9562e1fbce162d84de593a073bc15", "title": "Prefrontal cortex as a meta-reinforcement learning system"}, {"paperId": "944bd3b472c8a30163bbfc1b5cbab8545693c3e0", "title": "Learning to Adapt in Dynamic, Real-World Environments through Meta-Reinforcement Learning"}, {"paperId": "ebf3b0c284cb776d89951e4e67a59df6403fc9a6", "title": "Kickstarting Deep Reinforcement Learning"}, {"paperId": "b80991d12b41a5a68dc14dd87b692c0f903ceb9c", "title": "Some Considerations on Learning to Explore via Meta-Reinforcement Learning"}, {"paperId": "af10f3c1c0859aa620623f760c8a29e78f177f7f", "title": "Population Based Training of Neural Networks"}, {"paperId": "8760bc7631c0cb04e7138254e9fd6451b7def8ca", "title": "Revisiting Unreasonable Effectiveness of Data in Deep Learning Era"}, {"paperId": "fb9b0a6e88ca6e3cef9fc6ba060b27c5303da258", "title": "Teacher\u2013Student Curriculum Learning"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "8499a250422a3c66357367c8d5fa504de5424c59", "title": "Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play"}, {"paperId": "c889d6f98e6d79b89c3a6adf8a921f88fa6ba518", "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"}, {"paperId": "282a380fb5ac26d99667224cef8c630f6882704f", "title": "Learning to reinforcement learn"}, {"paperId": "954b01151ff13aef416d27adc60cd9a076753b1a", "title": "RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning"}, {"paperId": "bd6b6291c3c14551cf9f2aa0e04e2e33c86b800e", "title": "The Malmo Platform for Artificial Intelligence Experimentation"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "71683e224ab91617950956b5005ed0439a733a71", "title": "Learning to learn by gradient descent by gradient descent"}, {"paperId": "dc3e905bfb27d21675ee1720413e007b014b37d3", "title": "Safe and Efficient Off-Policy Reinforcement Learning"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "c6170fa90d3b2efede5a2e1660cb23e1c824f2ca", "title": "Prioritized Experience Replay"}, {"paperId": "8b20f103c1f20074fa35bd8fc41983964283acac", "title": "Fictitious Self-Play in Extensive-Form Games"}, {"paperId": "1eb09fecd75eb27825dce4f964b97f4f5cc399d7", "title": "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"}, {"paperId": "1a632fb89b6b05dc16fbc026d86e390e22ca6ac3", "title": "Robots that can adapt like animals"}, {"paperId": "e4996547720f4801eca284a3c3dfa7943cd08ecf", "title": "Ad Hoc Autonomous Agent Teams: Collaboration without Pre-Coordination"}, {"paperId": "4ad5b0b1a0ba1cf354e3eec41a7038f05ac0462e", "title": "An experiment in automatic game design"}, {"paperId": "909ed155a63f3c2ecb6ed0a23c4ae678c8d29018", "title": "Readings on the Development of Children"}, {"paperId": "50c770b425a5bb25c77387f687a9910a9d130722", "title": "Learning Complex, Extended Sequences Using the Principle of History Compression"}, {"paperId": "94db34f4b68189bfcba22beab33ee3b54f10b876", "title": "Curious model-building control systems"}, {"paperId": "e75fb417b54a6eae589ff382874de09d7f58a3de", "title": "Open-Ended Learning Leads to Generally Capable Agents"}, {"paperId": "77c9b9288a29d56676ba9cecf462c950971537d9", "title": "Alchemy: A structured task distribution for meta-reinforcement learning"}, {"paperId": "42edbc3c29af476c27f102b3de9f04e56b5c642d", "title": "A Survey of Generalisation in Deep Reinforcement Learning"}, {"paperId": null, "title": "We modify the configuration space as follows: \u2022 We introduce a new relation touching(a,b)"}, {"paperId": null, "title": "2021a,b), PLR contains the following hyper-parameters: replay probability p, maximum replay size Nmax, minimum replay size Nmin (we set p = 0 if |P"}, {"paperId": null, "title": "2020), use gating in the feedforward component as in Shazeer"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "We construct a competitive meta-game of \u201cagents vs"}, {"paperId": null, "title": "JAX: composable transformations of Python+NumPy programs, 2018"}, {"paperId": null, "title": "Minimalistic gridworld environment for OpenAI Gym"}, {"paperId": "696ccd4161cab0b92608bb00a9f8caadb6b9d67f", "title": "Natural Value Approximators: Learning when to Trust Past Estimates"}, {"paperId": null, "title": "2016) with [16, 32, 32] convolutional channels, each consisting of 2 \u00d7 2 blocks and a final"}, {"paperId": "0c652c8bd65348316d80e128dc658161cd751b45", "title": "Interaction between learning and development"}, {"paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5", "title": "of the Association for Computational Linguistics"}, {"paperId": null, "title": "We multiply the values in Table E.1 by the number of learner/actor steps for each experiment, then, for a given comparison"}]}