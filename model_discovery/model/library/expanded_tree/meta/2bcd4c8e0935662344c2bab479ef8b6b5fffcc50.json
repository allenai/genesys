{"paperId": "2bcd4c8e0935662344c2bab479ef8b6b5fffcc50", "abstract": "Parameter Efficient Fine-Tuning (PEFT) techniques have drawn significant attention due to their ability to yield competitive results while updating only a small portion of the adjustable parameters. However, existing PEFT methods pose challenges in hyperparameter selection, such as choosing the rank for LoRA or Adapter, or specifying the length of soft prompts. To address these challenges, we propose a novel fine-tuning approach for neural models, named Representation EDiting (RED), which modifies the representations generated at some layers through the application of scaling and biasing operations. While existing PEFT methods still demonstrate over-parameterization that could potentially undermine the generalization ability acquired from pre-training, RED can substantially reduce the number of trainable parameters by a factor of 25, 700 compared to full parameter fine-tuning and by a factor of 32 relative to LoRA. Remarkably, RED achieves results comparable or superior to both full parameter fine-tuning and other PEFT methods. Extensive experiments across various model architectures and scales, including RoBERTa, GPT-2, T5, and LLaMA-2, have demonstrated the effectiveness and efficiency of RED1, thereby positioning it as a promising PEFT strategy for large-scale neural models.", "venue": "arXiv.org", "year": 2024, "citationCount": 9, "influentialCitationCount": 3, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A novel fine-tuning approach for neural models, named Representation EDiting (RED), which modifies the representations generated at some layers through the application of scaling and biasing operations, and achieves results comparable or superior to both full parameter fine-tuning and other PEFT methods."}, "embedding": {"model": "specter_v2", "vector": [0.09800230711698532, 0.4985193908214569, -0.503875195980072, 0.03932695463299751, -0.10147741436958313, -0.3729773163795471, 0.7450488209724426, -0.37644198536872864, -0.7992057204246521, -0.1825951337814331, 0.14544852077960968, 0.3457721769809723, -0.06668107211589813, 0.17116709053516388, -0.12112010270357132, -0.1553482562303543, -0.8984566330909729, 0.8091878890991211, 0.23420438170433044, -0.46418336033821106, -0.184210404753685, -0.3088471293449402, -0.9380893111228943, -0.047313086688518524, 0.14361755549907684, 1.1049129962921143, 0.06263264268636703, 0.7004585862159729, -0.2664938271045685, -0.5280076861381531, 0.3000723421573639, -0.3004176616668701, 0.3847620189189911, 0.30482789874076843, -0.06620940566062927, 0.1198073998093605, 0.03264113515615463, -0.37791797518730164, -0.4443831443786621, 0.8435261249542236, 0.004005995579063892, 0.40254849195480347, 0.4916593134403229, -0.4647684693336487, -0.12170325964689255, 0.4898531138896942, 0.5156394243240356, 0.7940635085105896, -0.673114538192749, -0.4378011226654053, 0.7675200700759888, -0.9432804584503174, -0.1372705101966858, 1.4462566375732422, 0.5573152303695679, 0.3661418557167053, -0.5225782990455627, -0.8389537334442139, 0.7220762372016907, -0.08137419819831848, -0.9547605514526367, 0.024669017642736435, 0.20496496558189392, -0.15993794798851013, 1.8265984058380127, -0.7219396829605103, -0.17441219091415405, 0.6502054929733276, -0.17166998982429504, 0.8732582926750183, -0.031055184081196785, -0.36199358105659485, -0.044520337134599686, 0.4778482913970947, 0.15072987973690033, 0.7230398058891296, -0.28808537125587463, 0.5826805233955383, -0.7380468845367432, -0.4690524935722351, 0.956932544708252, -0.5317645072937012, 0.3077729046344757, -0.14441023766994476, -0.16547837853431702, 0.8173360824584961, 0.3665686249732971, 0.1433447301387787, -0.5424206852912903, 1.1640605926513672, 0.40725019574165344, 0.4926062226295471, 0.1852377951145172, 0.9943304061889648, -0.2436307817697525, 0.14910542964935303, -0.3857688307762146, 0.003456519450992346, -0.1644594669342041, 0.9097296595573425, 0.006241306662559509, 0.28885096311569214, -0.6776180267333984, 0.7842398881912231, 1.2143715620040894, -0.36669838428497314, 0.5844779014587402, -0.865540087223053, 0.33879807591438293, -0.44131872057914734, 0.2861751616001129, -0.5525690317153931, -0.4675024151802063, -0.539015531539917, -0.7893069386482239, -1.1933058500289917, -0.5365482568740845, 0.017673790454864502, -0.8115095496177673, 0.9926400184631348, -0.26698699593544006, -0.06423571705818176, -0.28104129433631897, 0.4660516083240509, 0.35418057441711426, 0.6453877687454224, 0.30396604537963867, 0.15476539731025696, 1.1354564428329468, -0.8484129309654236, -0.47262588143348694, -0.9107146263122559, 0.17799867689609528, -0.0735311284661293, 0.1488785594701767, 0.11649487912654877, -1.3929314613342285, -0.6400195360183716, -1.0021885633468628, 0.22535523772239685, -0.43031272292137146, 0.506574809551239, 1.3424659967422485, 0.2328028827905655, -0.5672083497047424, 0.7702582478523254, -0.138946995139122, -0.2779504060745239, 0.3469125032424927, 0.6299448013305664, 0.18806414306163788, 0.07189475744962692, -1.3263665437698364, 0.13320036232471466, 1.0214686393737793, -0.45944154262542725, -0.39166969060897827, -0.5424906611442566, -0.34769126772880554, 0.16506746411323547, 0.2625962495803833, -1.1620869636535645, 1.1622880697250366, -0.08665241301059723, -1.593213438987732, 0.4391247630119324, 0.33402690291404724, 0.09074710309505463, 0.4961475431919098, 0.22679100930690765, -0.49748289585113525, -0.24218690395355225, -1.1308614015579224, 1.0042991638183594, 0.95765221118927, -0.10941132158041, -0.07850352674722672, 0.4392598569393158, 0.09398344904184341, 0.10024649649858475, -0.5824399590492249, 0.8443849086761475, -0.8852171301841736, -0.5214296579360962, 0.564310610294342, 0.5629292726516724, 0.11413367092609406, -0.13323599100112915, -0.13680210709571838, -1.0052462816238403, 0.3659466803073883, 0.5850503444671631, 1.0470433235168457, -0.7932771444320679, -0.5692802667617798, 0.17299622297286987, 0.09650073200464249, 0.051915187388658524, -1.0818486213684082, 0.30468446016311646, -0.5047987103462219, 0.3024976849555969, -0.07769007980823517, -1.0553618669509888, 0.24071983993053436, -0.12799373269081116, -0.29279330372810364, -0.14949670433998108, 0.6625644564628601, 0.8193925619125366, -0.6789122223854065, 0.4484415650367737, -0.18330717086791992, 0.6070533990859985, -1.4130831956863403, 1.064695954322815, -0.663665771484375, 0.14974601566791534, -0.11036844551563263, -0.2899329662322998, 0.08301585912704468, -0.7880922555923462, 0.22208882868289948, -0.5705174803733826, 0.3539361357688904, 0.5478501915931702, -1.0630015134811401, 1.1999489068984985, -0.4479767978191376, 0.27943843603134155, 0.05257667228579521, -0.10007879883050919, 0.4323648512363434, 0.1499110609292984, -0.20099025964736938, -0.46174290776252747, 0.6263564825057983, 0.41488882899284363, -0.7957616448402405, 0.4881860017776489, 0.7719383835792542, 0.9550022482872009, -0.14072628319263458, 0.00725875049829483, 0.7784007787704468, -0.37047240138053894, 0.8664851188659668, -0.005424682516604662, 0.32033857703208923, 0.26576322317123413, 0.4163159430027008, 0.001152819604612887, -0.00036925336462445557, -1.0472911596298218, -0.16225530207157135, 0.3815198838710785, 0.9420343637466431, 0.8768824934959412, 0.5633891224861145, -0.7326016426086426, -0.5107644200325012, -0.3129063546657562, 0.18053700029850006, 1.812507152557373, -0.4042307138442993, -0.11522608250379562, -0.6194406747817993, 0.13201050460338593, -0.12085463851690292, -0.3141403794288635, -0.6798955202102661, -0.35620224475860596, -0.6015517711639404, -1.7118535041809082, 0.8457989692687988, 0.13014642894268036, 0.9392285346984863, -0.2917809784412384, -0.3955269753932953, 0.023901941254734993, 0.5820261240005493, -0.3742499053478241, -0.6899656653404236, 0.9123061895370483, -0.7384640574455261, -0.032256919890642166, -0.10354965180158615, 0.0011328147957101464, 0.2091565728187561, -0.8706362247467041, 0.8245385885238647, -0.7355046272277832, 0.04090278595685959, -0.3029264807701111, 0.7931660413742065, -0.6647671461105347, -0.6072909832000732, 0.6745995283126831, 0.21025210618972778, -0.09190645813941956, -0.07157990336418152, 0.23541538417339325, 0.17483314871788025, 0.588387131690979, -0.7839957475662231, 0.013022644445300102, 0.1788170039653778, 0.40219631791114807, 1.0512462854385376, -0.358568400144577, 0.43185776472091675, -1.56415593624115, 1.3366553783416748, -0.045458704233169556, -0.9188448786735535, 0.11846667528152466, -0.872336208820343, 0.1735684722661972, 0.4754728078842163, -1.0827888250350952, -0.3685201108455658, -0.9789518117904663, 0.3908647298812866, -0.4421820342540741, -0.029420290142297745, 0.005615202244371176, 0.6258430480957031, -0.23801392316818237, 0.7838737368583679, -0.1597762107849121, -0.03463219851255417, -0.40961453318595886, 0.44642844796180725, -1.072422742843628, 0.7664581537246704, -0.06095505133271217, 0.2301333099603653, -0.36570462584495544, -0.1561797708272934, -0.24111424386501312, -0.3584093749523163, -0.3816908299922943, 0.024855252355337143, 0.15535809099674225, -0.24185828864574432, -0.5992146134376526, -0.8209066390991211, 0.11300516873598099, -0.7177766561508179, -0.1977815479040146, -0.0009580388432368636, -0.020420938730239868, -0.3295814096927643, -1.2574596405029297, -1.072244644165039, -0.0888322964310646, -0.32645025849342346, -1.219146728515625, -0.014342519454658031, 0.2892443537712097, -0.25457510352134705, -0.704387903213501, 0.03770686686038971, -0.6572128534317017, 1.2811331748962402, -0.6088579893112183, 1.0499401092529297, 0.16654813289642334, 0.10004367679357529, -0.16213984787464142, -0.12167626619338989, 0.44548454880714417, -0.6738168597221375, 0.20016546547412872, -1.3273814916610718, 0.12490352988243103, -0.6137888431549072, -0.4206559658050537, 0.35580676794052124, 0.31998494267463684, 0.9498082995414734, -0.16145072877407074, -0.2011253535747528, 1.4659416675567627, 1.1513115167617798, -0.8157578110694885, -0.05143749713897705, 0.7613418102264404, 0.69545578956604, 0.2279750257730484, -0.40488728880882263, 1.1175103187561035, -0.08290619403123856, 0.42025065422058105, 0.3732728660106659, 0.07177595049142838, -0.2876405119895935, -0.725715160369873, -0.05010920390486717, 1.2443045377731323, 0.43700286746025085, -0.19406233727931976, -0.45211103558540344, 0.29669004678726196, -1.0729522705078125, -0.09986664354801178, 0.9865453243255615, 0.944093644618988, 0.5438703298568726, -0.3242258131504059, -0.2638360559940338, -0.5153070688247681, 0.4808138906955719, 0.40390098094940186, -0.8288840651512146, -0.7844080924987793, -0.20090317726135254, -0.16811347007751465, 0.5443568825721741, 0.4234117567539215, -0.2839667797088623, 0.5887461304664612, 14.627433776855469, 0.8907603621482849, 0.027155747637152672, 0.3376626670360565, 0.5183916091918945, -8.114738739095628e-05, -0.48290202021598816, -0.4422701597213745, -1.1940001249313354, -0.02006969042122364, 1.1216704845428467, 0.3249385952949524, 1.2772502899169922, 0.03761155903339386, -0.06814704835414886, 0.19275274872779846, -0.4968760907649994, 1.220758318901062, 0.27828070521354675, -1.3407628536224365, 0.46494048833847046, 0.027072710916399956, 0.8576272130012512, 0.5759937167167664, 1.0889049768447876, 0.7164770364761353, 0.48132312297821045, -0.4120359420776367, 0.38520658016204834, 0.45664578676223755, 0.993981659412384, -0.4507589340209961, 0.2731701731681824, 0.1285521686077118, -0.6396075487136841, -0.42492029070854187, -0.8937715888023376, -0.7460697889328003, 0.005731105804443359, -0.005626230966299772, -0.690513014793396, -0.689766526222229, 0.055108699947595596, 0.41357383131980896, -0.4310314953327179, 0.9352038502693176, -0.2197590321302414, 0.40053117275238037, -0.7092540264129639, 0.37244781851768494, 0.36296582221984863, 0.09097899496555328, 0.24868063628673553, -0.0905274748802185, 0.05028454214334488, -0.05508836731314659, -0.24982105195522308, 0.6385451555252075, -0.9010905623435974, -0.4706801772117615, 0.18898431956768036, -0.20329061150550842, 0.5567430257797241, 0.9352865815162659, 0.795011579990387, 0.5931645035743713, 0.2506653368473053, -0.014111435040831566, 0.7727571725845337, 0.4495255649089813, -0.4545319676399231, -0.05268404260277748, 0.3399198651313782, -0.5168975591659546, -0.42034271359443665, 0.820336103439331, -0.3191913962364197, -0.0190884992480278, -0.7760202884674072, -0.5063817501068115, 0.5245650410652161, -0.8348463773727417, -0.7304883003234863, 0.8818581700325012, 0.13330844044685364, -0.30367904901504517, 0.19526612758636475, -0.8065691590309143, -0.1528255194425583, 0.5099183320999146, -1.426323413848877, -0.33464038372039795, 0.245932936668396, -0.40540656447410583, -0.743703305721283, -0.5014748573303223, 1.2296963930130005, 0.1444065272808075, -0.7237017154693604, 0.532324492931366, 0.3422873914241791, -0.6914389133453369, 0.3637501299381256, -0.5219918489456177, 0.7677165269851685, -0.22659242153167725, -0.5815348625183105, 0.5684655904769897, -0.028570719063282013, 0.6888380646705627, -0.5440611243247986, -0.03418391942977905, -0.05825834721326828, -0.45761069655418396, -0.06139201670885086, -0.3472108542919159, -0.9405397176742554, 0.3087676763534546, 0.13115036487579346, -0.12657205760478973, 0.13842801749706268, 0.13816064596176147, -1.009597897529602, -0.1700725108385086, -0.9004094004631042, -0.13510744273662567, 0.2843882143497467, -0.4866071939468384, -0.142935112118721, -0.046181656420230865, 0.16122466325759888, -1.1772876977920532, -0.9512441754341125, -0.2769787907600403, -0.09658797830343246, 0.3166486322879791, 1.2163915634155273, -0.35938623547554016, -0.05078417807817459, 0.5356626510620117, 0.008034523576498032, -1.2464362382888794, -0.3824350833892822, -1.2003265619277954, 0.012505670078098774, -0.006624582223594189, 0.7910242676734924, -0.7532731294631958, 0.25566715002059937, 0.49639013409614563, 0.12806259095668793, -0.3203723132610321, -0.42989954352378845, 0.02601119875907898, 0.04341282695531845, -0.38051149249076843, 0.6274491548538208, -0.22999466955661774, -0.594007670879364, 0.2314501404762268, 0.46917563676834106, 0.6029205918312073, -0.43054184317588806, -1.0926562547683716, 0.207315593957901, -0.26816901564598083, -0.4938976764678955, -0.9294620752334595, -0.0800381451845169, -1.480399250984192, -0.396575003862381, -1.0416632890701294, -0.3349856436252594, -0.5838420987129211, -0.3008408844470978, -0.08713696151971817, -0.3298029899597168, -0.14338646829128265, 0.4931891858577728, -0.2974485754966736, -0.5279849767684937, -0.20547540485858917, -0.5484767556190491, 0.9680830240249634, 0.9372625350952148, -0.6707748174667358, -0.15698036551475525, -0.21082767844200134, 0.16106955707073212, 0.5662551522254944, 0.7576601505279541, -0.5593940615653992, -0.6173486709594727, -1.5936567783355713, 0.8240602016448975, -0.5275472402572632, -0.22132694721221924, -0.6226759552955627, 0.9459010362625122, 0.18780717253684998, 0.17158104479312897, 0.2557826340198517, 0.625010073184967, -0.9870707392692566, -0.3553694784641266, 0.008476526476442814, -0.7089164853096008, 0.5467697978019714, 0.6324083209037781, -0.28684166073799133, -0.062310781329870224, 0.4666455388069153, 0.3927250802516937, -0.612883985042572, -0.8658387660980225, 0.3897964656352997, -0.48396340012550354, 0.315957248210907, -0.47352802753448486, -0.20652267336845398, -1.6298670768737793, 5.059595423517749e-05, 0.14247435331344604, 0.6592715978622437, -0.3314365744590759, 0.7085185050964355, 0.19355110824108124, -1.124274730682373, 0.14576204121112823, 0.7181740403175354, 0.28947433829307556, 0.10431935638189316, 0.534911572933197, 0.5051179528236389, -0.37271955609321594, 0.46204322576522827, -0.20491009950637817, 0.5577892661094666, -0.1624833196401596, -0.32355964183807373, 0.9787910580635071, -0.6001049876213074, 0.08279366046190262, 1.445711612701416, -0.047436464577913284, -1.332428216934204, 0.6463240385055542, -0.9463809132575989, -0.6518644094467163, 0.053474340587854385, 0.45998063683509827, 0.44387286901474, 0.01345918420702219, 0.2720898687839508, -0.33028507232666016, 0.15425324440002441, -0.3155946135520935, -0.25464266538619995, 0.4569784700870514, -0.34487226605415344, -0.1428338885307312, 0.533457338809967, 0.8472200632095337, -1.2428903579711914, -1.5251041650772095, -0.9056327939033508, -0.3979496657848358, 0.10376185923814774, 0.6491175293922424, -0.7912179231643677, -0.8296694159507751, 0.6063499450683594, 0.6392552852630615, -0.22197677195072174, 0.17440271377563477, -0.21892619132995605, -0.3159060776233673, 1.1643003225326538, -0.013040721416473389, -1.1629867553710938, -0.23531731963157654, 1.170601725578308, 1.290987253189087, -0.7645999193191528, 0.32402506470680237, 0.06706049293279648, -0.5688868761062622, 0.8194697499275208, 0.30935239791870117, -0.14544227719306946, 0.5357475280761719, -0.38599640130996704, -0.2304256558418274, 0.029150603339076042, -1.3502521514892578, -0.04227602854371071, 0.9901504516601562, 0.989300012588501, 0.3270326554775238, 0.25589168071746826, 0.505141019821167, 0.9056976437568665, -0.1180301234126091, -0.30756300687789917, 0.4082946479320526, 0.06918288767337799, -0.1908733993768692, 0.0649879053235054, -0.130849227309227, 0.7901483178138733, -0.5668504238128662, -0.2171870917081833, -0.01980392262339592, 0.7440978288650513, 0.10692057758569717, 0.38471317291259766, 0.8172998428344727, 0.011521263979375362, 0.6944132447242737, -0.17237524688243866, 0.5178641080856323, -0.45789483189582825, -0.60391765832901, 0.29119712114334106, -0.41181084513664246, -0.28521373867988586, 0.2279006838798523, -0.21822087466716766, -0.2007887363433838, -0.23914721608161926, 0.2744397222995758, -0.017094876617193222, 0.6131656765937805, 0.5012774467468262, 0.5215179324150085, 0.9366962909698486, -0.11242878437042236, -0.8411178588867188, -0.9545533657073975, -1.0922660827636719, -0.056880611926317215, -0.7149282693862915, -0.5171106457710266, -0.6977366805076599, -0.20169642567634583, -0.6233595013618469]}, "authors": [{"authorId": "2257130069", "name": "Muling Wu"}, {"authorId": "2257377140", "name": "Wenhao Liu"}, {"authorId": "2273537815", "name": "Xiaohua Wang"}, {"authorId": "2235543174", "name": "Tianlong Li"}, {"authorId": "2220896023", "name": "Changze Lv"}, {"authorId": "2223116564", "name": "Zixuan Ling"}, {"authorId": "2276580337", "name": "Jianhao Zhu"}, {"authorId": "2257100381", "name": "Cenyuan Zhang"}, {"authorId": "2257315404", "name": "Xiaoqing Zheng"}, {"authorId": "2257129987", "name": "Xuanjing Huang"}], "references": [{"paperId": "aee47d4f45d5c02f79fff62ce4147f0d382cd87e", "title": "Aligning Large Language Models with Human Preferences through Representation Engineering"}, {"paperId": "0d7f24578340aae6df610ed95aaa276b9c3ddcd3", "title": "VeRA: Vector-based Random Matrix Adaptation"}, {"paperId": "aac3469581061cd5b46440c3eeca91c385d54ccf", "title": "Representation Engineering: A Top-Down Approach to AI Transparency"}, {"paperId": "965d15261b682fd3fd766311b99a11257322ac4c", "title": "Activation Addition: Steering Language Models Without Optimization"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "32ac52069e562d4f900afee70bdca63f53461481", "title": "QLoRA: Efficient Finetuning of Quantized LLMs"}, {"paperId": "8b32aa33601514976d88fabcb060a5cd38d34006", "title": "Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning"}, {"paperId": "f0b31fdf53ad60df454afd4ec8633b3aeb347bff", "title": "Scaling & Shifting Your Features: A New Baseline for Efficient Model Tuning"}, {"paperId": "55a250868627de2d202d06e7cb3f6cbcd3a66f88", "title": "ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts"}, {"paperId": "7cdaa08890895e1ad92afb5fad429690ad7b1dac", "title": "Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "ad471be93216ddbf8544721d50ee5aed14f07cae", "title": "UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning"}, {"paperId": "43a87867fe6bf4eb920f97fc753be4b727308923", "title": "Towards a Unified View of Parameter-Efficient Transfer Learning"}, {"paperId": "77d956cdab4508d569ae5741549b78e715fd0749", "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"}, {"paperId": "cddf40e579a596d0110b260313adf43470617c4c", "title": "Datasets: A Community Library for Natural Language Processing"}, {"paperId": "339b2b711fb5b228d097b03ebc3e62a521779235", "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "656ed155c2d345c19d9bff4b50f2ae00db8407cc", "title": "Compacter: Efficient Low-Rank Hypercomplex Adapter Layers"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "57d1e7ac339e783898f2c3b1af55737cbeee9fc5", "title": "Measuring Mathematical Problem Solving With the MATH Dataset"}, {"paperId": "e54ffc76d805c48660bb0fd20019ca82ac94ba0d", "title": "Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning"}, {"paperId": "d22e4cc3a501c17881b9478621f29760e429e76e", "title": "Parameter-Efficient Transfer Learning with Diff Pruning"}, {"paperId": "b68b2e81ae2de647394ec05ee62ecf108bf2b50a", "title": "Eliciting Knowledge from Language Models Using Automatically Generated Prompts"}, {"paperId": "bdeec55f95fd6b73e3e4635459b14c7248543efb", "title": "AdapterDrop: On the Efficiency of Adapters in Transformers"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "98ef0db84e62aef969629264c9de1f4d0013f3b9", "title": "AdapterFusion: Non-Destructive Task Composition for Transfer Learning"}, {"paperId": "7fb301ea25f02dc7f4f7ee1360137503ee942c8c", "title": "Masking as an Efficient Alternative to Finetuning for Pretrained Language Models"}, {"paperId": "1187c70c4011f935642084e84186284ac0add3d0", "title": "Exploring Versatile Generative Language Model Via Parameter-Efficient Transfer Learning"}, {"paperId": "4a4646a5ce6b57e369403e4efea1a2e4559fe9f1", "title": "What Would Elsa Do? Freezing Layers During Transformer Fine-Tuning"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "8f1c9b656157b1d851563fb42129245701d83175", "title": "Transforming Question Answering Datasets Into Natural Language Inference Datasets"}, {"paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca", "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"}, {"paperId": "cb0f3ee1e98faf92429d601cdcd76c69c1e484eb", "title": "Neural Network Acceptability Judgments"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096", "title": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"}, {"paperId": "531a7f2c659787165df4fd5b4580590b953448e4", "title": "The E2E Dataset: New Challenges For End-to-End Generation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "258986132bf17755fe8263e42429fe73218c1534", "title": "CIDEr: Consensus-based image description evaluation"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "5ef82a8c8aa50f99285f2143b57ca4e82da1af80", "title": "Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning"}, {"paperId": "4c8cc2383cec93bd9ea0758692f01b98a035215b", "title": "UltraFeedback: Boosting Language Models with High-quality Feedback"}, {"paperId": "20ada3235c996c7af345649935240d0b257d5a46", "title": "Parameter Efficient Multi-task Fine-tuning by Learning to Transfer Token-wise Prompts"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": null, "title": "Bert and pals: Projected attention layers for efficient adaptation in multi-task learning"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "136326377c122560768db674e35f5bcd6de3bc40", "title": "The Second PASCAL Recognising Textual Entailment Challenge"}, {"paperId": "a70e48c119742cb69b1cdbd62e58a8a8d0d28a8e", "title": "Comparing Automatic and Human Evaluation of NLG Systems"}, {"paperId": "475354f10798f110d34792b6d88f31d6d5cb099e", "title": "Automatically Constructing a Corpus of Sentential Paraphrases"}, {"paperId": null, "title": "2023. GPT-4 technical report"}, {"paperId": null, "title": "2022. Delta tuning: A comprehensive study of parameter efficient meth-ods for pre-trained language models"}, {"paperId": null, "title": "2023. Alpacaeval: An automatic evaluator of instruction-following models"}, {"paperId": null, "title": "Arvind"}, {"paperId": null, "title": "2022. Visual prompt tuning"}, {"paperId": null, "title": "2023. A framework for few-shot language model evaluation"}]}