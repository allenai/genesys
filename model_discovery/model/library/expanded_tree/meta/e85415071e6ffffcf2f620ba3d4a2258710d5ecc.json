{"paperId": "e85415071e6ffffcf2f620ba3d4a2258710d5ecc", "abstract": ": Vision transformers have shown excellent performance in computer vision tasks. However, the computation cost of their (local) self-attention mechanism is expensive. Comparatively, CNN is more e\ufb03cient with built-in inductive bias. Recent works show that CNN is promising to compete with vision transformers by learning their architecture design and training protocols. Nevertheless, existing methods either ignore multi-level features or lack dynamic prosperity, leading to sub-optimal performance. In this paper, we propose a novel attention mechanism named MCA, which captures di\ufb00erent patterns of input images by multiple kernel sizes and enables input-adaptive weights with a gating mechanism. Based on MCA, we present a neural network named ConvFormer. ConvFormer adopts the general architecture of vision transformers, while replacing the (local) self-attention mechanism with our proposed MCA. Extensive experimental results demonstrated that ConvFormer achieves state-of-the-art performance on ImageNet classi\ufb01cation, which outperforms similar-sized vision transformers(ViTs) and convolutional neural networks (CNNs). Moreover, for object detection on COCO and semantic segmentation tasks on ADE20K, ConvFormer also shows excellent performance compared with recently advanced methods. Code and models will be available.", "venue": "arXiv.org", "year": 2022, "citationCount": 10, "influentialCitationCount": 1, "openAccessPdf": {"url": "https://arxiv.org/pdf/2209.07738", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "A novel attention mechanism named MCA is proposed, which captures di\ufb00erent patterns of input images by multiple kernel sizes and enables input-adaptive weights with a gating mechanism and is presented as a neural network named ConvFormer, which adopts the general architecture of vision transformers, while replacing the (local) self-attention mechanism with MCA."}, "embedding": {"model": "specter_v2", "vector": [0.08736836910247803, 0.570137619972229, -0.34787753224372864, 0.25599202513694763, -0.1148894876241684, -0.07486242055892944, 0.4756883978843689, -0.2864852845668793, -0.6454629302024841, -0.7093268632888794, 0.2901238203048706, 0.5306878089904785, 0.994877278804779, -0.34058207273483276, -0.0048264749348163605, -0.05800773948431015, -0.22718854248523712, -0.1897721141576767, 0.852859377861023, -0.08377383649349213, 0.10590378195047379, -0.30674663186073303, -1.1744415760040283, 0.35633179545402527, 0.12407888472080231, 1.342663049697876, 0.5343683362007141, 0.9361453652381897, 0.02677958644926548, 0.34673693776130676, 0.5125494003295898, -0.33575451374053955, 0.2454719990491867, 0.20327244699001312, -0.4721261262893677, 0.20569153130054474, 0.9603250026702881, -0.1388808935880661, -0.5878727436065674, 1.2186564207077026, -0.14283309876918793, 0.1052720695734024, 0.28553706407546997, -0.8609912991523743, -0.3487934470176697, 0.25796371698379517, 0.608789324760437, 1.1172826290130615, -0.8537652492523193, -0.23593096435070038, 1.1870448589324951, -1.2478313446044922, 0.09166856110095978, 1.4791021347045898, 0.39355796575546265, 0.1480538249015808, -0.12324535846710205, -0.5103225111961365, 0.6447733044624329, 0.1987985521554947, -0.35753774642944336, -0.21562545001506805, 0.13726410269737244, -0.38261762261390686, 1.7803125381469727, -0.5338524580001831, 0.2941238582134247, 0.5999966263771057, 0.23164494335651398, 1.4073396921157837, -0.1546250432729721, -0.6594187617301941, -0.053406745195388794, -0.009981147944927216, 0.42262497544288635, 0.8193867802619934, -0.044158078730106354, 0.07401442527770996, -0.6819931864738464, 0.08862146735191345, 0.7491161823272705, 0.257802814245224, 0.27234524488449097, -0.32893940806388855, -0.15457355976104736, 0.8207229375839233, 1.1567503213882446, 0.7016918659210205, -0.3796178996562958, 0.8202690482139587, 0.5157976150512695, -0.17531462013721466, -0.22627168893814087, 0.5358420014381409, 0.08153644949197769, 1.092180609703064, -0.6228837370872498, -0.14350152015686035, -0.5715272426605225, 1.168066143989563, -0.15835559368133545, 0.4563930928707123, -0.38770049810409546, 0.01335216872394085, 1.4093378782272339, 0.33844897150993347, 0.42215466499328613, -0.6174328923225403, 0.04293109104037285, -0.3967284560203552, -0.40963423252105713, -0.8132858872413635, 0.15508097410202026, -0.6732548475265503, -1.170798659324646, -0.7805190086364746, -0.27947935461997986, 0.41259798407554626, -1.3866400718688965, 0.10377167165279388, -0.5970157980918884, 0.06723559647798538, -0.07416196167469025, 0.5282427668571472, 0.524620532989502, 0.16683660447597504, 0.4477337598800659, 0.49224308133125305, 1.409580945968628, -1.2754915952682495, -0.2647028863430023, -0.9147456884384155, -0.4438594579696655, -0.4352279007434845, 0.06612394005060196, -0.39820006489753723, -0.9696924686431885, -1.4507213830947876, -0.8232948184013367, 0.05247487500309944, -0.7722955346107483, 0.0960933193564415, 1.2242008447647095, 0.33005115389823914, -1.2495288848876953, 0.602782130241394, -0.35006991028785706, -0.692454993724823, 0.9201419949531555, -0.030346078798174858, 0.4706653654575348, 0.2791517674922943, -0.8949372172355652, 0.22004295885562897, 0.07240719348192215, -0.3179701268672943, -0.47649064660072327, -0.2324219048023224, -0.9277576208114624, 0.11031781136989594, 0.19975055754184723, -0.6455408930778503, 1.1911978721618652, -0.7482238411903381, -0.6025183796882629, 0.6926934719085693, -0.12500005960464478, -0.22840574383735657, 0.1840352863073349, -0.2499726563692093, -0.08178927004337311, -0.05673012137413025, -0.035589549690485, 0.5676249861717224, 1.001347303390503, -0.06375645846128464, -0.4006873369216919, 0.040945786982774734, -0.23336386680603027, -0.3861072063446045, -0.7237241268157959, 0.8629646897315979, -0.7841135263442993, -0.4052985906600952, 0.41843917965888977, 0.7349041700363159, -0.19337810575962067, -0.09288755804300308, -0.1214241087436676, -1.1685614585876465, 1.063474416732788, 0.5812166333198547, 0.4486837685108185, -0.9566256999969482, -1.0456702709197998, -0.11939416080713272, 0.01490566786378622, 0.04829461872577667, -0.8330858945846558, 0.090045265853405, -0.26293012499809265, 0.20006532967090607, 0.4819949269294739, -0.7894949913024902, -0.4591783285140991, -0.46968764066696167, -0.6325392723083496, 0.13190427422523499, 0.42235878109931946, 1.4690407514572144, -0.9195126295089722, -0.4915326237678528, 0.2550981938838959, 0.24059469997882843, -0.9963688254356384, 1.221242904663086, -0.35852909088134766, -0.3189832866191864, -0.4708481431007385, 0.5401691198348999, 0.029240375384688377, -0.4396267235279083, 0.49727538228034973, -0.9869340062141418, -0.21718290448188782, 0.13426826894283295, -0.09184163063764572, 0.9656189680099487, 0.09671297669410706, 0.7934311628341675, -0.004415706731379032, -0.9480068683624268, 0.30662307143211365, 0.2769795358181, -0.25836557149887085, -0.8667199611663818, 0.7730344533920288, -0.026728728786110878, -0.9435418844223022, 0.18800067901611328, 0.6459034085273743, 1.2379162311553955, -0.26249268651008606, -0.4070775508880615, 1.1229827404022217, -0.5122743248939514, -0.10787132382392883, 0.4332079291343689, 0.5871276259422302, 0.09890802204608917, 0.11135316640138626, -0.2999902665615082, -0.01757482998073101, -0.778189480304718, 0.13903087377548218, 0.871489405632019, 0.1344449520111084, 1.46047842502594, 0.5096926689147949, -0.7807801365852356, -0.412047803401947, -0.1676010936498642, 0.5562517046928406, 1.1794248819351196, 0.1407664567232132, 0.2185886800289154, -0.7569610476493835, -0.6022008657455444, -0.530697762966156, -0.7982708215713501, -0.6042680740356445, -0.09056688100099564, -0.17908364534378052, -1.0056954622268677, 0.829757809638977, 0.6875146627426147, 1.6234382390975952, -0.8130801320075989, -0.8190547227859497, -0.37638065218925476, 0.38831937313079834, -0.99393230676651, -0.6702820658683777, 0.3004038631916046, -0.5348783135414124, -0.4838864207267761, 0.055809371173381805, -0.6341019868850708, 0.39183667302131653, -0.21833084523677826, 0.8181509375572205, -0.4033479392528534, -0.5192857384681702, 0.48678362369537354, 0.4784877896308899, -0.879580020904541, 0.13771222531795502, 0.3094691038131714, -0.22164444625377655, 0.0543593131005764, 0.0944657176733017, 0.29300180077552795, -0.4698304235935211, 0.10674816370010376, -0.3429524004459381, -0.25492897629737854, 0.432990163564682, 0.1945282220840454, 0.8212288618087769, -0.493312805891037, 0.19350437819957733, -0.8473454713821411, 0.577755331993103, 0.35145148634910583, -0.4514959454536438, 0.09371431171894073, -0.4379749298095703, -0.47377464175224304, 0.16182145476341248, -0.7212055921554565, -0.25493761897087097, -0.2117518186569214, 0.536767303943634, -1.0025277137756348, -0.32745641469955444, -0.29498291015625, 0.11979011446237564, -0.10560499131679535, 0.37567800283432007, 0.09946645051240921, 0.14574089646339417, 0.15958340466022491, 0.3242832124233246, -0.8713030219078064, 1.124017596244812, 0.38131773471832275, 0.06366650760173798, 0.0775473490357399, -0.30392301082611084, -0.8614784479141235, -0.5283715128898621, -0.7858386635780334, -0.3657096028327942, -0.48438596725463867, 0.6896765232086182, -0.655483603477478, -0.7728340029716492, 0.38326314091682434, -0.9106593728065491, -0.2075185477733612, -0.1682829111814499, -0.2405063658952713, -0.14258719980716705, -1.1183314323425293, -0.7639685869216919, -0.39701417088508606, -0.9604688882827759, -0.8566986322402954, 0.2905241549015045, 0.746940016746521, 0.08895175904035568, -0.4633817970752716, -0.28390538692474365, -0.578159511089325, 1.3767848014831543, -0.1118554174900055, 0.006463800556957722, -0.3190123438835144, -0.4312671720981598, -0.2122688889503479, -0.4668697118759155, 0.8865471482276917, -0.3401082456111908, 0.12814666330814362, -1.16133451461792, 0.40285807847976685, -0.05111844465136528, -0.40725746750831604, 0.9877769351005554, 0.3105573058128357, 0.8966289162635803, 0.3966904580593109, -0.4809173345565796, 0.3958699703216553, 1.6442874670028687, -0.6714081168174744, 0.6985325813293457, 0.10369651019573212, 0.7412166595458984, -0.32212841510772705, -0.3140932023525238, 0.11690379679203033, 0.3245481848716736, -0.004167456645518541, 0.804021418094635, -0.8040648102760315, -0.8413266539573669, -0.438702255487442, -0.12080517411231995, 0.8364747762680054, 0.11495845019817352, 0.14241757988929749, -0.8565152883529663, 1.25274658203125, -1.2742760181427002, -0.7412007451057434, 0.579843282699585, 0.37556102871894836, -0.07358996570110321, -0.1595998853445053, -0.45691245794296265, -0.3820870518684387, 0.6909421682357788, 0.4533127248287201, -0.268841415643692, -0.42853885889053345, -0.09746693819761276, 0.7823585271835327, 0.571408748626709, 0.24998265504837036, -0.9516381621360779, 0.6715776324272156, 14.632877349853516, 0.5475131869316101, -0.3961792588233948, 0.5445889234542847, 0.7953792810440063, 0.9010250568389893, 0.2814175486564636, 0.10469885915517807, -1.053786039352417, -0.259716272354126, 0.19167956709861755, 0.5785295963287354, -0.15906362235546112, 0.6546241044998169, -0.36406680941581726, 0.009014412760734558, -0.2840409576892853, 0.8449209928512573, 0.9404987096786499, -1.403031826019287, 0.17933495342731476, 0.07474982738494873, 0.5444571375846863, 0.8342829346656799, 0.7214820981025696, 0.49212846159935, 0.3855088949203491, -0.20288199186325073, 0.4958539307117462, 0.24420134723186493, 0.7470982670783997, 0.4089655578136444, 0.5700945258140564, -0.24834048748016357, -1.222629427909851, -0.07264044135808945, -0.5980830788612366, -0.9511610269546509, -0.16656412184238434, 0.10048903524875641, -0.20034779608249664, -0.539008378982544, 0.3603658080101013, 0.6088630557060242, -0.3539043962955475, 0.7384656071662903, -0.31133952736854553, 0.3904527723789215, 0.20990699529647827, -0.2533509433269501, 0.3662697374820709, 0.8671144843101501, 0.07385251671075821, 0.26343801617622375, -0.40488091111183167, 0.32781070470809937, 0.406324177980423, 0.4510834515094757, -0.6893081068992615, -0.5911349058151245, -0.00472992192953825, 0.015009688213467598, -0.5107311606407166, 1.4257807731628418, -0.34393951296806335, -0.03626968339085579, -0.225180521607399, 0.3265913128852844, 0.2660321295261383, 0.11575932800769806, -0.5407763719558716, -0.5282094478607178, 0.09298276156187057, -0.22555364668369293, 0.46312227845191956, 0.3430527448654175, -0.33876752853393555, -0.8422131538391113, -0.9307131171226501, 0.08779240399599075, 0.6699490547180176, -0.810838520526886, -0.7039589881896973, 1.2028985023498535, -0.3201189935207367, 0.021782679483294487, 0.8674901723861694, -1.1199008226394653, -0.6770488619804382, 0.1557074785232544, -1.357193946838379, -1.0759525299072266, -0.5022110342979431, -0.11379513889551163, -0.12067265063524246, -0.04453765228390694, 0.7982378602027893, -0.031330227851867676, -0.03196302056312561, 0.0023640277795493603, -0.9000770449638367, 0.5952757000923157, -0.2058965116739273, -0.8544142246246338, 0.6431013941764832, 0.6424869894981384, -0.1019197404384613, -0.3637336492538452, -0.2294401228427887, 0.25876548886299133, -0.5377979278564453, -0.1985836774110794, 0.49296775460243225, -0.5971189141273499, -0.2771110534667969, -0.7377223968505859, -0.6715328097343445, 0.24906660616397858, 0.9169649481773376, 0.396575927734375, -0.40832242369651794, -0.06646248698234558, -0.6555010676383972, -0.3068031668663025, -0.7284040451049805, -0.20206312835216522, 0.3676052689552307, -0.7358161211013794, -0.6824549436569214, -0.15797631442546844, 0.27910372614860535, -0.7402656674385071, -0.16222532093524933, -0.05717502534389496, 0.3472897708415985, -0.19888950884342194, 1.1647074222564697, -0.2640590965747833, 0.2870018184185028, 0.8012088537216187, -0.16003167629241943, -0.402561753988266, -0.12508562207221985, -0.6229894161224365, 0.4253523051738739, 0.2928013503551483, 0.3662512004375458, -0.6307869553565979, 0.33240172266960144, 0.6024820804595947, 0.07963267713785172, -0.39595475792884827, -0.4651036262512207, 0.11532598733901978, -0.1881786733865738, -0.5670979619026184, -0.002769757993519306, -0.1860632598400116, -0.02683076076209545, 0.0010766189079731703, 0.9893214106559753, 0.4325287640094757, 0.2403828352689743, -0.40284037590026855, 0.15899676084518433, -0.2648942470550537, -0.04527774825692177, -0.47596532106399536, -1.0394951105117798, -1.2409629821777344, -0.41762885451316833, -0.8707948327064514, -0.01868877001106739, -0.9172114133834839, -0.16032293438911438, 0.25534406304359436, -0.6606650948524475, 0.36503857374191284, 0.3862185478210449, 0.29414138197898865, -0.17252704501152039, -0.5541879534721375, -1.004928469657898, 0.5451761484146118, 0.9706281423568726, -0.8189454674720764, -0.028778020292520523, -0.07131927460432053, -0.25608909130096436, 0.79167640209198, 0.4578167796134949, -0.10571032762527466, -0.40267401933670044, -1.057808518409729, 0.05646273121237755, -0.45261573791503906, 0.3207028806209564, -1.2272580862045288, 1.4871866703033447, 0.4325947165489197, 0.4581667184829712, -0.08114947378635406, 0.08454865962266922, -0.7009326815605164, -0.9337884783744812, 0.4492367208003998, -0.32133737206459045, 0.061377815902233124, 0.18062418699264526, -0.634645402431488, -0.33047133684158325, 1.0644770860671997, 0.4984866976737976, -1.1616252660751343, -1.1323670148849487, 0.36021000146865845, -0.6211557984352112, 0.3165335953235626, -0.08827047795057297, -0.054479122161865234, -1.445674180984497, -0.11275244504213333, -0.2150031477212906, 0.3491981625556946, -0.6803526282310486, 1.0999000072479248, 0.914485514163971, -1.0118480920791626, 0.3962276577949524, 0.5872266888618469, -0.3743302822113037, 0.09130784869194031, 0.2770969569683075, 0.5862104296684265, -0.2910264730453491, 0.30670446157455444, -0.13132509589195251, -0.018755657598376274, -0.7369226217269897, 0.11245868355035782, 1.1083564758300781, -0.18875257670879364, -0.008632962591946125, 0.981850802898407, -0.0922657921910286, -0.5363749265670776, 0.33236777782440186, -1.422068476676941, -0.5813902020454407, 0.03692831099033356, 0.5275650024414062, 0.04185596853494644, 0.08022549003362656, -0.14572319388389587, -0.6078510880470276, 0.3861517310142517, -0.043022364377975464, -0.4434851109981537, 0.41960039734840393, 0.15266019105911255, -0.19932249188423157, 0.07376129180192947, 0.5012683868408203, -0.9684432744979858, -0.9487099647521973, -0.8110111951828003, -0.5118760466575623, -0.30091404914855957, 0.28766068816185, -0.09959326684474945, -1.3621129989624023, 0.6286572813987732, 0.9662639498710632, 0.5415277481079102, 0.4661843478679657, 0.25309818983078003, -0.13999858498573303, 0.38250240683555603, -0.12472975999116898, -0.713600218296051, 0.33993780612945557, 1.3835361003875732, 1.2910163402557373, -0.6790279150009155, 0.17624545097351074, -0.4105807840824127, -0.46331945061683655, 0.7735714912414551, 0.8642614483833313, -0.8051159977912903, 1.1895958185195923, -0.16210822761058807, 0.11403941363096237, -0.013632819056510925, -0.646956741809845, -0.7947003245353699, 0.6794629096984863, 1.3853394985198975, 0.36162427067756653, -0.020493527874350548, 0.24992088973522186, 0.7843204140663147, 0.42227089405059814, -0.15208888053894043, 0.41130802035331726, 0.29245397448539734, -0.2570805847644806, 0.24041983485221863, -0.11422121524810791, 0.5804507732391357, -0.69708251953125, -0.2240084856748581, 0.05933576077222824, 0.6493784189224243, 0.5915100574493408, 0.7577424645423889, 1.2048851251602173, 0.03142256289720535, 0.9439979791641235, -0.14451010525226593, 0.2770446240901947, -0.44915971159935, -0.5493090748786926, 0.05010996386408806, -1.0375556945800781, -0.3733460605144501, -0.6443920731544495, -0.8359410166740417, -0.00892609916627407, 0.29722288250923157, -0.19001026451587677, -0.4091559648513794, 0.32239583134651184, 0.6044238209724426, 0.4133731424808502, 0.9410654902458191, -0.2834886908531189, -0.8839537501335144, -0.11231501400470734, -1.0818238258361816, 0.3668971061706543, -0.488079696893692, -0.05803775414824486, -0.2660251259803772, -0.13320520520210266, 0.06272342056035995]}, "authors": [{"authorId": "50825490", "name": "Zimian Wei"}, {"authorId": "2523734", "name": "H. Pan"}, {"authorId": "2057835657", "name": "Xin-Yi Niu"}, {"authorId": "2124487915", "name": "Dongsheng Li"}], "references": [{"paperId": "9f1b0e4c42a5a85d4c023030557ade4419f82ecf", "title": "Scaling Up Your Kernels to 31\u00d731: Revisiting Large Kernel Design in CNNs"}, {"paperId": "430bab3890e1e52c4c1f74900b0e408e47a1cb8f", "title": "How Do Vision Transformers Work?"}, {"paperId": "177e957f5cd93229c9794ea652c646d2557b4a69", "title": "A ConvNet for the 2020s"}, {"paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2", "title": "MetaFormer is Actually What You Need for Vision"}, {"paperId": "45f686be3b96302ede327645227134e1c304dbab", "title": "Attention mechanisms in computer vision: A survey"}, {"paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3", "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers"}, {"paperId": "9b6af0e358e76d22f209c75b1702c3e6ea7815b1", "title": "Global Filter Networks for Image Classification"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "6b6ffb94626e672caffafc77097491d9ee7a8682", "title": "On the Connection between Local Attention and Dynamic Depth-wise Convolution"}, {"paperId": "f43b98fcc2d56c60fc71bce96374c1e6b8e12c66", "title": "Shuffle Transformer: Rethinking Spatial Shuffle for Vision Transformer"}, {"paperId": "a0964686d80e173529efca6377f47e6a1b2fe69a", "title": "Less is More: Pay Less Attention in Vision Transformers"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5", "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "91e8117e7ebc966bc76de2cb52ec717d2acdb1a4", "title": "Scaling Local Self-Attention for Parameter Efficient Visual Backbones"}, {"paperId": "fbd730a948a06cd4918c1d632ffdb4572b52d99b", "title": "Involution: Inverting the Inherence of Convolution for Visual Recognition"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "837ac4ed6825502f0460caec45e12e734c85b113", "title": "Dynamic Neural Networks: A Survey"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "0c334b5e835253f405871a13284d9eca6a8487e9", "title": "MobileSal: Extremely Efficient RGB-D Salient Object Detection"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb", "title": "TAM: Temporal Adaptive Module for Video Recognition"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "173d31ea3ec9db19870fcf2710841b4a3e864c6d", "title": "Global-Local Temporal Representations for Video Person Re-Identification"}, {"paperId": "7823292e5c4b05c47af91ab6ddf671a0da709e82", "title": "Once for All: Train One Network and Specialize it for Efficient Deployment"}, {"paperId": "fb564bacfa790d44ab02a72256d55aa8b2209914", "title": "MixConv: Mixed Depthwise Convolutional Kernels"}, {"paperId": "c2c083df88e88223e1a411e61040b94c233b1b63", "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "5e19eba1e6644f7c83f607383d256deea71f87ae", "title": "Searching for MobileNetV3"}, {"paperId": "3e70bbe6c4cd98d66599db709e32b748f184a2d4", "title": "CondConv: Conditionally Parameterized Convolutions for Efficient Inference"}, {"paperId": "deb956b70eb93bb08eaabc18fb11aed9bd20d08f", "title": "SRM: A Style-Based Recalibration Module for Convolutional Neural Networks"}, {"paperId": "fb8cf663a71bf31f59557a35d36aaf8c465b50af", "title": "Selective Kernel Networks"}, {"paperId": "a84906dbd4d6640f918d0b6ed2a7313dda0d55f1", "title": "Panoptic Feature Pyramid Networks"}, {"paperId": "45532bffbfbb5553da0b2d0844e95a1b37e59147", "title": "FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search"}, {"paperId": "a5f782f08ae8df9b9926200fdc5adbe99565513a", "title": "Global Second-Order Pooling Convolutional Networks"}, {"paperId": "cd8ddaaf56e38dddafdeac3f9643b9b5e9d35d54", "title": "Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks"}, {"paperId": "f323407464c4cd492d3fc1afd7170eab08f44d9b", "title": "ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware"}, {"paperId": "4eee87d960754f755fdec073a160af3e2e31672f", "title": "PSANet: Point-wise Spatial Attention Network for Scene Parsing"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "c1f457e31b611da727f9aef76c283a18157dfa83", "title": "DARTS: Differentiable Architecture Search"}, {"paperId": "50bdda28de3dcf82a0e10f9ec13eea248b19edb5", "title": "Regularized Evolution for Image Classifier Architecture Search"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "79cfb51a51fc093f66aac8e858afe2e14d4a1f20", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "4a73a1840945e87583d89ca0216a2c449d50a4a3", "title": "Deformable Convolutional Networks"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "5582bebed97947a41e3ddd9bd1f284b73f1648c2", "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"}, {"paperId": "88512be44744615f4baa8e14f600f036db4c2433", "title": "Semantic Understanding of Scenes Through the ADE20K Dataset"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649", "title": "Understanding the difficulty of training deep feedforward neural networks"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": null, "title": "2019a. Efficientnet: Rethinking model scal"}, {"paperId": null, "title": "2022. Visual attention network"}, {"paperId": null, "title": "2017) on images selected from the ImageNet validation dataset. We compare different CAMs generated by"}]}