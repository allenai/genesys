{"paperId": "8e6c4425e48b09d64827c64d8de0008f41f9be54", "abstract": "Integrating large language models (LLMs) into healthcare holds great potential but faces challenges. Pre-training LLMs from scratch for domains like medicine is resource-heavy and often unfeasible. On the other hand, sole reliance on Supervised Fine-tuning (SFT) can result in overconfident predictions and may not tap into domain-specific insights. In response, we present a multi-stage training method combining Domain-specific Continued Pre-training (DCPT), SFT, and Direct Preference Optimization (DPO). In addition, we publish a 3Gb Chinese Medicine (ChiMed) dataset, encompassing medical question answering, plain texts, knowledge graphs, and dialogues, segmented into three training stages. The medical LLM trained with our pipeline, Qilin-Med, shows substantial performance improvement. In the CPT and SFT phases, Qilin-Med achieved 38.4% and 40.0% accuracy on the CMExam test set, respectively. It outperformed the basemodel Baichuan-7B (accuracy: 33.5%), by 7.5%. In the DPO phase, it scored 16.66 in BLEU-1 and 27.44 in ROUGE-1 on the Huatuo-26M test set, bringing further improvement to the SFT phase (12.69 in BLEU-1 and 24.21 in ROUGE-1). Additionally, we have further enhanced the model's performance through the Retrieval Augmented Generation (RAG) approach. Experiments demonstrate that Qilin-Med-RAG achieves an accuracy rate of 42.8% on CMExam. These results highlight the contribution of our novel training approach in building LLMs for medical applications.", "venue": "arXiv.org", "year": 2023, "citationCount": 10, "influentialCitationCount": 1, "openAccessPdf": {"url": "https://arxiv.org/pdf/2310.09089", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "A multi-stage training method combining Domain-specific Continued Pre-training (DCPT), SFT, and Direct Preference Optimization (DPO) is presented, and a 3Gb Chinese Medicine dataset, encompassing medical question answering, plain texts, knowledge graphs, and dialogues, is published."}, "embedding": {"model": "specter_v2", "vector": [-0.11059631407260895, 0.8329094648361206, -0.7189528346061707, 0.16784609854221344, -0.869860827922821, -0.11781211942434311, 0.2777397632598877, -0.10395295172929764, -0.24394550919532776, 0.14239932596683502, 0.7456978559494019, -0.2942487895488739, -0.17641714215278625, 0.2421640306711197, 0.34628304839134216, 0.20594048500061035, -0.9425652623176575, 1.0575653314590454, -0.38725823163986206, -0.4623414874076843, -0.37023815512657166, -0.8627176880836487, 0.008131147362291813, 0.14148841798305511, 0.6210352778434753, 0.021830057725310326, 0.2697262763977051, 0.915285050868988, -0.2748299837112427, 0.5547411441802979, 0.45144179463386536, -0.21352088451385498, -0.16528718173503876, -0.3960384726524353, -0.6063803434371948, 0.313968688249588, -0.34979960322380066, -0.4287065267562866, -0.23226360976696014, 0.5233959555625916, 0.315043568611145, 0.19144301116466522, 0.43984168767929077, -0.3670024275779724, -0.714312732219696, 0.652300238609314, 0.8121212124824524, 0.23710182309150696, 0.16598187386989594, -0.5151101350784302, 1.123525857925415, -1.2756842374801636, 0.7068493962287903, 1.4296530485153198, 0.17723818123340607, 1.093387484550476, 0.2200847864151001, -0.47080811858177185, 0.2050606608390808, -0.1692948341369629, -0.9268667697906494, 0.13079610466957092, -0.2817748785018921, -0.3326930105686188, 1.4486665725708008, -0.3148861825466156, -0.1272468864917755, 0.3373411297798157, -0.0326370932161808, 1.3669028282165527, -0.3006366789340973, -0.6925041079521179, -0.04978923872113228, 0.5021303296089172, -0.11158488690853119, 0.9519835710525513, -0.5364701151847839, 0.15736250579357147, -0.39489102363586426, -0.41076183319091797, 0.34519582986831665, -0.13281387090682983, -0.12591059505939484, 0.00865792017430067, -0.4100024998188019, 0.8100258111953735, 0.40811002254486084, 1.0916951894760132, 0.0359807088971138, 0.07992145419120789, -0.12643960118293762, 0.14228256046772003, -0.19521985948085785, 0.7524256110191345, -0.41542848944664, 0.4460732638835907, -0.7562375664710999, 0.30234289169311523, -0.035992398858070374, 0.8040943145751953, -0.4500855505466461, -0.28604328632354736, -1.3269879817962646, 0.051293086260557175, 1.467775583267212, -0.1956540048122406, 0.745250940322876, -0.5303894281387329, 0.21411554515361786, -0.3885495364665985, 0.47186756134033203, -0.2671411633491516, -0.6241331696510315, -0.20482179522514343, -0.8648291230201721, -1.7374411821365356, -0.7071864604949951, -0.06286139786243439, -0.7870045900344849, 0.8648291230201721, -0.28462228178977966, -0.19691820442676544, 0.5222746729850769, 0.5684793591499329, 1.0644317865371704, 0.49818477034568787, 0.42405468225479126, -0.06935515999794006, 0.885529100894928, -0.9073341488838196, -0.7875111699104309, -0.9805797338485718, 1.0124655961990356, -0.09413286298513412, -0.020621920004487038, -0.33586451411247253, -1.3588849306106567, -0.7776022553443909, -0.34238213300704956, -0.0169964786618948, -0.38237470388412476, 0.3090040385723114, 0.6824333071708679, 0.3680066168308258, -1.0459883213043213, 0.35776039958000183, 0.06494015455245972, -0.4970647394657135, 0.05010873079299927, 0.3377005457878113, 0.2905474603176117, -0.7817834615707397, -1.684179425239563, 0.3115933835506439, 0.4344341456890106, -0.6076719164848328, -0.189509779214859, -0.47489964962005615, -1.0503003597259521, -0.3261174261569977, 0.3069719970226288, -0.9717392325401306, 1.2106776237487793, 0.20816220343112946, -1.1306853294372559, 0.8071007132530212, -0.09533116221427917, 0.13541021943092346, 0.4377245604991913, 0.20532792806625366, -0.7101467251777649, -0.12563380599021912, -0.29575586318969727, 0.7691482305526733, 0.00868925265967846, 0.13240675628185272, 0.01974376104772091, 0.45205599069595337, -0.006166370585560799, -0.15638305246829987, -0.1913403421640396, 0.771021842956543, -0.7726689577102661, -0.16786423325538635, 0.17635886371135712, 0.5485557913780212, -0.7184593081474304, -0.15451228618621826, -0.572555661201477, -0.8244168758392334, 0.3975087106227875, -0.18777325749397278, 1.14762282371521, -0.6270396709442139, -0.5198469758033752, -0.15047892928123474, 0.20080719888210297, 0.15404312312602997, -0.725905179977417, 0.5866261720657349, -0.38277459144592285, 0.44800230860710144, -0.3652530610561371, -0.8867089152336121, 0.09858561307191849, -0.23309673368930817, -0.1474861204624176, -0.5208986401557922, 0.3780560791492462, 1.495766282081604, -1.0615355968475342, -0.17124564945697784, -0.06262370944023132, 0.1948399841785431, -1.3268427848815918, 1.3498446941375732, -0.7382879257202148, 0.7349549531936646, -0.49410995841026306, 0.1271568238735199, 0.045586273074150085, -0.6196351647377014, 0.5808886289596558, -0.24051682651042938, 0.12379539757966995, 0.007281439378857613, -0.2154335230588913, 1.6130921840667725, -0.14162322878837585, -0.1285947561264038, -0.15822696685791016, -0.5576087832450867, 0.036963943392038345, 0.8044523596763611, 0.3402545154094696, -0.5256273150444031, 0.20623281598091125, 0.3997188210487366, -0.6151476502418518, -0.35164323449134827, 0.22670795023441315, 0.23606730997562408, -0.43318963050842285, 0.02602354809641838, 0.45427951216697693, -0.18407651782035828, 0.6303018927574158, 0.4901447594165802, 0.5084384083747864, -0.15455685555934906, 0.6454640030860901, -0.04631005600094795, 0.7738396525382996, -0.6139702200889587, 0.07525420188903809, 0.520715057849884, 0.496975302696228, 0.76655113697052, 0.20823243260383606, -0.4868878722190857, 0.4017966687679291, 0.05220614746212959, 0.6735362410545349, 0.9387209415435791, -0.30997300148010254, -0.32808831334114075, -0.652557373046875, -0.49897071719169617, -0.3592830300331116, -0.06964464485645294, -0.5181252956390381, -0.3591541051864624, -0.31996920704841614, -1.3358886241912842, 0.6597208976745605, 0.21934621036052704, 0.7322983145713806, -0.5524808764457703, 0.01629229076206684, -0.05626114830374718, -0.17596228420734406, -0.7160683274269104, -0.7960378527641296, -0.09972145408391953, -0.5048384070396423, -0.28100743889808655, -0.6255223751068115, -0.29627156257629395, 0.2402786910533905, -1.045497179031372, 1.0518888235092163, -0.5727712512016296, -0.6858459711074829, 0.5400989055633545, 0.4520837962627411, -0.28787505626678467, -1.0477620363235474, -0.28116151690483093, -0.15612062811851501, -0.3631426692008972, 0.22550220787525177, 0.9440815448760986, -0.26798704266548157, 0.059198420494794846, -0.5699915289878845, 0.16762322187423706, 0.4221096336841583, 0.4504178464412689, 0.5027788281440735, -0.47350671887397766, 0.30495762825012207, -1.4184684753417969, 1.0720263719558716, 0.01824468933045864, -0.30538809299468994, 0.5598874688148499, -0.748682975769043, -0.3593616187572479, 0.30747416615486145, -0.3718565106391907, -0.3045814335346222, -1.1005009412765503, -0.20104758441448212, 0.03979792818427086, -0.14735634624958038, 0.8067587018013, 0.11655281484127045, 0.3160165548324585, 0.20202498137950897, 0.3411790728569031, 0.2709299325942993, -0.24489036202430725, 0.7642389535903931, -0.5810274481773376, 0.006827782839536667, 0.37519553303718567, 0.10375736653804779, -0.3381873667240143, -0.3265283703804016, -0.5067259669303894, -0.5461516976356506, -0.39613160490989685, -0.1978522092103958, 0.012829490005970001, 0.6474999189376831, -0.7585587501525879, -0.4199352562427521, -0.5102890729904175, -0.5708733797073364, -0.16261447966098785, 0.02958914451301098, -0.030091339722275734, -0.09488413482904434, -0.948589026927948, -1.1375514268875122, -0.19520877301692963, -0.5899419188499451, -1.1273398399353027, 0.4820728003978729, 0.05311215668916702, -0.5416654348373413, -0.8607962727546692, 0.21973079442977905, 0.10349791496992111, 0.8415651321411133, -0.5933178067207336, 1.2201557159423828, -0.09181797504425049, -0.12723881006240845, -0.42162275314331055, 0.3304499387741089, 0.36453476548194885, 0.30218687653541565, -0.19285856187343597, -0.26103639602661133, 0.12391512840986252, -0.22056390345096588, -0.3400060534477234, -0.12538708746433258, 0.3990617096424103, 0.6979323625564575, 0.30549100041389465, -0.5557724833488464, -0.09146316349506378, 1.2911431789398193, -0.41024211049079895, 0.019728563725948334, -0.17839618027210236, 0.9015793204307556, 0.4035066068172455, 0.11953109502792358, 0.6047325134277344, 0.48042967915534973, 0.2692231833934784, -0.22698169946670532, -0.5967429280281067, 0.004460460972040892, -0.318388432264328, 0.20796439051628113, 1.4446313381195068, 0.5107340216636658, -0.1403152197599411, -1.1911916732788086, 0.6106584072113037, -1.0654935836791992, -0.21985886991024017, 0.8164029121398926, 0.5138402581214905, 0.7106766700744629, -0.41920655965805054, -0.43953120708465576, -0.468825101852417, 0.06967003643512726, -0.1989641934633255, -0.12177037447690964, -0.22567959129810333, 0.09083840996026993, 0.48288363218307495, -0.17951229214668274, 0.6737666130065918, -0.15316082537174225, 0.5522992014884949, 14.931915283203125, 0.6314516663551331, -0.05439051613211632, 0.7177695035934448, 0.6962922811508179, 0.4439649283885956, -0.4627231955528259, -0.36026546359062195, -1.0041470527648926, -0.4096256494522095, 1.2334052324295044, 0.008103741332888603, 0.041236404329538345, 0.1620422899723053, 0.34008368849754333, 0.276185542345047, -0.4691711366176605, 0.6153988242149353, 0.5262489318847656, -1.3090399503707886, 0.7720444202423096, 0.30389586091041565, 0.5949231386184692, 0.3763967454433441, 0.8557952046394348, 0.8738362789154053, 0.2006578892469406, -0.6274819374084473, -0.07040970772504807, 0.4834739863872528, 0.7446204423904419, 0.03402482345700264, 0.6107284426689148, 0.6079695224761963, -0.636258602142334, -0.46690747141838074, -0.45067694783210754, -0.5436360239982605, 0.19916486740112305, 0.12997598946094513, -1.0128512382507324, -0.09072069823741913, -0.565298318862915, 0.6009162664413452, 0.1251106858253479, 0.3428674340248108, -0.007879798300564289, 0.39381876587867737, 0.49944543838500977, 0.11971230059862137, 0.3532876670360565, 0.4504406750202179, 0.12409451603889465, 0.03621763363480568, 0.13599826395511627, 0.10296396166086197, 0.438766747713089, 0.5450997352600098, -0.3992007374763489, 0.11803580075502396, -0.3286706209182739, -0.501888632774353, -0.49726754426956177, 0.6376422643661499, 0.6086472868919373, 0.09617938101291656, -0.6067969799041748, -0.032534804195165634, 0.09036760777235031, 0.10891120135784149, -0.05942395702004433, 0.25628337264060974, 0.3301123082637787, -0.47588035464286804, -0.28001806139945984, 0.5965142846107483, 0.16751699149608612, -0.5496999025344849, -0.9212777018547058, -0.46205276250839233, 0.6631494760513306, -0.5603287816047668, -0.8236979842185974, 1.0909910202026367, -0.3434416949748993, -0.9268007278442383, -0.301437646150589, -0.7798336744308472, 0.28544682264328003, 0.7692806124687195, -1.4041930437088013, -0.6729218363761902, 0.44636592268943787, -0.08389966189861298, -0.33663037419319153, -0.0019508027471601963, 1.8192415237426758, 0.29949241876602173, -0.5047594904899597, -0.019801534712314606, 0.20770324766635895, 0.038019802421331406, 0.09936682879924774, -0.7326076626777649, 0.30720826983451843, -0.1335398256778717, -0.37210506200790405, 0.4122435450553894, -0.24229075014591217, 0.002788526937365532, -0.8443060517311096, -0.6338734030723572, 0.8203068971633911, -1.0863081216812134, -0.5230490565299988, -0.8339001536369324, -0.5524372458457947, 0.05656423419713974, 0.47323155403137207, -0.36381813883781433, 0.8687406778335571, -0.2878129184246063, 0.2981797754764557, 0.16637539863586426, -1.2285646200180054, -0.03174474462866783, 0.27694258093833923, -0.7274602651596069, -0.40463122725486755, 0.7059751152992249, 0.4970884621143341, -0.9332630634307861, -0.741162121295929, 0.0686182975769043, -0.20154230296611786, 0.32091397047042847, 1.0605453252792358, -0.6227042078971863, 0.5462189316749573, 0.8916996717453003, 0.06438019126653671, -0.6287591457366943, -0.21333584189414978, -0.9254580736160278, -0.014298079535365105, -0.2845815420150757, 0.9010619521141052, -0.2799081802368164, 0.08213025331497192, 1.3399099111557007, 0.49341055750846863, -0.8361867666244507, -0.4289298355579376, -0.013549964874982834, 0.24616491794586182, 0.001662171445786953, 0.25402408838272095, -0.05325711518526077, 0.25316905975341797, 0.07730825990438461, 0.269715815782547, 0.8119223117828369, -0.35210832953453064, -0.43021100759506226, 0.13275045156478882, 0.002361358143389225, -0.31026992201805115, -0.3936447501182556, -0.16461576521396637, -1.2598013877868652, -0.3730708956718445, -1.0320374965667725, 0.10152306407690048, -1.2585512399673462, -0.2028942108154297, 0.24282817542552948, -0.2967509329319, 0.008851532824337482, 0.08936821669340134, -0.3218996822834015, -0.8637269139289856, -0.7611626982688904, -0.5674864053726196, 0.6406972408294678, 1.287605881690979, -0.805885374546051, -0.08320622146129608, -0.17369656264781952, -0.45855051279067993, 0.09189175069332123, 0.32869499921798706, -0.13364939391613007, -1.052162766456604, -1.1077684164047241, 0.1209680587053299, 0.1898035854101181, -0.2685041129589081, -0.42940279841423035, 0.5581508874893188, 0.37321487069129944, -0.2611478865146637, -0.11256299912929535, 0.17901507019996643, -0.7279171943664551, -0.324625164270401, 0.802434504032135, -0.9561063051223755, 0.04549882560968399, 0.14797107875347137, -0.9984791278839111, -0.5564618110656738, 0.5986716151237488, 0.029711168259382248, -1.6269924640655518, -0.6355525851249695, 0.6706473231315613, -0.8384741544723511, 0.23042573034763336, -0.43327000737190247, 0.22119753062725067, -0.6065342426300049, -0.4193340539932251, -0.5525336861610413, 0.7640315890312195, -1.0042322874069214, 0.8848676681518555, 0.6507182121276855, -0.9767140746116638, -0.18126288056373596, 0.3537861406803131, 0.14582140743732452, -0.13113188743591309, 0.8572790026664734, 0.4540559649467468, -0.23660366237163544, 1.0189435482025146, 0.5952638387680054, 0.41468188166618347, -0.7024914622306824, 0.17278876900672913, 1.0266368389129639, -0.9773832559585571, -0.0033940665889531374, 1.2843509912490845, -0.0823403000831604, -1.3929240703582764, 0.22692467272281647, -1.0959155559539795, -0.8046864867210388, -0.6292456984519958, 0.9458597302436829, -0.3009704053401947, 0.07655701041221619, 0.08449883759021759, -0.7045437097549438, 0.17298799753189087, -0.07040505111217499, -0.5640671849250793, 0.5027547478675842, -0.3673504889011383, -0.5880945324897766, 0.3614961504936218, 0.8607737421989441, -0.8110042214393616, 0.10840766876935959, -0.513964831829071, -0.25485482811927795, 0.3260751962661743, 0.16412444412708282, -0.7578762173652649, -0.348827987909317, 0.58796226978302, 0.9148916006088257, -0.09924519807100296, 0.3996358811855316, 0.028316659852862358, 0.2575809061527252, 0.6630757451057434, 0.053017329424619675, -0.42829254269599915, -0.3323807716369629, 1.0246561765670776, 1.200325846672058, -1.2606964111328125, -0.02137645147740841, -0.06762399524450302, -0.9231299161911011, 0.7013561129570007, 0.12758448719978333, 0.40332815051078796, 1.2397364377975464, -0.49396899342536926, 0.4609141945838928, -0.22996406257152557, -1.0117584466934204, -0.3626618981361389, 1.2796072959899902, 0.9964327216148376, 1.1267516613006592, 0.47514915466308594, -0.2303282767534256, 0.9808887243270874, 0.48146864771842957, 0.5792535543441772, 0.47223567962646484, 0.5071238875389099, 0.16884997487068176, -0.5143919587135315, 0.1940767616033554, 0.43445757031440735, -0.5672794580459595, -0.6422734260559082, -0.07478117942810059, 0.4055938422679901, 0.40480926632881165, 0.6883946657180786, 0.2696535587310791, 0.18329189717769623, 0.6503043174743652, 0.09340239316225052, 0.28502485156059265, -0.8864226341247559, -0.16002269089221954, 0.2341996282339096, -0.5927837491035461, -0.10398232191801071, -0.3042198419570923, -0.18760456144809723, -0.5988439917564392, 0.6100366711616516, 0.47304436564445496, 0.4550686478614807, 0.06506650149822235, 1.2102071046829224, 0.7581753730773926, 0.6572555899620056, -0.309330016374588, 0.2487500011920929, -0.4081542491912842, -0.8744316697120667, -0.03913062438368797, -0.5958527326583862, -0.052315231412649155, -0.033077422529459, 0.33116844296455383, -0.5514743328094482]}, "authors": [{"authorId": "2258550058", "name": "Qichen Ye"}, {"authorId": "2218869839", "name": "Junling Liu"}, {"authorId": "52290752", "name": "Dading Chong"}, {"authorId": "1800462890", "name": "Peilin Zhou"}, {"authorId": "2147311343", "name": "Y. Hua"}, {"authorId": "2170752745", "name": "Andrew Liu"}], "references": [{"paperId": "5cd2bf358a36ed729297da8269af5594eb1bb9dd", "title": "Continuous Training and Fine-tuning for Domain-Specific Language Models in Medical Question Answering"}, {"paperId": "c67a58bb5eb9cb6557a6032bb058a5cab978907f", "title": "Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare"}, {"paperId": "591d15dadf10e60b3cb94586879663ac6d74612d", "title": "Leveraging Language Models for Inpatient Diagnosis Coding"}, {"paperId": "838cd69a0b6c9c244a6eebb0f4742c0625132de6", "title": "An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning"}, {"paperId": "a50d4fd8f584276c0fd8560255884edd57aa926e", "title": "Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-world Multi-turn Dialogue"}, {"paperId": "5e6566354b23f7e849b1b439a24ba9d4c5cb655f", "title": "The shaky foundations of large language models and foundation models for electronic health records"}, {"paperId": "33112b58e3eb4a6506fa537d892dc6742c5e794d", "title": "Large language models in health care: Development, applications, and challenges"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "94ce1d5924e05e8d75e43ce70044293ddcef850a", "title": "Large language models in medicine"}, {"paperId": "ae2d35aeb5dd7043ac0056d60002e2e3c240bd1a", "title": "Exploring the potential of Chat-GPT as a supportive tool for sialendoscopy clinical decision making and patient information support."}, {"paperId": "a923cfbdc390457392250b90dcbe24ebb9927fea", "title": "A Deep Learning Approach for Transgender and Gender Diverse Patient Identification in Electronic Health Records"}, {"paperId": "1645e93f34ce34c0ff248a7349bf757a416c5312", "title": "Health system-scale language models are all-purpose prediction engines"}, {"paperId": "4b4ee637ef5107299212479c37a6594db5a72227", "title": "Benchmarking Large Language Models on CMExam - A Comprehensive Chinese Medical Exam Dataset"}, {"paperId": "e56d87170d11e9f26d5034e9c936bef436c03f3d", "title": "Iterative Proposal Refinement for Weakly-Supervised Video Grounding"}, {"paperId": "0d1c76d45afa012ded7ab741194baf142117c495", "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"}, {"paperId": "7ed0faa6720cd176d57badbc0455af31a03f080c", "title": "Towards Expert-Level Medical Question Answering with Large Language Models"}, {"paperId": "236c7dafea3df7ecffb5f18ec780d12f2f27d4b0", "title": "C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models"}, {"paperId": "6f7a08a3077cd90e25ad5ccfbaefc31b6d8e6fbe", "title": "Evaluating Chatbot Efficacy for Answering Frequently Asked Questions in Plastic Surgery: A ChatGPT Case Study Focused on Breast Augmentation."}, {"paperId": "1c5bc4f10b95a90d0283d0aacc94332aae508169", "title": "Huatuo-26M, a Large-scale Chinese Medical QA Dataset"}, {"paperId": "6486f0b6e443cb864639d4a85277d71cf69f78e0", "title": "Embracing Large Language Models for Medical Applications: Opportunities and Challenges"}, {"paperId": "59fc49dfd81b92661437eaf7e339c0792ccd8755", "title": "Safety Assessment of Chinese Large Language Models"}, {"paperId": "e5adc219685c9941b9a3d029480af4a51c0ea05a", "title": "Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"}, {"paperId": "302ee27524a717ddc21f332ca634b9211c6ec6aa", "title": "HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge"}, {"paperId": "38a9609a5bd874534527df9b00f2897927e57be9", "title": "MedAlpaca - An Open-Source Collection of Medical Conversational AI Models and Training Data"}, {"paperId": "9886731067c00e0eafd9a40d44be3b320576667e", "title": "The potential impact of ChatGPT/GPT-4 on surgery: will it topple the profession of surgeons?"}, {"paperId": "9e8cb8c91a0acb6e661b58ad724aa758490f2bea", "title": "Instruction Tuning with GPT-4"}, {"paperId": "bce55193d9a887ad00774a9134df08cd521a85ae", "title": "DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task"}, {"paperId": "4a7f6c4e71e20311ade4e76e8d0945d499c31fcd", "title": "ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge"}, {"paperId": "23684a07517870cffd1f97fafbaae16ba22bd2b7", "title": "Large AI Models in Health Informatics: Applications, Challenges, and the Future"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "7ccbedd10c5d5e31170a48200db199df6b944141", "title": "Exploring Social Media for Early Detection of Depression in COVID-19 Patients"}, {"paperId": "cb29cf52f0f7d2e4324c68690a55b22890f2212d", "title": "How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection"}, {"paperId": "6052486bc9144dc1730c12bf35323af3792a1fd0", "title": "Large language models encode clinical knowledge"}, {"paperId": "1139a20f41f8686f9d4e8b32550fe7bc8dc9ca13", "title": "GreenPLM: Cross-Lingual Transfer of Monolingual Pre-Trained Language Models at Almost No Cost"}, {"paperId": "1d26c947406173145a4665dd7ab255e03494ea28", "title": "GLM-130B: An Open Bilingual Pre-trained Model"}, {"paperId": "31ec2df38b42d7f3999936572726461dfc1a1657", "title": "LocVTP: Video-Text Pre-training for Temporal Localization"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "b9a977c73fd7522dd92ba39c2ee992494a6b254f", "title": "Unsupervised Pre-training for Temporal Action Localization Tasks"}, {"paperId": "f3a332ff1b73acda482e5d83696b2c701f487819", "title": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"}, {"paperId": "e924ce5fe6da93ce6ada4e001449da8f1e18b779", "title": "On Pursuit of Designing Multi-modal Transformer for Video Grounding"}, {"paperId": "4566c0d22ebf3c31180066ab23b6c445aeec78d5", "title": "Deduplicating Training Data Makes Language Models Better"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "8bf28d36e624f9a3c647d8eae7e09095c9c7511b", "title": "CoLA: Weakly-Supervised Temporal Action Localization with Snippet Contrastive Learning"}, {"paperId": "50796b0f3edf9cb5ff1e447c298b33755378aa4f", "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling"}, {"paperId": "12b71736392209b4292471b7da0aed71ba2aa545", "title": "ZeRO-Offload: Democratizing Billion-Scale Model Training"}, {"paperId": "763a2c057f529bfd3bf417fa60d93b3d5b219068", "title": "Decolonising Speech and Language Technology"}, {"paperId": "fc97c3f375c7228a1df7caa5c0ce5d2a6a171bd7", "title": "What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "a2f38d03fd363e920494ad65a5f0ad8bd18cd60b", "title": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "5e52f3b7fd14f151b26309e9f06239ddcd99b39a", "title": "MedDialog: A Large-scale Medical Dialogue Dataset"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c63bb976dc0d3a897f3b0920170a4c573ef904c6", "title": "Automatic Evaluation of Summaries Using N-gram Co-occurrence Statistics"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": null, "title": "Chatglm-med"}, {"paperId": "61b0f5cfd4f951632435707948201474e16e835b", "title": "Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding"}, {"paperId": null, "title": "2023b. Large language"}, {"paperId": null, "title": "Medicalgpt: Training medical gpt model"}, {"paperId": "f8ec8d44e55259d01ee742f9e209a4d76768bb3a", "title": "Automated LOINC Standardization Using Pre-trained Large Language Models"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "chatbot-base-on-knowledge-graph"}, {"paperId": null, "title": "Qasystemonmedicalgraph"}, {"paperId": null, "title": "2023. Bianque-1.0: Improving the\u201d question\u201d ability of medical chat model through finetuning with hybrid instructions and multi-turn doctor qa datasets,\u201d"}, {"paperId": null, "title": "2023. Stanford alpaca: An instruction-following llama model"}, {"paperId": null, "title": "2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"}, {"paperId": null, "title": "2023. Belle: Be everyone\u2019s large language model engine"}, {"paperId": null, "title": "2023. Exploring recommendation capabilities of gpt-4v (ision): A preliminary case study"}, {"paperId": null, "title": "OpenAI"}, {"paperId": null, "title": "a comprehensive Chinese evaluation suite designed to assess advanced knowledge and reasoning abilities of LLMs"}, {"paperId": null, "title": "2022b. Deep motion prior for weakly-supervised temporal action localization"}, {"paperId": null, "title": "medical text understanding, instruction following, and preference alignment"}]}