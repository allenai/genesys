{"paperId": "2b5e40c9c6c76569714b902a53838cb80ce89a26", "abstract": "The ever-growing ecosystem of LLMs has posed a challenge in selecting the most appropriate pre-trained model to fine-tune amidst a sea of options. Given constrained resources, fine-tuning all models and making selections afterward is unrealistic. In this work, we formulate this resource-constrained selection task into predicting fine-tuning performance and illustrate its natural connection with Scaling Law. Unlike pre-training, we find that the fine-tuning scaling curve includes not just the well-known\"power phase\"but also the previously unobserved\"pre-power phase\". We also explain why existing Scaling Law fails to capture this phase transition phenomenon both theoretically and empirically. To address this, we introduce the concept of\"pre-learned data size\"into our Rectified Scaling Law, which overcomes theoretical limitations and fits experimental results much better. By leveraging our law, we propose a novel LLM selection algorithm that selects the near-optimal model with hundreds of times less resource consumption, while other methods may provide negatively correlated selection. The project page is available at rectified-scaling-law.github.io.", "venue": "arXiv.org", "year": 2024, "citationCount": 6, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work forms this resource-constrained selection task into predicting fine-tuning performance and introduces the concept of \"pre-learned data size\" into the Rectified Scaling Law, which overcomes theoretical limitations and fits experimental results much better."}, "embedding": {"model": "specter_v2", "vector": [0.2267884910106659, 0.30618447065353394, -0.8043144941329956, -0.21161964535713196, -0.44968292117118835, -0.23174044489860535, 0.5284363031387329, -0.426767498254776, -0.7245335578918457, 0.05637650936841965, 0.1452636569738388, -0.1335168182849884, 0.006294569466263056, 0.32799214124679565, -0.15038499236106873, 0.20537406206130981, -0.7483319044113159, 0.5999158620834351, -0.22118771076202393, -0.7196964621543884, -0.40942057967185974, -0.511430025100708, -0.7459164261817932, -0.26915010809898376, 0.6198632121086121, 0.5192373394966125, 0.3087960481643677, 1.1179847717285156, -0.30954161286354065, -0.2511136531829834, 0.5229532718658447, 0.012240231037139893, 0.45647361874580383, -0.13874275982379913, -0.11048144102096558, -0.05593649297952652, 0.32274290919303894, -0.32993099093437195, -0.568446695804596, 0.8542100191116333, 0.11986888200044632, 0.3913128674030304, 0.41344428062438965, -0.6129624247550964, -0.186051607131958, 0.4383481442928314, 0.23167723417282104, 0.9127856492996216, -0.4699423015117645, -0.49534040689468384, 1.1775858402252197, -0.87278151512146, -0.08171044290065765, 1.5989532470703125, 0.3073303699493408, 0.7296040058135986, -0.21421870589256287, -0.6553551554679871, 0.30595266819000244, -0.5945878028869629, -0.967170238494873, -0.353626012802124, -0.5074700117111206, 0.05818891152739525, 1.6432344913482666, -0.5068298578262329, -0.517673134803772, 0.3980019986629486, 0.15222012996673584, 0.9211608171463013, -0.03184490650892258, -1.105101466178894, 0.013841892592608929, 0.3238835036754608, 0.009337126277387142, 0.39563217759132385, -0.2598720192909241, 0.34441161155700684, -1.072725772857666, -0.4300050437450409, 0.36540523171424866, -0.5099092721939087, 0.2690734565258026, -0.06223669648170471, 0.09974779188632965, 0.794929563999176, 0.15865811705589294, 0.7592822909355164, 0.21712270379066467, 0.9209339022636414, 0.4618794918060303, 0.802861213684082, 0.5691491961479187, 0.5700268745422363, -0.6780925989151001, 0.1285400390625, -0.9201603531837463, -0.05988279730081558, -0.03812507167458534, 0.9696859121322632, -0.34039151668548584, -0.01010229904204607, -0.6347470283508301, 0.738362729549408, 1.1677213907241821, 0.0553898811340332, 0.7958567142486572, -0.41353386640548706, 0.6352308988571167, -0.5756676197052002, 0.34768763184547424, 0.011948925442993641, -0.8072864413261414, -0.4725896716117859, -0.9653874039649963, -1.1482733488082886, -0.5855334997177124, -0.08229806274175644, -0.602370023727417, 0.8771911859512329, -0.34805384278297424, -0.4308811128139496, -0.16363820433616638, 0.7385010123252869, 0.21757164597511292, 0.24139198660850525, 0.49441877007484436, -0.2892826199531555, 0.8373579382896423, -0.7395333647727966, -0.2501869797706604, -0.906220018863678, 0.42031872272491455, -0.34398892521858215, 0.9550139307975769, -0.36401158571243286, -1.0646628141403198, -0.9986844062805176, -1.0164819955825806, 0.17731238901615143, -0.04306868463754654, 0.6415852308273315, 1.1892541646957397, 0.42437756061553955, -0.6944010853767395, 0.9910378456115723, -0.3810040354728699, -0.5609063506126404, 0.2088208943605423, 0.6623650789260864, 0.257546603679657, -0.11025626957416534, -1.4333207607269287, 0.2516850233078003, 0.3633747696876526, -1.1034839153289795, -0.19912385940551758, -0.5104929208755493, -0.36487096548080444, -0.169671431183815, 0.4306642413139343, -0.8388188481330872, 1.3494210243225098, -0.4299752116203308, -1.1926301717758179, 0.46875107288360596, 0.12301556766033173, 0.10369668155908585, 0.832214891910553, -0.2129031866788864, -0.8479223847389221, -0.6230509877204895, -0.5311834216117859, 0.5890179872512817, 0.6826478242874146, -0.03126147389411926, -0.4533052146434784, 0.2169816792011261, -0.12628811597824097, 0.26231497526168823, -0.5920686721801758, 0.6414342522621155, -0.75086909532547, -0.48674115538597107, 0.3392225503921509, 0.3219105303287506, -0.16305552423000336, -0.2839169502258301, -0.2208186686038971, -0.9701666831970215, 0.09345206618309021, 0.08397826552391052, 1.3385733366012573, -0.7608504295349121, -0.6949247121810913, 0.06646312773227692, -0.2146100550889969, -0.18300840258598328, -0.9310212731361389, 0.6792128682136536, -0.10816555470228195, 0.6563042402267456, 0.01253940723836422, -1.0881595611572266, 0.20485690236091614, -0.612984836101532, -0.4646129906177521, -0.07587619125843048, -0.09315665066242218, 0.7752803564071655, -0.6553725004196167, 0.37652841210365295, -0.4213940501213074, 0.45494890213012695, -0.9781749248504639, 1.1117665767669678, -0.5642940998077393, 0.4475364089012146, -0.20822128653526306, -0.28506147861480713, 0.20535363256931305, -0.643742024898529, 0.3795391917228699, -0.20386336743831635, 0.24452659487724304, 0.17715172469615936, -0.45542284846305847, 1.4859660863876343, -0.7850556969642639, 0.4172559082508087, -0.039435166865587234, -0.053606390953063965, -0.07410487532615662, 0.05868279188871384, -0.19674603641033173, -0.4316096305847168, 0.4065174162387848, 0.6515092253684998, -0.6560754179954529, 0.29794615507125854, 0.7238117456436157, 0.7093223333358765, -0.37861090898513794, 0.3201458156108856, 0.5294442772865295, -0.3568471670150757, 0.6059662699699402, 0.25491541624069214, 0.4314427077770233, 0.4495130479335785, 0.8427676558494568, -0.257805734872818, 0.5882440805435181, -0.9991803169250488, -0.26543018221855164, 0.7589141130447388, 0.8463486433029175, 0.6442095637321472, -0.06831516325473785, -0.7029669880867004, -0.5547308921813965, -0.05356872081756592, 0.5667592883110046, 2.2710554599761963, -0.16231822967529297, 0.03752923756837845, -0.7658984065055847, -0.2207135111093521, -0.23297615349292755, -0.015647733584046364, -0.41958552598953247, 0.13319054245948792, -0.64339679479599, -1.289962887763977, 0.5434472560882568, -0.10290202498435974, 0.7132425904273987, -0.13608747720718384, -0.03259045258164406, -0.2528609335422516, 0.4605560600757599, -0.6624376177787781, -1.1637532711029053, 0.5042128562927246, -0.6278861165046692, -0.13753952085971832, 0.09922074526548386, -0.013906002044677734, -0.09029998630285263, -0.6806780695915222, 1.0391569137573242, 0.1028003841638565, -0.004093983210623264, 0.13498876988887787, 0.25801384449005127, -0.7020339369773865, -1.1220357418060303, 0.8654710054397583, 0.788746178150177, -0.2565217912197113, 0.02433529496192932, 0.46419504284858704, 0.08354038000106812, 0.2760966718196869, -0.511524498462677, 0.12359295040369034, 0.3067907691001892, -0.008769068866968155, 0.5581487417221069, 0.013461473397910595, 0.6632739305496216, -1.2121880054473877, 1.5503156185150146, 0.30747824907302856, -0.5629426836967468, 0.6313563585281372, -1.0550919771194458, -0.14727003872394562, 0.3878486156463623, -1.060586929321289, -0.19357216358184814, -0.9774391651153564, 0.17518840730190277, 0.009148618206381798, -0.019009152427315712, -0.20631375908851624, 0.3926081955432892, -0.23379909992218018, 0.6135194897651672, 0.3196541666984558, 0.1933121532201767, -0.535312294960022, 0.26850736141204834, -0.4124581217765808, 0.2843445837497711, 0.28774434328079224, 0.3699110746383667, -0.2154684215784073, -0.29311686754226685, -0.5472241640090942, -0.5832484364509583, -0.2531350553035736, -0.5699739456176758, 0.2229127436876297, -0.1136665791273117, -0.7403193116188049, -0.6940479278564453, -0.3746528625488281, -0.42637643218040466, -0.3458566963672638, 0.291421502828598, 0.11220476776361465, -0.38033580780029297, -1.2495101690292358, -1.4245319366455078, -0.4080732464790344, -0.9027602076530457, -0.8646575212478638, 0.24655716121196747, 0.28840315341949463, -0.48198404908180237, -0.5932103991508484, -0.06420725584030151, -0.3989783525466919, 1.1977866888046265, -1.302222728729248, 1.064428448677063, -0.24402403831481934, 0.1803029626607895, -0.302361398935318, 0.02452738955616951, 0.3473929762840271, -0.1652233749628067, 0.08350321650505066, -0.956403911113739, -0.31799957156181335, -0.33169227838516235, -0.32277095317840576, 0.21019494533538818, 0.43206727504730225, 0.808760941028595, 0.2528541386127472, -0.43718215823173523, 0.6755831837654114, 1.480662226676941, -0.9274194240570068, -0.45027658343315125, 0.26642608642578125, 0.874125599861145, 0.05253015458583832, -0.038251299411058426, 0.6978742480278015, 0.13881416618824005, 0.5042632818222046, -0.2255288064479828, -0.10362684726715088, -0.223305806517601, -0.726101815700531, 0.22881700098514557, 1.670502781867981, 0.3105062246322632, -0.4157852530479431, -0.6919640302658081, 0.06160818785429001, -1.1269100904464722, -0.23481911420822144, 1.0159467458724976, 1.0873571634292603, 0.5051284432411194, -0.04465651884675026, -0.28060656785964966, -0.30261507630348206, 0.19345615804195404, 0.2136293351650238, -0.5370962619781494, -0.5646184682846069, -0.004374829586595297, -0.1550135463476181, 0.46488094329833984, 0.606515109539032, -0.5739083290100098, 0.6649358868598938, 14.86369514465332, 1.6289076805114746, 0.0758390799164772, 0.8926129341125488, 0.7396930456161499, 0.08989792317152023, -0.3614228665828705, -0.48773643374443054, -1.399895429611206, 0.11808586865663528, 1.0904104709625244, 0.037547558546066284, 1.446015477180481, -0.2266656756401062, 0.33346158266067505, 0.06813410669565201, -0.3036458492279053, 0.6951839327812195, 0.43828046321868896, -1.201432466506958, 0.5034244060516357, 0.1006893590092659, 0.809149444103241, 0.8725771307945251, 0.4452592432498932, 0.9840535521507263, 0.30978983640670776, -0.5539495348930359, 0.383926659822464, -0.12470881640911102, 1.3522926568984985, -0.1970636546611786, 0.17351387441158295, 0.9132803082466125, -0.683957040309906, -0.3940531313419342, -0.6043955087661743, -0.9362719655036926, 0.10706068575382233, 0.17358718812465668, -0.37662267684936523, -0.6192293167114258, -0.2110859453678131, 0.029260270297527313, -0.18956653773784637, 0.20825672149658203, -0.007413545157760382, 0.7247803211212158, -0.27968689799308777, 0.0844651386141777, -0.02430976927280426, 0.5216622352600098, 0.2596147954463959, -0.13389946520328522, 0.03809388726949692, -0.1637926697731018, 0.20727038383483887, -0.007873058319091797, -1.0415188074111938, 0.2614944875240326, 0.3585859537124634, -0.26902127265930176, 0.13367106020450592, 0.7151356935501099, 0.46576470136642456, 0.33481892943382263, -0.1769169569015503, 0.3060202896595001, 0.6568806171417236, 0.344138503074646, -0.21236009895801544, 0.28571775555610657, 0.39912745356559753, -0.30809247493743896, -0.589731752872467, 0.3636201024055481, -0.3127140998840332, -0.7138909697532654, -0.9121028184890747, -0.605286717414856, 0.2172955572605133, -0.6092274785041809, -1.1559315919876099, 0.9236437678337097, -0.19309380650520325, -0.4907703399658203, 0.5034085512161255, -0.36935973167419434, 0.08972223848104477, 0.5431166887283325, -1.3093727827072144, -0.655602753162384, 0.6356122493743896, -0.6850079298019409, -0.029334664344787598, -0.48556530475616455, 0.9909366369247437, 0.2865091860294342, -0.316554993391037, 0.47219163179397583, 0.5016515254974365, -0.49996283650398254, 0.2444286346435547, -0.49630632996559143, 0.9549790620803833, -0.19694916903972626, -0.2330680936574936, 0.358119398355484, 0.18726547062397003, 0.2653124928474426, -0.7383133172988892, 0.1671360582113266, 0.6143295764923096, -0.8218397498130798, -0.03524297848343849, -0.5952703356742859, -0.5900021195411682, -0.09759602695703506, 0.32114627957344055, -0.2947145998477936, 0.22852261364459991, 0.07940767705440521, -0.4717494547367096, 0.006876123603433371, -0.8518005013465881, -0.08915191143751144, 0.7317516803741455, -0.6986663937568665, -0.011693130247294903, 0.07828469574451447, 0.5417401194572449, -1.2035280466079712, -0.5684779286384583, 0.07085688412189484, -0.111961230635643, 0.3648829758167267, 0.7304202914237976, -0.7155193090438843, 0.21095891296863556, 0.8110114932060242, -0.44694700837135315, -1.018582820892334, 0.045441098511219025, -0.859541654586792, 0.23742160201072693, 0.003421215107664466, 0.6795168519020081, -0.38026779890060425, 0.23841892182826996, 0.6557069420814514, 0.8716192841529846, -0.55336993932724, -0.42975321412086487, -0.2633436322212219, 0.10753487050533295, -0.5802199840545654, 0.6021633148193359, -0.20997755229473114, -0.44307446479797363, 0.27992862462997437, 0.16599039733409882, 0.8369218707084656, -0.20833417773246765, -0.6046236753463745, 0.33358004689216614, -0.13407154381275177, -0.47068142890930176, -0.594695508480072, 0.13094232976436615, -1.7095773220062256, -0.05430030822753906, -0.9756504893302917, -0.04444500431418419, -0.5050182938575745, -0.2676859200000763, -0.35167360305786133, -0.051582638174295425, -0.5036361217498779, 0.35373857617378235, -0.14705106616020203, -0.12296218425035477, -0.012735464610159397, -0.37086281180381775, 0.7897987961769104, 0.9261372089385986, -0.6621904373168945, -0.2842501103878021, 0.36350756883621216, 0.024286536499857903, 0.6238740086555481, 0.7292503714561462, -0.4856729507446289, -0.9355027079582214, -1.3161396980285645, 0.7325540781021118, -0.1656031459569931, -0.4878656566143036, -0.3547673225402832, 0.6210546493530273, -0.2595963478088379, 0.021771561354398727, 0.6126671433448792, 0.3420390784740448, -0.8584126234054565, -0.5428587794303894, 0.11310852319002151, -1.0104578733444214, 0.28994959592819214, 0.04601767286658287, -0.4423031806945801, -0.03592029586434364, 0.35783758759498596, 0.0327606201171875, -0.6624768972396851, -0.48027607798576355, 0.4713915288448334, -0.09237192571163177, 0.5450012683868408, -0.5535447001457214, 0.43613201379776, -0.9694714546203613, -0.4272317588329315, -0.20310822129249573, 0.42244401574134827, -0.18055208027362823, 1.1980961561203003, -0.10156667232513428, -1.2505627870559692, -0.036995384842157364, 0.45333653688430786, -0.1524020880460739, -0.29550427198410034, 0.49445611238479614, 0.32628223299980164, -0.42452573776245117, 0.596703827381134, 0.650313675403595, 0.48410382866859436, -0.9924967288970947, -0.2319757491350174, 0.8719207048416138, -0.5379987359046936, 0.11112543195486069, 1.3506594896316528, -0.33605921268463135, -1.376880168914795, 0.16902339458465576, -0.8174973726272583, -0.3904706835746765, -0.4055827856063843, 0.7272666692733765, 0.3000359535217285, 0.036734577268362045, 0.030821753665804863, -0.4722990095615387, 0.46740272641181946, 0.18788981437683105, -0.36765000224113464, 0.34097468852996826, -1.053422212600708, -0.17735043168067932, 0.7094033360481262, 0.8725020885467529, -0.32888495922088623, -0.8960291743278503, -0.6439914703369141, -0.12237133085727692, -0.11163481324911118, 0.1444033831357956, -0.635549008846283, -0.5102940201759338, 0.4017476439476013, 0.6707746386528015, 0.021415257826447487, 0.16431653499603271, -0.09863019734621048, -0.18496538698673248, 0.5798823833465576, 0.5664825439453125, -0.8409754037857056, -0.7975048422813416, 0.9536054730415344, 1.3780348300933838, -1.5077824592590332, 0.5948807597160339, 0.08763383328914642, -0.8663981556892395, 0.9018025994300842, 0.5441436171531677, -0.0010264714946970344, 1.073204517364502, -0.2382740080356598, 0.262203574180603, 0.27848944067955017, -1.224076747894287, -0.15315751731395721, 1.265650749206543, 0.44083109498023987, 0.8180665969848633, 0.6504120826721191, -0.25905781984329224, 0.7593719363212585, -0.16126328706741333, 0.2790248394012451, 0.3812125027179718, 0.07682166993618011, -0.3577251434326172, -0.11102467775344849, 0.06335218995809555, 0.9359647631645203, -0.6335826516151428, -0.3336500823497772, 0.364204466342926, 0.4786088466644287, 0.2676527798175812, 0.5601097941398621, 0.5067857503890991, -0.2957485318183899, 0.42319947481155396, -0.16247273981571198, 0.6105110049247742, -0.5431020855903625, -0.3878867030143738, 0.07192867994308472, -0.590116024017334, 0.08431991189718246, -0.0011076930677518249, -0.09431133419275284, -0.5421711802482605, -0.2846348285675049, 0.08604522794485092, -0.0909750685095787, 0.49196580052375793, 1.090091586112976, 0.41006702184677124, 0.30116480588912964, -0.050386086106300354, -0.7774227261543274, -1.0812069177627563, -1.0400683879852295, -0.12163306027650833, -0.7361950874328613, -0.1407541036605835, -0.0868917778134346, -0.2644405663013458, -0.6539787650108337]}, "authors": [{"authorId": "2257447835", "name": "Haowei Lin"}, {"authorId": "2184278672", "name": "Baizhou Huang"}, {"authorId": "2284300618", "name": "Haotian Ye"}, {"authorId": "2273830934", "name": "Qinyu Chen"}, {"authorId": "47196237", "name": "Zihao Wang"}, {"authorId": "2257095534", "name": "Sujian Li"}, {"authorId": "2257367982", "name": "Jianzhu Ma"}, {"authorId": "2257016300", "name": "Xiaojun Wan"}, {"authorId": "2283249105", "name": "James Zou"}, {"authorId": "2257367774", "name": "Yitao Liang"}], "references": [{"paperId": "e61fde1309a9f5aab2060ace6f709711823c9ca5", "title": "Understanding Emergent Abilities of Language Models from the Loss Perspective"}, {"paperId": "5e71d0e85f65a1c0fb2af7bff281209122c58932", "title": "When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method"}, {"paperId": "7260442ef9c0448f07ce3803efd49cebaffcebe9", "title": "DeepSeek LLM: Scaling Open-Source Language Models with Longtermism"}, {"paperId": "9b093787f9be3d480cd11f8ec6ca5b0e44050d6d", "title": "Solving olympiad geometry without human demonstrations"}, {"paperId": "d32ba88571141ed0ebe7aeefbaa4ccaf8cda7be3", "title": "Mathematical discoveries from program search with large language models"}, {"paperId": "c6c9f36a1e0b7ffd2515be684e63aea2e7db7206", "title": "How to Determine the Most Powerful Pre-trained Language Model without Brute Force Fine-tuning? An Empirical Survey"}, {"paperId": "44f549034b950aecd78da08ea2137aba7096f817", "title": "Class Incremental Learning via Likelihood Ratio Based Task Prediction"}, {"paperId": "9b98ca94b7733feee1cff5c57596611ad35fa7aa", "title": "Scaling Laws for Sparsely-Connected Foundation Models"}, {"paperId": "e26888285436bc7998e5c95102a9beb60144be5e", "title": "Textbooks Are All You Need II: phi-1.5 technical report"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "bb2806625aa469af034727c4df71c33c9746ec85", "title": "Model Spider: Learning to Rank Pre-Trained Models Efficiently"}, {"paperId": "84725e8442f2ea59702b324471d4c7ca1b1d0b9f", "title": "Guided Recommendation for Model Fine-Tuning"}, {"paperId": "0d1c76d45afa012ded7ab741194baf142117c495", "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"}, {"paperId": "9e16d8cc6096ec0d2733a4ecf41ce09d9a4bd19c", "title": "Scaling Data-Constrained Language Models"}, {"paperId": "389ec3e8902a5dcfcde1adec735854e93f845937", "title": "LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions"}, {"paperId": "ece77610adfb0fb162dd22ef694f2777393c319a", "title": "Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster"}, {"paperId": "7af28fd91d91441ebbd029c002cb58d7de286210", "title": "Scaling Laws for Multilingual Neural Machine Translation"}, {"paperId": "e3ec55e9e6720194a0ed5d4033d93a941c8a4f99", "title": "Continual Pre-training of Language Models"}, {"paperId": "f2b0017ddd77fa38760a18145e63553105a1a236", "title": "The Flan Collection: Designing Data and Methods for Effective Instruction Tuning"}, {"paperId": "e3f839b01567ae73af822a3da5e160dac2fb4708", "title": "Adapting a Language Model While Preserving its General Knowledge"}, {"paperId": "468992bf970c37bd1fef58b78a6c2fcd8c018868", "title": "Scaling Laws for Generative Mixed-Modal Language Models"}, {"paperId": "6052486bc9144dc1730c12bf35323af3792a1fd0", "title": "Large language models encode clinical knowledge"}, {"paperId": "fb9f9e98d35340875905730e1a80221fec818944", "title": "Revisiting Neural Scaling Laws in Language and Vision"}, {"paperId": "20de79ec4fe682b68930eb4dcd91b1801b8d4731", "title": "Towards Understanding Grokking: An Effective Theory of Representation Learning"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "4fa282f35dacd5f390c5001af964adea9f44bb8b", "title": "Transferability Estimation using Bhattacharyya Class Separability"}, {"paperId": "0bf1e3ee521c5c5ea3a91819273b7574561f246b", "title": "Newer is not always better: Rethinking transferability metrics, their peculiarities, stability and performance"}, {"paperId": "2d4f66046bb436864cd6bf589e3a931c405f9f44", "title": "Scale Efficiently: Insights from Pre-training and Fine-tuning Transformers"}, {"paperId": "de1fdaf92488f2f33ddc0272628c8543778d0da9", "title": "Scaling Laws for Neural Machine Translation"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "60571e69c2263094478efba76cc8f26f9ad84852", "title": "Towards a Theoretical Framework of Out-of-Distribution Generalization"}, {"paperId": "6b2b5d3d9a2ca4bc4fbd81551a62370be2fbff1b", "title": "Explaining neural scaling laws"}, {"paperId": "4383a975c09b72ba2f1a77cd779bb6965dbfb2fb", "title": "Scaling Laws for Transfer"}, {"paperId": "38e7fbb3b64405e0a44148cb233869905bcce92e", "title": "A linearized framework and a new benchmark for model selection for fine-tuning"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "3efbcfeeb0ea1051a71101d3318da4411081f0b8", "title": "Scaling Laws for Autoregressive Generative Modeling"}, {"paperId": "74276a37bfa50f90dfae37f767b2b67784bd402a", "title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"}, {"paperId": null, "title": "Transformers: State-of-the-Art Natural Language Processing"}, {"paperId": "4f0c88950f7fa1cf50810b73e749d8855fd3e4f0", "title": "Duality Diagram Similarity: a generic framework for initialization selection in task transfer learning"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "d1206ccabd1980848f14472d6548251c2fab7963", "title": "Exploring and Predicting Transferability across NLP Tasks"}, {"paperId": "43f5124d50b5b148c71cb2e56970e4a386be055a", "title": "LEEP: A New Measure to Evaluate Transferability of Learned Representations"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "6ebfbc954b9975d2f2651f380b9bdf46ae963178", "title": "PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable"}, {"paperId": "d28c18a3c2a0afdc0a8634d18345af8d36e1f948", "title": "A Constructive Prediction of the Generalization Error Across Scales"}, {"paperId": "41db7308930ea8bf2fbefcab41294fac6f929721", "title": "Transferability and Hardness of Supervised Classification Tasks"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "854eca61a57d2c1ea1019663caf022bc8fd0b909", "title": "SciPy 1.0: fundamental algorithms for scientific computing in Python"}, {"paperId": "68e686817f2c33cd09ba3805fa082348f18affd9", "title": "Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction"}, {"paperId": "89c3355f5bc7130ae4ed090c8accc52dd885d558", "title": "Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "b36a5bb1707bb9c70025294b3a310138aae8327a", "title": "Automatic differentiation in PyTorch"}, {"paperId": "5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd", "title": "Deep Reinforcement Learning from Human Preferences"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "4aa9f5150b46320f534de4747a2dd0cd7f3fe292", "title": "Semi-supervised Sequence Learning"}, {"paperId": "1ac30af5522c7a50ec4d1ee43fd2bd8652a9bd52", "title": "A Neural Attention Model for Abstractive Sentence Summarization"}, {"paperId": "6471fd1cbc081fb3b7b5b14d6ab9eaaba02b5c17", "title": "Generating Sequences With Recurrent Neural Networks"}, {"paperId": "29c7f009df21d0112c48dec254ff80cc45fac3af", "title": "Are Emergent Abilities of Large Language Models a Mirage?"}, {"paperId": "8d188daf721fde8de4877718e96f89ae9d7a1925", "title": "Findings of the 2022 Conference on Machine Translation (WMT22)"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Acl 2019 fourth conference on machine translation (wmt19), shared task: Machine"}, {"paperId": null, "title": "English gigaword"}, {"paperId": null, "title": "Selecting Large Language Model to Fine-tune via Rectified Scaling Law"}, {"paperId": null, "title": "Hardware and Software run most of the experiments on clusters using NVIDIA A100s. We implemented our experiments using PyTorch"}, {"paperId": null, "title": "Gemini: a family of highly capable multimodal models"}]}