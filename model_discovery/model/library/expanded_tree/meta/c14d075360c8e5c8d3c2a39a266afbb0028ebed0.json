{"paperId": "c14d075360c8e5c8d3c2a39a266afbb0028ebed0", "abstract": "Layer normalization (LN) is a ubiquitous technique in deep learning but our theoretical understanding to it remains elusive. This paper investigates a new theoretical direction for LN, regarding to its nonlinearity and representation capacity. We investigate the representation capacity of a network with layerwise composition of linear and LN transformations, referred to as LN-Net. We theoretically show that, given $m$ samples with any label assignment, an LN-Net with only 3 neurons in each layer and $O(m)$ LN layers can correctly classify them. We further show the lower bound of the VC dimension of an LN-Net. The nonlinearity of LN can be amplified by group partition, which is also theoretically demonstrated with mild assumption and empirically supported by our experiments. Based on our analyses, we consider to design neural architecture by exploiting and amplifying the nonlinearity of LN, and the effectiveness is supported by our experiments.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper investigates the representation capacity of a network with layerwise composition of linear and LN transformations, referred to as LN-Net, and theoretically shows the lower bound of the VC dimension of an LN-Net."}, "embedding": {"model": "specter_v2", "vector": [0.14872050285339355, 0.6869677305221558, -0.6173280477523804, -0.3961903154850006, 0.08488136529922485, 0.04274563863873482, 0.6020987033843994, -0.3909599483013153, -0.5418897271156311, -0.11042636632919312, 0.5012019276618958, 0.40584298968315125, 0.37882623076438904, 0.02381005324423313, -0.23522841930389404, -0.2921910881996155, -0.9289081692695618, -0.08981091529130936, -0.07770568877458572, -0.10675196349620819, -0.08483123034238815, -0.29460060596466064, -0.9763129949569702, 0.443244069814682, -0.10356103628873825, 1.2472798824310303, -0.10237982124090195, 0.7594113945960999, -0.6142489314079285, 0.7125577330589294, 0.5408108830451965, -0.19525004923343658, 1.0116204023361206, -0.14988908171653748, -0.11389611661434174, 0.15420375764369965, 0.628819465637207, -0.4855639636516571, -0.6342689990997314, 1.0193634033203125, -0.2921244204044342, 0.6232645511627197, 0.5857849717140198, -0.9942810535430908, 0.027895115315914154, 0.6552907228469849, 0.37235027551651, 0.4774000644683838, -0.9468865990638733, -0.5590400695800781, 0.9104324579238892, -0.9346293807029724, -0.06992674618959427, 1.4256876707077026, 0.6094892024993896, 0.6078428626060486, -0.19186760485172272, -1.215787649154663, 0.7108703851699829, -0.16043949127197266, -0.8192134499549866, -0.09211269021034241, 0.31875184178352356, -0.3193798065185547, 1.180528163909912, -0.45361021161079407, -0.5761913657188416, 0.1317356377840042, -0.2588152289390564, 1.1533148288726807, 0.38917356729507446, -0.6704984903335571, 0.08137940615415573, 0.47674548625946045, 0.5518134236335754, 0.8237945437431335, 0.16795814037322998, 0.004162038676440716, -1.2168903350830078, 0.06613251566886902, 0.655867338180542, 0.1274481564760208, 0.19740813970565796, -0.4583374559879303, -0.05737372115254402, 0.880267858505249, 0.8673550486564636, 0.20122294127941132, -0.18232615292072296, 1.1642096042633057, 0.47022876143455505, 0.20413188636302948, 0.12497956305742264, 0.45095938444137573, 0.24910777807235718, 1.4060841798782349, -0.5016787052154541, -0.1394822597503662, -0.31704071164131165, 0.737813413143158, 0.1451539844274521, 0.1708783060312271, -0.3202330470085144, 0.1766836941242218, 1.287272572517395, -0.292977511882782, 0.6367255449295044, -0.7273519039154053, 0.46983781456947327, -0.2786230146884918, -0.37705251574516296, -0.6291548609733582, -0.2568202614784241, -0.5913293361663818, -1.4297813177108765, -0.340270459651947, -0.6920918822288513, 0.21835969388484955, -1.0236444473266602, 0.7375292181968689, -0.589855968952179, -0.00768341263756156, -0.01242567878216505, 0.5550781488418579, -0.08038139343261719, 0.5853398442268372, 0.2531092166900635, 0.10297319293022156, 0.8356037139892578, -1.065571665763855, -0.854950487613678, -0.5210956931114197, 0.550288736820221, -0.1895817071199417, 0.07403954863548279, -0.15819942951202393, -0.844094455242157, -1.2253718376159668, -1.3750431537628174, 0.11086643487215042, -0.6574450731277466, 0.3536868989467621, 1.2245030403137207, 0.4960457682609558, -0.8644730448722839, 0.9978288412094116, -0.3383265435695648, -0.1654912680387497, 0.8492709994316101, 0.775175929069519, -0.07703588902950287, -0.25837865471839905, -0.6302204728126526, 0.43363022804260254, 0.7606157660484314, -0.5733481645584106, 0.2022358924150467, -0.3828338384628296, -0.860746443271637, 0.08140911906957626, 0.18625977635383606, -0.8044387102127075, 0.9530606269836426, -0.36597511172294617, -1.1021161079406738, 0.5458239912986755, -0.06175507605075836, -0.09211604297161102, 0.5145551562309265, 0.12244978547096252, -0.5289265513420105, -0.4943445324897766, -0.43998023867607117, 0.6710860133171082, 0.2497013658285141, -0.5893281102180481, -0.3918001055717468, 0.2912062704563141, -0.40189680457115173, -0.2103695124387741, -0.8442276120185852, 0.7469218373298645, 0.09693669527769089, -0.3259602189064026, 1.0790585279464722, 0.7935982346534729, -0.08405109494924545, 0.2884495258331299, -0.44240400195121765, -0.9394931793212891, 0.6003802418708801, 0.5210016369819641, 0.7015921473503113, -0.91315096616745, -1.2405787706375122, 0.20755337178707123, 0.3204439580440521, -0.1538708359003067, -0.7785845994949341, 0.15309475362300873, -0.47366422414779663, 0.6812139749526978, -0.27404701709747314, -1.3416448831558228, 0.0776023119688034, -0.12021888792514801, -0.6415010094642639, 0.15933774411678314, 0.2945179343223572, 0.9165818691253662, -0.4838065505027771, 0.40092745423316956, -0.010069492273032665, -0.1139601618051529, -0.9191737771034241, 0.9704811573028564, -0.011820483952760696, -0.3021257519721985, 0.32502228021621704, -0.2803109884262085, 0.6584643721580505, -0.3951619565486908, 0.2714070975780487, -0.48316314816474915, 0.2654760777950287, 0.6886429786682129, -1.1256288290023804, 1.004899501800537, 0.383347749710083, 0.9800055623054504, -0.1910611093044281, -1.0737799406051636, 0.23528216779232025, 0.2051948755979538, -0.004727017134428024, -0.025890400633215904, 0.5372243523597717, 0.17626339197158813, -0.49982723593711853, 0.4031847417354584, 0.5551578998565674, 0.6674566268920898, -0.3103606104850769, 0.3831544518470764, 0.847406268119812, 0.04647893086075783, 0.09393968433141708, -0.10777588188648224, 0.13814596831798553, -0.1877090334892273, 0.4283916652202606, -0.24277828633785248, 0.1541675329208374, -1.0211023092269897, -0.11338935047388077, 0.6111392974853516, 0.49383822083473206, 0.9857184290885925, 0.31815657019615173, -0.8607865571975708, -0.4610218405723572, -0.2709638178348541, 0.7209364175796509, 1.40109384059906, -0.036766208708286285, -0.1404927372932434, -0.5703557133674622, -0.36054953932762146, -0.20236560702323914, -0.44246819615364075, -0.49256524443626404, -0.2992294728755951, -0.6536863446235657, -1.3694084882736206, 1.0103182792663574, 0.3353939950466156, 1.3876415491104126, -0.13613469898700714, 0.2014504075050354, -0.5726147890090942, 0.4376060962677002, -0.9022451043128967, -0.41865020990371704, 0.34082457423210144, -0.6632094383239746, -0.13586148619651794, 0.07172784209251404, -0.3003620207309723, 0.6288628578186035, -0.7410976886749268, 0.23797501623630524, -0.6808665990829468, 0.23449893295764923, -0.3212054967880249, 0.9797411561012268, -0.7466657161712646, -0.41319459676742554, 0.1474023461341858, 0.4704132676124573, 0.31596389412879944, 0.36903050541877747, 0.38110464811325073, 0.08043230324983597, 0.1239052563905716, -0.4966876804828644, 0.2760164737701416, 0.11883293092250824, -0.18607544898986816, 0.6839088797569275, -0.06706320494413376, 0.14225369691848755, -1.1411951780319214, 0.9791330099105835, 0.19286145269870758, -0.32580259442329407, 0.11773678660392761, -0.6467105746269226, 0.06007063016295433, 0.21736861765384674, -0.9713655710220337, 0.22300297021865845, -0.7014274001121521, 0.6511673927307129, -0.3874063491821289, -0.10424041748046875, -0.08618593215942383, 0.4424211084842682, -0.4069773554801941, 0.6603298783302307, 0.012908531352877617, 0.4528963267803192, -0.1596120148897171, 0.4295685589313507, -0.6506889462471008, 0.9456424117088318, 0.3829888105392456, 0.2670518457889557, 0.10874111950397491, 0.09278186410665512, -0.1747991442680359, -0.29558905959129333, -0.4160621166229248, -0.2614176273345947, -0.009133412502706051, 0.10340535640716553, -0.5631023645401001, -0.8748735189437866, 0.1339481621980667, -0.5414975881576538, 0.029543431475758553, -0.22415520250797272, 0.40220174193382263, -0.19218267500400543, -1.2713145017623901, -1.1101630926132202, -0.7109132409095764, -0.16993406414985657, -0.8427894115447998, -0.4281845688819885, 0.16826781630516052, 0.032591648399829865, -0.1196138858795166, -0.9459328055381775, -0.5072528123855591, 1.0767931938171387, -0.029834982007741928, 0.8956077694892883, -0.5490778088569641, -0.4535834789276123, -0.3988351821899414, -0.034216176718473434, 1.0769633054733276, -0.022700032219290733, 0.07205281406641006, -1.1530970335006714, 0.33971425890922546, 0.20537234842777252, -0.30193668603897095, 0.5453944206237793, 0.3296476900577545, 1.0726916790008545, -0.25169748067855835, -0.24195609986782074, 0.7380334138870239, 1.4364073276519775, -0.9164333939552307, -0.17145667970180511, 0.139878511428833, 1.1897393465042114, 0.6085940003395081, -0.7694082260131836, 0.11377164721488953, 0.05643089860677719, -0.13218873739242554, 0.2939130663871765, -0.4343520700931549, -0.5245680809020996, -0.43941134214401245, 0.0811806172132492, 1.5191302299499512, 0.4219259023666382, -0.2510512173175812, -0.6440702676773071, 0.10314866900444031, -1.2239261865615845, -0.6020414233207703, 0.7540085911750793, 0.6913392543792725, 0.004034634213894606, -0.12010271102190018, -0.2960917055606842, 0.4281097650527954, 0.9119393229484558, 0.2673594057559967, -0.15175741910934448, -0.44155871868133545, -0.21352694928646088, 0.19192348420619965, 0.9283166527748108, 0.5682468414306641, -0.5693618059158325, 0.3179105222225189, 14.876662254333496, 0.5517303347587585, -0.36788901686668396, 0.5736837387084961, 1.00157630443573, 0.12354522198438644, -0.10319400578737259, -0.4980863332748413, -1.365477204322815, 0.33399465680122375, 0.565742552280426, 0.3512977659702301, 0.6781103610992432, 0.21476557850837708, -0.42557257413864136, 0.20998965203762054, -0.5455257892608643, 1.0033282041549683, 0.7886006236076355, -1.5659633874893188, 0.32607877254486084, 0.3271956443786621, 1.010056972503662, 0.5357578992843628, 0.6558788418769836, 0.676044762134552, 0.1300952136516571, -0.5463099479675293, 0.2202957272529602, 0.14277081191539764, 0.7621021866798401, -0.26408445835113525, 0.7172251343727112, 0.7036082148551941, -0.708122193813324, -0.006258934270590544, -0.8132864832878113, -1.398068904876709, -0.10243411362171173, 0.18430054187774658, -0.6475977897644043, -0.5138488411903381, -0.4168710708618164, 0.34769031405448914, 0.10077798366546631, 0.6307786107063293, -0.43027976155281067, 0.4246373176574707, -0.6381946802139282, 0.18617166578769684, 0.15535354614257812, 0.8130407929420471, -0.09902354329824448, -0.1133214607834816, -0.05463056266307831, -0.0016897849272936583, 0.5262411832809448, 0.331997811794281, -1.212613582611084, -0.12987658381462097, 0.11792098730802536, -0.20083560049533844, -0.09342685341835022, 0.8774701952934265, 0.3219532072544098, -0.04781810939311981, 0.3545211851596832, 0.005559178534895182, 0.4524323642253876, 0.4023985266685486, -0.05651623755693436, -0.17278237640857697, 0.7510436177253723, -0.36792516708374023, -0.38728398084640503, 0.5851566791534424, -1.1588422060012817, -0.4221073091030121, -0.4361831247806549, 0.14521020650863647, 0.3307880461215973, -0.6205019950866699, -1.0171101093292236, 0.7523654699325562, -0.08918657153844833, -0.35544121265411377, 0.48409876227378845, -1.1622196435928345, -0.31959882378578186, 0.6351755261421204, -1.5175371170043945, -0.5884228944778442, -0.16975659132003784, -0.3734035789966583, -0.6333695650100708, -0.4368579685688019, 0.8034154772758484, 0.2493826001882553, -0.3529658019542694, 0.4586591422557831, -0.288670152425766, 0.01960652880370617, -0.04438301548361778, -0.6033711433410645, 0.5057961344718933, 0.5833818316459656, -0.3972139060497284, 0.2433740794658661, -0.40685880184173584, 0.538806140422821, 0.3069634735584259, -0.20826511085033417, 0.5666449666023254, -0.39230793714523315, -0.6004018783569336, -0.9731009602546692, -1.0425350666046143, 0.4210440516471863, 0.26674342155456543, 0.11363828927278519, 0.5116864442825317, 0.02110656350851059, -0.5374599695205688, -0.3315543234348297, -0.8849130868911743, -0.03615842014551163, 0.2948717772960663, -0.8761551976203918, -0.16455136239528656, -0.04786185547709465, 0.16777020692825317, -0.7888237237930298, -0.43183818459510803, 0.24245518445968628, -0.0929090678691864, 0.15980438888072968, 1.071668267250061, -0.7194036245346069, 0.5328715443611145, 0.21538865566253662, -0.4309174120426178, -0.37753504514694214, -0.3457237184047699, -0.7137326598167419, 0.26054057478904724, 0.2853107154369354, 0.17180147767066956, -0.8032385110855103, 0.6493120789527893, 0.5525885820388794, 0.09525228291749954, -0.3039240837097168, -0.5167639255523682, -0.17178496718406677, -0.19615909457206726, -0.5260030031204224, 0.4321039021015167, 0.3578994572162628, -0.5485790967941284, -0.3455162048339844, 0.4000929892063141, 0.6081058382987976, -0.028039496392011642, -0.9942932724952698, 0.3137966990470886, -0.2824784517288208, 0.12216000258922577, -1.1217292547225952, -0.881691575050354, -1.463291883468628, 0.059481728821992874, -1.561848759651184, -0.1466890275478363, -0.9467507600784302, -0.5833455324172974, 0.19652795791625977, -0.6939305663108826, 0.13448947668075562, 0.41636621952056885, 0.26968565583229065, 0.034978948533535004, -0.11998650431632996, -0.33700627088546753, 0.5043646693229675, 0.48479780554771423, -0.452044814825058, 0.007112222258001566, 0.20180393755435944, -0.14248423278331757, 0.6164554953575134, 0.733612060546875, -0.5748429298400879, -0.8607224225997925, -0.7985376119613647, 0.2807251811027527, -0.940767765045166, -0.32993918657302856, -1.113032579421997, 1.2102530002593994, 0.3841635584831238, 0.40639668703079224, -0.07990512996912003, 0.5804592370986938, -0.9120943546295166, -0.6703397035598755, 0.4086192548274994, -1.2791930437088013, -0.17120124399662018, -0.047695059329271317, -0.5446339249610901, -0.28047406673431396, 0.5168873071670532, 0.09099022299051285, -0.7136306166648865, -0.625887930393219, 0.4617476165294647, -0.3496609330177307, -0.19388559460639954, 0.05091121792793274, -0.2259245663881302, -1.5092158317565918, 0.08251968771219254, 0.1427011787891388, 0.5801699161529541, -0.4897320866584778, 0.575269341468811, -0.02337009459733963, -1.5998132228851318, 0.23909655213356018, 0.8944668173789978, -0.10427870601415634, 0.11259602755308151, 0.035965196788311005, 0.14377503097057343, -0.7546549439430237, 0.20647884905338287, -0.17424799501895905, 0.2664923071861267, -0.48160678148269653, -0.08233140408992767, 0.8361481428146362, -0.39508211612701416, 0.027576129883527756, 1.3785673379898071, 0.17119763791561127, -1.0626351833343506, 0.5805597901344299, -1.5085437297821045, -0.40888360142707825, -0.21695061028003693, 0.7603294849395752, 0.28921762108802795, -0.060799501836299896, 0.2620140314102173, -0.280494749546051, 0.06745754182338715, 0.19730110466480255, -0.37490251660346985, 0.30447617173194885, -0.09501383453607559, -0.2689952254295349, 0.8070719838142395, 1.1562668085098267, -1.1074843406677246, -0.9013885855674744, -0.8766270279884338, -0.12591767311096191, -0.28943932056427, -0.03571894392371178, -0.25292879343032837, -0.6034857034683228, 0.8023416996002197, 0.8006207942962646, 0.2604009807109833, 0.3648386299610138, -0.48242995142936707, -0.12394366413354874, 0.6659448146820068, -0.3039764165878296, -0.49942463636398315, -0.3795815408229828, 1.093583345413208, 0.9079421758651733, -0.8972039222717285, 0.45697182416915894, -0.6596721410751343, -0.5251252055168152, 1.0044066905975342, 0.466170072555542, -0.5281466245651245, 0.8532799482345581, -0.3520224690437317, -0.1467706561088562, 0.487346351146698, -0.8858602643013, -0.22192959487438202, 1.0696882009506226, 0.9013340473175049, 0.39202967286109924, 0.3544084131717682, 0.08512691408395767, 0.9448869824409485, -0.19567164778709412, -0.3570114076137543, 0.5974512696266174, 0.3395286202430725, -0.37567609548568726, 0.13164959847927094, -0.02502771094441414, 0.6319394707679749, -0.7939272522926331, 0.038703639060258865, 0.15996478497982025, 0.9310562014579773, 0.5797348618507385, 0.5227330923080444, 1.0101044178009033, -0.2599881589412689, 0.537446141242981, 0.31316879391670227, 0.23533426225185394, -0.5181742310523987, -0.41178977489471436, -0.19127459824085236, -0.9918959140777588, 0.029792359098792076, -0.27638864517211914, -0.042319346219301224, -0.4446225166320801, -0.579093337059021, 0.4242594242095947, -0.520973265171051, 0.887277364730835, 0.6350405812263489, 0.09546661376953125, 0.7303587794303894, 0.041664253920316696, -0.6126356720924377, -0.5671245455741882, -0.9387248158454895, -0.1496337503194809, -0.4160703420639038, 0.04632577672600746, -0.1654687225818634, -0.4699171483516693, -0.2806515395641327]}, "authors": [{"authorId": "2304445813", "name": "Yunhao Ni"}, {"authorId": "2305266373", "name": "Yuxin Guo"}, {"authorId": "2285453379", "name": "Junlong Jia"}, {"authorId": "2285207828", "name": "Lei Huang"}], "references": [{"paperId": "7470a1702c8c86e6f28d32cfa315381150102f5b", "title": "Segment Anything"}, {"paperId": "72ece269331ea69d6cb37063d469471595fa8bc1", "title": "Understanding the Generalization Benefit of Normalization Layers: Sharpness Reduction"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "658a017302d29e4acf4ca789cb5d9f27983717ff", "title": "Masked-attention Mask Transformer for Universal Image Segmentation"}, {"paperId": "cf5e6e3c50a798d87033e0e108e88b3647738bbe", "title": "How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers"}, {"paperId": "547f4c5180b14a13496e406335c912b4599d03fa", "title": "Beyond BatchNorm: Towards a Unified Understanding of Normalization in Deep Learning"}, {"paperId": "0bba261a58dcc42edd48bc9d9e5004c111210745", "title": "Proxy-Normalizing Activations to Match Batch Normalization while Removing Batch Dependence"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "41fc4acb579c347171f815c9ccea07bf88cd66f3", "title": "Group Whitening: Balancing Learning Efficiency and Representational Capacity"}, {"paperId": "f8c87389d78fc059f18bfc9d04b37614c19c3f91", "title": "Normalization Techniques in Training DNNs: Methodology, Analysis and Application"}, {"paperId": "f63405f53db3b1016f565f555fc8fa409f02fdbd", "title": "Minimum Width for Universal Approximation"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "40922d386116975853a743b1d810c1e0f03e886a", "title": "Understanding and Improving Layer Normalization"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "10eda4521c032adabaa8e70d6569e17370b29dcd", "title": "Root Mean Square Layer Normalization"}, {"paperId": "0417e7ca089195ccbf730109c637ef593ec94fa8", "title": "The Normalization Method for Alleviating Pathological Sharpness in Wide Neural Networks"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "409b9abbeecbc91d00187e73d441f556c8c6b598", "title": "An Investigation into Neural Net Optimization via Hessian Eigenvalue Density"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "253eba43d7e734ee6c5b00dca29be3c6c589f4a5", "title": "A Quantitative Analysis of the Effect of Batch Normalization on Gradient Descent"}, {"paperId": "3dfb0a18ab5a5413c50d911e49b3c83b1a9383a3", "title": "Theoretical Analysis of Auto Rate-Tuning by Batch Normalization"}, {"paperId": "ba618ec05a9dbef75310c5e4bcce8a559e0270b5", "title": "Three Mechanisms of Weight Decay Regularization"}, {"paperId": "9fa42ea422fe1729e04a98fa8072a7b48ce91bc8", "title": "Towards Understanding Regularization in Batch Normalization"}, {"paperId": "521ebc310afd88a2672f0af5f77dd4e6ec5c994f", "title": "Understanding Batch Normalization"}, {"paperId": "d08b35243edc5be07387a9ed218070b31e502901", "title": "Group Normalization"}, {"paperId": "48f0b0ab8ccdca861e374f26c3e54e1720cfb22e", "title": "Norm matters: efficient and accurate normalization schemes in deep networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "54ddb00fa691728944fd8becea90a373d21597cf", "title": "Understanding deep learning requires rethinking generalization"}, {"paperId": "63de0ad39d807f0c256f851428f211e8d5fcd3bb", "title": "Instance Normalization: The Missing Ingredient for Fast Stylization"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "78ccd68da3968689a2ed92fb00b1784f7ba2f3e7", "title": "Approximation by neural networks with a bounded number of nodes at each level"}, {"paperId": "4bdd1f845d26e488d67c0e4549cff17407b980ad", "title": "Lower bounds for approximation by MLP neural networks"}, {"paperId": "fe5e6b810957da9bc10b099b00fd64c221d97961", "title": "Almost Linear VC-Dimension Bounds for Piecewise Polynomial Networks"}, {"paperId": "f22f6972e66bdd2e769fa64b0df0a13063c0c101", "title": "Multilayer feedforward networks are universal approximators"}, {"paperId": null, "title": "An exponential learning rate schedule for batch normalized networks"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "How does batch normalization help optimization? In NeurIPS"}, {"paperId": "28a215515d10b0ccadef846c61894e2e8a4ff65a", "title": "Statistical Methods for Research Workers"}, {"paperId": null, "title": "Batch normalization provably avoids"}]}