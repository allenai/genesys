{"paperId": "6d68b5c1eaf03aba857476a9825acf3e48edd840", "abstract": "In-context learning (ICL) has emerged as a powerful paradigm leveraging LLMs for specific downstream tasks by utilizing labeled examples as demonstrations (demos) in the precondition prompts. Despite its promising performance, ICL suffers from instability with the choice and arrangement of examples. Additionally, crafted adversarial attacks pose a notable threat to the robustness of ICL. However, existing attacks are either easy to detect, rely on external models, or lack specificity towards ICL. This work introduces a novel transferable attack against ICL to address these issues, aiming to hijack LLMs to generate the target response or jailbreak. Our hijacking attack leverages a gradient-based prompt search method to learn and append imperceptible adversarial suffixes to the in-context demos without directly contaminating the user queries. Comprehensive experimental results across different generation and jailbreaking tasks highlight the effectiveness of our hijacking attack, resulting in distracted attention towards adversarial tokens and consequently leading to unwanted target outputs. We also propose a defense strategy against hijacking attacks through the use of extra clean demos, which enhances the robustness of LLMs during ICL. Broadly, this work reveals the significant security vulnerabilities of LLMs and emphasizes the necessity for in-depth studies on their robustness.", "venue": "arXiv.org", "year": 2023, "citationCount": 14, "influentialCitationCount": 3, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces a novel transferable attack against ICL, aiming to hijack LLMs to generate the target response or jailbreak, and reveals the significant security vulnerabilities of LLMs and emphasizes the necessity for in-depth studies on their robustness."}, "embedding": {"model": "specter_v2", "vector": [0.12812013924121857, 0.09270021319389343, -0.37075287103652954, 0.19775569438934326, -0.6697881817817688, -1.1962944269180298, 0.9850262403488159, 0.14310109615325928, -0.20169062912464142, -0.08013366907835007, -0.01557837426662445, -0.4984380900859833, 0.5891830325126648, 0.33364927768707275, -0.6577538251876831, 0.173754021525383, -0.7834732532501221, 0.2103327065706253, -0.3009137213230133, -0.5055450797080994, -0.0488034151494503, -0.4703252911567688, -0.33047041296958923, 0.2587214410305023, 0.5162314176559448, 0.43790897727012634, -0.1306842416524887, 1.2020115852355957, -0.3936992883682251, 0.17901140451431274, -0.14350108802318573, -0.5995539426803589, 0.2649538218975067, 0.06753474473953247, -0.12918998301029205, -0.2161271572113037, 0.6297448873519897, -0.5442584156990051, -0.3671629726886749, 0.6275779008865356, 0.1883593052625656, 0.054235491901636124, 0.2213427722454071, -0.6143063306808472, -0.71269291639328, 0.932683527469635, 0.5938629508018494, 0.5168049931526184, 0.47146448493003845, -0.42750653624534607, 1.2855138778686523, -1.5877511501312256, 0.1524973213672638, 1.231387972831726, 0.37947940826416016, 0.7136035561561584, 0.07315827161073685, -0.6290904879570007, 0.9447131156921387, -0.033024173229932785, -0.8630154728889465, -0.04005713388323784, 0.08906230330467224, 0.25977060198783875, 1.341994285583496, -0.32474178075790405, -0.3449467122554779, 1.0016212463378906, -0.5128472447395325, 1.8363956212997437, -0.2359522432088852, -1.3654921054840088, -0.24281780421733856, 0.031162790954113007, 0.052477139979600906, 0.6961017847061157, -0.3257884681224823, 0.672261118888855, -0.8788657188415527, -0.27081114053726196, 0.16645631194114685, -0.1699162721633911, 0.11207658052444458, 0.2332947999238968, -0.18767276406288147, 0.8939650058746338, 0.5379997491836548, 0.9572608470916748, -0.06058311089873314, 0.7384611964225769, 0.37571510672569275, 0.14552012085914612, -0.24234823882579803, 0.6681627631187439, -0.09406164288520813, 0.45338189601898193, -0.8817248344421387, 0.5835698246955872, 0.12229427695274353, 0.7522794604301453, -0.7151421904563904, 0.05232841148972511, -0.8374715447425842, -0.1333511918783188, 0.830234169960022, 0.3281678259372711, 0.47634169459342957, -0.5163264274597168, 0.55064457654953, -0.9762946963310242, 0.26077625155448914, -0.4152088165283203, 0.0914052203297615, -0.032423295080661774, -0.11363954842090607, -1.0777887105941772, -0.11023698002099991, -0.3746495246887207, -0.719791054725647, 1.0412830114364624, -0.14247813820838928, 0.2976211607456207, 0.21440748870372772, 0.41455045342445374, 0.37914347648620605, 0.7469161748886108, 0.2535829544067383, -0.0793251022696495, 0.2231287658214569, -0.8282512426376343, -0.14485026895999908, -1.028783917427063, 1.1517366170883179, -0.7355825304985046, 0.6063985228538513, -0.1786176562309265, -0.9467899799346924, -0.862042248249054, -1.1147023439407349, 0.24095144867897034, -0.7844382524490356, 0.20877808332443237, 0.7854008674621582, 0.5402640700340271, -0.7338034510612488, 0.6753191947937012, -0.1298186182975769, -0.23227737843990326, 0.12757539749145508, -0.1512834131717682, 0.42701277136802673, -0.9411990642547607, -1.514318585395813, -0.1484186202287674, 0.15487875044345856, -0.5601785778999329, -0.37265413999557495, -0.4151000380516052, -1.0163873434066772, -0.5280321836471558, 0.2873504161834717, -0.1704016923904419, 1.5774074792861938, -0.0986471027135849, -0.7761795520782471, 0.6209789514541626, 0.2338506579399109, 0.2868496775627136, 0.5005097389221191, -0.40257200598716736, -0.6940917372703552, -0.5565466284751892, 0.17726507782936096, 0.5751898884773254, 0.5521309971809387, -0.31307628750801086, 0.1555105447769165, 0.2334827333688736, 0.008620938286185265, 0.03406233713030815, -0.061186179518699646, 0.6708146333694458, -0.2636606991291046, -0.589809775352478, 0.3332040309906006, 0.5966963768005371, -0.130311518907547, -0.3694877028465271, -0.8420044183731079, -1.1355435848236084, 1.102036714553833, -0.12412796169519424, 1.0638970136642456, -0.7522521018981934, -1.1237502098083496, -0.2971712350845337, -0.7422114014625549, 0.2777128517627716, -0.7995575666427612, 1.2645061016082764, -0.3089597523212433, 0.6866708993911743, -0.0025003321934491396, -1.1528538465499878, 0.09688418358564377, -0.48313844203948975, -1.1787134408950806, -0.4707127511501312, 0.10627688467502594, 0.9593628644943237, -1.1629074811935425, 0.2982480823993683, -0.21541520953178406, 0.06250288337469101, -0.9320148229598999, 1.4461714029312134, -0.9190875887870789, 0.5990511178970337, -0.22365625202655792, 0.43213987350463867, -0.1000901535153389, -0.11859360337257385, 0.1997186541557312, -0.1095987930893898, 0.03174062818288803, 0.4359821379184723, -0.12233351916074753, 1.8328733444213867, -0.4487925171852112, -0.03921758010983467, -0.27848535776138306, -0.7246701717376709, -0.16110524535179138, 0.6397053599357605, -0.5081571936607361, -0.2361869066953659, -0.2113160640001297, 0.7293246984481812, -0.8155829906463623, 0.09881412982940674, 0.8449593186378479, 0.8431699872016907, -0.5777953267097473, 0.3531031310558319, 0.13880710303783417, -0.3910023868083954, 0.6031821370124817, 0.7781792879104614, 0.5946050882339478, 0.909562885761261, 0.33364856243133545, 0.6589431762695312, 0.5460054278373718, -0.644392728805542, -0.4680938720703125, 0.9693352580070496, 0.6641620397567749, 1.0610679388046265, 0.22183339297771454, -0.6357914209365845, 0.15971143543720245, -0.01260730717331171, 1.0209091901779175, 1.6867703199386597, -0.05836242064833641, -0.3347204923629761, -0.7230046391487122, -1.0880227088928223, -0.13090693950653076, 0.4198397397994995, -0.30190420150756836, -0.08485638350248337, -0.5121750831604004, -0.8561190366744995, 1.085377812385559, 0.2167498767375946, 0.601150631904602, -0.9166864156723022, 0.008705678395926952, 0.015812011435627937, -0.1176266148686409, -0.8362312912940979, -1.0769593715667725, 0.12979580461978912, -0.09370487928390503, -0.33992859721183777, 0.04291197285056114, -0.401113361120224, 0.17920027673244476, -0.8765247464179993, 1.0445120334625244, -0.13446366786956787, -0.66899174451828, 0.588072657585144, 0.19147087633609772, -0.4939270615577698, -1.0997031927108765, 0.11421584337949753, 0.0783170834183693, -0.5786881446838379, 0.21251782774925232, 0.4177599549293518, 0.09149497002363205, -0.3521627187728882, -0.7803623080253601, -0.23420512676239014, -0.042943861335515976, 0.14762209355831146, 0.5642020106315613, -0.9500443935394287, 0.5597005486488342, -1.1984411478042603, 1.0347057580947876, -0.1194663718342781, -0.3898375630378723, 0.4377123713493347, -0.7810583710670471, -0.6690697073936462, 1.0448099374771118, -0.7314994931221008, -0.021044792607426643, -0.888789713382721, 0.08323454111814499, -0.07982763648033142, -0.3988225758075714, 0.3451295793056488, 0.2802852392196655, 0.4975672662258148, 0.7177877426147461, 0.5824239253997803, -0.10544396191835403, -0.45330020785331726, 1.1413869857788086, -1.023011565208435, 0.7485944628715515, -0.25354260206222534, 0.284244179725647, -0.5115928649902344, -0.3403179943561554, -0.19438254833221436, -0.4991892874240875, -0.02448561042547226, -0.0806233212351799, -0.25030115246772766, -0.20436322689056396, -0.4442307651042938, -0.6700009107589722, 0.046961452811956406, -1.3375086784362793, -0.180090069770813, 0.15689997375011444, -0.5808612108230591, -0.21857520937919617, -0.698589563369751, -1.2762980461120605, -0.44584956765174866, -0.4919435977935791, -0.6937483549118042, 0.3648146390914917, 0.177071675658226, -0.41777437925338745, -0.6635524034500122, 0.22100667655467987, -0.4541884660720825, 0.7705696821212769, -0.13893483579158783, 0.6982334852218628, -0.19875194132328033, -0.3463660180568695, -0.687806248664856, 0.6703649759292603, 0.26758357882499695, -0.011998597532510757, 0.26849836111068726, -0.897244393825531, -0.13764061033725739, -0.4499730169773102, -0.9177071452140808, -0.09015364199876785, -0.14526233077049255, 0.445896714925766, -0.23464980721473694, -0.6180716156959534, 0.4187376797199249, 1.510449767112732, -0.2842675447463989, -0.5129551291465759, 0.1814393401145935, 1.0235530138015747, 0.504324197769165, 0.26229771971702576, 0.4179765284061432, -0.2391843944787979, 0.3618244230747223, 0.03985273465514183, 0.014643022790551186, 0.2233244627714157, -1.0287446975708008, 0.8291521072387695, 1.0946398973464966, 1.0982279777526855, -0.24697721004486084, -0.9124336242675781, 0.4378354549407959, -1.2702975273132324, -0.47117549180984497, 0.8018745183944702, 0.8109465837478638, 0.6004719734191895, -0.34111616015434265, -0.15895399451255798, -0.23296384513378143, 0.45127373933792114, 0.4354841709136963, -0.5724755525588989, -0.8908801078796387, 0.16582374274730682, 0.4116341173648834, -0.26228052377700806, 0.6090586185455322, -0.7153190970420837, 0.7691642045974731, 14.683448791503906, 0.7757402062416077, -0.27241745591163635, 0.32795801758766174, 0.6655857563018799, 0.26734620332717896, -0.30319324135780334, -0.21764248609542847, -1.1565778255462646, -0.038786109536886215, 0.8176124691963196, 0.3526175916194916, 0.5088019371032715, 0.33597704768180847, -0.1407158523797989, 0.4024752080440521, -0.8752485513687134, 0.6364196538925171, 0.7898227572441101, -1.2574347257614136, 0.34178945422172546, -0.30385300517082214, 0.4611780047416687, 0.40144771337509155, 1.1560579538345337, 0.876363217830658, 0.547091543674469, -0.5933671593666077, 0.4395160973072052, -0.3606962561607361, 1.11647367477417, -0.11816989630460739, 0.1182575523853302, 0.6935022473335266, -0.3372640609741211, -0.16249734163284302, -0.3657667934894562, -1.0746984481811523, 0.2750255763530731, -0.047262538224458694, -0.9513685703277588, -0.11015630513429642, -0.488720178604126, 0.5597273707389832, -0.08634927868843079, 0.09060963988304138, -0.6375499367713928, 0.8315470814704895, -0.2635210156440735, 0.2387552410364151, 0.471772164106369, 0.46071797609329224, 0.4482918381690979, 0.08538096398115158, 0.14723506569862366, -0.10421673208475113, 0.5418487787246704, 0.41236570477485657, -0.612813413143158, 0.14295268058776855, -0.5653010606765747, -0.3572251796722412, 0.36114174127578735, 0.5774368047714233, 0.7383831143379211, 0.2795065939426422, -0.32787322998046875, 0.7167971730232239, 0.5548300743103027, 0.46872642636299133, -0.15828824043273926, 0.14822377264499664, -0.23354971408843994, -0.6759699583053589, -0.029147174209356308, 0.5808922648429871, -0.06756340712308884, -0.47578611969947815, -0.2506954073905945, -0.5111863017082214, 0.49181950092315674, -0.5481676459312439, -1.097372055053711, 0.9870663285255432, -0.5409815311431885, -0.638006329536438, -0.47692060470581055, -0.3627891540527344, -0.6418331861495972, 0.6649148464202881, -1.3749521970748901, -0.9107545614242554, 0.5681668519973755, -0.5338044166564941, -0.3987732529640198, -0.199899822473526, 1.4560893774032593, 0.19263768196105957, -0.5356292128562927, 0.6952728033065796, 0.4231364130973816, -0.04263264313340187, 0.3509925901889801, -1.184293508529663, 1.2126030921936035, 0.6672508716583252, 0.35584619641304016, 0.1292341947555542, 0.14445658028125763, 0.018846692517399788, -0.39300426840782166, -0.022015441209077835, 0.826016902923584, -1.236926555633545, -0.7496686577796936, -0.5392479300498962, -0.5608140826225281, 0.3157387971878052, 0.42855578660964966, -0.16484150290489197, 0.4861806333065033, -0.15318666398525238, -0.7074862718582153, -0.055855777114629745, -0.8911682963371277, 0.12403498589992523, 0.22695057094097137, -0.6681856513023376, -0.1815452128648758, 0.37883904576301575, 0.6174004077911377, -0.9703024625778198, -0.1903524398803711, -0.288332462310791, -0.13160859048366547, -0.01074154395610094, 1.025668978691101, -0.6099340915679932, 0.8964517712593079, 0.7793137431144714, -0.4159961938858032, -0.7932897806167603, 0.561098039150238, -1.2175575494766235, -0.11226794123649597, 0.5628499388694763, 0.5631521344184875, -0.13380838930606842, 0.5126745104789734, 0.9625822901725769, 0.3805375099182129, -0.5000119209289551, -0.0797765776515007, -0.5257279276847839, 0.5470827221870422, -0.48904290795326233, 0.3064342439174652, 0.15924465656280518, -0.03893894702196121, 0.2992050051689148, 0.40733543038368225, 0.7194855213165283, -0.08792416751384735, -0.4257920980453491, 0.5674853920936584, 0.3298644721508026, -0.4385592043399811, -0.2275656759738922, 0.08795840293169022, -1.3959428071975708, -0.08155371248722076, -1.2389464378356934, -0.11779952049255371, -0.5924769639968872, -0.8096300363540649, -0.40092456340789795, -0.08650171011686325, -0.12975139915943146, -0.07380249351263046, -0.28839111328125, 0.026002073660492897, -0.43337559700012207, -0.36575642228126526, 0.4466775059700012, 0.49249857664108276, -0.6341894268989563, -0.0218945425003767, 0.2510506808757782, -0.058083221316337585, -0.04733581095933914, 0.2633834481239319, -0.44582319259643555, -0.7081230878829956, -1.0928764343261719, 0.16741682589054108, -0.03846781700849533, -0.11969244480133057, -0.6370492577552795, 0.37224388122558594, 0.4725044071674347, 0.09750038385391235, -0.06736762821674347, 0.037555817514657974, -0.8772144913673401, -0.8026139736175537, 0.20761705935001373, -0.8693164587020874, 0.36074039340019226, -0.04539106413722038, -0.46189096570014954, -0.5044749975204468, 0.501645028591156, -0.2699868977069855, -0.9820778369903564, -0.8686557412147522, 0.4576652944087982, -0.32328182458877563, 0.21408694982528687, -0.1818859875202179, 0.3321433961391449, -0.855158269405365, -0.670782744884491, -0.09587012976408005, 0.4242022633552551, -0.18105357885360718, 0.9687983989715576, 0.12002111971378326, -1.3707040548324585, -0.08706922084093094, 0.36084088683128357, 0.056258127093315125, 0.14565201103687286, 0.386321097612381, -0.012716547586023808, -0.6325567364692688, 0.46183133125305176, 0.606765627861023, 0.32335853576660156, -0.7555428147315979, 0.4613710343837738, 0.6860832571983337, -1.0550954341888428, 0.32318270206451416, 1.297511339187622, -0.1811981499195099, -1.3101521730422974, 0.36698997020721436, -0.5303637385368347, -0.3308696150779724, -0.6322659254074097, 0.7133146524429321, -0.06947744637727737, 0.12834687530994415, 0.12476888298988342, -0.6462114453315735, -0.13557195663452148, -0.41213375329971313, -0.6900202631950378, 0.08716230094432831, -0.20466721057891846, -0.08725148439407349, 0.2055659145116806, 1.0303653478622437, -0.22758212685585022, -0.7434380054473877, -0.7612782120704651, -0.30655285716056824, 0.0244655329734087, -0.5089011788368225, -0.9123266935348511, -0.17785997688770294, 0.49392762780189514, 0.33869802951812744, 0.3330594599246979, -0.02268521673977375, -0.23854774236679077, 0.7579583525657654, 0.8096870183944702, -0.0599602572619915, -0.3717157542705536, -0.03639594465494156, 1.053708791732788, 1.3566797971725464, -1.311940312385559, -0.0029496413189917803, 0.08641912788152695, -0.5957604646682739, 0.9982911944389343, 0.6125485897064209, -0.08258942514657974, 0.7173779606819153, -0.47513195872306824, 0.7739731669425964, 0.4705519676208496, -0.7359547019004822, 0.3128531277179718, 0.529029369354248, 0.9979978203773499, 1.0022813081741333, 0.37807050347328186, -0.1477804183959961, 0.8726823925971985, 0.21335189044475555, -0.08028434962034225, 0.5148513317108154, 0.9254212975502014, 0.33704495429992676, -0.9427492618560791, -0.5085465908050537, 0.20198571681976318, -1.1493667364120483, -0.8644111156463623, -0.25328439474105835, 0.6600733995437622, 0.2338700294494629, 0.7158855199813843, 0.38015085458755493, -0.0694495216012001, 0.5790886282920837, 0.6524059176445007, 0.36858317255973816, -0.6380751729011536, -0.3698878884315491, -0.7036653757095337, -0.9012947082519531, 0.03855086863040924, 0.20770499110221863, -0.5574332475662231, -0.22776192426681519, -0.05596478655934334, 0.47409871220588684, -0.1791369915008545, 0.15378957986831665, 1.002005696296692, 0.38175296783447266, -0.10515286028385162, 0.12804822623729706, -0.38760286569595337, -0.7162895798683167, -0.8211156129837036, 0.15069341659545898, -0.05981650575995445, -0.22001706063747406, 0.31031447649002075, -0.03574181720614433, -0.3259625732898712]}, "authors": [{"authorId": "2062242240", "name": "Yao Qiang"}, {"authorId": "2261896802", "name": "Xiangyu Zhou"}, {"authorId": "2261934883", "name": "Dongxiao Zhu"}], "references": [{"paperId": "982210d4d759efab60d2e50b9fac72dc614ee6d6", "title": "SemRoDe: Macro Adversarial Training to Learn Representations that are Robust to Word-Level Attacks"}, {"paperId": "2f4cc3f4a1c70cd5aca14c1304037491cd3aeb9b", "title": "RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content"}, {"paperId": "1cef01ab4db546659f42de237a54dd510f9906cb", "title": "A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems"}, {"paperId": "ba15e41eac064729c634464851ae0a268de777d4", "title": "Prompt Perturbation Consistency Learning for Robust Language Models"}, {"paperId": "b24fd97988e71585e943a6d30725926bab5ded97", "title": "Mitigating Fine-tuning based Jailbreak Attack with Backdoor Enhanced Safety Alignment"}, {"paperId": "b7ef6182f617ef3e7cc9682f562f794115a4c62c", "title": "COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability"}, {"paperId": "06d2de84ae766fb5483796fd2b1edd836ae46525", "title": "Hijacking Context in Large Multi-modal Models"}, {"paperId": "faffb6320ff1f25cd472ba0afe7cdba5dde79a5f", "title": "Test-time Backdoor Mitigation for Black-Box Large Language Models with Defensive Demonstrations"}, {"paperId": "05d2ced6a4fb7efb8d527a228ad792526a202235", "title": "How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities"}, {"paperId": "4f63c5a89c7299a864c6c48aa1844fb0fe8c9437", "title": "Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks"}, {"paperId": "4637f79ddfaf923ce569996ffa5b6cda1996faa1", "title": "Jailbreaking Black Box Large Language Models in Twenty Queries"}, {"paperId": "6b135e922a0c673aeb0b05c5aeecdb6c794791c6", "title": "Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations"}, {"paperId": "57207b935fc3484d175f5e9e2980d73ca793f994", "title": "Are Large Language Models Really Robust to Word-Level Perturbations?"}, {"paperId": "3e30a7ac4886b28eb50151f58e14a1d698cccd0e", "title": "Baseline Defenses for Adversarial Attacks Against Aligned Language Models"}, {"paperId": "b8b8d5655df1c6a71bbb713387863e34cc055332", "title": "Detecting Language Model Attacks with Perplexity"}, {"paperId": "fd81018bc72b030545a2d3f3010f3758ec4d48c3", "title": "Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions"}, {"paperId": "47030369e97cc44d4b2e3cf1be85da0fd134904a", "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models"}, {"paperId": "4d21debb0f5fec315181e0912b5105c6ce4fc67f", "title": "Backdoor Attacks for In-Context Learning with Language Models"}, {"paperId": "cf7368f38cc1f0861d4b35db1307776c7f3f237d", "title": "In-Context Learning Learns Label Relationships but Is Not Conventional Learning"}, {"paperId": "8724579d3f126e753a0451d98ff57b165f722e72", "title": "Are aligned neural networks adversarially aligned?"}, {"paperId": "1db819afb3604c4bfd1e5a0cb2ee9ab9dec52642", "title": "Explore, Establish, Exploit: Red Teaming Language Models from Scratch"}, {"paperId": "a2ce9963f1f072d578b1a1f1b995fec75e8c2247", "title": "PromptRobust: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts"}, {"paperId": "7264958c138579270ae79487985d5ac3b199f715", "title": "From Shortcuts to Triggers: Backdoor Defense with Denoised PoE"}, {"paperId": "9c6b635f714395529127acc6817615a54d3ca35e", "title": "Defending against Insertion-based Textual Backdoor Attacks via Attribution"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "154493f69d7db3d49da0e51df0192c6ad5f1724a", "title": "Larger language models do in-context learning differently"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "5c7353fac22a8fdc43fc2f5c006b5d6902c47e75", "title": "On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective"}, {"paperId": "b6207fe49e29c77402f8dbab052e949990949609", "title": "In-context Example Selection with Influences"}, {"paperId": "0cf694b8f85ab2e11d45595de211a15cfbadcd22", "title": "Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks"}, {"paperId": "6c489a9dc649298aea729c91822a3c89de503729", "title": "Black Box Adversarial Prompting for Foundation Models"}, {"paperId": "0c26bfc15a7caecce0ed4567dc2f2909b80e5bdd", "title": "Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery"}, {"paperId": "fef6bb50c6dce8d4b5fdcaab89400b9776bc00df", "title": "Learning Compact Features via In-Training Representation Alignment"}, {"paperId": "9716a2876d08fce9d8e5c5ba4d7b1a9af44806d6", "title": "Ignore Previous Prompt: Attack Techniques For Language Models"}, {"paperId": "46d64d0c1dd240f5035b1af57e738b3f70850ca2", "title": "On the Relation between Sensitivity and Accuracy in In-context Learning"}, {"paperId": "6a93057b6060623cc8659e693b2be258093ef77a", "title": "Tiny RNN Model with Certified Robustness for Text Classification"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "f4df78183261538e718066331898ee5cad7cad05", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"}, {"paperId": "af46b5ee6d0c1aada1c482d53018a50909aa4c90", "title": "Impact of Pretraining Term Frequencies on Few-Shot Reasoning"}, {"paperId": "f9838a3be5c94bb2674a0e224de349b50e18f3c4", "title": "Learning To Retrieve Prompts for In-Context Learning"}, {"paperId": "10bd4160b44803ada6a3d2e366c44b7e2a4ffe90", "title": "An Explanation of In-context Learning as Implicit Bayesian Inference"}, {"paperId": "0adec918885dff698acf359988ed79a543157f80", "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"}, {"paperId": "56fa0b9cba4d9aee5ccc327365b3b3a721031c69", "title": "Calibrate Before Use: Improving Few-Shot Performance of Language Models"}, {"paperId": "59641c10ed7431a3cf841f308367dc2dc0281b74", "title": "What Makes Good In-Context Examples for GPT-3?"}, {"paperId": "2ed004ed273bcf3cf33d37f4c6952ed68b55bb4b", "title": "Improving Adversarial Robustness via Probabilistically Compact Loss with Logit Constraints"}, {"paperId": "3a1f8829e641b46f661775f64a7f27b933a46103", "title": "ONION: A Simple and Effective Defense Against Textual Backdoor Attacks"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "c9b56cb026a38e39bb0228faac57accd6f65e6f7", "title": "TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP"}, {"paperId": "2ffcf8352223c95ae8cef4daaec995525ecc926b", "title": "Adversarial Training for Large Neural Language Models"}, {"paperId": "dc0ce66f5ab4c5173cdef951649044e4c4c05076", "title": "BERT-ATTACK: Adversarial Attack against BERT Using BERT"}, {"paperId": "b990e1fd1e0e100530add646d8321d44cc65f5e9", "title": "Toward Tag-free Aspect Based Sentiment Analysis: A Multiple Attention Network Approach"}, {"paperId": "8733fe2371b615609b04e2e910b1ecfa8e77cbc2", "title": "Square Attack: a query-efficient black-box adversarial attack via random search"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "f91175950edf3804ff1573f570b03db9b108dece", "title": "TextBugger: Generating Adversarial Text Against Real-world Applications"}, {"paperId": "fa12574c228542151ccd7d4e3f42cc4896cd274a", "title": "Black-Box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers"}, {"paperId": "514e7fb769950dbe96eb519c88ca17e04dc829f6", "title": "HotFlip: White-Box Adversarial Examples for Text Classification"}, {"paperId": "51a55df1f023571a7e07e338ee45a3e3d66ef73e", "title": "Character-level Convolutional Networks for Text Classification"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "6af58c061f2e4f130c3b795c21ff0c7e3903278f", "title": "Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales"}, {"paperId": "ce09d7a0bf35ee6a2d857c472efd8d480b9fa122", "title": "Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks"}, {"paperId": null, "title": ". Llm jailbreak attack versus defense techniques\u2013a comprehensive study"}, {"paperId": "29c7f009df21d0112c48dec254ff80cc45fac3af", "title": "Are Emergent Abilities of Large Language Models a Mirage?"}, {"paperId": "8aa98fbfb6f1e979dead13ce24075503fe47658e", "title": "A Survey for In-context Learning"}, {"paperId": null, "title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "2022. Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned"}, {"paperId": null, "title": "8.2 Impact of Sizes of LLMs We have shown in the main text (Table 3)"}, {"paperId": null, "title": "2023a. Multi-step jailbreak-ing privacy attacks on chatgpt"}, {"paperId": null, "title": "those on LLaMA-7b, suggesting that hijacking the larger LLM is more challenging"}, {"paperId": null, "title": "2024. Don\u2019t listen to me: Understanding and exploring jailbreak prompts of large language models"}, {"paperId": null, "title": "2023. Instructions as backdoors: Backdoor vulnerabilities of instruction tuning for large language models"}, {"paperId": null, "title": "2023. Tree of attacks: Jailbreak-ing black-box llms automatically"}, {"paperId": null, "title": "2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"}, {"paperId": null, "title": "2023. Interpretability-aware vision transformer"}]}