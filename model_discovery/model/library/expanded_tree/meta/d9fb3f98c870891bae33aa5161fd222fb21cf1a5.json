{"paperId": "d9fb3f98c870891bae33aa5161fd222fb21cf1a5", "abstract": "Chain-of-Thought (CoT) prompting has been shown to enhance the multi-step reasoning capabilities of Large Language Models (LLMs). However, debates persist about whether LLMs exhibit abstract generalization or rely on shallow heuristics when given CoT prompts. To understand the factors influencing CoT reasoning we provide a detailed case study of the symbolic reasoning task of decoding shift ciphers, where letters are shifted forward some number of steps in the alphabet. GPT-4 achieves zero accuracy on most shift ciphers with standard prompting, but with CoT its accuracy improves to an average of 32%. By focusing on a single relatively simple task, we are able to identify three factors that systematically affect CoT performance: the probability of the task's expected output (probability), what the model has implicitly learned during pre-training (memorization), and the number of intermediate operations involved in reasoning (noisy reasoning). We show that these factors can drastically influence the task accuracy; e.g., varying the output's probability of occurrence can shift accuracy from 26% to 70%. We also demonstrate that it is essential for the model to explicitly produce intermediate steps as output that can be conditioned on to increase the probability of the correct answer. Our experiments indicate that as long as the model does so, the validity of the demonstrations in the prompt does not matter. Overall, we conclude that CoT prompting performance reflects both memorization and a probabilistic version of genuine reasoning.", "venue": "", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "CoT prompting performance reflects both memorization and a probabilistic version of genuine reasoning, as well as the validity of the demonstrations in the prompt does not matter."}, "embedding": {"model": "specter_v2", "vector": [0.29397106170654297, 0.9705356359481812, -0.04818466305732727, 0.19799935817718506, -0.25427353382110596, -0.2477201521396637, 0.9837679862976074, 0.2185017317533493, -0.21441330015659332, -0.17277972400188446, 0.08826272934675217, -1.0038402080535889, 0.1517840176820755, 0.1341857612133026, -0.4262775778770447, -0.20743827521800995, -0.8743497729301453, -0.023152180016040802, -0.10506837069988251, -0.21877139806747437, 0.32521700859069824, -0.4597104489803314, -0.6588299870491028, 0.5126031041145325, 0.25428345799446106, 0.3881583511829376, -0.2733171582221985, 1.068419337272644, -0.24955449998378754, 1.0651907920837402, 0.16010525822639465, -0.454384982585907, 0.23424360156059265, 0.08089626580476761, -0.4676792025566101, -0.291739284992218, 0.11312876641750336, -0.3804362118244171, -0.6610420346260071, 0.6422942876815796, -0.2112847864627838, -0.17012029886245728, 0.4154838025569916, -0.7664713263511658, -0.7029574513435364, 0.9687879085540771, 0.8217452764511108, 0.7664337158203125, 0.28981614112854004, 0.07982681691646576, 1.451730489730835, -1.292531967163086, 0.19687625765800476, 1.2005562782287598, 0.7985198497772217, 0.4945732653141022, -0.14094622433185577, -0.42686131596565247, 0.8071887493133545, 0.09298443049192429, -0.8820833563804626, -0.21816155314445496, -0.4959934651851654, 0.10121551901102066, 1.6725075244903564, -0.45772019028663635, -0.05108482018113136, 0.4257684051990509, 0.1590271294116974, 1.6005102396011353, 0.7330187559127808, -0.9286738038063049, 0.08895321935415268, 0.03939415514469147, 0.3599230647087097, 0.7500802874565125, 0.1436031311750412, 0.5396739840507507, -1.2698725461959839, -0.330449640750885, 0.5379048585891724, -0.26683276891708374, -0.4116358458995819, 0.02536156214773655, -0.451168030500412, 0.23516835272312164, 0.16909512877464294, 0.7524603605270386, -0.45526090264320374, 0.9198640584945679, -0.15075939893722534, 0.639829158782959, -0.314641535282135, 0.40425658226013184, -0.20199386775493622, 0.1549021154642105, -0.7672858238220215, 0.48642411828041077, 0.6888741254806519, 0.8783165812492371, -0.18880906701087952, -0.10029911249876022, -0.8528415560722351, -0.21393625438213348, 1.545581340789795, 0.20210470259189606, 0.30788350105285645, -0.5869203209877014, 0.4054597020149231, -0.6216589212417603, 0.6260702610015869, -0.4633924663066864, -0.31540006399154663, -0.37373754382133484, -0.06660017371177673, -1.091200828552246, 0.11940967291593552, -0.18957117199897766, -0.7460928559303284, 0.7643015384674072, -0.6523571610450745, -0.06307412683963776, 0.379499614238739, 0.4366382360458374, 0.3781900703907013, 0.4636000394821167, 0.7339969277381897, -0.033663611859083176, 0.6874985098838806, -0.04740290343761444, -0.44440242648124695, -1.0354734659194946, 0.9516801834106445, -0.37395206093788147, 0.04241759702563286, -0.05285913497209549, -1.259576678276062, -0.9026064872741699, -1.087597131729126, 0.3453778922557831, -0.17795807123184204, 0.13496792316436768, 1.2481366395950317, 0.4505111277103424, -1.1398084163665771, 0.962719738483429, 0.11870379745960236, -0.09644439071416855, 0.5681066513061523, 0.22371695935726166, 0.42826730012893677, -0.9153026938438416, -1.0898288488388062, 0.4178101718425751, 0.37676429748535156, -0.44870784878730774, 0.02548827975988388, -0.42814064025878906, -0.8777962923049927, 0.06056777387857437, 0.31374433636665344, -0.6460570693016052, 1.8297464847564697, 0.2624844014644623, -0.9586538076400757, 0.5962266325950623, -0.3056927025318146, 0.02481633797287941, 0.3750188648700714, -0.1840120106935501, -0.47905826568603516, -0.13463926315307617, -0.17406974732875824, 0.6366550326347351, 0.4743090867996216, -0.729964554309845, -0.44139784574508667, 0.42906251549720764, -0.258461058139801, -0.3410366475582123, 0.4477195143699646, 0.5643362998962402, 0.29288411140441895, -0.06178199127316475, 0.4979555606842041, 0.6320416331291199, 0.12396585941314697, -0.09245680272579193, -0.15107181668281555, -1.3362387418746948, 0.2959892153739929, -0.0545881949365139, 0.9227571487426758, -0.865241289138794, -1.0016851425170898, -0.11735068261623383, 0.1259508579969406, -0.0038536309730261564, -0.3328627347946167, 1.1078510284423828, -0.3753131330013275, 0.536842942237854, -0.4419631361961365, -0.669735312461853, 0.23257282376289368, -0.15480387210845947, -0.8099596500396729, -0.18246489763259888, 0.19582223892211914, 1.0435032844543457, -0.9405698776245117, 0.06311971694231033, -0.038275789469480515, -0.05946158990263939, -0.7012465596199036, 1.145302653312683, -0.6969513893127441, 0.23935623466968536, -0.2625749111175537, -0.5353913307189941, 0.24251671135425568, -0.6330968141555786, 0.23780013620853424, 0.023161597549915314, -0.018743623048067093, 0.2681579291820526, -0.5400404930114746, 1.2187126874923706, -0.04709714651107788, 0.8292005062103271, -0.5704360604286194, -0.2650660574436188, -0.10631060600280762, 0.6246466040611267, -0.7947843074798584, -0.19048085808753967, 0.11540680378675461, 0.39019834995269775, -0.12069068104028702, -0.03915441781282425, 0.20100803673267365, 0.4958711564540863, -0.34377384185791016, 0.5956394672393799, 0.356833279132843, -0.6601769924163818, 0.19692160189151764, 0.3391053378582001, 0.8009840846061707, 0.39033243060112, 0.7080463767051697, 0.07262930274009705, 0.47016820311546326, -0.38797181844711304, -0.27762919664382935, 1.0802605152130127, 1.095330834388733, 0.5892809629440308, 0.5231961607933044, -0.8454840183258057, 0.050109535455703735, 0.054347872734069824, 0.6484646797180176, 1.3125536441802979, 0.10037992894649506, -0.5669631958007812, -0.7035444378852844, -0.21052095293998718, -0.22661863267421722, 1.152779221534729, -0.2344110608100891, -0.5580745935440063, -0.5105503797531128, -0.9801182746887207, 0.9027448296546936, 0.3462371826171875, 1.236457109451294, -0.5217370986938477, -0.3264685273170471, -0.23246751725673676, 0.6922487616539001, -0.9732220768928528, -0.011214944534003735, 0.586337685585022, -0.40600016713142395, -0.501055121421814, 0.16667285561561584, -0.15550172328948975, 0.5824816226959229, -0.38682183623313904, 0.5779514908790588, 0.21386589109897614, -0.04222150146961212, 0.471833735704422, 0.47471514344215393, -0.6588560938835144, -0.9739573001861572, -0.2931099236011505, -0.4628940224647522, -0.34082290530204773, 0.44825685024261475, 0.6900535225868225, -0.1617944985628128, -0.04575555399060249, -0.457309365272522, 0.5723258256912231, 0.529424786567688, 0.08495765924453735, -0.05597054213285446, -0.12629784643650055, -0.3798113465309143, -1.0833173990249634, 1.414786458015442, 0.36444371938705444, -0.09587334096431732, 0.37351512908935547, -1.0837393999099731, -0.06333509087562561, 0.49223455786705017, -0.5915287137031555, -0.17726697027683258, -1.2892109155654907, 0.37471431493759155, 0.4925942122936249, -0.5070219039916992, -0.00635739928111434, 0.6466379165649414, -0.1256372332572937, 0.4450959861278534, 0.8542238473892212, 0.3489149212837219, 0.28103646636009216, 0.48588046431541443, -0.5916517376899719, 0.19436447322368622, -0.12437812238931656, 0.2250882089138031, -0.45603740215301514, -0.0069991424679756165, -0.23040521144866943, -0.413108229637146, 0.37296462059020996, 0.1549776792526245, -0.08441763371229172, -0.01411572378128767, -0.7161908745765686, -1.166547417640686, 0.28905630111694336, -1.1604201793670654, -0.810224711894989, 0.04254939779639244, -0.3383464515209198, -0.44111567735671997, -1.0314249992370605, -1.1402431726455688, -0.47885364294052124, -0.11503472924232483, -0.8837297558784485, 0.5267197489738464, -0.009207165800035, -0.8533597588539124, -0.4084145426750183, -0.22896617650985718, -0.5296967029571533, 0.7224634289741516, -1.0193606615066528, 1.2755261659622192, -0.4633501172065735, -0.6648327708244324, -0.027919478714466095, 0.07724757492542267, 0.180684894323349, -0.39945173263549805, -0.08939457684755325, -0.8927488923072815, 0.37957680225372314, -0.0032929808367043734, -0.32575535774230957, -0.10342039912939072, -0.25418975949287415, 0.4387338161468506, -0.20022784173488617, -0.5363911986351013, -0.04220061004161835, 1.0325068235397339, -0.5119660496711731, 0.0002587118069641292, 0.2845326066017151, 0.6915918588638306, 0.29330965876579285, -0.0698029175400734, 0.5841623544692993, 0.4250609576702118, -0.011806289665400982, -0.30883193016052246, 0.42004552483558655, -0.18801605701446533, -0.8366260528564453, 0.45923635363578796, 0.7186059951782227, 0.07129734009504318, 0.09014689922332764, -1.4556009769439697, -0.13621613383293152, -1.3146287202835083, -0.46523886919021606, 0.6874127984046936, 0.7308722138404846, 0.48070475459098816, -0.2890588045120239, -0.964203417301178, 0.28917980194091797, 0.34128373861312866, 0.08547091484069824, 0.1077493280172348, -0.44316020607948303, 0.2013954222202301, 0.48403915762901306, 0.23907017707824707, 0.49714726209640503, -0.027557194232940674, 0.5686134696006775, 14.949408531188965, 0.5838214755058289, 0.14607352018356323, 0.24258744716644287, 0.5757002830505371, 0.823393702507019, -0.43261203169822693, 0.16067418456077576, -1.1776052713394165, -0.2796371877193451, 1.0109094381332397, 0.1927918940782547, 0.43313997983932495, -0.23170705139636993, -0.278687059879303, -0.43887022137641907, -0.8984221816062927, 0.6368139386177063, 0.43506091833114624, -1.2866297960281372, 0.7241074442863464, 0.127031147480011, 0.10104776918888092, -0.23139704763889313, 0.7946885824203491, 0.9667664766311646, 0.5929805040359497, -0.4220696687698364, 0.9486584067344666, 0.06419733166694641, 0.5149919986724854, 0.27331361174583435, 0.31310170888900757, 0.8889174461364746, -0.10055802762508392, -0.280678927898407, -0.17247796058654785, -1.3761452436447144, -0.21632426977157593, -0.22252622246742249, -1.000841498374939, -0.7120370268821716, -0.799791157245636, 0.25761306285858154, -0.12282120436429977, 0.4365811347961426, -0.9797062277793884, 0.8175439834594727, -0.03106417879462242, -0.4798596203327179, 0.05865607410669327, 1.055305004119873, 0.0907437726855278, -0.10519614815711975, 0.26298099756240845, 0.28775662183761597, -0.24865509569644928, 0.6278121471405029, -0.20794913172721863, -0.2866561710834503, -0.27234187722206116, -0.31790322065353394, -0.0556948147714138, 0.21103742718696594, 0.20973022282123566, 0.28534507751464844, -0.3065183758735657, 0.0801718533039093, 0.32841047644615173, 0.29842573404312134, 0.26669690012931824, 0.28338637948036194, 0.2516711354255676, -0.621816873550415, 0.17777180671691895, 0.2485686093568802, -0.5144087076187134, -0.29805421829223633, -0.7117823362350464, -0.6264954805374146, 0.08376914262771606, -1.1525743007659912, -0.32747989892959595, 0.4191927909851074, -0.0822792649269104, -0.41566768288612366, 0.09608998894691467, -1.000785231590271, -0.4954853653907776, 0.3268592953681946, -1.1898164749145508, -0.756129801273346, 0.13206055760383606, -0.2520010471343994, -0.3273519277572632, -0.06937217712402344, 1.4241485595703125, -0.7626499533653259, -0.02496509812772274, -0.28376784920692444, -0.4762730896472931, -0.08937631547451019, -0.19197671115398407, -1.0144109725952148, 0.9110725522041321, 0.2686312198638916, 0.0850183516740799, 0.9047015309333801, 0.3220008313655853, -0.0902145653963089, -0.9894821643829346, 0.4031614065170288, 0.989801287651062, -1.0553882122039795, -0.3179203271865845, -0.48002851009368896, -0.7542951703071594, 0.21228817105293274, 0.35154345631599426, -0.1439037024974823, 0.34884265065193176, 0.005885058082640171, -0.7428938150405884, 0.02771175466477871, -0.5528361797332764, 0.6422851085662842, 0.5460246205329895, -0.5741102695465088, -1.004199504852295, 0.16241660714149475, 0.2424786388874054, -1.1895085573196411, -0.18392860889434814, -0.29311880469322205, 0.002812958788126707, -0.12300104647874832, 0.5653371810913086, -0.6150004267692566, 0.5531172752380371, 0.5873652696609497, -0.038031626492738724, -0.9160850048065186, -0.22542382776737213, -1.283421277999878, 0.14694057404994965, -0.09860502928495407, 1.061310052871704, -1.0583536624908447, -0.21847055852413177, 1.5334380865097046, 0.19959458708763123, -0.3096538186073303, -0.3327302634716034, 0.2799573242664337, 0.15308095514774323, -0.9798024296760559, 0.44493019580841064, -0.4355848729610443, 0.018296750262379646, 0.10247953981161118, 0.8520703911781311, 1.018036127090454, -0.3465462625026703, -0.38604503870010376, 0.5325870513916016, -0.08184751123189926, -0.17090070247650146, -0.43208813667297363, -0.36860328912734985, -1.4734326601028442, -0.11899303644895554, -1.0536038875579834, 0.23064936697483063, -1.0716530084609985, -0.9007567763328552, 0.15989987552165985, -0.17989568412303925, 0.05140408128499985, 0.06159660220146179, -0.7863740921020508, -0.4730779528617859, -0.12968143820762634, -0.5259507894515991, 0.18274925649166107, 0.9359332919120789, -0.3573673367500305, 0.3617826998233795, 0.19951128959655762, -0.5226030945777893, 0.2873675227165222, 0.4366285800933838, -0.6920790076255798, -0.5617950558662415, -1.0518760681152344, 0.7916728854179382, -0.07997889816761017, 0.29616549611091614, -0.7886348962783813, 1.0771725177764893, 0.5655083656311035, 0.3192702829837799, 0.31889334321022034, 0.2092018574476242, -0.9205146431922913, -0.6347086429595947, 0.6534968018531799, -1.0755864381790161, -0.07627606391906738, 0.3379538357257843, -0.1913839876651764, 0.15888671576976776, 0.3279823064804077, -0.44910135865211487, -1.1540833711624146, -0.7678238153457642, -0.07796500623226166, -1.0409868955612183, 0.13920004665851593, -0.05323372408747673, -0.19799195230007172, -1.2406526803970337, 0.01618705876171589, -0.08282264322042465, 0.23715965449810028, -0.36089015007019043, 0.680971622467041, 0.3530656397342682, -0.5695842504501343, 0.46722400188446045, 0.5031453371047974, 0.009251585230231285, 0.14983433485031128, 0.06557995080947876, 0.24644087255001068, -0.4924250841140747, 0.6867822408676147, 0.4910031855106354, 0.14891164004802704, -0.7876099944114685, -0.38538628816604614, 0.46501344442367554, -0.11029157042503357, -0.5638384819030762, 0.83115553855896, -0.6511849164962769, -0.49826881289482117, 0.22289924323558807, -1.3900066614151, -0.23905301094055176, -0.8112745881080627, 0.35002416372299194, -0.1618223786354065, -0.20914438366889954, 0.6189885139465332, -0.21278581023216248, 0.40097805857658386, -0.1802377700805664, -0.6621943712234497, 0.1680980622768402, -0.0899876281619072, -0.31581953167915344, 0.5425640344619751, 0.11799733340740204, -0.631706714630127, -0.7142868638038635, -0.5907098054885864, -0.0919797345995903, -0.10363969951868057, 0.12665139138698578, -0.47528913617134094, 0.6248777508735657, 0.7170807719230652, 0.03626920282840729, 0.3704952001571655, -0.37760698795318604, -0.13290871679782867, -0.24810126423835754, 0.9901858568191528, 0.5534881353378296, -0.17678388953208923, -0.7761220335960388, 0.9789295196533203, 1.1455848217010498, -0.8217903971672058, 0.4341728985309601, -0.4104987382888794, -0.6689983606338501, 1.258792757987976, 0.3002318739891052, -0.05540115386247635, 0.6800022125244141, -0.44121137261390686, 0.19104088842868805, 0.04220341518521309, -0.9975720643997192, -0.1433737874031067, 0.5476411581039429, 0.8525911569595337, 0.440048485994339, 0.29950568079948425, 0.08198527991771698, 1.0125033855438232, -0.1365007758140564, 0.7140281200408936, 0.486939936876297, 0.9885208606719971, -0.31794172525405884, -0.02429754100739956, -0.2889041602611542, 0.524903416633606, -0.6941686272621155, -0.9686510562896729, 0.0046231490559875965, 0.9359793066978455, 0.2958989441394806, 0.6283883452415466, 0.4199581444263458, 0.05314582586288452, 0.2860674262046814, 0.6740286946296692, 1.0564414262771606, -0.7621778249740601, -0.42124760150909424, -0.5777446627616882, -0.29705777764320374, 0.24393807351589203, -0.10311952978372574, -0.6745916604995728, -0.5054485201835632, -0.29742127656936646, 0.3741275370121002, 0.24330441653728485, 0.11033698916435242, 1.3809641599655151, 0.5679212808609009, 0.24581970274448395, -0.505972683429718, -0.33046290278434753, -0.691260039806366, -0.8721213936805725, 0.3624520003795624, -0.9580000638961792, -0.26827147603034973, -0.14097629487514496, -0.4698062241077423, -0.22594648599624634]}, "authors": [{"authorId": "116606529", "name": "Akshara Prabhakar"}, {"authorId": "2267240667", "name": "Thomas L. Griffiths"}, {"authorId": "145534175", "name": "R. Thomas McCoy"}], "references": [{"paperId": "6c9c0338f1526437b7cd3b9ccec1fff7feafb14c", "title": "Chain of Thoughtlessness? An Analysis of CoT in Planning"}, {"paperId": "397e5015f761bc4a0d4e81daff7d6462ae7c5a98", "title": "Let's Think Dot by Dot: Hidden Computation in Transformer Language Models"}, {"paperId": "5a20aa49b81b4e14fdb36814e557b3da60259ce9", "title": "Chain of Thought Empowers Transformers to Solve Inherently Serial Problems"}, {"paperId": "559eae00cd1550b2530af1657c6b744b38d51b8f", "title": "Understanding In-Context Learning with a Pelican Soup Framework"}, {"paperId": "40c0d1f38ab081e21cc3b1e2e5334a9b54b6ff08", "title": "The Impact of Reasoning Step Length on Large Language Models"}, {"paperId": "297211bc86653d9ebbe694a75141c9a1c6c11e69", "title": "In-Context Learning Creates Task Vectors"}, {"paperId": "73dd6fce2db3e34d1f87f8449b1e8bde78c31547", "title": "Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve"}, {"paperId": "71d68782c3da41b77866c2fd0cb65726f60b3af1", "title": "Analyzing Chain-of-Thought Prompting in Large Language Models via Gradient-based Feature Attributions"}, {"paperId": "cf7368f38cc1f0861d4b35db1307776c7f3f237d", "title": "In-Context Learning Learns Label Relationships but Is Not Conventional Learning"}, {"paperId": "827afa7dd36e4afbb1a49c735bfbb2c69749756e", "title": "Measuring Faithfulness in Chain-of-Thought Reasoning"}, {"paperId": "4487bdcf1eb42bdec83709ba0df5b32dcf388976", "title": "What and How does In-Context Learning Learn? Bayesian Model Averaging, Parameterization, and Generalization"}, {"paperId": "c2260403fd5cb2de73491323433e48b6ec36872c", "title": "Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective"}, {"paperId": "7b7649b59d62d2ebfb3c34b7bc91204b9b7cefe8", "title": "Retentive or Forgetful? Diving into the Knowledge Memorizing Mechanism of Language Models"}, {"paperId": "7fa85f9c0fe44f1bf9e58a55f0f009296578c2f0", "title": "What In-Context Learning \"Learns\" In-Context: Disentangling Task Recognition and Task Learning"}, {"paperId": "7dc928f41e15f65f1267bd87b0fcfcc7e715cb56", "title": "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting"}, {"paperId": "35922cd0d6b17e45320917338e9f98cb5c1a4f6f", "title": "Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters"}, {"paperId": "6845bea94b2fb17d4377b3bb2bd10f73a959f9cc", "title": "Reasoning with Language Model Prompting: A Survey"}, {"paperId": "097dc73d5d422b3c09286e72d16b2561ae5fb395", "title": "Complementary Explanations for Effective In-Context Learning"}, {"paperId": "663a41c866d49ce052801fbc88947d39764cad29", "title": "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them"}, {"paperId": "e7028cd7ea838ab8294ecf26d5a2c0dbb8cfa81a", "title": "Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought"}, {"paperId": "7ce0c89a452e3c2917b63847495533865697c79c", "title": "Can Large Language Models Truly Understand Prompts? A Case Study with Negated Prompts"}, {"paperId": "4988b3d378b79eb8669112620baf1ff4e3e536fd", "title": "Text and Patterns: For Effective Chain of Thought, It Takes Two to Tango"}, {"paperId": "e850d4c0dad3aee3b8b40be5e5d5e5c31354d8cc", "title": "PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "9ffefdf1fcd780cb71450b0a7a29247c66aa87be", "title": "The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning"}, {"paperId": "146e9e1238ff6caf18f0bd936ffcfbe1e65d2afd", "title": "Data Distributional Properties Drive Emergent In-Context Learning in Transformers"}, {"paperId": "5f19ae1135a9500940978104ec15a5b8751bc7d2", "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"}, {"paperId": "f4df78183261538e718066331898ee5cad7cad05", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"}, {"paperId": "af46b5ee6d0c1aada1c482d53018a50909aa4c90", "title": "Impact of Pretraining Term Frequencies on Few-Shot Reasoning"}, {"paperId": "10bd4160b44803ada6a3d2e366c44b7e2a4ffe90", "title": "An Explanation of In-context Learning as Implicit Bayesian Inference"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "5ec78104de5e8d3fd0e0307e6e8559d0ce1e996f", "title": "In the End Was the Word"}, {"paperId": "2ceab7e0f9d28d78c89fcf498f189b2882e8bff9", "title": "Reasoning about knowledge"}, {"paperId": "8f71a9729ae782fa0d3b077d8cba97fcc636e70e", "title": "Reasoning about a Rule"}, {"paperId": null, "title": "non-word-initial tokens; thus, to be precise that we used were 3-letter word-initial 4-letter non-word-initial tokens. Following et al. ("}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "dd0e29a50c1790a59605d51fb2724d4e8c0d1922", "title": "Psychology of Reasoning: Structure and Content"}, {"paperId": null, "title": "Dissecting Chain-of-Thought: Compositionality through In-Context Filtering and Learning"}, {"paperId": null, "title": "The Standard prompt (Figure 5) used is adopted from McCoy et al. (2023) and yields poor performance on most shift levels. The Number-CoT prompt (Figure 6) in contrast gives nearly perfect"}, {"paperId": null, "title": "used to evaluate GPT-4, and a subset containing words used to evaluate logistic regression models that were fitted to GPT-4\u2019s performance on the 100-word subset"}, {"paperId": null, "title": "2022. Folio: Natural language reasoning with first-order logic"}, {"paperId": null, "title": "2024. Gpt-4 technical report"}, {"paperId": null, "title": "quotation mark in the context of \u2018 The word is \" \u2019. The closing quotation mark is included because it"}, {"paperId": null, "title": "assigns to the sentence \u2018 The word is \"WORD\" \u2019, minus the log probability that it assigns to \u2018 The word is \" \u2019"}, {"paperId": null, "title": "Noisy reasoning is like symbolic reasoning but with the addition of noise that introduces some possibility of each intermediate operation in a reasoning step being wrong"}, {"paperId": null, "title": "2023. Language models show human-like content effects on reasoning tasks"}, {"paperId": null, "title": "these 100-example sets"}]}