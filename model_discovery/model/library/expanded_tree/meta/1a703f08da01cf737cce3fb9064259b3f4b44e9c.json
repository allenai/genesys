{"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "abstract": "We show the formal equivalence of linearised self-attention mechanisms and fast weight controllers from the early '90s, where a ``slow\"neural net learns by gradient descent to program the ``fast weights\"of another net through sequences of elementary programming instructions which are additive outer products of self-invented activation patterns (today called keys and values). Such Fast Weight Programmers (FWPs) learn to manipulate the contents of a finite memory and dynamically interact with it. We infer a memory capacity limitation of recent linearised softmax attention variants, and replace the purely additive outer products by a delta rule-like programming instruction, such that the FWP can more easily learn to correct the current mapping from keys to values. The FWP also learns to compute dynamically changing learning rates. We also propose a new kernel function to linearise attention which balances simplicity and effectiveness. We conduct experiments on synthetic retrieval problems as well as standard machine translation and language modelling tasks which demonstrate the benefits of our methods.", "venue": "International Conference on Machine Learning", "year": 2021, "citationCount": 151, "influentialCitationCount": 18, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work infer a memory capacity limitation of recent linearised softmax attention variants, and replaces the purely additive outer products of self-invented activation patterns by a delta rule-like programming instruction, such that the FWP can more easily learn to correct the current mapping from keys to values."}, "embedding": {"model": "specter_v2", "vector": [-0.08505184203386307, 0.9741275906562805, -0.5241535305976868, 0.0783449336886406, -0.13103711605072021, -0.019786003977060318, 0.7264542579650879, -0.11045468598604202, -0.7985340356826782, -0.4786407947540283, 0.15454965829849243, 0.15487098693847656, 0.31146761775016785, -0.0404282808303833, -0.6298754811286926, -0.06810005754232407, -0.9209705591201782, 0.2112058848142624, 0.3299872577190399, -0.4068206548690796, 0.13964268565177917, -0.7088834047317505, -0.9148857593536377, 0.2955797612667084, 0.20616118609905243, 0.8245851993560791, -0.01659310609102249, 0.8362747430801392, -0.47465780377388, 0.5044071674346924, 0.7722597718238831, -0.2812437117099762, 0.36909055709838867, 0.43849295377731323, -0.16646024584770203, -0.520151674747467, 0.36481860280036926, -0.05059266835451126, -0.5992915034294128, 0.9175596237182617, -0.22458337247371674, -0.026360096409916878, 0.06973539292812347, -0.43745142221450806, -0.7018582820892334, 0.9176053404808044, 0.6676850318908691, 0.7838404178619385, -0.6308658719062805, -0.3646937608718872, 1.1239944696426392, -1.4201769828796387, 0.08692657202482224, 1.3305397033691406, 0.6340650916099548, 0.20119136571884155, -0.16574588418006897, -0.6487528085708618, 0.8822108507156372, 0.12210268527269363, -1.0296629667282104, -0.7310714721679688, -0.2997342050075531, 0.1621541529893875, 1.844583511352539, -0.4450032711029053, -0.08274108916521072, 0.021601425483822823, 0.2670453190803528, 1.579726219177246, 0.056154873222112656, -0.8785510063171387, -0.27486103773117065, 0.7898111343383789, 0.2643374800682068, 1.1929949522018433, -0.31694456934928894, 0.3668093979358673, -0.9285486936569214, -0.23316696286201477, 0.523697555065155, -0.06727351993322372, -0.026636572554707527, -0.8258967399597168, -0.05277908220887184, 0.6793469786643982, 0.8036669492721558, 0.7536930441856384, -0.372609406709671, 1.2127556800842285, 0.2436213195323944, 0.7859289050102234, 0.2821043133735657, 0.33858606219291687, -0.11881254613399506, 0.3330628573894501, -0.8128322958946228, -0.09128162264823914, -0.08889594674110413, 0.8954954743385315, 0.1947646141052246, 0.5147412419319153, -0.39494284987449646, 0.5119993686676025, 1.3548628091812134, 0.361881822347641, 1.1644726991653442, -0.39764636754989624, 0.16826023161411285, -0.6739340424537659, -0.054370686411857605, -0.6622114777565002, -0.02974640764296055, -0.5102699995040894, -0.6455759406089783, -1.231430172920227, -0.5436626672744751, 0.34626010060310364, -0.8530689477920532, 0.7271283864974976, -0.5158013701438904, -0.2871456742286682, -0.10610336065292358, 0.4878608286380768, 0.2193140983581543, 0.7019556760787964, 0.48966631293296814, 0.38557708263397217, 1.012494444847107, -0.7484421730041504, -0.35919564962387085, -1.0374644994735718, 0.7787204384803772, 0.21200041472911835, 0.2512779235839844, -0.04470547288656235, -1.7418735027313232, -0.9630782008171082, -0.7755358815193176, 0.15796522796154022, -0.8099978566169739, 0.10713685303926468, 1.2266125679016113, 0.527569055557251, -1.0919606685638428, 1.1077420711517334, -0.17025884985923767, -0.04543748497962952, 0.7102872729301453, 0.8053165674209595, 0.3155791461467743, -0.17376941442489624, -1.3743209838867188, 0.49440881609916687, 0.42866992950439453, -0.47074374556541443, 0.3451647460460663, -0.7295613884925842, -0.9962032437324524, 0.1554785817861557, 0.5988005995750427, -0.7354844212532043, 1.2426354885101318, -0.5688410997390747, -1.327735424041748, 0.8552566766738892, 0.006479816976934671, -0.15344935655593872, 0.10217931121587753, -0.23852689564228058, -0.4092289209365845, -0.4636622369289398, -0.7665918469429016, 0.6549113988876343, 0.9504690766334534, -0.42370644211769104, -0.4032283127307892, 0.1404893398284912, -0.25378209352493286, -0.021214155480265617, -0.646040678024292, 0.7630153894424438, -0.5693206787109375, -0.1560802012681961, 0.4778100848197937, 0.45819854736328125, 0.2440243810415268, -0.09597330540418625, 0.07321576029062271, -1.0957825183868408, 0.08959732204675674, 0.3048717677593231, 1.182927131652832, -1.211817979812622, -0.5895135998725891, 0.24288108944892883, -0.0032730703242123127, -0.0335775688290596, -0.7331653833389282, 0.2775120437145233, -0.6664939522743225, 0.20816999673843384, -0.052496287971735, -0.8229452967643738, 0.4407287836074829, -0.2927570044994354, -0.6374868154525757, 0.07882574200630188, 0.003681301139295101, 1.3729255199432373, -1.0781242847442627, 0.03763827681541443, -0.22127650678157806, 0.32825934886932373, -0.7173492312431335, 1.3008848428726196, -0.11434787511825562, -0.7802806496620178, 0.29660606384277344, -0.21408098936080933, -0.21769006550312042, -0.12163634598255157, 0.09548206627368927, -0.5931979417800903, 0.01744280941784382, 0.10920421034097672, -0.26903146505355835, 1.159646987915039, -0.5166352391242981, 0.5036577582359314, 0.13005195558071136, -0.6771227121353149, -0.15986274182796478, 0.49447527527809143, -0.23067356646060944, -0.6957395076751709, 0.1824636161327362, 0.3011869490146637, -0.5432745218276978, 0.2948053777217865, 0.75917649269104, 0.7411326169967651, -0.24619106948375702, 0.07232816517353058, 0.7263005375862122, -0.17173442244529724, 0.0222252756357193, 0.1305234134197235, 0.43623265624046326, 0.34041714668273926, 0.5269944667816162, -0.2953830659389496, 0.336893767118454, -0.8736264109611511, -0.21318887174129486, 0.8500357866287231, 0.9789441227912903, 0.7865799069404602, -0.034315939992666245, -0.856653094291687, -0.3335609436035156, -0.2737031877040863, 0.5907129645347595, 1.8016431331634521, -0.4996744990348816, 0.10436609387397766, -0.4793102443218231, 0.03637218847870827, -0.28459715843200684, 0.09554801881313324, -0.28786298632621765, -0.6801985502243042, -0.9456957578659058, -1.138857126235962, 0.5714015364646912, 0.27415528893470764, 0.9060915112495422, -0.5523237586021423, -0.39645853638648987, -0.03961758688092232, 0.8868806958198547, -0.22957627475261688, -0.9407998919487, 0.5852025747299194, -0.5245890021324158, 0.21790318191051483, -0.2532031536102295, 0.05735985189676285, 0.47524702548980713, -0.42922282218933105, 0.8336743116378784, -0.43513742089271545, -0.1999075710773468, 0.3715970516204834, 0.831023097038269, -0.9369432926177979, -0.44603201746940613, 0.5137115120887756, 0.35741084814071655, 0.17024724185466766, 0.0682801678776741, 0.6035139560699463, -0.443806529045105, -0.18379415571689606, -0.4719136357307434, -0.07399021834135056, 0.6796705722808838, 0.20800508558750153, 0.09892107546329498, -0.3933504521846771, 0.02127940207719803, -1.6846470832824707, 1.225028395652771, 0.08655843883752823, -0.312506765127182, 0.2659776508808136, -1.134857177734375, 0.09383808821439743, 0.31835854053497314, -0.9114371538162231, -0.023454289883375168, -0.8049328327178955, 0.22789371013641357, -0.36607035994529724, 0.06005345284938812, 0.1285199522972107, 0.5012163519859314, -0.3358478546142578, 0.18732517957687378, 0.527951180934906, 0.44912391901016235, 0.12675891816616058, 0.7278075814247131, -0.9011853337287903, 0.7615795135498047, 0.047689128667116165, 0.46009549498558044, -0.09130053967237473, -0.5486105680465698, -0.4334130585193634, -0.1589154750108719, -0.2396339476108551, 0.09085534512996674, -0.05333999544382095, -0.28690049052238464, -0.6566088199615479, -1.1932978630065918, -0.1707732379436493, -0.6545135378837585, -0.6101144552230835, -0.342247873544693, -0.5139530301094055, -0.17375540733337402, -1.096100926399231, -1.2414613962173462, -0.7729910016059875, -0.8302555680274963, -0.5756972432136536, -0.010520813055336475, 0.05816610902547836, -0.5186493992805481, -0.5861710906028748, -0.20113806426525116, -0.8905329704284668, 1.8505557775497437, -1.323909878730774, 0.6226837635040283, 0.27020785212516785, -0.2888798415660858, -0.6056457161903381, 0.14897862076759338, 0.3753308951854706, -0.5367400646209717, -0.19665338099002838, -0.8877483010292053, 0.07572982460260391, -0.3168709874153137, -0.3178926110267639, 0.3025330901145935, 0.35241907835006714, 0.7804679274559021, -0.3607015311717987, -0.5012404918670654, 0.32621535658836365, 1.3401434421539307, -0.5762856602668762, 0.22981983423233032, 0.3051553964614868, 0.936215341091156, 0.11356041580438614, -0.5973566770553589, 0.13272076845169067, 0.37473928928375244, 0.6142427921295166, 0.011160665191709995, -0.41283416748046875, 0.004138188436627388, -0.3786495327949524, 0.550134003162384, 1.453695297241211, 0.2520117163658142, 0.33578041195869446, -0.49575746059417725, 0.414664626121521, -1.390053153038025, -0.6618407964706421, 0.8817347884178162, 1.1296783685684204, 0.6296727061271667, -0.016815200448036194, -0.363459050655365, -0.5787560939788818, 0.07996043562889099, 0.1329651027917862, -0.2645983099937439, -0.7834154367446899, -0.07793401181697845, 0.7317348718643188, 0.9350818395614624, 0.6682619452476501, -0.3294754922389984, 0.9215731620788574, 14.780757904052734, 0.5811715722084045, -0.2052607238292694, 0.902251124382019, 0.2457810491323471, 0.018404947593808174, -0.09690386801958084, -0.13560374081134796, -0.8765118718147278, -0.039181485772132874, 1.1395984888076782, 0.35826167464256287, 0.6379040479660034, 0.12727302312850952, -0.30545929074287415, 0.16834136843681335, -0.40407976508140564, 0.7601022720336914, 0.5761513710021973, -1.1556077003479004, -0.06625040620565414, 0.0935530960559845, 0.01848580688238144, 0.6593531370162964, 0.9903631806373596, 0.9157240390777588, 0.691956639289856, -0.02179350145161152, 0.5351751446723938, 1.0234103202819824, 0.8242642283439636, 0.19297939538955688, -0.013909917324781418, 0.267901748418808, -0.420711874961853, -0.566438615322113, -0.5132206082344055, -0.6554795503616333, 0.12242898344993591, 0.1029813289642334, -0.2188730388879776, -0.7860873937606812, -0.2731166183948517, 0.1023215502500534, -0.09607992321252823, 0.5998221039772034, 0.04873158037662506, 0.5905187129974365, -0.4113042652606964, 0.07462020963430405, 0.062358204275369644, 0.7271336317062378, -0.24987825751304626, 0.2201235592365265, 0.031392067670822144, 0.08494797348976135, -0.2767089903354645, 0.6002581715583801, -0.47295036911964417, -0.19829799234867096, -0.05825885385274887, -0.08260703086853027, -0.3077569305896759, 0.7980269193649292, 0.8489482402801514, -0.0778842344880104, -0.02693193592131138, 0.5276505351066589, 0.6848787665367126, 0.262177437543869, -0.19206282496452332, -0.16364578902721405, 0.21918034553527832, -0.26793986558914185, -0.15533483028411865, 0.2948574423789978, 0.0595797635614872, -0.639062762260437, -0.925469696521759, -0.1869605928659439, 0.2853005826473236, -0.9492952823638916, -0.48099029064178467, 0.7604715824127197, -0.21433113515377045, -0.050628867000341415, 0.42755794525146484, -0.7956167459487915, 0.03798197582364082, 0.2781978249549866, -1.2864936590194702, -0.46947717666625977, 0.4058586061000824, -0.6370776295661926, -0.5224461555480957, -0.23543326556682587, 1.1849347352981567, 0.04435751959681511, -0.29481804370880127, 0.34379827976226807, 0.07170382887125015, -0.22522708773612976, 0.13059917092323303, -0.8788391351699829, 0.6994418501853943, -0.2731122374534607, 0.19841475784778595, 0.6973073482513428, 0.014215231873095036, 0.30700981616973877, -1.256302833557129, 0.5439225435256958, 0.8054531216621399, -0.9343370795249939, -0.4706973135471344, -0.8090541958808899, -0.968086302280426, 0.1441635936498642, 0.6289077401161194, -0.12217272818088531, -0.05253114178776741, 0.06707331538200378, -0.6178449988365173, -0.5879161953926086, -0.5179904103279114, 0.047313328832387924, 0.22866855561733246, -0.7806975245475769, -0.3574919104576111, -0.019673176109790802, -0.03819172456860542, -0.9253718852996826, -0.3254694938659668, -0.28394755721092224, 0.21294231712818146, 0.17195546627044678, 1.3677129745483398, -0.46479207277297974, 0.26184695959091187, 0.8716961741447449, 0.5114033222198486, -0.8604130148887634, -0.5785927772521973, -0.5937566161155701, -0.3929428458213806, -0.06062127649784088, 0.4743300974369049, -0.7693973779678345, 0.3636605739593506, 1.1341161727905273, 0.06900541484355927, -0.4805338680744171, -0.45247966051101685, 0.0699339359998703, -0.144975945353508, -0.5577699542045593, 0.14961831271648407, -0.10017850250005722, 0.1942564994096756, -0.026463408023118973, 0.4690735638141632, 0.16760340332984924, -0.0208507739007473, -0.9490482807159424, 0.13393351435661316, 0.01628565788269043, -0.03383059427142143, -0.9401251673698425, -0.41706547141075134, -1.3939753770828247, -0.18101878464221954, -1.3298566341400146, -0.003378885565325618, -0.7654165625572205, -0.6342733502388, -0.22846943140029907, -0.6757122874259949, 0.32919010519981384, 0.4773184359073639, -0.08514122664928436, -0.577724277973175, -0.2000606209039688, -0.5329720377922058, 0.4927964508533478, 0.16281792521476746, -0.7926564812660217, -0.0339457169175148, 0.06798651069402695, -0.2342597246170044, 0.024703284725546837, 0.5292485952377319, -0.5813004970550537, -0.7047607898712158, -1.3197243213653564, 0.9235641956329346, -0.3796372413635254, -0.14334765076637268, -0.631523609161377, 1.2966818809509277, 0.42503783106803894, 0.05605839192867279, 0.3482615649700165, 0.41384485363960266, -1.1332570314407349, -0.5702149868011475, 0.3804442584514618, -0.7110100984573364, 0.288046658039093, 0.348839670419693, -0.8221586346626282, 0.05021875351667404, 0.5536462664604187, -0.09271790832281113, -1.3750754594802856, -0.6305409669876099, 0.2762024998664856, -0.5236386060714722, -0.2724544405937195, -0.5771566033363342, -0.316519558429718, -1.0230315923690796, -0.2611654996871948, -0.00654888991266489, 0.36108630895614624, -0.49318456649780273, 1.0499061346054077, 0.38275083899497986, -1.1078613996505737, 0.28790900111198425, 0.6145300269126892, 0.0224169734865427, -0.18437407910823822, 0.5440309643745422, 0.5236743688583374, -0.2908225655555725, 0.7495572566986084, 0.3104037344455719, 0.5125916004180908, -0.5105311870574951, 0.14051881432533264, 0.8058913350105286, -0.08050137758255005, -0.3204021453857422, 1.146328330039978, -0.2494514286518097, -1.0396554470062256, 0.20865847170352936, -1.3058052062988281, -0.25935399532318115, -0.33737295866012573, 0.15017040073871613, -0.2652983069419861, -0.1045837476849556, 0.18468523025512695, -0.3471248149871826, 0.2795669734477997, -0.20627886056900024, -0.4414336085319519, 0.5927425622940063, -0.26106151938438416, -0.5333617329597473, 0.6168429851531982, 0.7856269478797913, -0.9365965127944946, -0.2922239303588867, -1.23610520362854, -0.19430460035800934, -0.09537113457918167, 0.6023445129394531, -0.26680344343185425, -0.7749986052513123, 0.5961637496948242, 0.981805145740509, -0.010943322442471981, -0.12212494760751724, -0.1543617695569992, -0.05747784301638603, 0.78573077917099, 0.05434487760066986, -1.038174033164978, -0.6690535545349121, 1.1636533737182617, 1.2208929061889648, -0.5463632345199585, 0.43330079317092896, -0.14785122871398926, -0.25489193201065063, 0.8589367270469666, 0.06158433482050896, -0.16026856005191803, 0.9856411814689636, -0.21928074955940247, 0.02309124916791916, -0.03563110902905464, -0.9568924903869629, -0.29927289485931396, 0.9563763737678528, 0.47997456789016724, 0.8711869120597839, 0.18852785229682922, 0.09244679659605026, 0.7117534279823303, 0.04953799769282341, 0.39689669013023376, 0.12457886338233948, 0.6592667102813721, -0.40304359793663025, -0.058051496744155884, -0.07007268816232681, 0.6191719174385071, -0.5178360939025879, -0.5795010328292847, 0.3593250811100006, 0.3671107888221741, 0.3395389914512634, -0.031085912138223648, 0.6973149180412292, 0.10581634938716888, 0.7872121334075928, 0.6217475533485413, 0.6495231986045837, -0.5053388476371765, -0.587270975112915, -0.2880602180957794, -0.7329733371734619, 0.004095949232578278, 0.29928892850875854, -0.4301725924015045, -0.32971543073654175, 0.05288560688495636, 0.08987480401992798, -0.27542176842689514, 0.539879560470581, 0.6949999332427979, 0.6721987724304199, 0.5289837718009949, -0.2868635654449463, -0.6915582418441772, -0.8676645755767822, -0.7485480904579163, 0.14492210745811462, -0.37140020728111267, -0.43583568930625916, -0.18763692677021027, 0.01736806519329548, -0.4805932939052582]}, "authors": [{"authorId": "35328044", "name": "Imanol Schlag"}, {"authorId": "2350348", "name": "Kazuki Irie"}, {"authorId": "145341374", "name": "J. Schmidhuber"}], "references": [{"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "cec7872b194aadf54140578b9be52939eb1112e9", "title": "LambdaNetworks: Modeling Long-Range Interactions Without Attention"}, {"paperId": "76e3ad12881e7ab1c36318d8f8818eca3f828349", "title": "Meta Learning Backpropagation And Improving It"}, {"paperId": "d642868ce4325ebf3026c0aa0c497a079f112a8d", "title": "On the Binding Problem in Artificial Neural Networks"}, {"paperId": "5e11e806d24dd80ecf0f91e7aacedbba8d9fd6fc", "title": "Learning Associative Inference Using Fast Weight Memory"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "1ca969119f4f6006047b159e35267d9a1c4afe8b", "title": "On the Modularity of Hypernetworks"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "804a6d7c23335bbca6eec3b7d3c8366dcbe395a5", "title": "Hopfield Networks is All You Need"}, {"paperId": "a88c5474d96a6629bd1f36c3c6c06242034cb0a4", "title": "How Much Self-Attention Do We Need\u0192 Trading Attention for Feed-Forward Layers"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "96b7abb1d35ec4bd6822f5a55996b3c4dd5c91ae", "title": "Training Language Models for Long-Span Cross-Sentence Evaluation"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "8cef9900c04d7f661c08f4b5b1ed4337ace042a3", "title": "Transformer Dissection: An Unified Understanding for Transformer\u2019s Attention via the Lens of Kernel"}, {"paperId": "a513bb6e1967f5a31ad4f38954e66d4169b613e5", "title": "Metalearned Neural Memory"}, {"paperId": "3928b2177086532775fbf607ae3e05a0375a5061", "title": "Language Modeling with Deep Transformers"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "5f4a22ee70ca613d9c0630eafc96364fe365fdf8", "title": "Efficient Attention: Attention with Linear Complexities"}, {"paperId": "f6fa98b0d1f6bff608a056acd7b82e2a9dd0a68e", "title": "Learning to Reason with Third-Order Tensor Products"}, {"paperId": "146c231532d4e38de95e63368dcd09d0f8cea291", "title": "Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "b9de9599d7241459db9213b5cdd7059696f5ef8d", "title": "Character-Level Language Modeling with Deeper Self-Attention"}, {"paperId": "b48f327d8f2515216ac19314a58292c43bb53422", "title": "Metalearning with Hebbian Fast Weights"}, {"paperId": "bf8fe437f779f2098f9af82b534aa51dc9edb06f", "title": "Scaling Neural Machine Translation"}, {"paperId": "b4bfadfca9742bb3ee98a0cd322d5ce4e59a3ceb", "title": "A Call for Clarity in Reporting BLEU Scores"}, {"paperId": "249ac07c5b87f44b85500e2d26b68a7edb93e83d", "title": "Differentiable plasticity: training plastic neural networks with backpropagation"}, {"paperId": "7cfa5c97164129ce3630511f639040d28db1d4b7", "title": "FiLM: Visual Reasoning with a General Conditioning Layer"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "204a4a70428f3938d2c538a4d74c7ae0416306d8", "title": "A Structured Self-attentive Sentence Embedding"}, {"paperId": "470d11b8ca4586c930adbbfc3f60bff08f2a0161", "title": "Meta Networks"}, {"paperId": "84bad036fbe21a024975cefa71785930fdec758e", "title": "On a Model of Associative Memory with Huge Storage Capacity"}, {"paperId": "c91ae35dbcb6d479580ecd235eabf98374acdb55", "title": "Using Fast Weights to Attend to the Recent Past"}, {"paperId": "563783de03452683a9206e85fe6d661714436686", "title": "HyperNetworks"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "2cd8e8f510c89c7c18268e8ad51c061e459ad321", "title": "A Decomposable Attention Model for Natural Language Inference"}, {"paperId": "ed332c92664cd64843a7ba9373d992e9547230f6", "title": "Dense Associative Memory for Pattern Recognition"}, {"paperId": "aba48504f4f9563eafa44e0cfb22e1345d767c80", "title": "Dynamic Filter Networks"}, {"paperId": "13fe71da009484f240c46f14d9330e932f8de210", "title": "Long Short-Term Memory-Networks for Machine Reading"}, {"paperId": "f63e917638553414526a0cc8550de4ad2d83fe7a", "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)"}, {"paperId": "385c18cc4024a3b3206c508c512e037b9c00b8f3", "title": "Image Question Answering Using Convolutional Neural Network with Dynamic Parameter Prediction"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "4d674fc145bb30a09d3ec41aaed327cf6016becb", "title": "A Dynamic Convolutional Layer for short rangeweather prediction"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "6471fd1cbc081fb3b7b5b14d6ab9eaaba02b5c17", "title": "Generating Sequences With Recurrent Neural Networks"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "61639af1a89c69094bcc0ed40fad752832b037c3", "title": "Reducing the Ratio Between Learning Complexity and Number of Time Varying Variables in Fully Recurrent Nets"}, {"paperId": "bc22e87a26d020215afe91c751e5bdaddd8e4922", "title": "Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks"}, {"paperId": "7826ff60d2dfb24d2af18c5bc565c357ef9db4c1", "title": "A stochastic version of the delta rule"}, {"paperId": "9fccf16e5205eaa44aa084b785372df1a0b44255", "title": "Dynamic connections in neural networks"}, {"paperId": "62fe57e40232add7ede5a683b31e643fc0712c9f", "title": "Bidirectional associative memories"}, {"paperId": "98b4d4e24aab57ab4e1124ff8106909050645cfa", "title": "Neural networks and physical systems with emergent collective computational abilities."}, {"paperId": "86a156a7cc6c63739d8c11684628056a3edd9b6d", "title": "The existence of persistent states in the brain"}, {"paperId": "d7f7f6dfbdbe5220aded6a211c50079e28b217ad", "title": "Correlation Matrix Memories"}, {"paperId": "6ca3455b28e165ab5c772bdb6048c312d06d1d1e", "title": "Learning Matrices and Their Applications"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "11503f8f1d94607b46f58ad4188facdadf257fe4", "title": "Gated Fast Weights for On-The-Fly Neural Program Generation"}, {"paperId": "85d346297ec37a451d4500afad53fed8f281af92", "title": "Adaptive Switching Circuits"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": "3c95c806c47a7afcf3301a5608b13c22079a97f9", "title": "Die Lernmatrix"}, {"paperId": "e62f7643f616aaad65ffd47155a53bfa325e455d", "title": "The Correlation Theory of Brain Function"}, {"paperId": "9438172bfbb74a6a4ea4242b180d4335bb1f18b7", "title": "Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems"}, {"paperId": null, "title": "Neural nets learn to program neural nets with fast weights\u2014like today\u2019s Transformer variants"}, {"paperId": "386db34312f780b8c1b01f43cbe6d2a19f8c97aa", "title": "Associative memory"}, {"paperId": "7257eacd80458e70c74494eb1b6759b52ff21399", "title": "Using fast weights to deblur old memories"}, {"paperId": null, "title": "The organization of behavior: a neuropsy-cholocigal theory"}, {"paperId": null, "title": "Linear Transformers Are Secretly Fast Weight Programmers Ba"}]}