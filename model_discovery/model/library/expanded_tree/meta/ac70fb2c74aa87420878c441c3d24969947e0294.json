{"paperId": "ac70fb2c74aa87420878c441c3d24969947e0294", "abstract": "Artificial neural networks have emerged as computationally plausible models of human language processing. A major criticism of these models is that the amount of training data they receive far exceeds that of humans during language learning. Here, we use two complementary approaches to ask how the models\u2019 ability to capture human fMRI responses to sentences is affected by the amount of training data. First, we evaluate GPT-2 models trained on 1 million, 10 million, 100 million, or 1 billion words against an fMRI benchmark. We consider the 100-million-word model to be developmentally plausible in terms of the amount of training data given that this amount is similar to what children are estimated to be exposed to during the first 10 years of life. Second, we test the performance of a GPT-2 model trained on a 9-billion-token dataset to reach state-of-the-art next-word prediction performance on the human benchmark at different stages during training. Across both approaches, we find that (i) the models trained on a developmentally plausible amount of data already achieve near-maximal performance in capturing fMRI responses to sentences. Further, (ii) lower perplexity\u2014a measure of next-word prediction performance\u2014is associated with stronger alignment with human data, suggesting that models that have received enough training to achieve sufficiently high next-word prediction performance also acquire representations of sentences that are predictive of human fMRI responses. In tandem, these findings establish that although some training is necessary for the models\u2019 predictive ability, a developmentally realistic amount of training (\u223c100 million words) may suffice.", "venue": "bioRxiv", "year": 2023, "citationCount": 12, "influentialCitationCount": 1, "openAccessPdf": {"url": "https://direct.mit.edu/nol/article-pdf/doi/10.1162/nol_a_00137/2214268/nol_a_00137.pdf", "status": "GOLD"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is established that although some training is necessary for the models\u2019 predictive ability, a developmentally realistic amount of training may suffice and lower perplexity\u2014a measure of next-word prediction performance\u2014is associated with stronger alignment with human data, suggesting that models that have received enough training to achieve sufficiently high next- word prediction performance also acquire representations of sentences that are predictive of human fMRI responses."}, "embedding": {"model": "specter_v2", "vector": [0.30358749628067017, 0.9665573239326477, 0.16063575446605682, -0.3184753954410553, 0.18181577324867249, 0.34526553750038147, 0.5015561580657959, -0.645528256893158, -0.5726564526557922, -0.2659675180912018, 0.6161854267120361, 0.12602224946022034, 0.3919689357280731, 0.17842857539653778, 0.13190388679504395, 0.3903488218784332, -1.124037504196167, 0.17546936869621277, -0.08157623559236526, -0.16148065030574799, -0.3810839354991913, -0.9051916599273682, -1.2086595296859741, 0.1479950100183487, 0.24982793629169464, 0.2176281064748764, 0.3810044527053833, 0.8770138621330261, 0.05138583481311798, 0.5454006791114807, 0.47034162282943726, -0.5232778787612915, 0.3488996922969818, -0.16456983983516693, -0.4690142571926117, -0.19382916390895844, 0.6461279988288879, -0.8124625086784363, -0.8593748211860657, 0.6372628211975098, -0.2994660437107086, 0.2668440639972687, 0.3239124119281769, -0.09838080406188965, -0.36654776334762573, 0.9955450296401978, 0.5952323079109192, 0.8849921822547913, -0.1902497112751007, -0.21107777953147888, 1.1479616165161133, -1.2806265354156494, 0.45692119002342224, 1.7865341901779175, 0.21535459160804749, 0.7902689576148987, -0.17329537868499756, -0.5209108591079712, 0.6596482992172241, -0.5081817507743835, -0.4432375729084015, -0.3018816411495209, 0.0875396654009819, -0.4834728240966797, 1.5603117942810059, -0.7773326635360718, 0.49600112438201904, 0.8612675666809082, 0.12947696447372437, 1.3674851655960083, 0.29391857981681824, -1.056221604347229, -0.4607737958431244, 0.06993364542722702, 0.48141270875930786, 0.8653032779693604, -0.23751462996006012, 0.44180381298065186, -1.1393991708755493, 0.2220037281513214, 0.8188145160675049, -0.3601440489292145, 0.12137068063020706, 0.6226117014884949, -0.7800557017326355, 0.582561731338501, 0.16870486736297607, 1.0865622758865356, -0.4645746648311615, 0.696499764919281, 0.5013500452041626, 0.3476608693599701, -0.05320564657449722, 0.20031100511550903, -0.2906050980091095, 0.7871426939964294, -1.0404986143112183, 0.10225660353899002, -0.30120015144348145, 0.807659387588501, -0.23233363032341003, 0.6260647773742676, -1.233247995376587, 0.37456512451171875, 1.3748252391815186, -0.14259332418441772, 0.7522623538970947, -0.7071273326873779, 0.4282379150390625, -0.856707751750946, -0.05394104868173599, -0.8795475363731384, -0.3877456486225128, -0.09225032478570938, -0.6660057306289673, -1.4420431852340698, -0.03623460233211517, -0.27449262142181396, -1.0727096796035767, 1.1204514503479004, -0.04295986890792847, -0.11026237159967422, -0.24852021038532257, 0.4734794497489929, 0.5453389286994934, 0.5044555068016052, 0.38794437050819397, 0.18653446435928345, 1.0106924772262573, -0.30264371633529663, -0.2704531252384186, -1.0755895376205444, 0.13810069859027863, 0.09424547106027603, 0.31207916140556335, -0.09700939804315567, -1.3770184516906738, -1.2444064617156982, -0.775741457939148, 0.17775851488113403, -0.07676217705011368, 0.1179407387971878, 1.6506141424179077, 0.5803261399269104, -1.1300822496414185, 1.024767518043518, -0.2591933608055115, -0.2864668667316437, 0.5201439261436462, 0.1540621519088745, -0.16732744872570038, -0.22581329941749573, -1.5971487760543823, 0.4820558726787567, 0.48285818099975586, -0.5499131679534912, -0.20250651240348816, -0.161237895488739, -0.9542366862297058, -0.00627098185941577, -0.06920316815376282, -0.7003089785575867, 1.0119965076446533, -0.43458279967308044, -0.7823209166526794, 1.3276374340057373, -0.383423388004303, -0.052493251860141754, -0.16498656570911407, 0.024568842723965645, -0.5608677864074707, 0.2588602900505066, -0.04205872118473053, 1.0614808797836304, 0.10655290633440018, -0.04168650507926941, 0.07402846217155457, 0.04377025365829468, -0.76856529712677, -0.5234271287918091, -0.4212442934513092, 1.0626046657562256, -0.29413050413131714, -0.759052574634552, 0.5015528798103333, 0.6520934700965881, 0.0034121714998036623, -0.08406398445367813, -0.44641852378845215, -0.8960703015327454, -0.34347546100616455, -0.5608686208724976, 0.6908249855041504, -0.7183524966239929, -1.0760164260864258, -0.17364194989204407, 0.060462430119514465, -0.34345540404319763, -0.8062370419502258, 0.2651408910751343, -0.19929176568984985, 0.656234860420227, -0.49105679988861084, -0.9183669090270996, -0.2100684940814972, -0.4475056529045105, -0.13651633262634277, -0.09668099880218506, 0.3635886013507843, 1.0033040046691895, -0.7043793201446533, -0.17998935282230377, -0.24452143907546997, 0.05193571373820305, -0.7177404761314392, 0.6962095499038696, -0.26524797081947327, 0.5186955332756042, -0.2104385495185852, -0.4593530297279358, -0.040761444717645645, -0.21864743530750275, 0.16657361388206482, 0.08564683794975281, -0.020332619547843933, 0.4197036623954773, 0.12570123374462128, 1.3059719800949097, 0.16051264107227325, 0.7744187712669373, -0.3327462673187256, -1.0326021909713745, -0.11623530834913254, 0.878470242023468, -0.24865175783634186, -0.618796169757843, 0.2783607542514801, 0.1441134214401245, -0.06357374787330627, -0.21684645116329193, -0.011020050384104252, 0.5463883876800537, -0.3317524492740631, 0.40233734250068665, 0.5563206672668457, 0.0028951503336429596, 0.4962632954120636, 0.11030164361000061, 0.37878721952438354, 0.03028520755469799, 0.10657372325658798, -0.37959545850753784, 0.1667916476726532, -1.0863304138183594, 0.29433169960975647, 0.5511482357978821, 0.6546289324760437, 0.7057377696037292, 0.6032249927520752, -1.0501757860183716, -0.5048612952232361, -0.09429358690977097, 0.4657066762447357, 0.9126673340797424, -0.9778838157653809, 0.5614380836486816, -0.9724565744400024, -0.04886452108621597, -0.546381413936615, 0.40000978112220764, -0.4423316717147827, 0.06909078359603882, -0.596365213394165, -0.9707499146461487, 0.5076282620429993, 0.21597829461097717, 0.920823872089386, -1.1457828283309937, -0.6730847358703613, -0.21912328898906708, 0.5903905034065247, -0.9057774543762207, -0.4722239077091217, -0.4005415737628937, -0.607627809047699, 0.18035849928855896, -0.3368194103240967, -0.5323153138160706, 0.27144724130630493, -0.9406406283378601, 0.7048658132553101, -0.10211283713579178, -0.5411612391471863, 0.23539960384368896, 0.777687132358551, -0.6112695932388306, -0.6794204711914062, -0.3666725754737854, 0.3181666135787964, -0.38150089979171753, 0.1724432408809662, 0.26065173745155334, -0.4920004606246948, -0.34316200017929077, -0.3277556002140045, 0.7141441702842712, 0.19827228784561157, 0.44901588559150696, 0.298887699842453, -0.15553024411201477, 0.496858686208725, -1.0805141925811768, 0.5220168232917786, 0.11334960907697678, -0.6002124547958374, 0.5835115313529968, -0.14773252606391907, -0.14953507483005524, 0.6828758120536804, -0.6797868609428406, -0.6100894808769226, -0.8640691637992859, 0.34962230920791626, 0.2762497365474701, -0.5633894801139832, 0.5720090270042419, 0.6758715510368347, 0.26210880279541016, -0.07295815646648407, 0.153156578540802, 0.13949090242385864, 0.3590962588787079, 0.12466011941432953, -0.8452220559120178, 0.40860840678215027, 0.2672365605831146, -0.005880043841898441, -0.11195914447307587, -0.20791108906269073, -1.048500895500183, -0.5754601359367371, 0.408174991607666, -0.4587634205818176, -0.35063719749450684, 0.4223640263080597, -0.5963018536567688, -0.7031263709068298, 0.10028603672981262, -1.0957599878311157, -0.3838304281234741, 0.3450694978237152, 0.294988214969635, -0.04285552725195885, -0.9122541546821594, -1.2132325172424316, -0.6393597722053528, -0.7597935795783997, -0.6148747205734253, 0.2613636255264282, 0.05465000122785568, -0.6101356744766235, -0.44338780641555786, -0.18075242638587952, -0.09482139348983765, 0.4721766412258148, -0.08716736733913422, 0.9829437732696533, -0.1858058124780655, 0.1448480188846588, -0.41028067469596863, 0.4638389050960541, 0.5751252770423889, -0.4179239571094513, 0.4601188004016876, -0.8807462453842163, 0.2466273009777069, 0.005140600726008415, -0.08120854198932648, 0.46677735447883606, 0.5337555408477783, 0.8208168745040894, 0.16340117156505585, -0.04600416123867035, -0.024338755756616592, 1.2917559146881104, -0.5995175242424011, -0.31411898136138916, -0.7664002776145935, 0.7335917949676514, 0.8541385531425476, -0.6149733066558838, 0.4972867965698242, 0.44084256887435913, -0.006456071510910988, -0.34285110235214233, 0.07128195464611053, -0.27822843194007874, -0.782132089138031, 0.3234601318836212, 1.579845905303955, 0.18046772480010986, -0.09857932478189468, -1.5249584913253784, 0.994712769985199, -0.7502399682998657, -0.6038157343864441, 0.577302873134613, 1.1087992191314697, 0.34467917680740356, -0.1687568724155426, -0.7269147634506226, -0.1993221491575241, 0.6786075234413147, 0.026538154110312462, -0.3999687135219574, -0.44554126262664795, -0.3424273431301117, 0.873188316822052, -0.2142377346754074, 0.24699711799621582, -0.30643078684806824, 0.794349193572998, 14.902552604675293, 0.3433552086353302, -0.03100399859249592, 0.4916984736919403, 1.2412686347961426, 0.26236072182655334, -0.47812560200691223, -0.3402613699436188, -0.6809439063072205, 0.22827157378196716, 1.3274738788604736, 0.5455501079559326, 0.9958631992340088, -0.25080639123916626, 0.27130135893821716, -0.059353072196245193, -0.7781597375869751, 0.5050171613693237, 0.3492036759853363, -0.8835672736167908, 0.5332951545715332, 0.01747145876288414, 0.49675291776657104, 0.5470472574234009, 0.6497623920440674, 0.4478428363800049, 0.038590576499700546, -0.49150320887565613, 0.42943400144577026, 0.5509864687919617, 0.8840002417564392, 0.36490437388420105, 0.07844128459692001, 0.5613488554954529, -0.520806074142456, -0.14683455228805542, -0.49582430720329285, -1.330735683441162, 0.1075369268655777, 0.19464848935604095, -0.47623807191848755, -0.9062718749046326, -0.4557073712348938, 0.08706355094909668, 0.11061232537031174, 0.3876025378704071, -0.6371064782142639, 0.9081047773361206, -0.03779900074005127, -0.3182297348976135, 0.013596114702522755, 1.0144104957580566, 0.24493786692619324, -0.31120091676712036, 0.3265341818332672, 0.1866597682237625, -0.08289086073637009, 0.47703230381011963, -0.6090344190597534, 0.1493922472000122, -0.3212144076824188, -0.1944972574710846, 0.12016253918409348, 0.25849029421806335, 0.045208968222141266, 0.15898248553276062, -0.5775338411331177, 0.29848742485046387, 0.5951168537139893, 0.3116382658481598, 0.39415591955184937, 0.11081451177597046, 0.19786635041236877, -0.606395959854126, -0.11958940327167511, 0.3083157241344452, -0.22413912415504456, -0.7079403400421143, -0.46841728687286377, -0.1606927067041397, 0.14166517555713654, -0.7792935371398926, -0.9562134742736816, 0.6428280472755432, -0.1838577687740326, 0.2522366940975189, 0.17140929400920868, -1.274427890777588, -0.6197319030761719, 0.3841644525527954, -0.9247303009033203, -0.6368353962898254, 0.6389527320861816, -0.14196981489658356, 0.0924341082572937, 0.0377243235707283, 1.1634888648986816, -0.20695433020591736, -0.7156479358673096, 0.1799147129058838, -0.23915927112102509, 0.2689186632633209, -0.5608605146408081, -0.7770676016807556, 1.2251735925674438, 0.6164082884788513, 0.06347697228193283, 0.4842415153980255, -0.13268668949604034, -0.11884991824626923, -0.5105569362640381, 0.3458212614059448, 1.0081675052642822, -0.8477291464805603, -0.4634525775909424, -0.7136368155479431, -0.5690521001815796, 0.23093406856060028, 0.5856994986534119, -0.3640282452106476, 0.3358387053012848, -0.09434870630502701, -0.04593878984451294, -0.14681193232536316, -0.9713737368583679, 0.30560317635536194, 0.492346853017807, -0.6465288400650024, -0.7549782991409302, 0.3189166486263275, 0.31552374362945557, -0.3886652886867523, -0.6718353033065796, -0.18095295131206512, 0.4670174717903137, -0.23477424681186676, 0.58636873960495, -0.8065458536148071, 0.7032983303070068, 1.0332860946655273, 0.3514489233493805, -0.8401170969009399, -0.22484908998012543, -0.8839702606201172, 0.33570557832717896, -0.03564515709877014, 0.5485407114028931, -0.578807532787323, 0.03470654413104057, 1.3556674718856812, 0.4246536195278168, -0.5345754623413086, -0.8206717371940613, 0.02295560948550701, 0.23962658643722534, -0.4045669436454773, 0.37015172839164734, -0.025814279913902283, -0.015850979834794998, -0.013904220424592495, 0.15343508124351501, 0.8391188383102417, -0.19419445097446442, -0.8297500014305115, -0.06355584412813187, -0.5203102827072144, -0.004746757913380861, -0.6098993420600891, -0.44075807929039, -1.1764397621154785, 0.15145699679851532, -0.9035108089447021, 0.03401000052690506, -1.0230813026428223, -0.4570635259151459, 0.5550646781921387, -0.2362889051437378, 0.18113034963607788, 0.031427811831235886, -0.6861717700958252, -0.6603155732154846, -0.8927100300788879, 0.10826627165079117, 0.5432120561599731, 1.0319842100143433, -0.36619704961776733, 0.24424681067466736, 0.01573791168630123, 0.15727366507053375, 0.7024611234664917, 0.592860221862793, -0.09438367187976837, -0.964094877243042, -1.9302648305892944, 0.2976316511631012, 0.19954244792461395, 0.11638307571411133, -0.9316650629043579, 0.6031652092933655, 0.7191598415374756, 0.27044177055358887, -0.16270135343074799, 0.22843298316001892, -0.4405239522457123, -0.6209201216697693, 0.3321811258792877, -0.7278573513031006, -0.04711508750915527, -0.0194314606487751, -0.7484217286109924, -0.04975341632962227, 0.535172700881958, -0.23091313242912292, -1.3745388984680176, -0.47762531042099, 0.7270879149436951, -0.9470354914665222, 0.15380629897117615, -0.3321211040019989, -0.13618645071983337, -0.7905882596969604, -0.1612032800912857, -0.234886035323143, 0.7403097748756409, -0.7993858456611633, 0.7863777875900269, 1.093054175376892, -0.8044943809509277, -0.33514195680618286, 0.4721031188964844, -0.33798593282699585, -0.1048465296626091, 0.7219865322113037, -0.014946273528039455, -0.41517773270606995, 0.7288022041320801, 0.2792731821537018, 0.7439819574356079, -0.49808138608932495, -0.08768201619386673, 0.42900538444519043, -0.04017198458313942, -0.18676550686359406, 1.3931989669799805, 0.11160885542631149, -0.8679505586624146, 0.2635398507118225, -1.2883458137512207, -0.7764217853546143, -0.3382735848426819, 0.5647253394126892, 0.17479455471038818, -0.8655117154121399, -0.21827034652233124, -0.08249115943908691, 0.2108272910118103, 0.002435369649901986, -0.7474623918533325, 0.3942163586616516, 0.04152180626988411, -0.2738460302352905, 0.9170530438423157, 0.378918319940567, -0.7277756333351135, -0.6423432230949402, -0.4463251531124115, -0.0883205458521843, 0.06771839410066605, 0.06424861401319504, -0.23814837634563446, -0.7996646761894226, 1.2117046117782593, 0.4308944642543793, 0.2504494786262512, 0.0827142596244812, -0.14158765971660614, 0.29180216789245605, 0.43894723057746887, 0.38054922223091125, -0.5287588834762573, -0.6531321406364441, 1.097840666770935, 1.0550603866577148, -0.8951343894004822, 0.22493641078472137, -0.19526790082454681, -0.8185012340545654, 0.9047490358352661, 0.7135838270187378, -0.09713368862867355, 0.9644005298614502, -0.9671328067779541, -0.24332772195339203, -0.2847190797328949, -0.9174119830131531, 0.1145370677113533, 1.0917929410934448, 0.7476880550384521, 0.9784904718399048, 0.6458055973052979, -0.25319433212280273, 1.1886913776397705, -0.46036699414253235, -0.17553086578845978, 0.2913118898868561, -0.06883148103952408, -0.36024728417396545, 0.39377567172050476, 0.2360101193189621, 0.8348392248153687, -0.8903443813323975, -0.7377076745033264, 0.22718362510204315, 0.32547566294670105, 0.37740492820739746, 0.556976854801178, 0.6950375437736511, 0.3480817377567291, 0.32879096269607544, 0.39076581597328186, 0.62209153175354, -0.6660137176513672, -0.3743937313556671, -0.33566591143608093, -0.25489842891693115, 0.2209768444299698, -0.37884682416915894, -0.6812512874603271, -0.3552202880382538, 0.47641444206237793, 0.3922099769115448, -0.34662631154060364, 0.017588991671800613, 1.2770589590072632, 0.2334025800228119, 0.026078050956130028, -0.08404926210641861, -0.23957788944244385, -0.09094159305095673, -0.9399308562278748, 0.06658405065536499, -0.7508097290992737, -0.015686871483922005, -0.1625618040561676, 0.005399883259087801, -0.27413636445999146]}, "authors": [{"authorId": "2741157", "name": "Eghbal A. Hosseini"}, {"authorId": "8551292", "name": "Martin Schrimpf"}, {"authorId": "9227100", "name": "Yian Zhang"}, {"authorId": "3644767", "name": "Samuel R. Bowman"}, {"authorId": "2121801234", "name": "Noga Zaslavsky"}, {"authorId": "144733430", "name": "Evelina Fedorenko"}], "references": [{"paperId": "1b5b701f658ef277fd9f37bf4b91d84d44d54c25", "title": "Bridging the data gap between children and large language models"}, {"paperId": "8e377067cdf38a4f35c650542f2e1fab71a09d86", "title": "Graded sensitivity to structure and meaning throughout the human language network"}, {"paperId": "8376e50e81329b3db5049a90851cc0418d071e3d", "title": "Scaling laws for language encoding models in fMRI"}, {"paperId": "c0b52e2eb308d1b823af3582956d246e47899be5", "title": "Lexical semantic content, not syntactic structure, is the main contributor to ANN-brain similarity of fMRI responses in the language network"}, {"paperId": "c04f6d98ca20c7be0da862ca2a3ccbe18febe8b9", "title": "Transformer-Based Language Model Surprisal Predicts Human Reading Times Best with About Two Billion Training Tokens"}, {"paperId": "34a833ed550b82952417f5449e1ede2cc2ec279d", "title": "Driving and suppressing the human language network using large language models"}, {"paperId": "eaee0b647d336c6fc8b844812675ec35cddf14a1", "title": "Why Does Surprisal From Larger Transformer-Based Language Models Provide a Poorer Fit to Human Reading Times?"}, {"paperId": "23e04389f8728a5736382d3662341a1a2a25e171", "title": "Predictive Coding or Just Feature Discovery? An Alternative Account of Why Language Models Fit Brain Data"}, {"paperId": "1be5a2186f0d4f4046f45a8b1703eb65dea8ba79", "title": "Probabilistic atlas for the language network based on precision fMRI data from >800 individuals"}, {"paperId": "1a7a24c73521eecf0a2d555e921b27e2c4d8e3c3", "title": "What Artificial Neural Networks Can Tell Us About Human Language Acquisition"}, {"paperId": "48b96fbd96e3fd3271a40e7cce709ce796f35d03", "title": "Neural Language Models are not Born Equal to Fit Brain Data, but Training Helps"}, {"paperId": "a5c39f4db1bf11fca385f7611f029e381b73092d", "title": "Reassessing hierarchical correspondences between brain and deep networks through direct interface"}, {"paperId": "c022f75b00d795c6297d6a9ea948856ea4d365a1", "title": "DeepSpeed- Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "a480257b3f9527638e644fc6e603fc221ef96b3f", "title": "LanA (Language Atlas): A probabilistic atlas for the language network based on fMRI data from >800 individuals"}, {"paperId": "b4206dd288958affeb314aee0ec1397de5c74c23", "title": "Shared computational principles for language processing in humans and deep language models"}, {"paperId": "83a491b6dfab0a9f30ce66d7dad1d7409e4d6e4d", "title": "Brains and algorithms partially converge in natural language processing"}, {"paperId": "18e736f814c6d64a27dc9ff088fb288bcac39002", "title": "Word Acquisition in Neural Language Models"}, {"paperId": "4c6f7fb5c2e1bd12899c3ec2788f9ce7eb2f8a5c", "title": "How much pretraining data do language models need to learn syntax?"}, {"paperId": "a2bb6f8b9c7078ac574dad062ebae7ec1940ec08", "title": "Diverse Deep Neural Networks All Predict Human Inferior Temporal Cortex Well, After Training and Fitting"}, {"paperId": "51866c8d3a340d9f24a3af0901d8e2dffbb7c75f", "title": "Parallel processing in speech perception with local and global representations of linguistic context"}, {"paperId": "841211b55852488147a3291f567511b82aa80e09", "title": "An ecologically motivated image dataset for deep learning yields better models of human vision"}, {"paperId": "4b2d04556f7d3377998f4f236b57086a1be74f23", "title": "A hierarchy of linguistic predictions during natural language comprehension"}, {"paperId": "edf33c4d8e9b3d21bee850e58fc4e6197eca2bfd", "title": "Recurrent babbling: evaluating the acquisition of grammar from limited input data"}, {"paperId": "644a33399711b31f8a5a1b464f6ffd7c2264fedc", "title": "The neural architecture of language: Integrative modeling converges on predictive processing"}, {"paperId": "27ffe951770b80ec9f239dbc96e63edaca0d76db", "title": "Lack of selectivity for syntax relative to word meanings throughout the language network"}, {"paperId": "19d68db5346c837bb428160619356e36045b351c", "title": "Wiring Up Vision: Minimizing Supervised Synaptic Updates Needed to Produce a Primate Ventral Stream"}, {"paperId": "fccfc6839777fe6f06197548dbe4bacb48b1a14b", "title": "On the Predictive Power of Neural Language Models for Human Real-Time Comprehension Behavior"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "cbcd7cd3f1dcf169a8ffc9decde8cd30c9090b9d", "title": "No evidence for differences among language regions in their temporal receptive windows"}, {"paperId": "427973cbf535187c95cd174adce64c20292a0c78", "title": "A Systematic Assessment of Syntactic Generalization in Neural Language Models"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "d0361d51b0f97c7e9f17401c2db2e1b25a9a1c64", "title": "Individual differences among deep neural network models"}, {"paperId": "e0dd32464121c6109a2c804fa080ad715df85a28", "title": "The neurobiology of language beyond single-word processing"}, {"paperId": "5abc9431d2442f419e5c499bfd1d9567ca30516c", "title": "Linking artificial and human neural representations of language"}, {"paperId": "e760e8b6647c694e21c9be1a386b92b917f9c307", "title": "The brain\u2019s default network: updated anatomy, physiology and evolving insights"}, {"paperId": "32abbcb3aa75ac34a92624dc779a9f7a82ee981c", "title": "A critique of pure learning and what artificial neural networks can learn from animal brains"}, {"paperId": "356645552f8f40adf5a99b4e3a69f47699399010", "title": "Quantity doesn\u2019t buy quality syntax with neural language models"}, {"paperId": "0bd4d7ef18c8b4df61629c88d1a648a53dea8363", "title": "Evaluating information-theoretic measures of word prediction in naturalistic sentence reading"}, {"paperId": "67ec09d6a7526c40583881a009f300e14cb6b49c", "title": "fMRI reveals language-specific predictive coding during naturalistic sentence comprehension"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "455a8838cde44f288d456d01c76ede95b56dc675", "title": "A Structural Probe for Finding Syntax in Word Representations"}, {"paperId": "e3567830f32444917af2d06c213435b7f1a92cd2", "title": "Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain)"}, {"paperId": "97906df07855b029b7aae7c2a1c6c5e8df1d531c", "title": "BERT Rediscovers the Classical NLP Pipeline"}, {"paperId": "6cf7ae9c0c790662eb018d578a22eeddd09c547b", "title": "Linguistic Analysis of Pretrained Sentence Encoders with Acceptability Judgments"}, {"paperId": "2cafeaff5e602f8e487f1343dba7b093a18b5e60", "title": "Modelling the N400 brain potential as change in a probabilistic representation of meaning"}, {"paperId": "6cbf16d6dd50e43b142cc3c3b2e23595c0f53c25", "title": "Distinct patterns of syntactic agreement errors in recurrent networks and humans"}, {"paperId": "009115bf52306860dbfffb169c3793c137d15998", "title": "The neural basis for human syntax: Broca's area and beyond"}, {"paperId": "048a4bad7fbd0cc5068422d0300a83e8f03b078d", "title": "Incorporating Context into Language Encoding Models for fMRI"}, {"paperId": "8e5acc4b6fd3126c41f74dae3644b7daa3f374ce", "title": "Toward a universal decoder of linguistic meaning from brain activation"}, {"paperId": "056366476e728476a767d126ae5881aa5b8468a2", "title": "The Natural Stories Corpus"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "082574d6b20f7b4e67e58ec32238c366e5645619", "title": "Using stochastic language models (SLM) to map lexical, syntactic, and phonological information processing in the brain"}, {"paperId": "046fb2f613dc9e1ba4325557b3274e58df6af551", "title": "Mapping the Early Language Environment Using All-Day Recordings and Automated Analysis."}, {"paperId": "263210f256603e3b62476ffb5b9bbbbc6403b646", "title": "What do Neural Machine Translation Models Learn about Morphology?"}, {"paperId": "9e4134d0fba86de14c31c8f9e9a237e2faaffc68", "title": "Discovering Event Structure in Continuous Narrative Perception and Memory"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "c50105953aba395a0beb78ae39346d28487ace95", "title": "Cognitive science in the era of artificial intelligence: A roadmap for reverse-engineering the infant language-learner"}, {"paperId": "67bbff920b98e0edf357ba053856eb19c93bb213", "title": "Dynamic reconfiguration of the default mode network during narrative comprehension"}, {"paperId": "7e07d99521053a210897153ef4c4cf36f9fadefc", "title": "Scanning the horizon: towards transparent and reproducible neuroimaging research"}, {"paperId": "2dee9e6c2e8d0e7b64c95caf687566a7466aa633", "title": "Prediction During Natural Language Comprehension."}, {"paperId": "7486e8cda40b7a87a91a386d34dfb629f36f1bc7", "title": "Abstract linguistic structure correlates with temporal activity during naturalistic comprehension"}, {"paperId": "8346f478233655b8da0bbc16c5a5cf6740443465", "title": "Language structure in the brain: A fixation-related fMRI study of syntactic surprisal in reading"}, {"paperId": "1a7b2655cc6c52f93e4493ca5f8b56a15177fd78", "title": "Publication and other reporting biases in cognitive sciences: detection, prevalence, and prevention"}, {"paperId": "8a523973e08d08fb6b1c01971b0ab881d09553b3", "title": "Data from Paper \u201cFalse-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant\u201d"}, {"paperId": "89774f17d4ae199ea6950b747bf21e390a6e023a", "title": "The effect of word predictability on reading time is logarithmic"}, {"paperId": "c2bc880156c10fc8d1752cd3d528e4ef96cbaac4", "title": "Power failure: why small sample size undermines the reliability of neuroscience"}, {"paperId": "b62b60be4fe51188d90a27dd9fc695c924a55b0b", "title": "Functional specificity for high-level linguistic processing in the human brain"}, {"paperId": "52c59c634e4800fb1ec64c141c51630737cea61b", "title": "Topographic Mapping of a Hierarchy of Temporal Receptive Windows Using a Narrated Story"}, {"paperId": "3fbcbe2e21fb6d85418adebeaf8e727995e7f6e5", "title": "Cortical representation of the constituent structure of sentences"}, {"paperId": "44c548044026726ddb15a09eb3fbd0773a665f8e", "title": "New method for fMRI investigations of language: defining ROIs functionally in individual subjects."}, {"paperId": "47133d54d4a5f1fb3c46bdbf3a7a5e270d930e2f", "title": "Language acquisition in the absence of explicit negative evidence: how important is starting small?"}, {"paperId": "0b44fcbeea9415d400c5f5789d6b892b6f98daff", "title": "Building a Large Annotated Corpus of English: The Penn Treebank"}, {"paperId": "6120372e5120ca259d03f7bb6eb78157af146ed5", "title": "American Parenting of Language-Learning Children: Persisting Differences in Family-Child Interactions Observed in Natural Home Environments."}, {"paperId": "8d350f2d767a70d55275a17d0b3dfcc80b2e0fee", "title": "Perplexity\u2014a measure of the difficulty of speech recognition tasks"}, {"paperId": null, "title": "2022, September 23). How Well Do Unsupervised Learning Algorithms Model"}, {"paperId": "4dac091ce96bb8c945c20cf3c5902bea40e6cee4", "title": "How Well Do Unsupervised Learning Algorithms Model Human Real-time and Life-long Learning?"}, {"paperId": "f6ea400d8c1eacfe84b9d5bbc663f652f77dc457", "title": "Scaffolded input promotes atomic organization in the recurrent neural network language model"}, {"paperId": null, "title": "LayerNorm weights performs close to zero, similarly to the model with a Gaussian initialization. hemispheres (although predictivity is higher in the LH, in line with other work"}, {"paperId": null, "title": "The MiniBERTas: Testing what RoBERTa learns with varying amounts of pretraining"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Experiment 2 results: performance"}, {"paperId": "30eb3863092dd52a1a4d9265fa10e3eca90038bb", "title": "The ERP response to the amount of information conveyed by words in sentences"}, {"paperId": null, "title": "Aligning books and movies: Neurobiology of Language"}, {"paperId": "e63360d91239921ef42acee9d3b687880a1cd194", "title": "Paradigms and processes in reading comprehension."}, {"paperId": "2e4babcb96e25915d7087084bd6153f8ecfdcf3c", "title": "Reconstructing the cascade of language processing in the brain using the internal computations of a transformer-based language model"}, {"paperId": null, "title": "Same as in B but for the Openwebtext training dataset in Experiment 2"}]}