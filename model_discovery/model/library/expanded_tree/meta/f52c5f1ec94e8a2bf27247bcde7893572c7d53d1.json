{"paperId": "f52c5f1ec94e8a2bf27247bcde7893572c7d53d1", "abstract": "A fundamental objective in robot manipulation is to enable models to comprehend visual scenes and execute actions. Although existing robot Multimodal Large Language Models (MLLMs) can handle a range of basic tasks, they still face challenges in two areas: 1) inadequate reasoning ability to tackle complex tasks, and 2) high computational costs for MLLM fine-tuning and inference. The recently proposed state space model (SSM) known as Mamba demonstrates promising capabilities in non-trivial sequence modeling with linear inference complexity. Inspired by this, we introduce RoboMamba, an end-to-end robotic MLLM that leverages the Mamba model to deliver both robotic reasoning and action capabilities, while maintaining efficient fine-tuning and inference. Specifically, we first integrate the vision encoder with Mamba, aligning visual data with language embedding through co-training, empowering our model with visual common sense and robot-related reasoning. To further equip RoboMamba with action pose prediction abilities, we explore an efficient fine-tuning strategy with a simple policy head. We find that once RoboMamba possesses sufficient reasoning capability, it can acquire manipulation skills with minimal fine-tuning parameters (0.1\\% of the model) and time (20 minutes). In experiments, RoboMamba demonstrates outstanding reasoning capabilities on general and robotic evaluation benchmarks. Meanwhile, our model showcases impressive pose prediction results in both simulation and real-world experiments, achieving inference speeds 7 times faster than existing robot MLLMs. Our project web page: https://sites.google.com/view/robomamba-web", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces RoboMamba, an end-to-end robotic MLLM that leverages the Mamba model to deliver both robotic reasoning and action capabilities, while maintaining efficient fine-tuning and inference."}, "embedding": {"model": "specter_v2", "vector": [-0.04942977428436279, 0.47480666637420654, -0.37936970591545105, -0.19650723040103912, -0.24665836989879608, 0.0407811664044857, 0.7033213973045349, -0.4106817841529846, -0.4692873954772949, -0.6151418685913086, 0.5026230812072754, -0.02504730597138405, 0.22788849472999573, 0.31483981013298035, -0.516626238822937, 0.1522877812385559, -0.8834590315818787, 0.20943602919578552, 0.08108324557542801, -0.6718539595603943, -0.23799194395542145, -0.28914594650268555, -0.7024821639060974, 0.04536133632063866, -0.1662798523902893, 0.5715292096138, 0.5667244791984558, 1.1560263633728027, -0.17923636734485626, 0.619929313659668, 0.7124938368797302, -0.06566677987575531, 0.38412919640541077, 0.08288312703371048, -0.6217301487922668, -0.011632259003818035, 0.18837794661521912, -0.7688475251197815, -1.0462461709976196, 1.0062110424041748, -0.363625168800354, 0.36584731936454773, 0.5783256888389587, -0.6350995302200317, -0.2070285826921463, 0.2879144847393036, 0.36916661262512207, 0.19969573616981506, -0.09933655709028244, 0.03386473283171654, 0.8059321045875549, -0.7672978639602661, 0.1259915828704834, 1.9630918502807617, 0.05567790940403938, 0.9317346215248108, -0.11249469220638275, -0.7290517687797546, 0.8529500961303711, -0.005795605480670929, -0.5312837362289429, -0.08603036403656006, -0.2697119414806366, -0.2890111804008484, 1.2428964376449585, -0.6411256790161133, 0.3817998170852661, 1.2663742303848267, 0.5243834257125854, 1.0824394226074219, -0.12207213044166565, -0.6728399991989136, 0.07237221300601959, -0.08666857331991196, -0.09992454200983047, 1.1902185678482056, -0.3933958113193512, 0.42726171016693115, -0.8017072677612305, 0.40432772040367126, 0.6426400542259216, 0.02359723299741745, 0.27326375246047974, -0.8250916600227356, -0.7432152032852173, 0.44331619143486023, 0.729620099067688, 0.2439025342464447, 0.03285851329565048, 1.062461495399475, 0.30289632081985474, 0.10443129390478134, -0.6633447408676147, 0.38816404342651367, 0.2084082067012787, 0.5896171927452087, -0.14623090624809265, 0.09712804108858109, 0.09349742531776428, 1.0569767951965332, -0.49614396691322327, 0.14980429410934448, -0.461302787065506, -0.15284207463264465, 1.8159122467041016, 0.26895833015441895, 0.650462806224823, -0.8698467016220093, 0.3654669523239136, -0.7587188482284546, 0.5146622061729431, -0.7490336298942566, -0.27496305108070374, 0.17017070949077606, -0.2707650363445282, -0.5419624447822571, -0.484578400850296, 0.464646577835083, -1.1099538803100586, 0.9718434810638428, -0.24129454791545868, -0.20131106674671173, 0.3969017267227173, 0.30375659465789795, 0.3592522442340851, 0.7338146567344666, 0.15930980443954468, 0.5500004291534424, 1.006136178970337, -1.1315689086914062, -0.936278223991394, -1.4535211324691772, 0.029987771064043045, 0.2992415130138397, 0.1024278998374939, -0.2089471071958542, -1.1744611263275146, -1.182966947555542, -1.2810300588607788, -0.0613168329000473, -0.777387261390686, 0.5510683655738831, 0.8807584047317505, 0.07686566561460495, -0.6020158529281616, 0.346672385931015, -0.8101951479911804, -0.4466654658317566, 0.33037325739860535, 0.4133441150188446, -0.17170079052448273, -0.31285569071769714, -0.6858606338500977, 1.3034576177597046, 0.736289918422699, 0.021231234073638916, -0.9204555749893188, 0.462515652179718, -1.8317285776138306, -0.47731122374534607, 0.45766040682792664, -0.6291415691375732, 1.2919472455978394, 0.28588271141052246, -1.682440996170044, 0.23923498392105103, -0.33801960945129395, 0.0335095152258873, 0.4284107983112335, -0.49242326617240906, -0.5124220848083496, -0.43788254261016846, -0.6329670548439026, 1.1905450820922852, 0.4543142020702362, -0.5470060706138611, -0.06011088564991951, 0.1212896779179573, 0.21004073321819305, -0.17516843974590302, -0.2218799740076065, 0.8565995693206787, -0.5910423994064331, 0.10053586214780807, 0.5282953977584839, 0.30085626244544983, -0.4540979266166687, 0.35040393471717834, -0.5607401728630066, -0.4651150703430176, 0.7683151364326477, 0.14648854732513428, 0.37567025423049927, -0.7416192889213562, -0.07875237613916397, -0.4113282859325409, -0.17709222435951233, -0.39188703894615173, -1.3615150451660156, 0.6148484945297241, -0.38272857666015625, 0.17473404109477997, 0.05019405111670494, -1.2490975856781006, 0.07269775867462158, 0.05636155977845192, -0.5917237401008606, 0.35299235582351685, 0.3066542446613312, 1.3548979759216309, -1.2480257749557495, -0.08455128222703934, 0.6877329349517822, -0.0982327088713646, -0.7578758001327515, 1.3559542894363403, -0.5849669575691223, 0.4624924063682556, -0.10193520784378052, -0.4406817853450775, -0.329175740480423, -0.34008660912513733, 0.6044998168945312, -0.8958162069320679, 0.2996225655078888, 0.3566681444644928, -0.333970844745636, 2.049049139022827, -0.5582937002182007, 0.6574757695198059, -0.18224605917930603, -0.44540008902549744, 0.20200708508491516, 0.013534221798181534, -0.26455798745155334, -0.04541448503732681, 0.6208416819572449, -0.21613170206546783, -0.505723774433136, -0.6022084951400757, 0.39537402987480164, 0.8590965270996094, -0.39742806553840637, -0.4055955111980438, 0.5065622925758362, -0.8226287961006165, 0.33302873373031616, 0.400106817483902, 0.6728630661964417, 0.6268846392631531, 0.710329532623291, 0.3380303382873535, 0.05860613286495209, -0.9446157813072205, -0.549737811088562, 0.5916497707366943, 0.40704256296157837, 0.8663899898529053, -0.038602523505687714, -0.7815019488334656, -0.264824777841568, -0.4967225193977356, 1.033787727355957, 0.7542124390602112, 0.7512407302856445, -0.09011803567409515, -0.3899887204170227, -0.3423510193824768, -0.5436505675315857, 0.02879190444946289, -0.6542547941207886, -0.5113691687583923, -0.4004298150539398, -0.49292415380477905, 0.402355432510376, 0.5654506087303162, 1.0627555847167969, -0.7469018697738647, -0.20041529834270477, -0.37854886054992676, 0.09686565399169922, -1.0815874338150024, -0.17727258801460266, 0.15218649804592133, -0.12107808887958527, -0.38017117977142334, 0.4211201071739197, -0.018460340797901154, 0.15920963883399963, -0.7565996050834656, 0.3908461928367615, -1.2403568029403687, -0.5186890959739685, 0.4520247280597687, 0.3748873174190521, -0.7210334539413452, -1.0516225099563599, -0.11822769790887833, 0.218839630484581, -0.3317255973815918, -0.041807372123003006, 0.7073948979377747, 0.19759565591812134, -0.2649816572666168, -0.4176574945449829, 0.44264569878578186, 0.5142229795455933, -0.12892165780067444, 0.21396207809448242, -0.8283011317253113, -0.012414947152137756, -0.2564634382724762, 0.6070960760116577, 0.05333760008215904, -0.5400683283805847, 0.09627215564250946, -0.1226813793182373, -0.048071376979351044, -0.13068276643753052, -0.9718067049980164, -0.19384273886680603, -0.19386623799800873, 0.16817431151866913, -0.7112036943435669, -0.6436086297035217, 0.08629003167152405, 0.5135655403137207, 0.08916720002889633, 0.45550814270973206, 0.40382522344589233, 0.9395913481712341, 0.12376726418733597, 0.7220043540000916, -0.8785281777381897, 0.8277726173400879, 0.5252622961997986, 0.4690799117088318, 0.33401525020599365, 0.2075619101524353, -0.36222317814826965, -0.5251327157020569, -0.39143311977386475, -0.5335858464241028, -0.6225018501281738, 0.920186460018158, -0.6389724612236023, -1.071123719215393, -0.26994800567626953, -1.0985286235809326, -0.34947100281715393, 0.29308387637138367, 0.06322698295116425, -0.5447885990142822, -0.7210902571678162, -0.8785712718963623, -0.7467624545097351, 0.20022077858448029, -1.519300103187561, 0.4645058214664459, 0.051943615078926086, -0.7654393911361694, -0.13311870396137238, 0.08859431743621826, -0.23921515047550201, 0.524090051651001, -0.3977493941783905, 0.4369603097438812, 0.0729590654373169, -0.22423963248729706, -0.6235354542732239, 0.3323952257633209, 0.4043027460575104, 0.19630900025367737, 0.1903230994939804, -0.5944068431854248, 0.17701883614063263, -0.6235238313674927, -0.5996758341789246, 0.11056280136108398, 0.15342137217521667, 0.8756802082061768, 0.28641611337661743, -0.4257335662841797, -0.0426323264837265, 1.092006802558899, -0.38745352625846863, 0.1296921670436859, 0.21441808342933655, 1.0702528953552246, 0.3495354652404785, -0.10035838931798935, 0.4578600823879242, 0.4980630874633789, 0.6816088557243347, 1.0348626375198364, 0.2640285789966583, -0.12794430553913116, -0.6835492849349976, 0.9917092323303223, 0.7119174599647522, 0.7220339775085449, 0.08860188722610474, -0.8174360990524292, 0.6537905931472778, -1.2651506662368774, -0.6576619744300842, 1.0706126689910889, 0.5882801413536072, 0.4214898645877838, -0.4461778402328491, -0.2865893840789795, -0.6684842109680176, 0.4714440703392029, 0.47439852356910706, -0.3063989281654358, -0.4329792559146881, 0.4859292805194855, -0.24619317054748535, -0.13160693645477295, 0.779606282711029, -0.8350332379341125, 0.38616943359375, 14.452095985412598, 0.6012206673622131, -0.19281025230884552, 0.2728370130062103, 0.11108055710792542, 0.2840654253959656, 0.20456796884536743, -0.3912634253501892, -1.191865086555481, -0.42262133955955505, 1.0034576654434204, 0.9985631108283997, 0.6703603267669678, 0.2854153513908386, 0.12511689960956573, 0.06492780894041061, -1.1279401779174805, 0.839633047580719, 0.7896687984466553, -1.0358034372329712, 0.24718868732452393, -0.1327584981918335, 0.08258139342069626, 0.4939900040626526, 0.8493394255638123, 1.0684820413589478, 0.6641719937324524, -0.5686166882514954, 1.0087629556655884, 0.33103543519973755, 0.7609851956367493, 0.4444097578525543, 0.15868353843688965, 0.9070133566856384, -1.0732076168060303, -0.6269067525863647, -0.17674504220485687, -0.8142895102500916, 0.5073853135108948, -0.7106813192367554, -0.514295756816864, -0.48139360547065735, -0.19094015657901764, 0.6128963828086853, 0.05432930961251259, 0.3921569883823395, -0.14934389293193817, 0.04437173902988434, -0.04118642583489418, -0.38500669598579407, 0.3023488521575928, 0.45817700028419495, 0.4070070683956146, -0.12128089368343353, -0.13907760381698608, -0.06837081164121628, 0.4325062334537506, 0.6522510647773743, -0.06547436118125916, -0.8257244825363159, -0.3893114924430847, -0.29493248462677, -0.32587525248527527, 0.6753857731819153, 0.7032521963119507, 0.35139819979667664, -0.08638574928045273, 0.1996985375881195, 0.6656385660171509, 0.4081878960132599, -0.6739920377731323, 0.3493301272392273, 0.43866676092147827, -1.0583020448684692, 0.056602440774440765, 0.13138695061206818, 0.05960890278220177, -0.5960566997528076, -0.5534430146217346, -0.3046673536300659, 0.016688168048858643, -1.0216165781021118, -0.7366917133331299, 0.7374128103256226, 0.28843244910240173, -0.5847878456115723, 0.21655172109603882, -1.1508965492248535, 0.010711709037423134, 0.06507249176502228, -1.0497910976409912, -0.9883769750595093, -0.19924059510231018, -0.4399837255477905, 0.14014932513237, 0.08691238611936569, 0.9990627765655518, -0.23895928263664246, -0.38595178723335266, -0.36779212951660156, -0.29913002252578735, 0.003920184448361397, -0.227726012468338, -0.5526695251464844, 0.3888964056968689, 0.10243148356676102, -0.0832652673125267, 0.22518274188041687, 0.24453610181808472, -0.1259462982416153, -0.9178037047386169, -0.17937612533569336, -0.38497403264045715, -1.2409628629684448, -0.27494877576828003, -0.9465972185134888, -0.22481732070446014, 0.6009153723716736, 0.3334328234195709, -0.044958263635635376, -0.21320463716983795, -0.2983647584915161, -0.774057149887085, -0.14725515246391296, -0.7989184856414795, 0.5344861149787903, -0.0013226403389126062, -0.5719813704490662, -0.6949042677879333, -0.05914090946316719, 0.35475853085517883, -1.3038028478622437, -0.1742587387561798, 0.12555117905139923, 0.6207244396209717, 0.25428506731987, 1.3313014507293701, -0.8031809329986572, 0.9196946024894714, 0.42859533429145813, -0.19040653109550476, -0.7022565007209778, 0.059195443987846375, -0.3960556387901306, -0.20579607784748077, -0.4944795072078705, 0.44337767362594604, -0.264361709356308, -0.003224156331270933, 0.6335187554359436, 0.4376859664916992, -0.5091711282730103, -0.3996660113334656, -0.5132455825805664, -0.10267999023199081, -0.48502734303474426, -0.23389297723770142, -0.6613402366638184, 0.14699752628803253, 0.1363002359867096, 0.15787449479103088, 1.1300593614578247, -0.43032705783843994, -0.6458753943443298, 0.7501536011695862, 0.5541824102401733, -0.3776238262653351, -0.5290809869766235, -0.6116498112678528, -1.8270761966705322, 0.12138762325048447, -0.9429196119308472, 0.8750950694084167, -1.0952484607696533, -0.2508094012737274, 0.5494386553764343, -0.08649396151304245, 0.15894441306591034, 0.45959386229515076, -0.5021766424179077, -0.038201358169317245, -0.642742395401001, -0.9128305315971375, 1.0202275514602661, 1.1215062141418457, -1.1435294151306152, 0.3375810384750366, -0.14022450149059296, 0.5955548286437988, 0.5861108899116516, 0.17056186497211456, -0.05709249898791313, -0.7411221861839294, -0.9769332408905029, 0.28776678442955017, 0.06235145777463913, 0.20365753769874573, -1.226125717163086, 0.7092206478118896, -0.04063490033149719, 0.04876643791794777, 0.07743185013532639, 1.4287824630737305, -1.2997372150421143, -0.4512123763561249, 0.957155704498291, -1.349600076675415, -0.08180757611989975, 0.36666175723075867, 0.17880834639072418, -0.10437783598899841, 0.4814736545085907, 0.2214636653661728, -0.9210572838783264, -1.199873685836792, 0.3464529812335968, -0.6889668107032776, -0.5935271382331848, 0.3675263822078705, 0.2782757878303528, -0.7624154686927795, -0.7977830171585083, -0.2663835287094116, 0.4090012013912201, -0.7652509808540344, 1.2635295391082764, 1.0246946811676025, -1.0377373695373535, 0.262798935174942, 0.0815805047750473, 0.4008137583732605, 0.17296536266803741, 0.2767607569694519, 0.33003178238868713, -0.25539761781692505, 0.2203499972820282, 0.07522748410701752, 0.3655288517475128, -0.7705559730529785, 0.351688027381897, 1.0251941680908203, -0.09957816451787949, 0.1369410902261734, 1.1178468465805054, -0.017132194712758064, -1.3326904773712158, 0.563730776309967, -1.1065624952316284, -0.657234251499176, -0.8604409694671631, 0.4958987832069397, -0.024855533614754677, -0.6177085041999817, -0.13010290265083313, -0.3699263632297516, 0.4972086250782013, 0.10978813469409943, -0.7198432683944702, -0.07685746252536774, -0.3189067840576172, -0.20754949748516083, 0.9280650019645691, 0.9950574636459351, -0.7579269409179688, -0.8530362248420715, -0.20712007582187653, -0.8420847654342651, -0.02951548434793949, -0.2215261161327362, -0.4451375901699066, -0.4708716571331024, 0.6732362508773804, 0.7389371991157532, -0.18015092611312866, -0.26012036204338074, 0.3319115936756134, -0.22309574484825134, 1.485888957977295, 0.07321643084287643, -0.13916067779064178, 0.15835633873939514, 1.1329350471496582, 1.7959591150283813, -1.342268943786621, 0.3269856870174408, -0.5156019926071167, -0.5166507959365845, 1.0014872550964355, 0.8343417644500732, -0.377174973487854, 0.8560100197792053, -0.2947576940059662, -0.09286785125732422, 0.18985682725906372, -0.6710298657417297, -0.1780511885881424, 1.1004984378814697, 0.9753676056861877, -0.07290027290582657, 0.2797771394252777, 0.6778449416160583, 0.09179005026817322, 0.22767072916030884, -0.11436298489570618, 0.423676073551178, 0.5245546102523804, -0.26901209354400635, 0.25735029578208923, 0.041558071970939636, 0.5193697810173035, -0.03677678108215332, -0.07224016636610031, 0.23902085423469543, 0.5604141354560852, -0.028205737471580505, 0.7411770224571228, 0.8483832478523254, -0.08731340616941452, 0.36784428358078003, -0.23659966886043549, 0.8836511373519897, -0.7230926156044006, 0.3567102551460266, -0.28207147121429443, -0.6919494867324829, -0.5444396138191223, -0.4433169364929199, -0.49538663029670715, -0.5902808904647827, 0.36577773094177246, 0.2222651243209839, -0.5627307891845703, 0.6495707035064697, 1.3857803344726562, 0.19406118988990784, 0.7075847387313843, -0.6649106740951538, -0.8376505374908447, -0.8374412655830383, -1.1185023784637451, 0.5641553997993469, -0.5433014631271362, 0.18932247161865234, -0.6379751563072205, -0.00926478672772646, -0.27411776781082153]}, "authors": [{"authorId": "2258602418", "name": "Jiaming Liu"}, {"authorId": "2305193018", "name": "Mengzhen Liu"}, {"authorId": "2305122598", "name": "Zhenyu Wang"}, {"authorId": "2303425561", "name": "Lily Lee"}, {"authorId": "2303804385", "name": "Kaichen Zhou"}, {"authorId": "2303845983", "name": "Pengju An"}, {"authorId": "2191631097", "name": "Senqiao Yang"}, {"authorId": "2275104296", "name": "Renrui Zhang"}, {"authorId": "2245065533", "name": "Yandong Guo"}, {"authorId": "2242835846", "name": "Shanghang Zhang"}], "references": [{"paperId": "02d3afd9c306ce0a0d39e211d60468732c591f8f", "title": "State Space Model for New-Generation Network Alternative to Transformers: A Survey"}, {"paperId": "c69c4164a3a84521a368190160a39cbf43467040", "title": "Any2Point: Empowering Any-modality Large Models for Efficient 3D Understanding"}, {"paperId": "40e996a7c3e914a67c708704fa9b4c54ea70f36e", "title": "Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference"}, {"paperId": "6d017adda6b2b1ea627dde2f0e85401ebb9fe566", "title": "MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?"}, {"paperId": "58e2e14d90a6f0cdf8b199b408cd05cf397af7c1", "title": "ManipVQA: Injecting Robotic Affordance and Physically Grounded Information into Multi-Modal Large Language Models"}, {"paperId": "e730beb44042499763d36214c0498434e470dfd5", "title": "MambaIR: A Simple Baseline for Image Restoration with State-Space Model"}, {"paperId": "6a6751f59c5dbc80823b3cf47c3aaae063991b86", "title": "TinyLLaVA: A Framework of Small-scale Large Multimodal Models"}, {"paperId": "efb7af4ae6943f298449416529c288e9559c991b", "title": "Pan-Mamba: Effective pan-sharpening with State Space Model"}, {"paperId": "7154fc93bdefcd237a0ce3902511c0b154049253", "title": "Scalable Diffusion Models with State Space Backbone"}, {"paperId": "ec8e2b45c4601730015608a58e33409224a81228", "title": "SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models"}, {"paperId": "08b30038fe938fb8460dff3085bda9ff6503e4c5", "title": "Mamba-UNet: UNet-Like Pure Visual Mamba for Medical Image Segmentation"}, {"paperId": "a091bf215c716a146140f81c751712db628c8e20", "title": "MobileVLM V2: Faster and Stronger Baseline for Vision Language Model"}, {"paperId": "ffaa66e698655d4b2dee1ab61448d5cc1a743a63", "title": "VM-UNet: Vision Mamba UNet for Medical Image Segmentation"}, {"paperId": "560c6f24c335c2dd27be0cfa50dbdbb50a9e4bfd", "title": "TinyLlama: An Open-Source Small Language Model"}, {"paperId": "ece33ee67d74c29cd2a83c505e5bf0b818f9c2a1", "title": "LLaVA-Phi: Efficient Multi-Modal Assistant with Small Language Model"}, {"paperId": "e36f79b2bfbf50cf6362cc563a6e5c261e3f0615", "title": "MobileVLM : A Fast, Strong and Open Vision Language Assistant for Mobile Devices"}, {"paperId": "d23662d2275498f4fa7a937dabd60fbc7faf9c14", "title": "ManipLLM: Embodied Multimodal Large Language Model for Object-Centric Robotic Manipulation"}, {"paperId": "5edf706467dc76cd09319592d18db0ad4e1fb64d", "title": "LiDAR-LLM: Exploring the Potential of Large Language Models for 3D LiDAR Understanding"}, {"paperId": "0f87251bb0ee57d94ae296301e6f23b032ca8c13", "title": "Continual-MAE: Adaptive Distribution Masked Autoencoders for Continual Test-Time Adaptation"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "76a3f4a79ae9a00db2f2b5f6877021d8deb96ada", "title": "SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models"}, {"paperId": "857efca0d4cbece97da4b904de1d506c2af25f9c", "title": "Vision-Language Foundation Models as Effective Robot Imitators"}, {"paperId": "0b47356f17aea1de66e39e5f182a105c96af8dd3", "title": "RoboVQA: Multimodal Long-Horizon Reasoning for Robotics"}, {"paperId": "56b5e5a0b1760fb3ad8dba7dd4f02d0549896ef5", "title": "SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous Manipulation"}, {"paperId": "1ddbd08ad8cf22a5c66c4242194c4286328533bf", "title": "MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning"}, {"paperId": "124d4d374fbef2016fa9880489871a58a7450644", "title": "Improved Baselines with Visual Instruction Tuning"}, {"paperId": "958ed4830ae80a189ecb9b93ab75a6ce2e3926fc", "title": "GPT-Driver: Learning to Drive with GPT"}, {"paperId": "22ebfc211d184ed615729378a43fde175bf14478", "title": "Point-Bind & Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding, Generation, and Instruction Following"}, {"paperId": "30cfc4e7174211aa48c965826d51db773f0d37c7", "title": "Chat-3D: Data-efficiently Tuning Large Language Model for Universal Dialogue of 3D Scenes"}, {"paperId": "94972e30504017156ef5b5debc419bf6edc67384", "title": "MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities"}, {"paperId": "7fbc502441d66daf1f53765d5d86a8dfba9ab0ce", "title": "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"}, {"paperId": "38939304bb760473141c2aca0305e44fbe04e6e8", "title": "RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control"}, {"paperId": "240103933ffe3dac2179cc160a2bd91299357a53", "title": "Retentive Network: A Successor to Transformer for Large Language Models"}, {"paperId": "b37b1dc72b1882858f5120f2cd6883134089a6ed", "title": "MMBench: Is Your Multi-modal Model an All-around Player?"}, {"paperId": "1cd8373490efc2d74c2796f4b2aa27c7d4415ec9", "title": "VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models"}, {"paperId": "c7a7104df3db13737a865ede2be8146990fa4026", "title": "Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning"}, {"paperId": "697e0add95e880bd42e00bef838181e105f91981", "title": "MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models"}, {"paperId": "debbb47abc9fb757857f7c06aa86ca558d37c2d7", "title": "2-D SSM: A General Spatial Layer for Visual Transformers"}, {"paperId": "44375d0996ef965e9555e1a0d12e150a8e864a04", "title": "ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "206400aba5f12f734cdd2e4ab48ef6014ea60773", "title": "Evaluating Object Hallucination in Large Vision-Language Models"}, {"paperId": "8bd6a2a89503be083176f2cc26fabedb79238cbd", "title": "InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"}, {"paperId": "570079bbdd8758dfe865097e05719313c9c1301a", "title": "LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "5a9cb1b3dc4655218b3deeaf4a2417a9a8cd0891", "title": "DINOv2: Learning Robust Visual Features without Supervision"}, {"paperId": "5d5024fae7223a0f8a8b86e1fdf5c5f4b7a9d9c6", "title": "UniDexGrasp++: Improving Dexterous Grasping Policy Learning via Geometry-aware Curriculum and Iterative Generalist-Specialist Learning"}, {"paperId": "a757999ed260d7bc45484dc6b4456bf33fe6f679", "title": "LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention"}, {"paperId": "35aba190f28b5c39df333c06ca21f46bd4845eba", "title": "Sigmoid Loss for Language Image Pre-Training"}, {"paperId": "38fe8f324d2162e63a967a9ac6648974fc4c66f3", "title": "PaLM-E: An Embodied Multimodal Language Model"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb", "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"}, {"paperId": "2218f1713d7f721ab76801063416ec9b11c7646f", "title": "ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "6e1c0a5f083db4ad691f54878aed36f284bde019", "title": "AnyGrasp: Robust and Efficient Grasp Perception in Spatial and Temporal Domains"}, {"paperId": "fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d", "title": "RT-1: Robotics Transformer for Real-World Control at Scale"}, {"paperId": "9a51c94f186b48f29fe649c6f4314b7291b952a7", "title": "RLAfford: End-to-End Affordance Learning for Robotic Manipulation"}, {"paperId": "6d7d141c75af752ffc0d8a6184cca3f9323d6c74", "title": "Simplified State Space Layers for Sequence Modeling"}, {"paperId": "47a67e76ed84260ff19f7a948d764005d1edf1c9", "title": "A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge"}, {"paperId": "c31160da259cf38503ab9a27920bb994ec039d8b", "title": "FlowBot3D: Learning 3D Articulation Flow to Manipulate Articulated Objects"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "cb5e3f085caefd1f3d5e08637ab55d39e61234fc", "title": "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "ca9047c78d48b606c4e4f0c456b1dda550de28b2", "title": "Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers"}, {"paperId": "391c892f63bc072325064329c62ebd265a0d4b60", "title": "Universal Manipulation Policy Network for Articulated Objects"}, {"paperId": "e06c005e98281af455c454ce2478285f6f3afeca", "title": "Mastering Visual Continuous Control: Improved Data-Augmented Reinforcement Learning"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "197037c0d6612d1510f98eb2a1719da05bede103", "title": "Where2Act: From Pixels to Actions for Articulated 3D Objects"}, {"paperId": "33db6ee825cad99045cecf5e57b8b830d7b39b01", "title": "Robotic Grasping using Deep Reinforcement Learning"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "33eadd4e666a894306a22ba0839c5e0cef77280e", "title": "TextCaps: a Dataset for Image Captioning with Reading Comprehension"}, {"paperId": "e0d2852be2a3f5952a6600eaa933f23bee448210", "title": "SAPIEN: A SimulAted Part-Based Interactive ENvironment"}, {"paperId": "1097cf8cf5961589ff693b069002e7181e24e631", "title": "OCR-VQA: Visual Question Answering by Reading Text in Images"}, {"paperId": "28ad018c39d1578bea84e7cedf94459e3dbe1e70", "title": "OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge"}, {"paperId": "a7ac99d7cf3f568ab1a741392144b646b856ae0c", "title": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering"}, {"paperId": "3ecbd9b6153e9ff2f490950a87853e68c808db4d", "title": "PartNet: A Large-Scale Benchmark for Fine-Grained and Hierarchical Part-Level 3D Object Understanding"}, {"paperId": "a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c", "title": "VizWiz Grand Challenge: Answering Visual Questions from Blind People"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "7e232313a59d735ef7c8a9f4cc7bc980a29deb5e", "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"}, {"paperId": "afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d", "title": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations"}, {"paperId": "9b686d76914befea66377ec79c1f9258d70ea7e3", "title": "ShapeNet: An Information-Rich 3D Model Repository"}, {"paperId": "e65142010431ffc089b272a1174214e00693e503", "title": "Generation and Comprehension of Unambiguous Object Descriptions"}, {"paperId": "92c141447f51b6732242376164ff961e464731c8", "title": "ReferItGame: Referring to Objects in Photographs of Natural Scenes"}, {"paperId": "5dc783a45ade5124fcd828a5a9b25e723ae9d37b", "title": "Semi-Mamba-UNet: Pixel-Level Contrastive Cross-Supervised Visual Mamba-based UNet for Semi-Supervised Medical Image Segmentation"}, {"paperId": "2eb5bd7183e26b4a86008317011cae1945231f5a", "title": "Exploring Sparse Visual Prompt for Cross-domain Semantic Segmentation"}, {"paperId": "7637ed79d30d0139901175ae4abedd822c217ab4", "title": "3D-LLM: Injecting the 3D World into Large Language Models"}, {"paperId": "5ddb51ae85deca14dc7fc8adc07305c22a1ebe0a", "title": "Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities"}, {"paperId": "cf0f8f585c8822e3c6bcd9527d546eefc8486aea", "title": "S4ND: Modeling Images and Videos as Multidimensional Signals with State Spaces"}]}