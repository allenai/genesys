{"paperId": "c87dd1d95e2c2f2dbd15682029d3c09d37cedab6", "abstract": "Large language models have led to state-of-the-art accuracies across a range of tasks. However,training large language model needs massive computing resource, as more and more open source pre-training models are available, it is worthy to study how to take full advantage of available model. We find a method to save training time and resource cost by changing the small well-trained model to large model. We initialize a larger target model from a smaller source model by copy weight values from source model and padding with zeros or small initialization values on it to make the source and target model have approximate outputs, which is valid due to block matrix multiplication and residual connection in transformer structure. We test the target model on several data sets and find it is still comparable with the source model. When we continue training the target model, the training loss can start from a smaller value.", "venue": "arXiv.org", "year": 2021, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A method to save training time and resource cost by changing the small well-trained model to large model, which is valid due to block matrix multiplication and residual connection in transformer structure, and initialize a larger target model from a smaller source model."}, "embedding": {"model": "specter_v2", "vector": [0.17891466617584229, 0.4471370577812195, -0.03237532079219818, -0.06995806843042374, -0.534686267375946, -0.059732586145401, 0.49723753333091736, -0.5098353028297424, -0.6422629356384277, 0.13782954216003418, 0.4695449769496918, 0.015438144095242023, 0.8880107998847961, -0.07497607171535492, -0.3256922662258148, 0.12736551463603973, -0.853538453578949, 0.3663043677806854, -0.013070940971374512, -0.612173318862915, -0.6045454144477844, -0.8005049824714661, -0.37753769755363464, 0.11413313448429108, 0.6476431488990784, 0.26762208342552185, 0.539254903793335, 0.5616137385368347, -0.46916311979293823, 0.39699283242225647, 0.3164457082748413, -0.5474004745483398, 0.49599671363830566, -0.3430006802082062, -0.480505108833313, -0.25469771027565, 0.4230097234249115, -0.5887933373451233, -0.0543060302734375, 0.6315913796424866, -0.12021540850400925, 0.49290359020233154, 0.13602061569690704, -0.7377901673316956, -0.28513234853744507, 0.6434140801429749, 0.513961136341095, 0.7070927619934082, -0.5834760665893555, -0.7354722619056702, 0.8596507906913757, -1.1743755340576172, 0.03561391308903694, 1.6925324201583862, 0.5602769255638123, 0.4849402606487274, -0.2160315364599228, -1.1822208166122437, 0.2528659701347351, -0.203849658370018, -0.8437661528587341, -0.34298840165138245, 0.13877397775650024, 0.06443192064762115, 1.9980792999267578, -0.30122166872024536, 0.16314513981342316, 0.3890647292137146, -0.10238917171955109, 1.2225245237350464, 0.031622882932424545, -0.7675599455833435, -0.9647971391677856, 0.28384047746658325, 0.17093735933303833, 1.026275873184204, -0.3014446794986725, 0.11559724807739258, -0.9210525155067444, 0.04417286813259125, 0.609707772731781, -0.2730616629123688, 0.16655604541301727, -0.07183105498552322, -0.7610703110694885, 0.7165063619613647, 0.259993314743042, 0.8584588766098022, 0.08940526843070984, 0.5076380968093872, 0.7058371305465698, 0.9324915409088135, 0.2908644378185272, 0.08575709909200668, -0.3452897071838379, 0.45422810316085815, -0.4510857164859772, -0.257637619972229, 0.05751870200037956, 0.8716088533401489, 0.08207348734140396, 0.6363253593444824, -0.8376814126968384, 0.4288988411426544, 1.1987504959106445, 0.3258834481239319, 0.5602117776870728, -0.44500407576560974, 0.7664912343025208, -0.7739567756652832, -0.22268086671829224, -0.3924906849861145, 0.12048933655023575, -0.7215880751609802, -0.8678490519523621, -1.3936736583709717, -0.3421037793159485, -0.11278674751520157, -0.7836843729019165, 0.7888467311859131, -0.2170562744140625, 0.3681738078594208, 0.33305129408836365, 0.21251602470874786, 0.45014452934265137, 0.9230165481567383, 0.5738488435745239, 0.15987521409988403, 0.592732846736908, -1.1352839469909668, -0.47108194231987, -0.6852428317070007, 1.069463849067688, -0.6599332094192505, 0.3931756913661957, -0.4022426903247833, -1.0834426879882812, -1.0951504707336426, -0.7730183601379395, -0.00015732015890534967, -0.597390353679657, 0.2260119616985321, 1.0758297443389893, 0.49358606338500977, -1.1094120740890503, 0.7540002465248108, -0.26960182189941406, -0.44058147072792053, 0.1615709364414215, 0.4759071171283722, 0.009494682773947716, -0.37502554059028625, -1.6273438930511475, 0.6204530596733093, 0.36920487880706787, -0.44821733236312866, -0.12552575767040253, -0.6910622715950012, -1.0685985088348389, -0.2125260829925537, -0.19155876338481903, -0.5046910643577576, 1.099735975265503, -0.5743356347084045, -1.7159301042556763, 0.6954193115234375, -0.3744111657142639, 0.13649792969226837, 0.15767709910869598, 0.04697522893548012, -0.5517776012420654, -0.7220649123191833, -0.27563348412513733, 0.5670783519744873, 0.37079185247421265, 0.16330598294734955, -0.2299242466688156, 0.23073577880859375, -0.2480139583349228, 0.18468299508094788, -0.6973841786384583, 1.2096948623657227, -0.34693723917007446, -0.42427563667297363, 0.21629419922828674, 0.4370514154434204, -0.0020007791463285685, -0.33759579062461853, -0.3314560651779175, -1.1160975694656372, 0.8378271460533142, -0.43003419041633606, 0.8515162467956543, -0.711694061756134, -0.5517978072166443, -0.09563052654266357, -0.4748533070087433, -0.05236602947115898, -0.977912962436676, 0.8019125461578369, -0.45838406682014465, 0.288289874792099, 0.16316312551498413, -0.9452649354934692, -0.10069242864847183, -0.4201135039329529, -0.6148388981819153, -0.29860684275627136, 0.14328481256961823, 1.0841357707977295, -0.5859741568565369, 0.10827439278364182, 0.028335733339190483, 0.31352248787879944, -0.879262387752533, 1.2321544885635376, 0.1211351752281189, 0.26398804783821106, -0.1456996649503708, -0.3590938448905945, 0.2651539146900177, -0.09980291873216629, 0.1865970939397812, -0.44420042634010315, 0.1032952219247818, 0.4888022243976593, -0.3249106705188751, 1.5837793350219727, -0.7372173070907593, 0.38228243589401245, -0.10448368638753891, -0.9868574738502502, 0.22905036807060242, 0.5651425123214722, -0.26718029379844666, -0.25586581230163574, 0.2703098952770233, 0.43995609879493713, -0.12139395624399185, 0.5029852390289307, 0.627124011516571, 0.40730181336402893, -0.21686677634716034, 0.1199127808213234, 0.6434506773948669, -0.23807542026042938, 0.10648782551288605, 0.27491122484207153, 0.1521110236644745, 0.05454922839999199, 0.1263146549463272, -0.19510771334171295, 0.5095113515853882, -0.7214081883430481, -0.17588722705841064, 0.11187837272882462, 0.4671030640602112, 0.44719433784484863, -0.1057979017496109, -0.5308096408843994, -0.21483489871025085, -0.24995188415050507, 0.7155114412307739, 1.7345393896102905, -0.37792715430259705, -0.21778863668441772, -0.3192037045955658, -0.23834757506847382, -0.2504100501537323, -0.1006573885679245, -0.3177708685398102, -0.19970664381980896, -0.9776430726051331, -0.709923505783081, 0.649352490901947, 0.050639525055885315, 1.1881017684936523, -0.21473366022109985, 0.28036847710609436, -0.34863513708114624, 0.033776454627513885, -0.6767908930778503, -0.8349852561950684, 0.01843610778450966, -1.156148910522461, 0.23115921020507812, -0.5386298298835754, -0.30339890718460083, 0.0483417846262455, -0.4460480511188507, 0.9073978066444397, -0.40014296770095825, 0.09290454536676407, -0.15130560100078583, 0.7938503623008728, -0.7434549927711487, -1.0487539768218994, 0.3072045147418976, 0.35123857855796814, -0.07242467999458313, 0.16183212399482727, 0.5687357783317566, 0.40677186846733093, 0.3606606721878052, -0.22190707921981812, 0.5451423525810242, 0.1474267989397049, -0.15474162995815277, 0.23316122591495514, -0.28313371539115906, 0.15112628042697906, -1.130846619606018, 0.973192036151886, 0.3514656722545624, -0.49253493547439575, 0.5652472972869873, -0.24369046092033386, -0.44877588748931885, 0.5365680456161499, -0.6846871972084045, -0.30765971541404724, -1.0607717037200928, 0.23750393092632294, -0.2918246388435364, 0.37084856629371643, 0.33381301164627075, 0.2870428264141083, 0.1623789519071579, 0.0035640273708850145, 0.5249542593955994, 0.43210992217063904, -0.35197198390960693, 0.2832425534725189, -0.623075544834137, -0.07633570581674576, 0.31782546639442444, 0.4762268662452698, -0.3000381290912628, -0.5586664080619812, -0.4845813810825348, -0.2589055001735687, -0.2099001258611679, -0.5196516513824463, -0.09201406687498093, -0.04715808108448982, -0.9174273014068604, -0.3203014135360718, 0.25689661502838135, -0.6503217816352844, -0.4368835389614105, 0.4302220940589905, 0.34393274784088135, 0.11495929211378098, -1.3753074407577515, -1.247054934501648, -0.08060342818498611, -0.7648417949676514, -1.014102578163147, 0.3327588140964508, -0.08687804639339447, -0.23453378677368164, -0.7304036617279053, 0.03292550891637802, -0.23306329548358917, 1.2760039567947388, -0.8884649276733398, 0.7622571587562561, 0.04830257222056389, -0.1938861608505249, -0.6010261178016663, 0.394559770822525, 0.9586482644081116, 0.13452458381652832, 0.2422393411397934, -0.7377797961235046, -0.32138171792030334, -0.16605624556541443, -0.4199690520763397, 0.3157688081264496, 0.09948335587978363, 0.33363503217697144, 0.26070529222488403, -0.6781765818595886, 0.14637303352355957, 1.120395302772522, -0.6240275502204895, 0.2712809145450592, 0.16795232892036438, 1.2252291440963745, 0.37269338965415955, -0.35198572278022766, -0.24062475562095642, 0.38961300253868103, 0.500085711479187, -0.329319566488266, -0.46134787797927856, -0.2995120584964752, -0.5338538885116577, 1.1492398977279663, 2.159536600112915, 0.036917056888341904, 0.08972447365522385, -1.0702320337295532, 0.39867252111434937, -0.7056474089622498, -0.7093477845191956, 0.8770962953567505, 0.967890202999115, 0.6888092756271362, -0.41494518518447876, -0.5665221214294434, -0.34110063314437866, 0.8970920443534851, 0.14999286830425262, -0.17214617133140564, -0.5175255537033081, 0.12913917005062103, 0.47177961468696594, 0.16035141050815582, 0.6932012438774109, 0.01150559913367033, 1.2637015581130981, 14.727215766906738, 1.1487420797348022, -0.41095438599586487, 0.8702847361564636, 0.6627203822135925, 0.09910944849252701, -0.24223360419273376, -0.31071537733078003, -1.1068968772888184, -0.2540819048881531, 1.248642921447754, -0.25978681445121765, 0.8672307133674622, 0.032921772450208664, 0.07420248538255692, 0.37491506338119507, -0.45780715346336365, 0.8315388560295105, 0.6476804614067078, -0.9896098971366882, 0.8126023411750793, 0.2649605870246887, 0.4186408519744873, 0.8750072717666626, 0.34675708413124084, 1.2070499658584595, 0.27511394023895264, -0.35064637660980225, 0.2688886523246765, -0.19026412069797516, 0.6452500820159912, -0.14504198729991913, 0.41362741589546204, 0.35916560888290405, -0.9826398491859436, 0.026653163135051727, -0.5882209539413452, -1.3536821603775024, 0.09896331280469894, 0.15056157112121582, -0.5751996636390686, -0.505287766456604, -0.3965058922767639, 0.9346116781234741, 0.0282360278069973, 0.3105362057685852, 0.00544083584100008, 0.9388753175735474, -0.30206429958343506, -0.17348888516426086, -0.007250126451253891, 0.05542973801493645, 0.3088954985141754, -0.10181897133588791, 0.17173564434051514, -0.2826060354709625, 0.08420931547880173, 0.1072118729352951, -0.7803468704223633, 0.36817917227745056, -0.6105022430419922, -0.3518602252006531, -0.24415764212608337, 0.875665009021759, 0.4841691851615906, -0.12999552488327026, -0.5030518174171448, 0.40825214982032776, 1.078700304031372, 0.1345171332359314, -0.39124956727027893, -0.052135735750198364, 0.3503934442996979, -0.4088200628757477, -0.18750937283039093, 0.19933341443538666, 0.11453919112682343, -0.9462456107139587, -0.6170397996902466, -0.18158164620399475, 0.28832194209098816, -0.9998656511306763, -0.5090748071670532, 1.1447007656097412, -0.27593159675598145, -0.921694278717041, 0.38642367720603943, -0.5449537038803101, -0.3947560489177704, 0.7867939472198486, -1.5989636182785034, -0.9688557386398315, 0.542346179485321, 0.25844553112983704, -0.25569596886634827, -0.08964376896619797, 1.2047637701034546, 0.43125373125076294, -0.6028851866722107, 0.23234893381595612, 0.21377037465572357, 0.2741168737411499, 0.04885571449995041, -0.20724907517433167, 0.7853541374206543, 0.4033413529396057, -0.02119704894721508, 0.41610726714134216, -0.35491225123405457, 0.14843137562274933, -0.8432373404502869, -0.2732200622558594, 0.9194225668907166, -0.7269005179405212, -0.16363169252872467, -1.0432648658752441, -0.8904455304145813, 0.3756207823753357, 0.8609122633934021, -0.6535189747810364, 0.45918285846710205, 0.40625908970832825, -0.4353238344192505, -0.5541695356369019, -0.7526857852935791, 0.19869667291641235, 0.45823314785957336, -0.8480373024940491, -0.17983677983283997, 0.13477303087711334, 0.61634761095047, -0.6833499670028687, -0.6418787837028503, -0.12209366261959076, -0.12536008656024933, 0.286136656999588, 0.9305828809738159, -0.6471049785614014, 0.3193736672401428, 1.0812485218048096, -0.22966858744621277, -1.024686336517334, 0.036152537912130356, -0.7473364472389221, 0.5132818818092346, 0.33336499333381653, 0.8202289938926697, -0.7299700379371643, -0.13742566108703613, 0.9096686840057373, 0.2596070170402527, -0.1953379511833191, -0.5080164670944214, -0.48679351806640625, 0.2360609620809555, -0.5058455467224121, 0.15032429993152618, 0.17067226767539978, -0.19027066230773926, 0.42347052693367004, 0.30983057618141174, 0.38161492347717285, -0.25861066579818726, -0.779983639717102, 0.6219370365142822, -0.26017820835113525, 0.0400581955909729, -0.389100581407547, -0.18424320220947266, -1.321199893951416, 0.4348917305469513, -1.782746434211731, -0.10271595418453217, -1.1490117311477661, -0.40355733036994934, -0.14815592765808105, -0.35119396448135376, 0.2670772969722748, 0.3439960777759552, -0.07215140014886856, -0.18789291381835938, -0.16136440634727478, -0.3405718505382538, 1.0787153244018555, 1.4492923021316528, -0.6039639115333557, 0.03891202062368393, 0.038645338267087936, 0.19979213178157806, 0.3044305145740509, 0.6431111097335815, -0.48465630412101746, -0.9670804142951965, -1.7878586053848267, 0.055936601012945175, -0.3465155065059662, -0.3873603940010071, -0.4457528293132782, 0.2919257581233978, 0.4291156232357025, -0.06244866922497749, 0.19929881393909454, 0.4689580798149109, -0.7782556414604187, -0.4691524803638458, 0.4163972735404968, -0.4998193681240082, 0.413339227437973, 0.5029626488685608, -0.7408847808837891, -0.3512491285800934, 0.8580279350280762, 0.14685335755348206, -1.0388416051864624, -0.6590392589569092, 0.42458322644233704, -0.7016707062721252, 0.2375057190656662, -0.2174808382987976, -0.053550612181425095, -0.8281294703483582, -0.39269208908081055, -0.07077395915985107, 0.15961971879005432, -0.6410625576972961, 1.093475103378296, 0.2391108274459839, -1.5079584121704102, -0.2028534859418869, 0.6223315000534058, -0.3200913071632385, -0.41473332047462463, 0.28510865569114685, 0.46498870849609375, -0.5932236909866333, 0.7782209515571594, 0.19769281148910522, 0.31388232111930847, -1.117857813835144, -0.29992055892944336, 0.7760412096977234, -0.49414265155792236, -0.17621591687202454, 1.2414766550064087, -0.3248606324195862, -1.5729268789291382, 0.15477167069911957, -1.2133002281188965, -0.30823278427124023, -0.6095715761184692, 0.5625274181365967, 0.10012590885162354, 0.028917720541357994, -0.33451807498931885, -0.17338865995407104, 0.13853399455547333, 0.04567123204469681, -0.40470513701438904, 0.40890753269195557, -0.3784436881542206, -0.625052809715271, 0.8329156041145325, 1.2136991024017334, -0.5839094519615173, -0.2883033752441406, -0.6825595498085022, -0.5273864269256592, -0.13203546404838562, 0.2568771243095398, -0.2581234574317932, -0.9443770051002502, 0.7403730154037476, 0.6314026117324829, 0.1567518562078476, 0.22358445823192596, -0.26990586519241333, 0.46023666858673096, 0.90406733751297, 0.35646215081214905, -0.39865267276763916, -0.6857414245605469, 1.6459664106369019, 1.3506808280944824, -1.2178845405578613, -0.23835575580596924, -0.4224485158920288, -0.8779351115226746, 0.6215524673461914, 0.5191566348075867, -0.1269017606973648, 1.0882664918899536, -0.5100420117378235, 0.563404381275177, 0.7535372972488403, -0.9301124215126038, -0.1644894778728485, 0.7317540049552917, 0.6153612732887268, 1.1512213945388794, 0.22881455719470978, 0.2190553843975067, 0.44605425000190735, -0.23769129812717438, 0.18444755673408508, 0.27290767431259155, 0.24422024190425873, -0.21322667598724365, -0.21272961795330048, -0.20838411152362823, 0.6519455313682556, -0.4558670222759247, -0.9646546840667725, 0.18563665449619293, 0.7845931053161621, -0.11928074061870575, 0.4498762786388397, 0.704728901386261, 0.09339993447065353, 0.7070459127426147, 0.35761356353759766, 0.738724946975708, -0.6314100623130798, -0.41228485107421875, -0.04038568586111069, -0.561573326587677, 0.00019866660295519978, -0.3818628787994385, -0.14517942070960999, -0.4090833365917206, -0.45277780294418335, 0.16103944182395935, 0.05299046263098717, 0.24925170838832855, 0.9745283126831055, 0.41283467411994934, 0.25170284509658813, -0.3413117229938507, -0.34703993797302246, -0.08479991555213928, -1.435732364654541, -0.1294325292110443, -0.26148226857185364, -0.08771853893995285, -0.0034377563279122114, 0.30571869015693665, -0.3845408856868744]}, "authors": [{"authorId": "2119079641", "name": "Han Zhang"}], "references": [{"paperId": "b4f30496a8fa212a40461ca1bdef32169e998902", "title": "Efficient pre-training objectives for Transformers"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "35a9749df07a2ab97c51af4d260b095b00da7676", "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting"}, {"paperId": "cc50f846ed7222698d130cddbc58ed4d547914ed", "title": "CPM: A Large-scale Generative Chinese Pre-trained Language Model"}, {"paperId": "3af8a493cf756f9fe72623204a11e378a9cd71a5", "title": "EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware Multi-Task NLP Inference"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "503503ec4395ab0e36d4f0a190772f7785649319", "title": "Towards Fully 8-bit Integer Inference for the Transformer Model"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "f02bb4bc0b711fd90d32bd7dadd505465d6b45e1", "title": "Probabilistically Masked Language Model Capable of Autoregressive Generation in Arbitrary Word Order"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "c44120f765fc43994c5cfb4e12e4f62999efeae6", "title": "How Context Affects Language Models' Factual Predictions"}, {"paperId": "f4e0723e048941ea73c77a7c69dbb731ef8de750", "title": "Bridging Text and Video: A Universal Multimodal Transformer for Video-Audio Scene-Aware Dialog"}, {"paperId": "388e2fcdcefbe0834e153ab2a0be127092f9674d", "title": "DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "aac508ec275994051e82ef039aee399d22f069eb", "title": "Improving the Transformer Translation Model with Document-Level Context"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Set transformer: A framework for attention-based permutation-invariant neural networks"}]}