{"paperId": "e0d3b7d2b7bd26dd526e48c2bae64e14dc5babcf", "abstract": "Multivariate time series forecasting focuses on predicting future values based on historical context. State-of-the-art sequence-to-sequence models rely on neural attention between timesteps, which allows for temporal learning but fails to consider distinct spatial relationships between variables. In contrast, methods based on graph neural networks explicitly model variable relationships. However, these methods often rely on predefined graphs that cannot change over time and perform separate spatial and temporal updates without establishing direct connections between each variable at every timestep. Our work addresses these problems by translating multivariate forecasting into a\"spatiotemporal sequence\"formulation where each Transformer input token represents the value of a single variable at a given time. Long-Range Transformers can then learn interactions between space, time, and value information jointly along this extended sequence. Our method, which we call Spacetimeformer, achieves competitive results on benchmarks from traffic forecasting to electricity demand and weather prediction while learning spatiotemporal relationships purely from data.", "venue": "arXiv.org", "year": 2021, "citationCount": 54, "influentialCitationCount": 2, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work addresses multivariate forecasting into a \"spatiotemporal sequence\"formulation where each Transformer input token represents the value of a single variable at a given time and Long-Range Transformers can then learn interactions between space, time, and value information jointly along this extended sequence."}, "embedding": {"model": "specter_v2", "vector": [0.2870050370693207, 0.21343626081943512, -0.37896013259887695, -0.2661969065666199, 0.13116545975208282, -0.22866179049015045, 1.0948028564453125, 0.10592984408140182, 0.024761123582720757, -0.026057150214910507, 0.5799245238304138, -0.1456597000360489, -0.013871579430997372, -0.5373201966285706, -0.0008212084067054093, -0.16933271288871765, -1.3846360445022583, 0.14115369319915771, 0.2942095398902893, -0.2904791831970215, 0.22064168751239777, -0.14158418774604797, -1.0905201435089111, -0.009603049606084824, 0.2625701427459717, 1.0832473039627075, -0.059507548809051514, 0.7403315305709839, -0.4243840277194977, 0.7004932165145874, 0.2988032400608063, -0.22917187213897705, 0.5151934027671814, 0.30117228627204895, -0.05347536876797676, -0.43136826157569885, 0.1912040263414383, -0.27788782119750977, -0.7480326890945435, 0.34693753719329834, -0.6833415031433105, 0.5017497539520264, 0.4051252603530884, -1.189021348953247, 0.0883660614490509, 0.5300209522247314, 0.6002102494239807, 0.9454699754714966, -0.13974487781524658, -0.6181102395057678, 1.582248330116272, -0.47528350353240967, -0.028739556670188904, 1.0339001417160034, 0.33866333961486816, -0.18486014008522034, -0.1723974198102951, -0.9026203155517578, 0.9671744108200073, 0.5358554124832153, -0.5504412651062012, 0.23166558146476746, 0.3970268964767456, -0.43397194147109985, 1.7190232276916504, -0.12500183284282684, 0.5991955399513245, 0.4772935211658478, 0.13416483998298645, 1.0095237493515015, -0.15216396749019623, -0.4950562119483948, -0.13980263471603394, -0.22496548295021057, 0.012350888922810555, 0.45567813515663147, -0.6876236796379089, 0.5002691745758057, -1.5011540651321411, -0.16963925957679749, 0.3446148633956909, 0.43872344493865967, 0.07718195021152496, 0.028020944446325302, -0.032296936959028244, 0.7661762237548828, 0.3783467411994934, 0.6638986468315125, -0.5924045443534851, 0.5819279551506042, 0.3673986494541168, 0.30065298080444336, 0.11832800507545471, 0.19308927655220032, 0.1635521799325943, 0.09004487842321396, -0.8011517524719238, 0.011722415685653687, -0.1796703040599823, 0.41773170232772827, -0.25927847623825073, 0.3093774914741516, -0.6368751525878906, 0.0635911300778389, 1.0348351001739502, -0.0481632724404335, 0.1354127675294876, -0.8139143586158752, 0.42664894461631775, -0.6148404479026794, 0.3279859721660614, -1.4461686611175537, -0.1556546688079834, -0.15797050297260284, -0.6199697256088257, -0.9375643730163574, -0.30276161432266235, 0.408101350069046, -0.4553065299987793, 0.4198801517486572, -0.5173951983451843, 0.7372474670410156, -0.2311522215604782, -0.04540955275297165, 0.23091858625411987, 1.1177066564559937, 0.012077007442712784, -0.10858792811632156, 0.028747864067554474, -0.6680004000663757, -0.5115945339202881, -0.7904341220855713, 0.10579050332307816, 0.5215435028076172, -0.0948496013879776, 0.09516292065382004, -1.0445866584777832, -0.8067441582679749, -0.5630063414573669, 0.7495663166046143, -0.8530864119529724, -0.7374005317687988, 1.2461042404174805, 0.04396331310272217, -1.0115140676498413, 1.3024344444274902, -0.5169416666030884, -0.25414586067199707, 0.5120960474014282, 0.09000012278556824, 0.6423441767692566, 0.21938736736774445, -1.6754640340805054, 0.6116794943809509, -0.057210568338632584, -0.25700807571411133, -0.14380516111850739, -0.5927410125732422, -0.8276729583740234, 0.2609698176383972, 0.10388413816690445, -0.08900846540927887, 0.9473922848701477, 0.2915174961090088, -0.9412370324134827, 0.10043542087078094, 0.04561324417591095, -0.1606709510087967, 0.3222736418247223, 0.19900016486644745, -0.7533009052276611, -0.37564945220947266, 0.01045453641563654, 0.1594654619693756, 0.0538153313100338, 0.08494079858064651, -0.7271075248718262, 0.040313586592674255, -0.45358768105506897, -0.29902806878089905, -0.6645023822784424, 0.7252357602119446, -0.1647680252790451, -0.29360586404800415, -0.349016010761261, 1.0702558755874634, -0.44902700185775757, -0.1020275205373764, 0.06179119274020195, -1.20113205909729, 0.6016632318496704, -0.05833980813622475, 1.2896956205368042, -0.5128780007362366, -0.792900025844574, 0.28002506494522095, -0.09069745987653732, -0.29148802161216736, -0.8297167420387268, 0.7553579807281494, -0.42666786909103394, -0.09458909928798676, 0.08974386006593704, -0.5166527032852173, -0.19621096551418304, 0.349545955657959, -0.8378406167030334, -0.23442377150058746, -0.343971312046051, 0.889003574848175, -1.2500816583633423, 0.07800398021936417, 0.4698801338672638, 0.13142728805541992, -0.39723145961761475, 1.324554204940796, -0.33525753021240234, -0.16192170977592468, -0.3505408763885498, -0.16091853380203247, -0.1160033643245697, -0.4376627504825592, 0.6736975312232971, -0.0008323467336595058, -0.1191307008266449, 0.37368884682655334, -0.3113572895526886, 0.8240382671356201, -0.050412196666002274, 0.7227523326873779, -0.5550770163536072, -1.2132776975631714, 0.6030281782150269, 0.21476563811302185, 0.839134693145752, -0.8843196034431458, 0.01613455079495907, -0.03684660419821739, -1.2453718185424805, 0.1640883833169937, 0.46634534001350403, 0.9610813856124878, -0.28587159514427185, 0.15269489586353302, 0.35452771186828613, -0.005313550122082233, 0.654478132724762, 0.20935779809951782, 0.836726188659668, 0.47033271193504333, 0.2601427137851715, 0.1817840188741684, 0.015891483053565025, -0.9759727120399475, 0.22878651320934296, 0.3283691704273224, 0.6014852523803711, 0.18158085644245148, 0.659824013710022, -0.9308838248252869, -0.31332165002822876, -0.09236294776201248, 0.7372377514839172, 1.2576806545257568, -0.10651137679815292, -0.5394218564033508, 0.10170328617095947, -0.1830696016550064, 0.21675778925418854, 0.3668423295021057, -0.6575045585632324, 0.04939951375126839, -0.42412224411964417, -0.7623610496520996, 0.5713165402412415, 0.8607835173606873, 0.49935808777809143, -0.5609623789787292, -0.1955944001674652, 0.058301959186792374, 0.26742973923683167, -0.5324863195419312, -0.22341644763946533, 0.3695698380470276, -0.39105889201164246, -0.0708433985710144, 0.13098406791687012, 0.3751735985279083, -0.22537629306316376, -0.7379650473594666, 0.9582667350769043, -0.6150814890861511, -0.18674442172050476, 0.3024269938468933, 0.681418776512146, -0.8050775527954102, 0.2444252371788025, -0.3431628346443176, -0.13845421373844147, 0.06172451376914978, 0.3757900595664978, -0.2109742909669876, -0.16723163425922394, -0.05826086550951004, -0.13477423787117004, 0.1473008692264557, -0.26583781838417053, -0.08014867454767227, 0.22485823929309845, 0.16840486228466034, 0.17282097041606903, -0.6401118040084839, 0.7693713903427124, -0.1936902552843094, -1.1387598514556885, 0.267162948846817, -0.9542789459228516, -0.47070449590682983, 0.6578934788703918, -0.6184125542640686, 0.1404772698879242, -1.1264442205429077, 0.7131288051605225, -0.5909150838851929, -0.3660672903060913, 0.5192368030548096, 0.5216425657272339, 0.3372979164123535, -0.1271006315946579, 0.39528852701187134, -0.08529386669397354, 0.10158590972423553, 0.2577907145023346, -0.5862549543380737, 0.7275664210319519, 0.26037341356277466, 0.21487608551979065, -0.009331448934972286, 0.46226733922958374, -0.5314168334007263, -0.726021409034729, -0.6055638194084167, -0.5045809745788574, -0.8352725505828857, 0.22397802770137787, -0.23583920300006866, -1.1684565544128418, -0.10831824690103531, -1.0339103937149048, -0.826144814491272, 0.09268459677696228, -0.44007667899131775, 0.06695719063282013, -1.0936014652252197, -1.0385805368423462, -0.8541384339332581, -0.20501808822155, -0.27934619784355164, 0.024734247475862503, 0.14691326022148132, -0.45127275586128235, -1.1799590587615967, 0.029587581753730774, -0.6717090010643005, 0.9633001089096069, 0.3091951608657837, 0.6233809590339661, 0.040545664727687836, -0.5258515477180481, -0.10155215859413147, 0.30185654759407043, -0.10924111306667328, 0.008204414509236813, 0.09599661082029343, -0.37077027559280396, 0.5109292268753052, -0.6182999610900879, 0.13094547390937805, -0.21700036525726318, 0.2928621172904968, 1.2776652574539185, -0.06117897480726242, -0.49618086218833923, 0.2270423024892807, 1.4162694215774536, -0.12028668820858002, -0.18361003696918488, 0.3373352587223053, 0.8042404055595398, 0.5892812609672546, 0.02198425494134426, 1.0488505363464355, 0.5032529830932617, 0.5751175880432129, 0.5491864085197449, -0.18071739375591278, 0.24981096386909485, -0.7069046497344971, 0.07438423484563828, 1.3910720348358154, -0.21764059364795685, -0.23534725606441498, -1.081903100013733, 0.8065701127052307, -1.2798951864242554, -1.1205195188522339, 0.6104938387870789, 0.7800526022911072, -0.1317281723022461, -0.41373422741889954, -0.12019222229719162, 0.1673506498336792, 0.3975730836391449, 0.8378587365150452, -0.47389402985572815, -0.3163492977619171, 0.1770625114440918, 0.5312528014183044, 0.4596221148967743, 0.677013635635376, -0.05381665378808975, 0.1193743571639061, 15.071057319641113, 0.5672210454940796, 0.050188761204481125, 0.199699267745018, 0.5092809796333313, 0.042418282479047775, -0.46483752131462097, -0.054764777421951294, -0.8704727292060852, 0.2518794536590576, 1.6417165994644165, -0.11382973939180374, 0.8612692356109619, -0.2602500319480896, 0.23019245266914368, 0.18537931144237518, -0.6445600986480713, 0.8187804222106934, 0.4647315740585327, -1.5157259702682495, 0.23464667797088623, 0.26588568091392517, 0.11666259169578552, 0.571179211139679, 0.6959402561187744, 0.35739096999168396, 0.8110570311546326, -0.5993245840072632, 0.6867433786392212, 0.5556434988975525, 1.0142545700073242, -0.28290149569511414, 0.0944695845246315, 0.19816522300243378, -1.7932077646255493, -0.45790860056877136, -0.45417702198028564, -1.1885830163955688, 0.5648438334465027, -0.03401691094040871, -0.306037038564682, -0.11180848628282547, 0.37652796506881714, 1.42208731174469, 0.11411529779434204, 0.2798117399215698, -0.2638324201107025, 0.6347296833992004, 0.09662855416536331, -0.06473087519407272, 0.35463976860046387, 0.2865231931209564, -0.1468263566493988, -0.4553205668926239, 0.2295958399772644, 0.06358201801776886, 0.11998391896486282, -0.011535062454640865, -0.06838709115982056, -0.25460970401763916, -0.7954922914505005, -0.3429500460624695, 0.3258589208126068, 0.5406685471534729, 0.48231253027915955, 0.06050725653767586, -0.6870836019515991, -0.023447804152965546, 0.34739950299263, 0.2210879623889923, -0.6005976796150208, -0.28743165731430054, 0.42952585220336914, -0.055269673466682434, -0.0493975393474102, 0.439889132976532, -0.5229819416999817, -0.249762162566185, -1.0082107782363892, 0.0692143514752388, 0.9255228042602539, -1.272565484046936, -0.968454897403717, 0.9148428440093994, -0.18402042984962463, -0.6120406985282898, -0.04883525148034096, -0.9073732495307922, -0.5070661306381226, 0.2928115129470825, -1.3808647394180298, -0.31195932626724243, -0.30635392665863037, 0.22762157022953033, -0.4139441251754761, -0.11065962165594101, 1.0050034523010254, -0.05248703062534332, -0.11507690697908401, -0.36561319231987, -0.005079484544694424, -0.09718628972768784, -0.49645447731018066, -0.9199478626251221, 0.4599706828594208, 0.27945125102996826, -0.011115041561424732, -0.13110728561878204, 0.02633707784116268, -0.023748446255922318, -0.311648428440094, -0.21774297952651978, 0.6761815547943115, -0.9772456884384155, 0.5357541441917419, -0.8340820074081421, -1.026214361190796, 0.45886436104774475, 0.7088090181350708, -0.26015275716781616, 0.28365376591682434, 0.03033529594540596, -0.34104812145233154, -0.6722159385681152, -0.6115592122077942, 0.05312197282910347, 0.38616663217544556, -0.6709914207458496, -0.34914642572402954, -0.0487288199365139, 0.25689515471458435, -0.48942476511001587, -1.0825178623199463, -0.0005048462189733982, 0.222291961312294, -0.23705321550369263, 0.9993475675582886, -0.19385656714439392, 0.5309433341026306, 0.8487980961799622, -0.2725691497325897, -0.5442231297492981, -0.2084682285785675, -1.0708256959915161, -0.07113809883594513, 0.34553247690200806, 0.30642592906951904, -0.774824857711792, 0.4895581305027008, 0.8153117895126343, 0.45627260208129883, -0.5545271039009094, -0.3590019643306732, -0.15219862759113312, -0.25561076402664185, -0.651535153388977, 0.9805471897125244, 0.3847634494304657, 0.03799119219183922, -0.022044848650693893, 0.04367534816265106, 0.7511337399482727, -0.08561740070581436, -0.26249924302101135, -0.007159177213907242, -0.5656642317771912, 0.11243422329425812, -0.6851550936698914, -0.5852910876274109, -1.236655354499817, -0.002129185711964965, -1.0119338035583496, -0.1927790492773056, -1.3762058019638062, -0.705969512462616, 0.02875041961669922, -0.731120765209198, 0.37624895572662354, 0.7291392087936401, -0.7731987833976746, -0.5446048974990845, -0.8885290622711182, -0.6297817826271057, 0.8377938270568848, 0.6234147548675537, -0.6366115808486938, 0.08412070572376251, 0.005323177669197321, 0.4715394973754883, 0.06019580736756325, 0.5327687859535217, -0.4478789269924164, -0.8687337636947632, -0.8881020545959473, 0.24999071657657623, 0.4539708197116852, -0.024457575753331184, -0.619562566280365, 0.827189028263092, -0.47579458355903625, 0.017564954236149788, -0.5538330674171448, 0.5919731855392456, -0.9326744079589844, -0.1348557472229004, 0.17495518922805786, -0.7823722958564758, 0.4837447702884674, -0.02454962767660618, -0.2131628841161728, -0.31270185112953186, 1.2604074478149414, -0.2503698170185089, -0.8160619735717773, -0.6566917300224304, 1.0735437870025635, -0.5763100385665894, -0.16256754100322723, 0.032321084290742874, -0.38285934925079346, -0.888812243938446, -0.6041175723075867, 0.1269288808107376, 0.8916656970977783, -0.6659926772117615, 1.134376883506775, 0.301107257604599, -1.1061865091323853, 0.3704644441604614, 0.21186651289463043, -0.3069749176502228, -0.24521490931510925, 0.271797239780426, 0.2729492783546448, 0.09455972164869308, 0.7311841249465942, -0.05917280912399292, 0.2032008171081543, -0.6459139585494995, 0.04276217892765999, 0.6998437643051147, -0.44535762071609497, -0.1676826924085617, 0.7993801832199097, -0.4010394215583801, -0.7478869557380676, 0.6501666903495789, -1.0433145761489868, -1.1902742385864258, -0.10723146796226501, 0.47104182839393616, 0.5779945850372314, -0.5440776348114014, 0.1328975111246109, -0.4876784384250641, 0.28902530670166016, 0.5832094550132751, -0.3060759902000427, 1.3850979804992676, -0.19705992937088013, -0.32514700293540955, 1.0083849430084229, 0.41514769196510315, -0.6882398128509521, -0.9929012060165405, -0.4967721402645111, -0.23024193942546844, -0.6946132779121399, 0.2308654487133026, -0.20295439660549164, -0.9178102016448975, 0.8012691140174866, 0.5000879168510437, 0.8485945463180542, 0.33686134219169617, 0.036724403500556946, 0.1984325349330902, 0.26819372177124023, 0.297351598739624, -0.5476401448249817, -0.3449588418006897, 0.7829260230064392, 1.2494221925735474, -0.37761062383651733, 0.24955354630947113, 0.27392882108688354, -0.46076542139053345, 1.1839826107025146, 0.5155516862869263, 0.1094498485326767, 1.065790057182312, -0.2563793957233429, 0.11789406836032867, -0.046370189636945724, -1.5151803493499756, -0.018649308010935783, 0.7172597050666809, 1.2690134048461914, 0.12490443140268326, 0.39946791529655457, 0.5377490520477295, 0.6601666808128357, 0.0832500234246254, 0.31751495599746704, 0.3652850389480591, 0.3641209602355957, 0.09501390904188156, -0.12292107939720154, 0.21521662175655365, 0.8719674348831177, -0.5837605595588684, -0.1487167626619339, 0.3749157786369324, 0.3821427822113037, -0.04137881100177765, 1.0401089191436768, 1.1323014497756958, -0.32045978307724, 0.7271875739097595, -0.4999716579914093, 0.18539245426654816, -0.3791654706001282, -0.14966392517089844, -0.2713215947151184, -0.424698144197464, -0.662603497505188, -0.40894991159439087, -0.8861275911331177, -0.2733372449874878, -0.39072954654693604, 0.4102780222892761, 0.5025134682655334, -0.11999182403087616, 0.8797988891601562, 0.21693450212478638, 0.5723401308059692, 0.09098224341869354, -0.6483046412467957, -0.034044742584228516, -0.4660969376564026, -0.15423321723937988, -0.5287990570068359, -0.0355854332447052, -0.46722131967544556, -0.20403167605400085, -0.47639957070350647]}, "authors": [{"authorId": "1829303908", "name": "J. Grigsby"}, {"authorId": "2108194537", "name": "Zhe Wang"}, {"authorId": "121817403", "name": "Yanjun Qi"}], "references": [{"paperId": "93fdf5cf598aefb0335f001039e83494dc721c3a", "title": "General-Purpose In-Context Learning by Meta-Learning Transformers"}, {"paperId": "394805c349140f9c2910d1869378657eef7fe1e7", "title": "Spatial-Temporal Adaptive Graph Convolution with Attention Network for Traffic Forecasting"}, {"paperId": "5be02c8db2078bb72224438df8003552e49b23a8", "title": "Are Transformers Effective for Time Series Forecasting?"}, {"paperId": "630468bcafc54001f7efdb32f671f06febc96079", "title": "Spatial\u2013Temporal Dynamic Graph Convolutional Network With Interactive Learning for Traffic Forecasting"}, {"paperId": "48c3cd0af13d0fecb1b3cb5a1383f5e36acb185c", "title": "Towards Spatio- Temporal Aware Traffic Time Series Forecasting"}, {"paperId": "a31f75b7bc853a2fb7673684428eb85f11b21c2a", "title": "Preformer: Predictive Transformer with Multi-Scale Segment-Wise Correlations for Long-Term Time Series Forecasting"}, {"paperId": "c49ac1f916d6d2edeb187e6619c8d23acd95eb21", "title": "cosFormer: Rethinking Softmax in Attention"}, {"paperId": "68d14c4203c8798ad94ddfc7bf1616b92ae25299", "title": "ETSformer: Exponential Smoothing Transformers for Time-series Forecasting"}, {"paperId": "563bac1c5cdd5096e9dbf8d4f3d5b3c4f7284e06", "title": "FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting"}, {"paperId": "80000464a095e2bf86c11db07bf1a72c6c95df9b", "title": "Spatio-Temporal meets Wavelet: Disentangled Traffic Flow Forecasting via Efficient Spectral Graph Attention Network"}, {"paperId": "eacf6b222cf2b3072e8472e622a2d4f53503118c", "title": "DMGCRN: Dynamic Multi-Graph Convolution Recurrent Network for Traffic Forecasting"}, {"paperId": "15ff155b9c370ef7edca7f727ad455e8c56dab7e", "title": "Meta Graph Transformer: A Novel Framework for Spatial-Temporal Traffic Prediction"}, {"paperId": "d033bdd1392f0ab4dfa5d6bd58a2c068631fe155", "title": "STNN: A Spatial-Temporal Graph Neural Network for Traffic Prediction"}, {"paperId": "64c0ad3ec19661cb08472f59b7cee4500e3866a2", "title": "TVGCN: Time-variant graph convolutional network for traffic forecasting"}, {"paperId": "6655c96eed35aceb2136809e4c0cd702cf4b41be", "title": "Yformer: U-Net Inspired Transformer Architecture for Far Horizon Time Series Forecasting"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "fc46ccb83dc121c33de7ab6bdedab7d970780b2f", "title": "Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting"}, {"paperId": "1f79005aecc269af7bd1c03cd09b3a67d934f795", "title": "Spatial-temporal graph neural network for traffic forecasting: An overview and open research issues"}, {"paperId": "e3288a7c7f2a7e272392f10491ed85d178d80089", "title": "Monash Time Series Forecasting Archive"}, {"paperId": "e32a12b14e212506115cc6804667b3d8297917e1", "title": "Poolingformer: Long Document Modeling with Pooling Attention"}, {"paperId": "f4566761fe39c4b5273d696d9bc3f4195c9325bb", "title": "Long-Span Summarization via Local Attention and Content Selection"}, {"paperId": "6709d5583f658f589ae6a2184805933aceb18849", "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers"}, {"paperId": "f4cd7998107d51963da4c3fbc423da191e1f5764", "title": "PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models"}, {"paperId": "14c52ffa7ea9c1971d5d82ea369c946c98d056a9", "title": "LocalViT: Bringing Locality to Vision Transformers"}, {"paperId": "0343875960a81feb75293a747d29ccb013285d23", "title": "UniDrop: A Simple yet Effective Technique to Improve Transformer without Extra Cost"}, {"paperId": "8de67fc4ef46eaff3378cc1062a51cf47276deab", "title": "Spatial\u2010temporal attention wavenet: A deep learning framework for traffic prediction considering spatial\u2010temporal dependencies"}, {"paperId": "b6382a7351c0c595f91472ac71d3b2d87b3c4844", "title": "ViViT: A Video Vision Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "11de4622bb72bb754762c2add2c12679ab2d7c22", "title": "Transfer Learning for Predicting Virus-Host Protein Interactions for Novel Virus Sequences"}, {"paperId": "24cff2aafcd66e1b7be4f647e478e8e73cf410a5", "title": "Spatial-Temporal Fusion Graph Neural Networks for Traffic Flow Forecasting"}, {"paperId": "35a9749df07a2ab97c51af4d260b095b00da7676", "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "9436806f98d0c71245135d5d45025427bb36cd33", "title": "Optimizing Transformer for Low-Resource Neural Machine Translation"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "ffd3b0192d5c03689d8393f44708cd5a835a256b", "title": "ST-GRAT: A Novel Spatio-temporal Graph Attention Networks for Accurately Forecasting Dynamically Changing Road Speed"}, {"paperId": "2051548f7681c96d603de932ee23406c525276f9", "title": "A Transformer-based Framework for Multivariate Time Series Representation Learning"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7ac55add5e93ca3fb9addabcb95714a3aa1c3361", "title": "Few-shot Learning for Time-series Forecasting"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "afd9e44d7d7b3a947bade59bb1bd000e5271a48b", "title": "Skeleton-based action recognition via spatial and temporal transformer networks"}, {"paperId": "68c24563bfce83fd112bdfbfadf36035564eb629", "title": "Spatiotemporal Attention for Multivariate Time Series Prediction and Interpretation"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "e00484961fb2f30d2d48a5f9853fa3ebab140cac", "title": "Improving Transformer Optimization Through Better Initialization"}, {"paperId": "8b163b75a6b833911c4e958f8bd52124205382ec", "title": "Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting"}, {"paperId": "5180bebd4a9e403f57c3730e86e00619308d9009", "title": "Multi-STGCnet: A Graph Convolution Based Spatial-Temporal Framework for Subway Passenger Flow Forecasting"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "1ff858576af755583559fdfcd366bd16002da297", "title": "Traffic transformer: Capturing the continuity and periodicity of time series for traffic forecasting"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "75e924bd79d27a23f3f93d9b1ab62a779505c8d2", "title": "Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks"}, {"paperId": "02d49b4dbaf8c093034918a76648fea53961753d", "title": "Time-series forecasting with deep learning: a survey"}, {"paperId": "9f3eef3283597f9e5199897e8db6334b2d64a614", "title": "Neural forecasting: Introduction and literature overview"}, {"paperId": "8d908042f139575d6688c745e94156c9df6eae07", "title": "Understanding the Difficulty of Training Transformers"}, {"paperId": "f420663fe8c69ed5ea5236201a1f4c734cd145a7", "title": "Spatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting"}, {"paperId": "5c27f7106d2f0c95fc51fb98ece672e00185ffa1", "title": "Scheduled DropHead: A Regularization Method for Transformer Models"}, {"paperId": "4076e421d1758fdb68411242044cd45747b7e35b", "title": "PowerNorm: Rethinking Batch Normalization in Transformers"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "2e6a8914745319cae682b807a6b4ae470b08c54a", "title": "Meta-learning framework with applications to zero-shot time-series forecasting"}, {"paperId": "da5d3cfc9898cbf05fdd5a6954378b07a4f8d846", "title": "Physical-Virtual Collaboration Modeling for Intra- and Inter-Station Metro Ridership Prediction"}, {"paperId": "24b50f529a69aca17f2729dc3a9f8c7ada1a7d02", "title": "Spatial-Temporal Transformer Networks for Traffic Flow Forecasting"}, {"paperId": "6a9d69fb35414b8461573df333dba800f254519f", "title": "Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "fc41d75288a81dd7e30087480f51821fc6572d95", "title": "GMAN: A Graph Multi-Attention Network for Traffic Prediction"}, {"paperId": "2e14e84ccec924ed770b58108ad1d9de6f0ca295", "title": "BP-Transformer: Modelling Long-Range Context via Binary Partitioning"}, {"paperId": "46b3ba0f3cb8340bc94f26e0fdf6dc4e38f68948", "title": "Hierarchical Transformers for Long Document Classification"}, {"paperId": "703685e969fed715e13937c11d7ecc5cc7c4dfd0", "title": "Transformers without Tears: Improving the Normalization of Self-Attention"}, {"paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1", "title": "Reducing Transformer Depth on Demand with Structured Dropout"}, {"paperId": "36cf500079b82e3adf4a3afe3356c1c03426bdcd", "title": "Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting"}, {"paperId": "10ffbbcf23923ffef2b1ae78b516ec4329c78727", "title": "Time2Vec: Learning a Vector Representation of Time"}, {"paperId": "36e30516683032634975c53e60f3737b6e35ff80", "title": "Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting"}, {"paperId": "fae129338c0899576524506008427f64477d3967", "title": "Graph WaveNet for Deep Spatial-Temporal Graph Modeling"}, {"paperId": "1ef6b9c734ceb775bc6055af93918b5db5bf190d", "title": "Evaluating time series forecasting models: an empirical study on performance estimation methods"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "2a31319e73d4486716168b65cdf7559baeda18ce", "title": "Star-Transformer"}, {"paperId": "9a57d9234eeb5570255910b29c187b9ce43d64e1", "title": "Contextualized Non-local Neural Networks for Sequence Learning"}, {"paperId": "5d1d53c671b20db116ba8c91c6446bb4757614da", "title": "Temporal pattern attention for multivariate time series forecasting"}, {"paperId": "ab1f816ce79817a09487ea7866c95ce930d37497", "title": "Forecasting at Scale"}, {"paperId": "72edcb3788f9c141a3ed28e6d36f75ca4977d27e", "title": "Spatio-temporal Graph Convolutional Neural Network: A Deep Learning Framework for Traffic Forecasting"}, {"paperId": "9ba0186ed40656329c421f55ada7313293e13f17", "title": "Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "4eebe0d12aefeedf3ca85256bc8aa3b4292d47d9", "title": "DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks"}, {"paperId": "76624f8ff1391e942c3313b79ed08a335aa5077a", "title": "A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction"}, {"paperId": "5f6c1b0a780cbaae92f6169312b7441decc9d6ef", "title": "Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks"}, {"paperId": "2c7752c6d8015293ff0914f0f827225816513b97", "title": "Conditional Time Series Forecasting with Convolutional Neural Networks"}, {"paperId": "7c6de5a9e02a779e24504619050c6118f4eac181", "title": "Learning Convolutional Neural Networks for Graphs"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "c1126fbffd6b8547a44c58b192b36b08b18299de", "title": "Neural Turing Machines"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "5e925a9f1e20df61d1e860a7aa71894b35a1c186", "title": "Spectral Networks and Locally Connected Networks on Graphs"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "8dcaf96f66340c453e775ab217a1b1bd9ba63449", "title": "Time series analysis, forecasting and control"}, {"paperId": "71423c75a47c1caf4d5ac8548b2f076c99a9da95", "title": "DSTAGNN: Dynamic Spatial-Temporal Aware Graph Neural Network for Traffic Flow Forecasting"}, {"paperId": "30dcc0e191a376fea0e7a46f94c53872c029efc9", "title": "Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting"}, {"paperId": "8a85ef6a7ebcd8735b868bf9c4a77e6a3c195caa", "title": "Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation"}, {"paperId": "0e95008a8c49a4c2538aed62ff61977ff7b47ca5", "title": "Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": null, "title": "National Weather Service Automated Surface Observing System (ASOS)"}, {"paperId": null, "title": "Unifying space and time in message passing"}, {"paperId": "3992ababc6f288b49e235f608ce2b1710407bb75", "title": "A hybrid method of exponential smoothing and recurrent neural networks for time series forecasting"}, {"paperId": "fb0bd71d0921ca53c6df689c687d8cd75bad3a40", "title": "Adversarial Sparse Transformer for Time Series Forecasting"}, {"paperId": "0eec749c9d712bdf8e807e9c3424514436eba849", "title": "The M4 Competition: 100,000 time series and 61 forecasting methods"}, {"paperId": null, "title": "Transformers are graph neural networks. The Gradient (2020)"}, {"paperId": null, "title": "Data dropout for wikitext-2"}, {"paperId": "81a4fd3004df0eb05d6c1cef96ad33d5407820df", "title": "A Comprehensive Survey on Graph Neural Networks"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "\u201cPyTorch Lightning\u201d"}, {"paperId": null, "title": "is a deep learning architecture for sequence-to-sequence prediction that is widely used in natural language processing (NLP)"}]}