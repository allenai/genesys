{"paperId": "e4add4391dfa2a806a50cc1fbe9a9696dac9501f", "abstract": "Secure multi-party computation (MPC) enables computation directly on encrypted data and protects both data and model privacy in deep learning inference. However, existing neural network architectures, including Vision Transformers (ViTs), are not designed or optimized for MPC and incur significant latency overhead. We observe Softmax accounts for the major latency bottleneck due to a high communication complexity, but can be selectively replaced or linearized without compromising the model accuracy. Hence, in this paper, we propose an MPC-friendly ViT, dubbed MPCViT, to enable accurate yet efficient ViT inference in MPC. Based on a systematic latency and accuracy evaluation of the Softmax attention and other attention variants, we propose a heterogeneous attention optimization space. We also develop a simple yet effective MPC-aware neural architecture search algorithm for fast Pareto optimization. To further boost the inference efficiency, we propose MPCViT+, to jointly optimize the Softmax attention and other network components, including GeLU, matrix multiplication, etc. With extensive experiments, we demonstrate that MPCViT achieves 1.9%, 1.3% and 3.6% higher accuracy with 6.2\u00d7, 2.9\u00d7 and 1.9\u00d7 latency reduction compared with baseline ViT, MPCFormer and THE-X on the Tiny-ImageNet dataset, respectively. MPCViT+ further achieves a better Pareto front compared with MPCViT. The code and models for evaluation are available at https://github.com/PKU-SEC-Lab/mpcvit.", "venue": "IEEE International Conference on Computer Vision", "year": 2022, "citationCount": 6, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2211.13955", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes an MPC-friendly ViT, dubbed MPCViT, to enable accurate yet efficient ViT inference in MPC, and develops a simple yet effective MPC-aware neural architecture search algorithm for fast Pareto optimization."}, "embedding": {"model": "specter_v2", "vector": [0.734276533126831, 0.68378084897995, -0.6476554870605469, 0.4779064357280731, -0.45769840478897095, -0.3426649570465088, 0.7841300368309021, -0.12324876338243484, -0.5783957242965698, -0.7214336395263672, 0.014836668036878109, -0.20047664642333984, 0.48152267932891846, -0.04099522903561592, -0.403798371553421, -0.04254380986094475, -0.5651041865348816, -0.21476247906684875, 0.057844601571559906, 0.2088722437620163, 0.11592049896717072, -0.5044354796409607, -0.6050413250923157, 0.2557356059551239, -0.03525803983211517, 1.8231128454208374, -0.5068642497062683, 1.2191131114959717, 0.28907155990600586, 0.28707385063171387, 0.47746512293815613, -1.0500987768173218, 0.751226007938385, 0.8828553557395935, -0.44312697649002075, -0.24207964539527893, 0.2627144157886505, -0.6548269987106323, -0.7543202638626099, 1.2726008892059326, -0.1438416689634323, -0.12312256544828415, 0.359529972076416, -0.9891486763954163, -0.4956606924533844, 0.08023464679718018, 0.30567190051078796, 0.4870264530181885, -0.9130769371986389, -0.28508275747299194, 1.2258208990097046, -0.8262004852294922, -0.06075883284211159, 1.0333173274993896, 0.2887333035469055, 0.2995028495788574, -0.22109314799308777, -0.6227454543113708, 0.3630847930908203, 0.4158311188220978, -0.748068630695343, -0.19664257764816284, 0.06570804864168167, 0.25989440083503723, 1.2459757328033447, -0.09164640307426453, -0.17233674228191376, 0.6887546181678772, 0.382109135389328, 1.212143063545227, 0.5181298851966858, -0.5091028213500977, 0.04932351037859917, 0.31022268533706665, 0.4032036364078522, 0.5675110220909119, 0.003589899279177189, 0.5776671767234802, -0.8260281682014465, -0.6031739711761475, -0.03771750256419182, 0.46636807918548584, 0.19267578423023224, -0.3204527199268341, 0.07078852504491806, 0.7053274512290955, 0.45884549617767334, -0.243570014834404, -0.0666743814945221, 1.2846332788467407, 0.6488357782363892, -0.044029466807842255, 0.014573918655514717, 0.07148226350545883, -0.035707928240299225, 0.42933523654937744, -0.7189583778381348, -0.20571206510066986, 0.06341676414012909, 0.842328667640686, -0.44918426871299744, -0.2611106038093567, -0.6051347851753235, -0.5519083142280579, 1.0814127922058105, 0.4154892563819885, -0.11143194139003754, -0.6718658804893494, 0.4707343876361847, -1.0409729480743408, -0.23558279871940613, -0.6230072975158691, 0.6734884977340698, 0.22918562591075897, -1.0982292890548706, -0.24690444767475128, -0.7692880034446716, -0.013608518056571484, -0.9324949383735657, 0.18210676312446594, -0.6903732419013977, 0.39749670028686523, 0.43604177236557007, 0.44498109817504883, 0.2605118155479431, 0.49463164806365967, -0.23905564844608307, 0.4416837990283966, 1.47902250289917, -0.8136634826660156, -0.23086519539356232, -0.7451420426368713, -0.5390233993530273, -0.4574742317199707, 0.1804862767457962, 0.36181971430778503, -1.2242536544799805, -0.6246055364608765, -1.357749581336975, -0.05740804225206375, -0.649931788444519, -0.24395374953746796, 0.9236636161804199, 0.9812748432159424, -1.0445477962493896, 0.7303432822227478, -0.4577063024044037, 0.11098147183656693, 1.0230399370193481, 0.9203009605407715, 0.5210407972335815, -0.011473792605102062, -1.1370928287506104, 0.40017226338386536, 0.16874843835830688, -0.7151957750320435, -0.46079590916633606, -0.31355735659599304, -0.7207305431365967, 0.44953280687332153, 0.2273339331150055, -0.7106397747993469, 1.2220999002456665, 0.07560531049966812, -1.1488912105560303, 0.6375535726547241, -0.08594291657209396, -0.19232429563999176, 0.428850382566452, -0.026734691113233566, -0.3449341654777527, -0.06269195675849915, -0.7586608529090881, 0.2533624470233917, 1.4470303058624268, -0.15591199696063995, -0.2794605493545532, 0.25954827666282654, -0.072258859872818, -0.3020249605178833, -0.5195510387420654, 0.8565272092819214, -0.5264803767204285, -0.07645860314369202, -0.21486906707286835, 0.4379971921443939, -0.013130526058375835, 0.19076843559741974, -0.6746912002563477, -0.5317925214767456, 1.3235632181167603, 0.2638816833496094, 0.4235221743583679, -0.8914539813995361, -0.9773208498954773, 0.6176367998123169, 0.4036858379840851, 0.2887250781059265, -0.2345774918794632, 0.1783687174320221, -0.35690295696258545, 0.2693544328212738, 0.23372206091880798, -1.0592411756515503, 0.267328679561615, -0.489972323179245, -1.1242022514343262, 0.14123542606830597, 0.0819467306137085, 1.3302528858184814, -0.21478410065174103, 0.1890317052602768, -0.050139449536800385, 0.35800257325172424, -0.7727170586585999, 1.0817853212356567, -0.36441731452941895, -0.13581572473049164, -0.07183215022087097, 0.10826434940099716, 0.4651390612125397, -0.548414945602417, 0.33136263489723206, -0.6091866493225098, 0.42465415596961975, 0.25804662704467773, -0.24977895617485046, 0.5892904996871948, -0.11253762990236282, 0.6240047812461853, 0.3098990023136139, -0.48080918192863464, 0.01621096581220627, 0.6195476055145264, -0.2630082070827484, -0.27036169171333313, 0.9218513369560242, -0.19604921340942383, -0.9304558038711548, 0.350027859210968, 0.7521135807037354, 1.1817684173583984, -0.2965451180934906, 0.403100848197937, 0.31237316131591797, -0.4479478597640991, -0.5441785454750061, 0.14833717048168182, 0.496294766664505, -0.0931222215294838, 0.43204399943351746, 0.15437892079353333, -0.011813413351774216, -1.3047834634780884, -0.34305262565612793, 0.6062726378440857, 0.19090861082077026, 0.869933009147644, 0.7902332544326782, -0.6440841555595398, -0.3220234513282776, -0.1723698079586029, 0.5929569602012634, 0.9804978966712952, 0.3940790295600891, -0.3736763000488281, -0.7975789308547974, -0.7172077298164368, -0.22371934354305267, -0.49228033423423767, -0.17640288174152374, -0.12128040194511414, -0.08696428686380386, -1.2707419395446777, 1.1720913648605347, -0.1825837790966034, 1.2110804319381714, -0.4734451472759247, -0.08963610231876373, -1.1207491159439087, 0.5081343650817871, -1.110174298286438, -0.8159347772598267, 0.13606497645378113, 0.019299078732728958, -0.08419036865234375, 0.3382163345813751, 0.17317995429039001, 0.38247883319854736, -0.7147353887557983, 0.1307084858417511, -0.5202065706253052, -0.22636279463768005, 0.5056670904159546, 0.6773425936698914, -1.188211441040039, -0.40162333846092224, 0.15515045821666718, -0.22708363831043243, 0.3660318851470947, 0.17995873093605042, 0.07240521162748337, -0.22851671278476715, -0.4530300796031952, -0.5669617056846619, -0.3133623003959656, 0.22875449061393738, -0.025778543204069138, 0.5511859059333801, -0.31904351711273193, -0.7865391969680786, -0.9290616512298584, 0.8718997240066528, 0.15598511695861816, -0.5533065795898438, 0.06600406020879745, -1.268721103668213, 0.0015327404253184795, 0.3562019467353821, -0.9830723404884338, 0.01610991545021534, -0.7636049389839172, 0.30130478739738464, -1.0685440301895142, -0.225474551320076, -0.48695898056030273, 0.33489176630973816, -0.5583131313323975, 0.24597664177417755, 0.5842794179916382, 0.4491492211818695, 0.46787554025650024, 0.7404815554618835, -0.5962799191474915, 0.7952099442481995, -0.10695644468069077, 0.5605130195617676, 0.34449806809425354, 0.18451811373233795, -0.2534419298171997, -0.3190402686595917, -0.06975346803665161, 0.19521628320217133, -0.33419597148895264, 0.31101328134536743, -0.4212701916694641, -1.48090398311615, 0.06310183554887772, -1.2383790016174316, -0.0639539361000061, 0.20786520838737488, -0.2291317880153656, -0.34051966667175293, -0.681131899356842, -1.1807869672775269, -0.41853174567222595, -1.5587430000305176, -1.4450112581253052, 0.16575977206230164, 0.31711679697036743, -0.26575785875320435, -0.3577462136745453, -0.6783926486968994, -0.0819125697016716, 0.9542602300643921, -0.3771645426750183, 0.5018304586410522, 0.020153973251581192, -0.8044298887252808, -0.27778080105781555, -0.48000895977020264, 0.5662738084793091, -0.6226451396942139, 0.12086038291454315, -1.5390129089355469, 0.10763460397720337, -0.18194462358951569, -0.3218870162963867, 0.4092724025249481, 0.2322092354297638, 1.1344577074050903, -0.4052586555480957, -0.22505034506320953, 1.2562326192855835, 1.582798957824707, -0.7235864400863647, 0.6012215614318848, 0.14049801230430603, 0.97201007604599, -0.5007731318473816, -0.40614283084869385, 0.6895583271980286, 0.18596044182777405, 0.09596849232912064, 0.7538419961929321, -0.25626927614212036, 0.14065973460674286, -0.21265366673469543, 0.4068956673145294, 0.43064752221107483, 0.19563812017440796, 0.0720067247748375, -0.34171250462532043, 0.4581768810749054, -1.229833960533142, -0.6968327760696411, 0.8236337304115295, 0.7765102982521057, 0.1023053452372551, 0.08920484036207199, -0.5597204566001892, -0.1586500108242035, 0.6496901512145996, 0.9276662468910217, -0.3300049304962158, -1.2162059545516968, 0.3449937701225281, 1.0800622701644897, 1.1053091287612915, 0.4107517898082733, -0.6603237390518188, 0.39170777797698975, 14.512166023254395, 0.9712892770767212, -0.5482227802276611, 0.8881908059120178, 0.6996973752975464, 0.12883725762367249, 0.09399152547121048, 0.022367335855960846, -1.0463814735412598, 0.26900386810302734, 0.9386137127876282, 0.19941511750221252, 0.6555628776550293, 0.3110755980014801, -0.796972393989563, 0.45079484581947327, -0.26687055826187134, 0.8134769797325134, 0.5710489153862, -1.6218719482421875, -0.33484840393066406, 0.5521983504295349, 0.5248260498046875, 0.6795942783355713, 1.4404751062393188, 0.16674110293388367, 0.6363178491592407, -0.2902798056602478, 0.6186394095420837, 0.10032390058040619, 1.5982712507247925, -0.24024531245231628, 0.4609389007091522, 0.2754279375076294, -0.7952195405960083, 0.12017343938350677, -0.5368849635124207, -0.8528707027435303, -0.2380419224500656, 0.06262002885341644, -0.3979402780532837, -0.2501324713230133, 0.056291867047548294, 0.3035571277141571, 0.5425606369972229, 0.14500246942043304, -0.6656987071037292, 0.5419923067092896, -0.3988296389579773, -0.17394809424877167, 0.04003753513097763, 0.5979174971580505, 0.12702982127666473, -0.3507506847381592, -0.17422597110271454, -0.22506679594516754, -0.03249368071556091, 0.410007119178772, -0.8731042742729187, -0.7421601414680481, -0.1331118643283844, 0.061275042593479156, -0.13171222805976868, 1.0866985321044922, 0.6944526433944702, 0.556509256362915, -0.4050021469593048, 0.7974041700363159, 0.3073229193687439, 0.05836882442235947, -0.5177958011627197, -0.057829272001981735, 0.6652132272720337, -0.6749691367149353, 0.09389954060316086, 0.7292702794075012, -0.7059670090675354, -0.6806969046592712, -0.465717077255249, -0.2227482944726944, 0.5333948731422424, -0.5957863330841064, -0.6835871934890747, 0.6598520278930664, -0.606156587600708, -0.2615189552307129, 0.7245416641235352, -0.8549302816390991, -0.6263431310653687, 0.5478928685188293, -1.7290273904800415, -1.3265316486358643, 0.7652794718742371, 0.14718393981456757, -0.9105784893035889, -0.1743287891149521, 1.1671701669692993, -0.12047192454338074, -0.13327573239803314, 0.5456485748291016, -0.006249256897717714, 0.23135793209075928, 0.1194208487868309, -0.6918510794639587, 0.9824528694152832, 0.7558971047401428, -0.17556941509246826, -0.17832696437835693, -0.3912716805934906, 0.24160292744636536, -0.7014807462692261, -0.23079930245876312, 0.21906344592571259, -0.9022127389907837, -0.14151369035243988, -0.6930074095726013, -0.021275710314512253, 0.4472191035747528, 0.7344575524330139, 0.20121556520462036, 0.03901071846485138, -0.20042051374912262, -1.024738073348999, -0.4078740179538727, -0.8413869738578796, 0.0935802087187767, -0.36290639638900757, -1.1970038414001465, -0.020918438211083412, -0.2323981374502182, 0.303039014339447, -1.1249799728393555, -0.5771193504333496, -0.04652518033981323, 0.4864179193973541, -0.27437129616737366, 1.3678956031799316, 0.09196892380714417, 0.7103861570358276, 0.9635982513427734, -0.09100291132926941, -0.25186479091644287, 0.140517458319664, -1.5187686681747437, -0.5798382759094238, 0.0267778392881155, 0.28976571559906006, -0.7155073285102844, 0.796392023563385, 0.9257005453109741, 0.8846536874771118, -0.4394146203994751, -0.5817015171051025, 0.23123732209205627, -0.16839784383773804, -0.8394412398338318, 0.4309520423412323, -0.2620113492012024, 0.15040044486522675, -0.4629996716976166, -0.05107028782367706, 1.1672557592391968, 0.49047309160232544, -0.5260646939277649, 0.299069881439209, 0.05992449074983597, -0.3214111626148224, -0.326825350522995, -0.9002907276153564, -1.224719762802124, -0.19446629285812378, -1.0038878917694092, -0.46002134680747986, -0.12068197131156921, -0.2414337545633316, 0.34450963139533997, -0.5629035234451294, 0.030663607642054558, 0.08701218664646149, 0.2707460820674896, 0.22321870923042297, -0.5114858746528625, -0.3217957317829132, 0.5570688843727112, 0.5885505080223083, -0.9869754314422607, 0.5983433127403259, 0.5368599891662598, -0.3853527009487152, 0.2994098365306854, 0.43805959820747375, -0.4760812520980835, -0.6615138649940491, -0.7617376446723938, 0.07063686847686768, -0.25236576795578003, 0.3299062252044678, -0.9325354695320129, 1.0371967554092407, 0.3404569625854492, -0.03868986666202545, 0.26973122358322144, 0.5643123388290405, -1.315954566001892, -0.7762446999549866, 0.5470699667930603, -0.5983583927154541, -0.32751724123954773, -0.005325652658939362, -0.40067005157470703, 0.140639990568161, 0.9924869537353516, 0.49125510454177856, -0.3579290509223938, -0.6351101994514465, 1.011860966682434, -0.2874896228313446, -0.24374592304229736, 0.08956489711999893, -0.1504717320203781, -1.8223779201507568, -0.5476261377334595, -0.14674603939056396, 0.1059955507516861, -0.3031449019908905, 0.5821574926376343, 0.5282309055328369, -0.7084819078445435, 0.4356655180454254, 0.7380757927894592, -0.22584564983844757, -0.01456015557050705, 0.10720265656709671, 0.5610586404800415, -0.4703855514526367, 0.14623457193374634, 0.11453018337488174, 0.39774221181869507, -1.1823402643203735, 0.35766083002090454, 0.5766367316246033, -0.7693126797676086, -0.09994020313024521, 1.0720945596694946, -0.19945377111434937, -0.5773481726646423, 0.16052013635635376, -1.0424906015396118, -0.22957655787467957, -0.5983518362045288, 0.46340417861938477, 0.038869112730026245, 0.1353949010372162, 0.5387207865715027, -0.3702425956726074, 0.20721228420734406, 0.162549689412117, -0.5862277746200562, -0.019389959052205086, -0.2759159505367279, -0.4558151066303253, -0.5055224895477295, 1.0884311199188232, -0.5606786012649536, -1.0293450355529785, -1.061287760734558, -0.7893348336219788, -0.041716884821653366, 0.5936575531959534, -0.06625750660896301, -0.9717875719070435, 0.7910434007644653, 0.6355149149894714, 0.3010983467102051, 0.5186995267868042, -0.13420912623405457, 0.7060467600822449, 0.43061548471450806, 0.17838351428508759, -0.3171393573284149, -0.5884280800819397, 0.959323525428772, 0.5223829746246338, -0.749448299407959, 0.7152941823005676, -0.6644405722618103, -0.612248957157135, 0.9659823775291443, -0.05175774544477463, -0.1429087221622467, 1.3373891115188599, 0.30601781606674194, -0.2139897495508194, 0.31825149059295654, -0.9421448111534119, -0.21571184694766998, 1.0411046743392944, 1.1572179794311523, -0.4863217771053314, 0.39476314187049866, 0.47479942440986633, 1.014835238456726, 0.23903733491897583, -0.08763521164655685, 0.4038242697715759, 0.44613781571388245, 0.33976560831069946, -0.3405306041240692, -0.7013567090034485, 0.6149169206619263, -1.6100012063980103, -0.6862431764602661, 0.03722551837563515, 0.18345873057842255, 0.5949239134788513, 0.6453417539596558, 0.6035661101341248, -0.4648272693157196, 0.32048481702804565, -0.4503602087497711, 0.3368741273880005, -0.20417816936969757, -0.3243178427219391, -0.2529436945915222, -0.8491779565811157, -0.4723365604877472, 0.21519045531749725, -0.332559734582901, -0.024817101657390594, -0.8842640519142151, 0.4677008092403412, -0.331229031085968, 0.3617299199104309, 0.8498614430427551, 0.5156806707382202, 0.4540517032146454, 0.17023257911205292, -0.790885329246521, -0.27329593896865845, -0.16069193184375763, -0.167115718126297, -0.7821013331413269, 0.059865087270736694, 0.5104838013648987, -0.038183216005563736, -0.15161369740962982]}, "authors": [{"authorId": "3468942", "name": "Wenyuan Zeng"}, {"authorId": "31289209", "name": "Meng Li"}, {"authorId": "49602412", "name": "Wenjie Xiong"}, {"authorId": "2213589973", "name": "Tong Tong"}, {"authorId": "2111608441", "name": "Wen-jie Lu"}, {"authorId": "2192527360", "name": "Jin Tan"}, {"authorId": "92276390", "name": "Runsheng Wang"}, {"authorId": "2140386509", "name": "Ru Huang"}], "references": [{"paperId": "ec6405ad32353640159fc7daa37128ab3ba92cd0", "title": "DeepReShape: Redesigning Neural Networks for Efficient Private Inference"}, {"paperId": "533296f687073b251d929149aff61b81e382f6d3", "title": "RRNet: Towards ReLU-Reduced Neural Network for Two-party Computation Based Private Inference"}, {"paperId": "f400b801becf89b1db03ef8bcedb845d20a9dcda", "title": "Learning to Linearize Deep Neural Networks for Secure and Efficient Private Inference"}, {"paperId": "2701d5b55ddacbdc82bc33901451f593a92127f1", "title": "MPCFormer: fast, performant and private Transformer inference with MPC"}, {"paperId": "f5caca89895c5638264e397643cbbacdf671bcf4", "title": "How to Train Vision Transformer on Small-scale Datasets?"}, {"paperId": "1859fb2b30a2e9d54cbb9605bdd6f270caac6d66", "title": "DARTFormer: Finding The Best Type Of Attention"}, {"paperId": "aa0d54517fd14adf8f45f2934ef8233a57dab675", "title": "PolyMPCNet: Towards ReLU-free Neural Architecture Search in Two-party Computation Based Private Inference"}, {"paperId": "ec139916edd6feb9b3cb3a0325ca96e21dbb0147", "title": "Hydra Attention: Efficient Attention with Many Heads"}, {"paperId": "86c8d930b492a4f9cadc6c60aecdaaded49acc86", "title": "Neural Architecture Search on Efficient Transformers and Beyond"}, {"paperId": "45cb47f6d7bb749b7c80b6f3f19894b92acc3495", "title": "THE-X: Privacy-Preserving Transformer Inference with Homomorphic Encryption"}, {"paperId": "d7f0a2e9ebd57c0231937acb973bdc064a7eb625", "title": "Vision Transformers in 2022: An Update on Tiny ImageNet"}, {"paperId": "6cfd71d6f3cbe63a0af95b0622a6dd7387ab6acf", "title": "Characterization of MPC-based Private Inference for Transformer-based Models"}, {"paperId": "9e82736043eebe3f71eb86cbef6e2ac45306ece5", "title": "Structured Pruning Learns Compact and Accurate Models"}, {"paperId": "c49ac1f916d6d2edeb187e6619c8d23acd95eb21", "title": "cosFormer: Rethinking Softmax in Attention"}, {"paperId": "56cbc33300cbfdfc25fb04ad6e6fbfbd090267fc", "title": "Selective Network Linearization for Efficient Private Inference"}, {"paperId": "13f7a106bb3814ad1fab25fd1356e99e91f402d3", "title": "Q-ViT: Fully Differentiable Quantization for Vision Transformer"}, {"paperId": "d780914102ecef35a0722d713ee521082854b6a8", "title": "Multi-Scale High-Resolution Vision Transformer for Semantic Segmentation"}, {"paperId": "2e644c67a697073d561da4f4dad35e5ad5316cfd", "title": "SOFT: Softmax-free Transformer with Linear Complexity"}, {"paperId": "649b706ba282de4eb5a161137f80eb49ed84a0a8", "title": "UFO-ViT: High Performance Linear Vision Transformer without Softmax"}, {"paperId": "7eb733c8ac1b3d1dd8b50e066ddae10769e3b46e", "title": "CrypTen: Secure Multi-Party Computation Meets Machine Learning"}, {"paperId": "ae88babf38716142d630fb6ee4059e46d787cb4e", "title": "Vision Transformer Architecture Search"}, {"paperId": "f73ccd90617b3fcbadbe09816c2773360a2df4e5", "title": "Sphynx: A Deep Neural Network Design for Private Inference"}, {"paperId": "2d98048c2d2fcd3f6b989d2a54003808906ab4b7", "title": "Efficient Training of Visual Transformers with Small Datasets"}, {"paperId": "a0964686d80e173529efca6377f47e6a1b2fe69a", "title": "Less is More: Pay Less Attention in Vision Transformers"}, {"paperId": "040c58928a9ff3d4373f23868313c49b0744643d", "title": "SiRnn: A Math Library for Secure RNN Inference"}, {"paperId": "4b06c7e29280b1c6bc05c9df39023b48fef02c93", "title": "Escaping the Big Data Paradigm with Compact Transformers"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "b6382a7351c0c595f91472ac71d3b2d87b3c4844", "title": "ViViT: A Video Vision Transformer"}, {"paperId": "4521c2e96fcd1560ade2489316eef1805c094cda", "title": "DeepReDuce: ReLU Reduction for Fast Private Inference"}, {"paperId": "064455ab95783c2dfd161bfa3b41475d84e5c608", "title": "Delphi: A Cryptographic Inference Service for Neural Networks"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "ad39e3cca72e8df981c11bb916d5a5ef3e6c3a1a", "title": "CrypTFlow2: Practical 2-Party Secure Inference"}, {"paperId": "c6aeb60d477031e6e0e36c2e09dbfbbb00763c49", "title": "CryptoNAS: Private Inference on a ReLU Budget"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "5c2d8867055de9df951c29492b5cbffd68ec95be", "title": "Reinforcement learning for neural architecture search: A review"}, {"paperId": "58beee332c449b7a9471cdacf6118f33aac97c68", "title": "Hardware/Software Co-Exploration of Neural Architectures"}, {"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "b03c7ff961822183bab66b2e594415e585d3fd09", "title": "Are Sixteen Heads Really Better than One?"}, {"paperId": "9a9dcc604321dd2dda93c3ad268e554b7f2b356e", "title": "ChamNet: Towards Efficient Network Design Through Platform-Aware Model Adaptation"}, {"paperId": "f8be3ede4a63e67dc2cf0c5a03cf7e3005f78782", "title": "IRLAS: Inverse Reinforcement Learning for Architecture Search"}, {"paperId": "45532bffbfbb5553da0b2d0844e95a1b37e59147", "title": "FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search"}, {"paperId": "54c4642d017830e1faddbb49f0377228d2b01493", "title": "HAQ: Hardware-Aware Automated Quantization With Mixed Precision"}, {"paperId": "61306b52c2d292928f7cbb2f2ef5711d15a2566c", "title": "ABY3: A Mixed Protocol Framework for Machine Learning"}, {"paperId": "693c97ecedb0a84539b7162c95e89fa3cd84ca73", "title": "MnasNet: Platform-Aware Neural Architecture Search for Mobile"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "2b7f9117eb6608a58be4c078ca3d69c0e5ccb875", "title": "SecureML: A System for Scalable Privacy-Preserving Machine Learning"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "c1e3a26fb88c6720f4e84b7118e6f2df7dc8efa3", "title": "From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "0166c8b5c6445043b94fc7b62d145d0c3c8b6483", "title": "More efficient oblivious transfer and extensions for faster secure computation"}, {"paperId": "0e0427aedfed65c8dd688c094b181feacf4eaab4", "title": "Protocols for secure computations"}, {"paperId": "88abb2cda4f2a57499a717966ac4fbe9a993027a", "title": "How to share a secret"}, {"paperId": "dfdec891ad57ef80bbc98f6017a927c8d1998db7", "title": "SecretFlow-SPU: A Performant and User-Friendly Framework for Privacy-Preserving Machine Learning"}, {"paperId": "0a68b0282c5ad62da67dfaa77a1f5c4a2e384c95", "title": "Cheetah: Lean and Fast Secure Two-Party Deep Neural Network Inference"}, {"paperId": "c616f197f5f95e60d2c7dc9d678d296ba11ce389", "title": "Improving Vision Transformers to Learn Small-Size Dataset From Scratch"}, {"paperId": "b8a919f4a2aaa97bef19aa43e01f8bc347693b73", "title": "NASViT: Neural Architecture Search for Efficient Vision Transformers with Gradient Conflict aware Supernet Training"}, {"paperId": "37a860cbc0a3334d446d72cab166a9c63e489442", "title": "Iron: Private Inference on Transformers"}, {"paperId": "be942d0c5640ceab1b7e72e106af413b0f842a28", "title": "SAFENet: A Secure, Accurate and Fast Neural Network Inference"}, {"paperId": "f043165e1f45e720f11cc110132dc78de3dbd24b", "title": "Newton-Raphson Method"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "15d1f5ccc812fdfbb618db3ebf7a2daac16eca8d", "title": "SPD Z 2 k : E\ufb03cient MPC mod 2 k for Dishonest Majority"}, {"paperId": "93a5eb1d3cb974b5ff9cb0a88af66142383ce2ed", "title": "SPD\u2124 2 k : Efficient MPC mod 2 k for Dishonest Majority."}, {"paperId": "6105e468a6a4d9d5082dd1b12c76992416292db3", "title": "Secure Multi-party Computation"}, {"paperId": "de4b461d1f1cc7f7044c92b49c586a2463b28a8e", "title": "Computationally Secure Oblivious Transfer"}, {"paperId": null, "title": "Escaping the 5038 Authorized licensed use limited to the terms of the applicable"}, {"paperId": null, "title": "Fbnet: Hardware-aware ef\ufb01cient con-vnet"}, {"paperId": null, "title": "Dublin, Ireland, May 2022"}, {"paperId": null, "title": "By selectively replacing the ReLU Softmax with the cheaper Scaling"}]}