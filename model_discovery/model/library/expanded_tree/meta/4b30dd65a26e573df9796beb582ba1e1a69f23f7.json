{"paperId": "4b30dd65a26e573df9796beb582ba1e1a69f23f7", "abstract": "We demonstrate that transformers obtain impressive performance even when some of the layers are randomly initialized and never updated. Inspired by old and well-established ideas in machine learning, we explore a variety of non-linear \u201creservoir\u201d layers interspersed with regular transformer layers, and show improvements in wall-clock compute time until convergence, as well as overall performance, on various machine translation and (masked) language modelling tasks.", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2020, "citationCount": 12, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Inspired by old and well-established ideas in machine learning, a variety of non-linear \u201creservoir\u201d layers interspersed with regular transformer layers are explored, and improvements in wall-clock compute time until convergence are shown."}, "embedding": {"model": "specter_v2", "vector": [0.45839616656303406, 0.7048680782318115, -0.6417480111122131, 0.23898598551750183, -0.4038494825363159, -0.11800295114517212, 1.1574455499649048, -0.18258143961429596, -0.30893218517303467, -0.2948547303676605, 0.492807537317276, -0.21296030282974243, 0.6080198884010315, 0.0938827320933342, -0.39162400364875793, -0.2050533890724182, -0.9965632557868958, 0.6444852948188782, -0.0084834648296237, -0.35217246413230896, -0.06697256118059158, -0.4930286109447479, -1.069574236869812, 0.11705054342746735, 0.46691006422042847, 0.4990299940109253, -0.18927691876888275, 0.7916284799575806, -0.707531213760376, 0.5817475914955139, 0.7351426482200623, -0.21930962800979614, 0.5049803853034973, -0.1529098004102707, -0.1814759224653244, 0.0014180578291416168, 0.27299898862838745, -0.3841122090816498, -0.2368955910205841, 0.8673473596572876, -0.3688025176525116, -0.1514594703912735, 0.21098990738391876, -0.7761242985725403, -0.14087899029254913, 1.1219720840454102, 0.6201958656311035, 0.8466572761535645, -0.7026960849761963, -0.37013521790504456, 0.8609270453453064, -1.5465818643569946, 0.00042536421096883714, 1.289436936378479, 0.8658048510551453, 0.39049211144447327, -0.39332249760627747, -0.6585352420806885, 0.5698401927947998, -0.2305316925048828, -0.7773841619491577, -0.8258814811706543, -0.045834943652153015, -0.3371327519416809, 1.7550780773162842, -0.40503010153770447, -0.045034389942884445, 0.17337314784526825, 0.19220873713493347, 1.281005620956421, 0.39638981223106384, -0.8238633871078491, -0.25149795413017273, 0.39958837628364563, -0.22457914054393768, 1.224655032157898, -0.36976057291030884, 0.6081425547599792, -1.2761996984481812, -0.25096288323402405, 0.3730083703994751, -0.1716804802417755, 0.13215526938438416, -0.6644519567489624, -0.693498432636261, 0.6289325952529907, 0.17971622943878174, 0.9302057027816772, -0.24573193490505219, 0.832483172416687, 0.37102293968200684, 0.5107760429382324, 0.3799675703048706, 0.3099961280822754, 0.12699440121650696, 0.4310794174671173, -1.0976096391677856, -0.17244301736354828, -0.25867608189582825, 0.6714661717414856, -0.009725567884743214, 0.4288269877433777, -0.9103562235832214, 0.06908440589904785, 1.1008461713790894, 0.2283933013677597, 0.46965861320495605, -0.3968198895454407, 0.22207464277744293, -0.6334037780761719, 0.009236077778041363, -0.4097094237804413, -0.004069282673299313, -0.5817000269889832, -1.1044704914093018, -1.1016074419021606, -0.6633639335632324, 0.5002287030220032, -1.0579628944396973, 0.735846757888794, -0.31767573952674866, 0.4207025170326233, 0.20278970897197723, 0.3034864664077759, 0.319106787443161, 0.6655960083007812, 0.03351358324289322, -0.08167890459299088, 0.8462061882019043, -0.9675506949424744, -0.5307639241218567, -1.2235875129699707, 0.5279653072357178, -0.2632807493209839, -0.021303782239556313, -0.05999431014060974, -1.3718839883804321, -0.778570294380188, -0.8954195380210876, 0.28293585777282715, -0.5050927996635437, 0.17306113243103027, 1.1506949663162231, 0.6093423962593079, -1.396877646446228, 0.8598754405975342, -0.271837055683136, 0.2596931457519531, 0.42766880989074707, 0.4662160575389862, 0.4985014498233795, -0.38430503010749817, -1.1928150653839111, 0.5998275876045227, 0.05126187577843666, -0.2818123996257782, -0.44724902510643005, -0.5814473628997803, -0.7747348546981812, -0.21270638704299927, 0.16393965482711792, -0.5959867238998413, 1.340161919593811, -0.04330866411328316, -1.5441826581954956, 0.7486381530761719, -0.5241898894309998, -0.043674103915691376, 0.4598982334136963, 0.1493266075849533, -0.2047545611858368, -0.5211841464042664, -0.322262704372406, 0.3286961019039154, 0.9502333402633667, -0.30384185910224915, 0.023191433399915695, 0.14186936616897583, -0.4876834452152252, -0.12097480148077011, -0.35333213210105896, 0.9543678760528564, -0.3946859538555145, -0.3093941807746887, 0.5436762571334839, 0.6588707566261292, -0.49657386541366577, -0.5924667716026306, -0.394683837890625, -0.8070368766784668, 0.329118549823761, -0.10257194191217422, 0.889220118522644, -0.7861698269844055, -0.33373138308525085, 0.07839217782020569, -0.07983745634555817, -0.2707025110721588, -0.6796488761901855, 0.4435361325740814, -0.4030627906322479, 0.26746904850006104, -0.31926459074020386, -1.1454756259918213, 0.13628248870372772, -0.14697544276714325, -0.7266563773155212, -0.08274567872285843, 0.4253954589366913, 1.1550954580307007, -1.1307083368301392, -0.0008878424996510148, 0.0344293937087059, 0.5054589509963989, -0.9550132751464844, 0.9563336372375488, -0.24784530699253082, 0.30090969800949097, 0.2600512206554413, -0.14907018840312958, 0.15979783236980438, -0.3163031339645386, 0.7620493769645691, -0.15516255795955658, -0.06614063680171967, 0.5353240966796875, -0.5568605065345764, 1.0745069980621338, -0.25380468368530273, 0.5749169588088989, -0.11688727140426636, -0.7586913108825684, 0.09152647852897644, 0.5049751400947571, -0.22367645800113678, -0.4128485321998596, 0.35885125398635864, 0.634072482585907, -0.6063188910484314, 0.9052912592887878, 0.9264388084411621, 0.3644424080848694, -0.18543624877929688, 0.22288931906223297, 0.6013678312301636, -0.2890274226665497, 0.26091620326042175, 0.260137677192688, 0.42290252447128296, 0.22662454843521118, 0.10978543758392334, -0.2686338722705841, 0.32444316148757935, -0.6100755333900452, -0.24125108122825623, 0.6483014225959778, 0.8256489038467407, 0.4487527012825012, 0.29870641231536865, -0.5668648481369019, -0.4627121090888977, -0.20396067202091217, 0.6866876482963562, 1.3756983280181885, -0.4625278413295746, -0.09471860527992249, -0.5129469037055969, 0.017237456515431404, -0.5110447406768799, -0.24141956865787506, -0.31679943203926086, -0.23787158727645874, -0.7213767170906067, -1.3102695941925049, 0.7719224691390991, 0.20277898013591766, 0.9450246691703796, -0.27280640602111816, -0.10874444246292114, -0.2580612301826477, 0.35981541872024536, -0.820895791053772, -0.4594608545303345, 0.555572509765625, -1.1484895944595337, 0.13881613314151764, -0.13629968464374542, -0.35400861501693726, 0.36722615361213684, -0.7795271873474121, 0.9903460741043091, -0.243564635515213, 0.10500087589025497, -0.24956974387168884, 1.1214053630828857, -0.4157887399196625, -1.198851227760315, -0.09545722603797913, 0.5179423689842224, -0.02680809423327446, 0.15253713726997375, 0.42221054434776306, 0.25773319602012634, 0.013772453181445599, -0.17235538363456726, 0.3296494483947754, 0.028376638889312744, 0.27441757917404175, 0.7329849600791931, -0.03958405554294586, -0.532321572303772, -1.120499849319458, 0.8249620199203491, 0.3407306969165802, -0.80754154920578, 0.30404776334762573, -0.8376539945602417, 0.08724807947874069, 0.4476860463619232, -0.7037466168403625, 0.04708061367273331, -1.0454025268554688, 0.5478665828704834, -0.4790382981300354, 0.5106741189956665, -0.0020390369463711977, 0.5264148712158203, 0.15897580981254578, 0.02146509476006031, 0.777381181716919, 0.40658310055732727, -0.18150998651981354, 0.7944488525390625, -0.66500324010849, 0.5451738238334656, 0.17983469367027283, 0.709202766418457, -0.08562468737363815, -0.20531758666038513, -0.3241712749004364, -0.1583705097436905, -0.050309885293245316, -0.1413157433271408, -0.2873428165912628, -0.0401073656976223, -0.9914827942848206, -0.533146321773529, 0.2432871311903, -0.691490650177002, -0.3473133146762848, 0.21484607458114624, -0.42818483710289, -0.11900217086076736, -1.0348130464553833, -1.4467339515686035, -0.786970317363739, -0.6832399368286133, -1.2193773984909058, 0.5470978617668152, -0.12638911604881287, 0.19684462249279022, -0.3960336446762085, -0.12610504031181335, -0.3890795409679413, 1.328044056892395, -0.800411581993103, 1.0070641040802002, 0.13050055503845215, -0.7059849500656128, -0.002779753413051367, 0.5540809035301208, 0.5992140769958496, -0.5156281590461731, 0.27788472175598145, -0.9788793921470642, -0.03479725122451782, -0.40697890520095825, -0.014503352344036102, 0.24726489186286926, 0.2656775116920471, 0.30980291962623596, -0.21706466376781464, -0.7084684371948242, 0.34872183203697205, 1.2400470972061157, -0.9176521897315979, -0.18863371014595032, 0.22923199832439423, 0.6889738440513611, -0.12507009506225586, -0.5729719400405884, 0.21264250576496124, 0.17635726928710938, 0.4315049648284912, 0.10821633040904999, -0.29061105847358704, 0.1049073189496994, -0.6296419501304626, 0.693729043006897, 1.9712202548980713, 0.31428655982017517, 0.21246559917926788, -1.0768390893936157, 0.5906350016593933, -0.8570349812507629, -0.5693010687828064, 0.7534517645835876, 0.9268584847450256, 0.3963158428668976, -0.026250401511788368, -0.2896575629711151, 0.04931900277733803, 0.5556947588920593, 0.30600836873054504, -0.34564387798309326, -0.8779261708259583, 0.0038348084781318903, 0.946708083152771, 0.6061950325965881, 0.6544179320335388, -0.0060112751089036465, 0.6080572009086609, 14.985998153686523, 0.4126416742801666, -0.09908660501241684, 0.9456437826156616, 0.6656869053840637, 0.11703767627477646, -0.5592754483222961, 0.17678461968898773, -0.7831690311431885, -0.22742335498332977, 1.0279006958007812, 0.3199930489063263, 0.9617936611175537, 0.13481628894805908, -0.27864912152290344, 0.44893431663513184, -0.4040180444717407, 0.31551533937454224, 0.2031458020210266, -1.8295818567276, 0.2956622540950775, 0.38864344358444214, 0.3869478106498718, 0.9939482808113098, 0.7940797805786133, 0.8838682770729065, 0.6660308241844177, -0.5564560294151306, 0.5675534605979919, 0.22708745300769806, 1.093473196029663, -0.005568569526076317, 0.30860084295272827, 0.45752453804016113, -0.9917465448379517, -0.18055155873298645, -0.36180999875068665, -1.2119262218475342, 0.02222532406449318, 0.23951317369937897, -0.9093001484870911, -0.4386970102787018, -0.2048688679933548, 0.6109935641288757, 0.2845534384250641, -0.02977466583251953, 0.07526008039712906, 0.8405290842056274, -0.40009117126464844, 0.16245031356811523, 0.182183638215065, 0.3051685094833374, 0.0031049528624862432, -0.18385478854179382, 0.14369870722293854, -0.37177619338035583, 0.012106558308005333, 0.37712281942367554, -0.5333883762359619, -0.28536126017570496, -0.2839790880680084, -0.6290664076805115, 0.03203284740447998, 0.6338537931442261, 0.33091118931770325, -0.12336583435535431, -0.18284039199352264, 0.35325002670288086, 0.29728153347969055, 0.051194027066230774, -0.15432624518871307, 0.2543588876724243, 0.41636547446250916, -0.2745591104030609, 0.12442173808813095, 0.4522761106491089, -0.018398914486169815, -0.7060015797615051, -0.6703819036483765, -0.6171410083770752, 0.11249655485153198, -0.5629318356513977, -0.4515222907066345, 1.053122639656067, -0.38749441504478455, -0.6001883745193481, 0.30390092730522156, -0.8147575855255127, -0.07408232986927032, 0.6174396872520447, -1.5137593746185303, -0.5604730248451233, 0.5449647307395935, -0.4501727521419525, -0.7080195546150208, -0.36523956060409546, 1.2502700090408325, 0.01907125860452652, -0.15470343828201294, 0.09979038685560226, 0.4019251763820648, 0.14279215037822723, -0.8078525066375732, -0.644262433052063, 1.368633508682251, 0.4300917983055115, 0.11344859004020691, 0.6144506931304932, 0.048949163407087326, 0.4239013195037842, -0.893997073173523, 0.1053234413266182, 0.8953279852867126, -0.9364030957221985, -0.40550264716148376, -0.9965105652809143, -0.619580864906311, 0.36073005199432373, 0.49862658977508545, -0.179142564535141, 0.33296769857406616, -0.04890880733728409, -0.5468780994415283, -0.05064887925982475, -0.689455509185791, 0.07826658338308334, 0.6639105081558228, -1.006766438484192, -0.15097500383853912, 0.1389225870370865, 0.1448320597410202, -1.0219231843948364, -0.33514145016670227, -0.16412271559238434, 0.045984186232089996, -0.2054535448551178, 1.3115726709365845, -0.4195884168148041, 0.3445611298084259, 0.4828472137451172, -0.14313429594039917, -0.7367029190063477, -0.14825491607189178, -1.2030856609344482, -0.18257327377796173, -0.10084405541419983, 0.43460914492607117, -0.6403999924659729, 0.21749840676784515, 0.23972798883914948, 0.4500487148761749, -0.39200669527053833, -0.9595845937728882, -0.27404114603996277, 0.20157498121261597, -0.48625725507736206, 0.7422780990600586, 0.04258231446146965, -0.2346806675195694, 0.2674601674079895, 0.13300642371177673, 0.6338657140731812, 0.12351671606302261, -0.6787338852882385, 0.3262481689453125, 0.023986797779798508, -0.05452398583292961, -0.7749319672584534, -0.27498993277549744, -1.2090513706207275, -0.2187110185623169, -1.4626214504241943, -0.03948687016963959, -1.0963129997253418, -0.31507450342178345, -0.13127033412456512, -0.5445732474327087, 0.14912572503089905, 0.4110327363014221, 0.1348651647567749, -0.4213044047355652, -0.2806979715824127, -0.07507693022489548, 0.7518231868743896, 0.8567501306533813, -0.8764040470123291, 0.31195375323295593, -0.15120773017406464, 0.14158762991428375, 0.006003980059176683, 0.4441052973270416, -0.4231281280517578, -0.8546202778816223, -1.2472827434539795, 0.48835599422454834, -0.11334408074617386, -0.20521359145641327, -0.6356837153434753, 0.5064806342124939, 0.37328511476516724, -0.18165276944637299, 0.10763286054134369, 0.4168627858161926, -0.49817731976509094, -0.08863972872495651, 0.6074811220169067, -0.648524820804596, 0.4583107531070709, 0.08349424600601196, -0.7023189067840576, -0.11549058556556702, 0.9694886803627014, 0.028700673952698708, -1.3398752212524414, -0.3931465148925781, 0.36612245440483093, -0.6012186408042908, 0.02202657051384449, -0.5523717999458313, -0.5332270264625549, -0.852206289768219, -0.1046210378408432, 0.14039532840251923, 0.36471980810165405, -0.08234279602766037, 0.9568222165107727, 0.19344614446163177, -1.0283691883087158, 0.11757422238588333, 0.547551155090332, -0.18147443234920502, -0.151515394449234, 0.06522095203399658, 0.6023480296134949, -0.1980336457490921, 0.5674332976341248, 0.3939303457736969, 0.13807377219200134, -0.5971453189849854, -0.10854505747556686, 1.0521193742752075, -0.9258174300193787, -0.4424133002758026, 1.165757417678833, -0.6008859872817993, -1.3167978525161743, -0.0027699449565261602, -1.360641598701477, -0.3764522969722748, -0.43961596488952637, 0.3576458692550659, -0.35898658633232117, 0.0009141149348579347, -0.014545497484505177, -0.8023162484169006, 0.20210064947605133, 0.27430039644241333, -0.5528820157051086, 0.5281409621238708, 0.12061858177185059, -0.705163836479187, 0.6727907061576843, 0.35057324171066284, -0.4979245960712433, -0.4660799503326416, -1.053665041923523, -0.15627121925354004, -0.06477668881416321, 0.7715416550636292, -0.2994703948497772, -0.4777056574821472, 0.9105454683303833, 0.6959011554718018, 0.18590617179870605, 0.25470441579818726, -0.3738742768764496, 0.05761861056089401, 0.3853362798690796, 0.5374728441238403, -0.5949652791023254, -0.6351944804191589, 1.1901289224624634, 0.725409984588623, -0.7156280279159546, 0.3451908528804779, 0.02266048640012741, -0.6579634547233582, 0.599703311920166, -0.19947421550750732, 0.2020217478275299, 0.8708649277687073, -0.07923953980207443, 0.35603660345077515, 0.20778942108154297, -1.1304165124893188, -0.2801700532436371, 0.6718481779098511, 0.8897968530654907, 0.7655332684516907, 0.2617454528808594, 0.4463021457195282, 0.43062686920166016, 0.07260177284479141, 0.35270053148269653, 0.5675030946731567, 0.7906639575958252, -0.188179612159729, -0.21173638105392456, -0.034840263426303864, 0.6217846870422363, -0.5144153833389282, -1.1684798002243042, 0.26092544198036194, 0.37772366404533386, 0.18015609681606293, 0.47224903106689453, 0.7243967652320862, -0.16066622734069824, 0.34105896949768066, 0.27789080142974854, 0.760590136051178, -0.5670157074928284, -0.47995293140411377, -0.17416872084140778, -0.6009114980697632, 0.177089661359787, -0.3142777681350708, -0.3689395785331726, -0.24911458790302277, -0.49156686663627625, 0.11996228247880936, 0.34067267179489136, 0.43942463397979736, 1.0212892293930054, 0.3355424404144287, 0.4773973226547241, -0.0010825427016243339, -0.48858100175857544, -0.8052522540092468, -0.9606919288635254, 0.32527515292167664, -0.8306607007980347, 0.036420587450265884, -0.32161417603492737, 0.008883360773324966, -0.4803314208984375]}, "authors": [{"authorId": "2191455", "name": "Sheng Shen"}, {"authorId": "51428394", "name": "Alexei Baevski"}, {"authorId": "4690624", "name": "Ari S. Morcos"}, {"authorId": "1732330", "name": "K. Keutzer"}, {"authorId": "2325985", "name": "Michael Auli"}, {"authorId": "1743722", "name": "Douwe Kiela"}], "references": [{"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "0acc3ee64c34b738a89cbc3790d4e5e1c9deb943", "title": "PipeTransformer: Automated Elastic Pipelining for Distributed Training of Transformers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "766bd9633ea0ed0ee2d8cc11ab083322666a3db9", "title": "Randomized Automatic Differentiation"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "8c5a394654822a5de53ac2e4a355c1c6ead4750c", "title": "Deep Encoder, Shallow Decoder: Reevaluating the Speed-Quality Tradeoff in Machine Translation"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "0b991a1a5bcdb13646ac0b6873d09bde4cc36fb5", "title": "Masked Language Modeling for Proteins via Linearly Scalable Long-Context Transformers"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "d27669c82faf78ea08cceaa0a171b540cccc304d", "title": "ETC: Encoding Long and Structured Inputs in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "2573af4e13d9a5dddb257d22cd38a600528d9a8b", "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"}, {"paperId": "f4b585c9a79dfce0807b445a09036ea0f9cbcdce", "title": "Information-Theoretic Probing with Minimum Description Length"}, {"paperId": "e52051204cb1179584f3b008c9d38848b52c1f28", "title": "ReZero is All You Need: Fast Convergence at Large Depth"}, {"paperId": "84ef2cf4f73bb4eae7ae63fbca04a4d774b75ac7", "title": "Training BatchNorm and Only BatchNorm: On the Expressive Power of Random Features in CNNs"}, {"paperId": "bd20069f5cac3e63083ecf6479abc1799db33ce0", "title": "A Primer in BERTology: What We Know About How BERT Works"}, {"paperId": "7c731d45c3c119757cd6f6dee79c491a6ae39f96", "title": "Echo State Neural Machine Translation"}, {"paperId": "95133180792648387b65fa69c23537cd6ebad02d", "title": "Deep Randomized Neural Networks"}, {"paperId": "8771679aac0e90371340bd8c657317f5be113e81", "title": "Train Large, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "7a87ab984ca45aae2c5768d22cd6df3b5fd509f9", "title": "What\u2019s Hidden in a Randomly Weighted Neural Network?"}, {"paperId": "3ff8d265f4351e4b1fdac5b586466bee0b5d6fff", "title": "Improving Transformer Models by Reordering their Sublayers"}, {"paperId": "361c00b22e29d0816ca896513d2c165e26399821", "title": "Grandmaster level in StarCraft II using multi-agent reinforcement learning"}, {"paperId": "4585611042d2be0d997ee135e3fe219d668db9ec", "title": "Depth-Adaptive Transformer"}, {"paperId": "84913d6f08942ddf8dd51418820537abfaa5ae19", "title": "vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations"}, {"paperId": "7455f5f3a524fea54be74fc002266eca0f003a91", "title": "Neural Language Priors"}, {"paperId": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1", "title": "Reducing Transformer Depth on Demand with Structured Dropout"}, {"paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"}, {"paperId": "2bb4b6b876581c0c21ef58d3c38809715173ca7a", "title": "PANLP at MEDIQA 2019: Pre-trained Language Models, Transfer Learning and Knowledge Distillation"}, {"paperId": "335613303ebc5eac98de757ed02a56377d99e03a", "title": "What Does BERT Learn about the Structure of Language?"}, {"paperId": "ee9d6faa165f98431f61b2c5f9de7bae96925501", "title": "On the impressive performance of randomly weighted encoders in summarization tasks"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "3c5f1ab37f70db503636075e15b3173f86eea00b", "title": "Green AI"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "97906df07855b029b7aae7c2a1c6c5e8df1d531c", "title": "BERT Rediscovers the Classical NLP Pipeline"}, {"paperId": "f7c410ab241bc972cda2f47993124ea8483003b6", "title": "Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask"}, {"paperId": "faadd7d081c8d67e8c2567e8a5579e46cd6b2280", "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling"}, {"paperId": "4ac62731b802c727f916e8deefda1a992991505d", "title": "Are All Layers Created Equal?"}, {"paperId": "7a8f8109e65ed9a6048859681a825eb5655e5dd2", "title": "No Training Required: Exploring Random Encoders for Sentence Classification"}, {"paperId": "fea820b7d953d32069e189af2961c28fd213470b", "title": "Pay Less Attention with Lightweight and Dynamic Convolutions"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "03e7e8663c69e691be6b6403b1eb1bbf593d31f2", "title": "Gradient Descent Finds Global Minima of Deep Neural Networks"}, {"paperId": "0cd9d2f74f4866a5b105cd88510cbeb13db39137", "title": "Language Modeling Teaches You More than Translation Does: Lessons Learned Through Auxiliary Syntactic Task Analysis"}, {"paperId": "2da4ce648f0c2f9932ac6b45b6cbdc4f7273d4f2", "title": "Recent Advances in Physical Reservoir Computing: A Review"}, {"paperId": "ccb1bafdae68c635cbd30d49fda7dbf88a3ce1b6", "title": "Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data"}, {"paperId": "bf8fe437f779f2098f9af82b534aa51dc9edb06f", "title": "Scaling Neural Machine Translation"}, {"paperId": "4a3df21d289bba93a40d27bb7dab970e0e3eca04", "title": "Randomly Weighted CNNs for (Music) Audio Classification"}, {"paperId": "21937ecd9d66567184b83eca3d3e09eb4e6fbd60", "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"}, {"paperId": "8da7822423e2d80dbd78b7e33ee1d52eef8f4595", "title": "Intriguing Properties of Randomly Weighted Networks: Generalizing While Learning Next to Nothing"}, {"paperId": "faa98e73eeee551c40923c896817ab640925ce20", "title": "Deep Image Prior"}, {"paperId": "3fc5ed18c2294596af072df929c8ee12c71f96a2", "title": "Classical Structured Prediction Losses for Sequence to Sequence Learning"}, {"paperId": "4873c78f0cd5a1fad96300e49e196af75800a24e", "title": "Regularizing Deep Neural Networks by Noise: Its Interpretation and Optimization"}, {"paperId": "a7484ac305e3746c9e612d558345d9664bd436de", "title": "FreezeOut: Accelerate Training by Progressively Freezing Layers"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "0413e59b39f20fa367c8595815faec6ffbfb7a43", "title": "Echo State Property of Deep Reservoir Computing Networks"}, {"paperId": "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c", "title": "Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"}, {"paperId": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e", "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"}, {"paperId": "7352c3f955d4cc992342686dce4395d253df6443", "title": "Randomness in neural networks: an overview"}, {"paperId": "049139382018f07899c8686437a60e8fe623e8a1", "title": "Understanding Synthetic Gradients and Decoupled Neural Interfaces"}, {"paperId": "a844595c3b561b00325c75d00e5cc7f639e8ed9a", "title": "Event-Driven Random Back-Propagation: Enabling Neuromorphic Deep Learning Machines"}, {"paperId": "27760cc69be4ce445962ccb270a02d1944a9d4c9", "title": "Decoupled Neural Interfaces using Synthetic Gradients"}, {"paperId": "568374ac9433e29b812008b2a01f81e657bdbd34", "title": "Noisy Activation Functions"}, {"paperId": "dade3d81749385e08ec0f163c806308c94b56f32", "title": "Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity"}, {"paperId": "9d0959c438e2947cf4604d9e23ef0f03269047dd", "title": "Deep Neural Networks with Random Gaussian Weights: A Universal Classification Strategy?"}, {"paperId": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba", "title": "Convolutional Neural Networks for Sentence Classification"}, {"paperId": "0b544dfe355a5070b60986319a3f51fb45d1348e", "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"}, {"paperId": "5ec85a0d88adcc4344bb5cc81b0d1aef9bcd8dcc", "title": "Findings of the 2014 Workshop on Statistical Machine Translation"}, {"paperId": "99c970348b8f70ce23d6641e201904ea49266b6e", "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks"}, {"paperId": "687bac2d3320083eb4530bf18bb8f8f721477600", "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"}, {"paperId": "a57142969791c536326fde4ec45d2a9b9397587c", "title": "Information Processing Using Transient Dynamics of Semiconductor Lasers Subject to Delayed Feedback"}, {"paperId": "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649", "title": "Understanding the difficulty of training deep feedforward neural networks"}, {"paperId": "69e5339c0c3928a354e848b9ccf5349f6397e60b", "title": "Reservoir computing approaches to recurrent neural network training"}, {"paperId": "47aa6d7381cc9993da60e4547b01f415a04f3cf2", "title": "Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning"}, {"paperId": "7a59fde27461a3ef4a21a249cc403d0d96e4a0d7", "title": "Random Features for Large-Scale Kernel Machines"}, {"paperId": "d19c0996dd91c1fe7e46b7d2a3808716ba1cd5b7", "title": "Compact hardware for real-time speech recognition using a Liquid State Machine"}, {"paperId": "f2df0c1026ffa474f603a535e48e5c115d3d8629", "title": "Extreme learning machine: Theory and applications"}, {"paperId": "3ef1b0469b43acc8ede2e56d8f001ad090b04826", "title": "An Introduction to Random Indexing"}, {"paperId": "e0535dedb8607d83cd2614317c99913378e89e26", "title": "Real-Time Computing Without Stable States: A New Framework for Neural Computation Based on Perturbations"}, {"paperId": "48ddd9101a90fe65e3061de69626741b843ff5e4", "title": "The use of the area under the ROC curve in the evaluation of machine learning algorithms"}, {"paperId": "030a977bf32e81fb694117d78ac84a3fbe2a1d81", "title": "An analysis of noise in recurrent neural networks: convergence and generalization"}, {"paperId": "43fac30640789e0034a768349ce5699836e6d43d", "title": "Learning and generalization characteristics of the random vector Functional-link net"}, {"paperId": "e472eb3e762dc4274d8592f2443d278538dce159", "title": "Feedforward neural networks with random weights"}, {"paperId": "1d20eff70cb168111fb5cc320cb692a11f1adf62", "title": "On the capabilities of multilayer perceptrons"}, {"paperId": "445ad69010658097fc317f7b83f1198179eebae8", "title": "Geometrical and Statistical Properties of Systems of Linear Inequalities with Applications in Pattern Recognition"}, {"paperId": "c3a20b9aa86033cec29f08e69f4bc81e8b329ae2", "title": "Further experiments with PAPA"}, {"paperId": "fa9bbbf384b8b4e8be7be6d7484f9b94dd3f0d58", "title": "An outline of a mathematical theory of PAPA"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "e4c7de957300c71ea70fc457c07199454531e585", "title": "Unconventional Information Processing Systems , Novel Hardware : A Tour d \u2019 Horizon"}, {"paperId": "81aace0e90c6a962059b117c24db0d856f340f41", "title": "Report on the 11th IWSLT evaluation campaign"}, {"paperId": null, "title": "Large text compression benchmark"}, {"paperId": "4c915c1eecb217c123a36dc6d3ce52d12c742614", "title": "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning"}, {"paperId": "24547f720f472dd92870c1a7c4cb8bb450307f27", "title": "Adaptive Nonlinear System Identification with Echo State Networks"}, {"paperId": "162d958ff885f1462aeda91cd72582323fd6a1f4", "title": "Gradient-based learning applied to document recognition"}, {"paperId": "56a2c50626f7f17e7b864c244354599799977b46", "title": "Effects of Noise on Convergence and Generalization in Recurrent Networks"}, {"paperId": "1d0635cda34b8af995313848a0c42bac6efe79ec", "title": "Extensions of Lipschitz mappings into Hilbert space"}, {"paperId": "f74ded11f72099d16591a1191d72262ae6b5f14a", "title": "Perceptrons: An Introduction to Computational Geometry"}, {"paperId": "eddfd0b187a06c1742932a63d002ea767ce1cdbf", "title": "The perceptron: a model for brain functioning. I"}, {"paperId": null, "title": "Table 6: RoBERTa Probing Results. The line in bold text are the the frozen layers in the T Reservoir"}]}