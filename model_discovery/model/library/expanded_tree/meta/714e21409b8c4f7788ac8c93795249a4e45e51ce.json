{"paperId": "714e21409b8c4f7788ac8c93795249a4e45e51ce", "abstract": "Intrigued by the inherent ability of the human visual system to identify salient regions in complex scenes, attention mechanisms have been seamlessly integrated into various Computer Vision (CV) tasks. Building upon this paradigm, Vision Transformer (ViT) networks exploit attention mechanisms for improved efficiency. This review navigates the landscape of redesigned attention mechanisms within ViTs, aiming to enhance their performance. This paper provides a comprehensive exploration of techniques and insights for designing attention mechanisms, systematically reviewing recent literature in the field of CV. This survey begins with an introduction to the theoretical foundations and fundamental concepts underlying attention mechanisms. We then present a systematic taxonomy of various attention mechanisms within ViTs, employing redesigned approaches. A multi-perspective categorization is proposed based on their application, objectives, and the type of attention applied. The analysis includes an exploration of the novelty, strengths, weaknesses, and an in-depth evaluation of the different proposed strategies. This culminates in the development of taxonomies that highlight key properties and contributions. Finally, we gather the reviewed studies along with their available open-source implementations at our \\href{https://github.com/mindflow-institue/Awesome-Attention-Mechanism-in-Medical-Imaging}{GitHub}\\footnote{\\url{https://github.com/xmindflow/Awesome-Attention-Mechanism-in-Medical-Imaging}}. We aim to regularly update it with the most recent relevant papers.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A systematic taxonomy of various attention mechanisms within ViTs, employing redesigned approaches is presented, and a multi-perspective categorization is proposed based on their application, objectives, and the type of attention applied."}, "embedding": {"model": "specter_v2", "vector": [0.7967110276222229, 0.639710009098053, -0.25100165605545044, 0.3545383810997009, -0.060143858194351196, 0.6592719554901123, 0.32508495450019836, -0.25546160340309143, -0.36284011602401733, -0.5638880133628845, 0.3787139654159546, 0.8131905794143677, -0.1467752307653427, -0.05899116024374962, 0.05217630788683891, -0.05934927240014076, -0.7117142677307129, -0.4921821057796478, 0.7376576066017151, -0.26558560132980347, 0.06472225487232208, -0.39649078249931335, -1.4779224395751953, 0.29271969199180603, 0.19343149662017822, 1.1400070190429688, 0.6773319244384766, 1.246189832687378, 0.10067316144704819, 0.6751365065574646, 0.6740739345550537, -0.08300698548555374, 0.4534705877304077, 0.02289324812591076, -0.17758584022521973, 0.22722165286540985, 0.9396833777427673, -0.2697124183177948, -0.9370283484458923, 1.035470962524414, 0.14332261681556702, 0.4123428165912628, 0.48105162382125854, -0.726019024848938, -0.11330768465995789, 0.17295955121517181, 0.24156448245048523, 1.2025424242019653, -0.597639799118042, -0.33262383937835693, 1.1654491424560547, -1.2770764827728271, 0.08937220275402069, 1.6155866384506226, 0.5224765539169312, 0.2280219942331314, -0.10654234141111374, -0.15135815739631653, 0.569957971572876, 0.12413233518600464, -0.17501124739646912, -0.5667678713798523, 0.39393651485443115, -0.04907046630978584, 1.4424667358398438, -0.4522756338119507, -0.0404948927462101, 0.5849267244338989, 0.46965670585632324, 1.5025008916854858, 0.0770086720585823, -0.986533522605896, 0.005704584065824747, -0.021450651809573174, 0.19739124178886414, 0.7802696228027344, -0.17599841952323914, 0.4073559641838074, -1.0450036525726318, 0.0718875527381897, 0.9252538084983826, -0.12248752266168594, -0.15925832092761993, -0.38637787103652954, -0.26416900753974915, 0.7968781590461731, 1.267217755317688, 0.5086021423339844, -0.7045148015022278, 1.0055850744247437, 0.3177618980407715, -0.20413422584533691, -0.3135055899620056, 0.23545576632022858, 0.6743879914283752, 1.1851774454116821, -0.6391646265983582, -0.2062898725271225, -0.47314533591270447, 0.9397938847541809, -0.3133414387702942, 0.3145078420639038, -0.8162475228309631, 0.40907523036003113, 1.0984086990356445, 0.1940762847661972, -0.09341469407081604, -0.7649443745613098, -0.016289101913571358, -0.9567912220954895, 0.1500396579504013, -0.971062183380127, 0.05709831416606903, -0.40847960114479065, -0.901759684085846, -0.28418248891830444, -0.3948642909526825, 0.44923675060272217, -1.032728672027588, 0.2555534839630127, -0.4576428532600403, -0.17445062100887299, -0.3210723400115967, 0.7061631679534912, 0.23316562175750732, 0.09210765361785889, 0.3022301197052002, 0.17876699566841125, 1.4712865352630615, -0.9187177419662476, -0.6139674186706543, -0.8205268383026123, -0.5816185474395752, -0.4290553331375122, 0.15973225235939026, -0.03320462629199028, -1.324513554573059, -1.3848026990890503, -0.6328620314598083, -0.15891331434249878, -0.31759434938430786, 0.21071116626262665, 1.0924285650253296, 0.12654811143875122, -1.536993145942688, 0.25754788517951965, 0.018985142931342125, -0.5690338611602783, 0.9220549464225769, 0.0093216672539711, 0.7096487879753113, -0.31887856125831604, -0.6060012578964233, 0.28052911162376404, -0.2748866379261017, -0.49401581287384033, -0.48292258381843567, -0.1532224416732788, -0.9505820870399475, 0.21830949187278748, 0.2467195689678192, -1.1789202690124512, 0.8196006417274475, -0.7193049192428589, -0.5057247281074524, 0.5788585543632507, -0.4882926642894745, -0.18875271081924438, -0.04452671483159065, -0.18704716861248016, -0.39256927371025085, 0.38803189992904663, -0.02112811803817749, 0.8367134928703308, 0.9409582018852234, -0.2641904354095459, -0.5463945269584656, 0.1662684679031372, -0.2783451974391937, -0.011289055459201336, -0.40430760383605957, 1.0973105430603027, -0.8233267664909363, -0.5677424073219299, 0.6094592809677124, 0.6843078136444092, -0.34217774868011475, 0.3974558413028717, -0.0006020375876687467, -0.6206760406494141, 0.7593372464179993, 0.35398563742637634, 0.485683411359787, -0.6062752604484558, -0.7791219353675842, -0.06433895230293274, 0.47163817286491394, -0.23100323975086212, -0.9117267727851868, -0.04288536682724953, -0.30838918685913086, -0.4135737121105194, -0.025729987770318985, -0.8475053906440735, -0.4631117284297943, -0.5066695809364319, -0.6778374910354614, 0.15978294610977173, 0.4255813956260681, 1.1317861080169678, -0.9831780791282654, -0.22617246210575104, 0.4076538383960724, 0.41931769251823425, -0.603644847869873, 0.949872612953186, -0.08335472643375397, -0.23737789690494537, -0.21114110946655273, 0.2885790765285492, 0.07826343178749084, -0.6709558963775635, 0.22831030189990997, -0.9053404331207275, 0.17237728834152222, -0.13219091296195984, 0.019823210313916206, 1.1490554809570312, -0.008414910174906254, 1.1643003225326538, -0.10696971416473389, -0.7581868171691895, 0.20545189082622528, 0.28630930185317993, 0.1015733927488327, -0.6711549162864685, 0.5862246155738831, -0.19963128864765167, -0.5718948841094971, 0.1841791570186615, 0.5563504695892334, 1.6484124660491943, 0.019387535750865936, -0.14735263586044312, 0.6345065236091614, -0.059180062264204025, -0.05215330049395561, 0.34598982334136963, 0.6294718980789185, 0.02887224592268467, 0.3413882851600647, -0.3429759442806244, 0.2347775250673294, -1.043766736984253, -0.04923098906874657, 1.107823133468628, 0.13510136306285858, 1.2857792377471924, 0.26091504096984863, -1.001579999923706, -0.3473939299583435, -0.5289889574050903, 0.6396177411079407, 1.326386570930481, 0.25656658411026, 0.21095462143421173, -0.684939980506897, -0.28824472427368164, -0.7105470895767212, -0.522967517375946, -0.7647784352302551, 0.0006382662104442716, -0.13876402378082275, -0.8155015110969543, 0.8618319630622864, 0.4227089285850525, 1.1212923526763916, -1.0711032152175903, -1.108803629875183, -0.17013606429100037, 0.10499164462089539, -0.9439288973808289, -0.8425567746162415, 0.340949684381485, -0.4887849986553192, -0.6101208925247192, -0.37416934967041016, -0.14912697672843933, 0.5420398116111755, 0.09830296784639359, 0.895691990852356, -0.5189117789268494, -0.8464842438697815, 0.4195713996887207, 0.7346851825714111, -1.1050961017608643, 0.1724039763212204, -0.3694230616092682, -0.15146014094352722, 0.04472466930747032, 0.421760618686676, 0.22550009191036224, -0.5560723543167114, 0.3968188464641571, -0.48379725217819214, -0.143092080950737, 0.5257485508918762, 0.26398590207099915, 0.8356509804725647, -0.44531863927841187, 0.20152616500854492, -0.6754831671714783, 0.9292648434638977, 0.2630186080932617, -0.5120345950126648, 0.25318875908851624, -0.5499267578125, -0.2602311074733734, -0.11505540460348129, -0.6619873046875, -0.36470505595207214, -0.49799787998199463, 0.8098693490028381, -0.9436101317405701, -0.19987346231937408, -0.5919984579086304, 0.6691807508468628, -0.6511008143424988, 0.6611053943634033, 0.3922906816005707, 0.3732236921787262, 0.6433577537536621, 0.18816527724266052, -0.9556270241737366, 0.8092669248580933, 0.3261505961418152, -0.21842166781425476, 0.4768882691860199, 0.0267182569950819, -1.0136840343475342, -0.42820098996162415, -0.6236196756362915, -0.08251023292541504, -1.0464117527008057, 0.5318198204040527, -0.35240447521209717, -1.1663531064987183, -0.08905772864818573, -1.0408509969711304, 0.13690611720085144, -0.03145511448383331, 0.018986251205205917, -0.5925357937812805, -0.9548338651657104, -0.4918043911457062, -0.727967381477356, -0.9671139121055603, -1.2228171825408936, 0.3292839229106903, 0.7382927536964417, -0.3414939045906067, -0.2963681221008301, -0.4663187563419342, -0.41483840346336365, 1.3475892543792725, -0.25228041410446167, 0.3240869343280792, 0.40346142649650574, -0.7003610730171204, 0.11486667394638062, -0.3524368107318878, 0.13576073944568634, 0.006333440076559782, -0.08507730811834335, -1.4174630641937256, 0.401285320520401, -0.1542082130908966, -0.08032119274139404, 0.7447701096534729, 1.124320387840271, 0.9281981587409973, 0.4918067753314972, -0.5790548324584961, 0.4377017617225647, 1.1240780353546143, -0.5737402439117432, 0.2768547534942627, 0.08645999431610107, 0.6819654107093811, 0.3659290075302124, -0.1364494264125824, 0.5288597345352173, -0.017331069335341454, 0.36491328477859497, 0.6055698394775391, -0.8244393467903137, -1.0790005922317505, -0.26481661200523376, -0.038473471999168396, 0.3364783823490143, 0.08860944211483002, -0.0912700891494751, -0.7397522330284119, 0.8557248115539551, -1.3006526231765747, -0.9800516963005066, 0.7166248559951782, 0.8410466909408569, -0.28077465295791626, -0.09446068108081818, -0.3121277093887329, -0.4361262619495392, 0.8898150324821472, 0.5458921194076538, -0.5208756327629089, -0.27862852811813354, -0.39801597595214844, 0.5149731040000916, 0.4340094327926636, 0.5603278875350952, -0.7109637260437012, 0.45722532272338867, 14.66420841217041, 0.5248672962188721, -0.21757139265537262, 0.4140486419200897, 0.8792115449905396, 0.2525731921195984, 0.06048622727394104, 0.056320466101169586, -0.779265284538269, -0.10211960971355438, 0.2972460687160492, 0.527292788028717, 0.4062013030052185, 0.19036006927490234, -0.0953230932354927, -0.34778329730033875, -0.2867012917995453, 1.1368215084075928, 0.7267065644264221, -1.386832356452942, 0.16506555676460266, 0.24782341718673706, 0.26841557025909424, 0.6562265753746033, 0.7262773513793945, 0.08455903828144073, 0.3400210738182068, -0.5578749775886536, 0.3242740333080292, 0.46602457761764526, 0.6619461178779602, 0.06988415867090225, 0.0320703387260437, -0.07669389992952347, -1.3829513788223267, -0.23625189065933228, -0.7800135612487793, -0.5548487305641174, 0.1539383828639984, 0.05020362511277199, -0.37928998470306396, -0.5399467945098877, 0.41895508766174316, 0.5451279282569885, -0.07369120419025421, 0.8446616530418396, -0.21298682689666748, 0.11564164608716965, -0.25461408495903015, 0.009172397665679455, 0.3065914809703827, 0.5648954510688782, 0.4027795195579529, 0.11111073940992355, -0.448539137840271, 0.2667539119720459, 0.10475742816925049, 0.51298588514328, -0.2075088769197464, -0.702555239200592, -0.48805058002471924, 0.3123895227909088, -0.08915931731462479, 0.9968487620353699, -0.04269333556294441, 0.4586485028266907, -0.008118757978081703, 0.13334013521671295, 0.15031741559505463, 0.45700258016586304, -0.35622549057006836, -0.4097056984901428, 0.40285298228263855, -0.26196831464767456, 0.38997456431388855, 0.8587851524353027, -0.44717109203338623, -0.11755885183811188, -0.6640294194221497, -0.24300028383731842, 0.6236757636070251, -1.1717960834503174, -0.7425660490989685, 1.2617664337158203, -0.13598035275936127, -0.2829388380050659, 0.9218373894691467, -0.7457621693611145, -0.622852623462677, 0.5575594902038574, -1.4794108867645264, -0.8702976703643799, -0.4432114362716675, 0.13527317345142365, -0.013897091150283813, -0.2696722149848938, 0.5228997468948364, -0.10047131776809692, 0.07813308387994766, 0.3272143006324768, -0.6878621578216553, -0.10175944119691849, 0.06213071569800377, -0.3575008511543274, 0.5388588309288025, 0.8778954148292542, -0.09042743593454361, 0.07631760835647583, 0.07784096896648407, 0.18531373143196106, -0.5472927689552307, 0.13395439088344574, 0.18129952251911163, -0.404974102973938, -0.7356853485107422, -0.4590330123901367, -0.8613981008529663, 0.07934778928756714, 0.6679927706718445, 0.3124963343143463, -0.34379446506500244, -0.04268423095345497, -0.27565470337867737, -0.26265543699264526, -0.7597993612289429, -0.06278418749570847, 0.3065727651119232, -0.6814122796058655, -0.3420974612236023, -0.26068639755249023, 0.10077965259552002, -0.7335594892501831, -0.1654687076807022, -0.12701267004013062, 0.33200907707214355, -0.4286109507083893, 1.554343819618225, -0.281535267829895, 0.20803286135196686, 0.4075508713722229, -0.0871945396065712, -0.38236501812934875, -0.4641413390636444, -0.9039530158042908, 0.17139670252799988, -0.12812349200248718, -0.06424912065267563, -0.5325325727462769, 0.2638118863105774, 0.3699095547199249, 0.3704743981361389, -0.3461909294128418, -0.7459495067596436, 0.3882651925086975, -0.8220484852790833, -0.4708324074745178, -0.18737256526947021, -0.42145437002182007, -0.46918562054634094, -0.036363765597343445, 0.3461911976337433, 0.6114577651023865, 0.5859768390655518, -0.589776337146759, 0.2702226936817169, -0.29801100492477417, -0.016003400087356567, -0.7386995553970337, -0.7531982064247131, -1.3190367221832275, -0.61599200963974, -0.5737147331237793, -0.0554942786693573, -0.9899989366531372, -0.7344127893447876, 0.13675934076309204, -0.5863432884216309, -0.14714376628398895, 0.2779107093811035, -0.3664911091327667, -0.19260871410369873, -0.5009147524833679, -0.6203721165657043, 0.6754980683326721, 0.9739295244216919, -0.676328182220459, 0.27793261408805847, 0.07146066427230835, -0.2055111527442932, 0.7935062050819397, 0.22197771072387695, -0.4632372260093689, -0.8706664443016052, -1.0033234357833862, -0.1721133589744568, -0.0911368727684021, 0.3463723361492157, -1.203324317932129, 1.5050724744796753, 0.4778986871242523, 0.571671724319458, -0.12894207239151, 0.6377439498901367, -1.1455345153808594, -0.709259033203125, 0.5114831924438477, -0.6870114803314209, -0.06300678849220276, 0.26284441351890564, -0.10795477032661438, -0.34068822860717773, 1.1322118043899536, 0.6919755935668945, -0.8083598613739014, -1.158857822418213, 0.5710000395774841, -0.34692254662513733, 0.027959758415818214, 0.25976043939590454, -0.4841526746749878, -1.1854655742645264, -0.3506920635700226, -0.26027122139930725, 0.3267347812652588, -0.7477987408638, 0.8760073184967041, 1.2502620220184326, -0.9828301668167114, 0.047963596880435944, 0.7613197565078735, -0.25080057978630066, -0.22149266302585602, 0.5807312726974487, 0.7183690071105957, -0.08415423333644867, 0.4625857174396515, -0.41006025671958923, -0.21538686752319336, -0.8350537419319153, 0.17377614974975586, 1.217941403388977, 0.023767266422510147, -0.30254608392715454, 1.0984047651290894, 0.36977383494377136, -0.12517035007476807, 0.4902728497982025, -1.0126537084579468, -0.501719057559967, -0.20760664343833923, 0.7408786416053772, 0.17868629097938538, -0.14436441659927368, 0.12173458188772202, -0.6112415194511414, 0.6300916075706482, -0.11900625377893448, -0.4969964027404785, 0.01495915837585926, -0.08634553104639053, 0.10675583779811859, -0.06676805764436722, 0.19291958212852478, -0.772765040397644, -1.275272011756897, -1.126092553138733, -0.538232147693634, -0.5576207041740417, 0.5755283236503601, -0.09205801039934158, -1.174452543258667, 0.846908450126648, 1.1130181550979614, 0.11958887428045273, 0.8795166015625, 0.1091487929224968, -0.3559606671333313, 0.42248770594596863, 0.013579847291111946, -0.4370337724685669, -0.16271524131298065, 0.7214595675468445, 1.3084783554077148, -0.8949828743934631, 0.32416895031929016, -0.5020006895065308, -0.6264740228652954, 0.9401439428329468, 0.38938507437705994, -0.5926277041435242, 0.8252860903739929, -0.26004546880722046, -0.06544102728366852, -0.04342040792107582, -0.8674395084381104, -0.4739481806755066, 1.2477056980133057, 1.691194772720337, 0.26007986068725586, -0.12229172140359879, 0.5944948792457581, 0.24667547643184662, 0.6296456456184387, 0.24282251298427582, 0.35451626777648926, 0.2132512480020523, -0.44214290380477905, 0.6323429346084595, -0.4365489184856415, 0.5120289325714111, -0.5317699313163757, -0.630759596824646, 0.19382822513580322, 0.6861987709999084, 0.10193781554698944, 0.7670964598655701, 0.9841678142547607, 0.20314159989356995, 0.6448701024055481, -0.6913158893585205, 0.7365440130233765, -0.18620866537094116, -0.2040487676858902, 0.22971713542938232, -0.9384143352508545, -0.2909776568412781, -0.530085563659668, -0.6562820076942444, 0.16153445839881897, 0.22232592105865479, 0.26232776045799255, -0.38396507501602173, 0.1502683311700821, 0.35795459151268005, 0.7459475994110107, 1.0568270683288574, -0.39247435331344604, -0.6426669359207153, 0.04970944672822952, -0.9158116579055786, 0.28948065638542175, -0.7993730902671814, 0.06918442994356155, -0.5189821720123291, 0.0053453100845217705, -0.027099022641777992]}, "authors": [{"authorId": "1491490451", "name": "Moein Heidari"}, {"authorId": "1763181", "name": "Reza Azad"}, {"authorId": "2294174753", "name": "Sina Ghorbani Kolahi"}, {"authorId": "2198489273", "name": "Ren'e Arimond"}, {"authorId": "2237423209", "name": "Leon Niggemeier"}, {"authorId": "116829435", "name": "Alaa Sulaiman"}, {"authorId": "9345245", "name": "Afshin Bozorgpour"}, {"authorId": "1411236504", "name": "Ehsan Khodapanah Aghdam"}, {"authorId": "2131612425", "name": "A. Kazerouni"}, {"authorId": "1836588", "name": "I. Hacihaliloglu"}, {"authorId": "1737693", "name": "D. Merhof"}], "references": [{"paperId": "6631167f0e9baa1963297727566bca3c43573192", "title": "SA2-Net: Scale-aware Attention Network for Microscopic Image Segmentation"}, {"paperId": "bacdb732960a52dd3b47ad0f73d2343edf808da0", "title": "Beyond Self-Attention: Deformable Large Kernel Attention for Medical Image Segmentation"}, {"paperId": "f55b95dbe6d89547736a3b54cbff120130f060f1", "title": "Laplacian-Former: Overcoming the Limitations of Vision Transformers in Local Texture Detection"}, {"paperId": "740512dfadd91cd52771f2a721509c371efb9b89", "title": "SG-Former: Self-guided Transformer with Evolving Token Reallocation"}, {"paperId": "131ba9932572c92155874db93626cf299659254e", "title": "FLatten Transformer: Vision Transformer using Focused Linear Attention"}, {"paperId": "d7890d1906d95c4ae4c430b350455156d6d8aed9", "title": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"}, {"paperId": "37defa9aa690c033f9c4d1510df32ae5e996f716", "title": "RSPrompter: Learning to Prompt for Remote Sensing Instance Segmentation Based on Visual Foundation Model"}, {"paperId": "c306dbb87b9afaa60e1d68c1d20cb21a9c8c01d5", "title": "Efficient Vision Transformer for Human Pose Estimation via Patch Selection"}, {"paperId": "9a83aeadc8db65fb6da39ec977360541cddaff5c", "title": "EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention"}, {"paperId": "c57467e652f3f9131b3e7e40c23059abe395f01d", "title": "SpectFormer: Frequency and Attention is what you need in a Vision Transformer"}, {"paperId": "53e5db85e2a7442f20670be2ae25019fcf9d27a2", "title": "Slide-Transformer: Hierarchical Vision Transformer with Local Self-Attention"}, {"paperId": "e658f8a80f3d859629a0eb0d338e4bf8d6d6c493", "title": "SparseViT: Revisiting Activation Sparsity for Efficient High-Resolution Vision Transformer"}, {"paperId": "af21d7b29a8b48967d0151a0b86f15d755eba02b", "title": "Vision Transformer With Quadrangle Attention"}, {"paperId": "3375b5693331c37b899d78115d91215b8b5716e9", "title": "SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications"}, {"paperId": "52cc542b60c99e8866a7fc515c10f443089005f2", "title": "FastViT: A Fast Hybrid Vision Transformer using Structural Reparameterization"}, {"paperId": "19921cefb2470b2f5d984ab9ce92ebb94aedf2ea", "title": "Sparsifiner: Learning Sparse Instance-Dependent Attention for Efficient Vision Transformers"}, {"paperId": "643359e68b899a431ff9ccbe68c2e6d3b3624002", "title": "Hybrid Spectral Denoising Transformer with Guided Attention"}, {"paperId": "2f4d8f3c016ec53380b376ae7ac516f9c0f07a0d", "title": "BiFormer: Vision Transformer with Bi-Level Routing Attention"}, {"paperId": "2d4b96178897b39891354908b80dced466071522", "title": "Token Sparsification for Faster Medical Image Segmentation"}, {"paperId": "61e721334296ebfbbf6443b5ed9eb8c83b708c95", "title": "Scaling Vision Transformers to 22 Billion Parameters"}, {"paperId": "0cd526723b87ae37981922992992d203448a2014", "title": "DilateFormer: Multi-Scale Dilated Transformer for Visual Recognition"}, {"paperId": "8b0357f1bceb9cf7a5629b0ba3acb5660edf90b2", "title": "Advances in Medical Image Analysis with Vision Transformers: A Comprehensive Review"}, {"paperId": "938414e8b3927ffe8c93c5b3d0bf5177d7e84447", "title": "MISSFormer: An Effective Transformer for 2D Medical Image Segmentation"}, {"paperId": "750676b67abef11d102f0a5e7e221bbb56fca2c8", "title": "UNETR++: Delving into Efficient and Accurate 3D Medical Image Segmentation"}, {"paperId": "262ce9a1f9203a103edfc3a7bb88c419982af99e", "title": "Fcaformer: Forward Cross Attention in Hybrid Vision Transformer"}, {"paperId": "46f7aa7bccd627e0ad43f76e47318cc0c5887f75", "title": "RTFormer: Efficient Design for Real-Time Semantic Segmentation with Transformer"}, {"paperId": "ffd91f85d6d19e75309ececfd190afa6bb562284", "title": "Spikformer: When Spiking Neural Network Meets Transformer"}, {"paperId": null, "title": "UNesT: Local Spatial Representation Learning with Hierarchical Transformer for Efficient Medical Segmentation"}, {"paperId": "ec139916edd6feb9b3cb3a0325ca96e21dbb0147", "title": "Hydra Attention: Efficient Attention with Many Heads"}, {"paperId": "88b7f8ab3933ee4775eaa200029755e0022f8870", "title": "EViT: Privacy-Preserving Image Retrieval via Encrypted Vision Transformer in Cloud Computing"}, {"paperId": "3e448df5aa191f7a3945d0fd609c8bc5966a2333", "title": "HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions"}, {"paperId": "3de7e0c4bb5648a8368135592e11e991305ac426", "title": "HiFormer: Hierarchical Multi-scale Representations Using Transformers for Medical Image Segmentation"}, {"paperId": "05b7bd47fa5cbe10497c49004b57eb5ab4fdd0b4", "title": "EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications"}, {"paperId": "bf6ce546c589fa8054b3972b266532664914bd21", "title": "Fast Vision Transformers with HiLo Attention"}, {"paperId": "9695824d7a01fad57ba9c01d7d76a519d78d65e7", "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"}, {"paperId": "24de23963bec39fe0e39612e2cacb76c83d66f93", "title": "Transformer Tracking with Cyclic Shifting Window Attention"}, {"paperId": "c5e6f0c52c1f91086879f46120efa79e96158eba", "title": "Cross-view Transformers for real-time Map-view Semantic Segmentation"}, {"paperId": "38085be7f53f1cdf5e6399fa170648f30182028b", "title": "Fusing Spatial Attention with Spectral-Channel Attention Mechanism for Hyperspectral Image Classification via Encoder-Decoder Networks"}, {"paperId": "7ccca665e5438c9e2ce8c94edfd8dd24f3ef2137", "title": "Self-Calibrated Efficient Transformer for Lightweight Super-Resolution"}, {"paperId": "ba609e5c83ad9b32723e547b9d3c89d97373f755", "title": "VSA: Learning Varied-Size Window Attention in Vision Transformers"}, {"paperId": "5a71bf38cf409b55b14b2d5159c0b06bef9ad603", "title": "A General Survey on Attention Mechanisms in Deep Learning"}, {"paperId": "859893aadb0d30d38b6f856392056188c18d0c78", "title": "RSTT: Real-time Spatial Temporal Transformer for Space-Time Video Super-Resolution"}, {"paperId": "fa717a2e31f0cef4e26921f3b147a98644d2e64c", "title": "Focal Modulation Networks"}, {"paperId": "71b646590bbc45f2d79bc9ca1251926beca02e7c", "title": "Efficient Long-Range Attention Network for Image Super-resolution"}, {"paperId": "879de0f5fba4c37dfff157672ed23d4e4e6c5fbc", "title": "Dynamic Group Transformer: A General Vision Transformer Backbone with Dynamic Group Attention"}, {"paperId": "9dc481ec44178e797466bbad968071917842156b", "title": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection"}, {"paperId": "ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2", "title": "Visual attention network"}, {"paperId": "577a350ade92578913245e2d474aeabcb576e6d6", "title": "XAI for Transformers: Better Explanations through Conservative Propagation"}, {"paperId": "934942934a6a785e2a80daa6421fa79971558b89", "title": "BViT: Broad Attention based Vision Transformer"}, {"paperId": "b52844a746dafd8a5051cef49abbbda64a312605", "title": "When Shift Operation Meets Vision Transformer: An Extremely Simple Alternative to Attention Mechanism"}, {"paperId": "3e906906d475c73b6d8ce24ac5ebdac9979fd01b", "title": "Video Transformers: A Survey"}, {"paperId": "c2df109689819d6f456c771874208840c98a7a9f", "title": "Lawin Transformer: Improving Semantic Segmentation Transformer with Multi-Scale Representations via Large Window Attention"}, {"paperId": "e5cb26148791b57bfd36aa26ce2401e231d01b57", "title": "Vision Transformer with Deformable Attention"}, {"paperId": "2a4024163826151303aa0bbb18320b8a67167794", "title": "Pale Transformer: A General Vision Transformer Backbone with Pale-Shaped Attention"}, {"paperId": "72e81bc41ffae1d414836169107910025aaacb75", "title": "Lite Vision Transformer with Enhanced Self-Attention"}, {"paperId": "5553f9508dd1056ecc20c5b1f367e9a07e2c7e81", "title": "StyleSwin: Transformer-based GAN for High-resolution Image Generation"}, {"paperId": "87e6f235c7a1fdeceb41605db64419fa11f7b98b", "title": "Couplformer: Rethinking Vision Transformer with Coupling Attention Map"}, {"paperId": "658a017302d29e4acf4ca789cb5d9f27983717ff", "title": "Masked-attention Mask Transformer for Universal Image Segmentation"}, {"paperId": "336e06e34eac2eeda8b34d95d545d8ff4dd1b2f9", "title": "Class-Agnostic Object Detection with Multi-modal Transformer"}, {"paperId": "45f686be3b96302ede327645227134e1c304dbab", "title": "Attention mechanisms in computer vision: A survey"}, {"paperId": "5e2180e4ce9d218cccb1c78a93a863d5f967d907", "title": "Transformers in computational visual media: A survey"}, {"paperId": "da74a10824193be9d3889ce0d6ed4c6f8ee48b9e", "title": "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer"}, {"paperId": "bd9ab344da99022cbbbfd3f5c9c82a0b21c60ad9", "title": "nnFormer: Volumetric Medical Image Segmentation via a 3D Transformer"}, {"paperId": "1cd6b0f41d62aca38ba5a69db10e79c05e618c21", "title": "Conditional DETR for Fast Training Convergence"}, {"paperId": "2c4d5b1278125d84c9e66ebe1032af888d9211f3", "title": "Token Shift Transformer for Video Classification"}, {"paperId": "d045133e6e022684329ff944d67f91888be1bc3b", "title": "Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer"}, {"paperId": "a5c41f188b0eb0acb444cb4899bf6af378ee9ede", "title": "CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention"}, {"paperId": "faa30dfcb1531df4e4d5c219bad06d65f6c860fa", "title": "LeViT-UNet: Make Faster Encoders with Transformer for Medical Image Segmentation"}, {"paperId": "800cfb3d23115cdcd4d114234b65bbdf2080f798", "title": "CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows"}, {"paperId": "9b6af0e358e76d22f209c75b1702c3e6ea7815b1", "title": "Global Filter Networks for Image Classification"}, {"paperId": "f1c3cd27f46ab21589c6f2b2cc4179f0d1b9ef2d", "title": "E-DSSR: Efficient Dynamic Surgical Scene Reconstruction with Transformer-based Stereoscopic Depth Perception"}, {"paperId": "7b664a306b7d2f68dd816ea1d6586cf3472d75c1", "title": "Early Convolutions Help Transformers See Better"}, {"paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a", "title": "PVT v2: Improved baselines with Pyramid Vision Transformer"}, {"paperId": "ba1b51e872cdf7744a50b1b2e76ee8b85a0d0dfd", "title": "P2T: Pyramid Pooling Transformer for Scene Understanding"}, {"paperId": "7fff8018bf625447df837c2fda5c58a705fbc038", "title": "XCiT: Cross-Covariance Image Transformers"}, {"paperId": "9f4b69762ffb1ba42b573fd4ced996f3153e21c0", "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes"}, {"paperId": "6b6ffb94626e672caffafc77097491d9ee7a8682", "title": "On the Connection between Local Attention and Dynamic Depth-wise Convolution"}, {"paperId": "2e8149dafb864ec3675087c99bf5572fcf4eb170", "title": "RegionViT: Regional-to-Local Attention for Vision Transformers"}, {"paperId": "dbdcabd0444ad50b68ee09e30f39b66e9068f5d2", "title": "DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification"}, {"paperId": "07e987364bf0be1949e379f976f8dea675977337", "title": "MSG-Transformer: Exchanging Local Spatial Information by Manipulating Messenger Tokens"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "ea7cfe7f2340584cbe653da6077ee7c213e49b92", "title": "Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation"}, {"paperId": "cc9f3a61ea4eaabf43cbb30cd1dd718074932679", "title": "All Tokens Matter: Token Labeling for Training Better Vision Transformers"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "97e2eb4d8ddccca8f3c4835ee89ac4617ee52e6a", "title": "Latent Correlation Representation Learning for Brain Tumor Segmentation With Missing MRI Modalities"}, {"paperId": "a56bf7ee9a56d8f84079684339a953c2df9ce76b", "title": "A review on the attention mechanism of deep learning"}, {"paperId": "40f4d7fe800810288a80f84cdb357a8f4c28e880", "title": "Rethinking Spatial Dimensions of Vision Transformers"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "b6382a7351c0c595f91472ac71d3b2d87b3c4844", "title": "ViViT: A Video Vision Transformer"}, {"paperId": "0eff37167876356da2163b2e396df2719adf7de9", "title": "CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification"}, {"paperId": "96da196d6f8c947db03d13759f030642f8234abf", "title": "DeepViT: Towards Deeper Vision Transformer"}, {"paperId": "70cf7c785952375e8061c92235aa20e94b02ecd4", "title": "Coordinate Attention for Efficient Mobile Network Design"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "367f7f64ded5d18528c1013db9dfa01b075db484", "title": "Medical Transformer: Gated Axial-Attention for Medical Image Segmentation"}, {"paperId": "24b8a0b02bcb7934967757fc59d273a71ba67e30", "title": "TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "9afcacef80e4961227439eedf5a3f06e5319b9b7", "title": "Channelized Axial Attention - considering Channel Relation within Spatial Attention for Semantic Segmentation"}, {"paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b", "title": "Transformers in Vision: A Survey"}, {"paperId": "d40c77c010c8dbef6142903a02f2a73a85012d5d", "title": "A Survey on Vision Transformer"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "33e738b6ca2a6e0c5020a3ea87c1ebd2a3c7497a", "title": "Rotate to Attend: Convolutional Triplet Attention Module"}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"}, {"paperId": "d920e0710d2a1ae966661d0513b817b6b81dc2b2", "title": "Improving Convolutional Networks With Self-Calibrated Convolutions"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb", "title": "TAM: Temporal Adaptive Module for Video Recognition"}, {"paperId": "76a9f336481b39515d6cea2920696f11fb686451", "title": "Quantifying Attention Flow in Transformers"}, {"paperId": "416fead21c20b452fbf1f105ee5b4b5646c75a42", "title": "Strip Pooling: Rethinking Spatial Pooling for Scene Parsing"}, {"paperId": "26051e0070a59444eefe5bed36627703235405b7", "title": "Segment"}, {"paperId": "173d31ea3ec9db19870fcf2710841b4a3e864c6d", "title": "Global-Local Temporal Representations for Video Person Re-Identification"}, {"paperId": "3e70bbe6c4cd98d66599db709e32b748f184a2d4", "title": "CondConv: Conditionally Parameterized Convolutions for Efficient Inference"}, {"paperId": "8043113812dae0f95f68677ba7ce986321401dd6", "title": "Relation-Aware Global Attention for Person Re-Identification"}, {"paperId": "c41a11c0e9b8b92b4faaf97749841170b760760a", "title": "VideoBERT: A Joint Model for Video and Language Representation Learning"}, {"paperId": "7fa4c034518dc272f4d234faa4eff7e1461d4822", "title": "Bidirectional LSTM with attention mechanism and convolutional layer for text classification"}, {"paperId": "01e00be6806917b097d4815e6194e0b32a5f3bb1", "title": "Improving User Attribute Classification with Text and Social Network Attention"}, {"paperId": "5f4a22ee70ca613d9c0630eafc96364fe365fdf8", "title": "Efficient Attention: Attention with Linear Complexities"}, {"paperId": "cd8ddaaf56e38dddafdeac3f9643b9b5e9d35d54", "title": "Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks"}, {"paperId": "ad655c25e052fa4eeed53421344aca6f239c4c9d", "title": "Dual Attention Network for Scene Segmentation"}, {"paperId": "e9021af7af143d84eec304d59fc6e1009214e592", "title": "Recalibrating Fully Convolutional Networks With Spatial and Channel \u201cSqueeze and Excitation\u201d Blocks"}, {"paperId": "de95601d9e3b20ec51aa33e1f27b1880d2c44ef2", "title": "CBAM: Convolutional Block Attention Module"}, {"paperId": "10bb4ef7a6719ea132e00f0ab5680919a4131d99", "title": "BAM: Bottleneck Attention Module"}, {"paperId": "136c96810238657bf0c6f0d4b56b0e40e24f3c47", "title": "Learning what and where to attend"}, {"paperId": "c52ac453e154953abdb06fc041023e327ea609a4", "title": "Self-Attentional Acoustic Models"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "4550a4c714920ef57d19878e31c9ebae37b049b2", "title": "Massive Exploration of Neural Machine Translation Architectures"}, {"paperId": "88513e738a95840de05a62f0e43d30a67b3c542e", "title": "SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for Image Captioning"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b", "title": "Hierarchical Question-Image Co-Attention for Visual Question Answering"}, {"paperId": "d7192b47b259a249f055cd448f6381088601354d", "title": "Layer-Wise Relevance Propagation for Neural Networks with Local Renormalization Layers"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0", "title": "Effective Approaches to Attention-based Neural Machine Translation"}, {"paperId": "3056add22b20e3361c38c0472d294a79d4031cb4", "title": "Listen, attend and spell: A neural network for large vocabulary conversational speech recognition"}, {"paperId": "b92aa7024b87f50737b372e5df31ef091ab54e62", "title": "Training Very Deep Networks"}, {"paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270", "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"}, {"paperId": "4d8f2d14af5991d4f0d050d22216825cac3157bd", "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"}, {"paperId": "ac3ee98020251797c2b401e1389461df88e52e62", "title": "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling"}, {"paperId": "47d2dc34e1d02a8109f5c04bb6939725de23716d", "title": "End-to-end Continuous Speech Recognition using Attention-based Recurrent NN: First Results"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "8a756d4d25511d92a45d0f4545fa819de993851d", "title": "Recurrent Models of Visual Attention"}, {"paperId": "0bff8898e3ebb1ab67fd20b5db00c6cb1938e6c3", "title": "Learning to combine foveal glimpses with a third-order Boltzmann machine"}, {"paperId": "f1eb9f77b6baf1eef537940bd428826a44702944", "title": "Focusing the spotlight: individual differences in visual attention control."}, {"paperId": "29842c1f1d487f0f3b9d8d2afebaff7c2f51f73c", "title": "A Model of Saliency-Based Visual Attention for Rapid Scene Analysis"}, {"paperId": "37b187e3df04fe7dd31293222407b4b86f3089fb", "title": "Attention!"}, {"paperId": "1d70fed85b2bf8eaac0878b88c3934d62578cb8a", "title": "Statistical Theory of Extreme Values and Some Practical Applications"}, {"paperId": "c3dd958431836616baf4adda22ecb1507f7d5e98", "title": "Knowing What it is: Semantic-Enhanced Dual Attention Transformer"}, {"paperId": "585c16a343fe301d28d5bf779162f24a7f3aa0bd", "title": "SCViT: A Spatial-Channel Feature Preserving Vision Transformer for Remote Sensing Image Scene Classification"}, {"paperId": "b503f607c8e73a117888e0d5f658c6855a11c319", "title": "ViT-NeT: Interpretable Vision Transformers with Neural Tree Decoder"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "1728d2eddd60941bb059b6d6c8f3e6bfc2d15e39", "title": "Speech-T: Transducer for Text to Speech and Beyond"}, {"paperId": null, "title": "Levit: avisiontransformerinconvnet\u2019sclothing for faster inference"}, {"paperId": null, "title": "Pre-trained image processing"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "602993051a5e6f1d18c1317ce7fe061f48a1f2c7", "title": "Convolutional Neural Networks"}, {"paperId": null, "title": "Squeeze-and-excitationnetworks"}, {"paperId": null, "title": "Spatial trans-former networks"}, {"paperId": null, "title": "Longshort-termmemory"}, {"paperId": null, "title": "Faculty of Informatics and Data Science, University of Regens-burg, Regensburg, Germany"}, {"paperId": null, "title": "FasterViT: Fast Vision"}, {"paperId": null, "title": "^Department of Industrial and Systems Engineering"}, {"paperId": null, "title": "Metaformer is actually what"}, {"paperId": null, "title": "Interpretability-Aware Vision"}, {"paperId": null, "title": ": Improved multiscale vision"}, {"paperId": null, "title": "Global context vision"}, {"paperId": null, "title": "Towards Evaluating Explanations of Vision"}, {"paperId": null, "title": "Castling-ViT"}, {"paperId": null, "title": "CAT-ViL: Co-Attention Gated Vision-LanguageEmbeddingforVisualQuestionLocalized-Answering"}, {"paperId": null, "title": "Transferring Foundation Models"}, {"paperId": null, "title": "School of Biomedical Engineering, University of British Columbia, British Columbia, Canada"}, {"paperId": null, "title": "Improve the Hierarchical Architecture of Vision"}, {"paperId": null, "title": "WhichTransformertoFavor: A Comparative Analysis of Efficiency in Vision"}, {"paperId": null, "title": "Efficiency 360: Efficient Vision"}, {"paperId": null, "title": "PixArt-\u03b1 : Fast Training of Diffusion Trans-former for Photorealistic"}, {"paperId": null, "title": "QuadTree Attention for Vision"}, {"paperId": null, "title": "Enhancing Efficiency in Vision Transformer Networks: Design Techniques Encoder\u2013Decoder Networks"}]}