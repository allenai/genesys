{"paperId": "35ab93f41115e860bee5e202b71061addfd0fd5d", "abstract": "Self-attention performs well in long context but has quadratic complexity. Existing RNN layers have linear complexity, but their performance in long context is limited by the expressive power of their hidden state. We propose a new class of sequence modeling layers with linear complexity and an expressive hidden state. The key idea is to make the hidden state a machine learning model itself, and the update rule a step of self-supervised learning. Since the hidden state is updated by training even on test sequences, our layers are called Test-Time Training (TTT) layers. We consider two instantiations: TTT-Linear and TTT-MLP, whose hidden state is a linear model and a two-layer MLP respectively. We evaluate our instantiations at the scale of 125M to 1.3B parameters, comparing with a strong Transformer and Mamba, a modern RNN. Both TTT-Linear and TTT-MLP match or exceed the baselines. Similar to Transformer, they can keep reducing perplexity by conditioning on more tokens, while Mamba cannot after 16k context. With preliminary systems optimization, TTT-Linear is already faster than Transformer at 8k context and matches Mamba in wall-clock time. TTT-MLP still faces challenges in memory I/O, but shows larger potential in long context, pointing to a promising direction for future research.", "venue": "", "year": 2024, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "With preliminary systems optimization, TTT-Linear is already faster than Transformer at 8k context and matches Mamba in wall-clock time, and TTT-MLP still faces challenges in memory I/O, but shows larger potential in long context, pointing to a promising direction for future research."}, "embedding": {"model": "specter_v2", "vector": [0.40328553318977356, 0.6687934398651123, -0.2814667224884033, -0.4319167733192444, 0.1453419178724289, -0.26355206966400146, 0.5717470049858093, -0.28245002031326294, -0.4796590507030487, -0.1713028848171234, 0.5310345888137817, 0.24950341880321503, 0.9143069982528687, 0.21707603335380554, -0.05152665823698044, 0.3357834219932556, -1.0363495349884033, 0.077390156686306, 0.42075100541114807, -0.28899335861206055, -0.026489559561014175, -0.9252143502235413, -0.859316885471344, 0.3528173863887787, 0.17815254628658295, 0.45769259333610535, 0.4115128219127655, 1.0197042226791382, -0.5337910652160645, 0.6468440890312195, 0.1488344520330429, -0.32384592294692993, 0.17400453984737396, -0.0891183391213417, -0.6443964242935181, -0.20691663026809692, 0.42813488841056824, -0.26393550634384155, -0.31939736008644104, 0.6327354311943054, -0.21774767339229584, 0.08789022266864777, 0.03132375329732895, -0.6210662126541138, -0.14371590316295624, 1.1429206132888794, 0.7774259448051453, 0.7408673167228699, -0.33441781997680664, -0.3571675717830658, 1.2984179258346558, -0.9139416813850403, 0.05783829092979431, 1.3892853260040283, 0.4727318286895752, 0.7973958849906921, -0.051238276064395905, -0.5570821762084961, 0.9533931016921997, 0.2539587914943695, -0.45856553316116333, -0.624963104724884, 0.004846010357141495, 0.18216180801391602, 1.9425122737884521, -0.440123587846756, 0.034363407641649246, 1.127120018005371, -0.09314430505037308, 1.5827885866165161, -0.20858348906040192, -0.5748311281204224, -0.2024472951889038, 0.1960996687412262, 0.4290129840373993, 0.7362059354782104, -0.607008695602417, 0.19826337695121765, -0.6517379879951477, 0.3376307785511017, 0.638430118560791, 0.20448242127895355, 0.1953839510679245, -0.17853499948978424, -0.5639075040817261, 0.4614257216453552, 0.30853021144866943, 1.3595062494277954, -0.2133033126592636, 1.003857970237732, 0.7748674154281616, 0.4354502558708191, -0.2445249706506729, 0.33283090591430664, -0.396696537733078, -0.03262018412351608, -0.961661696434021, -0.2597433626651764, -0.13849695026874542, 0.9243342280387878, -0.11617456376552582, 0.7010442614555359, -0.47447821497917175, 0.37700673937797546, 1.1286511421203613, -0.02600131370127201, 0.8137933611869812, -0.7379363179206848, 0.05418357253074646, -0.6161184310913086, -0.08965007960796356, -0.4310758411884308, -0.3233610987663269, -0.5896313786506653, -0.6730597615242004, -1.235188364982605, -0.5522841811180115, 0.01679220236837864, -0.7234726548194885, 0.8297708034515381, -0.5052818059921265, 0.3754930794239044, 0.25226375460624695, 0.1260133981704712, 0.3303067982196808, 0.7203236818313599, 0.13242599368095398, 0.1486196368932724, 0.6744635105133057, -1.2916951179504395, -0.817192018032074, -1.0415700674057007, 0.6076915860176086, 0.14335870742797852, 0.23127157986164093, -0.06959821283817291, -1.0561950206756592, -1.0968780517578125, -1.0162352323532104, 0.34670162200927734, -0.57290118932724, 0.12235474586486816, 0.6575199365615845, 0.5982424020767212, -0.9369474649429321, 1.2805362939834595, -0.4159858822822571, -0.4120854139328003, 0.13109560310840607, 0.026610570028424263, 0.22730953991413116, 0.023658310994505882, -1.305518388748169, 0.3544156551361084, 0.5817986726760864, -0.3348097801208496, -0.21403133869171143, -0.5208648443222046, -1.2342088222503662, -0.18185016512870789, 0.4210934340953827, -0.1397852748632431, 1.497343897819519, -0.5192652344703674, -1.3370225429534912, 0.6699976325035095, -0.49158528447151184, -0.1564195603132248, 0.09407314658164978, -0.22376912832260132, -1.0185227394104004, -0.41484224796295166, -0.1321648210287094, 0.4577715992927551, 0.23086288571357727, -0.18666701018810272, -0.4634053707122803, 0.10090970993041992, -0.47495490312576294, -0.5621042847633362, -0.2098957747220993, 0.8633933067321777, -0.4649718999862671, -0.16714400053024292, 0.13523003458976746, 0.672808825969696, 0.216158926486969, -0.4883483648300171, -0.5546784996986389, -1.3063031435012817, 0.8316813111305237, 0.11377468705177307, 0.8937331438064575, -1.0327394008636475, -0.977379322052002, -0.3008769452571869, -0.47589343786239624, 0.1128496304154396, -1.1195831298828125, 0.4787137806415558, -0.5571512579917908, 0.5441702604293823, 0.006027119234204292, -1.172914743423462, 0.08364056050777435, -0.041628628969192505, -0.4142371118068695, -0.4448699355125427, 0.38798660039901733, 1.015263319015503, -1.15337336063385, -0.0834864005446434, -0.024569060653448105, 0.07770397514104843, -0.835028350353241, 1.2120916843414307, -0.468219131231308, -0.16382375359535217, -0.027726879343390465, -0.3310118615627289, -0.11185073107481003, -0.2808515131473541, 0.3463180363178253, -0.35495269298553467, -0.2026531994342804, 0.7065632939338684, -0.3942069411277771, 1.363404631614685, -0.5075434446334839, 0.8769381642341614, -0.08918646723031998, -0.4996319115161896, 0.1389477699995041, 0.44999027252197266, -0.1337607353925705, -0.3552234172821045, 0.1855238825082779, 0.08955732733011246, -0.43876832723617554, -0.019604671746492386, 0.7347128391265869, 0.9466646313667297, -0.2972573935985565, -0.010297401808202267, 0.6647837162017822, 0.14695985615253448, 0.49708446860313416, 0.21562498807907104, 0.8759437799453735, 0.42430561780929565, 0.20710617303848267, 0.12079228460788727, -0.011716960929334164, -0.949731707572937, 0.3470734655857086, 0.25928571820259094, 0.4942206144332886, 0.6604008674621582, 0.433604896068573, -0.754421055316925, -0.6321176886558533, 0.22008560597896576, 0.5709154605865479, 1.340388536453247, -0.4957554042339325, -0.24354694783687592, -0.8449263572692871, -0.387827068567276, -0.49423402547836304, 0.5851702690124512, -0.42465782165527344, -0.15643014013767242, -0.7124010324478149, -0.4224816560745239, 0.9633093476295471, 0.4038776755332947, 1.2876050472259521, -1.0486096143722534, -0.3998797535896301, 0.12666888535022736, 0.3151727020740509, -0.9432982206344604, -0.7316177487373352, 0.37419822812080383, -0.4900779128074646, -0.24309229850769043, 0.07105563580989838, -0.15941788256168365, -0.12034570425748825, -0.7928796410560608, 0.6285106539726257, -0.6224177479743958, 0.03269046172499657, 0.3934643566608429, 0.4041023850440979, -0.5268312692642212, -0.6494218111038208, 0.5301240086555481, 0.31239694356918335, 0.06348197162151337, 0.1525006890296936, 0.17415843904018402, -0.03225545957684517, 0.2255445271730423, -0.3959619700908661, 0.03136710077524185, 0.21011699736118317, -0.31894293427467346, 0.31288257241249084, -0.25765129923820496, 0.33245354890823364, -1.4697023630142212, 0.29564806818962097, 0.19444887340068817, -0.24380265176296234, 0.32696065306663513, -0.7213820815086365, -0.22680827975273132, 0.32004082202911377, -0.6926025748252869, -0.04018077626824379, -0.8548000454902649, 0.3385924696922302, -0.5352648496627808, -0.4027819335460663, 0.0798843502998352, 0.11994164437055588, 0.48855727910995483, 0.14678552746772766, 0.563447892665863, 0.10783612728118896, 0.06749505549669266, 0.3418441116809845, -1.0001416206359863, 0.6320340037345886, 0.43420863151550293, 0.25366270542144775, -0.27290499210357666, -0.4136313498020172, -0.6883299946784973, -0.5879309773445129, -0.46316081285476685, -0.4048099219799042, -0.33585408329963684, 0.33445465564727783, -0.22980810701847076, -1.2284071445465088, -0.02029850147664547, -0.97659832239151, -0.8125824332237244, -0.02631790190935135, -0.40812787413597107, -0.29609739780426025, -0.8317046761512756, -0.9798219203948975, -0.9633765816688538, -0.5483562350273132, -0.3083629012107849, -0.1473657190799713, 0.05279293283820152, -0.3490864634513855, -0.6508463025093079, 0.07341127097606659, -0.5468798875808716, 1.1553726196289062, -0.4656745493412018, 0.29090192914009094, -0.1874891072511673, -0.13310806453227997, -0.19836311042308807, 0.3421871066093445, 0.8792714476585388, -0.04554985091090202, 0.298092782497406, -1.0708757638931274, 0.28086623549461365, -0.2164374142885208, -0.30027467012405396, 0.3335586190223694, 0.16991621255874634, 0.7040215134620667, -0.2165437489748001, -0.38958221673965454, 0.23440542817115784, 1.2666988372802734, -0.27081602811813354, 0.36948931217193604, -0.0006037793937139213, 0.7983448505401611, 0.1888655126094818, -0.3385997712612152, 0.3798001706600189, 0.4334005117416382, 0.2402801513671875, 0.3267304301261902, 0.18576274812221527, 0.1483399122953415, -0.7924763560295105, 0.8666318655014038, 1.4671739339828491, 0.17416037619113922, -0.009948601014912128, -0.8308429718017578, 0.8233047723770142, -1.1317435503005981, -1.098237156867981, 0.7839054465293884, 0.6849673390388489, 0.46822041273117065, -0.21938134729862213, -0.29483985900878906, -0.07245317846536636, 0.4865645468235016, 0.38694703578948975, -0.5192759037017822, -0.687945544719696, -0.0806371420621872, 0.18331393599510193, 0.1660756915807724, 0.5966057777404785, -0.3565625250339508, 0.7832149863243103, 15.002134323120117, 0.4773148000240326, -0.1452283263206482, 0.42477113008499146, 0.5237252712249756, -0.019081536680459976, -0.2870483100414276, -0.0049449182115495205, -1.2474366426467896, -0.03545340523123741, 1.5441226959228516, 0.46389272809028625, 0.6270346641540527, 0.11971797049045563, 0.17560401558876038, 0.25425297021865845, -0.9114305377006531, 0.6645735502243042, 0.7836991548538208, -0.9044303894042969, 0.10998885333538055, 0.03131997585296631, 0.09400533884763718, 0.559877336025238, 0.7049399018287659, 1.2056702375411987, 0.5283706784248352, -0.07618454098701477, 0.47192540764808655, 0.5823385715484619, 0.999010443687439, 0.14344003796577454, 0.3207142651081085, 0.4067976176738739, -0.7753157615661621, -0.19377559423446655, -0.5619099736213684, -0.7377480864524841, 0.2189389020204544, -0.01223064586520195, -0.6097281575202942, -0.6439208984375, -0.07866937667131424, 0.7528253197669983, -0.12133847177028656, 0.2724880576133728, -0.24608562886714935, 0.8660328388214111, 0.02823125757277012, -0.2757475972175598, 0.42646992206573486, 0.783303439617157, 0.40956735610961914, 0.26380762457847595, -0.12489739805459976, 0.08488178998231888, -0.08175068348646164, 0.6391363143920898, -0.3956386148929596, -0.2400740534067154, -0.23602667450904846, -0.44429701566696167, -0.28547391295433044, 0.7663251161575317, 0.7780308723449707, 0.14776767790317535, 0.09947596490383148, 0.7924809455871582, 0.4782402813434601, 0.2899306118488312, -0.14126966893672943, -0.12483969330787659, 0.3669992685317993, -0.37968459725379944, 0.1169833242893219, 0.3981513977050781, 0.22665658593177795, -0.6231629252433777, -0.5643815398216248, -0.06188023090362549, 0.498868465423584, -1.1780011653900146, -0.5465788841247559, 0.9563490748405457, -0.4847992956638336, -0.42272359132766724, -0.19835764169692993, -0.881713330745697, -0.507197916507721, 0.012111085467040539, -1.6018866300582886, -0.4479352831840515, 0.22141911089420319, 0.0033356603235006332, -0.07027130573987961, 0.007582264486700296, 1.1819075345993042, 0.15353119373321533, -0.5486226677894592, 0.22617395222187042, -0.08570381999015808, 0.3196173906326294, -0.10283244401216507, -1.0290002822875977, 0.9518141746520996, 0.08242267370223999, -0.13819697499275208, 0.22225232422351837, -0.24051877856254578, 0.2549511790275574, -0.509624719619751, -0.3010495901107788, 0.6933948397636414, -0.8633050322532654, -0.36186283826828003, -0.578197717666626, -0.7510440945625305, 0.745647668838501, 0.826781153678894, -0.2240932732820511, 0.25085893273353577, 0.277228444814682, -0.7871891856193542, -0.4202372133731842, -0.7199792861938477, 0.34043970704078674, 0.5967840552330017, -0.689155638217926, -0.28558793663978577, -0.5221570730209351, 0.6319656372070312, -0.6163412928581238, -0.5237153768539429, -0.28013795614242554, 0.01993015594780445, -0.4161626398563385, 0.3797331750392914, -0.357881098985672, 0.3955969214439392, 0.8184801936149597, 0.09143739193677902, -0.7676944136619568, -0.09931233525276184, -1.077657699584961, 0.3245537579059601, 0.6473997235298157, 0.7875601649284363, -0.5800761580467224, 0.3068331778049469, 0.6504823565483093, -0.008312461897730827, -0.32927894592285156, -0.6805554032325745, -0.6856334805488586, -0.31273704767227173, -0.735914409160614, 0.28622865676879883, 0.3782241642475128, 0.104224793612957, 0.25108155608177185, 0.4879453480243683, 0.3923603892326355, -0.2310405671596527, -1.142640233039856, 0.12495452910661697, -0.09797864407300949, 0.04649534448981285, -0.6587278246879578, -0.5899633169174194, -1.328519582748413, -0.08209355920553207, -1.0465368032455444, -0.20082896947860718, -0.959110677242279, -0.4400964379310608, 0.11407149583101273, -0.39222797751426697, 0.2281806915998459, 0.40725696086883545, -0.7524414658546448, -0.3017607629299164, -0.7913066744804382, -0.8095757961273193, 0.6356591582298279, 0.6086392998695374, -0.6511737704277039, 0.010460917837917805, 0.1437903791666031, 0.17753176391124725, 0.24604901671409607, 0.6664668917655945, -0.22472365200519562, -0.4643871486186981, -1.2874534130096436, 0.4671684503555298, -0.0781732127070427, -0.10069394111633301, -1.0970289707183838, 0.7212345600128174, 0.4782930612564087, -0.18662799894809723, -0.34362664818763733, 0.30558791756629944, -1.105755090713501, -0.5831145644187927, 0.22169232368469238, -0.8650760054588318, 0.24800452589988708, 0.28237685561180115, -0.6299133896827698, -0.24998007714748383, 0.3511810600757599, 0.00424692127853632, -1.0789790153503418, -0.8164227604866028, 0.415584921836853, -0.5040838122367859, 0.14896410703659058, -0.3677223324775696, -0.41442742943763733, -1.0498313903808594, -0.24672499299049377, -0.014623652212321758, 0.6597205996513367, -0.4912142753601074, 1.1653820276260376, 0.2900843620300293, -1.2969433069229126, 0.03187793865799904, 0.2774698734283447, 0.11331767588853836, 0.08618299663066864, 0.6956852078437805, -0.005037279333919287, -0.11191117763519287, 0.24338029325008392, 0.24348771572113037, 0.1132957935333252, -0.5988392233848572, 0.349122017621994, 1.0049372911453247, -0.3829353451728821, 0.0629696473479271, 0.7014699578285217, -0.6564381122589111, -1.157593011856079, 0.3761000633239746, -1.6013357639312744, -0.5892503261566162, -0.22433790564537048, 0.7079454660415649, 0.28778573870658875, -0.47919416427612305, 0.06851794570684433, -0.2541534900665283, 0.2521682679653168, 0.02526017650961876, -0.5988593697547913, 0.6734938025474548, 0.017608681693673134, -0.18211841583251953, 1.3866686820983887, 1.0107946395874023, -0.6571809649467468, -0.820662260055542, -1.0259742736816406, -0.22221636772155762, 0.4109886884689331, -0.07895960658788681, -0.4219610393047333, -0.6791848540306091, 0.831814706325531, 0.6686274409294128, 0.5269883275032043, -0.215373694896698, -0.22640709578990936, 0.1020432785153389, 0.8701024651527405, -0.03700202330946922, -0.6844740509986877, -0.10866916179656982, 1.5504896640777588, 1.2504652738571167, -0.690791130065918, -0.15357860922813416, -0.017842669039964676, -0.708403468132019, 0.8443076610565186, 0.5649467706680298, -0.01973445527255535, 0.7502512335777283, -0.4134061336517334, 0.15592101216316223, 0.29941362142562866, -1.2530876398086548, -0.4082237184047699, 0.45469966530799866, 0.923081636428833, 0.5751444697380066, 0.21921856701374054, 0.67535799741745, 0.7535452246665955, -0.12510888278484344, -0.1304692029953003, 0.36477312445640564, 0.16350901126861572, -0.3459678590297699, 0.0260689128190279, 0.29401105642318726, 0.48111894726753235, -0.5382938385009766, -0.5074520707130432, 0.39547643065452576, 0.48398256301879883, 0.17158091068267822, 0.7888494729995728, 1.185305118560791, -0.0223965123295784, 0.8740307688713074, 0.42851921916007996, 0.35752877593040466, -0.5031775832176208, -0.5248536467552185, -0.29400426149368286, -0.40873661637306213, -0.3310531675815582, -0.13724587857723236, -0.8431988954544067, -0.44445472955703735, -0.06405047327280045, 0.31409597396850586, -0.06645498424768448, 0.29296478629112244, 0.9401012659072876, 0.48183372616767883, 0.6387190818786621, -0.01526327058672905, -0.4563394784927368, -0.3140951693058014, -1.360274314880371, 0.06528414040803909, -0.4638059437274933, 0.08302026242017746, 0.2503975033760071, -0.06156577542424202, -0.2787635028362274]}, "authors": [{"authorId": "2261356138", "name": "Yu Sun"}, {"authorId": "2261360508", "name": "Xinhao Li"}, {"authorId": "2261284227", "name": "Karan Dalal"}, {"authorId": "2269714419", "name": "Jiarui Xu"}, {"authorId": "2310240417", "name": "Arjun Vikram"}, {"authorId": "2310289206", "name": "Genghan Zhang"}, {"authorId": "2257007362", "name": "Yann Dubois"}, {"authorId": "2261361557", "name": "Xinlei Chen"}, {"authorId": "2261365695", "name": "Xiaolong Wang"}, {"authorId": "123593472", "name": "Sanmi Koyejo"}, {"authorId": "2253575091", "name": "Tatsunori Hashimoto"}, {"authorId": "1412355294", "name": "Carlos Guestrin"}], "references": [{"paperId": "98372f2e164a4ae44c390a72a39bd6d7675cae89", "title": "xLSTM: Extended Long Short-Term Memory"}, {"paperId": "157ed5647da39a7f5d33a84a90414b2a9e97e301", "title": "Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence"}, {"paperId": "db7498f569be9852a04b2bb5bd68bd2885820bea", "title": "World Model on Million-Length Video And Language With Blockwise RingAttention"}, {"paperId": "62b18cc55dcc7ffe52c28e1086aee893b7bc4334", "title": "Gated Linear Attention Transformers with Hardware-Efficient Training"}, {"paperId": "7bbc7595196a0606a07506c4fb1473e5e87f6082", "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "c47484e8f718bfb91c32d7eaa598ce11d6e6b3e0", "title": "Test-Time Training on Video Streams"}, {"paperId": "776a9274623d3150cd4811b179bc001a99521bf0", "title": "Test-Time Training on Nearest Neighbors for Large Language Models"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "998ac3e945857cf2676ee7efdbaf443a0c6f820a", "title": "Hyena Hierarchy: Towards Larger Convolutional Language Models"}, {"paperId": "5a77b508302771fc083bf24e0bcda8553c9b5421", "title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models"}, {"paperId": "37ba9c33025fb31f25436010e12c65a0bafc0e1f", "title": "Meta-Learning Fast Weight Language Models"}, {"paperId": "e3fc46d5f4aae2c7a8a86b6bd21ca8db5d40fcbd", "title": "The Devil in Linear Transformer"}, {"paperId": "9bc2c47859d90a26e7f3fcedc1dbfe45d7ec9528", "title": "Test-Time Training with Masked Autoencoders"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "663662fbd9be73f99c764a7b85982bf825acfe8a", "title": "The Dual Form of Neural Networks Revisited: Connecting Test Time Predictions to Training Patterns via Spotlights of Attention"}, {"paperId": "ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51", "title": "Efficiently Modeling Long Sequences with Structured State Spaces"}, {"paperId": "2582a04918f6fe62dc142f2fca9ca0bb0b1d7895", "title": "NormFormer: Improved Transformer Pretraining with Extra Normalization"}, {"paperId": "21299d6e69c017ded9d91f50c09b8cd12ff683e1", "title": "Online Learning of Unknown Dynamics for Model-Based Controllers in Legged Locomotion"}, {"paperId": "86589b6286ef3c55b8b4fccfb41a3b30b7afdf61", "title": "Going Beyond Linear Transformers with Recurrent Fast Weight Programmers"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "76e3ad12881e7ab1c36318d8f8818eca3f828349", "title": "Meta Learning Backpropagation And Improving It"}, {"paperId": "798786f2d7f31b5361d700d3891a72e1096e5c8e", "title": "Self-Supervised Policy Adaptation during Deployment"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c09bc9f1fff9cb4731dc4f83924727fb3cc96e7e", "title": "Consistent video depth estimation"}, {"paperId": "a1b8a8df281bbaec148a897927a49ea47ea31515", "title": "Improved Baselines with Momentum Contrastive Learning"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "10eda4521c032adabaa8e70d6569e17370b29dcd", "title": "Root Mean Square Layer Normalization"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "a436e41141a9d9c5dfc44d16fade67b9a3b76778", "title": "Test-Time Training with Self-Supervision for Generalization under Distribution Shifts"}, {"paperId": "661d142c23cb2a3207d5f1ba2ac7ff61f2d4fb2f", "title": "Triton: an intermediate language and compiler for tiled neural network computations"}, {"paperId": "cd63025532a62fa245a02ec05e32ac4d23089631", "title": "Dynamic Evaluation of Transformer Language Models"}, {"paperId": "b042f9d9a5aa81451abbb252aa45bf74e8fa64cb", "title": "Online Model Distillation for Efficient Video Inference"}, {"paperId": "83040001210751239553269727b9ea53e152af71", "title": "Building Machines that Learn and Think Like People"}, {"paperId": "c6509a450bdda7ca5b8567103dfe9671dbf3b567", "title": "Meta-Learning Update Rules for Unsupervised Representation Learning"}, {"paperId": "7a0feeee49ac7692257fb21041e25511bc45192a", "title": "Zero-Shot Super-Resolution Using Deep Internal Learning"}, {"paperId": "fa9decd1395cc2f39e9921f870ebc8a8ec2bd08d", "title": "Dynamic Evaluation of Neural Sequence Models"}, {"paperId": "c889d6f98e6d79b89c3a6adf8a921f88fa6ba518", "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"}, {"paperId": "0f62e20489b8535e26e8e5f281353d97c394a348", "title": "A tutorial on kernel density estimation and recent advances"}, {"paperId": "c91ae35dbcb6d479580ecd235eabf98374acdb55", "title": "Using Fast Weights to Attend to the Recent Past"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "71683e224ab91617950956b5005ed0439a733a71", "title": "Learning to learn by gradient descent by gradient descent"}, {"paperId": "942deb7d865b7782c03176d95e3a0d56cb71009e", "title": "Training Deep Nets with Sublinear Memory Cost"}, {"paperId": "e2820bffe5b42cb7d88b7f65c12171c62ab4aae2", "title": "Gradient-based Hyperparameter Optimization through Reversible Learning"}, {"paperId": "72e93aa6767ee683de7f001fa72f1314e40a8f35", "title": "Building high-level features using large scale unsupervised learning"}, {"paperId": "30b9de9496492f9a33a20d9a163608a6b6e0ae03", "title": "Online domain adaptation of a pre-trained cascade of classifiers"}, {"paperId": "168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74", "title": "Scikit-learn: Machine Learning in Python"}, {"paperId": "03057ea57d9f2d9bbc8a141d51f76d5bbc715234", "title": "Using fast weights to improve persistent contrastive divergence"}, {"paperId": "843959ffdccf31c6694d135fad07425924f785b1", "title": "Extracting and composing robust features with denoising autoencoders"}, {"paperId": "007e186fd05b41f68b03d1ef0a5a65bebf1d6b83", "title": "Large Scale Transductive SVMs"}, {"paperId": "ceb0e1a86dc35e21ce5f0524c8476f15e1b08988", "title": "SVM-KNN: Discriminative Nearest Neighbor Classification for Visual Category Recognition"}, {"paperId": "8875c5ba38a9e9fbe40fa0314dbe78f2c5dbfc3c", "title": "Weighted Nadaraya\u2013Watson regression estimation"}, {"paperId": "008abebf4a9404db9050c9d2fbca769f4faf3ca6", "title": "Learning by Transduction"}, {"paperId": "3e06c979b01b1c235017495d7d3a2769bb6a81bc", "title": "Learning to Learn: Introduction and Overview"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "1ca97e1668e305fb719845f84a05a62dfb946a5d", "title": "Local Learning Algorithms"}, {"paperId": "bc22e87a26d020215afe91c751e5bdaddd8e4922", "title": "Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks"}, {"paperId": "d130325c41947a41a55a4431e9e8e15be89da8ea", "title": "Learning a synaptic learning rule"}, {"paperId": "98b4d4e24aab57ab4e1124ff8106909050645cfa", "title": "Neural networks and physical systems with emergent collective computational abilities."}, {"paperId": "c3e1d1e0c0835819e170654af9b58bab6e59939c", "title": "Variable Kernel Estimates of Multivariate Densities"}, {"paperId": "5d11aad09f65431b5d3cb1d85328743c9e53ba96", "title": "The perceptron: a probabilistic model for information storage and organization in the brain."}, {"paperId": null, "title": "A method for stochastic optimization"}, {"paperId": null, "title": "Pattern recognition and machine learning , volume 4"}, {"paperId": null, "title": "Learning to classify text using support vector machines , volume 668"}, {"paperId": "8213dbed4db44e113af3ed17d6dad57471a0c048", "title": "The Nature of Statistical Learning Theory"}, {"paperId": "35fbb4104b77b27cb6d7a35a7648b17ebd554a25", "title": "The Nadaraya-Watson Kernel regression function estimator"}, {"paperId": "bdaec1b3eb9a8f7a2b296be009a148c35236f3ce", "title": "Evolutionary principles in self-referential learning, or on learning how to learn: The meta-meta-. hook"}, {"paperId": "7257eacd80458e70c74494eb1b6759b52ff21399", "title": "Using fast weights to deblur old memories"}, {"paperId": null, "title": "Gri ffi"}, {"paperId": null, "title": "Strangely, matrix multiplications on gpus run faster when given \""}, {"paperId": null, "title": "We propose TTT layers, a new class of sequence modeling layers where the hidden state is a model, and the update rule is self-supervised learning"}, {"paperId": null, "title": "TTT-Linear, one simple instantiation of TTT layers, outperforms Transformers and Mamba in our evaluations ranging from 125M to 1.3B parameters"}, {"paperId": null, "title": "You just found out your book was used to train ai"}]}