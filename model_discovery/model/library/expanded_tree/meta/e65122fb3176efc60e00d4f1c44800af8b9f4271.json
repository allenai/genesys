{"paperId": "e65122fb3176efc60e00d4f1c44800af8b9f4271", "abstract": "Deep learning-based language models (LMs) have transcended the gold standard (human baseline) of SQuAD 1.1 and GLUE benchmarks in April and July 2019, respectively. As of 2022, the top five LMs on the SuperGLUE benchmark leaderboard have exceeded the gold standard. Even people with good general knowledge will struggle to solve problems in specialized fields such as medicine and artificial intelligence. Just as humans learn specialized knowledge through bachelor\u2019s, master\u2019s, and doctoral courses, LMs also require a process to develop the ability to understand domain-specific knowledge. Thus, this study proposes SciDeBERTa and SciDeBERTa (CS) as pretrained LMs (PLMs) specialized in the science and technology domain. We further pretrained DeBERTa, which was trained with a general corpus, with the science and technology domain corpus. Experiments verified that SciDeBERTa (CS) continually pretrained in the computer science domain achieved 3.53% and 2.17% higher accuracies than SciBERT and S2ORC-SciBERT, respectively, which are science and technology domain specialized PLMs, in the task of recognizing entity names in the SciERC dataset. In the JRE task of the SciERC dataset, SciDeBERTa (CS) achieved a 6.7% higher performance than the baseline SCIIE. In the GENIA dataset, SciDeBERTa achieved the best performance compared to S2ORC-SciBERT, SciBERT, BERT, DeBERTa and SciDeBERTa (CS). Furthermore, re-initialization technology and optimizers after Adam were explored during fine-tuning to verify the language understanding of PLMs.", "venue": "IEEE Access", "year": 2022, "citationCount": 4, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "SciDeberTa and SciDeBERTa (CS) are proposed as pretrained LMs (PLMs) specialized in the science and technology domain, and re-initialization technology and optimizers after Adam were explored during fine-tuning to verify the language understanding of PLMs."}, "embedding": {"model": "specter_v2", "vector": [-0.03355816379189491, 0.3910738527774811, -0.2896438241004944, 0.21437323093414307, -0.43331190943717957, -0.9822194576263428, 1.2114242315292358, -0.35876432061195374, -0.580021858215332, 0.4084303081035614, 0.41298434138298035, -0.4706692099571228, -0.014284485019743443, 0.005938317161053419, -0.13846220076084137, -0.09724017977714539, -0.4422455132007599, 0.7911131381988525, -0.5987451076507568, 0.12291844934225082, 0.2074430137872696, -0.02602500654757023, -0.5307876467704773, -0.28008151054382324, 0.3012427091598511, 0.4697530269622803, 0.14712312817573547, 0.6770802140235901, -0.7129391431808472, 0.38095709681510925, 0.21689341962337494, -0.5670967102050781, 0.0580006018280983, -0.11603502929210663, -0.9592393636703491, -0.24426670372486115, 0.5029242634773254, -0.27916836738586426, -0.2935885787010193, 0.7255862951278687, -0.18007270991802216, 0.19185148179531097, 0.9972196817398071, -0.254868745803833, -0.35251596570014954, 0.7741429209709167, 0.8128666877746582, 0.6885379552841187, -0.3048919141292572, -0.5127373933792114, 0.9236990213394165, -1.0808496475219727, 0.7219272255897522, 0.6779422163963318, 0.28372177481651306, 0.43560734391212463, 0.2601630985736847, -0.752181351184845, 0.08723845332860947, -0.015601248480379581, -0.7711102366447449, 0.11441364139318466, -0.04495895281434059, -0.5229268074035645, 1.7874819040298462, -0.4045521020889282, -0.2887928783893585, 0.2827291488647461, -0.03084009326994419, 1.1665087938308716, 0.4126606285572052, -0.6518027186393738, -0.34945231676101685, 0.5923105478286743, 0.4740109145641327, 0.5403814911842346, -0.1670588254928589, 0.09285926818847656, -0.5825827717781067, 0.13618941605091095, 0.4327034652233124, -0.4454285800457001, 0.0814044326543808, 0.32871606945991516, -0.5780528783798218, 0.044675979763269424, -0.02522904798388481, 0.9521229267120361, -0.02734343335032463, 0.05408162623643875, 0.24645951390266418, 0.4841671586036682, -0.23701272904872894, 1.1668730974197388, -0.5081620812416077, 0.5162336826324463, -0.8531712889671326, 0.04691581055521965, 0.37462612986564636, 0.9131372570991516, 0.04904983937740326, 0.2597449719905853, -0.9047211408615112, -0.21934190392494202, 0.8602896928787231, -0.1853533685207367, 0.39765429496765137, -0.8300355672836304, 0.3666360676288605, -0.11439350992441177, 0.5403757095336914, -0.46876075863838196, -0.515007495880127, -0.6701567769050598, -0.9339413642883301, -1.2161790132522583, -0.41975390911102295, -0.5708678364753723, -0.748037576675415, 0.4217836558818817, -0.3893561065196991, 0.38182777166366577, 0.3456608057022095, 0.7630431056022644, 1.1761102676391602, 0.42247381806373596, 0.1459018439054489, 0.2914850115776062, 1.0622577667236328, -0.5219510793685913, -0.7929295897483826, -1.1269711256027222, 0.4339262545108795, -0.22338959574699402, -0.20455580949783325, -0.08348342031240463, -1.1448322534561157, -0.5401476621627808, -0.9621827006340027, -0.2962381839752197, -0.8753831386566162, 0.8223257660865784, 0.8598712086677551, 0.21046000719070435, -0.3127996027469635, 0.5930389165878296, 0.3671855926513672, -0.23426741361618042, 0.11060310155153275, 0.286304771900177, 0.42863208055496216, -0.0665784403681755, -1.4026004076004028, 0.8582019209861755, 0.377015084028244, -0.706861138343811, -0.3164941072463989, -0.4163128435611725, -0.5540105104446411, 0.27784663438796997, 0.23381468653678894, -1.130699634552002, 1.1583235263824463, 0.2304442971944809, -1.1746673583984375, 1.0945963859558105, 0.0014464984415099025, -0.02121332287788391, 0.5163134336471558, -0.18324247002601624, -0.5763512849807739, -0.38808906078338623, -0.04422817751765251, 0.26665735244750977, 0.2828291058540344, -0.023191021755337715, -0.1339142918586731, 0.33554548025131226, -0.20605462789535522, -0.15080402791500092, -0.46015670895576477, 0.6050915718078613, -0.5175446271896362, -0.35779938101768494, -0.20887556672096252, 0.5799262523651123, 0.0950922966003418, -0.5736683011054993, -0.5423623323440552, -0.8384497165679932, 0.48533982038497925, -0.0052818479016423225, 0.8419820070266724, -0.4928704500198364, -0.15736235678195953, -0.3486180305480957, -0.15195512771606445, 0.07466372102499008, -0.3080989122390747, 0.09474726766347885, -0.341897577047348, 0.6480163335800171, -0.41301512718200684, -0.6407877802848816, 0.02283986657857895, -0.3445652425289154, -0.5995935797691345, -0.33540078997612, 0.39303746819496155, 1.2261884212493896, -0.5294489860534668, 0.09420117735862732, -0.10111916810274124, 0.27406299114227295, -0.4812886416912079, 0.9798325896263123, -0.48158329725265503, 0.4746444523334503, -0.6212696433067322, -0.20218923687934875, 0.2664361596107483, -0.42975980043411255, 0.37289220094680786, -0.39162498712539673, -0.4993886947631836, 0.6960217952728271, -0.6455481052398682, 1.3108934164047241, -0.28575223684310913, 0.5917834639549255, 0.5085113048553467, -0.5894848704338074, 0.5073709487915039, 0.49202874302864075, 0.07233026623725891, -0.1586197018623352, 0.612674355506897, 0.6187897324562073, -1.1450722217559814, -0.18639838695526123, 0.5821695327758789, 0.6865057349205017, -0.44397491216659546, 0.21739426255226135, 0.7480106353759766, -0.8181354999542236, 0.1967450976371765, 0.4920054078102112, 0.3363257050514221, 0.33410364389419556, 0.23180346190929413, -0.055555712431669235, 0.5756498575210571, -0.24011775851249695, -0.18507738411426544, 0.20186172425746918, 0.9383542537689209, 0.7335208654403687, 0.19010871648788452, -0.3861447274684906, -0.18179020285606384, 0.2517983913421631, 0.3312552571296692, 0.8913306593894958, 0.1532772034406662, 0.028696425259113312, -0.8107675909996033, -0.7035292983055115, -0.326980322599411, 0.18712492287158966, -0.11735466867685318, 0.021220598369836807, -0.6358860731124878, -1.2881606817245483, 0.909846305847168, -0.013317402452230453, 1.4316498041152954, -0.16793331503868103, 0.1259831041097641, -0.5925334692001343, 0.18742014467716217, -0.9159126877784729, -0.5763475298881531, 0.21854686737060547, -0.17657633125782013, -0.11461597681045532, -0.3794223368167877, -0.685512125492096, -0.10992656648159027, -0.638563871383667, 1.120896816253662, -0.7569941878318787, -0.2920112609863281, 0.3031076192855835, 0.8788685202598572, -0.5999283194541931, -0.5147815346717834, 0.45671847462654114, -0.12746506929397583, -0.3529576063156128, 0.4506126642227173, 0.313068687915802, 0.03989126905798912, -0.09390372037887573, -0.5225771069526672, 0.013611489906907082, 0.22590529918670654, 0.17935112118721008, 0.667753279209137, -0.18891413509845734, 0.5100654363632202, -1.1715103387832642, 1.0228015184402466, -0.18091820180416107, -0.6581507325172424, 0.42689064145088196, -0.8166795969009399, 0.007722138427197933, 0.3224238157272339, -0.22579580545425415, -0.8790701031684875, -0.617516040802002, 0.20402741432189941, -0.0003923265903722495, -0.45032596588134766, 0.5693417191505432, 0.41752728819847107, 0.05973535403609276, 0.37726086378097534, 0.16940590739250183, -0.27801668643951416, -0.5669994354248047, 0.5121110677719116, -0.16512379050254822, 0.8644758462905884, 0.2099546194076538, 0.1944519579410553, -0.4143056869506836, 0.15392659604549408, -0.3578733801841736, -0.5726945400238037, -0.33032119274139404, -0.5236260890960693, -0.08147698640823364, 0.3962329030036926, -0.7791514992713928, -0.46788489818573, 0.08788395673036575, -1.0451332330703735, -0.05794724449515343, -0.021556511521339417, 0.06372402608394623, 0.05404152348637581, -0.9165663719177246, -0.8781448006629944, -0.3846499025821686, -1.096588134765625, -0.5599966645240784, 0.5972968339920044, 0.5611395239830017, -0.15090641379356384, -0.48007529973983765, 0.135248601436615, -0.2583053410053253, 0.5839265584945679, -0.30194249749183655, 0.543673574924469, -0.09821495413780212, -0.39681476354599, -0.07529997825622559, -0.05008170008659363, 0.37361443042755127, -0.29037344455718994, 0.0948844850063324, -0.6554454565048218, 0.651985228061676, -0.08825930953025818, -0.19303981959819794, 0.3304024338722229, 0.06147410348057747, 0.43340864777565, 0.16662278771400452, -0.5188810229301453, 0.48672354221343994, 1.1438108682632446, -0.8808856010437012, 0.12255755066871643, 0.5202884078025818, 0.7497372031211853, 0.2516811788082123, -0.20558986067771912, 0.5221073031425476, 0.38405337929725647, 0.20116890966892242, -0.3300352394580841, -0.029781505465507507, -0.48957669734954834, -0.24764607846736908, 0.26051434874534607, 1.1417655944824219, 0.13904252648353577, -0.020990392193198204, -1.0823231935501099, 0.8319840431213379, -0.7540972232818604, -0.38622772693634033, 0.18312543630599976, 0.2803182601928711, 0.7886797189712524, -0.5758237838745117, -0.5989336967468262, -0.3498936891555786, 0.29168203473091125, -0.07245288789272308, -0.5608978271484375, -0.39076709747314453, -0.16654638946056366, 0.5424088835716248, 0.5203670263290405, 0.32899272441864014, -0.49374550580978394, 0.5841167569160461, 15.270862579345703, 0.7220661640167236, -0.007446741219609976, 0.22763371467590332, 0.44145625829696655, 0.31885015964508057, -0.2363724410533905, -0.513862669467926, -1.2903685569763184, -0.43206384778022766, 1.0605840682983398, -0.20477056503295898, 0.5300439596176147, 0.1371203362941742, -0.3507651090621948, 0.4204128384590149, -0.39399656653404236, 0.6442078351974487, 0.24258732795715332, -1.6207849979400635, 0.005426078103482723, 0.18914999067783356, 0.8943140506744385, 0.7784660458564758, 0.8393190503120422, 0.7576732635498047, 0.5936468243598938, -0.3141620457172394, 0.4779382348060608, 0.5347573757171631, 0.6838192343711853, 0.13421335816383362, 0.5408402681350708, 0.732865571975708, -0.481151819229126, -0.14824606478214264, -0.3699251115322113, -0.5450357794761658, -0.16834217309951782, 0.35341769456863403, -0.8087202310562134, -0.07273442298173904, -0.2691632807254791, 0.7468684315681458, 0.3511182963848114, 0.6427088379859924, -0.6537134051322937, 0.5889703631401062, 0.19196997582912445, 0.04609113559126854, 0.18820250034332275, 0.1297953873872757, 0.6089516878128052, 0.5507200956344604, 0.1822858452796936, 0.2770836353302002, -0.26903867721557617, 0.811758279800415, -1.289788842201233, -0.27443087100982666, -0.26764678955078125, -0.358051061630249, 0.02157682180404663, 1.1411502361297607, 0.48412811756134033, 0.14586609601974487, -0.24354828894138336, 0.28107985854148865, 0.16950121521949768, 0.3443891704082489, 0.18548168241977692, -0.7252557277679443, 0.3283679485321045, -0.3814132511615753, -0.25578001141548157, 0.10615463554859161, -0.8698346018791199, -0.7744618058204651, -0.8003219366073608, -0.3046640455722809, 0.5473384857177734, -0.734541118144989, -0.9427805542945862, 0.851054310798645, -0.4919475018978119, -0.6694936752319336, -0.10795547068119049, -1.063056468963623, 0.07471860945224762, 0.9329155683517456, -1.7220699787139893, -0.49928218126296997, 0.23427630960941315, -0.3811803460121155, -0.5925081372261047, -0.30781683325767517, 1.1315590143203735, 0.11464858800172806, -0.34876948595046997, -0.24047428369522095, 0.6278839111328125, 0.2846504747867584, 0.2599228620529175, -0.9221126437187195, 0.6337109208106995, -0.20765173435211182, -0.20031246542930603, 0.16606484353542328, -0.2012079656124115, -0.028614697977900505, -1.0068565607070923, -0.17315338551998138, 0.6460273861885071, -1.2359927892684937, -0.2879093885421753, -0.45447689294815063, -0.6984307169914246, 0.3017657399177551, 0.827754557132721, -0.8459310531616211, 0.011650409549474716, -0.02565496228635311, -0.3422546982765198, 0.17293760180473328, -1.4233285188674927, -0.2668701410293579, 0.41755571961402893, -0.9341166019439697, -0.5848963260650635, 0.28150850534439087, 0.26255902647972107, -0.9445982575416565, -0.9972913861274719, 0.028416572138667107, -0.05822069197893143, 0.5987889170646667, 1.2083306312561035, -0.4802507162094116, 0.6737151145935059, 0.7400543689727783, 0.3239074945449829, -0.7263989448547363, -0.0329255685210228, -0.603691816329956, -0.1494968831539154, 0.19798751175403595, 0.9231621026992798, -0.3396182656288147, 0.0458369180560112, 1.3079304695129395, 0.25116121768951416, -0.07640139013528824, -0.13858169317245483, -0.5274738073348999, 0.7197692394256592, -0.007415675092488527, 0.5194799900054932, 0.5156968235969543, 0.045199476182460785, 0.3881992995738983, 0.5966162085533142, 0.7004320025444031, -0.33152467012405396, 0.05234210565686226, 0.016575787216424942, -0.4114750623703003, -0.12303110957145691, -0.8187176585197449, -0.033106762915849686, -1.4183684587478638, 0.02304685302078724, -1.4595743417739868, -0.19095534086227417, -1.0629873275756836, -0.4138947129249573, 0.28772008419036865, -0.17240849137306213, 0.10574937611818314, 0.36524805426597595, -0.3289935886859894, -0.7867699861526489, -0.38886046409606934, -0.1938200145959854, 0.4104073941707611, 1.0880922079086304, -0.9520536661148071, -0.0252164825797081, -0.2481006681919098, -0.338992178440094, 0.3628910779953003, 0.4811208248138428, -0.3346763849258423, -0.2902916669845581, -1.4725359678268433, 0.22276319563388824, -0.020307671278715134, -0.24803246557712555, -0.4194284975528717, 1.0063457489013672, 0.4076783359050751, -0.04629345238208771, 0.010973744094371796, 0.02584434114396572, -0.5339555740356445, -0.3477167785167694, -0.3062880039215088, -0.8146991729736328, -0.41271111369132996, 0.44465315341949463, -1.0288445949554443, -0.1425199806690216, 0.0954543724656105, -0.22893691062927246, -0.8884425759315491, -0.41811010241508484, 0.03409493714570999, -0.71064692735672, 0.10829345136880875, -0.2984926402568817, 0.16928069293498993, -1.1033576726913452, -0.10326068103313446, -0.14526404440402985, 0.5793842673301697, -0.5911181569099426, 0.6360726356506348, -0.16365055739879608, -0.8080524802207947, -0.17715232074260712, -0.22965964674949646, -0.5475648641586304, -0.021881109103560448, 0.08050365746021271, 0.2688661813735962, -0.12432226538658142, 0.7684969902038574, 0.30012375116348267, 0.7302421927452087, -0.49328768253326416, -0.2281319797039032, 0.7684304118156433, -0.5310099124908447, -0.09621027857065201, 0.8999332189559937, -0.3515939712524414, -0.9379528760910034, 0.18155674636363983, -0.8877220749855042, -0.8231894373893738, -0.09667215496301651, 0.571912407875061, 0.07015997171401978, 0.2775501310825348, -0.022519363090395927, -0.4309055507183075, 0.46880215406417847, 0.09120997786521912, -0.5855535268783569, 1.1029959917068481, -0.03267261013388634, -0.27346178889274597, 0.058571621775627136, 0.7730375528335571, -0.5683339834213257, -0.1548379361629486, -0.7102116346359253, 0.05424121767282486, 0.24951650202274323, 0.7437437772750854, -1.1925771236419678, -0.7213795781135559, 0.5950533151626587, 0.3197331428527832, 0.14759722352027893, 0.43276798725128174, -0.060332514345645905, 0.19206464290618896, 0.9430730938911438, 0.01053064875304699, -0.5075722932815552, -0.8971859216690063, 1.2498576641082764, 1.4207223653793335, -1.0168123245239258, 0.5012015104293823, -0.12099727243185043, -0.7062538266181946, 0.9327319860458374, 0.08103734999895096, 0.2478456050157547, 1.005305290222168, 0.02035144716501236, -0.38569262623786926, -0.15911266207695007, -0.462271511554718, -0.54427570104599, 1.0413744449615479, 0.8349058032035828, 0.7069884538650513, 0.2481565773487091, -0.17677830159664154, 1.4559478759765625, 0.015659451484680176, 0.4841727018356323, 0.4247804582118988, 0.41132012009620667, -0.0407981351017952, -0.35808679461479187, -0.32380637526512146, 0.4233053922653198, -0.7547034621238708, -0.2935589551925659, -1.0200363397598267, 0.48269888758659363, 0.16871564090251923, 0.3612230718135834, 0.35494011640548706, -0.07464990019798279, 0.590126633644104, 0.3345145285129547, 0.26634228229522705, -0.2567065358161926, -0.908419132232666, -0.3817995488643646, -0.12660840153694153, 0.47727054357528687, -0.415706068277359, -0.7877469658851624, -0.7436978220939636, -0.10661382228136063, 0.2413819581270218, 0.3076556324958801, 0.7573217749595642, 1.0795483589172363, 0.9908118844032288, 0.3603084981441498, -0.5688050985336304, -0.1422901749610901, 0.06762920320034027, -1.043145775794983, 0.2166052609682083, -0.7771483063697815, -0.17757359147071838, -0.24241238832473755, -0.05308977887034416, -0.12750118970870972]}, "authors": [{"authorId": "2105577225", "name": "Yuna Jeong"}, {"authorId": "2084828", "name": "Eunhui Kim"}], "references": [{"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "c2a79e2a65b721d4de5f6d4806323174b9f8f393", "title": "Towards Zero-Label Language Learning"}, {"paperId": "319b84be7a843250bc81d7086f79a4126d550277", "title": "ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation"}, {"paperId": "d8d2e574965fe733eb1416e03df2b5c2914fc530", "title": "A Survey of Transformers"}, {"paperId": "19537be34dbadbcaa4fffcf028a8ada5095b1b5c", "title": "COCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "3efbcfeeb0ea1051a71101d3318da4411081f0b8", "title": "Scaling Laws for Autoregressive Generative Modeling"}, {"paperId": "8af3de56807c32172b06982cf785c9c8b14d117a", "title": "TweetBERT: A Pretrained Language Representation Model for Twitter Text Analysis"}, {"paperId": "a2f38d03fd363e920494ad65a5f0ad8bd18cd60b", "title": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing"}, {"paperId": "e11e8d81c68cc782f564ed78e595b66790719804", "title": "AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights"}, {"paperId": "056935031bc5cf0aeeaa0946320de26e14a1817e", "title": "Revisiting Few-sample BERT Fine-tuning"}, {"paperId": "8b9d77d5e52a70af37451d3db3d32781b83ea054", "title": "On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "8d908042f139575d6688c745e94156c9df6eae07", "title": "Understanding the Difficulty of Training Transformers"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "347e837b1aa03c9d17c69a522929000f0a0f0a51", "title": "SuperGlue: Learning Feature Matching With Graph Neural Networks"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "be283fc67ecbfe0cb1e50718181ce7b9c0d53a74", "title": "How Does BERT Answer Questions?: A Layer-Wise Analysis of Transformer Representations"}, {"paperId": "fac2368c2ec81ef82fd168d49a0def2f8d1ec7d8", "title": "Entity, Relation, and Event Extraction with Contextualized Span Representations"}, {"paperId": "7102bb3fe73bd057ff161d9db5214a267c1ef312", "title": "FinBERT: Financial Sentiment Analysis with Pre-trained Language Models"}, {"paperId": "2bf7c350a8280e7c593d46a60127f99b21517121", "title": "On the Variance of the Adaptive Learning Rate and Beyond"}, {"paperId": "d56c1fc337fb07ec004dc846f80582c327af717c", "title": "StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding"}, {"paperId": "80f9f109d1564cb8f82aa440a5f6f3fbe220c9ef", "title": "ERNIE 2.0: A Continual Pre-training Framework for Language Understanding"}, {"paperId": "81f5810fbbab9b7203b9556f4ce3c741875407bc", "title": "SpanBERT: Improving Pre-training by Representing and Predicting Spans"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "156d217b0a911af97fa1b5a71dc909ccef7a8028", "title": "SciBERT: A Pretrained Language Model for Scientific Text"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "b21b927c251c415b601b6d7f785a42cc5c292635", "title": "Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "0e1c784f42a60646df8c068a667627a250e772be", "title": "The ACL RD-TEC 2.0"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "da6c3fdf8ef9aae979a5dd156e074ba6691b2e2c", "title": "GENIA corpus - a semantically annotated corpus for bio-textmining"}, {"paperId": "5c5751d45e298cea054f32b392c12c61027d2fe7", "title": "S2ORC: The Semantic Scholar Open Research Corpus"}, {"paperId": null, "title": "\u201cLEGAL-BERT: The muppets straight out of law school,\u201d"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "f0b13f773d089ae43693036c5836eb2e18ece9b4", "title": "Repository Citation This Work Is Licensed under a Creative Commons Attribution 4.0 License"}]}