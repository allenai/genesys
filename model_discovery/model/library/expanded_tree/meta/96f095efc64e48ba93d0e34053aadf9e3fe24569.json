{"paperId": "96f095efc64e48ba93d0e34053aadf9e3fe24569", "abstract": "The large number of parameters in Pretrained Language Models enhance their performance, but also make them resource-intensive, making it challenging to deploy them on commodity hardware like a single GPU. Due to the memory and power limitations of these devices, model compression techniques are often used to decrease both the model's size and its inference latency. This usually results in a trade-off between model accuracy and efficiency. Therefore, optimizing this balance is essential for effectively deploying LLMs on commodity hardware. A significant portion of the efficiency challenge is the Feed-forward network (FFN) component, which accounts for roughly $\\frac{2}{3}$ total parameters and inference latency. In this paper, we first observe that only a few neurons of FFN module have large output norm for any input tokens, a.k.a. heavy hitters, while the others are sparsely triggered by different tokens. Based on this observation, we explicitly split the FFN into two parts according to the heavy hitters. We improve the efficiency-accuracy trade-off of existing compression methods by allocating more resource to FFN parts with heavy hitters. In practice, our method can reduce model size by 43.1\\% and bring $1.25\\sim1.56\\times$ wall clock time speedup on different hardware with negligible accuracy drop.", "venue": "arXiv.org", "year": 2024, "citationCount": 3, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper improves the efficiency-accuracy trade-off of existing compression methods by allocating more resource to FFN parts with heavy hitters, and can reduce model size by 43.1% and bring wall clock time speedup on different hardware with negligible accuracy drop."}, "embedding": {"model": "specter_v2", "vector": [0.21653041243553162, 0.2769322395324707, -0.7561039924621582, -0.3703494668006897, -0.019202278926968575, 0.14547690749168396, 0.5428950786590576, -0.2485034018754959, -0.7995138168334961, -0.3259544372558594, 0.48333102464675903, 0.12209481745958328, 0.5013895034790039, -0.06191432103514671, -0.3704175353050232, 0.3387511372566223, -0.6052371859550476, 0.41518446803092957, -0.0797244980931282, -0.16524125635623932, 0.1027403399348259, -0.4395277500152588, -1.2149624824523926, -0.0033115411642938852, 0.3874243497848511, 0.7740122675895691, 0.3830745816230774, 0.937953770160675, -0.9404698014259338, 0.2773951292037964, 0.7060375809669495, -0.2974857687950134, -0.010504425503313541, 0.047581400722265244, -0.19488485157489777, -0.352687805891037, 0.09559088200330734, -0.5316775441169739, -0.5188117623329163, 0.9217958450317383, -0.36813604831695557, 0.4194529056549072, 0.44662219285964966, -0.6173974871635437, -0.012226802296936512, 0.855305016040802, 0.36365774273872375, 0.711570680141449, -0.5168692469596863, -0.4239354133605957, 0.842617392539978, -1.437793493270874, 0.08709058165550232, 1.533394694328308, 0.5166162252426147, 0.3912034332752228, -0.16624952852725983, -0.556736171245575, 0.6445760130882263, -0.12677815556526184, -0.6961110234260559, -0.6014173626899719, -0.21753600239753723, 0.13493762910366058, 2.2035622596740723, -0.05918304994702339, 0.10727185010910034, 0.5760450959205627, -0.4114089012145996, 1.4085334539413452, -0.3006743788719177, -0.7664254903793335, -0.13735513389110565, -0.0801100954413414, 0.3434187173843384, 0.9150840640068054, -0.18553005158901215, 0.13194294273853302, -1.1135730743408203, 0.12450848519802094, 0.6535205245018005, 0.13495129346847534, 0.45690450072288513, 0.35022762417793274, 0.11309245228767395, 0.956606388092041, 0.3917708098888397, 0.7075054049491882, 0.038323838263750076, 0.944282591342926, 0.6957792043685913, 0.029421286657452583, 0.08974709361791611, 0.10033123940229416, -0.018637632951140404, 0.16018922626972198, -1.2299479246139526, 0.158001109957695, 0.08119122684001923, 0.6328656077384949, -0.2738396227359772, 0.6393446922302246, -0.4774567484855652, 0.42189323902130127, 1.408328890800476, 0.16376182436943054, 0.6481444835662842, -0.8089063167572021, 0.46693262457847595, -0.8497320413589478, -0.2597457468509674, -0.44146081805229187, 0.021548667922616005, -0.37587863206863403, -1.0657768249511719, -1.312140703201294, -0.7700419425964355, 0.1944435089826584, -0.8942352533340454, 0.7053953409194946, -0.6382946372032166, 0.567793071269989, -0.275325208902359, 0.39661017060279846, 0.4103919565677643, 0.9275016784667969, 0.3440294563770294, 0.09112844616174698, 0.9543481469154358, -1.4054070711135864, -0.6672274470329285, -1.3546054363250732, 0.4024316370487213, -0.42056795954704285, 0.3608795404434204, -0.3827584683895111, -1.3719691038131714, -0.9988499879837036, -0.7218526601791382, -0.12714305520057678, -0.39907413721084595, 0.34659770131111145, 1.1617848873138428, -0.025257928296923637, -0.8871464133262634, 0.9368834495544434, -0.5209282636642456, -0.021612200886011124, 0.5547835826873779, 0.45716428756713867, 0.35662341117858887, -0.15453653037548065, -1.3649425506591797, 0.04610215872526169, 0.25517186522483826, -0.43347087502479553, 0.30333465337753296, -0.549519956111908, -1.0924392938613892, 0.5142713189125061, 0.16875430941581726, -0.613411009311676, 1.3702635765075684, -0.07963155955076218, -1.2470059394836426, 0.5970628261566162, -0.5578173398971558, -0.22593393921852112, 0.04005249962210655, -0.24544015526771545, -0.558096170425415, -0.31737181544303894, -0.5557125210762024, 0.8022568225860596, 0.5811895728111267, 0.09640861302614212, -0.1555079221725464, 0.49899569153785706, -0.5793842673301697, 0.07303474098443985, -0.3771708309650421, 1.1390804052352905, -0.809312641620636, -0.24318277835845947, 0.4575497508049011, 0.6506027579307556, -0.06478913873434067, -0.11493974924087524, -0.5128013491630554, -0.9261438846588135, 0.6318051815032959, 0.048031892627477646, 1.2182945013046265, -0.839259684085846, -1.1954504251480103, 0.025870295241475105, -0.16498474776744843, 0.13674530386924744, -0.6179866194725037, 0.4239725172519684, -0.06513164937496185, 0.5016058683395386, -0.0511949248611927, -1.344840168952942, 0.2958647310733795, -0.09433285892009735, -0.9246624112129211, -0.4312877058982849, 0.20208513736724854, 0.8789538741111755, -0.5906109809875488, -0.15949127078056335, -0.09058219939470291, 0.7089573740959167, -1.2388771772384644, 1.0704070329666138, -0.4930688738822937, -0.41455960273742676, -0.028358325362205505, -0.367444783449173, 0.3399561643600464, -0.3633427321910858, 0.1883387714624405, -0.40434566140174866, -0.20696894824504852, 0.7260128855705261, -0.3061408996582031, 1.274255633354187, -0.4783712923526764, 0.5296726822853088, -0.24749413132667542, -0.3886929154396057, 0.16991321742534637, 0.13525323569774628, -0.4406155049800873, -0.3256274163722992, 0.28519150614738464, 0.7287486791610718, -0.5004039406776428, 0.3259100019931793, 1.0519827604293823, 0.8908856511116028, -0.3848661780357361, 0.221584290266037, 0.606399416923523, -0.1445493847131729, 0.6727641820907593, 0.44138386845588684, 0.2634109854698181, 0.15316811203956604, 0.11220428347587585, 0.2204129993915558, 0.35851073265075684, -1.1075751781463623, -0.2122536301612854, 0.6528670191764832, 0.7422526478767395, 0.996863067150116, 0.29440838098526, -0.7255122065544128, -0.11458870768547058, 0.11678797006607056, 0.6136459708213806, 1.534177303314209, -0.4199194312095642, 0.016130683943629265, -0.7946184277534485, -8.071533375186846e-05, -0.23122940957546234, -0.08756542205810547, -0.06640186160802841, -0.1525724083185196, -0.5980514287948608, -1.0593817234039307, 1.1776957511901855, 0.28233006596565247, 1.1520709991455078, -0.7593125104904175, -0.23920242488384247, -0.350517213344574, 0.22217774391174316, -0.8443861603736877, -0.7041880488395691, 0.6000055074691772, -0.7193849086761475, 0.2882782220840454, 0.42791277170181274, 0.02025340497493744, 0.09105917811393738, -0.8077898621559143, 0.736271858215332, -0.3061778247356415, -0.2371130734682083, -0.4978252947330475, 1.0097407102584839, -0.40324628353118896, -0.6709460020065308, 0.4913792312145233, 0.1663031131029129, -0.25218698382377625, 0.4856610894203186, 0.516082227230072, -0.1049247682094574, -0.36090612411499023, -0.2991622984409332, 0.16502568125724792, -0.03267008811235428, -0.27307143807411194, 0.866396963596344, -0.5505110025405884, -0.10116282105445862, -1.311714768409729, 0.8794145584106445, 0.005409781355410814, -0.3017745912075043, 0.035139065235853195, -0.8130722045898438, 0.051203351467847824, 0.6759061217308044, -0.47601547837257385, -0.34402480721473694, -0.8284586071968079, -0.08841273188591003, -0.6157108545303345, -0.11101759225130081, 0.3949025273323059, 0.7702568173408508, 0.10468452423810959, -0.11109266430139542, 0.6049041152000427, 0.34671300649642944, -0.4418830871582031, 0.20750173926353455, -0.7959778308868408, 0.931828498840332, 0.42184191942214966, 0.007528799585998058, -0.29001203179359436, -0.17558816075325012, -0.49585506319999695, -0.23763594031333923, -0.4513019621372223, 0.19822153449058533, 0.056098803877830505, -0.22909554839134216, -0.5420572757720947, -0.7912369966506958, -0.2272365689277649, -0.9973717331886292, -0.008260020054876804, 0.1477024257183075, -0.01579427532851696, -0.33960434794425964, -1.1772159337997437, -1.7301799058914185, -0.7211769223213196, -0.8811977505683899, -0.9739491939544678, 0.2897357642650604, 0.253719687461853, -0.2475833296775818, -0.5464461445808411, -0.19864438474178314, -0.6847736239433289, 1.413572907447815, -0.8551065921783447, 0.7805831432342529, -0.06607430428266525, 0.09857336431741714, -0.3344746232032776, -0.08882725238800049, 0.39562246203422546, -0.48907822370529175, 0.5664647817611694, -1.2807178497314453, 0.5541627407073975, -0.24672609567642212, -0.18390801548957825, 0.7713760733604431, 0.5363073945045471, 1.023893117904663, -0.24264422059059143, -0.5998525619506836, 0.6777445077896118, 1.5214385986328125, -0.9296535849571228, 0.2916078269481659, -0.24477577209472656, 0.7633215188980103, -0.34018537402153015, -0.5774039626121521, 0.6207007169723511, -0.06650544703006744, 0.45821720361709595, 0.0057456172071397305, -0.2782248258590698, -0.3306639492511749, -0.7755425572395325, 0.4493238925933838, 2.1010348796844482, 0.3603348433971405, -0.31704652309417725, -0.6886934041976929, 0.10188411176204681, -1.2769943475723267, -0.7809229493141174, 0.49021029472351074, 0.7950156927108765, 0.5449813008308411, -0.016434358432888985, -0.2462279200553894, 0.03454668074846268, 0.5359364151954651, 0.5186923742294312, -0.3431640863418579, -1.2040847539901733, -0.042737964540719986, 0.3705466091632843, 0.30954238772392273, 0.767417848110199, -0.38846975564956665, 0.5855898261070251, 14.551162719726562, 1.1098140478134155, -0.4454294741153717, 0.3456172049045563, 0.9718484878540039, 0.12065989524126053, -0.14012880623340607, -0.5550668835639954, -1.5590249300003052, 0.15182410180568695, 1.64658522605896, 0.20249973237514496, 0.7503069639205933, 0.19101908802986145, 0.2847614884376526, 0.26840725541114807, -0.19792847335338593, 0.9643338918685913, 0.39295893907546997, -1.5064877271652222, 0.27525794506073, -0.17391228675842285, 0.0282417181879282, 0.7962431311607361, 0.8754632472991943, 0.9492188692092896, 0.19150623679161072, -0.6590571999549866, 0.3931363821029663, 0.45358309149742126, 0.9723960161209106, -0.08500832319259644, 0.3612116277217865, 0.6126648187637329, -0.9359650611877441, 0.06419988721609116, -0.6659848690032959, -1.3666062355041504, 0.138090580701828, 0.24215182662010193, -0.4694167375564575, -0.7430039048194885, -0.45908433198928833, 0.7071906328201294, 0.0979553684592247, 0.5612247586250305, 0.06688332557678223, 0.8748948574066162, -0.5775557160377502, 0.05192381143569946, 0.3487457036972046, 0.3826133608818054, -0.07044526189565659, 0.3257412612438202, 0.16005125641822815, -0.38825514912605286, 0.029823672026395798, 0.7675753831863403, -0.8737087249755859, -0.2869340181350708, -0.016991078853607178, -0.3115818500518799, 0.038171812891960144, 0.8224328756332397, 0.24546906352043152, 0.3164333701133728, -0.4179893136024475, 0.25462138652801514, 0.7554974555969238, 0.39569488167762756, -0.4495737850666046, 0.1432437151670456, 0.3882715404033661, -0.26907265186309814, 0.07648306339979172, 0.6526405811309814, -0.4087025821208954, -0.5493096709251404, -0.800072968006134, -0.13434118032455444, 0.1677045077085495, -0.6104608774185181, -0.5951276421546936, 0.750709593296051, -0.2348649501800537, 0.014788161963224411, -0.06599775701761246, -0.5063832998275757, -0.2953626215457916, 0.39201846718788147, -1.6295597553253174, -0.3201039433479309, 0.6416901350021362, -0.44258540868759155, -0.26430633664131165, 0.13889670372009277, 1.3756812810897827, 0.49045616388320923, -0.5391884446144104, 0.23760831356048584, 0.0042093675583601, -0.1269219070672989, -0.42469140887260437, -0.4188271760940552, 1.1151154041290283, 0.378283828496933, 0.028335358947515488, 0.35233181715011597, -0.07889700680971146, 0.29379379749298096, -0.790876567363739, -0.4521688222885132, 1.1211401224136353, -0.10138631612062454, -0.5218642354011536, -0.8320249319076538, -0.7382349371910095, 0.2653835415840149, 0.2635093033313751, 0.1590113341808319, 0.19209696352481842, 0.0858980119228363, -0.6662443280220032, -0.03492331877350807, -0.8132632374763489, -0.026426244527101517, 0.4028622806072235, -0.8004589080810547, 0.3340771496295929, -0.18958967924118042, 0.2683006823062897, -0.9930115938186646, -0.1952349841594696, -0.2990734577178955, 0.09398341923952103, -4.5960594434291124e-05, 1.134060263633728, -0.48706984519958496, 1.0831478834152222, 1.0522483587265015, -0.2750532031059265, -0.5131869316101074, 0.10753334313631058, -0.6187072992324829, -0.4513263702392578, -0.023929445073008537, 0.8055516481399536, -0.3863334655761719, 0.43183621764183044, 0.9030963182449341, 0.19157499074935913, -0.6150760650634766, -0.5499981045722961, -0.41399744153022766, -0.26748213171958923, -0.6357883810997009, 0.31605100631713867, -0.26448243856430054, -0.09917380660772324, 0.06369899213314056, 0.45807191729545593, 0.04349324107170105, -0.4548811912536621, -0.6551020741462708, -0.21212968230247498, -0.004892165306955576, -0.2659878432750702, -0.6213868856430054, -0.19465422630310059, -1.3717994689941406, 0.06410959362983704, -1.179256558418274, -0.005474812351167202, -0.6779229640960693, -0.26787081360816956, -0.18277084827423096, -0.24016399681568146, 0.11927177757024765, 0.37341049313545227, 0.04412715137004852, -0.26469171047210693, -0.368141770362854, -0.49288877844810486, 0.7147517204284668, 0.6048921942710876, -0.3508349657058716, 7.216159247036558e-06, 0.06454598158597946, 0.24933002889156342, 0.6015771627426147, 0.5118888020515442, -0.3186495900154114, -0.7433011531829834, -1.5406007766723633, 0.4346889853477478, -0.0699501484632492, -0.19255448877811432, -0.6911405324935913, 0.933906614780426, 0.272792786359787, -0.1717301905155182, 0.16175933182239532, 0.5371705889701843, -0.8544675707817078, -0.4460396468639374, 0.7016560435295105, -0.8549379110336304, 0.20446372032165527, 0.32729557156562805, -0.7186324596405029, -0.545503556728363, 0.318181574344635, 0.021796783432364464, -0.7304671406745911, -0.7630656957626343, 0.5712530016899109, -0.2854894697666168, 0.3607582449913025, -0.8998015522956848, 0.06767414510250092, -1.2022902965545654, -0.34270015358924866, 0.10666859149932861, -0.2429499328136444, -0.7713598608970642, 0.6751704812049866, 0.7507851123809814, -1.2860885858535767, 0.18038040399551392, 0.8404452204704285, -0.49155691266059875, -0.12664097547531128, 0.3389584720134735, 0.48377326130867004, -0.625269889831543, 0.6647623777389526, 0.42772001028060913, 0.26339712738990784, -0.752636730670929, -0.23808354139328003, 0.8130887746810913, -0.6488120555877686, -0.23874206840991974, 1.1910511255264282, -0.6431781649589539, -0.8844044804573059, 0.17989826202392578, -1.5977680683135986, -0.28348052501678467, -0.4597918391227722, 0.6442396640777588, 0.12324235588312149, 0.2588810324668884, -0.02802799455821514, -0.47051966190338135, -0.016149871051311493, -0.10547101497650146, -0.56747967004776, 0.45181721448898315, 0.01520634163171053, -0.15850912034511566, 0.4488166272640228, 1.1960850954055786, -0.7542836666107178, -0.6331396102905273, -0.6802717447280884, -0.5308513045310974, -0.29353848099708557, 0.5362203121185303, -0.28100302815437317, -1.0504937171936035, 0.8246114253997803, 0.262346476316452, 0.16250304877758026, 0.13779018819332123, -0.508766770362854, 0.550135612487793, 0.4096030592918396, -0.10419128090143204, -0.7383742332458496, -0.7313798069953918, 1.590168833732605, 1.0896812677383423, -0.7375807762145996, 0.10948973894119263, -0.7562497854232788, -0.4650357663631439, 0.6797699332237244, 0.2485727220773697, -0.3572438657283783, 0.9995319843292236, 0.34700143337249756, -0.3625764846801758, 0.3746214807033539, -1.1379045248031616, -0.22763463854789734, 0.49588170647621155, 0.5380237102508545, 0.8677617907524109, 0.24767786264419556, 0.0650068074464798, 1.1221139430999756, 0.046979065984487534, 0.33787184953689575, 0.23823906481266022, 0.19647188484668732, -0.35304906964302063, 0.16287201642990112, 0.04904918745160103, 1.103151559829712, -0.6153860688209534, -0.9919055700302124, 0.5383177995681763, 0.5689706206321716, 0.19453157484531403, 0.34099283814430237, 1.070813775062561, 0.03676251694560051, 0.32538461685180664, 0.34406694769859314, 0.5849705338478088, -0.26717597246170044, -0.6039674282073975, 0.15367086231708527, -0.7649611234664917, 0.03611985966563225, 0.21194645762443542, -0.3666706383228302, -0.845596194267273, -0.5818187594413757, 0.5679360032081604, -0.2328566014766693, 0.6393855810165405, 0.9790602922439575, 0.45406439900398254, 0.5350270867347717, -0.34018632769584656, -0.5332897305488586, -0.3296520709991455, -0.8890635371208191, -0.16319850087165833, -0.306688517332077, -0.3831159472465515, 0.08641628175973892, -0.19090880453586578, -0.3346557021141052]}, "authors": [{"authorId": "47781070", "name": "Zirui Liu"}, {"authorId": "25274194", "name": "Qingquan Song"}, {"authorId": "2278429911", "name": "Q. Xiao"}, {"authorId": "2229563519", "name": "Sathiya Keerthi Selvaraj"}, {"authorId": "2237807462", "name": "Rahul Mazumder"}, {"authorId": "2278545430", "name": "Aman Gupta"}, {"authorId": "2282544390", "name": "Xia Hu"}], "references": [{"paperId": "95240dda409e28acccdc5cf619ad0c036cf4292d", "title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "86bb2a8cf04991a99a21dc7462a861214002d805", "title": "InRank: Incremental Low-Rank Learning"}, {"paperId": "db9507cdd3e2d7d9c90ed185bd831e55c62dcec9", "title": "AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration"}, {"paperId": "6d31db7c53853de62cacec26facdb4300d6b5092", "title": "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model"}, {"paperId": "5f187af087ebbaf1ce4bca686a4b1c2afee92b6d", "title": "Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt"}, {"paperId": "42a14d824caa3348046eb34c37e2ab7985faa7a3", "title": "High-throughput Generative Inference of Large Language Models with a Single GPU"}, {"paperId": "909ad57ce8caa6b390a65ae09db352d27d8f3996", "title": "SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot"}, {"paperId": "2c994fadbb84fb960d8306ee138dbeef41a5b323", "title": "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models"}, {"paperId": "7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6", "title": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers"}, {"paperId": "e0271cb75087ccfd4a8c3351e0f5189a6de04c03", "title": "The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers"}, {"paperId": "4be7d1524edb0137599a5cc95f72844b85a52fe1", "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "9e82736043eebe3f71eb86cbef6e2ac45306ece5", "title": "Structured Pruning Learns Compact and Accurate Models"}, {"paperId": "fb145e1e49d3269d8223c7710e22b45438613ff0", "title": "A Fast Post-Training Pruning Framework for Transformers"}, {"paperId": "b4d207a2096aee4a3764933373eef6edb574c952", "title": "Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N: M Transposable Masks"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "0c0dfe47afcec2e229015f3c8f213d4c88e86b28", "title": "Up or Down? Adaptive Rounding for Post-Training Quantization"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "1717255b6aea01fe956cef998abbc3c399b5d7cf", "title": "AMC: AutoML for Model Compression and Acceleration on Mobile Devices"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "d79b9042fe9c30027d49fdd6fe24e737b720af6b", "title": "DRONE: Data-aware Low-rank Compression for Large NLP Models"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}]}