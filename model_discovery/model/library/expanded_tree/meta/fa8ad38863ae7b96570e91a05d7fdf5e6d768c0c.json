{"paperId": "fa8ad38863ae7b96570e91a05d7fdf5e6d768c0c", "abstract": "Text-to-image generation (TTI) refers to the usage of models that could process text input and generate high fidelity images based on text descriptions. Text-to-image generation using neural networks could be traced back to the emergence of Generative Adversial Network (GAN), followed by the autoregressive Transformer. Diffusion models are one prominent type of generative model used for the generation of images through the systematic introduction of noises with repeating steps. As an effect of the impressive results of diffusion models on image synthesis, it has been cemented as the major image decoder used by text-to-image models and brought text-to-image generation to the forefront of machine-learning (ML) research. In the era of large models, scaling up model size and the integration with large language models have further improved the performance of TTI models, resulting the generation result nearly indistinguishable from real-world images, revolutionizing the way we retrieval images. Our explorative study has incentivised us to think that there are further ways of scaling text-to-image models with the combination of innovative model architectures and prediction enhancement techniques. We have divided the work of this survey into five main sections wherein we detail the frameworks of major literature in order to delve into the different types of text-to-image generation methods. Following this we provide a detailed comparison and critique of these methods and offer possible pathways of improvement for future work. In the future work, we argue that TTI development could yield impressive productivity improvements for creation, particularly in the context of the AIGC era, and could be extended to more complex tasks such as video generation and 3D generation.", "venue": "arXiv.org", "year": 2023, "citationCount": 5, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2309.00810", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is argued that TTI development could yield impressive productivity improvements for creation, particularly in the context of the AIGC era, and could be extended to more complex tasks such as video generation and 3D generation."}, "embedding": {"model": "specter_v2", "vector": [0.6923812031745911, 0.5751509070396423, 0.448799729347229, 0.34427356719970703, -0.5000688433647156, -0.2839016914367676, 0.9665912389755249, -0.6094014048576355, 0.2050764560699463, -0.6131929755210876, 0.249186173081398, 0.5028665661811829, 0.04731517285108566, -0.49557819962501526, -0.6200838088989258, -0.2561302185058594, -0.9550043344497681, 0.3000514507293701, -0.07715162634849548, -0.475009560585022, -0.14034418761730194, -0.4573245346546173, -1.230212688446045, 0.11871223896741867, 0.38768404722213745, 0.9175252318382263, 0.03737294673919678, 1.479557752609253, -0.05690058693289757, 0.34764984250068665, 0.3882695734500885, -0.5454272627830505, 0.5448879599571228, -0.5999699831008911, -0.02937692403793335, 0.42728593945503235, 0.2814622223377228, -0.6272295713424683, -0.494972825050354, 0.4293064475059509, 0.12628735601902008, 0.04570750519633293, 0.9112823605537415, -0.5431332588195801, -0.6915568709373474, 0.3168168067932129, 0.3776017129421234, 0.6364336609840393, 0.16010239720344543, -0.4334990382194519, 0.9211183190345764, -1.090320348739624, 0.5098393559455872, 1.4880510568618774, 0.31733468174934387, 0.7189880609512329, -0.22487741708755493, -0.5281102061271667, 0.2173793762922287, -0.26176008582115173, -0.825636088848114, -0.07924199104309082, 0.30463987588882446, -0.5586559176445007, 1.0639537572860718, -0.40585052967071533, 0.13405460119247437, 1.0921869277954102, 0.38964539766311646, 1.307015299797058, -0.08497604727745056, -1.1526463031768799, -0.042139843106269836, -0.049483925104141235, -0.5820721983909607, 0.8688239455223083, -0.5738657116889954, 0.4392775893211365, -0.9998555779457092, 0.07460280507802963, 0.654548168182373, -0.41054707765579224, 0.28691697120666504, -0.029628055170178413, -0.11473693698644638, 0.9670928716659546, 0.18114924430847168, 0.7148525714874268, -0.31280335783958435, 0.9726646542549133, 0.06939412653446198, 0.16542010009288788, 0.26943761110305786, 0.13715077936649323, 0.6235985159873962, 0.5123301148414612, -0.845647931098938, 0.39373937249183655, -0.2926778495311737, 1.0753579139709473, -0.24938254058361053, 0.5918071866035461, -0.8955042958259583, 0.0845387652516365, 1.1536117792129517, 0.016474472358822823, 0.8487305045127869, -0.7511258721351624, 0.27838730812072754, -1.111009120941162, 0.28852444887161255, -0.7632601261138916, 0.07017021626234055, -0.24303115904331207, -1.0007879734039307, -0.6553269028663635, -0.7403843402862549, -0.1472897231578827, -1.5462214946746826, 0.41135650873184204, -0.29702216386795044, -0.29005998373031616, 0.026924937963485718, 0.5542158484458923, 0.14351582527160645, 0.7663814425468445, -0.15519584715366364, 0.3089982569217682, 0.4344940483570099, -0.7621402740478516, -0.5063303112983704, -0.7060408592224121, 0.27923938632011414, -0.2526737451553345, 0.35929030179977417, -0.029689086601138115, -1.78598153591156, -1.126296043395996, -0.9953376650810242, 0.38158118724823, -0.24224044382572174, 0.24127061665058136, 0.9173487424850464, 0.48876237869262695, -0.9815901517868042, 0.6308441758155823, -0.21554604172706604, -0.30023983120918274, 0.6335591077804565, 0.05433449521660805, 0.14993011951446533, -0.3216626048088074, -0.8786792159080505, -0.15035074949264526, -0.025897696614265442, -0.8075723052024841, -0.6480900049209595, -0.2492278814315796, -0.8412347435951233, -0.18654434382915497, 0.06785522401332855, -0.926500141620636, 1.0115596055984497, -0.32909095287323, -1.2624685764312744, 0.4152680039405823, -0.3615131378173828, -0.04505293071269989, 0.502429187297821, 0.10814706981182098, -0.14474770426750183, -0.18929257988929749, -0.1066819429397583, 0.8181658983230591, 0.9130422472953796, -0.5372400283813477, -0.14271728694438934, 0.304889976978302, -0.3189217150211334, -0.4120104908943176, -0.1449078470468521, 0.6341114044189453, -0.5419743657112122, -0.732283353805542, 0.4456547796726227, 0.2169131189584732, -0.4538115859031677, -0.41413167119026184, -0.5031329989433289, -0.6808878779411316, 0.8667499423027039, 0.09727748483419418, 0.6174730658531189, -0.624395489692688, -0.718405544757843, -0.10437240451574326, -0.0724099799990654, -0.6633639335632324, -0.7793949842453003, 0.8500434756278992, -0.548939049243927, 0.726856529712677, -0.20086373388767242, -0.9449588656425476, -0.07993733882904053, -0.6446782946586609, -0.709583580493927, -0.45892825722694397, 0.44023025035858154, 1.0909415483474731, -0.23063017427921295, 0.004183796234428883, -0.22866392135620117, 0.04538842290639877, -0.9007863402366638, 1.0777190923690796, -0.7188225388526917, 0.7103173732757568, -0.5949674248695374, -0.2155524641275406, -0.09544513374567032, -0.24993133544921875, -0.3554460108280182, -0.11212820559740067, 0.42142677307128906, -0.11524587869644165, -0.2499348372220993, 1.7275445461273193, 0.04156523570418358, 0.40872201323509216, -0.7377794981002808, -0.6786530613899231, 0.42519432306289673, 0.6074717044830322, 0.055015526711940765, -0.41225385665893555, 0.21830406785011292, 0.28683704137802124, -0.3657064735889435, 0.18120504915714264, 0.5036244988441467, 0.5107938051223755, -0.3648480772972107, 0.34994786977767944, 0.5497965216636658, -0.7662006616592407, 0.8447325229644775, 0.6781675219535828, 0.9581623673439026, 0.5211707949638367, -0.37212568521499634, 0.284137099981308, 0.19004221260547638, -0.7035179734230042, -0.5150842666625977, 0.8361032605171204, 1.1731809377670288, 1.678182601928711, 0.07969935238361359, -1.0700557231903076, -0.7435213923454285, -0.33141833543777466, 1.2569925785064697, 0.7976770401000977, -0.5297597646713257, -0.5076515078544617, -0.9639943242073059, -0.44074392318725586, -0.7189934253692627, 0.10004433989524841, -0.8819162845611572, -0.1299850195646286, -0.30821558833122253, -1.047426700592041, 0.7229706048965454, 0.03418496251106262, 0.9728162884712219, -0.6062968373298645, -0.10300363600254059, -0.21522508561611176, 0.3062801957130432, -0.7624382376670837, -0.7502846717834473, -0.3414304554462433, -0.17588891088962555, 0.43997639417648315, -0.8221689462661743, 0.00260732788592577, 0.5316262245178223, -0.7612768411636353, 0.5796664357185364, -0.13533329963684082, -0.7915927171707153, 0.4989565312862396, 0.2870456576347351, -1.013492465019226, -1.220880150794983, -0.13133594393730164, -0.2542601227760315, -0.02410856820642948, -0.5920721888542175, 0.2716107666492462, -0.033729735761880875, 0.06741514056921005, -0.9667969942092896, 0.10309262573719025, -0.057240843772888184, -0.052451785653829575, 0.7039569020271301, 0.1297101229429245, -0.2418874055147171, -0.9129252433776855, 1.1959030628204346, 0.42608389258384705, -0.5077277421951294, 0.13532908260822296, -0.6775422692298889, -0.28387537598609924, 0.494945228099823, -0.6111559867858887, -0.5561351180076599, -0.7763822078704834, 0.28847405314445496, -0.2884620130062103, -0.384308397769928, 0.044099222868680954, 0.6883144378662109, -0.036583662033081055, 0.3953718841075897, 0.6449483633041382, 0.29183948040008545, 0.2690682113170624, 0.6871123909950256, -1.2523698806762695, 0.37276381254196167, 0.13188517093658447, 0.665473997592926, 0.32429707050323486, 0.1278950721025467, -0.27819108963012695, -0.38997578620910645, 0.5670443773269653, -0.3535962700843811, -0.9322423934936523, 0.684422492980957, -0.4398886263370514, -0.3964691162109375, 0.23984618484973907, -0.8572663068771362, -0.04730955883860588, -0.01168031245470047, -0.6153580546379089, -0.731076717376709, -0.9198769927024841, -0.9143426418304443, -0.5406549572944641, -0.7565094232559204, -1.230387806892395, 0.5602330565452576, 0.23576293885707855, -0.3326749801635742, -0.5123686194419861, 0.22024397552013397, -0.06803067028522491, 0.8539325594902039, -0.21885547041893005, 0.8444046974182129, 0.2210204303264618, -0.44634097814559937, -0.5515047907829285, 0.6802886724472046, 0.1919364631175995, -0.21275605261325836, 0.5995784401893616, -0.7163400053977966, 0.08878092467784882, -0.38374969363212585, -0.4423828125, 0.048283059149980545, 0.47823065519332886, 0.5392333269119263, 0.11007696390151978, -0.4637055993080139, 0.2772049605846405, 1.3486136198043823, -0.028181811794638634, 0.2858964204788208, -0.02852385863661766, 0.7642883062362671, 0.43732598423957825, -0.5970191359519958, 0.7838437557220459, 0.19771228730678558, 0.334261029958725, -0.121116504073143, -0.30056050419807434, -0.7025744318962097, -0.9639735817909241, 0.5558438897132874, 1.431035041809082, 0.2694236934185028, -0.8725353479385376, -0.8641385436058044, 0.5927748084068298, -0.9112407565116882, -0.6399866938591003, 0.8786032795906067, 0.5415117740631104, -0.06327547132968903, -0.22350507974624634, -0.21247953176498413, -0.24746857583522797, 0.49144864082336426, 0.13501203060150146, -0.1565546840429306, -0.3817041218280792, -0.2855110764503479, 0.436720073223114, -0.1589953750371933, 0.38750511407852173, -0.0873141661286354, 0.2988824248313904, 14.83371353149414, 1.279504418373108, 0.14550355076789856, 0.2499603033065796, 0.924397885799408, 0.2744728922843933, -0.6252319812774658, -0.1348731964826584, -0.8202579021453857, -0.14611375331878662, 0.867051899433136, 0.0011990648927167058, 0.3543015122413635, 0.00666753388941288, -0.009644478559494019, 0.13689424097537994, -0.12888509035110474, 0.38341930508613586, 0.8149205446243286, -1.6400866508483887, 0.8460996747016907, 0.43624165654182434, 0.9084466099739075, 0.31079626083374023, 0.9850658178329468, 0.40172669291496277, 0.37011387944221497, -0.3983307480812073, 0.8698145747184753, 0.627360463142395, 0.6140503883361816, 0.15603439509868622, -0.11809958517551422, 0.4977714419364929, -0.7984666228294373, -0.25025510787963867, -0.5912577509880066, -0.6402895450592041, 0.5202413201332092, 0.04723067581653595, -0.5976997017860413, -0.1943145990371704, 0.08893850445747375, 0.3484266400337219, -0.3285042345523834, 0.3349636197090149, -0.12176406383514404, 0.6880576610565186, -0.20428967475891113, 0.24821317195892334, 0.2907247841358185, 0.173044353723526, 0.5023237466812134, -0.5645485520362854, 0.707584023475647, 0.02122468501329422, 0.06688467413187027, 0.8422986268997192, -0.4526142179965973, -0.1935935616493225, -0.8099570274353027, -0.23587389290332794, -0.5293921232223511, 0.5616702437400818, -0.12244583666324615, 0.44632071256637573, -0.1777760535478592, 0.578713059425354, 0.26795628666877747, 0.24192224442958832, -0.3287361264228821, -0.09872961044311523, -0.33972904086112976, 0.07428640872240067, 0.38030752539634705, 0.2814171314239502, -0.04009654000401497, -0.11299705505371094, -0.5708732604980469, -0.3595218062400818, 0.28608375787734985, -1.3790315389633179, -0.9688265323638916, 1.2810558080673218, -0.026400990784168243, -0.39059802889823914, -0.3028997480869293, -0.21233931183815002, -0.5330913662910461, 0.3958088755607605, -0.8439081907272339, -1.1560280323028564, 0.21156154572963715, -0.2690383791923523, 0.05280125513672829, -0.5518169403076172, 0.8989033699035645, -0.38414737582206726, -0.07262025773525238, 0.05492899566888809, 0.1181609109044075, 0.018816569820046425, -0.27332431077957153, -0.44806143641471863, 1.3035812377929688, 0.49514254927635193, 0.3003826141357422, -0.4160113036632538, 0.09780941158533096, -0.17093026638031006, -0.8366186618804932, 0.18319463729858398, -0.014071084558963776, -0.9773926734924316, -0.7188435792922974, -0.7579293847084045, -0.4327712059020996, 0.04097488150000572, 0.9432445168495178, -0.49836599826812744, -0.21380971372127533, -0.5108136534690857, -0.06950093805789948, -0.1316937804222107, -0.6589460372924805, 0.386985719203949, 0.21422871947288513, -0.2940243184566498, 0.31113874912261963, 0.18699362874031067, 0.3866000473499298, -0.9961417317390442, -0.4008764624595642, -0.1905161440372467, 0.31007182598114014, -0.49642905592918396, 0.9098184108734131, -0.09268967062234879, 0.9768585562705994, 0.8578163385391235, 0.016385991126298904, -0.5304645895957947, -0.36487218737602234, -1.3949192762374878, 0.7137587070465088, 0.48022735118865967, 0.7868877053260803, -0.09613635390996933, 0.7344859838485718, 0.966727614402771, 0.5616340041160583, -0.24614772200584412, -0.4421655237674713, -0.060514237731695175, 0.2936179041862488, -0.742796003818512, 0.4210197925567627, -0.8053497076034546, -0.7046074271202087, 0.06524238735437393, 0.0004683060687966645, 0.6397208571434021, -0.15084730088710785, -0.7679989337921143, 0.928182065486908, 0.2875325679779053, -0.052674006670713425, -0.47406989336013794, -0.5186060070991516, -1.2632088661193848, -0.2773948311805725, -0.998917281627655, 0.10291197896003723, -1.0933053493499756, -0.4719564616680145, 0.23989984393119812, 0.5310285091400146, -0.4427478611469269, 0.7227464914321899, -0.15712623298168182, 0.072720967233181, -0.4368540048599243, -0.1739111840724945, 0.8616486191749573, 1.2393264770507812, -0.8702561855316162, 0.13923320174217224, -0.1294987052679062, 0.1580197662115097, 0.4992230236530304, 0.29177284240722656, -0.8003121018409729, -1.2482869625091553, -1.47288179397583, 0.45751503109931946, -0.019812865182757378, -0.05207112058997154, -1.4168258905410767, 0.5453697443008423, 0.841680645942688, 0.4076991379261017, -0.14591486752033234, 0.517411470413208, -0.5776705741882324, 0.017579512670636177, -0.039544228464365005, -0.9785440564155579, 0.38609862327575684, 0.06964103877544403, -0.3739147484302521, -0.12981556355953217, 0.30447450280189514, -0.13553500175476074, -1.3721675872802734, -0.28778618574142456, 0.6264362335205078, -0.8838896751403809, 0.07501521706581116, -0.03736979886889458, -0.3493649959564209, -0.804263174533844, -1.0290647745132446, -0.15894675254821777, -0.16342958807945251, -0.2611023783683777, 1.1164741516113281, 0.9746935963630676, -1.0764344930648804, -0.2531479299068451, 0.4948711097240448, -0.22043126821517944, -0.1577111929655075, 0.8965581059455872, 0.06219187006354332, -0.21404577791690826, 0.28152891993522644, 0.4595704972743988, 0.29709482192993164, -0.45049020648002625, 0.057391345500946045, 0.7791507244110107, -0.5170281529426575, -0.14682692289352417, 1.226324200630188, 0.1488085389137268, -0.7769783735275269, -0.26717376708984375, -0.6462807655334473, -0.33175280690193176, -0.6753482222557068, 0.6145837903022766, -0.2077019363641739, -0.41993021965026855, -0.014778087846934795, 0.18589729070663452, 0.7109852433204651, -0.18667243421077728, -1.1893901824951172, 0.30025503039360046, -0.5515629053115845, -0.001265434199012816, 0.24408935010433197, 0.46893543004989624, -0.5694957375526428, -0.8229191899299622, -0.17010720074176788, -0.606698751449585, -0.29399511218070984, 0.11293722689151764, -0.6361014246940613, -0.7543526291847229, 0.9302515983581543, 0.9774271845817566, 0.49259498715400696, 0.5142697691917419, 0.20720623433589935, 0.522100031375885, 0.05324600636959076, -0.10144023597240448, -0.4754367768764496, 0.04941544681787491, 0.8278922438621521, 1.5184906721115112, -0.5102419853210449, 0.42506304383277893, -0.14841744303703308, -0.9258029460906982, 1.1469266414642334, 0.20490285754203796, -0.04667872190475464, 0.8675879836082458, -0.18928316235542297, 0.038026437163352966, 0.0023626727052032948, -1.0370020866394043, -0.11826504021883011, 1.0437891483306885, 1.4387502670288086, 0.5670106410980225, -0.32057008147239685, 0.3371620774269104, 0.8066863417625427, -0.08851465582847595, 0.39649489521980286, 0.8543620705604553, 0.43744170665740967, 0.04859358072280884, -0.3063569664955139, -0.35941657423973083, 0.5022270679473877, -0.8365142941474915, -0.3266267776489258, 0.14198026061058044, 0.49369534850120544, 0.2970222532749176, 0.9836088418960571, 0.6272429823875427, -0.1878170371055603, 0.46645140647888184, -0.1748514324426651, 0.9191719889640808, 0.005699923727661371, -0.12917375564575195, 0.4067733883857727, -0.8589123487472534, 0.09568951278924942, -0.22922749817371368, -0.5031934380531311, -0.1275818645954132, 0.0020317090675234795, 0.23836718499660492, -0.08095839619636536, 0.28824517130851746, 0.9546411633491516, 0.8386535048484802, 0.26877561211586, -0.010932868346571922, -0.7438115477561951, 0.10880176723003387, -0.8159397840499878, 0.17133717238903046, -0.3221457302570343, -0.28373950719833374, -0.2724790871143341, 0.10227940231561661, 0.46165817975997925]}, "authors": [{"authorId": "2271095802", "name": "Fengxiang Bie"}, {"authorId": "2270553819", "name": "Yibo Yang"}, {"authorId": "2226690406", "name": "Zhongzhu Zhou"}, {"authorId": "2256976897", "name": "Adam Ghanem"}, {"authorId": "2257093455", "name": "Minjia Zhang"}, {"authorId": "2262242352", "name": "Zhewei Yao"}, {"authorId": "2129511744", "name": "Xiaoxia Wu"}, {"authorId": "2059083875", "name": "Connor Holmes"}, {"authorId": "38147257", "name": "Pareesa Ameneh Golnari"}, {"authorId": "2270218158", "name": "David A. Clifton"}, {"authorId": "2257185770", "name": "Yuxiong He"}, {"authorId": "2257210161", "name": "Dacheng Tao"}, {"authorId": "2243324798", "name": "S. Song"}], "references": [{"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "f52293edcaccf33cc16c372175a69ffa63cf3460", "title": "Towards Open Vocabulary Learning: A Survey"}, {"paperId": "f02ea7a18f00859d9ea1b321e3385ae7d0170639", "title": "VideoComposer: Compositional Video Synthesis with Motion Controllability"}, {"paperId": "7820f9e98c9d064a0402685be2cf875a916edd27", "title": "Probabilistic Adaptation of Text-to-Video Models"}, {"paperId": "52b10ae66d025e99fbb602935e155f97f4f0696f", "title": "Make-Your-Video: Customized Video Generation Using Textual and Structural Guidance"}, {"paperId": "481e00d33baba3a2c8023e0185630bb17240bca5", "title": "Gen-L-Video: Multi-Text to Long Video Generation via Temporal Co-Denoising"}, {"paperId": "48a7c60b023ebd2cf0587df1cc09f1309fe51d28", "title": "Control-A-Video: Controllable Text-to-Video Generation with Diffusion Models"}, {"paperId": "7b9646b33c96fb43c51c979637b10651aff97d87", "title": "DiffFacto: Controllable Part-Based 3D Point Cloud Generation with Cross Diffusion"}, {"paperId": "d203076c28587895aa344d088b2788dbab5e82a1", "title": "Transformer-Based Visual Segmentation: A Survey"}, {"paperId": "18e5fecd0ce09ac71706147393301dd25f42b359", "title": "Control3Diff: Learning Controllable 3D Diffusion Models from Single-view Images"}, {"paperId": "34e95464be6cc3041041f145758493401b8a75e8", "title": "DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion"}, {"paperId": "cf923fb70bbad20c485cef355444a08096747f68", "title": "Generative Novel View Synthesis with 3D-Aware Diffusion Models"}, {"paperId": "ee73edebd42626d9c2d91e35fd2ed3cdb0fb26d0", "title": "Follow Your Pose: Pose-Guided Text-to-Video Generation using Pose-Free Videos"}, {"paperId": "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d", "title": "A Survey of Large Language Models"}, {"paperId": "83edcfbb206ddad38a971d605da09390604248ea", "title": "BloombergGPT: A Large Language Model for Finance"}, {"paperId": "b8b5015b153709176385873e34339f9e520d128f", "title": "Conditional Image-to-Video Generation with Latent Flow Diffusion Models"}, {"paperId": "923a03032014a12c4e8b26511c0394e1b915fe74", "title": "Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "e7d4c895222241aee5e654dd0139c0809762a2b4", "title": "Point Cloud Diffusion Models for Automatic Implant Generation"}, {"paperId": "b7a783e3897baed760fb91cd1289dd0e353377f5", "title": "MeshDiffusion: Score-based Generative 3D Mesh Modeling"}, {"paperId": "0930fe943d7d9b5bb943613d87c4ca92850dd43a", "title": "Scaling up GANs for Text-to-Image Synthesis"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "08ea934db9d135a08dddff878536a8b1b3e317c6", "title": "ChatGPT: A Meta-Analysis after 2.5 Months"}, {"paperId": "3c7582bf1a6682f6d33c47fa0c911e55823a3c44", "title": "Video Probabilistic Diffusion Models in Projected Latent Space"}, {"paperId": "efbe97d20c4ffe356e8826c01dc550bacc405add", "title": "Adding Conditional Control to Text-to-Image Diffusion Models"}, {"paperId": "4e1e6e82c7c4c652a37e0d07d726178e56a87e54", "title": "GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis"}, {"paperId": "2a3213cb3c755f036d5dfec7261d726a819c78c1", "title": "Muse: Text-To-Image Generation via Masked Generative Transformers"}, {"paperId": "3d94322b049959cac15efd67af22207b73afa245", "title": "MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation"}, {"paperId": "7e993a9ca01dcd4538362454aaac29a18a63c000", "title": "RODIN: A Generative Model for Sculpting 3D Digital Avatars Using Diffusion"}, {"paperId": "79d00d53b1ad857d4a63d10566ed49ee1c13e60c", "title": "3D-LDM: Neural Implicit 3D Shape Generation with Latent Diffusion Models"}, {"paperId": "69d8fbd6721a490ca58116242274d642e3a9bbd9", "title": "3D Neural Field Generation Using Triplane Diffusion"}, {"paperId": "35c7586457f8a158a967a3d73207ee8ecd1e8eb6", "title": "SpaText: Spatio-Textual Representation for Controllable Image Generation"}, {"paperId": "30c7d7bd208314ea1e925835eabddd98aca29f01", "title": "Shifted Diffusion for Text-to-image Generation"}, {"paperId": "55036dea7f6068d6b5de6ffe178bb324d01918a0", "title": "Sketch-Guided Text-to-Image Diffusion Models"}, {"paperId": "831c240d7725b8e4ba3e4039f16a693253fab2ab", "title": "Inversion-based Style Transfer with Diffusion Models"}, {"paperId": "4f1502111d35aa6651dfaedfeb1184b3c3dd2fcb", "title": "Paint by Example: Exemplar-based Image Editing with Diffusion Models"}, {"paperId": "b000d6865db824af1563708fb7a545ddd65c6b3a", "title": "Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation"}, {"paperId": "2808b8bf0508dc0890a4f765afb95496b45d758a", "title": "Next3D: Generative Neural Texture Rasterization for 3D-Aware Head Avatars"}, {"paperId": "94b690162ead76af6a487d6e10998ea585c035d1", "title": "MagicVideo: Efficient Video Generation With Latent Diffusion Models"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "e24f4b28167b05fbf7d29000490fc0a4e4c109c7", "title": "eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert Denoisers"}, {"paperId": "8ff9667c8c948df1e84606dc086d9a4fba2256f7", "title": "UPainting: Unified Text-to-Image Diffusion Generation with Cross-modal Guidance"}, {"paperId": "ee9c6f9f9702553f404856287e1388a2916d5383", "title": "ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with Knowledge-Enhanced Mixture-of-Denoising-Experts"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "69144d537f90f214d5b07a7c79121d16afd7da16", "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models"}, {"paperId": "e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9", "title": "LAION-5B: An open large-scale dataset for training next generation image-text models"}, {"paperId": "9793e6f3883e5ce5dbb92c0b940df06021ece1ae", "title": "LION: Latent Point Diffusion Models for 3D Shape Generation"}, {"paperId": "1d26c947406173145a4665dd7ab255e03494ea28", "title": "GLM-130B: An Open Bilingual Pre-trained Model"}, {"paperId": "498ac9b2e494601d20a3d0211c16acf2b7954a54", "title": "Imagen Video: High Definition Video Generation with Diffusion Models"}, {"paperId": "ec1ac8df419a241c3cc6bfd209a38b494af792ee", "title": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator"}, {"paperId": "1e33716e8820b867d5a8aaebab44c2d3135ea4ac", "title": "Make-A-Video: Text-to-Video Generation without Text-Video Data"}, {"paperId": "0ab5fa0d4b18d655e22ca7fec7c321ac7158dbca", "title": "Neural Wavelet-domain Diffusion for 3D Shape Generation"}, {"paperId": "efa1647594b236361610a20d507127f0586a379b", "title": "Diffusion Models in Vision: A Survey"}, {"paperId": "244054a4254a2147e43a3dad9c124b9b7eb4a04a", "title": "Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow"}, {"paperId": "e342165a614588878ad0f4bc9bacf3905df34d08", "title": "Diffusion Models: A Comprehensive Survey of Methods and Applications"}, {"paperId": "5b19bf6c3f4b25cac96362c98b930cf4b37f6744", "title": "DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation"}, {"paperId": "6348ffdbcd9ac4de69b139fa0303b9b2a7f61679", "title": "Text-to-Image Generation via Implicit Visual Guidance and Hypernetwork"}, {"paperId": "d739843820444060c6e1ee74360c50fdf358c2bb", "title": "Memory-Driven Text-to-Image Generation"}, {"paperId": "2cbea7615ebecea2c414d8fbad47d5d258a5c3b4", "title": "Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning"}, {"paperId": "33eed2817c4cd43977d91d19fec4392228e56198", "title": "Learning to Generate 3D Shapes from a Single Example"}, {"paperId": "914254fac74a2da051cccf6ca16afcaad416a079", "title": "AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model"}, {"paperId": "af9f365ed86614c800f082bd8eb14be76072ad16", "title": "Classifier-Free Diffusion Guidance"}, {"paperId": "0270ec4bc946b59c5cf6204be2553682dee0346c", "title": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models"}, {"paperId": "c036f75da24ba64a583e0b6d41c5b792347bffa6", "title": "Diffsound: Discrete Diffusion Model for Text-to-Sound Generation"}, {"paperId": "dd7b8d097cf6ee0d42d200b2019912af582b31dd", "title": "EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic Differential Equations"}, {"paperId": "3a37d567573a8a340c5e376e3b605328c8595ece", "title": "Eliminating Gradient Conflict in Reference-based Line-Art Colorization"}, {"paperId": "1243e13254bb4ea1f71b4be8a3e4e54ffd02d2fe", "title": "Scaling Autoregressive Models for Content-Rich Text-to-Image Generation"}, {"paperId": "d09dc1f8b0cc5c3a43bf63bf9c7df3e63e0da313", "title": "VLMixer: Unpaired Vision-Language Pre-training via Cross-Modal CutMix"}, {"paperId": "5a826383a109aa971fddc200f563121ed615e00e", "title": "Latent Diffusion Energy-Based Model for Interpretable Text Modeling"}, {"paperId": "4530c25da949bb2185c50663158ef19d52e3c6b5", "title": "DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps"}, {"paperId": "1386b8a11929cf02da291c56aca353e33bbc22ed", "title": "Diffusion-LM Improves Controllable Text Generation"}, {"paperId": "d593b9b8d63426f0d6a795dd7f2294619bc03610", "title": "NaturalProver: Grounded Mathematical Proof Generation with Language Models"}, {"paperId": "9695824d7a01fad57ba9c01d7d76a519d78d65e7", "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"}, {"paperId": "805748eec6be59ae0cd92a48400a902b3b7ed8e6", "title": "Flexible Diffusion Modeling of Long Videos"}, {"paperId": "3ebdd3db0dd91069fa0cd31cbf8308b60b1b565e", "title": "Planning with Diffusion for Flexible Behavior Synthesis"}, {"paperId": "203da5aaec7b3e06cd91df0d4cdf78e399f7a1d3", "title": "Few-Shot Font Generation by Learning Fine-Grained Local Styles"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "75bb9eda70751c63fc54dbe63377c673b7dbdb15", "title": "CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers"}, {"paperId": "0221d3f45899e226ba7840ca9b19117de3a394bc", "title": "Semi-Parametric Neural Image Synthesis"}, {"paperId": "06d7cb8c8816360feb33c3367073e0ef66d7d0b0", "title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "c57293882b2561e1ba03017902df9fc2f289dea2", "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"}, {"paperId": "3b2a675bb617ae1a920e8e29d535cdf27826e999", "title": "Video Diffusion Models"}, {"paperId": "a225d5d846ba5110232ed5bb32d54ea742b1c2d4", "title": "KNN-Diffusion: Image Generation via Large-Scale Retrieval"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "3d111fd3e4c7da698baa21af8c0aac550bf4b419", "title": "ART-Point: Improving Rotation Robustness of Point Cloud Classifiers via Adversarial Rotation"}, {"paperId": "1bc9865ebf52b59abac7f5ee4456ff2ac37fcff3", "title": "ST-MoE: Designing Stable and Transferable Sparse Expert Models"}, {"paperId": "212732c649d84382f4e74ca047b13f3c835591d7", "title": "DALL-EVAL: Probing the Reasoning Skills and Social Biases of Text-to-Image Generation Models"}, {"paperId": "84f65cfb597d574ee09cb84731181cfeeeac78cd", "title": "Infergrad: Improving Diffusion Models for Vocoder by Considering Inference in Training"}, {"paperId": "6296aa7cab06eaf058f7291040b320b5a83c0091", "title": "Generative Adversarial Networks"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "1e91fa21b890a8f5d615578f4ddf46c3cb394691", "title": "RePaint: Inpainting using Denoising Diffusion Probabilistic Models"}, {"paperId": "b3848d32f7294ec708627897833c4097eb4d8778", "title": "LaMDA: Language Models for Dialog Applications"}, {"paperId": "9b7b218b0f4e14f97260b6192add37da5e9ae2c5", "title": "Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models"}, {"paperId": "7d1e512888a2fa4e838c12a02ae7fce867d322a8", "title": "DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale"}, {"paperId": "cdd92d3740ac0bd646e18bcc373c52578a341725", "title": "TransVOD: End-to-End Video Object Detection With Spatial-Temporal Transformers"}, {"paperId": "a3184d40d390793232c99c89b57b8f65c16320b2", "title": "ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation"}, {"paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d", "title": "High-Resolution Image Synthesis with Latent Diffusion Models"}, {"paperId": "7002ae048e4b8c9133a55428441e8066070995cb", "title": "GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models"}, {"paperId": "2f3efe44083af91cef562c1a3451eee2f8601d22", "title": "WebGPT: Browser-assisted question-answering with human feedback"}, {"paperId": "002c256d30d6be4b23d365a8de8ae0e67e4c9641", "title": "Improving language models by retrieving from trillions of tokens"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "42f2271cebb7f272b0066c1f22d33381f139ee68", "title": "Label-Efficient Semantic Segmentation with Diffusion Models"}, {"paperId": "03a718819cdd3fcc102db640330037ff46431d67", "title": "Diffusion Models for Implicit Image Segmentation Ensembles"}, {"paperId": "55022c4f52fe34022143a5c8f886ded527cb4662", "title": "PolyphonicFormer: Unified Query Learning for Depth-aware Video Panoptic Segmentation"}, {"paperId": "98598d0c472694f3bdaf84997400c98d9ec7ffd6", "title": "FuseDream: Training-Free Text-to-Image Generation with Improved CLIP+GAN Space Optimization"}, {"paperId": "1c1cc65908dd5ca3d0103d650de896e053e0e7d7", "title": "SegDiff: Image Segmentation with Diffusion Probabilistic Models"}, {"paperId": "414e554d281d529401c873cb9c97186365ec5dd8", "title": "Vector Quantized Diffusion Model for Text-to-Image Synthesis"}, {"paperId": "88e8801e4daf404d3d40f1648ef29faeb8e6d58a", "title": "Blended Diffusion for Text-driven Editing of Natural Images"}, {"paperId": "37c9c4e7648f639c0b36f150fc6c6c90b3682f4a", "title": "Palette: Image-to-Image Diffusion Models"}, {"paperId": "cf7c2e0e4fb2af689aaf4b7a7cddf7b1f4d5e3f0", "title": "VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts"}, {"paperId": "b668ce936cff0b0ca8b635cd5f25a62eaf4eb3df", "title": "LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs"}, {"paperId": "c19e71fb84c9a2b06af2ae51e33f3b84cc6be507", "title": "A survey on text generation using generative adversarial networks"}, {"paperId": "ee8984a6712791d4e0f2c776dad8119a3b893dd9", "title": "Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "767923635f2fd4467d848dba9655866e4f9b55c8", "title": "Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm"}, {"paperId": "9c7a2cd13b783bb73ad2d1ec2880bdd9b995cbdc", "title": "Vector-quantized Image Modeling with Improved VQGAN"}, {"paperId": "916d10920b79cef09b14e86810637ab3c70e5956", "title": "Transformer for Single Image Super-Resolution"}, {"paperId": "91b32fc0a23f0af53229fceaae9cce43a0406d2e", "title": "Structured Denoising Diffusion Models in Discrete State-Spaces"}, {"paperId": "722ad6ac92286507437b31486f47987d6ece05c9", "title": "BEiT: BERT Pre-Training of Image Transformers"}, {"paperId": "8690d62d4bbbd0b1ed5e1f25320d10853bfbeb01", "title": "Scaling Vision with Sparse Mixture of Experts"}, {"paperId": "9d1934ea1bd69d928d17e05d44495d42edf8601d", "title": "You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection"}, {"paperId": "0f183bcfe65781c06b1a48a6f56e0f3c63e8e4a4", "title": "Cascaded Diffusion Models for High Fidelity Image Generation"}, {"paperId": "1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa", "title": "CogView: Mastering Text-to-Image Generation via Transformers"}, {"paperId": "64ea8f180d0682e6c18d1eb688afdb2027c02794", "title": "Diffusion Models Beat GANs on Image Synthesis"}, {"paperId": "d0cefc4621a55540c77e8ade9b8ae1bfeb530f42", "title": "SRDiff: Single Image Super-Resolution with Diffusion Probabilistic Models"}, {"paperId": "2d9ae4c167510ed78803735fc57ea67c3cc55a35", "title": "VideoGPT: Video Generation using VQ-VAE and Transformers"}, {"paperId": "38b0567e83386ddc294d6c81b541deacbd8e3c2a", "title": "CLIPScore: A Reference-free Evaluation Metric for Image Captioning"}, {"paperId": "8a1ea7b6e7e834d146ad782be5d63f57f806a9cc", "title": "Image Super-Resolution via Iterative Refinement"}, {"paperId": "14c52ffa7ea9c1971d5d82ea369c946c98d056a9", "title": "LocalViT: Bringing Locality to Vision Transformers"}, {"paperId": "52488dd5dfb1ca17dde179ff7e993f93d3f0a8cc", "title": "Text to Image Generation with Semantic-Spatial Aware GAN"}, {"paperId": "809b231e915c35db47cb81abfd8600f4c0f9fa10", "title": "Kaleido-BERT: Vision-Language Pre-training on Fashion Domain"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "616e0ed02ca024a8c1d4b86167f7486ea92a13d9", "title": "VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning"}, {"paperId": "394be105b87e9bfe72c20efe6338de10604e1a11", "title": "Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts"}, {"paperId": "cb596bffc5c5042c254058b62317a57fa156fea4", "title": "Unifying Vision-and-Language Tasks via Text Generation"}, {"paperId": "0839722fb5369c0abaff8515bfc08299efc790a1", "title": "ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision"}, {"paperId": "33e8cad403a52ad10d0fe418ff980760401e869f", "title": "Generating images from caption and vice versa via CLIP-Guided Generative Latent Space Search"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "abac50aa18e037f8149b2b212f1691d738f7b056", "title": "Adversarial Text-to-Image Synthesis: A Review"}, {"paperId": "652032fbb744da4f279e8f30eef2323155878ac4", "title": "Cross-Modal Contrastive Learning for Text-to-Image Generation"}, {"paperId": "1ad6da856f5d76b4df35d52fec6d8fb48a8b4462", "title": "GAN-Control: Explicitly Controllable GANs"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "47f7ec3d0a5e6e83b6768ece35206a94dc81919c", "title": "Taming Transformers for High-Resolution Image Synthesis"}, {"paperId": "633e2fbfc0b21e959a244100937c5853afca4853", "title": "Score-Based Generative Modeling through Stochastic Differential Equations"}, {"paperId": "887dca3660b7c6543faac513d804e621f0134470", "title": "Text-to-Image Generation Grounded by Fine-Grained User Attention"}, {"paperId": "74276a37bfa50f90dfae37f767b2b67784bd402a", "title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "014576b866078524286802b1d0e18628520aa886", "title": "Denoising Diffusion Implicit Models"}, {"paperId": "a2cd073b57be744533152202989228cb4122270a", "title": "Sharpness-Aware Minimization for Efficiently Improving Generalization"}, {"paperId": "0a57f4d82e985358a5792860d1131f4207d83037", "title": "Efficient Learning of Generative Models via Finite-Difference Score Matching"}, {"paperId": "62d337dbaead376ca042f23d62c0d4b65ec98546", "title": "GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis"}, {"paperId": "5c126ae3421f05768d8edd97ecd44b1364e2c99a", "title": "Denoising Diffusion Probabilistic Models"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "598a2ee223e2949c3b28389e922c1892b4717d2a", "title": "Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal Transformers"}, {"paperId": "b9779ddeb6a8a9de0f7e104d8742728aa14578d6", "title": "InterBERT: Vision-and-Language Interaction for Multi-modal Pretraining"}, {"paperId": "1d0d9550ecd2bece6a34fe1ffd12fb7504e7aaa0", "title": "XGPT: Cross-modal Generative Pre-Training for Image Captioning"}, {"paperId": "832fff14d2ed50eb7969c4c4b976c35776548f56", "title": "REALM: Retrieval-Augmented Language Model Pre-Training"}, {"paperId": "a9fd5511b42206a27748f373e0fdb7eb76a23055", "title": "ImageBERT: Cross-modal Pre-training with Large-scale Weak-supervised Image-Text Data"}, {"paperId": "71bfdaa0ab11fd02976af50e56e7c64733b2464a", "title": "It GAN Do Better: GAN-Based Detection of Objects on Images With Varying Quality"}, {"paperId": "14fdc18d9c164e5b0d6d946b3238c04e81921358", "title": "Analyzing and Improving the Image Quality of StyleGAN"}, {"paperId": "e6efbccdfd7b054ee91402cf9da27f05bde65cd3", "title": "SOGNet: Scene Overlap Graph Network for Panoptic Segmentation"}, {"paperId": "d7015a7c12550b5138181f4d054ea7dbe9022bed", "title": "Effectively Unbiased FID and Inception Score and Where to Find Them"}, {"paperId": "7be8c119dbe065c52125ee7716601751f3116844", "title": "Generalization through Memorization: Nearest Neighbor Language Models"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "9de50870d5a8399c22f116d5f0ff32b694284ede", "title": "Generative Modeling for Small-Data Object Detection"}, {"paperId": "4d158f43fc1dfe148f63ad2c7162b51ee7e743cc", "title": "PolarMask: Single Shot Instance Segmentation With Polar Representation"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "5aec474c31a2f4b74703c6f786c0a8ff85c450da", "title": "VisualBERT: A Simple and Performant Baseline for Vision and Language"}, {"paperId": "8b57fe884a89dea887b39676e27f9c51949dad10", "title": "Perceptual Pyramid Adversarial Networks for Text-to-Image Synthesis"}, {"paperId": "da0cfa0585a95bfba4de3516d42d2e79c4ab88b6", "title": "CU-Net: Cascaded U-Net with Loss Weighted Sampling for Brain Tumor Segmentation"}, {"paperId": "965359b3008ab50dd04e171551220ec0e7f83aba", "title": "Generative Modeling by Estimating Gradients of the Data Distribution"}, {"paperId": "81664382e5db10bc6598db0b8814a8e765d30576", "title": "Sliced Score Matching: A Scalable Approach to Density and Score Estimation"}, {"paperId": "5f994dc8cae24ca9d1ed629e517fcc652660ddde", "title": "ERNIE: Enhanced Language Representation with Informative Entities"}, {"paperId": "1c71771c701aadfd72c5866170a9f5d71464bb88", "title": "Unified Language Model Pre-training for Natural Language Understanding and Generation"}, {"paperId": "69455376f5ad52cac5b72d5e8c6cf03fb466b55c", "title": "Cross-Modal Self-Attention Network for Referring Image Segmentation"}, {"paperId": "4308c530613ea437fe8224cc65720adf28b1a589", "title": "Semantics Disentangling for Text-To-Image Generation"}, {"paperId": "ab995f96722969a0dfc6dc9139eef4c9b13c0524", "title": "DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-To-Image Synthesis"}, {"paperId": "a1a19aaddf57c0546357d890d9269092ba0afb26", "title": "Semantic Image Synthesis With Spatially-Adaptive Normalization"}, {"paperId": "5af2d424bb38db7e6a72f7bec2cfd8a5bb8af7fb", "title": "MirrorGAN: Learning Text-To-Image Generation by Redescription"}, {"paperId": "fc5cb771ef25ed57e4902cf86433db906cdbbc39", "title": "Object-Driven Text-To-Image Synthesis via Adversarial Training"}, {"paperId": "333b99ba26d6113d8ba79e420a258e6545f4497a", "title": "Adversarial Learning of Semantic Relevance in Text to Image Synthesis"}, {"paperId": "29309743870c825f9645a4803af727402462e513", "title": "Bag of Tricks for Image Classification with Convolutional Neural Networks"}, {"paperId": "22aab110058ebbd198edb1f1e7b4f69fb13c0613", "title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis"}, {"paperId": "b4df354db88a70183a64dbc9e56cf14e7669a6c0", "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"}, {"paperId": "46b5d408d950287637dd21ce04772d9b2bacfd14", "title": "Image Generation from Scene Graphs"}, {"paperId": "cb86ae88e59dd3430662201289a1f4e1ccd9824b", "title": "An Improved Evaluation Framework for Generative Adversarial Networks"}, {"paperId": "d1e3f6d69c1a7bb2bc97273fb18470df92b1c7a4", "title": "Photographic Text-to-Image Synthesis with a Hierarchically-Nested Adversarial Network"}, {"paperId": "dce916351ef589afa7a63452648dd8acba931e92", "title": "Panoptic Segmentation"}, {"paperId": "8b35c00edfa4edfd7a99d816e671023d2c000d55", "title": "AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks"}, {"paperId": "4ace72f12491a7c06967a6011c4bef004192d767", "title": "StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks"}, {"paperId": "231af7dc01a166cac3b5b01ca05778238f796e41", "title": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium"}, {"paperId": "ee4a012a4b12d11d7ab8c0e79c61e807927a163c", "title": "Rethinking Atrous Convolution for Semantic Image Segmentation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "c43d954cf8133e6254499f3d68e45218067e4941", "title": "Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks"}, {"paperId": "8fb82c76d3a8522a30b443c95facc66d30ef5999", "title": "TAC-GAN - Text Conditioned Auxiliary Classifier Generative Adversarial Network"}, {"paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586", "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"}, {"paperId": "ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921", "title": "StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks"}, {"paperId": "ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7", "title": "Conditional Image Synthesis with Auxiliary Classifier GANs"}, {"paperId": "cad4ac0d2389a89cf1955dd4788278c1e8ac1af9", "title": "Learning What and Where to Draw"}, {"paperId": "df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3", "title": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"}, {"paperId": "711683de61ee8d2aa929ec4d5d97d616b8e281d3", "title": "Discrete Variational Autoencoders"}, {"paperId": "372bc106c61e7eb004835e85bbfee997409f176a", "title": "Coupled Generative Adversarial Networks"}, {"paperId": "571b0750085ae3d939525e62af510ee2cee9d5ea", "title": "Improved Techniques for Training GANs"}, {"paperId": "6c7f040a150abf21dbcefe1f22e0f98fa184f41a", "title": "Generative Adversarial Text to Image Synthesis"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "f46714d200d69eb9cb5cce176297b89a3f5e3a2c", "title": "An Introduction to Convolutional Neural Networks"}, {"paperId": "8388f1be26329fa45e5807e968a641ce170ea078", "title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"}, {"paperId": "0875fc92cce33df5cf7df169590dbf0ca00d2652", "title": "Generating Images from Captions with Attention"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "47900aca2f0b50da3010ad59b394c870f0e6c02e", "title": "Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks"}, {"paperId": "4dcdae25a5e33682953f0853ee4cf7ca93be58a9", "title": "LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop"}, {"paperId": "6364fdaa0a0eccd823a779fcdd489173f938e91a", "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation"}, {"paperId": "2dcef55a07f8607a819c21fe84131ea269cc2e3c", "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"}, {"paperId": "66e9dc728b5041271bff0cd6ac0d7eadcd88442f", "title": "Image Super-Resolution Using Deep Convolutional Networks"}, {"paperId": "1eb09fecd75eb27825dce4f964b97f4f5cc399d7", "title": "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "484ad17c926292fbe0d5211540832a8c8a8e958b", "title": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models"}, {"paperId": "872bae24c109f7c30e052ac218b17a8b028d08a0", "title": "A Connection Between Score Matching and Denoising Autoencoders"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "e23c34414e66118ecd9b08cf0cd4d016f59b0b85", "title": "Bidirectional recurrent neural networks"}, {"paperId": "c7a5128b45edb4db9105ec5167210b887617ddf2", "title": "Reverse-time diffusion equation models"}, {"paperId": "cac33f91e59f0a137b46176d74cee55c7010c3f8", "title": "LIII. On lines and planes of closest fit to systems of points in space"}, {"paperId": "4972b88f8f324a4fa18e921f62a9857af2b5fc7b", "title": "Crosslingual Generalization through Multitask Finetuning"}, {"paperId": "735fcf085059f419112b76f7217e7f1407efcbb0", "title": "Latent Video Diffusion Models for High-Fidelity Video Generation with Arbitrary Lengths"}, {"paperId": null, "title": "\u201cDall\u00b7 e mini,\u201d"}, {"paperId": "3f0e435028c6930a751f8c587c9edd0a735c1931", "title": "A survey on generative adversarial network-based text-to-image synthesis"}, {"paperId": "ef4f5a50837a7c1b3e87b9300ffc7ba00d461a0f", "title": "AUTO-ENCODING VARIATIONAL BAYES"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Electra: Pretraining text encoders as discriminators rather than generators"}, {"paperId": "c68796f833a7151f0a63d1d1608dc902b4fdc9b6", "title": "GENERATIVE ADVERSARIAL NETS"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": "5cd47e5d004d75fe773a252bde35b56d5d56ce06", "title": "Conditional generative adversarial nets for convolutional face generation"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "b8af8548bbba1b45ca09e76ede409a2f64e15bbb", "title": "Probabilistic Models"}, {"paperId": "df11660a0ae4ea2b87e6cfb65a2ed3c9f5c7d68b", "title": "The multivariate gaussian distribution"}, {"paperId": "7449f8982f9de36faf9d34bca680444ab827657c", "title": "The Frkhet Distance between Multivariate Normal Distributions"}, {"paperId": null, "title": "\u201cNovelai,\u201d"}, {"paperId": null, "title": "\u201cMidjourney,\u201d"}, {"paperId": null, "title": "Stable diffusion online"}, {"paperId": null, "title": "\u201cComptes rendus hebdomadaires des seances de l\u2019academie des sciences,\u201d"}, {"paperId": null, "title": "\u201cCoyo-700m: Image-text pair dataset,\u201d"}, {"paperId": null, "title": "\u201cCommon crawl,\u201d"}, {"paperId": null, "title": "We compare the performance of different types of TTI models with both visual results and statistical results"}, {"paperId": null, "title": "\u201cStylegan-nada: Clip-guided domain adaptation of image generators,\u201d"}]}