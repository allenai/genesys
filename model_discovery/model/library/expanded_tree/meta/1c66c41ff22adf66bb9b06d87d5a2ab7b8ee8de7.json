{"paperId": "1c66c41ff22adf66bb9b06d87d5a2ab7b8ee8de7", "abstract": "Large language models (LLMs) have received considerable attention recently due to their outstanding comprehension and reasoning capabilities, leading to great progress in many fields. The advancement of LLM techniques also offers promising opportunities to automate many tasks in the telecommunication (telecom) field. After pre-training and fine-tuning, LLMs can perform diverse downstream tasks based on human instructions, paving the way to artificial general intelligence (AGI)-enabled 6G. Given the great potential of LLM technologies, this work aims to provide a comprehensive overview of LLM-enabled telecom networks. In particular, we first present LLM fundamentals, including model architecture, pre-training, fine-tuning, inference and utilization, model evaluation, and telecom deployment. Then, we introduce LLM-enabled key techniques and telecom applications in terms of generation, classification, optimization, and prediction problems. Specifically, the LLM-enabled generation applications include telecom domain knowledge, code, and network configuration generation. After that, the LLM-based classification applications involve network security, text, image, and traffic classification problems. Moreover, multiple LLM-enabled optimization techniques are introduced, such as automated reward function design for reinforcement learning and verbal reinforcement learning. Furthermore, for LLM-aided prediction problems, we discussed time-series prediction models and multi-modality prediction problems for telecom. Finally, we highlight the challenges and identify the future directions of LLM-enabled telecom networks.", "venue": "arXiv.org", "year": 2024, "citationCount": 4, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work presents LLM fundamentals, including model architecture, pre-training, fine-tuning, inference and utilization, model evaluation, and telecom deployment, and introduces LLM-enabled key techniques and telecom applications in terms of generation, classification, optimization, and prediction problems."}, "embedding": {"model": "specter_v2", "vector": [0.2700946629047394, 0.6804066300392151, -0.4999469220638275, 0.13067065179347992, -0.33530670404434204, -0.10075701773166656, 0.44600310921669006, -0.39896297454833984, 0.042656440287828445, 0.4078512489795685, -0.22664155066013336, -0.7583231925964355, 0.1519375741481781, -0.0861535370349884, -0.3325647711753845, 0.2555873990058899, -1.1829946041107178, 0.5774667859077454, -0.3398117125034332, -0.06220576539635658, -0.3511371314525604, -0.42606121301651, -0.5973153710365295, -0.07346957176923752, 0.05863996595144272, 0.7715606093406677, 0.029622023925185204, 1.0695091485977173, -0.40659618377685547, 0.5324203372001648, 0.22095966339111328, -0.38618460297584534, 0.20723624527454376, -0.09852950274944305, -0.3115580677986145, 0.20186784863471985, -0.1578928828239441, -0.39671656489372253, -0.38713985681533813, 0.532503604888916, -0.22972950339317322, 0.23510406911373138, 0.17453733086585999, -0.8822228312492371, 0.07060374319553375, 0.677951991558075, 0.4888480007648468, 0.5769596099853516, -0.3624785244464874, -0.729248046875, 1.4030219316482544, -0.6276828646659851, -0.22170406579971313, 1.618334174156189, 0.4617649018764496, 0.24036291241645813, -0.37125271558761597, -0.7854717969894409, 0.6296722888946533, -0.2870810329914093, -0.32999202609062195, -0.01585296355187893, -0.19021546840667725, -0.2665942907333374, 1.1690057516098022, -0.0754082202911377, 0.06385785341262817, 0.8848739266395569, 0.06936666369438171, 1.0779355764389038, 0.3140076994895935, -0.845411479473114, 0.007877626456320286, 0.05905438959598541, -0.036432936787605286, 0.9382904171943665, -0.367674320936203, 0.50312739610672, -0.6561384201049805, -0.33105766773223877, 0.691602885723114, -0.20965085923671722, 0.18334031105041504, 0.07298395782709122, 0.0748668983578682, 0.7646387219429016, -0.00999424047768116, 0.4492582082748413, -0.28261473774909973, 0.9553675651550293, 0.3880111277103424, 0.7517905235290527, 0.10750407725572586, 0.1377406120300293, -0.24003386497497559, 0.05507761240005493, -0.958382248878479, -0.0686207190155983, -0.08333634585142136, 0.9341433644294739, -0.34430959820747375, 0.6560620665550232, -0.7402984499931335, 0.27223506569862366, 1.5444135665893555, 0.05160574987530708, 0.12747150659561157, -0.7575632929801941, 0.6202009320259094, -1.0595057010650635, 0.39892274141311646, -0.3789716064929962, -0.25436216592788696, -0.3952948749065399, -0.6126015782356262, -0.9467421174049377, -0.6263043880462646, -0.37211599946022034, -0.7304114699363708, 0.5761999487876892, -0.9809505343437195, 0.2771718204021454, 0.14080333709716797, 0.1603596955537796, -0.35981428623199463, 0.8868729472160339, 0.07335692644119263, -0.4341032803058624, 0.4793887138366699, -0.9211707711219788, -0.43717822432518005, -0.982418954372406, 0.3010101914405823, -0.02707524411380291, -0.06840577721595764, -0.2031215876340866, -1.2030620574951172, -0.8497760891914368, -0.49601396918296814, 0.9210997819900513, -0.11765436083078384, 0.38045138120651245, 1.1960935592651367, 0.8357452750205994, -1.0233705043792725, 0.3845473527908325, 0.08168751001358032, -0.33381375670433044, 0.05969198793172836, 0.4690495431423187, 0.748561441898346, -0.1359294354915619, -1.5424193143844604, 0.01850673370063305, 0.02819492295384407, -0.5464088916778564, -0.1824755221605301, -0.01160972099751234, -0.5887445211410522, -0.23761427402496338, 0.11003104597330093, -0.3497522473335266, 1.2708463668823242, -0.0055292644537985325, -1.4945855140686035, 0.18923142552375793, 0.1428757607936859, -0.4796540141105652, 0.4981025457382202, 0.048365890979766846, -0.9441342353820801, -0.23538480699062347, -0.30541831254959106, 0.08122794330120087, 0.6777103543281555, -0.22280146181583405, -0.5342552661895752, 0.7425717115402222, -0.09797056019306183, -0.5006849765777588, 0.18578507006168365, 1.1425907611846924, -0.5600365400314331, -0.37431997060775757, 0.023103835061192513, 0.2754667401313782, -0.7469350695610046, 0.05794158950448036, -0.37368467450141907, -0.2910504639148712, 0.7682194113731384, -0.31097280979156494, 1.0150700807571411, -0.47662878036499023, -1.0742143392562866, 0.24550192058086395, -0.2667980492115021, 0.1254081130027771, -0.8117372393608093, 0.5942332744598389, -0.3035776615142822, 0.3451482057571411, 0.09386908262968063, -0.8723793625831604, 0.004387452732771635, -0.11117208749055862, -0.8239937424659729, -0.42798522114753723, 0.08355025947093964, 0.8394843935966492, -0.5489279627799988, 0.28862953186035156, 0.22345982491970062, 0.04197392240166664, -0.9093785285949707, 1.3190333843231201, -0.6744528412818909, 0.3286222815513611, -0.5582227110862732, -0.2705706059932709, 0.0935230404138565, -0.5415862798690796, 0.519551694393158, 0.14545094966888428, 0.09593487530946732, 0.26338785886764526, -0.22603872418403625, 1.0766900777816772, -0.6545146107673645, 0.5795006155967712, 0.022603845223784447, -0.6401395797729492, 0.5675840973854065, 0.6420164108276367, 0.22735337913036346, -0.40525946021080017, 0.4068934917449951, 0.2331034392118454, -0.606296956539154, 0.09846773743629456, 0.3925892114639282, 0.7080532908439636, -0.33436670899391174, 0.748786985874176, 0.34784403443336487, -0.02928762510418892, 0.713233470916748, 0.074982650578022, 0.39819514751434326, 0.1676834225654602, 0.26756179332733154, 0.36822056770324707, 0.28804534673690796, -1.4568321704864502, -0.16273260116577148, 0.8010547757148743, 0.5089554190635681, 0.44806814193725586, 0.44371339678764343, -0.5032447576522827, -0.10467630624771118, -0.17502261698246002, 0.9516854286193848, 1.056270718574524, -0.25456318259239197, -0.2255709022283554, -0.652127206325531, -0.5423811674118042, -0.16876834630966187, 0.17002345621585846, -0.010713395662605762, 0.2084081768989563, -0.27100157737731934, -1.1812533140182495, 0.8313167691230774, 0.16729870438575745, 0.7430676221847534, -0.5014620423316956, 0.16969391703605652, 0.10937583446502686, 0.04732266813516617, -1.1337827444076538, -0.556566059589386, 0.23890043795108795, -0.4471971392631531, 0.19190546870231628, -0.2730277478694916, 0.21291959285736084, 0.07016565650701523, -0.8674560785293579, 0.47185471653938293, -0.5346043109893799, -0.021183442324399948, 0.3843523859977722, 0.547520101070404, -0.5006409883499146, -1.2331011295318604, -0.14168553054332733, 0.14043790102005005, 0.22437448799610138, 0.04289538785815239, 0.2014331966638565, 0.726379930973053, -0.004216036759316921, 0.20181939005851746, 0.011233925819396973, 0.2961026430130005, -0.1980995088815689, 0.1443811058998108, -0.0031816507689654827, 0.1072150245308876, -0.9489059448242188, 1.21217679977417, 0.3080901801586151, -0.8859507441520691, 0.4982547163963318, -0.7531437873840332, -0.34263646602630615, 0.4978772699832916, -0.43934425711631775, 0.12475595623254776, -1.3399920463562012, 0.3797595500946045, -0.19060645997524261, -0.4895246624946594, 0.3515815734863281, 0.6048341989517212, -0.020729638636112213, -0.31525591015815735, 0.5737079977989197, 0.534778356552124, 0.006783682852983475, 0.3127953112125397, -0.16510654985904694, -0.1845889389514923, -0.03160644322633743, 0.2587423324584961, -0.2889510989189148, -0.027057362720370293, -0.4795292615890503, -0.5191667079925537, 0.13161581754684448, 0.021185889840126038, -0.763609766960144, -0.10958166420459747, -0.6532242894172668, -0.7996920347213745, -0.27184510231018066, -1.00980544090271, -0.1254567950963974, 0.34013527631759644, -0.027243398129940033, -0.48815807700157166, -0.9367376565933228, -1.3324648141860962, -1.2280398607254028, -0.3672744929790497, -0.9155876040458679, 0.021125737577676773, -0.16485676169395447, -0.30140456557273865, -0.7436249256134033, -0.48386386036872864, -0.07646232843399048, 0.9124107360839844, -0.6317800879478455, 1.0955266952514648, 0.2153308391571045, -0.5056607723236084, -0.24875399470329285, 0.019647154957056046, 0.5366359353065491, -0.1154092475771904, 0.30729031562805176, -0.5598411560058594, -0.07774418592453003, -0.6498405337333679, -0.156845822930336, -0.30024707317352295, 0.47784778475761414, 0.9497586488723755, 0.1454414278268814, -0.31281739473342896, 0.2388986498117447, 0.8361301422119141, -0.3860379457473755, -0.1594965159893036, 0.002837191103026271, 0.612852156162262, 0.175902858376503, -0.28026872873306274, 0.7008420825004578, -0.006575382314622402, 0.5363973379135132, -0.041192974895238876, -0.12669336795806885, 0.2157452255487442, -0.6441390514373779, 0.434607595205307, 1.524344563484192, -0.0004397556185722351, -0.5529117584228516, -0.6286883354187012, 0.143752783536911, -1.27451491355896, -0.6334920525550842, 0.7041528224945068, 0.6138903498649597, -0.23453493416309357, 0.2776203155517578, -0.12662501633167267, 0.13942702114582062, 0.8213613033294678, 0.47570183873176575, 0.11692436784505844, -0.9005171656608582, 0.13561567664146423, 0.2507001459598541, 0.15221573412418365, 0.772450864315033, -0.2322331666946411, 0.38028979301452637, 15.199081420898438, 0.9056769609451294, -0.14980341494083405, 0.5003336668014526, 0.5436872243881226, 0.5349456071853638, -0.08326417952775955, -0.15974724292755127, -0.9477515816688538, 0.23656465113162994, 1.6387319564819336, 0.04730480536818504, 0.8204919695854187, -0.024738075211644173, 0.5396568179130554, 0.547524094581604, -0.01779751479625702, 0.6890029311180115, 0.34316158294677734, -1.419070839881897, 0.8382437825202942, 0.3525877594947815, 0.24168702960014343, 0.42219945788383484, 0.7060700058937073, 0.8180884122848511, 0.489124059677124, -0.2662476897239685, 0.753923773765564, 0.20176373422145844, 1.1429316997528076, -0.28620806336402893, 0.32143324613571167, 0.7566601634025574, -0.9771629571914673, -0.40146297216415405, -0.3600584864616394, -1.1650956869125366, 0.4821547865867615, 0.2672664523124695, -0.3120054304599762, -0.16139237582683563, -0.6620132923126221, 0.6454642415046692, 0.5451024174690247, 0.26367223262786865, -0.2675577998161316, 1.0304700136184692, -0.014368008822202682, -0.0692744329571724, 0.23552477359771729, 0.09459233283996582, 0.2518700063228607, -0.2851717174053192, 0.3283466398715973, -0.4385855495929718, 0.4824196994304657, 0.37843525409698486, -0.45405513048171997, -0.38316085934638977, -0.1577436327934265, -0.6223256587982178, -0.04854471981525421, 0.3738262951374054, 0.6785222291946411, 0.6470878720283508, -0.5442677736282349, 0.2429773211479187, 0.19267518818378448, 0.7214086651802063, -0.7034018635749817, 0.12580031156539917, 0.543307900428772, -0.3284778594970703, -0.11216827481985092, 0.4011797308921814, 0.07211332768201828, -0.2835848927497864, -0.8890821933746338, -0.2741963565349579, 0.17616848647594452, -0.9830135703086853, -0.7824413776397705, 1.0414760112762451, -0.6652570962905884, -0.7268497943878174, 0.1297934502363205, -0.8106817007064819, 0.11376065015792847, 0.7373547554016113, -1.5872079133987427, -0.8619691729545593, 0.6486439108848572, -0.2598664164543152, -0.24361005425453186, -0.5597074627876282, 1.3482983112335205, 0.3373330235481262, -0.5526306629180908, -0.002946047578006983, 0.12611591815948486, 0.058759622275829315, -0.5212823748588562, -0.2706742584705353, 0.9329209327697754, 0.35570165514945984, -0.05120880901813507, -0.15514011681079865, -0.19480915367603302, 0.2887919843196869, -0.09625829756259918, -0.6505730152130127, 0.6691644191741943, -0.6098730564117432, -0.00670345313847065, -1.0598570108413696, -0.053931158035993576, 0.400783896446228, 0.12041418254375458, -0.18657805025577545, 0.12222248315811157, -0.00981106050312519, -0.25543954968452454, -0.02089080959558487, -0.4908777177333832, 0.1896807700395584, 0.14963889122009277, -0.8454931378364563, 0.2967742085456848, 0.030142419040203094, 0.5094186067581177, -0.6926762461662292, -0.13492293655872345, -0.39771929383277893, -0.0293709859251976, -0.003111105877906084, 0.6393972635269165, -0.7207178473472595, 0.525871992111206, 0.9058613777160645, -0.2649520933628082, -0.5520381331443787, -0.23616480827331543, -1.5939302444458008, -0.11770928651094437, -0.002566947601735592, 0.8331031203269958, -0.6397753953933716, 0.5293604135513306, 0.4164380431175232, 0.7008433938026428, -0.44884514808654785, -0.5986757874488831, -0.432466059923172, -0.33660411834716797, -1.0084576606750488, 0.4721114933490753, -0.3392288386821747, -0.36885735392570496, -0.05394814535975456, -0.17437343299388885, 0.8602795004844666, -0.12721087038516998, -0.37007811665534973, 0.37837108969688416, -0.19152653217315674, -0.3903595507144928, -0.44574061036109924, -0.4484573304653168, -1.6853381395339966, 0.2974427044391632, -0.9883081316947937, -0.1215602308511734, -0.7894808650016785, -0.6057891845703125, -0.1909896433353424, -0.3311038613319397, -0.2888529896736145, 0.9568883180618286, -0.6240245699882507, -0.25249648094177246, -0.5778893232345581, -0.3964103162288666, 0.7396553754806519, 0.7360905408859253, -0.7192847728729248, 0.3842703104019165, 0.7148566842079163, 0.385656476020813, 0.21119946241378784, 0.499215692281723, -0.5109015703201294, -0.824073851108551, -1.0024001598358154, 0.14452706277370453, 0.25858330726623535, -0.0006533093983307481, -0.8536646366119385, 0.22599196434020996, -0.16610869765281677, -0.5569641590118408, 0.44412457942962646, 0.47120630741119385, -1.0618327856063843, -0.44037166237831116, 0.3176572620868683, -0.9535456895828247, -0.07614853978157043, 0.06271445751190186, -0.14153239130973816, -0.28410667181015015, 0.7998580932617188, 0.013981249183416367, -0.6957176923751831, -0.2538912296295166, 0.7856400012969971, -1.0564814805984497, -0.02842724695801735, -0.00474547129124403, 0.012306919321417809, -0.635244607925415, -0.9049540162086487, -0.38369131088256836, 0.4080549478530884, -0.891186535358429, 1.3017572164535522, 0.14680007100105286, -0.9546797275543213, -0.08953110873699188, 0.5940979719161987, -0.34346696734428406, -0.8929606080055237, 0.0053074536845088005, 0.40901991724967957, -0.2879699766635895, 0.7895529270172119, 0.2999021112918854, 0.6178792119026184, -0.7445237636566162, -0.2831480801105499, 1.0257983207702637, -0.6919355392456055, 0.16243864595890045, 1.0232564210891724, -0.8198236227035522, -1.2082579135894775, 0.40459826588630676, -0.974990725517273, -0.49670636653900146, -0.6236003637313843, 0.22959817945957184, -0.04380608722567558, -0.411143034696579, 0.11757106333971024, -0.13365815579891205, 0.10097808390855789, 0.3058687150478363, -0.5984992384910583, 0.27842244505882263, -0.7711025476455688, -0.32485881447792053, 0.9465430378913879, 0.5936724543571472, -0.6018327474594116, -0.7829136252403259, -0.29568740725517273, -0.42255792021751404, -0.03792624548077583, 0.14839906990528107, -0.5018343925476074, -0.8335955142974854, 0.9619359970092773, 0.5559349060058594, 0.5133712887763977, -0.006093590520322323, -0.42947280406951904, 0.3013828694820404, 0.37317320704460144, 0.8416610956192017, -0.8307941555976868, -0.6209160685539246, 1.2802741527557373, 1.1331040859222412, -0.722690999507904, 0.005925060715526342, -0.6375096440315247, -0.5778598785400391, 1.0360177755355835, 0.05985649675130844, 0.3570851981639862, 1.0996745824813843, 0.11488252878189087, 0.265490859746933, 0.5157896280288696, -1.138224720954895, -0.3055640459060669, 0.4184775948524475, 0.9910898804664612, 0.6626840829849243, 0.6003101468086243, 0.2614173889160156, 0.9043843150138855, 0.21241138875484467, 0.457719087600708, 0.784816563129425, 0.46262702345848083, -0.10202930867671967, -0.34640562534332275, -0.11894624680280685, 0.7660243511199951, -0.6185234189033508, -0.5033366084098816, 0.3167955279350281, 0.3790816068649292, 0.14398521184921265, 0.8797762393951416, 0.6954786777496338, -0.20347848534584045, 0.45140013098716736, -0.10693901777267456, 0.44822457432746887, -0.5417400598526001, 0.15819799900054932, -0.12030059099197388, -0.29843905568122864, 0.05769580975174904, -0.19261163473129272, -0.2814089357852936, -0.3278898000717163, -0.31173110008239746, 0.31324508786201477, 0.5220680236816406, 0.0749136209487915, 1.0438822507858276, 0.5804819464683533, 0.5804188847541809, 0.21488909423351288, -0.30738508701324463, -0.48723068833351135, -0.5750179290771484, -0.6503480076789856, -1.0113896131515503, -0.027143962681293488, 0.06452803313732147, -0.25552240014076233, -0.5175519585609436]}, "authors": [{"authorId": "2302316320", "name": "Hao Zhou"}, {"authorId": "11577774", "name": "Chengming Hu"}, {"authorId": "2283264350", "name": "Ye Yuan"}, {"authorId": "2301404967", "name": "Yufei Cui"}, {"authorId": "2302296620", "name": "Yili Jin"}, {"authorId": "2243412535", "name": "Can Chen"}, {"authorId": "107747459", "name": "Haolun Wu"}, {"authorId": "2212193383", "name": "Dun Yuan"}, {"authorId": "2302565436", "name": "Li Jiang"}, {"authorId": "2302271437", "name": "Di Wu"}, {"authorId": "2243903453", "name": "Xue Liu"}, {"authorId": "2288317098", "name": "Charlie Zhang"}, {"authorId": "2302210920", "name": "Xianbin Wang"}, {"authorId": "2302284624", "name": "Jiangchuan Liu"}], "references": [{"paperId": "bed6d407ac43102039de6d2fb4a986cbcd6a8f49", "title": "A Large-Scale Dataset of 4G, NB-IoT, and 5G Non-Standalone Network Measurements"}, {"paperId": "13f44206745d20971ca271401eff6772aa80de80", "title": "SaulLM-7B: A pioneering Large Language Model for Law"}, {"paperId": "7a57a52e1a273799bed7c882bc12177ca89609ab", "title": "Large Multi-Modal Models (LMMs) as Universal Foundation Models for AI-Native Wireless Systems"}, {"paperId": "78875987dc674fc556873df037cf114f04932e80", "title": "When Large Language Model Agents Meet 6G Networks: Perception, Grounding, and Alignment"}, {"paperId": "00e18c603e60d861c4e99c541e4d65ef442d5945", "title": "LLM in a flash: Efficient Large Language Model Inference with Limited Memory"}, {"paperId": "81061c12d722e5942d881a20f078eb06f094e055", "title": "EdgeFM: Leveraging Foundation Model for Open-set Learning on the Edge"}, {"paperId": "7ea6064f68911d7422f3d8666c45fe58cc6d0ee7", "title": "CloudEval-YAML: A Practical Benchmark for Cloud Configuration Generation"}, {"paperId": "4ae95f6dcdf5d4e2269869f23b205b358f2b7b17", "title": "AI-native Interconnect Framework for Integration of Large Language Model Technologies in 6G Systems"}, {"paperId": "49c1d6c09b482bd7744f42c7ddc8e7be3c5c722a", "title": "LLM-Based Policy Generation for Intent-Based Management of Applications"}, {"paperId": "5f86c548675f54299a0a1f7abe2b6ca9d3a3296c", "title": "TeleQnA: A Benchmark Dataset to Assess Large Language Models Telecommunications Knowledge"}, {"paperId": "9e540662619327a3056d9e40bb58058868f6f805", "title": "Prompt Distillation for Efficient LLM-based Recommendation"}, {"paperId": "6ca16c1c2c60ceda87242c8f8e522d12cc4a13bc", "title": "Eureka: Human-Level Reward Design via Coding Large Language Models"}, {"paperId": "49f302e9a76eb39c88fcd861bdd0d954bd3d76b0", "title": "Large Language Model for Multi-objective Evolutionary Optimization"}, {"paperId": "f45f85fa1beaa795c24c4ff86f1f2deece72252f", "title": "A decoder-only foundation model for time-series forecasting"}, {"paperId": "44576a2c6337f41019f29b055d8c7f7f5891be92", "title": "AgentCF: Collaborative Learning with Autonomous Language Agents for Recommender Systems"}, {"paperId": "123acfbccca0460171b6b06a4012dbb991cde55b", "title": "Large Language Models Are Zero-Shot Time Series Forecasters"}, {"paperId": "37a30e97ae043075f09738984a59991ff20ecf0c", "title": "OptiMUS: Optimization Modeling Using MIP Solvers and large language models"}, {"paperId": "09f9d0cbff77a8b12b271a469552ec35bced1fd8", "title": "Towards Optimizing with Large Language Models"}, {"paperId": "32b15b02bd2640346678a773079c5d42190bbac9", "title": "TimeGPT-1"}, {"paperId": "16f01c1b3ddd0b2abd5ddfe4fdb3f74767607277", "title": "Time-LLM: Time Series Forecasting by Reprogramming Large Language Models"}, {"paperId": "ccd6f8b6544f112de632e49bfbe592a0a654537d", "title": "DriveGPT4: Interpretable End-to-end Autonomous Driving via Large Language Model"}, {"paperId": "54814744b42b06c855c97b23de1366e0bcbe775a", "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)"}, {"paperId": "d34ca9843a08248e1be259626f02e0a892010c26", "title": "Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities"}, {"paperId": "4ea8e22236681a09225ee3f8ff5fffd934ec9bae", "title": "From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference"}, {"paperId": "32479758dc9ff9820828a12aa7f3d066f187dc1c", "title": "LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models"}, {"paperId": "5d95d2b9bc203447000bd201ceabe67404eedeeb", "title": "Using Large Language Models to Generate, Validate, and Apply User Intent Taxonomies"}, {"paperId": "0c72450890a54b68d63baa99376131fda8f06cf9", "title": "The Rise and Potential of Large Language Model Based Agents: A Survey"}, {"paperId": "6b4da2023c3a11aea6e3ccb9ab13e594833c47eb", "title": "Self-Refined Large Language Model as Automated Reward Function Designer for Deep Reinforcement Learning in Robotics"}, {"paperId": "5ba398a4e64c688de82c5b8f26583d86269a3781", "title": "Making Network Configuration Human Friendly"}, {"paperId": "279c798fd53c8dc84044273d08b6a060dbe9f702", "title": "Toward Reproducing Network Research Results Using Large Language Models"}, {"paperId": "00e889fcfaf4396a20f37f681cf8b14f3e878879", "title": "LLMCad: Fast and Scalable On-device Large Language Model Inference"}, {"paperId": "f8a2dca1e8fe56e698984c077f7ff58d8ca867e9", "title": "Large Language Models as Optimizers"}, {"paperId": "5001abb0bb5a3814d726d2ef5105f23e40360044", "title": "When Configuration Verification Meets Machine Learning: A DRL Approach for Finding Minimum k-Link Failures"}, {"paperId": "558f81f3fb2284d9561482143aba363c624de559", "title": "Diagnosing Infeasible Optimization Problems Using Large Language Models"}, {"paperId": "f0950a3f27c0fefffba60ae1c9a8ee360d5eb55f", "title": "Instruction Tuning for Large Language Models: A Survey"}, {"paperId": "663dc434fabc1cf1d3e85fff3f7ddcd313035d18", "title": "LLM4TS: Aligning Pre-Trained LLMs as Data-Efficient Time-Series Forecasters"}, {"paperId": "06c7c6d2dacbebd4157180f6d678b79206aeb9e3", "title": "Big AI Models for 6G Wireless Networks: Opportunities, Challenges, and Research Directions"}, {"paperId": "4388f8a34b46bb3e07f75619d4592439d784cad5", "title": "Enhancing Network Management Using Code Generated by Large Language Models"}, {"paperId": "83c48aa341850af478247e3b34ba1ee1db9f1236", "title": "Meta-Transformer: A Unified Framework for Multimodal Learning"}, {"paperId": "b8b92b06d460c8f3861ea6f687d0136fe60b60ae", "title": "Leveraging Large Language Models for the Generation of Novel Metaheuristic Optimization Algorithms"}, {"paperId": "fdb5b1ade3dfcdb3f7deb62392416942c0effe65", "title": "The Power of Large Language Models for Wireless Communication System Development: A Case Study on FPGA Platforms"}, {"paperId": "105c11cd7920a606bee6048f129e3440cfba58fd", "title": "NetGPT: An AI-Native Network Architecture for Provisioning Beyond Personalized Generative Services"}, {"paperId": "3d60156d0184816799fce3b3d49d22a047b789e3", "title": "What do LLMs need to Synthesize Correct Router Configurations?"}, {"paperId": "4c55dd37ab4c41565226a3c8194166d7412b0a02", "title": "Large Language Models Empowered Autonomous Edge AI for Connected Intelligence"}, {"paperId": "888728745dbb769e29ed475d4f7661eebe1a71cf", "title": "A Survey on Evaluation of Large Language Models"}, {"paperId": "e3b6993e041c088dbc24b1c9efafbf358b46e2ef", "title": "Heuristic Algorithms for RIS-assisted Wireless Networks: Exploring Heuristic-aided Machine Learning"}, {"paperId": "688fc1e744877c3a68f306443042f016196ce98a", "title": "The Perils of Trial-and-Error Reward Design: Misdesign through Overfitting and Invalid Task Specifications"}, {"paperId": "0e1c60dc4119589bbbf02da26f73f4fd6330be4b", "title": "Revolutionizing Cyber Threat Detection With Large Language Models: A Privacy-Preserving BERT-Based Lightweight Model for IoT/IIoT Devices"}, {"paperId": "6a3ed569d47b4ea08aca4f69ec7da5e8d87734b0", "title": "Understanding Telecom Language Through Large Language Models"}, {"paperId": "af705d648b5b16daa3dcc593bc593f2574d76c07", "title": "Grammar Prompting for Domain-Specific Language Generation with Large Language Models"}, {"paperId": "27cb586fcea5ec076b984750e9c77f0d7fc976e5", "title": "AlignScore: Evaluating Factual Consistency with A Unified Alignment Function"}, {"paperId": "ce913026f693101e54d3ab9152e107034d81fce1", "title": "Holistic Evaluation of Language Models"}, {"paperId": "32ac52069e562d4f900afee70bdca63f53461481", "title": "QLoRA: Efficient Finetuning of Quantized LLMs"}, {"paperId": "506f571f4c3ef3c5c52761cd6b99400acd22ebd6", "title": "Observations on LLMs for Telecom Domain: Capabilities and Limitations"}, {"paperId": "5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200", "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints"}, {"paperId": "546d0624adfc6e18fb87d8cc77e7705bb9ea7445", "title": "LIMA: Less Is More for Alignment"}, {"paperId": "2f3822eb380b5e753a6d579f31dfc3ec4c4a0820", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models"}, {"paperId": "7ed0faa6720cd176d57badbc0455af31a03f080c", "title": "Towards Expert-Level Medical Question Answering with Large Language Models"}, {"paperId": "3db1219429c3f04e88347d41269bdc83c457fbf9", "title": "Symbol tuning improves in-context learning in language models"}, {"paperId": "d9f7e21b60d65650456132966f46093e9649d4fd", "title": "Smart Home Energy Management: VAE-GAN Synthetic Dataset Generator and Q-Learning"}, {"paperId": "585f8b9725f5f5e5495c3508d39f70d1c053e190", "title": "FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance"}, {"paperId": "d50f023fe0921cabdd6d053c377cdd26c715994c", "title": "Tabi: An Efficient Multi-Level Inference System for Large Language Models"}, {"paperId": "62176de125738e3b95850d1227bac81fd646b78e", "title": "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models"}, {"paperId": "93752cae0d4ecd2d09d6660feb3c1860af973f18", "title": "Can Large Language Models Transform Computational Social Science?"}, {"paperId": "9e8cb8c91a0acb6e661b58ad724aa758490f2bea", "title": "Instruction Tuning with GPT-4"}, {"paperId": "c61d54644e9aedcfc756e5d6fe4cc8b78c87755d", "title": "A Survey of Large Language Models"}, {"paperId": "83edcfbb206ddad38a971d605da09390604248ea", "title": "BloombergGPT: A Large Language Model for Finance"}, {"paperId": "fd746b2500cfcadf4af180ba7d8be8fedbcb8fab", "title": "Efficient Parallel Split Learning over Resource-constrained Wireless Edge Networks"}, {"paperId": "61f7025be5cb03b92d61e14c90459b1242e9b124", "title": "A Survey on Model-Based, Heuristic, and Machine Learning Optimization Approaches in RIS-Aided Wireless Networks"}, {"paperId": "4a7f6c4e71e20311ade4e76e8d0945d499c31fcd", "title": "ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge"}, {"paperId": "574beee702be3856d60aa482ec725168fe64fc99", "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4"}, {"paperId": "0671fd553dd670a4e820553a974bc48040ba0819", "title": "Reflexion: language agents with verbal reinforcement learning"}, {"paperId": "da3aca9d7b50da823f669c983edeb60445720fe0", "title": "The Learnability of In-Context Learning"}, {"paperId": "154493f69d7db3d49da0e51df0192c6ad5f1724a", "title": "Larger language models do in-context learning differently"}, {"paperId": "16c64f74ce0e6a59b0709c0d8e66596a5bc08ed6", "title": "The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset"}, {"paperId": "76b19363b10d7ea783e4a6494eae40d73c8e9628", "title": "Parameter-efficient fine-tuning of large-scale pre-trained language models"}, {"paperId": "d318e0169f649656c71f02a1f84194a734fe1962", "title": "Reward Design with Language Models"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "5b7f5488c380cf5085a5dd93e993ad293b225eee", "title": "One Fits All: Power General Time Series Analysis by Pretrained LM"}, {"paperId": "e8455abf71a686aa3e3a9f6d2b872157db371afa", "title": "BFCN: A Novel Classification Method of Encrypted Traffic Based on BERT and CNN"}, {"paperId": "720574165a68bd6296fcad998d0157cd67ae12c7", "title": "Using the AraBERT Model for Customer Satisfaction Classification of Telecom Sectors in Saudi Arabia"}, {"paperId": "7249b119141aa7129b8291f5b529104c7a6fa959", "title": "Knowledge Transfer and Reuse: A Case Study of Ai-Enabled Resource Management in RAN Slicing"}, {"paperId": "e4f8cb7bb933d95bec8d6eaeeb9d1815ed095f21", "title": "Benchmarking Large Language Models for Automated Verilog RTL Code Generation"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "663a41c866d49ce052801fbc88947d39764cad29", "title": "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them"}, {"paperId": "99832586d55f540f603637e458a292406a0ed75d", "title": "ReAct: Synergizing Reasoning and Acting in Language Models"}, {"paperId": "1d26c947406173145a4665dd7ab255e03494ea28", "title": "GLM-130B: An Open Bilingual Pre-trained Model"}, {"paperId": "2a0456b0408cd4c33f2ff4400374e7be2497a362", "title": "Repairing Bugs in Python Assignments Using Large Language Models"}, {"paperId": "863171ed35ca0035074f73bb202b153cc346f2f3", "title": "PromptCast: A New Prompt-Based Learning Paradigm for Time Series Forecasting"}, {"paperId": "007fe51fddfae031570f2d69e67dc67e1fe33621", "title": "What does a platypus look like? Generating customized prompts for zero-shot image classification"}, {"paperId": "a9162d4af78b955c93e444a5a9fb0c2177add92a", "title": "Toward Intelligent Millimeter and Terahertz Communication for 6G: Computer Vision-Aided Beamforming"}, {"paperId": "b9ae207757ab5c74ac545bf497013845318ba743", "title": "Terahertz communications can work in rain and snow: impact of adverse weather conditions on channels at 140 GHz"}, {"paperId": "2a7ae3e98357569c41424dacd60c62d3df78a0db", "title": "Limitations of Language Models in Arithmetic and Symbolic Induction"}, {"paperId": "6135ef80c249323c95922f9fd44cc562a24f62f7", "title": "Joint Sensing and Communications for Deep Reinforcement Learning-based Beam Management in 6G"}, {"paperId": "fbac870d10c86b652e977cc364f7a632eaf45d54", "title": "Federated Deep Reinforcement Learning for Resource Allocation in O-RAN Slicing"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "5437e8adab596d7294124c0e798708e050e25321", "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"}, {"paperId": "7502cf8c1c79f33b8880d62d0fb40ae81db9c3e3", "title": "Great Power, Great Responsibility: Recommendations for Reducing Energy for Training Language Models"}, {"paperId": "3fae8c26d383979b24dbfdb81306bbcc6b222da5", "title": "The Evolution of Telecom Business, Economy, Policies and Regulations"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "456a70485aafc12dfed4fb7354668d72aae9b658", "title": "SecureBERT: A Domain-Specific Language Model for Cybersecurity"}, {"paperId": "d6c73f758b05f38529c1a96cab7e908a2047dabd", "title": "Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language Model"}, {"paperId": "38115e80d805fb0fb8f090dc88ced4b24be07878", "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "b32a6f6ef7dd775e0f876b4713ceccebc56e651e", "title": "A systematic evaluation of large language models of code"}, {"paperId": "29ed68d701f8450853938827b5124c9613c56aff", "title": "ET-BERT: A Contextualized Datagram Representation with Pre-training Transformers for Encrypted Traffic Classification"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "d827388ec32e4da0fce0beefe21fd97da83d4485", "title": "Edge-IIoTset: A New Comprehensive Realistic Cyber Security Dataset of IoT and IIoT Applications for Centralized and Federated Learning"}, {"paperId": "fd558b31f012823189b48cfac4020db418f0a8c3", "title": "Multi-cell Multi-beam Prediction using Auto-encoder LSTM for mmWave systems"}, {"paperId": "1847975de1943ead8f899121d5ac8939acdd9520", "title": "AFB: Improving Communication Load Forecasting Accuracy with Adaptive Feature Boosting"}, {"paperId": "a2502d2cd7144c5e2bc1d0d7ec37d2c84b37d381", "title": "ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic"}, {"paperId": "02ea9246093c08d024aff6b089e5734af8b08af6", "title": "CyBERT: Cybersecurity Claim Classification by Fine-Tuning the BERT Language Model"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "95de1a7e06a8ed17d3b0790494a4db37b2a6d017", "title": "Learning From Peers: Deep Transfer Reinforcement Learning for Joint Radio and Cache Resource Allocation in 5G RAN Slicing"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "747497c505adf731e83db4046c5be3b152793c4f", "title": "RAN Resource Slicing in 5G Using Multi-Agent Correlated Q-Learning"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "0adec918885dff698acf359988ed79a543157f80", "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "3544650f12a05cf4ed3bf2f7e22fc5c02fcabf50", "title": "Pretrained Transformers as Universal Computation Engines"}, {"paperId": "ad9f226d9fd37626618efb9b8ce758d488e11780", "title": "Q-Meter: Quality Monitoring System for Telecommunication Services Based on Sentiment Analysis Using Deep Learning"}, {"paperId": "efa31ddf6082bb4a9e40ad9059760bf3f1c474a0", "title": "Vision-Aided 6G Wireless Communications: Blockage Prediction and Proactive Handoff"}, {"paperId": "040ad14a2c97e51510889ae6a0c3c23b29da801d", "title": "TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale Language Models"}, {"paperId": "59641c10ed7431a3cf841f308367dc2dc0281b74", "title": "What Makes Good In-Context Examples for GPT-3?"}, {"paperId": "19f693cdb025dbb21212a680b1afc2df5efd17bf", "title": "Apply transfer learning to cybersecurity: Predicting exploitability of vulnerabilities by description"}, {"paperId": "72111ee13f68f98261a2e75cff5feb4fc2474a20", "title": "Power Scaling Law Analysis and Phase Shift Optimization of RIS-Aided Massive MIMO Systems With Statistical CSI"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "21426451ae01e3aafe5f23128097b1e3de27ab90", "title": "Optimizing Coverage and Capacity in Cellular Networks using Machine Learning"}, {"paperId": "a0a91bda925635e1cd5a6e5fcae61b679c3053c9", "title": "Two decades of blackbox optimization applications"}, {"paperId": "e532c3ab98d063d6bc999391c8afe7038762139c", "title": "Edge-Network-Assisted Real-Time Object Detection Framework for Autonomous Driving"}, {"paperId": "a2f38d03fd363e920494ad65a5f0ad8bd18cd60b", "title": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing"}, {"paperId": "44734e1e7df1e7f71673b83d21323a510b61bfaa", "title": "Cellular Traffic Load Prediction with LSTM and Gaussian Process Regression"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "4c8e5684396df3dd1f63a21018ae9cafa031e723", "title": "openwifi: a free and open-source IEEE802.11 SDR implementation on SoC"}, {"paperId": "01203341a8b5b7df21dec5359afe8cc388786ebf", "title": "Wiki-40B: Multilingual Language Model Dataset"}, {"paperId": "90c9c6562b435dc8a97cda47b24789047bd2c352", "title": "Code Smells and Refactoring: A Tertiary Systematic Review of Challenges and Observations"}, {"paperId": "a080e5a6fe7d0468d3f8c38ea4f168c6009f844a", "title": "Deep Learning for Fading Channel Prediction"}, {"paperId": "f9296d55d45c2ce271155f5aa818058fc24dea0b", "title": "FlowPrint: Semi-Supervised Mobile-App Fingerprinting on Encrypted Network Traffic"}, {"paperId": "839fe3534ea76b1d18224632e06a41101385630c", "title": "Channel State Information Prediction for 5G Wireless Communications: A Deep Learning Approach"}, {"paperId": "dc52b09089704ebd6f471177474bc29741c50023", "title": "Fast Transformer Decoding: One Write-Head is All You Need"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "00c957711b12468cb38424caccdf5291bb354033", "title": "ZeRO: Memory optimizations Toward Training Trillion Parameter Models"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "7a15950dc71079285a4eaf195de5aadd87c41b40", "title": "Fine-Tuning Language Models from Human Preferences"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "ffa6396d0749697fc11e24a5d9ce53f8bf10c1fc", "title": "6G Wireless Networks: Vision, Requirements, Architecture, and Key Technologies"}, {"paperId": "670aa1e6dbc74bb3c1207a8c6e3d88a8cf190a21", "title": "Position Prediction Based Fast Beam Tracking Scheme for Multi-User UAV-mmWave Communications"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "f6a1b4c87bc5751e0396f912105658ff8829707a", "title": "ThreatZoom: neural network for automated vulnerability mitigation"}, {"paperId": "156d217b0a911af97fa1b5a71dc909ccef7a8028", "title": "SciBERT: A Pretrained Language Model for Scientific Text"}, {"paperId": "8ce33519ef65f74f2a14a339f565f3a0ff5e02b4", "title": "Toward Intelligent Network Optimization in Wireless Networking: An Auto-Learning Framework"}, {"paperId": "d79a26226393f687ddbc375e32055b40b8ad8d38", "title": "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"}, {"paperId": "e73bd7f9bdc262b9b7fb60ca0d5230d3ab0fad5e", "title": "Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates"}, {"paperId": "88ad983ffdc8bb6c2a88e6237ab875a6a494d62b", "title": "Fractional Programming for Communication Systems\u2014Part I: Power Control and Beamforming"}, {"paperId": "3136a798a0bf31e6e924eb2f78a90f71d089ca4a", "title": "Deep Fingerprinting: Undermining Website Fingerprinting Defenses with Deep Learning"}, {"paperId": "59094d64844ee21e32560fb08db6d53cc3af0c51", "title": "Inverse Reward Design"}, {"paperId": "938f6ef7eed095919e6a482c7f1836a01d62db4b", "title": "Google Vizier: A Service for Black-Box Optimization"}, {"paperId": "2adaf352b4ea1ada8f2e29200cfda327004a9f4c", "title": "Enhancing QoE-Aware Wireless Edge Caching With Software-Defined Wireless Networks"}, {"paperId": "68777fd0a8e2f3e89d5b56e07c6772ca9bdfbc15", "title": "A comparative analysis of optimization solvers"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd", "title": "Deep Reinforcement Learning from Human Preferences"}, {"paperId": "2646857d350689ae5431ffc31e59bf5e100c306e", "title": "A Survey on QoE-oriented Wireless Resources Scheduling"}, {"paperId": "9a6c177e000b03a832b4210a44c6a8187594068f", "title": "Automated Moving Object Classification in Wireless Multimedia Sensor Networks"}, {"paperId": "dd95f96e3322dcaee9b1e3f7871ecc3ebcd51bfe", "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset"}, {"paperId": "e177365c0dd642341469ba2f045405646c5dbb79", "title": "CVXPY: A Python-Embedded Modeling Language for Convex Optimization"}, {"paperId": "28862175a0426761c4f41fdbbec5b244026c4010", "title": "Characterization of Encrypted and VPN Traffic using Time-related Features"}, {"paperId": "93badd5d3a0e4b885ad00ba0ca7f3cac360b487b", "title": "A General Approach to Network Configuration Analysis"}, {"paperId": "1e880ec81c962a7c6208821573e7ee86529a99fb", "title": "Context-Aware QoE Modelling, Measurement, and Prediction in Mobile Computing Systems"}, {"paperId": "0460f67924366bf46ed37f2ed3adacdfe6fa81ff", "title": "Independent comparison of popular DPI tools for traffic classification"}, {"paperId": "68bf22a988c4199b28fa36a4d23b039ce38207b4", "title": "A Survey of Software-Defined Networking: Past, Present, and Future of Programmable Networks"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "9825ff6538bd4890701f62b0ccd64b70c7ddff67", "title": "Visual-LLM Zero-Shot Classification"}, {"paperId": "7a29f47f6509011fe5b19462abf6607867b68373", "title": "GPT-4V(ision) System Card"}, {"paperId": "41c9455e4f01adc757269854575070a9c4c93ec7", "title": "Large Language Models for Telecom: The Next Big Thing?"}, {"paperId": "2db77485736cf29778a4464fe500a289bd46e7ac", "title": "ChatGPT as a Factual Inconsistency Evaluator for Abstractive Text Summarization"}, {"paperId": "b7ab7a91584a97a93d09936f079019ccce008d35", "title": "Cooperative Hierarchical Deep Reinforcement Learning based Joint Sleep, Power, and RIS Control for Energy-Efficient HetNet"}, {"paperId": "fb0b5df8d5a17e2f26501aea1c5c686a27f72ad5", "title": "Weather-Aware Fiber-Wireless Traffic Prediction Using Graph Convolutional Networks"}, {"paperId": "35f38cfde36ab86ba4400e73cc3f8b22bba31458", "title": "DialSummEval: Revisiting Summarization Evaluation for Dialogues"}, {"paperId": "467d4468f9187e39da22275ee844b186bb73142b", "title": "An Attack Detection Framework Based on BERT and Deep Learning"}, {"paperId": null, "title": "\u201cBidirectional encoder representations from transformers (bert) for question answering in the telecom domain,\u201d"}, {"paperId": null, "title": "\u201cNatural language processing model for log analysis to retrieve solutions for troubleshooting processes,\u201d"}, {"paperId": "eede75be4acee533db939b5bef9fb82e72e66e91", "title": "Comparison of Machine Learning Techniques Applied to Traffic Prediction of Real Wireless Network"}, {"paperId": "a03aa43a6326589ad9bbd6ca761c9dde279e3d00", "title": "TSCRNN: A novel classification scheme of encrypted traffic based on flow spatiotemporal features for efficient management of IIoT"}, {"paperId": "861df6a3727446d2c8f4a78f51224ca64eb9110d", "title": "Explicable Reward Design for Reinforcement Learning Agents"}, {"paperId": "d7d185da8e12bcd2e50924001cc4555a16579018", "title": "THE AUTOMATED MACHINE LEARNING CLASSIFICATION APPROACH ON TELCO TROUBLE TICKET DATASET"}, {"paperId": "5bad2aee51444810d861eae8a7ec38091c8596dc", "title": "Beyond Throughput: The Next Generation a 5G Dataset with Channel and Context Metrics"}, {"paperId": null, "title": "\u201cThreatzoom: Hierarchical neural network for cves to cwes classification,\u201d"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "\u201cNetcom-plete: Practical network-wide configuration synthesis with autocom-pletion,\u201d"}, {"paperId": null, "title": "\u201cZero-shot learn-ing\u2014a comprehensive evaluation of the good, the bad and the ugly,\u201d"}, {"paperId": "c8442541a445e5dc9a953d87c16e9633de4df72c", "title": "Distributed Base Station Association and Power Control for Heterogeneous Cellular Networks"}, {"paperId": "ef1224f0accb548fb82810b7343f9eba78843729", "title": "Metaheuristics and Applications to Optimization Problems in Telecommunications"}, {"paperId": "97efafdb4a3942ab3efba53ded7413199f79c054", "title": "Reinforcement Learning: An Introduction"}, {"paperId": null, "title": "\u201cIntegrating telecommunications-specific language models into a trouble report retrieval approach,\u201d"}, {"paperId": null, "title": "in-context by gradient descent"}, {"paperId": null, "title": "\u201cPalm: Scaling"}, {"paperId": null, "title": "\u201cReconfigurable intelligent surface aided massive MIMO systems with low-resolution"}, {"paperId": null, "title": "\u201cQualcomm brings the best of on-device ai to more smartphones with snapdragon 8s gen 3,\u201d"}, {"paperId": null, "title": "\u201cTransformers learn in-context 46"}, {"paperId": null, "title": "\u201cCost estimation of using gpt-3 for real applications,\u201d"}]}