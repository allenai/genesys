{"paperId": "15c19249814219de76ba92e8aa40a05f181c7648", "abstract": "With the advent of pre-trained language models (LMs), increasing research efforts have been focusing on infusing commonsense and domain-specific knowledge to prepare LMs for downstream tasks. These works attempt to leverage knowledge graphs, the de facto standard of symbolic knowledge representation, along with pre-trained LMs. While existing approaches leverage external knowledge, it remains an open question how to jointly incorporate knowledge graphs represented in varying contexts \u2014 from local (e.g., sentence), document-level, to global knowledge, to enable knowledge-rich and interpretable exchange across contexts. In addition, incorporating varying contexts can especially benefit long document understanding tasks that leverage pre-trained LMs, typically bounded by the input sequence length. In light of these challenges, we propose KALM, a language model that jointly leverages knowledge in local, document-level, and global contexts for long document understanding. KALM firstly encodes long documents and knowledge graphs into the three knowledge-aware context representations. KALM then processes each context with context-specific layers. These context-specific layers are followed by a ContextFusion layer that facilitates knowledge exchange to derive an overarching document representation. Extensive experiments demonstrate that KALM achieves state-of-the-art performance on three long document understanding tasks across 6 datasets/settings. Further analyses reveal that the three knowledge-aware contexts are complementary and they all contribute to model performance, while the importance and information exchange patterns of different contexts vary on different tasks and datasets.", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2022, "citationCount": 9, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2210.04105", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "KALM is proposed, a language model that jointly leverages knowledge in local, document-level, and global contexts for long document understanding and achieves state-of-the-art performance on three long documentUnderstanding tasks across 6 datasets/settings."}, "embedding": {"model": "specter_v2", "vector": [0.14283236861228943, 0.45132946968078613, -0.368460476398468, -0.3450017273426056, -0.24206234514713287, -0.5867231488227844, 0.8294036388397217, 0.13159848749637604, -0.4240444004535675, 0.03335849195718765, 0.7835992574691772, -0.040462613105773926, 0.09937600791454315, 0.18734021484851837, -0.12026058882474899, 0.17636168003082275, -0.9040639400482178, 0.23555785417556763, -0.24308019876480103, -0.40517550706863403, 0.2581263482570648, -0.7879832983016968, -0.6328709721565247, 0.39583513140678406, 0.5922292470932007, 0.21593542397022247, 0.7796446084976196, 1.2464772462844849, -0.7986531853675842, 0.5086793899536133, 0.42335572838783264, -0.31794583797454834, -0.2751561105251312, 0.10385408252477646, -0.5961915850639343, -0.08313731849193573, 0.44817987084388733, -0.6542513966560364, -0.4654427766799927, 0.5338677167892456, -0.25081929564476013, 0.1456095427274704, 0.48168280720710754, -0.3820347487926483, -0.5205872654914856, 1.3891046047210693, 1.1956859827041626, 0.2759997546672821, -0.03351140022277832, -0.7347455620765686, 1.4056190252304077, -1.2296624183654785, 0.5175354480743408, 1.541283369064331, 0.43223679065704346, 0.4618683159351349, 0.1859780102968216, -0.4766530990600586, 0.9813345074653625, 0.2896583080291748, -0.7815291881561279, -0.2881903648376465, -0.35122692584991455, -0.29198935627937317, 2.146627902984619, -0.5825880765914917, -0.28545597195625305, 0.4225523769855499, -0.16728034615516663, 1.6391087770462036, -0.34490451216697693, -1.1712279319763184, -0.6751009821891785, -0.2588801681995392, 0.521392285823822, 0.9923051595687866, -0.5965386033058167, 0.010215629823505878, -1.0370122194290161, 0.32736891508102417, 0.5256868600845337, -0.06860778480768204, -0.4876607358455658, 0.22981487214565277, -0.49636945128440857, 0.4180377721786499, 0.16748368740081787, 1.0266791582107544, -0.006071844138205051, 0.4258277714252472, 0.3676345646381378, 0.5455710291862488, -0.15942080318927765, 0.38423874974250793, -0.40137454867362976, 0.3711698651313782, -0.8890557289123535, 0.421751469373703, 0.3592715263366699, 0.8660664558410645, -0.1879352182149887, -0.010328089818358421, -0.697431743144989, 0.41451460123062134, 1.345981240272522, 0.03958386927843094, 0.6303974390029907, -0.6312344670295715, 0.681779682636261, -0.5020684599876404, 0.45363324880599976, -0.7524215579032898, -0.1716306060552597, -0.3332847058773041, -0.09775608032941818, -1.650872826576233, -0.05468805879354477, -0.030116727575659752, -0.6489467024803162, 1.0174896717071533, -0.4713924825191498, 0.4210837781429291, 0.7848920226097107, 0.13971370458602905, 0.7715033888816833, 0.8615018129348755, 0.30402225255966187, -0.1491420418024063, 0.6422204971313477, -0.8318650722503662, -0.7848745584487915, -1.162533164024353, 1.2806848287582397, -0.21016435325145721, 0.22092416882514954, -0.4934235215187073, -1.1287232637405396, -1.1781166791915894, -1.0526283979415894, -0.3254302144050598, -1.0495545864105225, 0.44091367721557617, 0.6096598505973816, 0.26384463906288147, -1.0364779233932495, 1.0661953687667847, 0.12650401890277863, -0.23891505599021912, -0.041309673339128494, -0.1005888506770134, 0.4280512034893036, -0.9962940216064453, -1.7559311389923096, 0.3562283217906952, 0.5910421013832092, -0.32676154375076294, -0.3823012411594391, -0.4368481934070587, -1.5295220613479614, -0.060753777623176575, 0.5486346483230591, -0.670917809009552, 1.2097272872924805, 0.08328434824943542, -1.2869701385498047, 0.2677496671676636, -0.4181312024593353, 0.19794036448001862, 0.05465531721711159, -0.5580792427062988, -0.8148690462112427, -0.4253273606300354, -0.20234045386314392, 0.24733403325080872, 0.1575157642364502, -0.11217779666185379, -0.37286293506622314, -0.08906695246696472, -0.18164485692977905, 0.33664026856422424, -0.29743045568466187, 0.93216472864151, -0.689723551273346, -0.3323196768760681, 0.24111633002758026, 0.7576059103012085, 0.20405493676662445, -0.6511602997779846, -0.2714923918247223, -1.0852607488632202, 1.1233434677124023, -0.3709339201450348, 1.392006516456604, -0.6938449740409851, -0.4156500995159149, -0.3669610917568207, -0.4450414776802063, 0.2337212711572647, -0.9960387349128723, 1.0028760433197021, 0.1578780561685562, 0.3821219205856323, -0.09023609757423401, -1.0721815824508667, 0.24793852865695953, -0.06751736253499985, -0.9846047759056091, -0.916702389717102, -0.13912607729434967, 1.2304575443267822, -1.3005750179290771, 0.08368352800607681, 0.08332851529121399, 0.3346084952354431, -0.23195601999759674, 1.2146378755569458, -0.7437944412231445, -0.005242202430963516, -0.44451436400413513, -0.12683063745498657, -0.21770232915878296, -0.3798504173755646, 0.9041728377342224, -0.27483972907066345, -0.017080597579479218, 0.197883740067482, -0.6128848195075989, 1.6008459329605103, -0.7106148600578308, 0.5234391093254089, -0.3538356423377991, -0.4160566031932831, 0.04292766749858856, 0.8885163068771362, -0.5966293811798096, -0.12377107888460159, 0.03960501402616501, 0.5267481803894043, -0.9345313310623169, -0.07711736857891083, 0.8156276345252991, 0.7890781760215759, -0.2997169494628906, 0.4421587288379669, 0.5514705777168274, -0.3930947184562683, 0.8420848250389099, 0.5593414902687073, 0.7890127301216125, 0.41789913177490234, 0.33421197533607483, 0.2260100543498993, 0.7772408723831177, -0.7061876058578491, -0.43226221203804016, 0.6250649094581604, 0.9699639081954956, 0.5877477526664734, 0.02715945430099964, -0.2975045442581177, -0.012804924510419369, 0.2438502460718155, 1.0463703870773315, 1.6309884786605835, 0.17809556424617767, -0.5158417820930481, -0.9740544557571411, -0.6758430600166321, -0.08347075432538986, 0.5188199281692505, -0.22001981735229492, 0.04831824079155922, -0.6393663287162781, -0.3985483646392822, 0.6152262687683105, 0.957234799861908, 1.1656757593154907, -0.5998578071594238, 0.110501229763031, 0.1371755748987198, -0.05734938010573387, -0.9026117324829102, -0.6356729865074158, -0.04851025715470314, -0.6532759666442871, -0.4581466317176819, 0.05462675541639328, -0.21966038644313812, 0.1902032345533371, -0.6848324537277222, 1.1734967231750488, -0.27855414152145386, -0.2208980917930603, 0.6999872326850891, 0.3720422089099884, -0.6119990944862366, -0.8619184494018555, -0.3127102553844452, 0.022181779146194458, -0.4376552104949951, 0.5251432061195374, 0.8224869966506958, 0.1009727418422699, 0.17106471955776215, -0.3414737284183502, 0.2720155119895935, 0.2802542448043823, -0.03868399187922478, 0.6663326025009155, -0.024948198348283768, 0.5626038312911987, -1.383595585823059, 0.862227201461792, 0.15265217423439026, -0.13475455343723297, 0.8914715647697449, -0.5552027821540833, -0.351327121257782, 0.6131560206413269, -0.4575752019882202, -0.7770017385482788, -1.1369822025299072, 0.8520690202713013, 0.02923600561916828, -0.39420706033706665, 0.886600136756897, -0.00708035659044981, 0.41376593708992004, -0.1695196032524109, 0.49765050411224365, 0.31337839365005493, -0.3665124773979187, 1.0646839141845703, -0.454852819442749, 0.5865592360496521, 0.2967574894428253, -0.1769256293773651, -0.5175386667251587, -0.2912850081920624, -0.85523521900177, -0.6381002068519592, -0.6889992356300354, -0.7506582140922546, -0.3173293173313141, 0.2667008936405182, -0.48875004053115845, -0.25480902194976807, 0.09228961914777756, -1.0683588981628418, -0.5614713430404663, 0.4793068468570709, -0.3612493872642517, -0.17445464432239532, -0.9118277430534363, -0.9669091701507568, -0.2972613573074341, -0.28189465403556824, -0.7613260746002197, 0.3409157991409302, -0.08937451988458633, -0.6265396475791931, -1.23703134059906, 0.07521634548902512, -0.09096954762935638, 0.8895307183265686, -0.4372577369213104, 1.0357604026794434, -0.05296739563345909, -0.19293439388275146, -0.20551170408725739, 0.14612001180648804, 0.7165116667747498, -0.05735233426094055, 0.09569641947746277, -0.7582944631576538, 0.02849206142127514, -0.13893194496631622, -0.5462350845336914, 0.1877375990152359, 0.35994598269462585, 0.6238003969192505, 0.24392545223236084, -0.7532064914703369, -0.05791174992918968, 1.5407073497772217, -0.4652252793312073, -0.43842029571533203, -0.12984220683574677, 1.1961219310760498, 0.6804752349853516, -0.10896047204732895, 0.07470354437828064, 0.396012544631958, 0.1088821068406105, -0.2118329107761383, 0.36658161878585815, -0.3344668447971344, -0.7401059865951538, 0.762880265712738, 1.7736046314239502, 0.10402823984622955, -0.33767077326774597, -1.0766063928604126, 0.8421992063522339, -1.4554225206375122, -0.33543074131011963, 0.8969032168388367, 0.6571314334869385, 0.5520965456962585, -0.8451470136642456, -0.8381201028823853, -0.404498428106308, 0.5989596247673035, 0.5297165513038635, -0.4137692153453827, -0.3965652585029602, 0.13523462414741516, 0.18576385080814362, -0.17965757846832275, 0.7956570982933044, -0.5160985589027405, 0.543757438659668, 14.057087898254395, 0.9500715136528015, 0.1793147623538971, 0.2780766189098358, 0.28307682275772095, 0.4024670720100403, -0.24210526049137115, -0.2369440346956253, -1.6605093479156494, -0.3685356378555298, 1.3251270055770874, -0.07899335026741028, 0.243854820728302, -0.08969419449567795, 0.0019441706826910377, 0.32900527119636536, -0.9172830581665039, 0.5330005884170532, 0.7668036818504333, -1.2913601398468018, 0.8398393988609314, -0.08312616497278214, 0.33979901671409607, 0.1457623392343521, 0.8275704979896545, 1.054762840270996, 0.393183171749115, -0.7138763070106506, 0.23031727969646454, 0.3763786554336548, 0.7216603755950928, -0.11554381996393204, 0.6531375646591187, 0.755254864692688, -0.9928417205810547, -0.6550132036209106, -0.49755752086639404, -0.8841481804847717, 0.4477226138114929, -0.1350015103816986, -0.754296600818634, -0.051020074635744095, -0.7255388498306274, 0.9855356812477112, -0.07166782021522522, -0.11892709881067276, -0.5937657356262207, 0.6039365530014038, 0.4602551758289337, 0.12499342113733292, 0.5290789008140564, 0.42258477210998535, 0.3452940583229065, 0.1734696924686432, 0.3116248846054077, 0.36308005452156067, 0.30757105350494385, 0.21740283071994781, -0.5808587670326233, 0.09237257391214371, -0.7662106156349182, -0.6430497169494629, 0.03305504843592644, 0.2767915427684784, 0.3905942738056183, -0.024858759716153145, -0.5198305249214172, 0.3397209942340851, 0.5779574513435364, 0.32908332347869873, 0.376639723777771, -0.3033381402492523, -0.05535605177283287, -0.5456088185310364, 0.12529586255550385, 0.2922159731388092, 0.041379816830158234, -0.5101161599159241, -0.8064240217208862, -0.2517130672931671, 0.7488059997558594, -0.7902466058731079, -0.813202977180481, 0.8734493851661682, -0.017435815185308456, -0.2566142976284027, -0.5499595403671265, -1.0913029909133911, -0.42975562810897827, 0.4329412281513214, -1.4543226957321167, -1.1671223640441895, 0.17929162085056305, -0.10462528467178345, -0.04995519667863846, -0.10770898312330246, 1.413852334022522, -0.33698639273643494, -0.3814496695995331, -0.24550695717334747, 0.6947958469390869, 0.00817088596522808, 0.1162499263882637, -1.0646319389343262, 0.3383265435695648, 0.1803356409072876, -0.006040753331035376, 0.5495008826255798, -0.26976239681243896, -0.5986644625663757, -0.8970575928688049, -0.40127992630004883, 1.0550118684768677, -1.1282665729522705, -0.5148940086364746, -0.5357896089553833, -1.197991132736206, 0.4950139820575714, 0.6612051725387573, -0.6467008590698242, 0.45738542079925537, 0.3583314120769501, -0.43037521839141846, 0.1678088903427124, -0.8448144793510437, 0.1339646875858307, 0.4286545515060425, -0.7116519808769226, -0.6870473027229309, 0.20755141973495483, 0.4452587068080902, -0.8271396160125732, -0.6044474244117737, -0.3465212285518646, 0.09447287768125534, 0.3245856463909149, 0.8961916565895081, -0.23766537010669708, 0.587649941444397, 0.8098318576812744, -0.1564481109380722, -0.9852077960968018, 0.3551929295063019, -0.8687467575073242, -0.28010374307632446, 0.17487595975399017, 0.8429355025291443, -0.13895690441131592, -0.26633283495903015, 0.9780170917510986, 0.32320690155029297, -0.4764801263809204, -0.06567830592393875, -0.5258410573005676, 0.23200677335262299, -0.4052102565765381, 0.2484057992696762, 0.1097433865070343, 0.14778973162174225, 0.005410545505583286, 0.9310804605484009, 1.0415478944778442, -0.1776115894317627, -0.4876551330089569, 0.4455723166465759, -0.04430655390024185, -0.09483359754085541, -0.45233237743377686, -0.3559178113937378, -1.488917589187622, 0.4186662435531616, -1.3117220401763916, -0.1103443130850792, -1.2296544313430786, -0.5615322589874268, 0.364522784948349, -0.32189711928367615, -0.07647562772035599, 0.08248680084943771, -0.6737369894981384, -0.39907363057136536, -0.675183892250061, -0.752192497253418, 0.39466413855552673, 0.9301983118057251, -0.3719579875469208, 0.02077224664390087, -0.40428227186203003, 0.1508244276046753, 0.44578129053115845, 0.19681714475154877, 0.16546638309955597, -1.3019875288009644, -1.7188022136688232, 0.10515761375427246, -0.055633485317230225, -0.1791418194770813, -0.3188841938972473, 0.8265987038612366, 0.3150452673435211, -0.12246432900428772, -0.031485725194215775, 0.1588384211063385, -0.46152031421661377, -0.7824743986129761, 0.05071662366390228, -0.9449402689933777, -0.06324020028114319, 0.30364471673965454, -0.16401870548725128, -0.6836835741996765, 0.4406017065048218, -0.4907686710357666, -1.1666591167449951, -1.34974205493927, 0.23845969140529633, -0.2888404428958893, -0.05799564719200134, -0.22146043181419373, 0.0016335903201252222, -1.155077338218689, -0.7352355122566223, -0.08256927132606506, 0.8023574352264404, -0.48852500319480896, 0.9999893307685852, 0.7127062082290649, -0.907221257686615, -0.10344970971345901, 0.17852072417736053, -0.0733678787946701, 0.09138114005327225, 0.8355218172073364, -0.029175274074077606, -0.13081537187099457, 0.8175169825553894, 0.44929155707359314, 0.3679543733596802, -1.224954605102539, -0.30783772468566895, 0.5430049896240234, -0.6698424220085144, -0.16122452914714813, 1.289698600769043, -0.297441303730011, -0.9940773248672485, 0.2397870421409607, -1.2243763208389282, -0.9667671918869019, -0.29538893699645996, 1.131658673286438, 0.19175098836421967, -0.19806912541389465, -0.07863560318946838, -0.02496061660349369, 0.6275988221168518, -0.3388928771018982, -0.6277214884757996, 0.619556725025177, -0.7179667353630066, -0.4045068919658661, 0.7525181174278259, 0.7131670117378235, -0.8883236646652222, -0.6775948405265808, -0.7779362797737122, -0.14193561673164368, -0.1134125292301178, 0.5491967797279358, -0.8598757982254028, -0.08995187282562256, 0.7612011432647705, 0.1721426546573639, 0.3001440167427063, -0.06137837842106819, -0.09763259440660477, 0.6177523732185364, 1.2487282752990723, -0.23949937522411346, -0.7505591511726379, -0.44150349497795105, 1.4325083494186401, 1.6647803783416748, -1.0026262998580933, 0.09351292997598648, -0.09218058735132217, -0.5900810360908508, 1.370595932006836, 0.20676405727863312, 0.5059638619422913, 0.7492352724075317, -0.49068304896354675, 0.4949679374694824, -0.0040591140277683735, -0.9629358053207397, 0.07195620983839035, 0.8871843218803406, 1.1803553104400635, 1.034439206123352, 0.2910574972629547, 0.26502564549446106, 0.9888149499893188, 0.20634956657886505, 0.2707618176937103, 0.39790409803390503, 0.7071302533149719, -0.41141998767852783, -0.3167415261268616, 0.24558065831661224, 0.3073870539665222, -0.3723049759864807, -0.46883153915405273, -0.1888991743326187, 0.5673851370811462, 0.16552652418613434, 0.7039947509765625, 0.5105689764022827, 0.43440544605255127, 0.4106837213039398, 0.9871314764022827, 0.6592651605606079, -0.8450857996940613, -0.13085636496543884, -0.6467078328132629, -0.3688894510269165, -0.11461891978979111, -0.5570092797279358, -0.29798075556755066, -0.5188776254653931, 0.21728841960430145, 0.3851354718208313, -0.031983938068151474, 0.5353480577468872, 1.578585147857666, 0.569722056388855, 0.3115982115268707, -0.6892741918563843, 0.05736356973648071, -0.4320984184741974, -1.0978097915649414, -0.07744882255792618, -0.39413395524024963, -0.3030205965042114, -0.22061754763126373, -0.07404683530330658, 0.12827597558498383]}, "authors": [{"authorId": "2114887261", "name": "Shangbin Feng"}, {"authorId": "2093186816", "name": "Zhaoxuan Tan"}, {"authorId": "49039233", "name": "Wenqian Zhang"}, {"authorId": "2161968765", "name": "Zhenyu Lei"}, {"authorId": "2073587169", "name": "Yulia Tsvetkov"}], "references": [{"paperId": "b4c9b57c0d9aacfa98db6247015def1826172bbd", "title": "PAR: Political Actor Representation Learning with Social Context and Expert Knowledge"}, {"paperId": "2d80d0b053179988f2155ea9eaf57b60a7742c16", "title": "Neural Methods for Logical Reasoning over Knowledge Graphs"}, {"paperId": "7b2efc62b9a46e711916e524070e2c057d152047", "title": "KRACL: Contrastive Learning with Graph Context Modeling for Sparse Knowledge Graph Completion"}, {"paperId": "3eb419ca9b1760222178605787057561685791c7", "title": "LM-CORE: Language Models with Contextually Relevant External Knowledge"}, {"paperId": "89900b12bf7dff0cf604ad20dd2720aa1303e942", "title": "Selection Bias Induced Spurious Correlations in Large Language Models"}, {"paperId": "6f9aa703c1dea0bd316ff7c758381199b321a3ba", "title": "Modularized Transfer Learning with Multiple Knowledge Graphs for Zero-shot Commonsense Reasoning"}, {"paperId": "eea2129457fcd78c4071a9020355a2fe1da4d2fd", "title": "SKILL: Structured Knowledge Infusion for Large Language Models"}, {"paperId": "8c9d8a23b15f8cc43b4e06c7dadbb66a3cab3cf3", "title": "Hypergraph Transformer: Weakly-Supervised Multi-hop Reasoning for Knowledge-based Visual Question Answering"}, {"paperId": "6ae63be462816bdd0da32894985d16f1e8cbdd5c", "title": "KALA: Knowledge-Augmented Language Model Adaptation"}, {"paperId": "3d6b094f439ceae770ad1ca5cb322421debf3ba8", "title": "DialoKG: Knowledge-Structure Aware Task-Oriented Dialogue Generation"}, {"paperId": "70517aef0466b49bed4017c698bd9169a763a2b7", "title": "KCD: Knowledge Walks and Textual Cues Enhanced Political Perspective Detection in News Media"}, {"paperId": "a1bec459a755ed399daf4671fcbd93293d765f37", "title": "C^3KG: A Chinese Commonsense Conversation Knowledge Graph"}, {"paperId": "2957bdd2bce3124f84935277231c2867a9a4ef4e", "title": "Speaker Information Can Guide Models to Better Inductive Biases: A Case Study On Predicting Code-Switching"}, {"paperId": "18ec13d5c66f6ba6c38ede6ba9b451f89e986432", "title": "Dynamic Key-value Memory Enhanced Multi-step Graph Reasoning for Knowledge-based Visual Question Answering"}, {"paperId": "4ab41d9780f1d1ac34d39fa7e527e73652507fcc", "title": "GreaseLM: Graph REASoning Enhanced Language Models for Question Answering"}, {"paperId": "79950179d60ba39a74d5fe2aedc47a57c0bf4c03", "title": "UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models"}, {"paperId": "a6d3aa3164688fa113f9333382a1335520c64368", "title": "NewsClaims: A New Benchmark for Claim Detection from News with Attribute Knowledge"}, {"paperId": "83c4b8fcef3c214cfae45818a5b4b637372f3083", "title": "JointLK: Joint Reasoning with Language Models and Knowledge Graphs for Commonsense Question Answering"}, {"paperId": "e7b0efb8a2b8be26124ce80b490eb51c1fc82dc4", "title": "DeepKG: an end-to-end deep learning-based workflow for biomedical knowledge graph extraction, optimization and applications"}, {"paperId": "8bcb1e12aa1d12221808d4e3643559077cfe7db2", "title": "Open Domain Question Answering with A Unified Knowledge Interface"}, {"paperId": "12a763cb52f650710900790ca0bc43e5d5b88be6", "title": "Generated Knowledge Prompting for Commonsense Reasoning"}, {"paperId": "521ccc898395a2818fced22b4cf371b0e5121f94", "title": "Symbolic Knowledge Distillation: from General Language Models to Commonsense Models"}, {"paperId": "7083181d36fa22a35a511f3eb361fa4ab312de24", "title": "KG-FiD: Infusing Knowledge Graph in Fusion-in-Decoder for Open-Domain Question Answering"}, {"paperId": "d105b192d887a84746fb35ceb30e35511495da78", "title": "Towards Automatic Bias Detection in Knowledge Graphs"}, {"paperId": "8cdb9f975aaff5adb51cfa164199010bb9b9b6d1", "title": "Mixture-of-Partitions: Infusing Large Biomedical Knowledge Graphs into BERT"}, {"paperId": "57baa478fd06ed18f3d271fefe9de5e833f47961", "title": "KELM: Knowledge Enhanced Pre-Trained Language Representations with Message Passing on Hierarchical Relational Graphs"}, {"paperId": "f236e060e0e74e87cc0415e40a8a20fb13a18824", "title": "Legislator Representation Learning with Social Context and Expert Knowledge"}, {"paperId": "895318492b3322bc5213b1cdddc26b67054e98c4", "title": "KGAP: Knowledge Graph Augmented Political Perspective Detection in News Media"}, {"paperId": "6f0aba8102d63938ce0b48ec23ff5ddd8110f2e8", "title": "Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification"}, {"paperId": "114aa720872462b0ca1b97bfdec0ebd56c36fd0a", "title": "Towards Understanding and Mitigating Social Biases in Language Models"}, {"paperId": "69285c9040c1356272752499b7e1e53ef25ac008", "title": "Beyond Paragraphs: NLP for Long Sequences"}, {"paperId": "60163eab80666401862f16c01a799368ddd8be8d", "title": "Investigating the Effect of Background Knowledge on Natural Questions"}, {"paperId": "1a1e99514d8d175459f7c61cfd0c394b46e63359", "title": "Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training"}, {"paperId": "3950df97ea527009a32569cb7016bc3df1383dca", "title": "QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering"}, {"paperId": "26b7eacd6aaff6c2bd1beac40b96597fb1d29a1e", "title": "Lawyers are Dishonest? Quantifying Representational Harms in Commonsense Knowledge Resources"}, {"paperId": "1540045f8967a0c70384d9f095c64cfc88a2fc4a", "title": "UniK-QA: Unified Representations of Structured and Unstructured Knowledge for Open-Domain Question Answering"}, {"paperId": "9b8193a38ad9fd3e0b14bd1c0b0f4c6e3a7df18a", "title": "CSKG: The CommonSense Knowledge Graph"}, {"paperId": "9fa9d5dd481400b2f3904b33d542d70a6affccb9", "title": "Dynamic Neuro-Symbolic Knowledge Graph Construction for Zero-shot Commonsense Question Answering"}, {"paperId": "2292c89ba08a5b5f1dde2bf4fa65241e2cd98fef", "title": "Debiasing Knowledge Graph Embeddings"}, {"paperId": "37bf0bf34603145246c3311df19e2afdf6e0270a", "title": "JAKET: Joint Pre-training of Knowledge Graph and Language Understanding"}, {"paperId": "eedf2748a9a1ba2779cde95fd8bad9c2260d5317", "title": "LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention"}, {"paperId": "7eda139d737eea10fc1d95364327a41ec0cee4a4", "title": "CoLAKE: Contextualized Language and Knowledge Embedding"}, {"paperId": "baa8f524c82735f174b8d1ab512ac5750146d67e", "title": "KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning"}, {"paperId": "bbd5db3b21eb9de3c0a13a43e125746be1079912", "title": "Benchmark and Best Practices for Biomedical Knowledge Graph Embeddings"}, {"paperId": "024a2c03be8e468e7c4fdf9bda36cdc0eaae85fb", "title": "Array programming with NumPy"}, {"paperId": "5b3c0e0f8ba544cda342e56c8c5fa25d27dc92f6", "title": "Explainable and Discourse Topic-aware Neural Language Understanding"}, {"paperId": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583", "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"}, {"paperId": "7b12198a77972508689a904c544010b2a406ed20", "title": "YAGO 4: A Reason-able Knowledge Base"}, {"paperId": "3ca320cb73c962cd29b8211cb4fd8074c5e8c9b8", "title": "Contextualized Representations Using Textual Encyclopedic Knowledge"}, {"paperId": "babeda48b10a4d638252118f2238d05a06f4ec55", "title": "StereoSet: Measuring stereotypical bias in pretrained language models"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "4f03e69963b9649950ba29ae864a0de8c14f1f86", "title": "K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters"}, {"paperId": "d5e11bc965b62b486a7000f311787fe40b6c4515", "title": "Measuring Social Bias in Knowledge Graph Embeddings"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "56cafbac34f2bb3f6a9828cd228ff281b810d6bb", "title": "KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation"}, {"paperId": "4b244a6778c95b1df8e9e02332ff8d22e675f628", "title": "Composition-based Multi-Relational Graph Convolutional Networks"}, {"paperId": "5fc2df0e3261edf5e2d3acc79a903011d8d176df", "title": "Multi-domain Dialogue State Tracking as Dynamic Knowledge Graph Enhanced Question Answering"}, {"paperId": "875f3cb9e710d054b2d9611a1eff049dad5b0396", "title": "Machine Reading Comprehension Using Structural Knowledge Graph-aware Network"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "bfeb827d06c1a3583b5cc6d25241203a81f6af09", "title": "Knowledge Enhanced Contextual Word Representations"}, {"paperId": "2bf7c350a8280e7c593d46a60127f99b21517121", "title": "On the Variance of the Adaptive Learning Rate and Beyond"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "cfca1faca73f5c310ff669f27024b3182d5731e3", "title": "Encoding Social Information with Graph Convolutional Networks forPolitical Perspective Detection in News Media"}, {"paperId": "f48ae425e2567be2d993efcaaf74c2274fc9d7c5", "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction"}, {"paperId": "fc089a09074c84979d1f34e89341318a5bc26d3d", "title": "SemEval-2019 Task 4: Hyperpartisan News Detection"}, {"paperId": "5f994dc8cae24ca9d1ed629e517fcc652660ddde", "title": "ERNIE: Enhanced Language Representation with Informative Entities"}, {"paperId": "63a513832f56addb67be81a2fa399b233f3030fc", "title": "Fast Graph Representation Learning with PyTorch Geometric"}, {"paperId": "8ab29eea2110f02802fbb1d879dc837ecb9e0b16", "title": "OpenKE: An Open Toolkit for Knowledge Embedding"}, {"paperId": "8f096071a09701012c9c279aee2a88143a295935", "title": "RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space"}, {"paperId": "ed01746601d9cb7724568645d8b53876f6cd7c16", "title": "textTOvec: Deep Contextualized Neural Autoregressive Models of Language with Distributed Compositional Prior"}, {"paperId": "01eb299fec9b9f5f499d0ce9702d5aeb77848d88", "title": "Topic Compositional Neural Language Model"}, {"paperId": "33998aff64ce51df8dee45989cdca4b6b1329ec4", "title": "Graph Attention Networks"}, {"paperId": "7d3c2ff37d04914836f9cbd9ce54b6c97aa74a22", "title": "Truth of Varying Shades: Analyzing Language in Fake News and Political Fact-Checking"}, {"paperId": "983ea560aebc17cbdbc28ff9166b49bd348b4403", "title": "Sparsity and Noise: Where Knowledge Graph Embeddings Fall Short"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "2a911eba95814258ff14502b49e5342c0a05f395", "title": "From word models to executable models of signaling networks using automated assembly"}, {"paperId": "26aa6fe2028b5eefbaa40ab54ef725bbbe7d9810", "title": "ConceptNet 5.5: An Open Multilingual Graph of General Knowledge"}, {"paperId": "bc297b4f88a75ecbfd20c3288e2aca855d02d22a", "title": "An Embedding Model for Predicting Roll-Call Votes"}, {"paperId": "36eff562f65125511b5dfab68ce7f7a943c27478", "title": "Semi-Supervised Classification with Graph Convolutional Networks"}, {"paperId": "455afd748e8834ef521e4b67c7c056d3c33429e2", "title": "Hierarchical Attention Networks for Document Classification"}, {"paperId": "f63e917638553414526a0cc8550de4ad2d83fe7a", "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)"}, {"paperId": "994afdf0db0cb0456f4f76468380822c2f532726", "title": "Learning Entity and Relation Embeddings for Knowledge Graph Completion"}, {"paperId": "dab7e605237ad4f4fe56dcba2861b8f0a57112be", "title": "Wikidata"}, {"paperId": "2582ab7c70c9e7fcb84545944eba8f3a7f253248", "title": "Translating Embeddings for Modeling Multi-relational Data"}, {"paperId": "62e14dec73970514a5e3f81b059d63b34e9ad37c", "title": "Predicting Legislative Roll Calls from Text"}, {"paperId": "168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74", "title": "Scikit-learn: Machine Learning in Python"}, {"paperId": "cfdd423c8672a7b178ea85d56079328df4eea647", "title": "Steven Bird, Ewan Klein and Edward Loper: Natural Language Processing with Python, Analyzing Text with the Natural Language Toolkit"}, {"paperId": "c69eb9148510430b0226fdeb6fe07f72919bfbb2", "title": "Fast and Accurate Annotation of Short Texts with Wikipedia Pages"}, {"paperId": "c652fa4691f50bd96fcb41e459c3c633d973f177", "title": "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics"}, {"paperId": "d58d5172fbe7b40e9c2da382da5507fb3483bcc3", "title": "Multi-Hop Open-Domain Question Answering over Structured and Unstructured Knowledge"}, {"paperId": "d5416e20ade6dc31cce76011a802d9319f928348", "title": "Constraint-based Multi-hop Question Answering with Knowledge Graph"}, {"paperId": "359eac135d494b928eea23e1c156862911d7d37a", "title": "Learning from Missing Relations: Contrastive Learning with Commonsense Knowledge Graphs for Commonsense Inference"}, {"paperId": "18637c36a2737e51051113e56b4438b06b568a3d", "title": "Explainable GNN-Based Models over Knowledge Graphs"}, {"paperId": "0d9d603a2366200fc573a6bb1a7bf3c7e7710a17", "title": "Understanding Gender Bias in Knowledge Base Embeddings"}, {"paperId": "cc9d3a5f2fbfd15d014af95a077fd94aad120c80", "title": "Explaining Toxic Text via Knowledge Enhanced Text Generation"}, {"paperId": "87cf9edc4f91bb65ed8c1264bec7ecc803998552", "title": "Metadata Shaping: A Simple Approach for Knowledge-Enhanced Language Models"}, {"paperId": "7b7416c90e8d3fc9ad5c9fb3923a638f69294ed7", "title": "MENTION MEMORY : INCORPORATING TEXTUAL KNOWLEDGE INTO TRANSFORMERS THROUGH ENTITY MENTION ATTENTION"}, {"paperId": null, "title": "2022a) for fair comparison"}, {"paperId": "f95a4568a714c34984aa32327fa66344ebe52861", "title": "Compare to The Knowledge: Graph Neural Fake News Detection with External Knowledge"}, {"paperId": "e7d4fd44400391888226b3f5d8acac0ab2106bac", "title": "KLMo: Knowledge Graph Enhanced Pretrained Language Model with Fine-Grained Relationships"}, {"paperId": "56441f4f3beb3276350d811c67307e28d5f61b43", "title": "Using Social and Linguistic Information to Adapt Pretrained Representations for Political Perspective Identification"}, {"paperId": "d8daacb809e890742d3e4681cc3bbd5fdb4786a4", "title": "Align Voting Behavior with Public Statements for Legislator Representation Learning"}, {"paperId": "e349b557c5b7458d338ef93f672337e3493ad144", "title": "C 3 KG: A Chinese Commonsense Conversation Knowledge Graph"}, {"paperId": null, "title": "2021) time-based Table 7: Dataset statistics. The number of long documents and class distribution does not add up for RCVP since multiple legislators vote on the same legislation"}, {"paperId": null, "title": "We present important dataset details in Table 6. We follow the exact same dataset settings and splits in previous works"}, {"paperId": null, "title": "2021) proposes to generate synthetic pretraining corpora based on structured knowledge bases. In this paper, we further pretrained the roberta-base checkpoint on the KELM synthetic corpus and report"}, {"paperId": null, "title": "2021) for misinformation detection on graphs"}, {"paperId": null, "title": "2020) are pre-trained language models. We use the pre-trained weights roberta-base, electra-small-discriminator, deberta-v3-base, bart-base, and longformer-base-4096 in Huggingface Transformers"}, {"paperId": null, "title": "2019) is one of the first works to leverage external knowledge bases to enrich language representations. We used the three pretrained models, KnowBERT-Wordnet, KnowBERT-Wikidata, and KnowBERT-W+W"}, {"paperId": null, "title": "William Falcon and The PyTorch Lightning team"}, {"paperId": null, "title": "LongFormer (Beltagy et al., 2020) task agnostic KELM"}, {"paperId": null, "title": "Electra: Pre-training text encoders as discriminators rather than generators"}, {"paperId": null, "title": "proposes the LUN dataset and argues that misinformation detection should have more fine-grained labels than true or false"}, {"paperId": "3dffde1e26f12b0f30abe8b5a046932fa6004ae0", "title": "Fake News or Truth? Using Satirical Cues to Detect Potentially Misleading News"}, {"paperId": null, "title": "2021) ideal-point (Gerrish & Blei, 2011) ideal-vector"}, {"paperId": null, "title": "2016) proposes the SLN dataset and leverages satirical cues for misinformation detection"}, {"paperId": null, "title": "Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? Section B"}, {"paperId": null, "title": "2016) is short for hierarchical long short-term memory networks. It was used in previous works (Li & Goldwasser, 2019; 2021) for political perspective detection"}, {"paperId": null, "title": "crowdworkers) or research with human participants?"}, {"paperId": null, "title": "Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators"}, {"paperId": null, "title": "2022) proposes to leverage multi-hop knowledge reasoning with knowledge walks and textual cues with document graphs for political perspective detection"}, {"paperId": null, "title": "error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run? Section 3 and Section A C4"}, {"paperId": null, "title": "2021) proposes to leverage knowledge graphs and compare the textual content to external knowledge for misinformation detection"}, {"paperId": null, "title": "We manually examined 20 news articles from the LUN"}, {"paperId": null, "title": "crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic"}, {"paperId": null, "title": "performance on documents that are longer and contain more external knowledge, which are positioned the top-right corner of the \ufb01gure. A.3 Manual Error Analysis"}, {"paperId": null, "title": "Was the data collection protocol approved (or determined exempt) by an ethics review board? No response"}, {"paperId": null, "title": "2021) GreaseLM+ (ours)"}, {"paperId": null, "title": "epochs, which shows that the attention matrices started out dense and ended sparse, indicating that the role of different contexts is gradually developed through time"}, {"paperId": null, "title": "Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? No response"}, {"paperId": null, "title": "HYPERPARAMETER DETAILS We present KALM's hyperparameter settings in Table 8. We conduct hyperparameter searches for different datasets and report the best setups"}, {"paperId": null, "title": "GreaseLM+ is our extended version of GreaseLM, which adds the document-level context while keeping the original MInt layer instead of our proposed ContextFusion layer"}, {"paperId": null, "title": "2021a) proposes to construct document graphs to jointly encode textual content and external knowledge"}, {"paperId": null, "title": "the 2022 Conference of the North American Chapter of the Association for"}, {"paperId": null, "title": "KALM (ours)"}, {"paperId": null, "title": "2021b) proposes to learn legislator representations with social context and expert knowledge for roll call vote prediction"}]}