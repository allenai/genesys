{"paperId": "b1c0a7a595c1c2cca63eaf9aab80ef3bc75dc786", "abstract": "Large language models show impressive abilities in memorizing world knowledge, which leads to concerns regarding memorization of private information, toxic or sensitive knowledge, and copyrighted content. We introduce the problem of Large Scale Knowledge Washing, focusing on unlearning an extensive amount of factual knowledge. Previous unlearning methods usually define the reverse loss and update the model via backpropagation, which may affect the model's fluency and reasoning ability or even destroy the model due to extensive training with the reverse loss. Existing works introduce additional data from downstream tasks to prevent the model from losing capabilities, which requires downstream task awareness. Controlling the tradeoff of unlearning and maintaining existing capabilities is also challenging. To this end, we propose LAW (Large Scale Washing) to update the MLP layers in decoder-only large language models to perform knowledge washing, as inspired by model editing methods and based on the hypothesis that knowledge and reasoning are disentanglable. We derive a new objective with the knowledge to be unlearned to update the weights of certain MLP layers. Experimental results demonstrate the effectiveness of LAW in forgetting target knowledge while maintaining reasoning ability. The code will be open-sourced at https://github.com/wangyu-ustc/LargeScaleWashing.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "LAW (Large Scale Washing) is proposed to update the MLP layers in decoder-only large language models to perform knowledge washing, as inspired by model editing methods and based on the hypothesis that knowledge and reasoning are disentanglable."}, "embedding": {"model": "specter_v2", "vector": [-0.1379787027835846, 0.8842859864234924, -0.1821836531162262, 0.25784340500831604, -0.22509603202342987, -0.40085360407829285, 0.6704484224319458, -0.02173876203596592, -0.6219332814216614, 0.17583602666854858, 0.21765366196632385, -0.2564818263053894, 0.3126503825187683, -0.2506834864616394, -0.6718321442604065, 0.046650853008031845, -0.8226771354675293, 0.20569951832294464, 0.27099743485450745, -0.2909547686576843, -0.2389398068189621, -0.444633811712265, -0.7105124592781067, 0.3880673348903656, 0.7934169173240662, 0.21230927109718323, 0.03109067678451538, 0.877197802066803, -0.48894229531288147, 0.7756545543670654, 0.2511972188949585, -0.8325219750404358, 0.35295620560646057, 0.27275535464286804, -0.3972056210041046, 0.1422698199748993, 0.3280169367790222, -0.540473222732544, -0.7074731588363647, 0.873863160610199, -0.22131647169589996, 0.34479355812072754, 0.1536877453327179, -0.6226112246513367, -0.5969008207321167, 0.895728349685669, 0.6612021327018738, 0.9006339311599731, -0.33877259492874146, -0.640546441078186, 0.8654571175575256, -1.397361397743225, 0.1553562730550766, 1.422650933265686, 0.6440943479537964, 0.249311625957489, 0.16330520808696747, -0.9602323174476624, 0.8776645660400391, 0.23503562808036804, -1.138484239578247, -0.14288021624088287, -0.42655760049819946, -0.03583409637212753, 1.6631957292556763, -0.7229961156845093, -0.0015598866157233715, 0.36351075768470764, 0.10465429723262787, 1.6379865407943726, -0.028180217370390892, -0.7787842154502869, -0.24241670966148376, 0.4525299072265625, 0.07827811688184738, 1.3126118183135986, -0.06246527284383774, 0.02301712892949581, -1.0679378509521484, -0.07760535925626755, 0.7293612957000732, -0.08741217106580734, -0.39985066652297974, -0.21028344333171844, -0.006603437475860119, 0.46646544337272644, 0.10460050404071808, 0.7099034190177917, -0.08667033165693283, 0.45678961277008057, 0.09537370502948761, 0.8812116980552673, 0.010022461414337158, 0.5752688050270081, -0.48246899247169495, 0.20813007652759552, -0.8976581692695618, 0.02174222655594349, 0.20454159379005432, 0.912182629108429, -0.09557531028985977, 0.16315269470214844, -0.508944571018219, 0.28289419412612915, 1.2112350463867188, 0.13035030663013458, 0.6334705948829651, -0.7369088530540466, 0.49014538526535034, -0.6098161339759827, 0.5822045803070068, -0.514021098613739, -0.34934595227241516, -0.5640594363212585, -0.4646407663822174, -0.9123070240020752, -0.28819116950035095, -0.005956951063126326, -0.6781877279281616, 0.9663733243942261, -0.5826439261436462, 0.2015734761953354, 0.23863789439201355, 0.29409852623939514, 0.28023216128349304, 0.5757657289505005, 0.14489005506038666, -0.12820850312709808, 0.6458304524421692, -0.971001923084259, -0.7076671719551086, -0.9357913732528687, 0.378006249666214, -0.12356360256671906, 0.1525249034166336, 0.05670376867055893, -1.4349380731582642, -0.8045417666435242, -1.2068259716033936, 0.13727621734142303, -1.130088448524475, -0.055538110435009, 1.093618631362915, 0.5812538862228394, -0.8913707137107849, 0.8622226715087891, -0.015453824773430824, -0.22082090377807617, 0.6229473352432251, 0.12882539629936218, 0.056509170681238174, -0.7697519659996033, -1.6903913021087646, 0.8235325813293457, 0.61388099193573, -0.5042135715484619, -0.3466445803642273, -0.5490229725837708, -1.0650299787521362, -0.351373553276062, 0.6589288711547852, -0.45108872652053833, 1.204250693321228, -0.1572222262620926, -1.0572497844696045, 0.3112509250640869, -0.017001766711473465, 0.3690994083881378, 0.9486770033836365, -0.5900694727897644, -0.9396972060203552, -0.4545819163322449, -0.4576590061187744, 0.13341765105724335, 0.7267722487449646, -0.717511773109436, -0.43432196974754333, 0.2925461232662201, 0.08977589011192322, -0.2140941172838211, -0.3153006136417389, 0.3563971221446991, -0.6261084079742432, -0.40955740213394165, 0.03523353859782219, 0.9680928587913513, 0.5129536390304565, 0.04629788175225258, -0.06397508829832077, -0.7038339972496033, 0.5517027378082275, -0.46819183230400085, 1.1596275568008423, -0.8792262077331543, -0.5360496640205383, 0.07735477387905121, -0.19711875915527344, 0.28589120507240295, -1.160334587097168, 0.7186726927757263, 0.11902555823326111, 0.5231148600578308, -0.2784518301486969, -0.8316819071769714, 0.16797900199890137, 0.07482568919658661, -0.8740383982658386, -0.22966712713241577, 0.18241874873638153, 1.234440803527832, -1.0493947267532349, 0.26304998993873596, -0.2324826568365097, 0.3572642207145691, -0.8193203806877136, 1.138183355331421, -0.5696033239364624, -0.0031983572989702225, 0.03562907874584198, -0.05863266810774803, 0.36787188053131104, -0.13955803215503693, 0.35507503151893616, -0.25137338042259216, 0.06588473916053772, -0.03331593796610832, -0.8337528705596924, 1.2858635187149048, -0.600142240524292, 0.45904016494750977, -0.009315426461398602, -0.301187664270401, -0.328328013420105, 0.5058186054229736, -0.707699716091156, -0.09795597940683365, 0.1426113396883011, 0.11313678324222565, -0.6131797432899475, -0.13486601412296295, 0.6580817699432373, 0.3047056496143341, 0.08817875385284424, 0.23550191521644592, 0.6929044127464294, -0.5534949898719788, 0.5436704158782959, 0.4499940276145935, 0.8367943167686462, 0.3352387845516205, 0.41287732124328613, 0.32902857661247253, 0.2339109629392624, -0.9276455044746399, 0.027197444811463356, 0.6613466143608093, 0.7027832865715027, 0.6452682614326477, 0.260469526052475, -0.3236578702926636, -0.4437335729598999, -0.1732122302055359, 0.7540926933288574, 1.5943511724472046, 0.10121174901723862, -0.036989644169807434, -0.5099709033966064, -0.5027821660041809, 0.16993360221385956, 0.6889053583145142, -0.7507674694061279, -0.2552241086959839, -0.4368564188480377, -0.8105707764625549, 0.6583118438720703, 0.33115649223327637, 1.382078766822815, -0.5617759227752686, 0.28825628757476807, -0.15164576470851898, 0.38470587134361267, -0.6911551356315613, -0.4113844633102417, 0.02512199617922306, -0.388954758644104, -0.45232537388801575, -0.07009044289588928, -0.1821039468050003, 0.3723035752773285, -0.4943520724773407, 0.7488759160041809, -0.12788093090057373, 0.01291740220040083, 0.6340785026550293, 0.4794906675815582, -0.8379648327827454, -0.8259831070899963, 0.028684545308351517, 0.2060202956199646, -0.11671087145805359, 0.14815641939640045, 0.36678346991539, 0.2083573043346405, 0.09313131123781204, -0.869627058506012, 0.11656848341226578, 0.7557052969932556, -0.13680776953697205, 0.2894083857536316, 0.31037774682044983, 0.5977923274040222, -1.4765123128890991, 0.9239554405212402, 0.10903764516115189, -0.30051112174987793, 0.7175012826919556, -0.5391286015510559, -0.3658859133720398, 0.4721636474132538, -0.9359059929847717, -0.6100246906280518, -1.5781563520431519, 0.3067256808280945, -0.15387344360351562, 0.15491682291030884, 0.31101757287979126, 0.05254076421260834, -0.180446594953537, -0.0270429328083992, 0.6495847702026367, 0.3406144678592682, -0.1681375801563263, 0.9041932225227356, -0.7064436078071594, 0.4418708384037018, 0.29280906915664673, 0.4177371859550476, 0.08310358226299286, -0.5340997576713562, -0.5939235687255859, -0.8317961692810059, -0.18533073365688324, -0.6099252700805664, 0.053384289145469666, -0.10699284076690674, -0.7168276906013489, -0.5702564716339111, 0.13385307788848877, -0.9946345090866089, -0.7574074268341064, 0.05699203908443451, -0.3037985563278198, -0.06469655781984329, -0.9604668617248535, -1.1552364826202393, -0.3803616464138031, 0.045291051268577576, -0.46674448251724243, -0.08431056886911392, -0.007569931913167238, -0.3542351722717285, -1.0142165422439575, -0.03223755210638046, -0.22195175290107727, 1.1434621810913086, -1.0488133430480957, 1.0713584423065186, -0.07117053866386414, -0.38336652517318726, -0.2649707496166229, 0.09755777567625046, 0.6061235666275024, -0.06409983336925507, -0.2539629638195038, -0.8089959621429443, -0.13059647381305695, -0.15586359798908234, -0.4690590500831604, 0.24790099263191223, -0.25837206840515137, 0.4757266342639923, -0.2241380214691162, -0.370807409286499, -0.1737544685602188, 1.2997539043426514, -0.7971787452697754, 0.19176903367042542, 0.2883702218532562, 0.8941492438316345, 0.2703050673007965, -0.28949663043022156, 0.3628000319004059, 0.10023190826177597, -0.32834020256996155, -0.1219625473022461, 0.16578269004821777, -0.3452455997467041, -0.8581930994987488, 0.5286022424697876, 1.5866436958312988, 0.08156898617744446, 0.1908532828092575, -0.8506074547767639, 0.6235537528991699, -1.2327969074249268, -0.7517876625061035, 1.3434864282608032, 0.7887468338012695, 0.8066182732582092, -0.46845579147338867, -0.9095578789710999, -0.12771816551685333, 0.5243529081344604, 0.1636776328086853, -0.5869325399398804, -0.01884552650153637, 0.11546313017606735, 0.1748032122850418, 0.21020136773586273, 1.0090579986572266, -0.2814883589744568, 0.5054217576980591, 14.807909965515137, 1.091928243637085, 0.20467981696128845, 0.9683845043182373, 0.12002292275428772, 0.15753452479839325, -0.6000893115997314, -0.41765037178993225, -1.0557986497879028, -0.4344116747379303, 0.6227408051490784, 0.1407860815525055, 0.8274750113487244, -0.13458289206027985, -0.3134540915489197, -0.06811253726482391, -0.10060419142246246, 0.5113292932510376, 0.923157811164856, -1.1043051481246948, 0.9122803807258606, -0.07767189294099808, 0.6907889246940613, 0.2964671850204468, 0.8434326648712158, 1.2582168579101562, 0.44437921047210693, -0.3907219469547272, 0.8219785094261169, 0.24320366978645325, 0.6200559735298157, -0.05903630331158638, 0.6057456731796265, 0.8643576502799988, -0.583154559135437, -0.3975072205066681, -0.5814531445503235, -0.8094860911369324, 0.14723621308803558, 0.18715743720531464, -0.14624330401420593, -0.4822092652320862, -0.5812320709228516, 0.33613547682762146, -0.2637961208820343, 0.2585194408893585, -0.6414194107055664, 0.5041958689689636, 0.13127456605434418, 0.32744890451431274, 0.10175689309835434, 0.6092694997787476, 0.16230475902557373, -0.15410327911376953, -0.029601268470287323, 0.17698286473751068, 0.00018488684145268053, 0.2247084528207779, -0.8237453103065491, -0.10298328846693039, -0.2350664585828781, -0.4088645577430725, 0.00037655411870218813, 0.41930699348449707, 0.6323965787887573, 0.15441028773784637, -0.7650327086448669, 0.5434306263923645, 1.0157068967819214, 0.43985408544540405, -0.09464114904403687, 0.17101825773715973, 0.0029645657632499933, -0.2049250602722168, 0.3151637315750122, 0.530318021774292, 0.03310266137123108, -0.7399184703826904, -0.5140117406845093, -0.23080626130104065, 0.4425552785396576, -1.1013611555099487, -0.8980829119682312, 0.5496113300323486, -0.39892104268074036, -0.3882766664028168, 0.7018166780471802, -0.8106942772865295, -0.0313471294939518, -0.024067066609859467, -1.7116600275039673, -0.9566452503204346, 0.21733757853507996, -0.10188374668359756, -0.3163321912288666, -0.24390679597854614, 1.1075488328933716, 0.02236265130341053, -0.22517427802085876, -0.03673849627375603, 0.27221933007240295, 0.05955743417143822, 0.046348053961992264, -0.714958131313324, 0.12084387242794037, 0.09553954005241394, -0.11679672449827194, 0.5993764996528625, -0.04759318381547928, -0.3523624539375305, -0.6771361231803894, -0.30455708503723145, 0.5503401756286621, -1.0790574550628662, -0.10466906428337097, -0.4947184920310974, -1.2417058944702148, 0.6547942161560059, 0.6078481674194336, -0.3827733099460602, 0.3592042922973633, 0.06750994920730591, -1.0449872016906738, -0.11569317430257797, -1.0679072141647339, 0.19483210146427155, 0.2865970730781555, -0.7723182439804077, -0.829438328742981, 0.08540374040603638, 0.16179496049880981, -0.8901777863502502, -0.6411994695663452, -0.3241053819656372, -0.10246823728084564, 0.08762506395578384, 0.5097250938415527, -0.5145784020423889, 0.20540086925029755, 0.6613180637359619, 0.07851965725421906, -0.9057443737983704, -0.02113955467939377, -0.9964658617973328, -0.07074108719825745, 0.1586587131023407, 1.0945191383361816, -0.5599591135978699, -0.18328386545181274, 0.9555268287658691, 0.6873341798782349, -0.3083748519420624, -0.5253969430923462, -0.3979351818561554, 0.6123573184013367, -0.6871888041496277, 0.01424809917807579, 0.04028802737593651, 0.17609837651252747, 0.06806875765323639, 0.493913471698761, 1.0599018335342407, -0.20572848618030548, -0.7651645541191101, 0.1372162252664566, 0.019381215795874596, -0.032690975815057755, -0.5290794372558594, -0.27928540110588074, -1.2443586587905884, 0.0850391536951065, -1.0780988931655884, 0.02672191895544529, -1.2588341236114502, -0.31602054834365845, 0.43062734603881836, -0.21824179589748383, 0.024956008419394493, 0.21644514799118042, -0.5465206503868103, -0.46244582533836365, -0.3895823061466217, -0.7870765924453735, 0.7218555212020874, 0.9735410809516907, -0.8286132216453552, 0.25452739000320435, -0.15785174071788788, 0.014681154862046242, 0.6409865617752075, 0.5275439023971558, -0.2081202119588852, -0.9977259039878845, -1.2463023662567139, 0.6019585728645325, -0.7027187347412109, -0.23016494512557983, -0.5229202508926392, 1.025346279144287, 0.45138266682624817, 0.10662908852100372, 0.2627832293510437, 0.4475635886192322, -0.9756233096122742, -0.744217574596405, 0.2845652997493744, -0.6866644024848938, -0.22485803067684174, 0.5492176413536072, -0.1341463029384613, -0.3881407082080841, 0.4281546473503113, 0.120242640376091, -1.2623637914657593, -0.829552173614502, 0.23933149874210358, -0.7624620199203491, 0.3307655155658722, -0.08534946292638779, 0.3631298243999481, -1.3873978853225708, -0.5432114005088806, -0.28122493624687195, 0.6001299023628235, -0.37279945611953735, 1.063255786895752, 0.44382449984550476, -1.052620530128479, 0.016160234808921814, 0.26326385140419006, -0.16943521797657013, 0.033554453402757645, 0.6297277808189392, 0.11292757093906403, -0.5098803639411926, 0.39490339159965515, 0.5120611190795898, 1.044856071472168, -0.573621928691864, 0.17018139362335205, 0.8630908727645874, -0.43162044882774353, -0.14302697777748108, 1.0089055299758911, -0.4169124960899353, -1.0847837924957275, 0.5918219089508057, -0.9475137591362, -0.5598699450492859, -0.29536283016204834, 0.921890914440155, 0.1597462147474289, -0.1071343794465065, 0.41628026962280273, -0.14965948462486267, 0.26824361085891724, -0.21745458245277405, -0.6185150146484375, 0.5329985618591309, -0.46754392981529236, -0.5837110280990601, 0.9004871249198914, 0.5072360634803772, -0.08077491819858551, -0.9552441835403442, -0.7594304084777832, -0.5347018837928772, -0.23226298391819, 0.1923106610774994, -0.8221667408943176, -0.37109142541885376, 0.490452378988266, 0.1899767965078354, 0.327917218208313, -0.2848856449127197, -0.07011376321315765, 0.040138762444257736, 1.2310385704040527, 0.35427188873291016, -0.9728677272796631, -0.39672333002090454, 1.0974607467651367, 1.7075115442276, -0.9048914909362793, 0.42559534311294556, -0.355204313993454, -0.7853578329086304, 0.8863454461097717, 0.47856634855270386, 0.27324625849723816, 1.1838840246200562, -0.2106797695159912, 0.3698663115501404, 0.2557552754878998, -0.7803399562835693, -0.24693530797958374, 0.4836622178554535, 0.920706033706665, 0.3036709427833557, 0.024368196725845337, 0.45323067903518677, 1.1136338710784912, 0.32465502619743347, 0.48348236083984375, 0.7567471861839294, 0.6567240357398987, -0.5931981801986694, 0.18568867444992065, -0.07426042854785919, 0.45316436886787415, -0.5161677002906799, -0.4561024010181427, 0.1321655511856079, 0.8975053429603577, 0.3759390115737915, 0.5267049074172974, 0.3763768672943115, 0.4280277192592621, 0.6396281123161316, 0.6058608293533325, 0.8369108438491821, -0.5365807414054871, 0.01947946660220623, -0.5837430953979492, -0.53542160987854, 0.15506745874881744, -0.3645547032356262, -0.2535177767276764, -0.34173083305358887, -0.35156866908073425, 0.31511378288269043, -0.06973475217819214, -0.0553293377161026, 1.4217714071273804, 0.5407939553260803, 0.389817476272583, -0.7329449653625488, -0.033024728298187256, -0.4034992456436157, -0.9954906105995178, -0.3187337815761566, -0.3983554542064667, -0.22183915972709656, -0.49944305419921875, -0.3088838458061218, -0.3082674741744995]}, "authors": [{"authorId": "2256185766", "name": "Yu Wang"}, {"authorId": "2303432425", "name": "Ruihan Wu"}, {"authorId": "2116458151", "name": "Zexue He"}, {"authorId": "2283264499", "name": "Xiusi Chen"}, {"authorId": "2258962117", "name": "Julian McAuley"}], "references": [{"paperId": "ec072b1382e8da7480737a8cc5b9ca98dda30c9a", "title": "Machine Unlearning of Pre-trained Large Language Models"}, {"paperId": "b6d2f5c7c488d3de265559e005dec13d65ef7607", "title": "Model Editing by Standard Fine-Tuning"}, {"paperId": "5dd7c7654811a45f364ceca9fdbc2b4116e49eda", "title": "Towards Safer Large Language Models through Machine Unlearning"}, {"paperId": "d0b02eb4f0d3efd884b49450efc88145bdf49abc", "title": "Rethinking Machine Unlearning for Large Language Models"}, {"paperId": "3287f11b060dc720d8b6a71a3404679d5bd76f56", "title": "Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models"}, {"paperId": "2ad4dd3cd42accd2fb04150b3bf02d3dd8879e22", "title": "Unlearning Traces the Influential Training Data of Language Models"}, {"paperId": "be974844cd1e5a441fcfebcff62f72e48af46f63", "title": "Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges"}, {"paperId": "0399533de2d1d21f456663d1bd5355c8b3c32a58", "title": "Unlearn What You Want to Forget: Efficient Unlearning for LLMs"}, {"paperId": "18d18d4ffdc070868ce06f216a2a8d040d42a4cb", "title": "Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models"}, {"paperId": "8fd11c6f3eb1d0aeb915369f3c4f0b1bb24cab0c", "title": "Large Language Model Unlearning"}, {"paperId": "6cc6d59984853e5ddcbd696c443b14244d305b50", "title": "In-Context Unlearning: Language Models as Few Shot Unlearners"}, {"paperId": "40a7c44d1cfaa9faf1f731a6f93a889fab5426da", "title": "Who's Harry Potter? Approximate Unlearning in LLMs"}, {"paperId": "b31a5884a8ebe96b6300839b28608b97f8f8ef76", "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding"}, {"paperId": "8f93f95e093aab16e594b4a246a205007e107c7a", "title": "Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions"}, {"paperId": "ff2a0fb125e7f03428420230c6ecbeafd4cf07a8", "title": "Can We Edit Factual Knowledge by In-Context Learning?"}, {"paperId": "f5c73d9e6641b018b633690102121f5605d34fb0", "title": "Editing Large Language Models: Problems, Methods, and Opportunities"}, {"paperId": "a9be51698e7c2247853b7b6f1f70fc4d6d7ef605", "title": "Transformer-Patcher: One Mistake worth One Neuron"}, {"paperId": "560b1bc012588731b26748e33236570df777baa0", "title": "Aging with GRACE: Lifelong Model Editing with Discrete Key-Value Adaptors"}, {"paperId": "2fe1ac0b09cc0f50eb83eef6c7c6b45ac8b12413", "title": "Mass-Editing Memory in a Transformer"}, {"paperId": "ddc9aeac18638575bbb90ede4c6829ec15c2947e", "title": "Prompting as Probing: Using Language Models for Knowledge Base Construction"}, {"paperId": "1d650f1afd45c59ff907396fe8b678595dcb85ea", "title": "Memory-Based Model Editing at Scale"}, {"paperId": "023edab4738690444e3924e224c2641017a0d794", "title": "Quark: Controllable Text Generation with Reinforced Unlearning"}, {"paperId": "37e664778284314b05fd26177ce14f631ac1550e", "title": "Probing Simile Knowledge from Pre-trained Language Models"}, {"paperId": "996445d847f06e99b0bd259345408a0cf1bce87e", "title": "Locating and Editing Factual Associations in GPT"}, {"paperId": "9286ac6e9b1aacd7d93496eb4615ae7678876d2a", "title": "Fast Model Editing at Scale"}, {"paperId": "7e5008713c404445dd8786753526f1a45b93de12", "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow"}, {"paperId": "4a54d58a4b20e4f3af25cea3c188a12082a95e02", "title": "Transformer Feed-Forward Layers Are Key-Value Memories"}, {"paperId": "5270b626feb66c8c363e93ba6608daae93c5003b", "title": "Modifying Memories in Transformer Models"}, {"paperId": "83b404d692d8a1f587cf4498dc86e8b3ca2c04f0", "title": "The California Consumer Privacy Act (CCPA)"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "133000fa446dc445ba0a2930f9629ee19a62fb35", "title": "General Data Protection Regulation (GDPR)"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": "fa025e5d117929361bcf798437957762eb5bb6d4", "title": "Zero-Shot Relation Extraction via Reading Comprehension"}, {"paperId": "7ff1fb0eac5a72301e33ecf8344c4a03f430dc67", "title": "Deciphering the lmpact of Pretraining Data on Large Language Models through Machine Unlearning"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully"}, {"paperId": null, "title": "A framework for few-shot language model evaluation"}]}