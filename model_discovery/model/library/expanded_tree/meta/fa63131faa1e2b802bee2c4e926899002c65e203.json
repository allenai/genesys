{"paperId": "fa63131faa1e2b802bee2c4e926899002c65e203", "abstract": "Modern large language models (LLMs), such as ChatGPT, have demonstrated impressive capabilities for coding tasks including writing and reasoning about code. They improve upon previous neural network models of code, such as code2seq or seq2seq, that already demonstrated competitive results when performing tasks such as code summarization and identifying code vulnerabilities. However, these previous code models were shown vulnerable to adversarial examples, i.e. small syntactic perturbations that do not change the program's semantics, such as the inclusion of\"dead code\"through false conditions or the addition of inconsequential print statements, designed to\"fool\"the models. LLMs can also be vulnerable to the same adversarial perturbations but a detailed study on this concern has been lacking so far. In this paper we aim to investigate the effect of adversarial perturbations on coding tasks with LLMs. In particular, we study the transferability of adversarial examples, generated through white-box attacks on smaller code models, to LLMs. Furthermore, to make the LLMs more robust against such adversaries without incurring the cost of retraining, we propose prompt-based defenses that involve modifying the prompt to include additional information such as examples of adversarially perturbed code and explicit instructions for reversing adversarial perturbations. Our experiments show that adversarial examples obtained with a smaller code model are indeed transferable, weakening the LLMs' performance. The proposed defenses show promise in improving the model's resilience, paving the way to more robust defensive solutions for LLMs in code-related applications.", "venue": "arXiv.org", "year": 2023, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "The experiments show that adversarial examples obtained with a smaller code model are indeed transferable, weakening the LLMs' performance, and proposed prompt-based defenses show promise in improving the model's resilience, paving the way to more robust defensive solutions for LLMs in code-related applications."}, "embedding": {"model": "specter_v2", "vector": [0.01118586678057909, 0.8813735246658325, -0.3105350732803345, 0.4844018816947937, -0.8626591563224792, -0.8000608086585999, 0.7986096143722534, 0.029039926826953888, 0.16247406601905823, -0.4109589159488678, 0.3230123519897461, -0.6259059309959412, 0.9675502181053162, 0.2437005341053009, -0.5736313462257385, 0.11699371039867401, -0.6303576231002808, -0.32812267541885376, 0.2056482583284378, -0.33878082036972046, 0.4394722878932953, -0.6792205572128296, -0.4896351099014282, 0.5341128706932068, 0.5925804376602173, 0.16376613080501556, -0.8067798614501953, 0.9550653100013733, -0.40055933594703674, 0.9170080423355103, -0.03831794857978821, -0.6928042769432068, 0.2871960699558258, 0.1944335699081421, -0.4338069260120392, -0.22511136531829834, 0.3931747078895569, -0.1940736323595047, -0.3900701403617859, 1.1710741519927979, -0.2623446583747864, -0.11682885140180588, 0.01880074292421341, -0.5737486481666565, -0.44493648409843445, 0.9578359723091125, 0.019165443256497383, 0.6328868865966797, 0.08750621229410172, 0.18271683156490326, 0.6413058042526245, -1.02378249168396, 0.1890222728252411, 1.3513036966323853, 0.6423177123069763, 0.8024500608444214, -0.3843579590320587, -0.6955004930496216, 0.16259649395942688, -0.16222158074378967, -1.038074016571045, -0.3025585412979126, -0.25193673372268677, -0.24210698902606964, 1.634492039680481, -0.10476797819137573, -0.7290918231010437, 0.36044469475746155, 0.4724627435207367, 1.0144951343536377, -0.08374057710170746, -0.8337159752845764, -0.07853832840919495, 0.22012071311473846, 0.1442309021949768, 0.8982946276664734, -0.027939466759562492, 0.35233521461486816, -0.7411302924156189, -0.6762785911560059, -0.06497190147638321, -0.31973785161972046, -0.048642292618751526, -0.13072700798511505, 0.1572517603635788, 0.6842836737632751, 0.21286991238594055, 0.6162718534469604, 0.35183990001678467, 1.1564639806747437, 0.6321448683738708, 0.29308149218559265, -0.12879793345928192, 0.6931590437889099, 0.08548472821712494, 0.044577281922101974, -0.3964497447013855, -0.012986150570213795, 0.26614758372306824, 0.9091341495513916, -0.32468268275260925, 0.43773946166038513, -0.7798404693603516, -0.33311501145362854, 0.7903696298599243, 0.09814584255218506, 0.33669811487197876, -0.5976009368896484, 0.6741185784339905, -0.7627900838851929, 0.10386106371879578, -0.6801590919494629, 0.2090347558259964, -0.05551939830183983, -0.31173673272132874, -0.5411163568496704, -0.31125694513320923, -0.49397650361061096, -0.4952540099620819, 0.47936517000198364, -0.6023414731025696, -0.06797260791063309, 0.0809621661901474, 0.138376846909523, 0.4096909165382385, 0.644384503364563, 0.25654515624046326, 0.038456957787275314, 0.4386095404624939, -0.5242448449134827, -0.30144208669662476, -0.9675993919372559, 1.1638768911361694, -0.5124779343605042, 0.054321594536304474, -0.3206632435321808, -1.3846675157546997, -0.7008327841758728, -0.8595894575119019, 0.3549308478832245, -0.399841845035553, -0.04200097918510437, 0.37821587920188904, 0.6766310930252075, -0.8154342174530029, 0.841145932674408, -0.5477312207221985, -0.08235671371221542, 0.7287253737449646, 0.2773621380329132, 0.24390091001987457, -0.32453131675720215, -1.0140539407730103, 0.337936669588089, 0.36543697118759155, -0.946462094783783, -0.29639068245887756, -0.47497960925102234, -1.2025443315505981, 0.0008030074532143772, 0.5769880414009094, -0.03249076008796692, 1.3920530080795288, 0.010461459867656231, -0.9114347100257874, 0.7104889154434204, 0.025729205459356308, -0.01965206116437912, 0.42180487513542175, 0.0578203946352005, -0.4227767884731293, -0.5349116921424866, -0.25910839438438416, 0.10080890357494354, 0.6850337386131287, -0.6629396677017212, 0.4212331175804138, 0.7434081435203552, 0.04771946743130684, -0.7063685655593872, -0.4063471555709839, 0.8704747557640076, -0.05700496584177017, 0.02573087066411972, -0.21845151484012604, 0.5801032185554504, 0.2096010148525238, -0.08039657026529312, -0.9562130570411682, -0.6464266180992126, 0.9229573607444763, -0.11544826626777649, 1.2296258211135864, -1.2313649654388428, -0.7302102446556091, -0.047607630491256714, -0.28776970505714417, 0.46196502447128296, -0.5548291206359863, 1.049398422241211, -0.7702535390853882, 1.349454641342163, -0.5566969513893127, -1.1826032400131226, -0.1699865758419037, -0.40800297260284424, -0.9518579840660095, 0.12254096567630768, 0.38197773694992065, 1.3215904235839844, -0.6832332015037537, 0.40205034613609314, -0.45264920592308044, -0.3709797263145447, -1.010774850845337, 1.3930490016937256, -0.4852341413497925, 0.2097300887107849, 0.18107286095619202, -0.0731058344244957, 0.09840162098407745, 0.17436397075653076, 0.17387694120407104, 0.014638339169323444, -0.29919952154159546, 0.36815327405929565, 0.22490699589252472, 1.1398601531982422, -0.1644793152809143, 0.2755929231643677, -0.010137366130948067, -0.9380955696105957, -0.009725392796099186, 0.6806363463401794, -0.6850341558456421, 0.14020222425460815, 0.12557584047317505, 0.248540461063385, -0.13149474561214447, -0.3543778955936432, 0.6054760217666626, 0.4854919910430908, -0.5156616568565369, 0.632548451423645, 0.2091740369796753, -0.797565221786499, 0.06006450578570366, 0.4540517330169678, 1.1508800983428955, 0.20967301726341248, 0.4913431406021118, 0.2272578477859497, 0.43917855620384216, -0.47092896699905396, -0.37470558285713196, 0.4335366487503052, 0.6413013339042664, 1.3520601987838745, 1.0624873638153076, -0.8249015808105469, -0.25497153401374817, 0.28269386291503906, 0.9607282876968384, 0.9935465455055237, -0.07362876832485199, -0.6817228198051453, -0.5311329364776611, -1.0018151998519897, 0.010922830551862717, 0.49087628722190857, -0.6947968006134033, -1.1533637046813965, -0.6896994113922119, -1.0336922407150269, 1.2617253065109253, 0.22977212071418762, 0.9566549062728882, -0.44264158606529236, -0.19997170567512512, -0.6270332932472229, 0.3413110077381134, -0.6889142394065857, -0.7781614065170288, 0.2277657687664032, -0.19321542978286743, -0.4460431635379791, 0.6400102972984314, 0.07592728734016418, 0.5300261378288269, -0.6550322771072388, 0.6617971062660217, 0.1851317137479782, -0.6944937705993652, 0.2730652987957001, 0.3126765191555023, -0.7249434590339661, -1.5177340507507324, 0.1077205166220665, -0.20356249809265137, -0.33732685446739197, 0.10199990123510361, 0.6678937077522278, 0.5737161040306091, -0.11191479861736298, -0.9928348064422607, -0.4910496175289154, 0.10694841295480728, 0.2985295057296753, -0.2517745792865753, -0.26067599654197693, -0.21231338381767273, -1.5537278652191162, 0.815488338470459, -0.29633939266204834, -0.4973300099372864, 0.2338455617427826, -0.3408687114715576, -0.05634142830967903, 1.0771909952163696, -0.7458842992782593, -0.21026834845542908, -1.4181084632873535, 0.17984753847122192, -0.01793462224304676, -0.08054229617118835, 0.48490890860557556, 0.44616392254829407, -0.33140480518341064, 0.681062638759613, 0.5597788691520691, 0.4938699007034302, -0.013152350671589375, 0.2549825608730316, -1.0157208442687988, 0.5916545987129211, 0.07980719208717346, 1.1584275960922241, -0.2712274491786957, -0.342183917760849, -0.27165237069129944, -0.15666721761226654, 0.3555581569671631, 0.0690167248249054, 0.011013466864824295, 0.013272491283714771, -0.28616729378700256, -0.8827356696128845, 0.07538773119449615, -1.2725027799606323, -0.4838533401489258, -0.0016717662801966071, -0.8197517395019531, -0.25460612773895264, -0.39471763372421265, -1.1578030586242676, -0.6012679934501648, -0.20893628895282745, -0.8361109495162964, 0.31128990650177, 0.020722420886158943, -0.7944217324256897, -0.31179675459861755, -0.032193221151828766, -0.3901880979537964, 0.9851114153862, -0.13250264525413513, 1.2614474296569824, -0.10936974734067917, -0.36230525374412537, -0.35310831665992737, 0.4305286705493927, 0.4641090929508209, -0.36728596687316895, 0.7056927680969238, -0.8991716504096985, -0.23860152065753937, 0.07052778452634811, -0.765465497970581, -0.017207108438014984, -0.618948221206665, 0.7782883048057556, -0.4106130003929138, -0.4047929048538208, 0.4385281205177307, 1.5882682800292969, -0.32843390107154846, 0.18656009435653687, 0.10601060092449188, 1.180769681930542, 0.5028595924377441, -0.14147433638572693, 0.6838628053665161, -0.3557352125644684, 0.14372436702251434, 0.6740894913673401, 0.1852813959121704, 0.26516300439834595, -0.35412877798080444, 0.7960318922996521, 0.9571892619132996, 0.5140902996063232, -0.08102848380804062, -1.5272279977798462, 0.2589375376701355, -1.1532280445098877, -0.7315327525138855, 0.6378183960914612, 0.76727294921875, 0.578291654586792, -0.14995981752872467, -0.6861287355422974, -0.038725391030311584, 0.7086620926856995, 0.26592138409614563, -0.5328502655029297, -1.1256237030029297, 0.5412049889564514, 0.4873216450214386, 0.23600895702838898, 0.3297122120857239, -0.5950448513031006, 0.28458818793296814, 14.667994499206543, 0.6487874388694763, -0.21142363548278809, 0.6582280397415161, 0.3752356469631195, 0.25218379497528076, -0.2908198833465576, -0.2111586332321167, -0.7046763896942139, -0.07226161658763885, 1.0484760999679565, -0.19660012423992157, 0.45028895139694214, 0.2824479639530182, -0.42168301343917847, 0.03749542310833931, -0.3178195059299469, 0.33578673005104065, 0.8310428261756897, -1.2962055206298828, 0.10290340334177017, 0.10301301628351212, 0.8376015424728394, 0.2869393527507782, 1.0864379405975342, 0.8052765130996704, 0.7205258011817932, -0.6839762926101685, 0.6283136606216431, -0.5197115540504456, 1.0872316360473633, -0.17854762077331543, 0.7458567023277283, 0.9505643248558044, -0.2817329168319702, -0.5403278470039368, -0.6339574456214905, -1.2675925493240356, -0.1778637319803238, -0.36513108015060425, -0.7082551717758179, -0.2919110059738159, -0.49003663659095764, 0.5607585310935974, -0.3694882094860077, 0.42389747500419617, -0.5379243493080139, 0.6094896197319031, 0.18554045259952545, 0.25770071148872375, -0.05754467472434044, 1.122934341430664, 0.3557690382003784, 0.0039702244102954865, 0.08297353982925415, 0.0192966777831316, 0.0544479601085186, 0.7406578063964844, -0.6306252479553223, -0.23353414237499237, -0.6945931911468506, -0.49332597851753235, -0.10341618955135345, 0.5225968360900879, 0.7228236794471741, 0.31741392612457275, -0.6812731027603149, 0.36801910400390625, 0.8335192203521729, 0.17894625663757324, -0.18197274208068848, -0.04701373726129532, 0.29750552773475647, -0.003409401513636112, 0.13483752310276031, 0.3354750871658325, -0.466359406709671, -0.7529675960540771, -0.5905190110206604, -0.503426194190979, 0.2364417314529419, -0.47421374917030334, -0.49660083651542664, 0.9116509556770325, -0.2884107232093811, -0.9341453313827515, 0.2971689999103546, -0.5296499729156494, -0.8960193991661072, 0.31539785861968994, -1.224531888961792, -0.27108344435691833, 0.36389097571372986, -0.49876901507377625, -0.5663815140724182, -0.28773748874664307, 1.4647586345672607, -0.47543585300445557, -0.3748507797718048, 0.2728632092475891, 0.26073023676872253, 0.35119637846946716, 0.2795066237449646, -0.9749072194099426, 1.3428723812103271, 0.860649585723877, -0.4457387328147888, 0.3515699505805969, 0.18108732998371124, -0.14173369109630585, -0.7158517241477966, -0.2589305341243744, 0.3339094817638397, -1.3145884275436401, -0.12264233082532883, -0.6658498048782349, -1.0060968399047852, 0.31641942262649536, 0.6313831806182861, -0.11718607693910599, 0.37328049540519714, -0.24476784467697144, -1.0991078615188599, 0.2727130651473999, -0.7797278165817261, 0.08079562336206436, 0.09043683856725693, -1.1444798707962036, -0.694943368434906, 0.027421651408076286, 0.27497372031211853, -1.003199577331543, -0.28039729595184326, -0.12929818034172058, -0.2089170664548874, -0.3948570489883423, 0.29977431893348694, -0.4315362870693207, 1.4173036813735962, 0.6648702025413513, 0.201398104429245, -0.8910724520683289, 0.15295688807964325, -1.3096123933792114, 0.19304373860359192, 0.5138363242149353, 0.5280315279960632, -0.3974617123603821, -0.004561515524983406, 1.521572232246399, -0.056780967861413956, 0.010182758793234825, -0.6106184124946594, -0.17543254792690277, 0.5278862118721008, -0.3872867226600647, -0.1468334197998047, 0.08811605721712112, 0.5877547264099121, -0.5832836031913757, 0.17188744246959686, 0.9586620330810547, -0.5483845472335815, -0.668176531791687, 0.6489136219024658, 0.25338008999824524, -0.37096235156059265, -0.31739187240600586, -0.5519610643386841, -0.6906927824020386, 0.2764800190925598, -1.2640321254730225, 0.45077845454216003, -0.29287031292915344, -0.6563274264335632, 0.6013774871826172, 0.219447061419487, 0.22721238434314728, 0.16521839797496796, -0.131480872631073, 0.0732002779841423, -0.2837636172771454, -0.469736784696579, 0.6000677347183228, 0.2982531189918518, -0.9339255094528198, 0.44857969880104065, 0.05443573370575905, -0.28413617610931396, 0.20204947888851166, 0.4178032875061035, -1.046277403831482, -0.3105074167251587, -1.3354096412658691, 0.4433678090572357, -0.23667435348033905, -0.17338326573371887, -0.8515092730522156, 0.5956224799156189, 0.5587226152420044, -0.3962498605251312, 0.8782760500907898, -0.06352955102920532, -0.9409263730049133, -0.6302737593650818, 0.8057935833930969, -0.9102785587310791, 0.2903328835964203, 0.5711506605148315, -0.3554621934890747, -0.46325284242630005, 0.3760819733142853, -0.05470196157693863, -0.9705098271369934, -0.3013034760951996, 0.17419908940792084, -1.074341893196106, 0.14303606748580933, 0.4771231710910797, 0.2269454002380371, -1.6597243547439575, -0.4682466983795166, -0.1384037882089615, 0.3828921914100647, 0.09443935751914978, 0.9475383758544922, -0.09647982567548752, -0.8517624139785767, 0.22524495422840118, 0.7332974672317505, 0.07621423155069351, -0.06431791186332703, 0.43189695477485657, 0.20375895500183105, -0.8870395421981812, 0.31980058550834656, 0.231017604470253, 0.559621274471283, -1.1117891073226929, 0.5603955984115601, 0.5602746605873108, -0.3354889750480652, 0.1190243810415268, 1.141737699508667, -0.010124758817255497, -0.9001631140708923, 0.05700318142771721, -0.931373655796051, -0.26231980323791504, -0.7031374573707581, 0.6635122895240784, -0.15265628695487976, -0.18287523090839386, 0.05913687124848366, -0.5389611721038818, 0.33855539560317993, -0.10075604170560837, -0.13377754390239716, 0.14015436172485352, -0.07059549540281296, -0.5977439284324646, 0.5466539263725281, 0.7777566313743591, 0.03188292682170868, -0.4594271183013916, -0.6734512448310852, -0.23445791006088257, -0.22023829817771912, -0.5089249014854431, -0.26179057359695435, -0.44578948616981506, 1.121011734008789, -0.10265644639730453, 0.6152952313423157, -0.1669108122587204, -0.19808341562747955, -0.13690389692783356, 0.4976886212825775, 0.015190326608717442, 0.021951694041490555, -0.24033895134925842, 1.2430250644683838, 1.3587756156921387, -0.9695154428482056, 0.2625659704208374, -0.6045336127281189, -0.7222458124160767, 1.2346220016479492, 0.6801158785820007, -0.29736173152923584, 0.765117347240448, 0.010714282281696796, 0.36187106370925903, 0.5165274739265442, -1.2356629371643066, 0.3761286437511444, 0.43656501173973083, 0.7640016078948975, 0.5587380528450012, -0.02980879135429859, -0.006525326520204544, 0.6731034517288208, 0.2780078947544098, -0.06735917180776596, 1.4291415214538574, 0.9606581926345825, 0.11696513742208481, -0.47454726696014404, -0.6281986236572266, 0.3424207270145416, -1.328961730003357, -0.6508200168609619, -0.2764440178871155, 0.818651020526886, 0.4031680226325989, 0.6560952067375183, 0.4342556297779083, -0.48777666687965393, 0.4106364846229553, 0.7085835337638855, -0.15827113389968872, -1.256064772605896, -0.6384332180023193, -0.6603251695632935, -0.3734762668609619, -0.2505365014076233, 0.09953780472278595, -0.5490831136703491, -0.20196622610092163, -0.6319640874862671, 0.2631850838661194, -0.06493112444877625, -0.2635055184364319, 0.9243781566619873, 0.429860383272171, 0.3632875680923462, -0.07704271376132965, -0.5490263104438782, -0.6448478698730469, -0.7137157320976257, -0.1322348266839981, -0.3915308713912964, -0.09948844462633133, 0.2286677360534668, -0.3672257959842682, -0.18296319246292114]}, "authors": [{"authorId": "2267867094", "name": "Chi Zhang"}, {"authorId": "2255392820", "name": "Zifan Wang"}, {"authorId": "2258710751", "name": "Ravi Mangal"}, {"authorId": "2623167", "name": "Matt Fredrikson"}, {"authorId": "2267879376", "name": "Limin Jia"}, {"authorId": "2258709468", "name": "Corina S. Pasareanu"}], "references": [{"paperId": "8cf9b49698fdb1b754df2556576412a7b44929f6", "title": "SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks"}, {"paperId": "1ab91d6ac7afc1a0121487a9089fa70edc1634d4", "title": "Certifying LLM Safety against Adversarial Prompting"}, {"paperId": "3e30a7ac4886b28eb50151f58e14a1d698cccd0e", "title": "Baseline Defenses for Adversarial Attacks Against Aligned Language Models"}, {"paperId": "0b0debb710366cdff461938c80763eace1651af6", "title": "Code Llama: Open Foundation Models for Code"}, {"paperId": "47030369e97cc44d4b2e3cf1be85da0fd134904a", "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models"}, {"paperId": "8275b605a1363bbb4e19028c5b3bd6ad4ce25c99", "title": "Discrete Adversarial Attack to Models of Code"}, {"paperId": "ab4ce5dda7ad4d9032995c9c049a89d65723c6aa", "title": "Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback"}, {"paperId": "c76dd4a70361c3afd2e19d046343e2dedd16ecc3", "title": "Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search"}, {"paperId": "b45ec1cb2ba6b2d1ac24723fa836aee06a3db97a", "title": "Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation"}, {"paperId": "4610ffb1b016acaa82a2065ffd1a3adbae1ce722", "title": "Large Language Models Are Human-Level Prompt Engineers"}, {"paperId": "142ebbf4760145f591166bde2564ac70c001e927", "title": "Language Models (Mostly) Know What They Know"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "a3035562e83f1638cec5beebc4669e936fa20a03", "title": "RoPGen: Towards Robust Code Authorship Attribution via Automatic Coding Style Transformation"}, {"paperId": "5cbe278b65a81602a864184bbca37de91448a5f5", "title": "Competition-level code generation with AlphaCode"}, {"paperId": "a38e0f993e4805ba8a9beae4c275c91ffcec01df", "title": "Program Synthesis with Large Language Models"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "2e05413a737a7fe823c97e12c2ddc10d4a4c9dc0", "title": "Generating Adversarial Computer Programs using Optimized Obfuscations"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "6acf0d7b24a93953269a4d52c6b2f0c7d11f9ae4", "title": "Hoppity: Learning Graph Transformations to Detect and Fix Bugs in Programs"}, {"paperId": "c345b74be9f98cca9592cc376465118df5c9f2da", "title": "Improved Code Summarization via a Graph Neural Network"}, {"paperId": "0fe2636446cd686830da3d971b31a004d6094b3c", "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages"}, {"paperId": "c6127b88f9099f93a6a5fd8698b1aaf0a35f7d5d", "title": "Adversarial Robustness for Code"}, {"paperId": "17c8d5d173d915d9662ad7b45c593d1ab3b742e1", "title": "Semantic Robustness of Models of Source Code"}, {"paperId": "2ab44880e1763baf3d8753ccb43ad3bd5f122b70", "title": "Adversarial examples for models of code"}, {"paperId": "c8e4d8ded0624f13cd7763b8e7a62fe7e36da6d3", "title": "Generalizing from a Few Examples"}, {"paperId": "564bce85c8ad9a50f4652a4d05e1ed0aaa22df49", "title": "Neural Program Repair by Jointly Learning to Localize and Repair"}, {"paperId": "98d1307bed619b58b4a44acd8e65ac58495776c2", "title": "code2seq: Generating Sequences from Structured Representations of Code"}, {"paperId": "c70f11da5a8bb2df36def1d99c4c08df315e2233", "title": "DeepBugs: a learning approach to name-based bug detection"}, {"paperId": "c68fbc1f4aa72d30974f8a3071054e3b227137fd", "title": "Generating Natural Language Adversarial Examples"}, {"paperId": "2403c68b7805342fc2c7dc6815bc29e189fb495a", "title": "code2vec: learning distributed representations of code"}, {"paperId": "514e7fb769950dbe96eb519c88ca17e04dc829f6", "title": "HotFlip: White-Box Adversarial Examples for Text Classification"}, {"paperId": "5f1d429ba574581ac14effe3ebab654a57dc0e39", "title": "Learning to Represent Programs with Graphs"}, {"paperId": "7aa38b85fa8cba64d6a4010543f6695dbf5f1386", "title": "Towards Deep Learning Models Resistant to Adversarial Attacks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "62e176977d439aac2e2d7eca834a7a99016dfcaf", "title": "Probabilistic model for code with decision trees"}, {"paperId": "484ed558a5863060b373e8a2cb7cb302b8c36116", "title": "A Convolutional Attention Network for Extreme Summarization of Source Code"}, {"paperId": "bee044c8e8903fb67523c1f8c105ab4718600cdb", "title": "Explaining and Harnessing Adversarial Examples"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad", "title": "Intriguing properties of neural networks"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "33a0803fc10233bd05756ed83db92e8d827d3396", "title": "Randomized Smoothing for Stochastic Optimization"}, {"paperId": "e50921bc8585bf78ef896e1f31718c5ca102aa67", "title": "Can Large Language Models Reason about Program Invariants?"}, {"paperId": null, "title": ". Model Card and Evaluations for Claude Models"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Transfer Attacks and Defenses for Large Language Models on Coding Tasks"}, {"paperId": null, "title": "2022. Chain-of-thought prompting elicits reasoning in large language models"}, {"paperId": null, "title": "2023. Automated program repair in the era of large pre-trained language models"}, {"paperId": null, "title": "OpenAI. 2023. GPT-4 Technical Report"}]}