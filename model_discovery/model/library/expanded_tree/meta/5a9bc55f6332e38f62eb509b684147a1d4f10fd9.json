{"paperId": "5a9bc55f6332e38f62eb509b684147a1d4f10fd9", "abstract": "Recently, Vision Transformer and its variants have shown great promise on various computer vision tasks. The ability of capturing local and global visual dependencies through self-attention is the key to its success. However, this also brings challenges due to quadratic computational overhead, especially for the high-resolution vision tasks ( e.g. , object detection). Many recent works have attempted to reduce the cost and improve model performance by applying either coarse-grained global attention or \ufb01ne-grained local attention. However, both approaches cripple the modeling power of the original self-attention mechanism of multi-layer Transformers, leading to sub-optimal solutions. In this paper, we present focal attention , a new attention mechanism that incorporates both \ufb01ne-grained local and coarse-grained global interactions. In this new mechanism, each token attends its closest surrounding tokens at \ufb01ne granularity and the tokens far away at coarse granularity, and thus can capture both short-and long-range visual dependencies ef\ufb01ciently and effectively. With focal attention, we build a new variant of Vision Transformer models, called Focal Transformers , which achieve superior performance over the state-of-the-art (SoTA) Vision Transformers on a range of public image classi\ufb01cation and object detection benchmarks. In particular, our Focal Transformer models with a moderate size of 51.1M and a large size of 89.8M achieve 83.6 % and 84.0 % Top-1 accuracy, respectively, on ImageNet classi\ufb01cation at 224 \u00d7 224 . When employed as the backbones, Focal Transformers achieve consistent and substantial improvements over the current SoTA Swin Transformers [43] across 6 different object detection methods. Our largest Focal Transformer yields 58.7 / 59.0 box mAPs and 50.9 / 51.3 mask mAPs on COCO mini-val/test-dev, and 55.4 mIoU on ADE20K for semantic segmentation, creating new SoTA on three of the most challenging computer vision tasks. Our code is available at: https://github. com/microsoft/Focal-Transformer .", "venue": "Neural Information Processing Systems", "year": 2021, "citationCount": 106, "influentialCitationCount": 11, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A new variant of Vision Transformer models, called Focal Transformers, is built, which achieve superior performance over the state-of-the-art (SoTA) Vision Transformers on a range of public image classi\ufb01cation and object detection benchmarks."}, "embedding": {"model": "specter_v2", "vector": [0.3656126856803894, 0.27427369356155396, -0.37709593772888184, 0.1457003355026245, -0.18918484449386597, 0.2564835846424103, 0.7500418424606323, -0.3586684763431549, -0.6109142303466797, -0.5626586675643921, 0.35809126496315, 0.9058365225791931, 0.5793004631996155, -0.07100814580917358, -0.36377716064453125, 0.10447809100151062, -0.8169954419136047, 0.12166307121515274, 1.0207703113555908, -0.3841915428638458, 0.14333559572696686, -0.6227338910102844, -1.4313057661056519, 0.26279008388519287, 0.2843802571296692, 0.8564687967300415, 0.5505803227424622, 1.1034129858016968, -0.26357534527778625, 0.528652012348175, 0.21646124124526978, -0.1879831701517105, 0.2703644931316376, 0.12921665608882904, -0.4780724048614502, 0.18076670169830322, 0.8267848491668701, -0.31484556198120117, -0.6311432719230652, 1.1526165008544922, -0.19952651858329773, 0.016901319846510887, 0.32504260540008545, -0.7518543601036072, -0.41933634877204895, 0.6176841855049133, 0.20302660763263702, 1.0969918966293335, -0.6332553029060364, -0.47764071822166443, 1.2686713933944702, -1.3585081100463867, 0.32136040925979614, 1.8807591199874878, 0.3025601804256439, 0.08055061101913452, -0.14796032011508942, -0.45696187019348145, 0.9796873331069946, 0.5919628143310547, -0.6843039989471436, -0.45241302251815796, 0.08500459045171738, -0.1533762365579605, 2.008315324783325, -0.5713332295417786, 0.20424926280975342, 0.33986493945121765, 0.3320922255516052, 1.5380802154541016, -0.22482769191265106, -0.7003669142723083, -0.3411540687084198, -0.3030804395675659, 0.46427226066589355, 0.8363677263259888, -0.11244852095842361, 0.2535896599292755, -0.9778006076812744, 0.34428688883781433, 0.7224798798561096, 0.11702194064855576, 0.4451455771923065, -0.22716982662677765, -0.20902173221111298, 0.5942850708961487, 0.9643990397453308, 0.5742900371551514, -0.332352876663208, 1.1989145278930664, 0.49387574195861816, -0.09992289543151855, -0.08999048173427582, 0.07216066867113113, 0.1400935798883438, 0.9104396104812622, -0.5854393243789673, 0.14834561944007874, -0.3219149708747864, 0.9480424523353577, 0.1577369123697281, 0.1266091912984848, -0.5926029682159424, 0.16537486016750336, 1.4506480693817139, 0.2538273334503174, 0.21783864498138428, -0.6553577780723572, -0.16337375342845917, -0.6991279721260071, 0.08640912920236588, -0.9311426877975464, 0.07065629214048386, -0.5542318224906921, -0.4338533580303192, -0.5953306555747986, -0.149936243891716, 0.7066125273704529, -1.1878193616867065, 0.4689902663230896, -0.05746743083000183, 0.3069028854370117, -0.2577313780784607, 0.6815611124038696, 0.5931645035743713, 0.272601455450058, 0.5758476257324219, 0.5105637907981873, 1.410553216934204, -1.3317006826400757, -0.21659588813781738, -1.1907399892807007, -0.1331644207239151, -0.4345564544200897, 0.14527684450149536, -0.4117956757545471, -1.140657901763916, -1.2518783807754517, -0.9234800338745117, -0.09922504425048828, -0.7365365624427795, -0.0319509394466877, 0.8672433495521545, 0.005073279608041048, -1.094939947128296, 0.6202601194381714, -0.3558741807937622, -0.46359413862228394, 0.8383798599243164, 0.07551106810569763, 0.5307794213294983, -0.254472017288208, -1.2106469869613647, 0.4740448594093323, -0.1444210708141327, -0.4934256374835968, -0.618859589099884, -0.476225346326828, -1.15342116355896, 0.2085578888654709, 0.5939997434616089, -0.58334881067276, 1.1746360063552856, -0.4720359444618225, -0.5231320858001709, 0.7180002927780151, -0.38954028487205505, -0.26783084869384766, 0.3171367049217224, -0.3695415258407593, -0.145354762673378, -0.15520836412906647, 0.2536682188510895, 0.8955300450325012, 0.9235405921936035, -0.3513268232345581, -0.5673370957374573, -0.09814418107271194, -0.23113124072551727, -0.0019883266650140285, -0.47794604301452637, 1.147665023803711, -0.7289669513702393, -0.15046562254428864, 0.24862119555473328, 0.6979005932807922, -0.004874201957136393, -0.22992518544197083, -0.17130286991596222, -1.2152104377746582, 1.1656697988510132, 0.6826725006103516, 0.2093830555677414, -0.8530102372169495, -1.061033844947815, -0.3950605094432831, 0.10258813202381134, 0.006801167968660593, -0.8942383527755737, -0.0024301987141370773, -0.15982477366924286, 0.12753242254257202, 0.1942843198776245, -0.8012120127677917, 0.09254436194896698, -0.4064027667045593, -0.5485853552818298, 0.08495555073022842, 0.627094566822052, 1.3709511756896973, -0.9320881366729736, -0.44742730259895325, 0.19435515999794006, 0.3813450038433075, -0.7082451581954956, 0.7492247223854065, -0.60061115026474, -0.3182545304298401, -0.26633408665657043, 0.035590384155511856, 0.012723703868687153, -0.41412994265556335, 0.12388838827610016, -0.6667793393135071, -0.16949382424354553, 0.5091969966888428, -0.31361156702041626, 0.9875911474227905, 0.13651831448078156, 0.5677774548530579, -0.017728086560964584, -0.8415245413780212, 0.1705978959798813, 0.020660696551203728, -0.1055503785610199, -0.8405046463012695, 0.37249404191970825, -0.29391881823539734, -0.6408312916755676, 0.2842431366443634, 0.7486178874969482, 1.3085734844207764, -0.34250909090042114, -0.029792888090014458, 0.6701180934906006, -0.18963830173015594, 0.34308186173439026, 0.5715329647064209, 0.6607385277748108, 0.7019795179367065, 0.31212306022644043, -0.4618665874004364, -0.03471121937036514, -0.5529108047485352, 0.08215687423944473, 0.771466076374054, 0.011222731322050095, 0.8680381774902344, 0.4025611877441406, -0.9228695631027222, -0.4299878180027008, 0.21384185552597046, 0.5886029601097107, 1.6898328065872192, 0.25645366311073303, 0.05510823801159859, -0.9272788166999817, -0.3845135569572449, -0.437460333108902, -0.6502659320831299, -0.7755330801010132, -0.19207891821861267, -0.3412292003631592, -1.0751683712005615, 0.7751944661140442, 0.653393030166626, 1.4896389245986938, -1.0003938674926758, -0.9209137558937073, -0.12108276039361954, 0.33567067980766296, -1.0148093700408936, -0.8514153361320496, 0.3975445628166199, -0.03302549198269844, -0.3329313099384308, 0.1857733428478241, -0.39305728673934937, 0.16642096638679504, -0.14882196485996246, 1.0631301403045654, -0.4883998930454254, -1.012690544128418, 0.2980618476867676, 0.5673873424530029, -0.8270756006240845, -0.12470857053995132, 0.10561119765043259, -0.06614184379577637, -0.058094944804906845, 0.6004649996757507, 0.6349998116493225, -0.4032649099826813, 0.5225951075553894, -0.39016464352607727, -0.22889718413352966, 0.11299251019954681, -0.010891474783420563, 0.8676570653915405, -0.16394807398319244, 0.30638939142227173, -0.9992270469665527, 0.30847442150115967, 0.3170243799686432, -0.36796095967292786, 0.16313418745994568, -0.4581064283847809, -0.47710826992988586, 0.0498497411608696, -0.6907491683959961, -0.27417677640914917, -0.33898693323135376, 0.7746549844741821, -0.7571091055870056, -0.37160345911979675, -0.32606241106987, 0.16712957620620728, -0.16214461624622345, 0.6173766851425171, 0.24327218532562256, 0.021497301757335663, 0.391250878572464, 0.4941507875919342, -1.1423096656799316, 0.9095398783683777, 0.1811394989490509, -0.1493319720029831, 0.23808415234088898, -0.17440271377563477, -0.9165117144584656, -0.4287758767604828, -0.8063953518867493, -0.4397536516189575, -0.45458075404167175, 0.5072373747825623, -0.43776237964630127, -0.8252139687538147, 0.44837498664855957, -0.9766718745231628, -0.23594307899475098, -0.0644499883055687, -0.3788587152957916, -0.2770902216434479, -1.0488781929016113, -0.9682860970497131, -0.3353327512741089, -0.4914904832839966, -1.1047930717468262, 0.30456987023353577, 0.454783171415329, -0.13333424925804138, -0.45262637734413147, -0.3384462296962738, -0.4320211112499237, 1.1875853538513184, -0.40508905053138733, 0.05074818432331085, -0.05057644098997116, -0.6885586977005005, -0.16986458003520966, -0.48762765526771545, 0.2178688496351242, -0.09072309732437134, 0.25898849964141846, -1.0222337245941162, 0.4488699734210968, -0.27759402990341187, -0.25585705041885376, 1.0163484811782837, 0.6429740786552429, 0.4612112045288086, 0.4265733063220978, -0.7120835185050964, 0.18674792349338531, 1.4089161157608032, -0.8804113268852234, 0.33487606048583984, 0.23162215948104858, 1.1004526615142822, 0.12390918284654617, 0.09298110008239746, 0.33204615116119385, 0.5981470942497253, 0.08772280067205429, 0.746828019618988, -0.5888676643371582, -0.7338859438896179, -0.46289896965026855, 0.1614580601453781, 0.5983796119689941, 0.059473924338817596, 0.27360254526138306, -0.973400890827179, 1.1228158473968506, -1.5198163986206055, -1.0069069862365723, 0.6756876111030579, 0.6455885171890259, -0.0719146654009819, -0.2036800980567932, -0.07770267874002457, -0.631811261177063, 1.0404642820358276, 0.4529609680175781, -0.7687532305717468, -0.17093148827552795, -0.16750971972942352, 0.3577655255794525, 0.5235666036605835, 0.6875383257865906, -0.8784360289573669, 1.1829015016555786, 14.672845840454102, 0.5808003544807434, -0.2107936590909958, 0.4959847033023834, 0.8403942584991455, 0.46169859170913696, 0.026055317372083664, -0.02619398944079876, -1.293591022491455, -0.38408616185188293, 0.6320294141769409, 0.366138756275177, 0.1790553331375122, 0.23081788420677185, -0.09963884204626083, 0.08862538635730743, -0.35010412335395813, 0.5714706182479858, 0.8133706450462341, -1.090566873550415, 0.14835327863693237, 0.0012363522546365857, 0.28279438614845276, 0.7281637191772461, 0.8067052960395813, 0.41835659742355347, 0.727384090423584, -0.31467387080192566, 0.5018109679222107, 0.1602245420217514, 1.015605092048645, -0.003328948048874736, -0.01723448373377323, -0.08062221109867096, -1.353869915008545, -0.13448947668075562, -0.8228816390037537, -1.0509188175201416, -0.1615726798772812, 0.07714895904064178, -0.44303980469703674, -0.7720900774002075, 0.41465675830841064, 0.8252955079078674, -0.07339169830083847, 0.5648301839828491, -0.07295579463243484, 0.12847131490707397, -0.026837171986699104, -0.05609285086393356, 0.4519864022731781, 0.9432069063186646, 0.26807573437690735, 0.3476368188858032, -0.4525550603866577, 0.20071536302566528, 0.4621245563030243, 0.4706471860408783, -0.3603596091270447, -0.4672817289829254, -0.030128514394164085, 0.18469390273094177, -0.24717578291893005, 1.1887348890304565, -0.28415820002555847, -0.010849986225366592, -0.2510044574737549, 0.1933564692735672, 0.2784965932369232, 0.2347702980041504, -0.6889230012893677, -0.09784793853759766, 0.31079041957855225, -0.3002650737762451, 0.49229463934898376, 0.5681740045547485, -0.21173958480358124, -0.34982308745384216, -0.8526908755302429, -0.0025282553397119045, 0.47819605469703674, -0.6571815609931946, -0.4766957461833954, 1.1049047708511353, -0.20060084760189056, 0.024712737649679184, 0.65803462266922, -0.8339220285415649, -0.5550249814987183, 0.06771578639745712, -1.5361930131912231, -0.9057758450508118, -0.09712600708007812, -0.061082623898983, 0.0906766876578331, 0.16143183410167694, 0.6709086894989014, 0.11151228100061417, 0.012036587111651897, -0.03631333261728287, -0.6580629348754883, 0.17806504666805267, 0.07059207558631897, -0.8692042827606201, 0.8798293471336365, 0.44829970598220825, -0.05032319575548172, -0.24338556826114655, -0.009340237826108932, 0.21203500032424927, -0.4268876314163208, -0.12385790050029755, 0.4801638424396515, -0.7512944340705872, -0.47302278876304626, -0.6032435894012451, -0.7087036967277527, 0.29711589217185974, 0.817162275314331, 0.453866571187973, -0.2607596814632416, 0.00948779284954071, -0.6335709095001221, -0.12669166922569275, -0.8314089775085449, -0.08378241956233978, 0.5550574660301208, -0.4959271252155304, -0.3590163588523865, -0.16806812584400177, 0.39683088660240173, -0.9037973284721375, -0.21312351524829865, -0.29109546542167664, 0.35332369804382324, -0.21784643828868866, 1.44214928150177, -0.41808122396469116, 0.5489864945411682, 0.6290706396102905, -0.2234703004360199, -0.5543171763420105, -0.4656108021736145, -0.6563316583633423, 0.2488551288843155, 0.48362889885902405, 0.20287925004959106, -0.4415128231048584, 0.15690124034881592, 0.6564902067184448, 0.3501497507095337, -0.31468066573143005, -0.4754081964492798, 0.016867367550730705, -0.06550541520118713, -0.4961254596710205, 0.22091719508171082, -0.11470173299312592, -0.09278078377246857, 0.005515976808965206, 0.7285537123680115, 0.5272951126098633, 0.3463676869869232, -0.47496724128723145, 0.22626620531082153, -0.14211483299732208, 0.10351477563381195, -0.6453112363815308, -0.8831714987754822, -1.3818351030349731, -0.13534002006053925, -0.7939401865005493, 0.19665025174617767, -0.9800014495849609, -0.2857266962528229, 0.13086891174316406, -0.7109696269035339, 0.19684959948062897, 0.0833413377404213, 0.30442553758621216, -0.1591625064611435, -0.4827687740325928, -1.0100511312484741, 0.5593341588973999, 1.1062254905700684, -1.00287663936615, 0.16810539364814758, -0.11226307600736618, -0.26054760813713074, 0.6892068386077881, 0.17737498879432678, -0.4242591857910156, -0.5355621576309204, -1.110061764717102, 0.06564568728208542, -0.5027438998222351, 0.3565107583999634, -0.967222273349762, 1.2173010110855103, 0.31853508949279785, 0.18149906396865845, -0.042628806084394455, 0.40234440565109253, -0.563055694103241, -1.1425336599349976, 0.48348405957221985, -0.6623363494873047, -0.1971314251422882, 0.19875109195709229, -0.44514989852905273, -0.3215438723564148, 1.199588418006897, 0.35792839527130127, -1.4131722450256348, -1.2236419916152954, 0.36991679668426514, -0.3313145339488983, 0.2964143753051758, -0.12817659974098206, -0.175624281167984, -1.5098514556884766, -0.05909576267004013, -0.2198026478290558, 0.4528924822807312, -0.6444812417030334, 1.1671870946884155, 0.7918557524681091, -0.991479754447937, -0.007755323778837919, 0.3085253834724426, -0.24604417383670807, 0.41997474431991577, 0.571537971496582, 0.36473238468170166, -0.1506553739309311, 0.5360958576202393, -0.1566280871629715, -0.1536075919866562, -0.7536599040031433, 0.27922749519348145, 0.9828837513923645, -0.20723509788513184, -0.26815709471702576, 1.0536054372787476, 0.26535850763320923, -0.47560450434684753, 0.134349063038826, -1.0969301462173462, -0.6093423366546631, -0.0717153325676918, 0.665691614151001, 0.34618279337882996, -0.19419434666633606, -0.2859782576560974, -0.9158374667167664, 0.5905745625495911, -0.45868438482284546, -0.5639058947563171, 0.26672297716140747, -0.09960921108722687, -0.22567452490329742, 0.12454266101121902, 0.4279026389122009, -0.867268979549408, -1.3411402702331543, -1.093120813369751, -0.6122354865074158, -0.3610173761844635, 0.42511942982673645, -0.27700257301330566, -0.9009095430374146, 0.7645444869995117, 0.6324813365936279, 0.5603499412536621, 0.13214413821697235, 0.2120964527130127, -0.03708989545702934, 0.5361241698265076, -0.15912805497646332, -0.6752390265464783, -0.26937317848205566, 1.1522964239120483, 1.1906442642211914, -0.6926829218864441, -0.014224948361515999, -0.44873881340026855, -0.6608152985572815, 0.4723353683948517, 0.8425145745277405, -0.7659178376197815, 0.9113110303878784, 0.053253449499607086, 0.18796786665916443, 0.08943727612495422, -0.9822549819946289, -0.7427317500114441, 0.689443826675415, 1.3545862436294556, 0.24876394867897034, 0.10494542866945267, 0.5032987594604492, 0.5797792077064514, 0.5479820966720581, -0.12304535508155823, 0.2691532373428345, 0.0516674742102623, -0.6441991329193115, 0.5274108052253723, -0.3172096312046051, 0.5197443962097168, -0.7001638412475586, -0.30570152401924133, -0.053581602871418, 0.5188137292861938, 0.36645662784576416, 0.6148928999900818, 1.143924593925476, 0.27249085903167725, 0.3529447317123413, -0.09714852273464203, 0.5988279581069946, -0.4085303246974945, -0.11377063393592834, 0.12032110244035721, -1.0215431451797485, -0.23431278765201569, -0.4938778281211853, -0.9544194340705872, -0.553498387336731, 0.09003835916519165, 0.048496443778276443, -0.4123184084892273, 0.4190438985824585, 0.900982141494751, 0.5963008999824524, 1.1640359163284302, -0.519280195236206, -0.7987268567085266, -0.0656968504190445, -0.9531125426292419, 0.2996337413787842, -0.538994312286377, -0.009918919764459133, -0.5422874093055725, 0.18966108560562134, -0.053578589111566544]}, "authors": [{"authorId": "120157163", "name": "Jianwei Yang"}, {"authorId": "2109737569", "name": "Chunyuan Li"}, {"authorId": "9325940", "name": "Pengchuan Zhang"}, {"authorId": "3386593", "name": "Xiyang Dai"}, {"authorId": "2054421528", "name": "Bin Xiao"}, {"authorId": "145347147", "name": "Lu Yuan"}, {"authorId": "48441311", "name": "Jianfeng Gao"}], "references": [{"paperId": "262654ac1d13cf8d8b204594f4a88d3e04f3dd37", "title": "K-Net: Towards Unified Image Segmentation"}, {"paperId": "1fb10189c500e4902cd1b5afd406f57323d21be8", "title": "VOLO: Vision Outlooker for Visual Recognition"}, {"paperId": "b70bb1855e217edffb5dfa0632e8216860821870", "title": "Efficient Self-supervised Vision Transformers for Representation Learning"}, {"paperId": "1ee1160b8c7c70ded02e786c184a6da651e88bed", "title": "Dynamic Head: Unifying Object Detection Heads with Attentions"}, {"paperId": "77366bef01df1ab277149b330336a0ef9c5041c4", "title": "Transformer"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "68f080e0ac836ea230cb5316fbed273c70422d75", "title": "Segmenter: Transformer for Semantic Segmentation"}, {"paperId": "df9dfbe775df0c66a57308ec52900a590a92c9f7", "title": "SCTN: Sparse Convolution-Transformer Network for Scene Flow Estimation"}, {"paperId": "ad4a0938c48e61b7827869e4ac3baffd0aefab35", "title": "Emerging Properties in Self-Supervised Vision Transformers"}, {"paperId": "a1bb2e9134ca0ee67d2cbd8c54eb021625a8f17d", "title": "Vision Transformers with Patch Diversification"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "739ceacfafb1c4eaa17509351b647c773270b3ae", "title": "An Empirical Study of Training Self-Supervised Vision Transformers"}, {"paperId": "028fb10e650f68617fb7b3891da879f6cda69d94", "title": "Augmented Transformer with Adaptive Graph for Temporal Action Proposal Generation"}, {"paperId": "3cbe314cc5407a6c3249815b5173f22ea15173c2", "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "7c3ce1b3ad598a282546e03e2dc8b52c338caed6", "title": "Transformer Tracking"}, {"paperId": "91e8117e7ebc966bc76de2cb52ec717d2acdb1a4", "title": "Scaling Local Self-Attention for Parameter Efficient Visual Backbones"}, {"paperId": "2984ab83ade26639c3a82d29628d0d9e4abbebb0", "title": "Incorporating Convolution Designs into Visual Transformers"}, {"paperId": "75284d5e4dfe1cd8a9ce69085210319e14fcfa3d", "title": "Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking"}, {"paperId": "a9492c323562d31fe1d26ab8bdac1112dfdee9fe", "title": "Probabilistic two-stage detection"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"}, {"paperId": "63812f583caac3ac32bbfb64f66ba69e57c1e90a", "title": "Conditional Positional Encodings for Vision Transformers"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78", "title": "Bottleneck Transformers for Visual Recognition"}, {"paperId": "b9c3fbbea151fc2c78339139ce645ee33d2f60cd", "title": "Trear: Transformer-Based RGB-D Egocentric Action Recognition"}, {"paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b", "title": "Transformers in Vision: A Survey"}, {"paperId": "d29430adccb805ab57b349afa8553954347b3197", "title": "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "914a593b7f2e980470075a9955f1407641669a8f", "title": "Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation"}, {"paperId": "787119e3c3f819244c82b7d97779473773e60696", "title": "MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers"}, {"paperId": "2ac7999cce9f415ee87643f56631b55ed26aa10e", "title": "End-to-End Video Instance Segmentation with Transformers"}, {"paperId": "2e1db8cb373f4d4a51d44308b7a457886d855fbb", "title": "End-to-End Object Detection with Adaptive Clustering Transformer"}, {"paperId": "c13a8f9edb933e60c7a989244aee56283a54ce37", "title": "UP-DETR: Unsupervised Pre-training for Object Detection with Transformers"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "39ca8f8ff28cc640e3b41a6bd7814ab85c586504", "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "93586a3caf5c3428045399abbc5e1b096b59d623", "title": "Disentangled Non-Local Neural Networks"}, {"paperId": "13da774fe604027bff2951ba82f4c3d9be7e415e", "title": "Augment Your Batch: Improving Generalization Through Instance Repetition"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "fb93ca1e004cbdcb93c8ffc57357189fa4eb6770", "title": "ResNeSt: Split-Attention Networks"}, {"paperId": "baed71eed57ad462f3ab138d4b1700a738cd5414", "title": "ETC: Encoding Long and Structured Data in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "19f3299deda9f33003a6378788806acdb089669f", "title": "SpineNet: Learning Scale-Permuted Backbone for Recognition and Localization"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "46b3ba0f3cb8340bc94f26e0fdf6dc4e38f68948", "title": "Hierarchical Transformers for Long Document Classification"}, {"paperId": "ea700a101e501b455b1f7258216a4feff74e7286", "title": "Adaptive Context Network for Scene Parsing"}, {"paperId": "a88c914f5a738d38f02790bb5de41453bf17bde1", "title": "Object-Contextual Representations for Semantic Segmentation"}, {"paperId": "5f5fd2a068588f1d963ab88ffcbcff35b76aeb37", "title": "InstaBoost: Boosting Instance Segmentation via Probability Map Guided Copy-Pasting"}, {"paperId": "d6dccb5d71fbb6f5765f89633ba3a8e6809a720d", "title": "Stand-Alone Self-Attention in Vision Models"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "66143960c0325c70329a3869cc8052f0416b87aa", "title": "GCNet: Non-Local Networks Meet Squeeze-Excitation Networks and Beyond"}, {"paperId": "27ac832ee83d8b5386917998a171a0257e2151e2", "title": "Attention Augmented Convolutional Networks"}, {"paperId": "6303bac53abd725c3b458190a6abe389a4a1e72d", "title": "Deep High-Resolution Representation Learning for Human Pose Estimation"}, {"paperId": "1e7678467b1807777dcd9be557b79328ce9419a8", "title": "MultiGrain: a unified image embedding for classes and instances"}, {"paperId": "21248bcc81539e7cd1ef83b3b184768603f6f247", "title": "Hybrid Task Cascade for Instance Segmentation"}, {"paperId": "aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1", "title": "Unified Perceptual Parsing for Scene Understanding"}, {"paperId": "de95601d9e3b20ec51aa33e1f27b1880d2c44ef2", "title": "CBAM: Convolutional Block Attention Module"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "9217e28b2273eb3b26e4e9b7b498b4661e6e09f5", "title": "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "fb37561499573109fc2cebb6a7b08f44917267dd", "title": "Squeeze-and-Excitation Networks"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "79cfb51a51fc093f66aac8e858afe2e14d4a1f20", "title": "Focal Loss for Dense Object Detection"}, {"paperId": "2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d", "title": "Scene Parsing through ADE20K Dataset"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "53c0aa8d33d240197caff824a6225fb223c1181c", "title": "Soft-NMS \u2014 Improving Object Detection with One Line of Code"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "f6e0856b4a9199fa968ac00da612a9407b5cb85c", "title": "Aggregated Residual Transformations for Deep Neural Networks"}, {"paperId": "f651593fa6c83d717fc961482696a53b6fca5ab5", "title": "Dual Attention Networks for Multimodal Reasoning and Matching"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "71b7178df5d2b112d07e45038cb5637208659ff7", "title": "Microsoft COCO: Common Objects in Context"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "563e821bb5ea825efb56b77484f5287f08cf3753", "title": "Convolutional networks for images, speech, and time series"}, {"paperId": "6dc61f37ecc552413606d8c89ffbc46ec98ed887", "title": "Acceleration of stochastic approximation by averaging"}, {"paperId": "ea81eb2adbc71496cfc301a136385e3745ecd052", "title": "Instances"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "361ae6c15a64e4da7debc320a47dd28e5040a3c2", "title": "TubeR: Tube-Transformer for Action Detection"}, {"paperId": "03ce51e5e854faa614e79afe4dab8baeb5f73980", "title": "Twins: Revisiting Spatial Attention Design in Vision Transformers"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9e4b20d6d51cabd02ff58ed4e1b5736190e269e9", "title": "Cross-channel Communication Networks"}, {"paperId": "1e7cf9047604f39e517951d129b2b3eecf9e1cfb", "title": "Modeling Interestingness with Deep Neural Networks"}]}