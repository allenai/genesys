{"paperId": "d78df936a717f278e89221f74f3f894e90d8c1fe", "abstract": "Scholarship on generative pretraining (GPT) remains acutely Anglocentric, leaving serious gaps in our understanding of the whole class of autoregressive models. For example, we have little knowledge about the potential of these models and their societal impacts in diverse linguistic and cultural settings. We alleviate this issue for Arabic, a wide collection of languages and dialectal varieties with more than 400 million population, by introducing JASMINE. JASMINE is a suite of powerful Arabic autoregressive Transformer language models ranging in size between 300 million-6.7 billion parameters pretrained on a large and diverse dataset (~ 235 GB of text). We also carefully design and release a comprehensive benchmark for both automated and human evaluation of Arabic autoregressive models, with coverage of potential social biases, harms, and toxicity. Using our novel benchmark, we evaluate JASMINE extensively showing powerful performance intrinsically as well as in few-shot learning on a wide range of NLP tasks. We aim to responsibly release our models and evaluation benchmark with interested researchers, along with code for experimenting with them.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "citationCount": 4, "influentialCitationCount": 2, "openAccessPdf": {"url": "http://arxiv.org/pdf/2212.10755", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces JASMINE, a suite of powerful Arabic autoregressive Transformer language models ranging in size between 300 million-6.7 billion parameters pretrained on a large and diverse dataset, and carefully design and release a comprehensive benchmark for both automated and human evaluation."}, "embedding": {"model": "specter_v2", "vector": [0.1742088347673416, 1.0829957723617554, 0.10350241512060165, -0.37768876552581787, -0.2858300805091858, -0.3547310531139374, 0.9073847532272339, -0.31162405014038086, -0.1454745978116989, -0.23585988581180573, 0.36990973353385925, -0.0959831103682518, 0.33960866928100586, -0.1873500943183899, -0.1881047785282135, -0.2754962742328644, -0.9404721260070801, 0.6868253946304321, -0.39747393131256104, -1.0323718786239624, -0.42251133918762207, -0.6540337800979614, -0.7324879765510559, -0.18964941799640656, 0.4646795094013214, 0.19257639348506927, -0.24457910656929016, 0.6354060173034668, -0.19434665143489838, 0.44444510340690613, 0.5674542784690857, -1.027525544166565, 0.30509254336357117, -0.2525981068611145, -0.34100228548049927, 0.03144880011677742, 0.28262823820114136, -0.582546055316925, -0.41024330258369446, 0.6603884696960449, -0.08386316150426865, 0.3346129059791565, 0.6724092960357666, -0.6704726815223694, -0.6723080277442932, 1.0803593397140503, 0.7113226056098938, 0.6764039993286133, -0.20063447952270508, -0.32986345887184143, 0.9695529937744141, -1.302985429763794, 0.02049114927649498, 1.697616457939148, 0.7168926000595093, 0.6947075724601746, -0.07367607951164246, -0.6274935007095337, 0.5878430008888245, -0.11392267048358917, -0.4201863408088684, -0.48573780059814453, 0.12747174501419067, -0.055028386414051056, 1.2250807285308838, -0.8024332523345947, -0.025837836787104607, 0.8112324476242065, -0.08825673907995224, 1.1740872859954834, 0.04196128249168396, -0.984917938709259, -0.218973308801651, -0.09412872046232224, 0.2608336806297302, 1.1209930181503296, -0.8649551868438721, 0.2252628356218338, -0.5001919865608215, -0.10199984163045883, 0.28558778762817383, -0.1570393592119217, 0.07857570797204971, 0.3613261878490448, 0.39947637915611267, 1.2098970413208008, 0.2799077033996582, 0.8463166356086731, -0.3401297926902771, 0.4908570945262909, 0.13531740009784698, 0.3782137632369995, 0.0824657529592514, 0.12356193363666534, 0.12933792173862457, 0.4804036617279053, -0.6917296051979065, 0.07877017557621002, -0.09063007682561874, 0.9553754925727844, -0.1715424805879593, 0.6571820974349976, -0.8575449585914612, 0.1846642792224884, 1.619425892829895, 0.05842660367488861, 0.5078741908073425, -0.7943288087844849, -0.0581759475171566, -0.7122585773468018, -0.004805398639291525, -0.9726117849349976, -0.00532928854227066, -0.04478287696838379, -0.8237626552581787, -1.5050674676895142, -0.16133856773376465, -0.11490125209093094, -1.2289271354675293, 0.8366793394088745, -0.457943856716156, -0.037808652967214584, 0.14878582954406738, 0.46344199776649475, 0.47997328639030457, 1.201977014541626, 0.6098452806472778, -0.2687891125679016, 0.8422157168388367, -0.5596604347229004, -0.8457160592079163, -1.3903361558914185, 0.8318911194801331, 0.040491197258234024, 0.24941319227218628, -0.018527448177337646, -1.3416715860366821, -0.561407744884491, -0.7809368371963501, -0.029031742364168167, -0.2869880199432373, 0.27668073773384094, 1.235568642616272, 0.9435461759567261, -0.8335599899291992, 0.5154840350151062, -0.21589866280555725, -0.18715953826904297, 0.5070303082466125, 0.03787580505013466, 0.30401766300201416, -0.8003488779067993, -1.5905420780181885, 0.45608118176460266, 0.19196301698684692, -0.20053362846374512, -0.21642974019050598, -0.33712273836135864, -1.2016115188598633, 0.08511882275342941, 0.23715446889400482, -0.3372298777103424, 1.1219621896743774, -0.381399929523468, -1.6166049242019653, 0.887330174446106, -0.4224986732006073, -0.36788657307624817, 0.03875361755490303, -0.061681538820266724, -0.5922549962997437, -0.5038488507270813, -0.24693414568901062, 0.5404802560806274, 0.6601885557174683, 0.0264881681650877, 0.46017470955848694, 0.00431358627974987, -0.3122311532497406, -0.30705559253692627, -0.2863210439682007, 1.1497160196304321, -0.4750242233276367, -0.3525296449661255, 0.38332027196884155, 0.3856923580169678, -0.14808708429336548, -0.3364086151123047, -0.035318899899721146, -1.0630701780319214, 0.3812015950679779, -0.3207832872867584, 1.039488434791565, -0.8307061195373535, -0.6308637857437134, -0.2156669795513153, -0.6619746088981628, 0.12263897061347961, -0.9445590376853943, 0.4821627736091614, -0.4092859625816345, 0.2980971038341522, -0.4450453817844391, -1.0675220489501953, -0.014870201237499714, 0.09194649755954742, -1.0829020738601685, -0.10431820154190063, 0.47826096415519714, 1.0229718685150146, -0.8032501339912415, 0.08857635408639908, -0.03993228077888489, 0.3156069815158844, -1.0680310726165771, 1.011655330657959, -0.30815547704696655, 0.04577353969216347, -0.17023853957653046, 0.16702161729335785, 0.2240312546491623, -0.2901567816734314, 0.44506189227104187, -0.2958487868309021, 0.23124359548091888, 0.29784730076789856, -0.3271593153476715, 1.2738051414489746, -0.04469853267073631, 0.13764426112174988, -0.21367855370044708, -0.9144054055213928, 0.2700790762901306, 0.430078387260437, -0.45834559202194214, -0.5480279326438904, 0.46219730377197266, 0.47278159856796265, -0.4648357033729553, 0.586147665977478, 0.41004812717437744, 0.24547412991523743, -0.5359353423118591, 0.19265742599964142, 1.0550546646118164, -0.23688171803951263, 0.36634361743927, 0.4481153190135956, 0.3903086483478546, 0.17428795993328094, 0.45747169852256775, 0.041496943682432175, 0.23540380597114563, -0.8502205610275269, 0.10863432288169861, 0.4345380961894989, 0.4612494707107544, 0.7620835304260254, 0.25865980982780457, -0.8267683386802673, 0.07112488150596619, -0.018714096397161484, 0.7052211165428162, 1.7446157932281494, -0.5533242225646973, -0.17197635769844055, -0.5391237735748291, -0.20843450725078583, -0.6488243341445923, 0.32188576459884644, -0.4197140038013458, -0.03281388804316521, -0.7599791884422302, -1.502575159072876, 0.7515777349472046, 0.01576635241508484, 0.7680904865264893, -0.5358681082725525, 0.04191858693957329, -0.0023184646852314472, 0.23165789246559143, -0.4750264883041382, -0.32846343517303467, 0.05137280002236366, -0.4310718774795532, 0.2380279004573822, -0.2902340590953827, 0.020243877544999123, 0.11149907857179642, -0.9726105332374573, 0.8754969835281372, -0.6078446507453918, 0.06912358105182648, 0.2824179530143738, 0.5038658380508423, -0.9201520681381226, -0.9909548163414001, -0.20177768170833588, 0.31357622146606445, -0.12735778093338013, 0.3586772382259369, 0.3846573233604431, 0.5786820650100708, -0.009533068165183067, -0.10304868221282959, -0.31789496541023254, 0.09481105953454971, 0.11445276439189911, 0.5089583992958069, -0.43155989050865173, 0.31920501589775085, -1.2744742631912231, 0.7609261274337769, -0.06460122019052505, -0.7497237324714661, 0.4952121675014496, -0.4525561034679413, -0.4865674674510956, 0.20554614067077637, -0.5676600337028503, -0.532576858997345, -0.8168008327484131, 0.059117987751960754, -0.02439490146934986, -0.19571806490421295, 0.48970526456832886, 0.31528276205062866, 0.3630024790763855, 0.4672464430332184, 0.6138264536857605, 0.3363601267337799, 0.09175916016101837, 0.785955548286438, -0.9976664781570435, 0.44108396768569946, 0.31159892678260803, 0.18334145843982697, -0.3454441726207733, -0.1017514020204544, -0.6102676391601562, -0.735540509223938, 0.20426686108112335, -0.13456763327121735, -0.38071611523628235, 0.07547515630722046, -0.9132845401763916, -0.49547243118286133, 0.26313602924346924, -0.753629207611084, -0.13224096596240997, 0.3162893056869507, -0.5669580101966858, -0.3281850516796112, -0.8940138220787048, -1.289854645729065, -0.954310953617096, -0.6282737851142883, -0.6347976326942444, 0.4247567057609558, 0.27125856280326843, -0.09393645077943802, -0.7372141480445862, 0.2066659927368164, -0.2908942401409149, 0.9425989985466003, -0.49851614236831665, 0.920732855796814, -0.2886684834957123, -0.10468333959579468, -0.29909467697143555, 0.8875779509544373, 0.4003033936023712, -0.23294392228126526, 0.4550737738609314, -0.7623322010040283, 0.18734461069107056, -0.3183504641056061, -0.686761736869812, 0.014822383411228657, 0.5465375185012817, 0.3877188265323639, -0.3706355392932892, -0.20468662679195404, 0.03191523998975754, 1.1850628852844238, -0.5277340412139893, 0.2639065384864807, -0.03804737329483032, 0.6174610257148743, 0.31749629974365234, 0.08327271044254303, 0.2571370601654053, 0.36792808771133423, 0.2099197953939438, -0.0011425323318690062, 0.39154568314552307, 0.4823976159095764, -0.4316660463809967, 0.8273571729660034, 1.6444600820541382, -0.0008117250399664044, -0.38065147399902344, -1.4570239782333374, 0.6195582151412964, -0.9447280764579773, -1.0091981887817383, 0.6539846658706665, 0.5243049263954163, 0.5972385406494141, -0.46462512016296387, -0.33211231231689453, -0.1535058170557022, 0.4069383442401886, 0.32478463649749756, 0.23045781254768372, -0.9405748248100281, -0.2137320339679718, 0.7565942406654358, -0.24981850385665894, 0.616265058517456, -0.6896191835403442, 0.8302338719367981, 15.015403747558594, 0.6402820348739624, -0.10151123255491257, 0.5776383876800537, 0.9175798296928406, 0.43821021914482117, -0.28815680742263794, -0.1854325383901596, -1.1361231803894043, -0.1873551309108734, 1.301352858543396, 0.2654373049736023, 0.6882562637329102, 0.306294709444046, -0.3175428807735443, 0.3223210275173187, -0.151746928691864, 0.38816356658935547, 0.7035837769508362, -1.25810968875885, 0.7381964921951294, 0.029901789501309395, 0.49224668741226196, 0.6167463660240173, 0.9992468357086182, 1.147238850593567, 0.6238644123077393, -0.5814598202705383, 0.09563832730054855, 0.5444819927215576, 0.307285875082016, -0.23203031718730927, 0.5487686991691589, 0.5980867147445679, -0.22904600203037262, -0.556063175201416, -0.6419876217842102, -1.1633143424987793, 0.29007402062416077, 0.0701313316822052, -0.4518689513206482, -0.38298749923706055, -0.22632946074008942, 0.7096971869468689, -0.013493098318576813, -0.044543296098709106, -0.224366694688797, 1.0848640203475952, -0.24553844332695007, 0.3091552257537842, 0.5395391583442688, -0.15372663736343384, 0.19868941605091095, -0.3596784472465515, 0.5630287528038025, 0.5505245923995972, -0.16570815443992615, 0.2828580439090729, -0.5140607953071594, 0.08977709710597992, -0.4416835904121399, -0.7944392561912537, 0.09185578674077988, 0.726657509803772, 0.7238214612007141, 0.3223664462566376, -0.20936793088912964, 0.1063341423869133, 0.35160595178604126, -0.011665103025734425, -0.1422213315963745, 0.07020653784275055, -0.08579815179109573, -0.5941985845565796, 0.007546743378043175, 0.6470287442207336, 0.13950221240520477, -0.2548644244670868, -1.0377777814865112, -0.6266359686851501, 0.6022879481315613, -1.239485502243042, -1.0764559507369995, 0.671958327293396, -0.5042017698287964, -0.13020436465740204, -0.27291691303253174, -0.672112762928009, -0.4537643790245056, 0.6195737719535828, -1.0251142978668213, -1.2572788000106812, 0.4733067750930786, -0.3355559706687927, -0.5164623260498047, -0.3926062285900116, 1.4443532228469849, -0.16574779152870178, -0.4445502460002899, 0.10834939777851105, -0.10389479249715805, 0.20956280827522278, -0.18925611674785614, -0.6440041065216064, 0.8132657408714294, 0.5928608775138855, 0.024713551625609398, 0.36203083395957947, 0.2556287348270416, 0.34497469663619995, -0.773701548576355, -0.050332263112068176, 0.7527248859405518, -1.1272249221801758, -0.6089779138565063, -0.6043842434883118, -0.9084335565567017, 0.7642692923545837, 0.5840831995010376, -0.439410924911499, 0.214002788066864, 0.32059216499328613, -0.33346429467201233, -0.12035001069307327, -0.8162355422973633, 0.05193103849887848, 0.10884467512369156, -0.619290292263031, -0.5466811656951904, 0.019899362698197365, 0.1679006814956665, -0.767509937286377, -0.3933458626270294, -0.16948384046554565, 0.05967743322253227, -0.012906337156891823, 0.8297947645187378, -0.5913220047950745, 0.594296395778656, 1.0274403095245361, -0.16864340007305145, -0.9653838276863098, -0.10955877602100372, -0.9340348243713379, 0.06485287100076675, 0.500036895275116, 0.4727202355861664, -0.4477735161781311, 0.047859109938144684, 0.9224730730056763, 0.15719036757946014, -0.26775869727134705, -0.7563717365264893, -0.07537221908569336, 0.442733496427536, -0.22185459733009338, 0.23808884620666504, 0.25512856245040894, -0.4600694179534912, 0.16546913981437683, -0.019472409039735794, 0.8639506697654724, -0.25634440779685974, -0.815741240978241, 0.35965055227279663, -0.4018353521823883, -0.08568955212831497, -0.34907886385917664, -0.31379303336143494, -1.0754666328430176, 0.02147715352475643, -0.8493500351905823, 0.03532737120985985, -0.8997992873191833, -0.7878857254981995, 0.09073997288942337, 0.10747813433408737, 0.3665069043636322, 0.42865702509880066, -0.3245435953140259, -0.4865856468677521, -0.7640047073364258, -0.06697754561901093, 0.9349302053451538, 0.815897524356842, -0.7465438842773438, 0.10755903273820877, -0.040841732174158096, -0.021646015346050262, 0.43422967195510864, 0.50033038854599, -0.6006065607070923, -0.8153541684150696, -1.2549004554748535, 0.34694021940231323, 0.04071512073278427, -0.13023963570594788, -0.6762353777885437, 0.5004611611366272, 0.2820344567298889, -0.2811507284641266, 0.09360332041978836, 0.7154408097267151, -0.6080734133720398, -0.2492567002773285, 0.09434786438941956, -0.4201125502586365, 0.24404771625995636, 0.11126039922237396, -0.40588483214378357, -0.2946472764015198, 0.5553784966468811, 0.14710810780525208, -1.0900830030441284, -0.4890000820159912, 0.6635340452194214, -0.8001258373260498, 0.1827368587255478, -0.1798797994852066, 0.01908053830265999, -1.0883054733276367, -0.5415884852409363, -0.26470881700515747, 0.26784947514533997, -0.5910847783088684, 0.8703001737594604, 0.2140766978263855, -1.1330400705337524, -0.10102444142103195, 0.2969896197319031, -0.17206822335720062, -0.25827935338020325, 0.5522376298904419, 0.284159779548645, -0.09689713269472122, 0.5730700492858887, 0.08159486949443817, 0.37644878029823303, -0.6086689233779907, -0.328678160905838, 0.8590105175971985, -0.33044663071632385, -0.024694079533219337, 1.2070221900939941, -0.3413366973400116, -1.2985262870788574, -0.1056223139166832, -0.7877591848373413, -0.8082314729690552, 0.013770046643912792, 0.4605410099029541, -0.050855252891778946, -0.2993154525756836, -0.4816734790802002, -0.17636463046073914, 0.1939985454082489, -0.044184137135744095, -0.4595518112182617, 0.9459113478660583, -0.14740407466888428, -0.4007926285266876, 0.7012993097305298, 0.21247588098049164, -0.5314114689826965, -0.6025683879852295, -0.5087700486183167, -0.4988800585269928, 0.0728161409497261, 0.21847504377365112, -0.6750307679176331, -0.39223209023475647, 1.012825608253479, 0.6202370524406433, 0.11516879498958588, 0.31726107001304626, -0.3340127468109131, -0.15579691529273987, 0.886684775352478, 0.2779673933982849, -0.6360098123550415, -0.3902215361595154, 1.6107512712478638, 1.2047189474105835, -0.8496760129928589, 0.017645882442593575, -0.332981675863266, -0.9887445569038391, 0.7823136448860168, 0.22177395224571228, -0.07796453684568405, 1.0509639978408813, -0.6316540837287903, 0.2929143011569977, 0.15670441091060638, -0.8975463509559631, -0.15861985087394714, 0.7850056886672974, 1.091480016708374, 0.7582361102104187, -0.026170436292886734, 0.00821773149073124, 1.2458267211914062, -0.005708085838705301, 0.15535412728786469, 0.8401186466217041, 0.4989239573478699, -0.44779977202415466, 0.07065553963184357, 0.30302631855010986, 0.5609936714172363, -0.6991179585456848, -0.5937411189079285, 0.009234054014086723, 0.6436401605606079, 0.06949222087860107, 0.4873393476009369, 0.5863935947418213, 0.5797790288925171, 0.3816226124763489, 0.705620288848877, 0.5942903757095337, -0.33160144090652466, -0.00955993216484785, -0.26215288043022156, -0.6003533005714417, 0.1386227309703827, -0.4400571584701538, -0.4571245312690735, -0.18244890868663788, -0.13407354056835175, 0.337812602519989, -0.10422829538583755, 0.18510204553604126, 1.5137194395065308, 0.5568679571151733, -0.08672813326120377, -0.2398359775543213, -0.25541046261787415, -0.5490117073059082, -1.0460463762283325, 0.022442713379859924, -0.7613623738288879, -0.3840383291244507, -0.2486780434846878, -0.0583227314054966, -0.22192472219467163]}, "authors": [{"authorId": "17771023", "name": "El Moatez Billah Nagoudi"}, {"authorId": "2065312024", "name": "Muhammad Abdul-Mageed"}, {"authorId": "1397289779", "name": "AbdelRahim Elmadany"}, {"authorId": "2188651859", "name": "Alcides Alcoba Inciarte"}, {"authorId": "118865912", "name": "Md. Tawkat Islam Khondaker"}], "references": [{"paperId": "7a1e71cb1310c4a873e7a4e54d1a6dab0553adce", "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "ccf90a4f1b63e14e2012ca349d1293b85f76c0f9", "title": "ORCA: A Challenging Benchmark for Arabic Language Understanding"}, {"paperId": "e65b346d442e9962a4276dc1c1af2956d9d5f1eb", "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "c1bec16532c631f7de1e571c5404e3b25c3ef22f", "title": "NADI 2022: The Third Nuanced Arabic Dialect Identification Shared Task"}, {"paperId": "74eae12620bd1c1393e268bddcb6f129a5025166", "title": "Improving alignment of dialogue agents via targeted human judgements"}, {"paperId": "3a37fef290d76029c295201cc168c0f8ecb0a0cf", "title": "Fewer Errors, but More Stereotypes? The Effect of Model Size on Gender Bias"}, {"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "7a25155364476839b6d1fc0653cd8611327ab9ba", "title": "mGPT: Few-Shot Learners Go Multilingual"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "c37d0b258386293097fa3f71f971dc5dfceb4684", "title": "Data Contamination: From Memorization to Exploitation"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "b3848d32f7294ec708627897833c4097eb4d8778", "title": "LaMDA: Language Models for Dialog Applications"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "fd1b829261ba04bb92e0ab60c4f6e7cea0d99fbf", "title": "Ethical and social risks of harm from Language Models"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "a6fdb277d0a4b09899f802bda3359f5c2021a156", "title": "Recursively Summarizing Books with Human Feedback"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "a05973d939f5a2b63f6b052e8f059d5fd73c25a1", "title": "AraT5: Text-to-Text Transformers for Arabic Language Generation"}, {"paperId": "73f949b35d0d6a234565ba219ad0f865c2db5657", "title": "Evaluating Gender Bias in Natural Language Inference"}, {"paperId": "0adec918885dff698acf359988ed79a543157f80", "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "1adadbfa95e43a70fcd17e6ce947a0652b86bfc3", "title": "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus"}, {"paperId": "7e5008713c404445dd8786753526f1a45b93de12", "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow"}, {"paperId": "56ba945a373b8e45ab77c3eb5aa6cdf670af8b39", "title": "NADI 2021: The Second Nuanced Arabic Dialect Identification Shared Task"}, {"paperId": "ca2f1088d3e581b2c6c75cf0ebc96506d620f64d", "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c"}, {"paperId": "b41e07349b87a178d904e6b5d05a2f90b16f8e1e", "title": "Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models"}, {"paperId": "c342798bafc1eaaa60c652fc90fd738941542133", "title": "AraGPT2: Pre-Trained Transformer for Arabic Language Generation"}, {"paperId": "1e4cda8be54999ced1324777fa462a85e2c9746c", "title": "ARBERT & MARBERT: Deep Bidirectional Transformers for Arabic"}, {"paperId": "806e9c367689a684ae053d8f3b5e6a9548e20607", "title": "Machine Generation and Detection of Arabic Manipulated and Fake News"}, {"paperId": "016ca039d9f5220c96b26f15d90d82064c361bfa", "title": "Learning from Task Descriptions"}, {"paperId": "74276a37bfa50f90dfae37f767b2b67784bd402a", "title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"}, {"paperId": "3294dddef61d16941db1c2d76fb4421daced2037", "title": "NADI 2020: The First Nuanced Arabic Dialect Identification Shared Task"}, {"paperId": "f00f2d4b8ddd55aa2cc202f44053e5f97a254175", "title": "WikiLingua: A New Benchmark Dataset for Multilingual Abstractive Summarization"}, {"paperId": "053b1d7b97eb2c91fc3921d589c160b0923c70b1", "title": "Learning to summarize from human feedback"}, {"paperId": "aa3b5cd16ffed973d46dd0b1020ef5df8c333acd", "title": "OpenITI: a Machine-Readable Corpus of Islamicate Texts"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "64efb2f9d7e9f139ceacc91641c2e3b7344abd0d", "title": "Understanding and Detecting Dangerous Speech in Social Media"}, {"paperId": "babeda48b10a4d638252118f2238d05a06f4ec55", "title": "StereoSet: Measuring stereotypical bias in pretrained language models"}, {"paperId": "4d96bfa3a4c283d6fcd71122897c2cb8ee1c886d", "title": "\u201cYou Are Grounded!\u201d: Latent Name Artifacts in Pre-trained Language Models"}, {"paperId": "f9ef88bfc78baeb24e697b05c307cf019f8a3630", "title": "Learning to Compare for Better Training and Evaluation of Open Domain Natural Language Generation Models"}, {"paperId": "1359d2ef45f1550941e22bf046026c89f6edf315", "title": "AraBERT: Transformer-based Model for Arabic Language Understanding"}, {"paperId": "8ae9a17c87a4518b513e860683a0ef7824be994d", "title": "Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7a15950dc71079285a4eaf195de5aadd87c41b40", "title": "Fine-Tuning Language Models from Human Preferences"}, {"paperId": "85ea337f6c0ba48bd238287068548fa9f83a8429", "title": "Finding Generalizable Evidence by Learning to Convince Q&A Models"}, {"paperId": "e471dccea2b2a05196137984847d7e2067d259a1", "title": "OSIAN: Open Source International Arabic News Corpus - Preparation and Integration into the CLARIN-infrastructure"}, {"paperId": "92343cecdc990380de362b969eec60081959f507", "title": "Asynchronous Pipeline for Processing Huge Corpora on Medium to Low Resource Infrastructures"}, {"paperId": "57daffd65a5d73a439903f3e50950c21c9eba687", "title": "Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog"}, {"paperId": "1670a07b70f90cc4ddba71343e6a7ee4b5198595", "title": "Evaluating Gender Bias in Machine Translation"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "c4afa2b3eda95a1194313394901e0e96e24cefaa", "title": "Bias in Bios: A Case Study of Semantic Representation Bias in a High-Stakes Setting"}, {"paperId": "b0b96270a9bbeb9f3ec040e70114d565fbcaaed9", "title": "Learning from Dialogue after Deployment: Feed Yourself, Chatbot!"}, {"paperId": "af5c4b80fbf847f69a202ba5a780a3dd18c1a027", "title": "SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference"}, {"paperId": "ad23a0651b0eeb87bb2bb856bea26c6b0c2f15af", "title": "The MADAR Arabic Dialect Corpus and Lexicon"}, {"paperId": "9967cb4fd949039c6f04dd9f2f4c3331dbebe6f7", "title": "Gender Bias in Coreference Resolution"}, {"paperId": "0be19fd9896e5d40222c690cc3ff553adc7c0e27", "title": "Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods"}, {"paperId": "f3eeef4afb81223df96575adadf808fe7fe440b4", "title": "1.5 billion words Arabic Corpus"}, {"paperId": "ed26aa25ee18271f8b997605888b536484787053", "title": "Large Scale Arabic Error Annotation: Guidelines and Framework"}, {"paperId": "fec1c5be9ba9d0dfc96a5d8e46b4767c54802d72", "title": "Evaluation of Topic Identification Methods on Arabic Corpora"}, {"paperId": null, "title": "Koala: A dialogue model for academic research"}, {"paperId": "448e1493034dafe35699ae054ff4480b31dcf64a", "title": "Memory-assisted prompt editing to improve GPT-3 after deployment"}, {"paperId": null, "title": "Abdel-Rahim Elmadany, Houda Bouamor, and Nizar Habash"}, {"paperId": null, "title": "Jurassic-1: Technical details and evaluation"}, {"paperId": "1d7a2d2f5671f85e9013e1c8e527c663ada12320", "title": "Twenty Years of Confusion in Human Evaluation: NLG Needs Evaluation Sheets and Standardised Definitions"}, {"paperId": null, "title": "Toward micro-dialect identification in diaglossic and code-switched environments"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "2016. 1.5 billion words arabic corpus. arXiv preprint arXiv:1611.04033"}, {"paperId": "886c019398cea760ca3711638a85b1061996e921", "title": "Subjectivity and sentiment analysis of Arabic as a morophologically-rich language"}, {"paperId": null, "title": "Accuracy and performance of google\u2019s compact language detector"}, {"paperId": null, "title": "Introduction to Arabic natural language processing , volume 3"}, {"paperId": null, "title": "Levels of contemporary arabic in egypt"}, {"paperId": null, "title": "2023. Stanford alpaca: An instruction-following llama model"}, {"paperId": null, "title": "2022. Quantifying memorization across neural language models"}, {"paperId": null, "title": "2022. Overview of OSACT5 shared task on Arabic offensive language and hate speech detection"}, {"paperId": null, "title": "2023. Gpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo"}, {"paperId": null, "title": "OpenAI"}, {"paperId": null, "title": "2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality"}, {"paperId": null, "title": "a comprehensive evaluation benchmark for zero, one, and few-shot learning across a wide range of NLP tasks"}, {"paperId": "f2e9681935997f0c54fac5235494e9287b7c76ae", "title": "Scholarship, Research, and Creative Work at Bryn Mawr College Scholarship, Research, and Creative Work at Bryn Mawr College"}]}