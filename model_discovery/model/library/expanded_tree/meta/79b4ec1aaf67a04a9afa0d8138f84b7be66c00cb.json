{"paperId": "79b4ec1aaf67a04a9afa0d8138f84b7be66c00cb", "abstract": "The research community has proposed copious modifications to the Transformer architecture since it was introduced over three years ago, relatively few of which have seen widespread adoption. In this paper, we comprehensively evaluate many of these modifications in a shared experimental setting that covers most of the common uses of the Transformer in natural language processing. Surprisingly, we find that most modifications do not meaningfully improve performance. Furthermore, most of the Transformer variants we found beneficial were either developed in the same codebase that we used or are relatively minor changes. We conjecture that performance improvements may strongly depend on implementation details and correspondingly make some recommendations for improving the generality of experimental results.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2021, "citationCount": 108, "influentialCitationCount": 7, "openAccessPdf": {"url": "https://aclanthology.org/2021.emnlp-main.465.pdf", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "It is found that most modifications to the Transformer architecture do not meaningfully improve performance, and conjecture that performance improvements may strongly depend on implementation details and correspondingly make some recommendations for improving the generality of experimental results."}, "embedding": {"model": "specter_v2", "vector": [0.6698122024536133, 0.3765309751033783, -0.09583120793104172, -0.11683470755815506, -0.4427016079425812, -0.5147287845611572, 0.5319067239761353, -0.15366333723068237, -0.6788977384567261, -0.5652624368667603, 0.8035343885421753, -0.3466131091117859, 0.4924149215221405, 0.06954449415206909, -0.19229087233543396, 0.14708924293518066, -0.38135355710983276, 0.06549298763275146, 0.12908649444580078, -0.35374829173088074, -0.5706133842468262, -0.4675132930278778, -1.0393462181091309, 0.5852176547050476, 0.5026956796646118, 0.09854522347450256, 0.01244908757507801, 0.5705208778381348, -0.2941895127296448, 0.3161258399486542, 0.6566252112388611, -0.6962190866470337, 0.5028877258300781, 0.43775805830955505, -0.17698833346366882, -0.1471560299396515, 0.4437437653541565, -0.16823875904083252, -0.0816936045885086, 0.8270307779312134, -0.41160252690315247, -0.06347232311964035, 0.1984110027551651, -1.0031450986862183, -0.49262699484825134, 1.466513991355896, 0.6543239951133728, 0.8158438801765442, -0.2640017569065094, -0.16386620700359344, 1.3699456453323364, -1.5264842510223389, 0.3331545293331146, 1.3135112524032593, 0.8771239519119263, 0.4570068418979645, -0.7828491926193237, -0.5847668647766113, 0.3046824038028717, -0.240567147731781, -0.9641784429550171, -0.9938036203384399, -0.02791113592684269, 0.06325747817754745, 1.942103385925293, -0.27375930547714233, -0.21056993305683136, -0.0865640938282013, -0.07745733112096786, 1.3124176263809204, -0.17648306488990784, -0.6757504343986511, -0.6595579981803894, -0.020248020067811012, 0.10433227568864822, 0.9142577648162842, -0.37086066603660583, 0.409225195646286, -0.7687608003616333, -0.174278125166893, 0.14695408940315247, -0.1675134003162384, -0.2859170436859131, -0.25356367230415344, -0.2977156341075897, 0.5644776225090027, 0.11449883878231049, 1.2701122760772705, -0.3064507842063904, 0.5090451240539551, 0.9933779835700989, 0.6497292518615723, -0.032939549535512924, 0.6288425326347351, -0.34061896800994873, 0.4208455979824066, -0.7681312561035156, 0.2597110867500305, 0.11900085210800171, 1.0167467594146729, 0.021956508979201317, 0.288032591342926, -0.8475882411003113, 0.14845818281173706, 1.0662325620651245, 0.2021494358778, 0.4390442371368408, -0.9090256094932556, 0.2519364058971405, -0.41226616501808167, 0.0583421066403389, -0.15646205842494965, 0.09613188356161118, 0.09453899413347244, -0.43544089794158936, -1.4030773639678955, 0.07115397602319717, 0.12332268059253693, -0.7672231793403625, 0.6886082291603088, -0.4500482678413391, -0.288120836019516, 0.13788840174674988, 0.01473538763821125, 0.6948589086532593, 0.19693979620933533, 0.7433350682258606, -0.0930066779255867, 1.0086493492126465, -0.23154491186141968, -0.716838538646698, -1.1421419382095337, 1.0373209714889526, -0.5941219925880432, 0.6619489192962646, -0.5804278254508972, -1.5553600788116455, -0.6589086055755615, -0.5887612104415894, 0.05351543799042702, -0.4914504885673523, 0.14653867483139038, 0.7969268560409546, 0.6323518753051758, -1.4782332181930542, 0.46162697672843933, 0.025207245722413063, -0.4448654353618622, 0.06060471758246422, -0.014575756154954433, 0.05805448070168495, -0.26122868061065674, -1.107122778892517, 0.10936158895492554, 0.2610378861427307, -0.6298230290412903, -0.005333275068551302, -0.9643166065216064, -1.4702807664871216, 0.041606638580560684, 0.42990392446517944, -0.6379498839378357, 1.6997404098510742, 0.005763088818639517, -1.330170750617981, 0.6866796612739563, -0.5662785172462463, 0.19794979691505432, -0.19467730820178986, -0.04521351680159569, -0.39630088210105896, -0.7667747139930725, 0.05232295021414757, 0.46675631403923035, 0.2219533920288086, 0.0005849400768056512, -0.3172890841960907, 0.21659164130687714, 0.11741874366998672, -0.05132599174976349, -0.25383317470550537, 1.226090431213379, 0.17713843286037445, -0.24077971279621124, 0.10711043328046799, 0.6234359741210938, -0.10895249992609024, -0.343427836894989, -0.41844984889030457, -1.0941740274429321, 0.7914596796035767, 0.07203999161720276, 1.0566805601119995, -1.2932746410369873, -0.48936644196510315, -0.13688236474990845, -0.3084189295768738, -0.17616644501686096, -0.9629542827606201, 0.8843442797660828, -0.6309478282928467, 0.738655686378479, -0.3507281541824341, -0.8376719355583191, 0.19365066289901733, -0.3711448609828949, -0.6012529134750366, -0.3359951376914978, 0.1631903350353241, 1.2314958572387695, -0.8181890845298767, 0.16524672508239746, 0.08074180036783218, 0.12533918023109436, -1.0508720874786377, 1.1175390481948853, 0.05693892762064934, -0.12245234102010727, 0.5700893998146057, -0.010055232793092728, 0.06218128278851509, -0.05367070809006691, 0.5104014873504639, -1.080451488494873, -0.6676453351974487, 0.7109982371330261, 0.08616893738508224, 1.2393865585327148, -0.5463415384292603, -0.0009013285161927342, 0.3674643337726593, -0.6829049587249756, -0.2518535852432251, 0.8439329266548157, -0.4023064076900482, -0.3118429481983185, 0.28623151779174805, 0.37877362966537476, -0.1727115362882614, 0.5983104705810547, 0.8503391742706299, 0.375023752450943, -0.3135269284248352, 0.2857396602630615, 0.5231000185012817, -0.6972969770431519, 0.618777871131897, 0.32834091782569885, 1.0430927276611328, 0.042106080800294876, 0.5035545825958252, -0.31822824478149414, 0.5833259224891663, -0.5275953412055969, 0.04061249643564224, 0.2885821759700775, 0.6094954609870911, 0.40984588861465454, 0.15471865236759186, -0.41547253727912903, -0.3102395832538605, -0.3340672254562378, 0.5406907796859741, 1.892230749130249, -0.4774094223976135, -0.3209124505519867, -0.5821771025657654, -0.33400067687034607, -0.81529700756073, 0.4214322566986084, -0.2340766340494156, -0.3439304530620575, -0.6939201951026917, -0.725802481174469, 1.1089566946029663, 0.2827630639076233, 0.9776245951652527, -0.6293095350265503, -0.52276611328125, -0.41352930665016174, 0.11956426501274109, -0.9230369329452515, -0.7029829621315002, 0.39926162362098694, -0.8599186539649963, -0.4046683609485626, 0.45484715700149536, -0.22502921521663666, -0.01914946176111698, -0.24458786845207214, 0.8724715709686279, -0.2914921045303345, -0.13213570415973663, 0.38476845622062683, 0.4561062455177307, -0.4811457097530365, -1.2617994546890259, 0.23807397484779358, -0.19533106684684753, -0.43928685784339905, 0.39404988288879395, 0.5658491253852844, 0.2972465753555298, 0.24220681190490723, -1.0240297317504883, -0.19580799341201782, 0.12213115394115448, 0.2432582974433899, 0.5998855829238892, -0.10820449143648148, -0.5585290193557739, -1.4340487718582153, 1.3463135957717896, 0.4839121401309967, -0.35037901997566223, 0.5213934779167175, -0.6236039400100708, 0.02807203307747841, 0.5432605147361755, -0.5092864036560059, -0.29750797152519226, -0.642665684223175, 0.2982640266418457, -0.04096563905477524, 0.007574538700282574, 0.5367804169654846, -0.09852328896522522, 0.3624213635921478, 0.19542156159877777, 0.590459406375885, 0.3331325352191925, -0.26063528656959534, 0.8747843503952026, -0.8557286262512207, 0.20636016130447388, 0.44136348366737366, 0.6540696024894714, -0.22880536317825317, -0.6020716428756714, -0.6085935235023499, 0.05661528930068016, -0.1814943253993988, 0.24380940198898315, -0.00861665140837431, -0.09417499601840973, -0.5013174414634705, -0.45526525378227234, 0.03471089527010918, -1.1481670141220093, -0.14690415561199188, -0.19665636122226715, -0.5845789313316345, 0.10708106309175491, -0.7918800711631775, -1.442733883857727, -0.369398832321167, -0.8604831695556641, -1.1934046745300293, 0.8709208369255066, -0.26911336183547974, -0.39499253034591675, -0.3417326807975769, 0.022952228784561157, -0.41323786973953247, 1.0576667785644531, -1.0374058485031128, 1.1977941989898682, 0.00853721797466278, -0.1091194897890091, 0.167702779173851, 0.16853199899196625, 0.5405464172363281, -0.11599908024072647, 0.5588600635528564, -0.8882483839988708, 0.1528349667787552, -0.23159246146678925, 0.12515674531459808, 0.10502626746892929, 0.1929665207862854, 0.2675732672214508, -0.13649232685565948, -0.6418948769569397, 0.24563927948474884, 0.9454054236412048, -0.40030044317245483, 0.2892317473888397, 0.309551477432251, 0.6408149600028992, 0.28897231817245483, -0.3393010199069977, 0.22787539660930634, 0.1869647204875946, 0.22808928787708282, 0.024555178359150887, 0.009816940873861313, 0.043584711849689484, -0.312723845243454, 0.9839823246002197, 1.6350239515304565, 0.3241654634475708, -0.15079796314239502, -1.3503117561340332, 0.4481777548789978, -1.1009055376052856, -0.8613734841346741, 0.6895634531974792, 0.5094687938690186, 0.6100704073905945, -0.6913889646530151, -0.49006399512290955, 0.16626986861228943, 0.47305986285209656, 0.37819570302963257, -0.057334963232278824, -0.7791198492050171, 0.19769839942455292, 0.8063185214996338, 0.4630822539329529, 0.5879244804382324, -0.3227013647556305, 0.9310853481292725, 14.645781517028809, 0.616596519947052, 0.015214186161756516, 0.6142345666885376, 0.021760091185569763, 0.6194230318069458, -0.6883337497711182, 0.06497398763895035, -0.8133790493011475, -0.7443516254425049, 0.8129738569259644, -0.3875004053115845, 0.9114646315574646, 0.012257557362318039, -0.06562730669975281, 0.5079159140586853, -0.6793844103813171, 0.45355334877967834, 0.029660513624548912, -1.0879943370819092, 0.6788308620452881, 0.0966300442814827, -0.24211108684539795, 0.5059571862220764, 0.659969687461853, 0.6826300024986267, 0.715032696723938, -0.3243311047554016, 0.41054216027259827, -0.1715841442346573, 0.8815712928771973, -0.11872147023677826, 0.5278340578079224, 0.30477550625801086, -1.371051549911499, -0.31598782539367676, -0.12261883169412613, -1.1253610849380493, 0.23166202008724213, 0.1912531852722168, -1.0114963054656982, -0.6613321900367737, 0.04648367315530777, 0.9411993622779846, 0.028733503073453903, 0.33791831135749817, -0.42971038818359375, 0.6103689670562744, -0.17397524416446686, 0.1653599888086319, -0.1628328114748001, 0.6300306916236877, 0.6210262179374695, 0.1735970824956894, 0.2643895447254181, -0.18598435819149017, -0.04346547648310661, 0.3658428192138672, -0.7472227811813354, 0.2997196316719055, -0.8197543025016785, -0.4875132143497467, 0.11681018024682999, 0.8451269268989563, 0.03555561602115631, 0.31621214747428894, -0.3830333948135376, 0.02726639248430729, 0.6227474808692932, 0.17440728843212128, 0.019594872370362282, -0.20167602598667145, 0.47710075974464417, 0.13133618235588074, -0.03795865923166275, 0.42832091450691223, 0.03513924404978752, -0.6690059900283813, -0.7342896461486816, -0.5439766049385071, 0.38770055770874023, -0.5436226725578308, -0.97991943359375, 0.9016939401626587, -0.0018190874252468348, -0.5571455955505371, 0.4597414433956146, -0.6804600954055786, -0.17565788328647614, -0.10087606310844421, -1.213180422782898, -0.7994645237922668, 0.44160932302474976, -0.09329649806022644, -0.6134744882583618, -0.08723749965429306, 1.3379935026168823, 0.1273924857378006, -0.08243046700954437, 0.32593339681625366, -0.07286987453699112, 0.4650595486164093, -0.006007012911140919, -0.7371731400489807, 1.0477036237716675, 0.5243744254112244, 0.21224428713321686, 0.7469838857650757, 0.3086870610713959, 0.2667708098888397, -0.8821191191673279, -0.1502443104982376, 1.0304450988769531, -0.6773545742034912, -0.00672758836299181, -0.6469822525978088, -0.8659670948982239, 0.5184157490730286, 0.737506091594696, -0.4818814694881439, 0.7787563800811768, 0.3869113624095917, -0.7984354496002197, -0.2890956699848175, -1.157349705696106, 0.4688013792037964, 1.334882378578186, -1.2593376636505127, -0.5600568652153015, -0.5570387244224548, 0.5227595567703247, -0.8890451192855835, -0.4949696362018585, 0.16625285148620605, 0.19052889943122864, 0.015950748696923256, 0.7173271179199219, -0.30233272910118103, 0.20153096318244934, 0.4368355870246887, -0.2016616314649582, -1.0039831399917603, -0.377206951379776, -0.7534180283546448, 0.6947635412216187, 0.20426958799362183, 0.906561553478241, -0.7663997411727905, -0.19871261715888977, 1.075700283050537, -0.061760421842336655, 0.23380397260189056, -0.8811787366867065, -0.05280420556664467, 0.037789907306432724, -0.540990948677063, 0.6862002611160278, -0.2439977526664734, 0.21912060678005219, 0.4374895393848419, 0.9743841290473938, 0.4939657747745514, -0.3505987823009491, -0.7180876731872559, 0.4178256392478943, -0.25760096311569214, 0.055288564413785934, -0.544129490852356, -0.44291815161705017, -0.9869021773338318, 0.2710375189781189, -1.295349359512329, 0.4647354185581207, -0.6980605721473694, -0.45714473724365234, 0.19547885656356812, -0.12517933547496796, 0.6568582653999329, 0.433336466550827, -0.29351159930229187, -0.4782370328903198, -0.41922980546951294, -0.2968969941139221, 0.8824439644813538, 0.5651265978813171, -1.0617040395736694, 0.03750714659690857, -0.30593547224998474, -0.33469319343566895, 0.31528306007385254, 0.24783186614513397, -0.6354602575302124, -0.797636091709137, -1.6537483930587769, 0.37229350209236145, -0.24818985164165497, -0.25131756067276, -0.2581198811531067, 0.7928890585899353, 0.38757410645484924, -0.47893619537353516, 0.6889174580574036, -0.26839691400527954, -1.1186052560806274, -0.16606555879116058, 0.3413843810558319, -0.6101282238960266, 0.9908190965652466, 0.5723806023597717, -0.9196209907531738, -0.4201275408267975, 0.7041064500808716, -0.009398385882377625, -1.1260826587677002, -0.7607653141021729, 0.19692085683345795, -1.2030829191207886, 0.17231033742427826, -0.1898922622203827, -0.2515135407447815, -1.0352143049240112, 0.0861230120062828, 0.09231512248516083, 0.15318916738033295, 0.027948033064603806, 0.9088246822357178, 0.3605208694934845, -0.7109655141830444, 0.18095357716083527, 0.3264482915401459, 0.17110328376293182, -0.44233813881874084, -0.023421669378876686, 0.317504346370697, -0.17873936891555786, 0.24334798753261566, 0.1498202234506607, 0.37955158948898315, -1.441595196723938, -0.32706302404403687, 0.8548641204833984, -0.4054972231388092, -0.3148907423019409, 0.8741163611412048, -0.20889684557914734, -1.1426525115966797, -0.5732836723327637, -1.501983642578125, -0.3522382080554962, -0.6720418334007263, 0.3954129219055176, 0.07380465418100357, -0.000823478156235069, -0.07733428478240967, -0.5926691293716431, 0.020627588033676147, -0.28818538784980774, -0.5006775259971619, 0.4149109423160553, 0.048879992216825485, -0.7857266664505005, 0.41140076518058777, -0.01957179233431816, -0.23847661912441254, 0.07390041649341583, -0.6863144636154175, -0.09674504399299622, 0.03222368285059929, 0.301146000623703, -0.0647105723619461, -0.9103127717971802, 0.6758154630661011, 0.36765334010124207, 0.24751366674900055, 0.4046042859554291, -0.26006364822387695, 0.11980904638767242, 0.813189685344696, 0.430671751499176, -0.5196472406387329, -0.971507728099823, 1.5056769847869873, 1.191138744354248, -0.5987704396247864, 0.13683916628360748, -0.556111216545105, -0.4440571367740631, 0.5891438126564026, 0.17183440923690796, 0.08288190513849258, 1.1964497566223145, 0.35003000497817993, 0.41693586111068726, 0.19528788328170776, -0.858871579170227, -0.3086749315261841, 0.4075290858745575, 1.0334174633026123, 1.2471823692321777, 0.3079548180103302, -0.27573299407958984, 0.7148826122283936, 0.0918571949005127, 0.5559790134429932, 0.6698492169380188, 0.6553566455841064, -0.011576632969081402, -0.6019700765609741, 0.44769832491874695, 0.6871562004089355, -0.5533374547958374, -1.2748253345489502, -0.007593183312565088, 1.0246105194091797, 0.3188052773475647, 0.6108312606811523, 0.29711711406707764, -0.0742536410689354, 1.0008152723312378, 0.6601740121841431, 0.469788134098053, -1.0582410097122192, -0.8324110507965088, -0.33957427740097046, -0.32170504331588745, -0.2972240149974823, -0.5119993686676025, -0.7260937094688416, -0.4244980216026306, -0.36736324429512024, 0.06515796482563019, 0.3561099171638489, 0.019122634083032608, 0.9220372438430786, 0.6927413940429688, 0.16443173587322235, -0.8319936394691467, -0.1727420538663864, -0.12771351635456085, -1.1786144971847534, -0.05864011123776436, -0.522570013999939, -0.45157918334007263, -0.03255379572510719, -0.27881142497062683, 0.05460895225405693]}, "authors": [{"authorId": "46617804", "name": "Sharan Narang"}, {"authorId": "3351938", "name": "Hyung Won Chung"}, {"authorId": "144447820", "name": "Yi Tay"}, {"authorId": "26958176", "name": "W. Fedus"}, {"authorId": "79215748", "name": "Thibault F\u00e9vry"}, {"authorId": "1380243217", "name": "Michael Matena"}, {"authorId": "1666667717", "name": "Karishma Malkan"}, {"authorId": "22640071", "name": "Noah Fiedel"}, {"authorId": "1846258", "name": "Noam M. Shazeer"}, {"authorId": "34692532", "name": "Zhenzhong Lan"}, {"authorId": "2389316", "name": "Yanqi Zhou"}, {"authorId": "2157338362", "name": "Wei Li"}, {"authorId": "2066767241", "name": "Nan Ding"}, {"authorId": "2059685709", "name": "Jake Marcus"}, {"authorId": "145625142", "name": "Adam Roberts"}, {"authorId": "2402716", "name": "Colin Raffel"}], "references": [{"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "bc87279d4b32a425377ff18ab63f7ecf95ff228c", "title": "Rethinking embedding coupling in pre-trained language models"}, {"paperId": "74276a37bfa50f90dfae37f767b2b67784bd402a", "title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"}, {"paperId": "4ca3b0ea12f02e2dea01a4aa505956bae5500a09", "title": "Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing"}, {"paperId": "d7c4b8f15f82825de9edcf57e499b05256c7885d", "title": "Text-to-Text Pre-Training for Data-to-Text Tasks"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "ad5970584754cc7a1d91c95ab84a1e210258183a", "title": "UnifiedQA: Crossing Format Boundaries With a Single QA System"}, {"paperId": "a238109c3969ae681eee0d4f1bf2012f28850593", "title": "Synthesizer: Rethinking Self-Attention in Transformer Models"}, {"paperId": "b2a839e3ee68e81b863b73ee08c6626c94477fef", "title": "WT5?! Training Text-to-Text Models to Explain their Predictions"}, {"paperId": "f6e0164466e827112fd415afdc28ddf8e0eb1ba3", "title": "Document Ranking with a Pretrained Sequence-to-Sequence Model"}, {"paperId": "e52051204cb1179584f3b008c9d38848b52c1f28", "title": "ReZero is All You Need: Fast Convergence at Large Depth"}, {"paperId": "baf60d13c98916b77b09bc525ede1cd610ed1db5", "title": "Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "b45d656ac8cc2e940609580cf291ee76ffcac20a", "title": "On Layer Normalization in the Transformer Architecture"}, {"paperId": "80376bdec5f534be78ba82821f540590ebce5559", "title": "How Much Knowledge Can You Pack into the Parameters of a Language Model?"}, {"paperId": "d08463bd665589d04619f04dbde84183ffcf2e63", "title": "Towards a Human-like Open-Domain Chatbot"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "10eda4521c032adabaa8e70d6569e17370b29dcd", "title": "Root Mean Square Layer Normalization"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "bf442ab269074665a68e4dbbe19e4efc97862541", "title": "Large Memory Layers with Product Keys"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "16c844fd4d97f3c6eb38b0d6527c87d184efedc3", "title": "The Evolved Transformer"}, {"paperId": "fea820b7d953d32069e189af2961c28fd213470b", "title": "Pay Less Attention with Lightweight and Dynamic Convolutions"}, {"paperId": "96c82727dd5a80fef93007f888bb8569feb6bd85", "title": "Fixup Initialization: Residual Learning Without Normalization"}, {"paperId": "2270b8628fd8ca67ae39d277f45bc3c38ac63d5f", "title": "Mesh-TensorFlow: Deep Learning for Supercomputers"}, {"paperId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "title": "Adaptive Input Representations for Neural Language Modeling"}, {"paperId": "305b2cf37e5dece81e95c92883d5a6e28ac93b22", "title": "Don\u2019t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "8fec5d6ac57e90f459e7330775165f2671abc445", "title": "Training Deeper Neural Machine Translation Models with Transparent Attention"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "54a13bcc9613dcaa76fb25fbe96572f376cfcca9", "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost"}, {"paperId": "642c1b4a9da95ea4239708afc5929a5007a1870d", "title": "Tensor2Tensor for Neural Machine Translation"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "50bdda28de3dcf82a0e10f9ec13eea248b19edb5", "title": "Regularized Evolution for Image Classifier Architecture Search"}, {"paperId": "7f4afc1bf3272ae6ec00b46e27efc4a4f6b0826d", "title": "MaskGAN: Better Text Generation via Filling in the ______"}, {"paperId": "ef9ddbc35676ce8ffc2a8067044473727839dbac", "title": "Breaking the Softmax Bottleneck: A High-Rank RNN Language Model"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "33690ff21ef1efb576410e656f2e60c89d0307d6", "title": "Deep Reinforcement Learning that Matters"}, {"paperId": "d0611891b9e8a7c5731146097b6f201578f47b2f", "title": "Learning Transferable Architectures for Scalable Image Recognition"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "424a6e62084d919bfc2e39a507c263e5991ebdad", "title": "Self-Normalizing Neural Networks"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "9ec499af9b85f30bdbdd6cdfbb07d484808c526a", "title": "Efficient softmax approximation for GPUs"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "04cca8e341a5da42b29b0bc831cb25a0f784fa01", "title": "Adaptive Computation Time for Recurrent Neural Networks"}, {"paperId": "13fe71da009484f240c46f14d9330e932f8de210", "title": "Long Short-Term Memory-Networks for Machine Reading"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "f63e917638553414526a0cc8550de4ad2d83fe7a", "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)"}, {"paperId": "a546966db50cc8fdef98bb744990f35248932930", "title": "Adding Gradient Noise Improves Learning for Very Deep Networks"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "33af9298e5399269a12d4b9901492fe406af62b4", "title": "Striving for Simplicity: The All Convolutional Net"}, {"paperId": "5ec85a0d88adcc4344bb5cc81b0d1aef9bcd8dcc", "title": "Findings of the 2014 Workshop on Statistical Machine Translation"}, {"paperId": "5e83ab70d0cbc003471e87ec306d27d9c80ecb16", "title": "Network In Network"}, {"paperId": "b29447ba499507a259ae9d8f685d60cc1597d7d3", "title": "Semantic Parsing on Freebase from Question-Answer Pairs"}, {"paperId": "aa7bfd2304201afbb19971ebde87b17e40242e91", "title": "On the importance of initialization and momentum in deep learning"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "2e9d221c206e9503ceb452302d68d10e293f2a10", "title": "Long Short-Term Memory"}, {"paperId": "766ce989b8b8b984f7a4691fd8c9af4bdb2b74cd", "title": "\u201cCloze Procedure\u201d: A New Tool for Measuring Readability"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "c8c4ab59ac29973a00df4e5c8df3773a3c59995a", "title": "Searching for Activation Functions"}, {"paperId": null, "title": "2016) and layer normalization (Ba et al., 2016). Layer normalization is defined as an operation over a sequence"}, {"paperId": "34f25a8704614163c4095b3ee2fc969b60de4698", "title": "Dropout: a simple way to prevent neural networks from overfitting"}, {"paperId": null, "title": "Lecture 6a: Overview of mini-batch gradient descent"}, {"paperId": "70d6dfdc40c4681ba5d51d60116db0311b5126ce", "title": "Language Models"}, {"paperId": "2bcf3e6c2b45c052a0bd0183cc29c03acc4b49ac", "title": "Human behavior and the principle of least effort"}, {"paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5", "title": "of the Association for Computational Linguistics"}]}