{"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "abstract": "Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning. Given their computational cost, these models are difficult to replicate without significant capital. For the few that are available through APIs, no access is granted to the full model weights, making them difficult to study. We present Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, which we aim to fully and responsibly share with interested researchers. We show that OPT-175B is comparable to GPT-3, while requiring only 1/7th the carbon footprint to develop. We are also releasing our logbook detailing the infrastructure challenges we faced, along with code for experimenting with all of the released models.", "venue": "arXiv.org", "year": 2022, "citationCount": 2522, "influentialCitationCount": 301, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, is presented, which is aimed to fully and responsibly share with interested researchers."}, "embedding": {"model": "specter_v2", "vector": [0.29103678464889526, 0.7983176112174988, -0.38727858662605286, 0.11572518199682236, -0.18645641207695007, -0.3454909324645996, 1.0145297050476074, -0.47433507442474365, -0.6085153818130493, -0.54022616147995, 0.43673694133758545, -0.2496432363986969, 0.37129732966423035, 0.24721096456050873, -0.1410897970199585, 0.1983191817998886, -0.8144532442092896, 0.5626667737960815, -0.21374917030334473, -0.6143765449523926, -0.36344701051712036, -0.9949149489402771, -0.8586974143981934, -0.29804518818855286, 0.3565998375415802, 0.3909212052822113, 0.1465749889612198, 0.7660056352615356, -0.5102477669715881, 0.34636926651000977, 0.7788634896278381, -0.6065701842308044, 0.39691174030303955, 0.10073995590209961, -0.284231573343277, -0.007309382781386375, 0.1577850580215454, -0.4530438184738159, -0.5027691125869751, 0.9208465814590454, -0.28885921835899353, 0.24534784257411957, 0.271382212638855, -0.823157012462616, -0.601330041885376, 0.9980867505073547, 0.8508847951889038, 0.6117613315582275, -0.29167017340660095, -0.15832380950450897, 1.3520400524139404, -1.4988136291503906, 0.25658974051475525, 1.50479257106781, 0.497433602809906, 0.5365514159202576, -0.4081090986728668, -0.6209200024604797, 0.4312642216682434, -0.11860070377588272, -0.8506676554679871, -0.6721624135971069, -0.13288874924182892, -0.13771399855613708, 2.140395402908325, -0.5965092182159424, 0.3281809389591217, 0.8937233686447144, -0.07136895507574081, 1.091484546661377, -0.12490472942590714, -0.7350037097930908, -0.3124356269836426, 0.11669888347387314, 0.2861464023590088, 0.9718001484870911, -0.6284481287002563, 0.34802624583244324, -0.65083909034729, 0.007193274796009064, 0.002916785655543208, 0.03414122015237808, 0.09668232500553131, -0.11820776760578156, -0.12707309424877167, 0.837200403213501, 0.01792079210281372, 0.9278257489204407, 0.16368468105793, 0.61040198802948, 0.5176175832748413, 0.5026756525039673, 0.22633597254753113, 0.20762304961681366, -0.3109593689441681, 0.2837572693824768, -0.9104136228561401, 0.019437529146671295, 0.034190282225608826, 1.038621425628662, -0.18518781661987305, 0.27631062269210815, -0.8677697777748108, 0.17108115553855896, 1.3440334796905518, 0.13747574388980865, 0.3801940381526947, -0.7322912812232971, 0.13990169763565063, -0.8441997170448303, -0.19964225590229034, -0.24264416098594666, 0.04132083058357239, -0.14850087463855743, -0.6202483773231506, -1.5822914838790894, -0.5550294518470764, 0.3857240080833435, -1.1976603269577026, 0.9791001677513123, -0.4737125039100647, 0.17018364369869232, 0.3208768665790558, 0.27427610754966736, 0.8575750589370728, 0.8050034642219543, 0.20868615806102753, -0.10452219098806381, 1.0200893878936768, -1.0298078060150146, -0.7655094861984253, -1.2221620082855225, 0.7234005928039551, -0.24686168134212494, 0.38401663303375244, -0.003594326553866267, -1.2953258752822876, -0.5358854532241821, -0.7864509224891663, -0.46530547738075256, -0.6048648357391357, 0.15469589829444885, 1.0072132349014282, 0.7436344027519226, -1.1025420427322388, 0.551417887210846, 0.05655951797962189, -0.2783966064453125, 0.3113621771335602, 0.09812550246715546, 0.2854676842689514, -0.5644832849502563, -1.4775463342666626, 0.47841677069664, 0.182260662317276, -0.6256033778190613, -0.4990324079990387, -0.6362585425376892, -1.1125788688659668, -0.052397776395082474, 0.47063693404197693, -0.20757931470870972, 1.4545632600784302, -0.03802867233753204, -1.5897514820098877, 1.0730304718017578, -0.500704824924469, -0.0626973807811737, 0.11608044058084488, -0.08195140957832336, -0.4984687268733978, -0.4943695664405823, -0.336527556180954, 0.4656311869621277, 0.5623118281364441, 0.2577317953109741, 0.26467931270599365, 0.37426048517227173, -0.05765414983034134, -0.1918565034866333, -0.345988929271698, 1.2096765041351318, -0.8007826209068298, -0.09919764846563339, 0.33371683955192566, 0.4717279076576233, -0.24468372762203217, -0.21092009544372559, -0.6241229772567749, -1.0123119354248047, 0.438253790140152, -0.15136997401714325, 0.801814615726471, -0.9387656450271606, -0.7552838325500488, -0.20134058594703674, -0.0826847180724144, 0.07561352849006653, -0.799845814704895, 0.6710175275802612, -0.3219490647315979, 0.5122437477111816, -0.0507376529276371, -1.3980501890182495, 0.38709497451782227, -0.2163880467414856, -0.7912254929542542, -0.06916473060846329, -0.026641247794032097, 1.1785818338394165, -0.9456729888916016, 0.07580608129501343, 0.15795418620109558, 0.4320167601108551, -1.1974204778671265, 0.9660237431526184, -0.49744269251823425, 0.0953054428100586, 0.12311873584985733, -0.1322653889656067, 0.04406300559639931, -0.14223894476890564, 0.43521374464035034, -0.2752717137336731, -0.28960782289505005, 0.3953118920326233, -0.02144329436123371, 1.7036694288253784, -0.33622583746910095, 0.376163512468338, -0.16055460274219513, -0.5421372056007385, 0.0898343175649643, 0.5850692987442017, -0.12519285082817078, -0.6639468669891357, 0.6303797960281372, 0.4675210416316986, -0.5929687023162842, 0.5558416247367859, 0.7875756621360779, 0.6271154284477234, -0.35893356800079346, 0.1298435628414154, 0.8648414015769958, -0.2384323924779892, 0.5136759877204895, 0.6132147908210754, 0.6262122988700867, 0.1339288353919983, 0.25791624188423157, -0.16656479239463806, 0.2627348005771637, -0.9597922563552856, -0.1951286941766739, 0.47944438457489014, 0.5201476812362671, 0.8520323038101196, 0.4261862337589264, -0.6877781748771667, -0.23632338643074036, -0.2532714307308197, 0.7456384897232056, 1.5835736989974976, -0.31014981865882874, -0.42907315492630005, -0.699579656124115, 0.05043016001582146, -0.6499261260032654, 0.20487132668495178, -0.1693992167711258, -0.33304694294929504, -0.3021916151046753, -1.0024009943008423, 0.7613738179206848, -0.5434711575508118, 0.6541893482208252, -0.2833739221096039, -0.08274640142917633, -0.17606231570243835, 0.31443628668785095, -1.0958205461502075, -0.7659221291542053, 0.41536837816238403, -0.41986268758773804, 0.0544043593108654, -0.11982765793800354, -0.02548506297171116, 0.13024723529815674, -0.6579424738883972, 0.7830300331115723, -0.5308806300163269, -0.29441148042678833, 0.25545379519462585, 0.5367958545684814, -0.45350712537765503, -0.9469981789588928, 0.11082988977432251, 0.2421347200870514, -0.21709869801998138, 0.2698584496974945, 0.35980024933815, 0.31057512760162354, -0.19121283292770386, -0.1766747534275055, 0.2532917559146881, -0.20174150168895721, -0.31164494156837463, 0.5452141761779785, -0.46724191308021545, -0.38576647639274597, -1.049570918083191, 0.8069937229156494, 0.14713643491268158, -0.6655313372612, 0.4170646667480469, -0.8015419840812683, -0.2667338252067566, 0.5005793571472168, -0.6244548559188843, -0.32077524065971375, -0.796494722366333, 0.1367550492286682, -0.3792929947376251, 0.25981879234313965, 0.011341016739606857, 0.23839081823825836, 0.41419994831085205, -0.010367661714553833, 0.6833772659301758, 0.16572929918766022, -0.2424376904964447, 0.8459340929985046, -1.0235342979431152, 0.285244345664978, 0.3837955594062805, 0.39047449827194214, -0.2717653214931488, -0.3521272540092468, -0.5839980244636536, -0.6169114112854004, -0.289472371339798, -0.16101649403572083, -0.36069661378860474, 0.4061957001686096, -0.8059776425361633, -0.5325562357902527, 0.3190619647502899, -1.0947614908218384, -0.21774503588676453, 0.18339261412620544, -0.4461458921432495, -0.10882212966680527, -0.8226216435432434, -1.1278690099716187, -0.5662021040916443, -0.9733117818832397, -1.1153432130813599, 0.4356369972229004, 0.04992092028260231, -0.06291947513818741, -0.61387699842453, 0.14580219984054565, -0.2075466513633728, 0.9950475096702576, -0.8848113417625427, 0.9227434992790222, -0.244595468044281, -0.1524156630039215, -0.12094771862030029, 0.29684704542160034, 0.6076176762580872, -0.6034837365150452, 0.48845091462135315, -0.9127969741821289, 0.04615950956940651, -0.6268004775047302, -0.4127379059791565, 0.25737616419792175, 0.385527104139328, 0.35957571864128113, -0.10769090056419373, -0.5040997862815857, 0.6128848195075989, 1.2229714393615723, -0.6830034255981445, 0.0903400406241417, 0.015976151451468468, 0.9698846340179443, -0.1751914769411087, -0.44323471188545227, 0.5119307637214661, 0.479870080947876, 0.45367661118507385, 0.09179080277681351, 0.14818617701530457, 0.15199747681617737, -0.6155197024345398, 0.9624252319335938, 1.6884303092956543, 0.42773115634918213, -0.2075941413640976, -1.0968072414398193, 0.739618718624115, -0.7989249229431152, -0.7328132390975952, 0.4140391945838928, 0.7507766485214233, 0.5293074250221252, -0.19805601239204407, -0.5893502831459045, -0.13866233825683594, 0.3093573749065399, 0.5563992261886597, -0.17071479558944702, -1.306522250175476, -0.07526468485593796, 0.8678556680679321, 0.1551002711057663, 0.5714221596717834, -0.17407482862472534, 1.0354318618774414, 14.700154304504395, 0.9851050972938538, 0.009953315369784832, 0.909719705581665, 0.5351279973983765, -0.07443974912166595, -0.47849321365356445, 0.2828792929649353, -1.086694359779358, -0.2502383589744568, 1.4085454940795898, -0.06498468667268753, 1.1154102087020874, 0.16000722348690033, 0.1288035809993744, 0.15937688946723938, -0.43620213866233826, 0.4457034766674042, 0.5210349559783936, -1.0926514863967896, 0.3008193373680115, 0.3035907745361328, 0.3922784626483917, 0.9337483644485474, 0.9504877328872681, 1.2020587921142578, 0.5319366455078125, -0.5261160135269165, 0.567779004573822, 0.34712958335876465, 1.0470292568206787, -0.12191060930490494, 0.08110654354095459, 0.6853524446487427, -0.8559032082557678, -0.11314824968576431, -0.507784903049469, -1.2997355461120605, 0.18637533485889435, 0.24278561770915985, -0.5041152238845825, -0.6091099977493286, -0.26070061326026917, 0.8254764676094055, 0.01123818103224039, 0.1674879789352417, -0.011807337403297424, 0.7807611227035522, -0.30182161927223206, 0.10555887967348099, 0.538723349571228, 0.11512264609336853, 0.33137044310569763, -0.31737929582595825, 0.30323103070259094, -0.10729124397039413, 0.12208660691976547, 0.5770441293716431, -0.6239815354347229, -0.12151280790567398, -0.3379455804824829, -0.5948761105537415, -0.19874152541160583, 0.8271393179893494, 0.5784301161766052, 0.32419681549072266, -0.5655883550643921, 0.27825841307640076, 0.4494510591030121, 0.031562142074108124, -0.37022554874420166, 0.2722378671169281, 0.33635684847831726, -0.6918251514434814, 0.003632901469245553, 0.5829408168792725, 0.26680460572242737, -0.686308741569519, -0.9130460619926453, -0.435838520526886, 0.2494398057460785, -0.7351565957069397, -0.43556469678878784, 0.5549237132072449, -0.4330001473426819, -0.09200923144817352, 0.29072144627571106, -0.6195042729377747, -0.2550840973854065, 0.5160986185073853, -1.311623454093933, -0.9606026411056519, 0.7365387082099915, -0.3583211302757263, -0.3402920067310333, -0.1313493847846985, 1.290199875831604, 0.2802111506462097, -0.43398627638816833, 0.16058003902435303, 0.5022716522216797, -0.03365703299641609, -0.6164047122001648, -0.5416586399078369, 1.143761157989502, 0.40532413125038147, -0.026197979226708412, 0.3058146834373474, 0.16736838221549988, 0.4278208911418915, -1.0408366918563843, -0.1385045349597931, 1.0942420959472656, -0.9668822288513184, -0.42929884791374207, -1.2278602123260498, -0.4828380048274994, 0.42040884494781494, 0.7873824834823608, -0.30565303564071655, 0.20408903062343597, 0.13660529255867004, -0.5543038249015808, -0.05441499501466751, -0.6959052681922913, 0.08465082198381424, 0.6618348956108093, -0.9668152332305908, -0.14542433619499207, 0.03465230390429497, 0.43868401646614075, -0.8512343764305115, -0.3850899934768677, -0.33733701705932617, 0.22031272947788239, -0.0875948965549469, 1.0744801759719849, -0.050346896052360535, 0.43647435307502747, 1.3378233909606934, -0.13871152698993683, -0.7764319777488708, 0.09113482385873795, -1.1712242364883423, -0.03428322821855545, 0.21223323047161102, 0.6393721103668213, -0.4916851818561554, -0.15952782332897186, 0.9448387026786804, 0.35600098967552185, -0.5384305119514465, -0.8783445358276367, -0.6448059678077698, 0.2138269692659378, -0.6490234732627869, 0.39608103036880493, -0.16899748146533966, -0.05393749475479126, 0.25528767704963684, 0.0964999720454216, 0.41833463311195374, -0.060401733964681625, -1.2080947160720825, 0.39280304312705994, -0.08761539310216904, -0.08462395519018173, -0.5226678848266602, -0.18594220280647278, -1.1571974754333496, 0.07464239001274109, -1.3654372692108154, 0.06814081221818924, -0.9304826855659485, -0.0979568138718605, 0.15745072066783905, -0.24120184779167175, 0.20946277678012848, 0.6191032528877258, -0.22535476088523865, -0.46386611461639404, -0.8107417821884155, -0.48937955498695374, 0.9813665747642517, 0.8667902946472168, -0.8292566537857056, 0.2765224575996399, -0.28334274888038635, 0.2578626275062561, 0.3189888000488281, 0.38104215264320374, -0.5099248886108398, -1.1957069635391235, -1.435593843460083, 0.36886459589004517, -0.30831649899482727, -0.08019718527793884, -0.6770989894866943, 0.3560813069343567, 0.34019824862480164, -0.7831135988235474, 0.18235379457473755, 0.5330381393432617, -0.6994573473930359, -0.24848276376724243, 0.44352659583091736, -0.5832788348197937, 0.16694368422031403, 0.12329451739788055, -0.7556859254837036, 0.10632095485925674, 0.5085960030555725, 0.07010465860366821, -1.2953605651855469, -0.7247430086135864, 0.7648977041244507, -0.7654464840888977, 0.3031238615512848, -0.2563183605670929, -0.2660296857357025, -0.8409720659255981, -0.37314414978027344, -0.0011629753280431032, 0.27391186356544495, -0.22708044946193695, 1.088424563407898, 0.3667060434818268, -0.9111740589141846, 0.19115062057971954, 0.293417364358902, 0.048781510442495346, -0.4881638288497925, 0.3243230879306793, 0.43717679381370544, -0.043900202959775925, 0.656059980392456, 0.3737318515777588, 0.41874024271965027, -0.8973087072372437, -0.06523655354976654, 0.7886057496070862, -0.6834790706634521, -0.25108733773231506, 1.2527270317077637, -0.41418027877807617, -1.1887871026992798, 0.05800523981451988, -1.3387835025787354, -0.38596072793006897, -0.48935648798942566, 0.3216319680213928, -0.1229260191321373, 0.019729509949684143, -0.31219619512557983, -0.49474644660949707, 0.19395750761032104, 0.014471443369984627, -0.8007981181144714, 0.6793600916862488, -0.19284866750240326, -0.3820700943470001, 0.7320299744606018, 0.9982436299324036, -0.6838594079017639, -0.6002627611160278, -0.7299222946166992, -0.6253138780593872, 0.25117748975753784, 0.6554957032203674, -0.465621680021286, -0.506220281124115, 0.980411946773529, 0.5387578010559082, 0.13173586130142212, 0.10900729894638062, -0.32721757888793945, 0.2935781180858612, 0.7998853921890259, 0.3194292187690735, -0.8415612578392029, -0.5592069625854492, 1.854453682899475, 0.7554198503494263, -0.9792422652244568, 0.07621853798627853, -0.08001814037561417, -0.7314398884773254, 0.475363165140152, 0.07937632501125336, 0.32979026436805725, 0.9208049178123474, -0.5245254635810852, -0.09042645245790482, 0.13119596242904663, -1.2561802864074707, -0.46244534850120544, 0.866584837436676, 0.6656349897384644, 0.8171786069869995, 0.15521523356437683, 0.07741519063711166, 0.9758781790733337, 0.060196395963430405, 0.11867129057645798, 0.5958655476570129, 0.44067859649658203, -0.2421671748161316, 0.06395430862903595, 0.3951224088668823, 0.6846747398376465, -0.6162838339805603, -1.2521095275878906, 0.11905182898044586, 0.36543896794319153, 0.5556023120880127, 0.6147333383560181, 0.5612179040908813, 0.17500533163547516, 0.35239264369010925, 0.4310339391231537, 0.6342403888702393, -0.6350522041320801, -0.21879033744335175, -0.44483688473701477, -0.5223065614700317, 0.08945127576589584, 0.20493200421333313, -0.3405494689941406, -0.27187854051589966, -0.3126038610935211, 0.25369054079055786, -0.11495742946863174, 0.2894255220890045, 1.5424607992172241, 0.3024671971797943, 0.15277865529060364, -0.18631677329540253, -0.31265315413475037, -0.24353456497192383, -0.7094460129737854, -0.039267104119062424, -0.775458037853241, -0.32108309864997864, -0.10723580420017242, -0.03782450035214424, -0.47697383165359497]}, "authors": [{"authorId": "2108244542", "name": "Susan Zhang"}, {"authorId": "3849208", "name": "Stephen Roller"}, {"authorId": "39589154", "name": "Naman Goyal"}, {"authorId": "2347956", "name": "Mikel Artetxe"}, {"authorId": "2108267192", "name": "Moya Chen"}, {"authorId": "1782969", "name": "Shuohui Chen"}, {"authorId": "2065332326", "name": "Christopher Dewan"}, {"authorId": "2138579860", "name": "Mona T. Diab"}, {"authorId": "2116235416", "name": "Xian Li"}, {"authorId": "143724481", "name": "Xi Victoria Lin"}, {"authorId": "39980906", "name": "Todor Mihaylov"}, {"authorId": "40511414", "name": "Myle Ott"}, {"authorId": "88728159", "name": "Sam Shleifer"}, {"authorId": "35752280", "name": "Kurt Shuster"}, {"authorId": "2082239112", "name": "Daniel Simig"}, {"authorId": "2146367061", "name": "Punit Singh Koura"}, {"authorId": "5382923", "name": "Anjali Sridhar"}, {"authorId": "1785372925", "name": "Tianlu Wang"}, {"authorId": "1982950", "name": "Luke Zettlemoyer"}], "references": [{"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "8342b592fe238f3d230e4959b06fd10153c45db1", "title": "Training Compute-Optimal Large Language Models"}, {"paperId": "f8292d4ddf7a6dfe240eeaa9685f5d18eed9a3f6", "title": "Language Models that Seek for Knowledge: Modular Search & Generation for Dialogue and Prompt Completion"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "f4df78183261538e718066331898ee5cad7cad05", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"}, {"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19", "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"}, {"paperId": "b3848d32f7294ec708627897833c4097eb4d8778", "title": "LaMDA: Language Models for Dialog Applications"}, {"paperId": "fb01415a0decfa3f3d6339930e95028ae1ff4170", "title": "Efficient Large Scale Language Modeling with Mixtures of Experts"}, {"paperId": "2f3efe44083af91cef562c1a3451eee2f8601d22", "title": "WebGPT: Browser-assisted question-answering with human feedback"}, {"paperId": "002c256d30d6be4b23d365a8de8ae0e67e4c9641", "title": "Improving language models by retrieving from trillions of tokens"}, {"paperId": "fd1b829261ba04bb92e0ab60c4f6e7cea0d99fbf", "title": "Ethical and social risks of harm from Language Models"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "2c6df83795cd5baf3b8c6e2639b85e2df0cee1d0", "title": "Sustainable AI: Environmental Implications, Challenges and Opportunities"}, {"paperId": "47df3fd32d00220c85c2c51a571254fd99b2ecc7", "title": "MetaICL: Learning to Learn In Context"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "0794333779d775abc2053052d1e7009066cbd4f1", "title": "SaFeRDialogues: Taking Feedback Gracefully after Conversational Safety Failures"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "9ba50f992ccd92f428503ea6246157260a26cd77", "title": "Do Prompt-Based Models Really Understand the Meaning of Their Prompts?"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "de549c1592a62c129b8d49c8c0137aa6859b103f", "title": "Internet-Augmented Dialogue Generation"}, {"paperId": "88064de690af282dbdf222774f03ff070b9df22b", "title": "Beyond Goldfish Memory: Long-Term Open-Domain Conversation"}, {"paperId": "2ef4ab54d00203f9ac610213ac3abc8e1fe541b4", "title": "Anticipating Safety Issues in E2E Conversational AI: Framework and Tooling"}, {"paperId": "114aa720872462b0ca1b97bfdec0ebd56c36fd0a", "title": "Towards Understanding and Mitigating Social Biases in Language Models"}, {"paperId": "041c4a3932eae3931d90b1a0fc033cf5f491c267", "title": "Bot-Adversarial Dialogue for Safe Conversational Agents"}, {"paperId": "b58d8579ece27a60432e667bfbdb750590fa65d9", "title": "True Few-Shot Learning with Language Models"}, {"paperId": "7a16d9b4e04300d034502dc7dd58428714594e2c", "title": "Carbon Emissions and Large Neural Network Training"}, {"paperId": "0adec918885dff698acf359988ed79a543157f80", "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "49f905eb03958c7cfae52ac759ea8978b8b2a6ea", "title": "Alignment of Language Agents"}, {"paperId": "098370508aaf56f718a472511987ac2072d0f917", "title": "Detecting Hate Speech with GPT-3"}, {"paperId": "a9fe5bd8da2d9603cf2cf6c6ea8b0f83c6d3a4f9", "title": "How many data points is a prompt worth?"}, {"paperId": "ca2f1088d3e581b2c6c75cf0ebc96506d620f64d", "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? \ud83e\udd9c"}, {"paperId": "ce9ca56036307217ea565644d3d3bd74b879e045", "title": "Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP"}, {"paperId": "ce3b364b7e6358940ce97d8d5887a65e5024ca21", "title": "BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation"}, {"paperId": "59641c10ed7431a3cf841f308367dc2dc0281b74", "title": "What Makes Good In-Context Examples for GPT-3?"}, {"paperId": "85e7d63f75c0916bd350a229e040c5fbb1472e7a", "title": "Making Pre-trained Language Models Better Few-shot Learners"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "292839cb8e5c601be8cd467184939de7873fdd44", "title": "Chasing Carbon: The Elusive Environmental Footprint of Computing"}, {"paperId": "4fa24cc5b17e8ff1eb5a01fd37a9d267a57ac563", "title": "Recipes for Safety in Open-domain Chatbots"}, {"paperId": "b38c6d318f3d7f72d46b947e2e746bd3afd3c02f", "title": "Precise Task Formalization Matters in Winograd Schema Evaluations"}, {"paperId": "645bd6eadc247989abc5e0b0aa0be79ec8b11ea6", "title": "CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models"}, {"paperId": "399e7d8129c60818ee208f236c8dda17e876d21f", "title": "RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models"}, {"paperId": "f30444fbb6ad806168e2564db4815cd27faa7fd9", "title": "It\u2019s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners"}, {"paperId": "07bcda1dff9bb696ea9cbc69303eee8bd3d85bd6", "title": "GeDi: Generative Discriminator Guided Sequence Generation"}, {"paperId": "a6e6197fcbb5bbe7d332904f2624e7bf1687c024", "title": "Best-First Beam Search"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "58ed1fbaabe027345f7bb3a6312d41c5aac63e22", "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"}, {"paperId": "9b539d413393047b28bb7be9b195f142aaf7a80e", "title": "Recipes for Building an Open-Domain Chatbot"}, {"paperId": "babeda48b10a4d638252118f2238d05a06f4ec55", "title": "StereoSet: Measuring stereotypical bias in pretrained language models"}, {"paperId": "71017cc6d270d28d9edcd47550450dc05edd65f4", "title": "Can You Put it All Together: Evaluating Conversational Agents\u2019 Ability to Blend Skills"}, {"paperId": "d08463bd665589d04619f04dbde84183ffcf2e63", "title": "Towards a Human-like Open-Domain Chatbot"}, {"paperId": "1a6f4495474f75ae1e8bbf407f70d9a874e5b4d6", "title": "The Pushshift Reddit Dataset"}, {"paperId": "681f4fbce872f138cbac9cdd92e8f6ed89ba6f8d", "title": "Measurement and Fairness"}, {"paperId": "04f4e55e14150b7c48b0287ba77c7443df76ed45", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"}, {"paperId": "22d3dfd27bfd4ec00ab6d9744cec851982e9b89a", "title": "Queens Are Powerful Too: Mitigating Gender Bias in Dialogue Generation"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "5334e1857e910e2c7855c909c9495fb0ea28efbb", "title": "Does Gender Matter? Towards Fairness in Dialogue Systems"}, {"paperId": "e04a80263d252a3d8a382ba37a249b9345620570", "title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "5019dbe8d1da5f128f4f373d6849095cf18fd519", "title": "The Woman Worked as a Babysitter: On Biases in Language Generation"}, {"paperId": "d0086b86103a620a86bc918746df0aa642e2a8a3", "title": "Language Models as Knowledge Bases?"}, {"paperId": "b91c4edd30b63cd1cb1b86cbeefb33a461535e09", "title": "Build it Break it Fix it for Dialogue Safety: Robustness from Adversarial Human Attack"}, {"paperId": "53a77e8f73f2ca422d6e38fa9ecc490231ac044c", "title": "Neural Text Generation with Unlikelihood Training"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "9ae17b09c59f06f02ef824b856a440de663471d0", "title": "The Second Conversational Intelligence Challenge (ConvAI2)"}, {"paperId": "a33a06ddc762fb855b6954c08d5aca603080b011", "title": "Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset"}, {"paperId": "7365f887c938ca21a6adbef08b5a520ebbd4638f", "title": "Model Cards for Model Reporting"}, {"paperId": "227458886343b86bd15adf58c769be326b4b058a", "title": "Wizard of Wikipedia: Knowledge-Powered Conversational agents"}, {"paperId": "1536e8958697c5364f68b2e2448905dbbeb3a0ca", "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"}, {"paperId": "d7b6753a2d4a2b286c396854063bde3a91b75535", "title": "A Simple Method for Commonsense Reasoning"}, {"paperId": "0df347f5e3118fac7c351917e3a497899b071d1e", "title": "Datasheets for datasets"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": "45dfef0cc1ed96558c1c650432ce39d6a1050b6a", "title": "Fixing Weight Decay Regularization in Adam"}, {"paperId": "e7fd6848cb29ca221a7e17d823e06fb566f1f135", "title": "Mixed Precision Training"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "0e6824e137847be0599bb0032e37042ed2ef5045", "title": "Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"}, {"paperId": "8215fb083cb4b0ed2b6858b81dcc30fbd0afb6e1", "title": "Mining of Massive Datasets"}, {"paperId": "128cb6b891aee1b5df099acb48e2efecfcff689f", "title": "The Winograd Schema Challenge"}, {"paperId": "7fefba4d85d8eb32efe43fd54a13c9b396ac19dc", "title": "Neural network based language models for highly inflective languages"}, {"paperId": "74f61af390292fc197659ae698429df4a2de62df", "title": "Unsupervised Learning of Narrative Event Chains"}, {"paperId": "8faac15828f76fe8dff49309a8167d34814ae18c", "title": "A Conversational Paradigm for Program Synthesis"}, {"paperId": null, "title": "McMillanMajor, and Shmargaret Shmitchell"}, {"paperId": null, "title": "Jurassic-1: Technical details and evaluation"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "3e65f572322e192fe36ae52a8a7f025b0685dfc6", "title": "Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets"}, {"paperId": null, "title": "2021) and provide a data card for the dataset used to train the OPT models"}, {"paperId": null, "title": "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts"}, {"paperId": null, "title": "ETHOS: an online hate speech detection dataset"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "92e121c6e114fe3cfb89370df03847c66a9b4e28", "title": "An Adversarial Winograd Schema Challenge at Scale"}, {"paperId": null, "title": "2018), we provide a model card for OPT-175B"}, {"paperId": null, "title": "Improving language understanding with unsupervised learning"}, {"paperId": null, "title": "A corpus and evaluation framework for deeper understanding of commonsense stories"}, {"paperId": null, "title": "\u2022 Will older versions of the dataset continue to be supported/hosted/maintained? If so, please describe how. If not, please describe how its obsolescence will be communicated to users"}, {"paperId": null, "title": "\u2022 Model type: OPT-175B is a large decoder-only transformer language model"}, {"paperId": null, "title": "other) tasks could the dataset be used for? This data can be used to pre-train language models, which are foundation to many current and future language tasks"}, {"paperId": null, "title": "\u2022 How can the owner/curator/manager of the dataset be contacted (e.g., email address)? Refer to the main document"}, {"paperId": null, "title": "\u2022 Has the dataset been used for any tasks already? If so"}, {"paperId": null, "title": "Model Details \u2022 Person or organization developing model: OPT-175B was developed by Meta AI"}, {"paperId": null, "title": "to correct labeling errors, add new instances, delete instances)? If so, please describe how often"}, {"paperId": null, "title": "Maintenance \u2022 Who is supporting/hosting/maintaining the dataset"}, {"paperId": null, "title": "\u2022 Primary intended users: We primarily target researchers and the related research community"}, {"paperId": null, "title": "\u2022 Where to send questions or comments about the model: Please contact the corresponding authors {susanz,roller,namangoyal}@fb.com for any questions or comments"}, {"paperId": null, "title": "\u2022 Is there an erratum? If so"}, {"paperId": null, "title": "were individuals in question told that their data would be retained for a fixed period of time and then deleted)? If so"}, {"paperId": null, "title": "\u2022 Are there tasks for which the dataset should not be used? If so, please provide a description"}, {"paperId": null, "title": "OPT-175B and the smaller baseline models are made available through a non-commercial use license agreement provided in our model license"}, {"paperId": null, "title": "\u2022 Is the dataset self-contained, or does it link to or otherwise rely on external resources (e.g., websites, tweets, other datasets)? It's self-contained"}, {"paperId": null, "title": "Is there a repository that links to any or all papers or systems that use the dataset? If so"}, {"paperId": null, "title": "raw\" data saved in addition to the preprocessed/cleaned/labeled data (e.g., to support unanticipated future uses)? If so, please provide a link or other access point to the \"raw\" data. The \"raw"}, {"paperId": null, "title": "Preprocessing/cleaning/labeling"}, {"paperId": null, "title": "Bogdan"}, {"paperId": null, "title": "\u2022 Does the dataset relate to people? If not, you may skip the remaining questions in this section. Some documents of this data relate to people"}]}