{"paperId": "76eef89e0a05c4b67f19697e233916f4b3a77ff4", "abstract": "The self-attention mechanism is the performance bottleneck of Transformer-based language models, particularly for long sequences. Researchers have proposed using sparse attention to speed up the Transformer. However, sparse attention introduces significant random access overhead, limiting computational efficiency. To mitigate this issue, researchers attempt to improve data reuse by utilizing row/column locality. Unfortunately, we find that sparse attention does not naturally exhibit strong row/column locality, but instead has excellent diagonal locality. Thus, it is worthwhile to use diagonal compression (DIA) format. However, existing sparse matrix computation paradigms struggle to efficiently support DIA format in attention computation. To address this problem, we propose ASADI, a novel software-hardware co-designed sparse attention accelerator. In the soft-ware side, we propose a new sparse matrix computation paradigm that directly supports the DIA format in self-attention computation. In the hardware side, we present a novel sparse attention accelerator that efficiently implements our computation paradigm using highly parallel in-situ computing. We thoroughly evaluate ASADI across various models and datasets. Our experimental results demonstrate an average performance improvement of 18.6 \u00d7 and energy savings of 2.9\u00d7 compared to a PIM-based baseline.", "venue": "International Symposium on High-Performance Computer Architecture", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "ASADI, a novel software-hardware co-designed sparse attention accelerator that efficiently implements the self-attention paradigm using highly parallel in-situ computing, is presented."}, "embedding": {"model": "specter_v2", "vector": [0.46023428440093994, 0.07998062670230865, -0.1995515376329422, 0.09126097708940506, -0.39601266384124756, 0.24772348999977112, 0.27087873220443726, 0.24127784371376038, -0.31200551986694336, -0.6047669649124146, 0.8672813177108765, -0.011795701459050179, 0.6838501691818237, -0.09114527702331543, -0.3724299669265747, 0.14955896139144897, -0.7357348799705505, 0.003184633096680045, -0.0804135873913765, -0.2328626960515976, 0.5059340596199036, -0.6534945964813232, -1.4782230854034424, 0.3966015577316284, 0.4572458863258362, 0.7478513121604919, 0.5738255977630615, 0.5039547085762024, -0.6437026858329773, 0.5318620800971985, 0.7267727255821228, 0.017619462683796883, 0.3563271462917328, -0.0014515105867758393, -0.15598978102207184, -0.3712689280509949, 0.4661894142627716, -0.04688738286495209, -0.5280572772026062, 0.9857499599456787, -0.25997328758239746, 0.3467946946620941, 0.37642231583595276, -0.3226430118083954, -0.2912772297859192, 0.7453349232673645, 0.19992193579673767, 0.9533765316009521, 0.1619117707014084, -0.44272688031196594, 1.3719152212142944, -1.6600840091705322, 0.019050203263759613, 1.2892920970916748, 0.44625815749168396, -0.04073062539100647, -0.05760389193892479, -0.560178279876709, 0.6050441861152649, 0.3698374927043915, -1.0677824020385742, -0.7899853587150574, 0.163860484957695, -0.29341986775398254, 2.146984577178955, 0.11066444218158722, 0.22293411195278168, 0.33566004037857056, 0.16533614695072174, 1.2771615982055664, -0.33942967653274536, -0.9191607236862183, 0.06989069283008575, -0.5464144349098206, 0.4186742603778839, 0.8685135841369629, -0.2433801144361496, 0.12523484230041504, -1.150329828262329, -0.1781580150127411, 0.032826341688632965, 0.16696159541606903, 0.5446354150772095, -0.2985485792160034, -0.2099156230688095, 0.8164937496185303, 0.18558602035045624, 0.8232125043869019, -0.35604575276374817, 0.7343713045120239, 0.7577122449874878, 0.08037343621253967, 0.020405903458595276, 0.11350855231285095, 0.3861779570579529, 0.0012531807878986, -1.2125539779663086, 0.02878757193684578, -0.019787229597568512, 1.082245945930481, -0.3158734440803528, 0.7166493535041809, -0.7897769808769226, -0.08300705999135971, 1.0968903303146362, 0.6083841919898987, 0.6586322784423828, -0.46340298652648926, 0.22301232814788818, -0.7398157119750977, -0.36410239338874817, -1.3528927564620972, -0.049044471234083176, -0.3907102942466736, -1.1115269660949707, -1.3581335544586182, -0.8417129516601562, 0.3769513964653015, -0.574464738368988, 0.4277418255805969, -0.5053785443305969, 0.3177052140235901, -0.19921095669269562, -0.07368720322847366, 0.6954952478408813, 0.7849745750427246, 0.1458290070295334, 0.04624965041875839, 1.0374131202697754, -1.1369309425354004, -0.4435161054134369, -1.3473618030548096, 0.7012857794761658, -0.5001441240310669, 0.27418282628059387, -0.48951756954193115, -1.377877116203308, -0.8624372482299805, -0.4630833864212036, -0.14399048686027527, -0.18669447302818298, -0.11704720556735992, 0.9610188603401184, 0.047992389649152756, -1.1307423114776611, 0.32577842473983765, -0.6397666335105896, -0.17316719889640808, 0.43519896268844604, 0.03850799426436424, 0.5759000182151794, -0.2279592901468277, -0.9668603539466858, 0.02914898470044136, -0.3385547697544098, -0.7254546880722046, -0.09591997414827347, -0.606704592704773, -1.3561286926269531, 0.5519078969955444, 0.037530411034822464, -0.10539709776639938, 0.9242374300956726, -0.07047409564256668, -0.8967532515525818, 0.7079685926437378, -0.8337147235870361, -0.2637857496738434, -0.5017545223236084, -0.14205831289291382, -0.42259418964385986, -0.4941616356372833, 0.1141233742237091, 0.41732001304626465, 0.667793869972229, 0.1469133496284485, 0.06763017177581787, 0.010293426923453808, -0.4544569253921509, 0.0994347631931305, -0.4523947834968567, 1.2039704322814941, -0.7632137537002563, -0.34844842553138733, 0.5646786689758301, 0.3790498673915863, -0.2992052733898163, -0.3755302429199219, -0.611487090587616, -0.5202688574790955, 0.8980201482772827, 0.2230915129184723, 1.4304778575897217, -1.2434161901474, -0.8347491025924683, 0.17834389209747314, -0.12183628231287003, -0.11722716689109802, -0.701336681842804, 0.6920105218887329, -0.5589224100112915, -0.09739400446414948, 0.03106079436838627, -0.6031200885772705, -0.20400500297546387, -0.654315173625946, -1.053076148033142, -0.3580555021762848, -0.1965206414461136, 0.740144670009613, -0.8235105872154236, -0.06118594855070114, -0.2492036074399948, 0.35149750113487244, -1.4995331764221191, 1.0347485542297363, -0.24090686440467834, -0.08784188330173492, 0.05501309409737587, -0.05827787145972252, -0.03305284306406975, -0.6556047201156616, 0.6688671112060547, -0.7807298302650452, -0.40463852882385254, 0.5913062691688538, -0.02872234210371971, 1.1548620462417603, -0.5014254450798035, 0.591923713684082, -0.27547791600227356, -0.6093551516532898, 0.304448664188385, -0.0015707247657701373, 0.13352985680103302, -0.8739830851554871, 0.39189407229423523, 0.14369098842144012, -0.27922648191452026, 0.3912088871002197, 0.9601207971572876, 1.396968960762024, -0.32760584354400635, 0.18314702808856964, 0.1394653171300888, -0.24809235334396362, 0.6455672979354858, 0.6094820499420166, 0.977856457233429, -0.06656526029109955, 0.7501287460327148, -0.34556567668914795, 0.6566163897514343, -0.9198868870735168, -0.20610187947750092, 0.6017601490020752, 0.7694208025932312, 0.713575005531311, 0.16176308691501617, -0.610766589641571, -0.44545233249664307, 0.5413715243339539, 0.765147864818573, 1.590091347694397, -0.34023430943489075, -0.35754862427711487, -0.6435196995735168, 0.05485554784536362, -0.31262168288230896, 0.05365779623389244, -0.12490694969892502, -0.19245053827762604, -0.4295140504837036, -0.6672899127006531, 0.3432595133781433, 0.4779864549636841, 0.8226062059402466, -0.4983433187007904, -0.5022400617599487, -0.4215400516986847, 0.20729295909404755, -0.682322084903717, -1.1425102949142456, 0.5389817953109741, -0.29271185398101807, 0.32476815581321716, 0.31226232647895813, -0.3104589879512787, 0.20066587626934052, 0.1347602754831314, 1.0867425203323364, -0.38805845379829407, -0.18247240781784058, -0.02927219681441784, 0.45289120078086853, -0.6553627848625183, -0.5232083797454834, 0.25596436858177185, 0.09702840447425842, -0.34705856442451477, 1.0339112281799316, 0.01758665218949318, -0.16391333937644958, -0.3698062300682068, -0.16029278934001923, 0.03304583951830864, 0.024432770907878876, -0.07993058115243912, 0.7503947019577026, -0.7104294300079346, -0.5657851696014404, -1.0755289793014526, 0.6316565871238708, -0.16149437427520752, -0.39049503207206726, -0.2408154308795929, -0.3660076856613159, -0.293521910905838, 0.3946574926376343, -0.37218397855758667, -0.03239564225077629, -0.4425414800643921, 0.02904963679611683, -0.2946590483188629, -0.002108511049300432, 0.31475016474723816, 0.4740932881832123, -0.03914417326450348, 0.24461641907691956, 0.9072333574295044, 0.37330156564712524, 0.16937534511089325, 0.20540545880794525, -0.6492015719413757, 0.4387195408344269, 0.05008299648761749, 0.12250817567110062, 0.14442743360996246, -0.17962683737277985, -0.7876944541931152, -0.4855878949165344, -0.2856507897377014, 0.029432233422994614, -0.1907625049352646, 0.12803345918655396, -0.8593104481697083, -0.9148083329200745, -0.3979535400867462, -1.161743402481079, 0.05236784741282463, -0.07507392764091492, -0.3913600444793701, -0.21417079865932465, -0.8200982213020325, -1.2051644325256348, -0.5532104969024658, -1.201764702796936, -1.216051697731018, 0.5106438398361206, -0.13500560820102692, -0.5732707977294922, -0.15959537029266357, -0.13006500899791718, -0.750958263874054, 1.4775869846343994, -0.8831183910369873, 0.6380589604377747, -0.19982045888900757, -0.3788870573043823, -0.09562310576438904, -0.16755971312522888, -0.07636743038892746, -0.39649325609207153, 0.29747387766838074, -0.5402402877807617, 0.2554633915424347, -0.21956373751163483, -0.11098133772611618, 0.2640816867351532, 0.4189794361591339, 1.203508734703064, -0.023062588647007942, -0.8407183885574341, 0.2863454818725586, 1.3665213584899902, -0.15267892181873322, 0.3377327620983124, -0.10518812388181686, 0.9635799527168274, -0.3933335840702057, -0.21575844287872314, 0.9635857939720154, 0.3146916925907135, 0.6458132266998291, 0.040370866656303406, -0.008709713816642761, -0.11001541465520859, -0.1892053335905075, 0.7477012276649475, 2.4669148921966553, 0.48468270897865295, 0.16055983304977417, -0.949577808380127, 0.6045679450035095, -0.9222379326820374, -1.1596136093139648, 0.4259485900402069, 0.6760303378105164, 0.5689928531646729, -0.46789491176605225, -0.21493636071681976, -0.07633998245000839, 0.12041042000055313, 0.6561972498893738, -0.37902915477752686, -1.0169669389724731, 0.08374710381031036, 0.5829318165779114, 0.29305315017700195, 0.5884561538696289, -0.26253530383110046, 0.5123578906059265, 14.75047492980957, 1.0183371305465698, -0.2765938937664032, 0.7147611975669861, 0.7932752370834351, 0.2877059578895569, -0.3474613130092621, -0.1692499965429306, -1.3601683378219604, 0.08047980070114136, 1.254538655281067, -0.08340555429458618, 0.2828028202056885, 0.4158104956150055, -0.14527763426303864, 0.2594453692436218, -0.4452480375766754, 0.7246074676513672, 0.8719236850738525, -1.5810984373092651, 0.32471078634262085, -0.006707370281219482, 0.24469856917858124, 0.5856788754463196, 0.9783616065979004, 0.5267064571380615, 0.5024724006652832, -0.21459037065505981, 0.24225468933582306, 0.4123973846435547, 1.23419189453125, 0.11947624385356903, 0.021059948951005936, 0.16169621050357819, -1.1946014165878296, -0.08143480867147446, -0.5877008438110352, -1.334286093711853, 0.0326961986720562, 0.513251006603241, -0.22601664066314697, -0.9215731024742126, -0.17291630804538727, 0.8456220030784607, 0.31241869926452637, 0.4953756332397461, 0.4019709825515747, 0.4993915557861328, -0.11535584181547165, -0.12644484639167786, 0.08677934110164642, 0.41789644956588745, 0.09781812876462936, 0.2528618276119232, 0.4056004583835602, -0.08823077380657196, 0.199579119682312, 0.3260650336742401, -0.2141023725271225, 0.012259072624146938, -0.5874237418174744, -0.22128137946128845, 0.08748508244752884, 0.4317493140697479, 0.6724454760551453, 0.3115762174129486, -0.9292010068893433, 0.2259705811738968, 0.450168639421463, -0.11402178555727005, -0.5128738880157471, 0.0051172333769500256, 0.20956920087337494, -0.3363831341266632, 0.34618091583251953, 0.3920879065990448, -0.4160703420639038, -0.6579909324645996, -0.9981496334075928, -0.8294478058815002, 0.28843653202056885, -0.6561794281005859, -0.6626548767089844, 0.9338352084159851, -0.4923456013202667, -0.28592318296432495, 0.20403799414634705, -0.42787477374076843, -0.19802787899971008, 0.2984142005443573, -0.754010021686554, -0.11174152046442032, 0.21302583813667297, -0.40876007080078125, -0.21374087035655975, -0.22453606128692627, 1.4161195755004883, 0.46585509181022644, -0.3141848146915436, 0.26847195625305176, 0.32953616976737976, -0.30069175362586975, -0.4200240671634674, -0.31655779480934143, 1.1007996797561646, 0.3420960605144501, -0.02614169754087925, 0.40964841842651367, 0.24443143606185913, 0.04858213663101196, -1.3693242073059082, -0.05693932995200157, 0.8793044686317444, -0.39060908555984497, -0.17205283045768738, -0.8921511769294739, -0.6860652565956116, 0.31269726157188416, 0.48594608902931213, -0.20812803506851196, 0.5829868912696838, 0.09795355796813965, -0.656352698802948, -0.3684430420398712, -0.4473956823348999, 0.4072982966899872, 0.7253678441047668, -0.8236023187637329, 0.2762097418308258, 0.09135930985212326, 0.5089066028594971, -1.2120678424835205, -0.2914096713066101, -0.1777506023645401, -0.011298451572656631, -0.1185484305024147, 1.2136479616165161, 0.05762863904237747, 1.23048996925354, 0.8297114372253418, -0.4633520543575287, -0.3134268522262573, -0.225180521607399, -0.6519614458084106, -0.48400750756263733, -0.09257662296295166, 0.6115833520889282, -0.019453348591923714, 0.6407264471054077, 0.8812991976737976, 0.3779056966304779, -0.415484756231308, -0.4818630516529083, -0.08971066772937775, -0.4424121677875519, -0.509684145450592, 0.21983662247657776, -0.05900174006819725, 0.2922757565975189, 0.1063477024435997, 0.3198094964027405, 0.004253792110830545, -0.2828986346721649, -0.2839062511920929, 0.3523341417312622, 0.13807262480258942, -0.12431821972131729, -0.3895673453807831, -0.5115101337432861, -1.3185315132141113, -0.13083647191524506, -1.1273168325424194, -0.0963813066482544, -0.4292157292366028, 0.09418006241321564, 0.13287413120269775, -0.0702146515250206, -0.09317385405302048, 0.4246214032173157, -0.11438629031181335, -0.40428459644317627, -0.49595925211906433, -0.7301173210144043, 0.8018792867660522, 0.6213400959968567, -0.7354577779769897, 0.12527593970298767, -0.36252865195274353, -0.15408171713352203, 0.37842679023742676, 0.3569636046886444, -0.4739898443222046, -0.6114304065704346, -1.2454320192337036, 0.33723342418670654, -0.13642461597919464, -0.4157758355140686, -1.1467220783233643, 1.0801278352737427, 0.11652281880378723, -0.5087728500366211, -0.14974841475486755, 0.25979530811309814, -0.9921385049819946, -0.34462717175483704, 0.8289139270782471, -0.820306658744812, 0.6507948040962219, 0.5580381751060486, -0.598835289478302, -0.31346508860588074, 0.7586939334869385, 0.0033450720366090536, -0.9099575281143188, -0.7372192144393921, 0.37603485584259033, -0.6341039538383484, 0.442116916179657, -0.2650749683380127, -0.0207635760307312, -1.02660071849823, -0.6211602091789246, 0.2147102802991867, -0.24879173934459686, -0.45834699273109436, 0.6414341330528259, 0.4295269548892975, -1.1952955722808838, 0.31186914443969727, 0.6673068404197693, -0.13994403183460236, -0.3854476511478424, 0.8483841419219971, 0.549229621887207, -0.4543086290359497, 0.6354409456253052, 0.22850514948368073, 0.22709429264068604, -1.0569179058074951, 0.3426269292831421, 0.2129841446876526, -0.5164642333984375, 0.0016955434111878276, 0.9041777849197388, -0.2384115308523178, -0.4785148501396179, -0.065752312541008, -1.1122937202453613, -0.4567510187625885, -0.46136903762817383, 0.7061477303504944, 0.054623957723379135, 0.08451485633850098, -0.197592630982399, -0.7758121490478516, -0.034686196595430374, -0.336060106754303, -0.2272123098373413, 0.27296003699302673, -0.0005979615380056202, -0.6549113988876343, 0.2581144869327545, 0.8953584432601929, -0.03698163479566574, -0.14337268471717834, -0.9287729859352112, -0.6544762253761292, -0.2968738377094269, 0.39002135396003723, 0.1643080860376358, -0.9863474369049072, 0.6547673344612122, 0.48711928725242615, 0.344992071390152, 0.1264638602733612, -0.48862412571907043, 0.691011369228363, 0.6292828321456909, 0.012675444595515728, -0.4473622143268585, -0.5193437933921814, 1.8702665567398071, 1.2546478509902954, -0.5971862077713013, 0.3865610361099243, -0.533850908279419, -0.5856291651725769, 0.5264401435852051, 0.4915221333503723, -0.3363620340824127, 1.2596769332885742, 0.6339022517204285, -0.22969618439674377, 0.10798463970422745, -1.083333134651184, -0.4105527997016907, 0.8784258365631104, 0.9781361818313599, 1.2239549160003662, 0.04165966808795929, -0.13632215559482574, 0.5831409096717834, 0.3349454700946808, 0.20124346017837524, 0.2639608085155487, 0.34193655848503113, -0.4082047939300537, 0.06273114681243896, -0.1260199099779129, 0.9946680068969727, -0.5071671605110168, -1.4494752883911133, 0.6711962819099426, 0.24029216170310974, -0.20125320553779602, 0.3981298804283142, 1.3427554368972778, -0.3288101553916931, 0.244370698928833, 0.0019031647825613618, 0.2145746797323227, -0.6770967245101929, -0.38722217082977295, -0.24837824702262878, -0.8683136701583862, -0.1654181033372879, -0.040808286517858505, -0.6644954681396484, -0.334732323884964, -0.37157729268074036, 0.46538856625556946, -0.2507478594779968, 0.18118248879909515, 0.6908160448074341, 1.243087649345398, 0.573983371257782, -0.4556768536567688, -0.6711979508399963, -0.24908897280693054, -0.6398361325263977, 0.28985175490379333, -0.3950886130332947, -0.610480010509491, 0.1455308049917221, 0.08912405371665955, -0.34074166417121887]}, "authors": [{"authorId": "2265615205", "name": "Huize Li"}, {"authorId": "1665894016", "name": "Zhaoying Li"}, {"authorId": "2294754284", "name": "Zhenyu Bai"}, {"authorId": "2239094310", "name": "Tulika Mitra"}], "references": [{"paperId": "3a4e97478ad1b113a7f51668f05d5ba85e500f5a", "title": "CPSAA: Accelerating Sparse Attention Using Crossbar-Based Processing-In-Memory Architecture"}, {"paperId": "13270b9759cf0296b5a346fbb58b706e8ad0a982", "title": "Adaptable Butterfly Accelerator for Attention-based NNs via Hardware and Algorithm Co-design"}, {"paperId": "f841f3d912be52a621aab1a979632e9daeab6599", "title": "Sparse Attention Acceleration with Synergistic In-Memory Pruning and On-Chip Recomputation"}, {"paperId": "e8a69aeec395ec60f1c0f9dd2a1128c728a641d9", "title": "ReSMA: accelerating approximate string matching using ReRAM-based content addressable memory"}, {"paperId": "f5edad3a50ba8a6329d202f31677d988f1d0cf87", "title": "TransPIM: A Memory-based Acceleration via Software-Hardware Co-Design for Transformer"}, {"paperId": "2babc9ba9dd301d6e61117302bd2a200f7b422e2", "title": "DOTA: detect and omit weak attentions for scalable transformer acceleration"}, {"paperId": "d8349ab318cd280e5f5233e774be2c4a1734fee5", "title": "A four-megabit compute-in-memory macro with eight-bit precision based on CMOS and resistive random-access memory for AI edge devices"}, {"paperId": "b97c3c370401dc34d2adbeb24f34de5180a14be6", "title": "Sanger: A Co-Design Framework for Enabling Sparse Attention using Reconfigurable Architecture"}, {"paperId": "62764bb2728d95805c93daef5f7a3a9debcd6417", "title": "Algorithm-hardware Co-design of Attention Mechanism on FPGA Devices"}, {"paperId": "9d1934ea1bd69d928d17e05d44495d42edf8601d", "title": "You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection"}, {"paperId": "309fb5c6ed6d7ec85281ee315760df342e6c4fcc", "title": "Ten Lessons From Three Generations Shaped Google\u2019s TPUv4i : Industrial Product"}, {"paperId": "e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60", "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"}, {"paperId": "4badd753be64c5c5b57dd2bb2e515fbe0c0720d8", "title": "SparseBERT: Rethinking the Importance Analysis in Self-attention"}, {"paperId": "337648624e4560b99db2ce5c04064c11762e1cde", "title": "25.4 A 20nm 6GB Function-In-Memory DRAM, Based on HBM2 with a 1.2TFLOPS Programmable Computing Unit Using Bank-Level Parallelism, for Machine Learning Applications"}, {"paperId": "99026c277735284df33636455702e9eaf469583b", "title": "ReTransformer: ReRAM-based Processing-in-Memory Architecture for Transformer Acceleration"}, {"paperId": "ac286619e413c5cc19268fe0f5b16dd647d931ac", "title": "ReSQM: Accelerating Database Operations Using ReRAM-Based Content Addressable Memory"}, {"paperId": "b78150c2f9e2b69e2c149fc9086e75b16cb8daa3", "title": "PCI Express\u00ae 6.0 Specification at 64.0 GT/s with PAM-4 signaling: a low latency, high bandwidth, high reliability and cost-effective interconnect"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "7c6c31412c5dad22543bb71e31620e8868d644a3", "title": "FTRANS: energy-efficient acceleration of transformers using FPGA"}, {"paperId": "a0185d4f32dde88aa1749f3a8000ed4721787b65", "title": "Visual Transformers: Token-based Image Representation and Processing for Computer Vision"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "d3c6c635b9cfd8890c7244d3db4be53d45944963", "title": "A^3: Accelerating Attention Mechanisms in Neural Networks with Approximation"}, {"paperId": "140c914f0add58a9599a2fa58eeb95cdd5365348", "title": "In-Memory Low-Cost Bit-Serial Addition Using Commodity DRAM Technology"}, {"paperId": "b03cf6324ecf7a295a4aeae5970c88d1a1c3f336", "title": "Explicit Sparse Transformer: Concentrated Attention Through Explicit Selection"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "a3ef6ee560e93e6f58be2b28f27aed0eb86dc463", "title": "Fine-tune BERT with Sparse Self-Attention Mechanism"}, {"paperId": "c95383f251a62c63217586059c67f63507c3e839", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"}, {"paperId": "be283fc67ecbfe0cb1e50718181ce7b9c0d53a74", "title": "How Does BERT Answer Questions?: A Layer-Wise Analysis of Transformer Representations"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "5a2b2f48b31f5ecf809d2fd15d0a18511fca902d", "title": "FloatPIM: In-Memory Acceleration of Deep Neural Network Training with High Precision"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "4d1c856275744c0284312a3a50efb6ca9dc4cd4c", "title": "Know What You Don\u2019t Know: Unanswerable Questions for SQuAD"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "9071775ebcfebddd54d879fe7e6c627673e4d305", "title": "ISAAC: A Convolutional Neural Network Accelerator with In-Situ Analog Arithmetic in Crossbars"}, {"paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd", "title": "ImageNet Large Scale Visual Recognition Challenge"}, {"paperId": "69cd11bf39f5cf9007bb0b97789bb21963dee69d", "title": "A 3.1 mW 8b 1.2 GS/s Single-Channel Asynchronous SAR ADC With Alternate Comparators for Enhanced Speed in 32 nm Digital SOI CMOS"}, {"paperId": "d9c91cd78453345e84db52bea42294acc2f85223", "title": "ZSim: fast and accurate microarchitectural simulation of thousand-core systems"}, {"paperId": "1e4d081c6fa2103ccd0b9d977d98dffaff3a6f3c", "title": "Computer Architecture with Associative Processor Replacing Last-Level Cache and SIMD Accelerator"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "1600c3ed12301b06a1107a68c2de84fb3582a918", "title": "Relaxing non-volatility for fast and energy-efficient STT-RAM caches"}, {"paperId": "7ce099f7a0233645e63ae76cb957df3d1706b871", "title": "Analysis of Power Consumption and Linearity in Capacitive Digital-to-Analog Converters Used in Successive Approximation ADCs"}, {"paperId": "fd840d5275cac98d64e7778a1b9173b937a77386", "title": "Resistive Random Access Memory (ReRAM) Based on Metal Oxides"}, {"paperId": "35a8c483ed0641ebbb56da1bd2d0f188b000a8ca", "title": "RETROSPECTIVE:PRIME: A Novel Processing-in-memory Architecture for Neural Network Computation in ReRAM-based Main Memory"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "ff5da2bc9951173d51fcc1d50d44488702b5f1f5", "title": "Ramulator: A Fast and Extensible DRAM Simulator"}, {"paperId": "ab992b1d7ea296b3bc3a1d3b496d10447d00a789", "title": "Phase change memory"}, {"paperId": null, "title": "license agreement with IEEE. Restrictions apply"}]}