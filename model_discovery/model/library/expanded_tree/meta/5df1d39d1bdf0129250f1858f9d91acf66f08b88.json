{"paperId": "5df1d39d1bdf0129250f1858f9d91acf66f08b88", "abstract": "Query-focused summarization (QFS) aims to produce summaries that answer particular questions of interest, enabling greater user control and personalization. With the advent of large language models (LLMs), shows their impressive capability of textual understanding through large-scale pretraining, which implies the great potential of extractive snippet generation. In this paper, we systematically investigated two indispensable characteristics that the LLMs-based QFS models should be harnessed, Lengthy Document Summarization and Efficiently Fine-grained Query-LLM Alignment, respectively. Correspondingly, we propose two modules called Query-aware HyperExpert and Query-focused Infini-attention to access the aforementioned characteristics. These innovations pave the way for broader application and accessibility in the field of QFS technology. Extensive experiments conducted on existing QFS benchmarks indicate the effectiveness and generalizability of the proposed approach. Our code is publicly available at https://github.com/DCDmllm/IDEAL_Summary.", "venue": "", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper systematically investigated two indispensable characteristics that the LLMs-based QFS models should be harnessed, Lengthy Document Summarization and Efficiently Fine-grained Query-LLM Alignment, respectively and proposes two modules called Query-aware HyperExpert and Query-focused Infini-attention to access the aforementioned characteristics."}, "embedding": {"model": "specter_v2", "vector": [-0.08975429832935333, 0.39553457498550415, -0.518913745880127, -0.1370203197002411, -0.8699736595153809, -0.3925315737724304, 0.5103417634963989, 0.08537007123231888, -0.44170328974723816, -0.06828425079584122, 1.1471039056777954, 0.49772897362709045, -0.340152770280838, 0.3376348316669464, 0.2463167905807495, 0.5696533918380737, -0.9385639429092407, 0.43395501375198364, -0.37354034185409546, -0.4653873145580292, 0.4724428653717041, -0.7451217770576477, -0.8732295632362366, 0.3925060033798218, 1.0786378383636475, -0.07212083041667938, 0.014013043604791164, 1.1935248374938965, -0.5933876633644104, 0.055552080273628235, 0.06357221305370331, -0.18061792850494385, -0.3834540843963623, 0.009636876173317432, -0.46187666058540344, 0.07842686772346497, 0.44576314091682434, -0.6505540013313293, -0.43363744020462036, 0.6079856753349304, 0.1741049736738205, 0.21327228844165802, 0.6447674632072449, -0.12399602681398392, -0.2740943133831024, 1.0746243000030518, 0.7782914042472839, 0.7741527557373047, 0.26470524072647095, -0.5498613119125366, 1.4816169738769531, -1.4088741540908813, 0.4284058213233948, 1.6085731983184814, 0.1033264696598053, 0.3958287835121155, -0.08818599581718445, -0.4024416506290436, 0.7391756176948547, -0.05519113317131996, -1.0056407451629639, -0.3961217701435089, -0.2420177459716797, -0.2198527306318283, 1.9165287017822266, -0.003913980443030596, -0.026417210698127747, 0.23961780965328217, -0.16267696022987366, 1.9631885290145874, -0.7918450236320496, -0.6821388006210327, -0.2135898917913437, 0.0956086739897728, 0.8071027398109436, 0.6679214835166931, -0.5379769206047058, -0.12005993723869324, -0.9416165351867676, -0.16900497674942017, 0.227730855345726, -0.12262029200792313, -0.5826361179351807, 0.44816744327545166, -0.18150651454925537, 0.5615837574005127, 0.24284520745277405, 0.8007058501243591, -0.38806092739105225, 0.22350701689720154, 0.2369711697101593, 0.25616392493247986, 0.22498135268688202, 0.8259603381156921, -0.1221606582403183, 0.3589082658290863, -1.1771103143692017, 0.7423390746116638, 0.2646634578704834, 0.986129105091095, -0.28264060616493225, 0.06499457359313965, -1.2619444131851196, 0.24984110891819, 0.8934251070022583, 0.13436786830425262, 0.7049074769020081, -0.7415880560874939, 0.09416523575782776, -0.3150002062320709, 0.773247241973877, -0.6803698539733887, -0.4244268834590912, -0.47593429684638977, -0.3870803117752075, -1.6977452039718628, -0.8313286304473877, -0.10933863371610641, -0.3100399374961853, 0.5825638771057129, -0.5052391886711121, -0.2580745220184326, 0.15809787809848785, 0.44693875312805176, 0.984480082988739, 0.8316842317581177, 0.3024919629096985, -0.29094386100769043, 0.9123126864433289, -0.6414018869400024, -0.8889073133468628, -1.197755217552185, 1.0574275255203247, 0.06704377382993698, 0.1559072583913803, -0.2249319702386856, -1.3566830158233643, -1.0185445547103882, -0.8082211017608643, 0.067938432097435, -0.35898953676223755, 0.5419744849205017, 0.6399261355400085, 0.14649075269699097, -0.9216620922088623, 0.8367350101470947, -0.07750103622674942, -0.5233292579650879, -0.0837734043598175, 0.1552419811487198, 0.2862732708454132, -0.40483608841896057, -1.261240005493164, 0.1214941218495369, 0.2629842460155487, -0.8008744120597839, -0.054095786064863205, -0.5631938576698303, -1.0652210712432861, 0.04273666813969612, 0.554050087928772, -0.9384786486625671, 1.3262161016464233, 0.11131582409143448, -1.0117937326431274, 0.40393751859664917, -0.6917250156402588, 0.16991925239562988, 0.20073775947093964, -0.9348715543746948, -0.6568930745124817, 0.05435433238744736, 0.06000901386141777, 0.49149075150489807, 0.07132992148399353, -0.11051806062459946, -0.41617631912231445, -0.02544807642698288, -0.42890462279319763, 0.11972402781248093, -0.6623637676239014, 1.0071024894714355, -0.7455575466156006, -0.13169720768928528, 0.03547284007072449, 1.150944471359253, -0.14676804840564728, -0.7226541638374329, -0.8178792595863342, -1.3685483932495117, 0.4681096374988556, -0.3479733169078827, 1.997357964515686, -0.7236682772636414, -0.48854860663414, -0.5731106400489807, 0.07293114066123962, 0.18163517117500305, -1.038870930671692, 1.168188452720642, 0.017965024337172508, 0.9754267334938049, -0.15522201359272003, -1.0324490070343018, 0.24952378869056702, -0.6935635209083557, -0.6529546976089478, -0.6361006498336792, 0.42423874139785767, 1.3643789291381836, -1.0364893674850464, -0.0548403300344944, -0.21283894777297974, -0.0686047375202179, -0.8386393189430237, 1.3066033124923706, -0.6526724100112915, 0.20647810399532318, -0.8307290077209473, -0.23382550477981567, 0.1404506415128708, -0.19138537347316742, 0.14824117720127106, -0.46191418170928955, -0.5675460696220398, 0.15249024331569672, -0.6015306711196899, 1.4449657201766968, 0.039385613054037094, 0.19581520557403564, -0.3893345594406128, -0.3262956142425537, 0.12562188506126404, 0.5209977030754089, -0.23537325859069824, -0.429796040058136, 0.05656026676297188, 0.48834073543548584, -1.1807552576065063, -0.5150730013847351, 0.9631644487380981, 0.7955413460731506, -0.7817867398262024, 0.3394326865673065, 0.5967423915863037, -0.22893626987934113, 1.1886041164398193, 0.7400572896003723, 0.8011792302131653, 0.253618985414505, 0.5841948390007019, -0.1810101717710495, 0.4581793546676636, -0.39844170212745667, -0.0766342431306839, 0.7154865264892578, 0.9930753111839294, 0.7677150368690491, 0.2026793658733368, -0.508159339427948, 0.05431879311800003, 0.1803179532289505, 0.9005739688873291, 1.3323673009872437, -0.04544908553361893, -0.743537425994873, -0.8782193660736084, -0.3377615511417389, -0.2360137552022934, 0.5031673312187195, -0.22997085750102997, -0.07247906178236008, -0.6182957887649536, -0.8420431017875671, 0.4951082170009613, 0.3203640282154083, 0.8193318247795105, -0.595937967300415, -0.38233569264411926, -0.06434863060712814, -0.014518789947032928, -0.38439780473709106, -0.7040630578994751, 0.08744361251592636, -0.5892665982246399, -0.27812060713768005, -0.19253821671009064, 0.04414159804582596, -0.04123593121767044, -0.6348316073417664, 1.2900235652923584, -0.3600633144378662, -0.20081016421318054, 0.41396257281303406, 0.3704596757888794, -0.6648841500282288, -0.5280002355575562, 0.023436862975358963, -0.05444138124585152, -0.5264377593994141, 0.45047664642333984, 0.5794837474822998, -0.22305403649806976, -0.0012145390501245856, -0.6498793959617615, 0.1298854798078537, 0.18312233686447144, -0.11774177104234695, 0.5208337306976318, -0.03554796427488327, 0.5265334844589233, -1.2836328744888306, 1.3655167818069458, 0.03053594008088112, -0.022770334035158157, 0.6196479797363281, -0.3590903878211975, -0.2071017175912857, 0.5882712006568909, -0.5110718011856079, -0.4651522934436798, -1.2121444940567017, 0.5718798637390137, 0.49651750922203064, -0.3715824484825134, 1.0099055767059326, -0.10815957933664322, 0.8051888942718506, 0.2500845193862915, 0.4995541274547577, 0.033602163195610046, -0.48146483302116394, 0.6731029152870178, -0.20972447097301483, 0.6700063347816467, 0.6619343757629395, -0.07097335904836655, -0.33718204498291016, -0.6935153007507324, -0.983924388885498, -0.566682755947113, -0.8426780104637146, -0.24449129402637482, -0.13144360482692719, -0.06591913849115372, -0.5260894894599915, -0.4710274338722229, -0.3007752597332001, -1.2681396007537842, 0.23260138928890228, 0.10776693373918533, -0.3878350555896759, -0.13475145399570465, -0.9716402888298035, -1.0166945457458496, -0.8744504451751709, -0.7810001969337463, -0.36786437034606934, 0.613398015499115, 0.2647722065448761, -1.0486935377120972, -0.5716405510902405, 0.19131678342819214, -0.3547450602054596, 0.7572662830352783, -0.3646196126937866, 1.0853065252304077, -0.30915015935897827, -0.05318570137023926, -0.7386720776557922, 0.3990188241004944, 0.43313708901405334, -0.11589595675468445, 0.11719240993261337, -0.38252225518226624, 0.1845141351222992, -0.10318449884653091, -0.07387028634548187, 0.35264378786087036, 0.7026564478874207, 0.34861746430397034, 0.1158061996102333, -0.8438001871109009, -0.14990893006324768, 1.4200773239135742, -0.5851749777793884, -0.12041025608778, -0.1714058816432953, 0.743000328540802, 0.7681769728660583, 0.10726924240589142, 0.9100987911224365, 0.2153523713350296, 0.09227414429187775, -0.12436895072460175, -0.49619919061660767, 0.07747586816549301, -0.42843499779701233, 0.7369247078895569, 1.7622568607330322, 0.5935892462730408, -0.7195938229560852, -0.8059595227241516, 0.718528151512146, -1.4567782878875732, -0.41716521978378296, 0.44553515315055847, 0.5564876198768616, 0.16794688999652863, -0.8210138082504272, -0.23303766548633575, -0.41799256205558777, 0.22260326147079468, 0.18557915091514587, -0.5155869722366333, -0.30968019366264343, 0.07756457477807999, 0.30992549657821655, -0.26204073429107666, 0.47126537561416626, -0.2292454093694687, 0.6202980875968933, 14.353882789611816, 0.7611695528030396, 0.47282618284225464, -0.04964858666062355, 0.560642421245575, 0.056210484355688095, -0.5828380584716797, -0.35503068566322327, -1.3528136014938354, -0.41432756185531616, 1.437601923942566, -0.6790496706962585, 0.06441611051559448, -0.10445765405893326, 0.7089321613311768, -0.025327978655695915, -0.8877971172332764, 0.4944225549697876, 0.5216841101646423, -1.1616822481155396, 0.959743320941925, 0.16432823240756989, 0.17298190295696259, 0.15892910957336426, 0.6068477630615234, 1.0874425172805786, 0.10811147838830948, -0.4909326136112213, 0.4475264251232147, 0.5938801765441895, 0.5520843863487244, -0.5822433233261108, 0.6984509229660034, 1.3066189289093018, -0.6468449234962463, -0.5382347106933594, -0.6324352025985718, -0.8638820052146912, 0.633142352104187, 0.07566717267036438, -0.4257855713367462, 0.05748136714100838, -0.48980703949928284, 0.9544630646705627, -0.10370778292417526, 0.3946059048175812, -0.21243515610694885, 0.5149059891700745, 0.2964460849761963, -0.21383115649223328, 0.1756468564271927, 0.5265214443206787, 0.5567643046379089, 0.17038047313690186, 0.35897791385650635, 0.2606080174446106, 0.2952736020088196, 0.6792090535163879, -0.38778313994407654, 0.3929479420185089, -0.4224455952644348, -0.5644446611404419, 0.13360531628131866, 0.49089315533638, 0.7949975728988647, -0.03633718192577362, -0.257412314414978, 0.3302170932292938, 0.5479444265365601, 0.23310038447380066, 0.3221093714237213, -0.34637823700904846, -0.03760067746043205, -0.0498959943652153, -0.2760240435600281, 0.6835994720458984, -0.029729485511779785, -0.47834694385528564, -0.741624116897583, -0.37707197666168213, 0.6350600719451904, -0.5352305173873901, -0.8773754239082336, 0.9462698101997375, 0.2106044441461563, -0.7140530347824097, -0.375234454870224, -0.34480321407318115, -0.4834398627281189, 0.49368876218795776, -1.120099663734436, -0.6150591373443604, 0.32991480827331543, -0.8113009333610535, 0.00583752803504467, 0.2754268944263458, 1.4889923334121704, -0.23120996356010437, -0.7930359840393066, -0.26648417115211487, 0.2636902928352356, -0.5357780456542969, -0.15668323636054993, -0.9118624329566956, 0.6084969639778137, 0.19343416392803192, -0.3492046892642975, 0.7129092216491699, 0.11828383058309555, -0.2605438828468323, -0.9341238737106323, -0.22108648717403412, 1.0818908214569092, -1.0177415609359741, -0.7964832782745361, -0.6782784461975098, -0.943488359451294, -0.024525530636310577, 0.6325092911720276, -0.9372292160987854, 0.5856798887252808, 0.1890154480934143, 0.39852216839790344, 0.25161558389663696, -0.7436481714248657, 0.09398820996284485, 0.38328665494918823, -0.3958776891231537, -0.4410935640335083, 0.15255171060562134, 0.4761599004268646, -0.33801335096359253, -0.3173425495624542, -0.21256707608699799, -0.20021232962608337, -0.10060176253318787, 0.7539868950843811, -0.54853755235672, 0.6771190762519836, 0.8056873679161072, 0.0253756046295166, -0.8916886448860168, -0.11023413389921188, -0.848939836025238, -0.030859844759106636, 0.4452165961265564, 0.8028238415718079, 0.041105687618255615, 0.0829123854637146, 1.1738255023956299, 0.3495721220970154, -0.571824848651886, -0.01630011387169361, -0.1619277000427246, 0.30047866702079773, -0.23593750596046448, 0.1310005635023117, -0.5741977095603943, 0.15521252155303955, 0.1535732001066208, 0.508166491985321, 0.753763735294342, -0.45021045207977295, -0.5443418622016907, 0.7077170610427856, -0.22997276484966278, 0.20753298699855804, -0.5671731233596802, -0.006616530008614063, -1.7328404188156128, -0.059327658265829086, -0.9424381256103516, 0.0053650555200874805, -1.4254454374313354, -0.011523629538714886, 0.9658398032188416, -0.16593614220619202, -0.5157944560050964, 0.03519602119922638, -0.7732561230659485, -0.8148889541625977, -0.5656445026397705, -1.1222364902496338, 0.6530499458312988, 0.9438138604164124, -0.6523759365081787, -0.3920416235923767, -0.2517567276954651, -0.4559180438518524, 0.2658637464046478, 0.1906048208475113, -0.3477158546447754, -0.8778166770935059, -1.24526846408844, 0.3183349072933197, 0.18760043382644653, -0.21474532783031464, -0.3650752007961273, 0.6425676345825195, 0.5331777334213257, -0.18250250816345215, -0.5440120100975037, -0.08837788552045822, -0.27928879857063293, -0.42719098925590515, 0.22360634803771973, -1.0940440893173218, -0.10953473299741745, 0.32793229818344116, -0.6181050539016724, -0.8197564482688904, 0.3292591869831085, -0.5364773273468018, -1.3166420459747314, -0.7906929850578308, 0.5447351932525635, -0.6749823689460754, 0.06307481974363327, -0.6151692867279053, -0.17785939574241638, -0.8184428811073303, -0.5922947525978088, 0.17321929335594177, 0.9186999201774597, -0.4309059977531433, 0.6250941753387451, 0.7029224634170532, -1.0424411296844482, -0.4398691952228546, 0.021074118092656136, 0.12669622898101807, -0.05117448791861534, 0.985755205154419, 0.1665326952934265, 0.05984945595264435, 0.756161093711853, 0.7312281131744385, 0.32683637738227844, -0.8390082716941833, -0.1728730946779251, 0.4864175617694855, -0.8657731413841248, -0.21424046158790588, 1.1979188919067383, -0.08917288482189178, -0.778667151927948, 0.0205161701887846, -0.9860844612121582, -1.0521794557571411, -0.08814886212348938, 1.3797204494476318, 0.43545272946357727, -0.18162858486175537, 0.01119207963347435, -0.4739551544189453, 0.36044183373451233, -0.2920290231704712, -0.5946228504180908, 1.0543016195297241, -0.4535543620586395, -0.37038588523864746, 0.5428383946418762, 0.8884522914886475, -0.7065367102622986, -0.30481091141700745, -0.5298166871070862, 0.3649297058582306, -0.027346516028046608, 0.47289466857910156, -0.42953091859817505, 0.22987952828407288, 0.5530601739883423, 0.3700891435146332, 0.4635293185710907, 0.4243936240673065, -0.04418380931019783, 0.48214852809906006, 0.4803895056247711, -0.18122217059135437, -0.7945502400398254, -0.27836930751800537, 1.0319058895111084, 1.7800363302230835, -0.8169010281562805, 0.23194020986557007, 0.008525177836418152, -0.8299182057380676, 1.0999915599822998, 0.0003340753319207579, 0.009718338958919048, 0.4948730766773224, -0.3697570264339447, 0.21991121768951416, -0.40238073468208313, -1.2912389039993286, -0.24019405245780945, 1.1946632862091064, 0.8751399517059326, 1.048909306526184, 0.20309658348560333, -0.21405534446239471, 1.3110039234161377, 0.24415327608585358, 0.47155219316482544, 0.5149405002593994, 0.5094984769821167, -0.6913924217224121, 0.1069735735654831, 0.3907019793987274, 0.566633939743042, -0.46073660254478455, -0.4445512890815735, -0.1802825778722763, 0.5397438406944275, -0.10937854647636414, 1.039335012435913, 0.5162402987480164, 0.1745826154947281, 0.9675270318984985, 0.3239842653274536, 0.13967140018939972, -0.9618105292320251, -0.38748952746391296, 0.08317949622869492, -0.32996323704719543, -0.025524012744426727, -0.0994017943739891, -0.3524983525276184, -0.4536364674568176, 0.15355144441127777, 0.15531803667545319, 0.24491220712661743, 0.14120088517665863, 1.0835368633270264, 0.7999468445777893, 0.26516106724739075, -0.2685012221336365, -0.24101069569587708, -0.665595293045044, -1.2108516693115234, -0.45381778478622437, -0.23750703036785126, -0.13723260164260864, 0.1372431218624115, -0.2788744270801544, -0.30432289838790894]}, "authors": [{"authorId": "2109811486", "name": "Jie Cao"}, {"authorId": "2302798653", "name": "Dian Jiao"}, {"authorId": "2311684610", "name": "Qiang Yan"}, {"authorId": "2108125912", "name": "Wenqiao Zhang"}, {"authorId": "2118071462", "name": "Siliang Tang"}, {"authorId": "2253660817", "name": "Yueting Zhuang"}], "references": [{"paperId": "3fd5bc3077d04965eaa3498372c39bbdd09d55e4", "title": "Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention"}, {"paperId": "823ca4778e1027f2f0b356df051d762dcecaaba0", "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"}, {"paperId": "dbc368bc8b49347dd27679894524fa62f88492c9", "title": "Unlimiformer: Long-Range Transformers with Unlimited Length Input"}, {"paperId": "a757999ed260d7bc45484dc6b4456bf33fe6f679", "title": "LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "d2fe7536b347a7039a241bb60d507880ada686e8", "title": "OASum: Large-Scale Open Domain Aspect-based Summarization"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "43a87867fe6bf4eb920f97fc753be4b727308923", "title": "Towards a Unified View of Parameter-Efficient Transfer Learning"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "aa28873534c24e4a8c5deb7bff723cd5fc69a6f0", "title": "QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization"}, {"paperId": "5e11e806d24dd80ecf0f91e7aacedbba8d9fd6fc", "title": "Learning Associative Inference Using Fast Weight Memory"}, {"paperId": "485c3da76c7ac70ba2cde24ad88f0d36b6549cb9", "title": "Summarizing Text on Any Aspects: A Knowledge-Informed Weakly-Supervised Approach"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "a4a5e06c86d594d7a2899d23a3903247d9fdf917", "title": "Appendix 1"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "295065d942abca0711300b2b4c39829551060578", "title": "BERTScore: Evaluating Text Generation with BERT"}, {"paperId": "57eedf785fd9e3ea28b4cd30539cb0fa374f9e74", "title": "Characterizing and Avoiding Negative Transfer"}, {"paperId": "f63e917638553414526a0cc8550de4ad2d83fe7a", "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)"}, {"paperId": "cc8fe65096cc0971aebe45c50c64a173b94a36d5", "title": "Bayesian Query-Focused Summarization"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "04e4ef19431f76d6fa41f22933e8fc444e564dc5", "title": "Recent automatic text summarization techniques: a survey"}, {"paperId": null, "title": "Hyper-networks"}, {"paperId": null, "title": "2022. SQuAL-ITY: Building a Long-Document Summarization Dataset the Hard Way"}, {"paperId": null, "title": "2022. Peft: State-of-the-art parameter-efficient fine-tuning methods"}, {"paperId": null, "title": "2022. Why do you feel this way? summarizing triggers of emotions in social media posts"}, {"paperId": null, "title": "models in our experiments can be trained on at least a single 24GB Nvidia GeForce RTX 3090, except for the large local context size setting for long documents"}, {"paperId": null, "title": "parameters and 32-bit for trainable parameters to conserve memory. Additionally"}, {"paperId": null, "title": "2024b. Hyper-llava: Dynamic visual and language expert tuning for multimodal large language models"}, {"paperId": null, "title": "2023a. Exploring the Limits of Chat-GPT for Query or Aspect-based Text Summarization"}, {"paperId": null, "title": "used in our experiments. A.2 Implementation Details All LLaMA-based models in our experiments"}, {"paperId": null, "title": "2024. HyperMoE: Paying Attention to Unselected Experts in Mixture of Experts via Dynamic Transfer"}, {"paperId": null, "title": "2022. Hyper-decoders: Instance-specific decoders for multi-task NLP"}]}