{"paperId": "2d968cbfbf8d5bd40041dc50b9d490642ce47e98", "abstract": "This study addresses the application of encoder-only Pre-trained Language Models (PLMs) in keyphrase generation (KPG) amidst the broader availability of domain-tailored encoder-only models compared to encoder-decoder models. We investigate three core inquiries: (1) the efficacy of encoder-only PLMs in KPG, (2) optimal architectural decisions for employing encoder-only PLMs in KPG, and (3) a performance comparison between in-domain encoder-only and encoder-decoder PLMs across varied resource settings. Our findings, derived from extensive experimentation in two domains reveal that with encoder-only PLMs, although keyphrase extraction with Conditional Random Fields slightly excels in identifying present keyphrases, the KPG formulation renders a broader spectrum of keyphrase predictions. Additionally, prefix-LM fine-tuning of encoder-only PLMs emerges as a strong and data-efficient strategy for KPG, outperforming general-domain seq2seq PLMs. We also identify a favorable parameter allocation towards model depth rather than width when employing encoder-decoder architectures initialized with encoder-only PLMs. The study sheds light on the potential of utilizing encoder-only PLMs for advancing KPG systems and provides a groundwork for future KPG methods. Our code and pre-trained checkpoints are released at https://github.com/uclanlp/DeepKPG.", "venue": "International Conference on Language Resources and Evaluation", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": null}, "embedding": {"model": "specter_v2", "vector": [0.27027788758277893, 0.6141091585159302, -0.3726952075958252, 0.4941287636756897, -0.40638262033462524, -1.0113054513931274, 0.9932385087013245, 0.08571382611989975, -0.32532089948654175, 0.003651896957308054, 0.8646506667137146, -0.3173471987247467, 0.10373467206954956, 0.07183044403791428, -0.40753933787345886, 0.20918771624565125, -0.7116608023643494, -0.1021885946393013, -0.40575939416885376, -0.4955039322376251, 0.4787062406539917, -0.8605653643608093, -0.5405104160308838, 0.014474544674158096, 0.29136016964912415, 0.323942095041275, 0.43467167019844055, 1.1116843223571777, -0.3207894563674927, 0.31006288528442383, 0.2759469747543335, -0.5952956080436707, 0.300321489572525, -0.04362747445702553, -0.3993401527404785, -0.24536477029323578, 0.18027067184448242, -0.44419604539871216, -0.36480456590652466, 0.5246246457099915, -0.05599690601229668, 0.13194184005260468, 0.4308358132839203, -0.41336461901664734, -0.7134202122688293, 1.4694972038269043, 1.0789616107940674, 0.47201403975486755, 0.07332973182201385, -0.5350987911224365, 1.569210171699524, -1.1895979642868042, 0.30112510919570923, 0.986229419708252, 0.47646352648735046, 0.5963063836097717, 0.08099979162216187, -0.754594087600708, 0.681553840637207, -0.008651027455925941, -0.7828142642974854, -0.29302650690078735, -0.006834057159721851, 0.02719377540051937, 1.7051769495010376, -0.30341437458992004, 0.026236409321427345, 0.2195359766483307, -0.04361188784241676, 1.472400426864624, -0.11932547390460968, -0.8708322048187256, -0.6028869152069092, 0.3331865072250366, -0.1604241579771042, 0.4831198751926422, -0.6746013164520264, 0.3806663453578949, -0.7641296982765198, -0.13306616246700287, 0.5428520441055298, -0.3275907337665558, -0.3393523693084717, 0.5234009027481079, -0.4301363527774811, 0.5978224873542786, -0.0645337924361229, 0.930626392364502, -0.4211387038230896, 0.6517789363861084, 0.2653137743473053, 0.08053841441869736, 0.019869035109877586, 0.9361043572425842, -0.4767777621746063, 0.2626393139362335, -1.1522517204284668, 0.8374384641647339, 0.3227294385433197, 0.7363724112510681, -0.19684500992298126, -0.15066392719745636, -1.0299075841903687, -0.30193427205085754, 0.6420605182647705, -0.33403152227401733, 0.5542165637016296, -0.7153877019882202, -0.03943401947617531, -0.939644992351532, 0.44846802949905396, -0.871516764163971, 0.010057337582111359, -0.0013541452353820205, -0.295332670211792, -1.7994426488876343, -0.6636370420455933, -0.13377167284488678, -0.6054919958114624, 0.9542694091796875, -0.4596947729587555, 0.27797654271125793, 0.25193673372268677, 0.16324535012245178, 0.8620759844779968, 0.6658485531806946, -0.01230104360729456, -0.13518103957176208, 0.8874003887176514, -0.7852984666824341, -0.7507891058921814, -0.7628771066665649, 0.8806434869766235, -0.6088385581970215, 0.1835852563381195, 0.047347113490104675, -1.410112977027893, -0.9549472332000732, -0.7802238464355469, 0.04255164414644241, -0.5671103596687317, 0.8806207180023193, 1.1627769470214844, 0.38613173365592957, -1.1209378242492676, 0.8408088684082031, 0.3481366038322449, -0.007755842059850693, -0.14902769029140472, -0.1286468207836151, 0.3033716082572937, -0.2403232604265213, -1.6140718460083008, -0.05638831853866577, 0.7135087847709656, -1.058760643005371, -0.11572689563035965, -1.1346185207366943, -0.6560978293418884, -0.12417440861463547, 0.45901986956596375, -0.3383348286151886, 1.4659318923950195, 0.0845521092414856, -1.3423210382461548, 0.7806119918823242, -0.15970484912395477, -0.03974748030304909, 0.046094126999378204, -0.48470795154571533, -0.5027698874473572, -0.1500873863697052, 0.0322999581694603, 0.7834306955337524, 0.7432669997215271, 0.05946335569024086, -0.3578391373157501, 0.7898610234260559, -0.07438986003398895, 0.06266196817159653, -0.26743417978286743, 1.1279159784317017, -0.4818534851074219, -0.8992384076118469, 0.08157702535390854, 0.5190982222557068, 0.0721769705414772, -0.502763569355011, -0.5464778542518616, -1.0572925806045532, 0.5998399257659912, -0.6300119757652283, 1.5277431011199951, -0.7171796560287476, -0.7012122273445129, -0.5849294066429138, -0.17207440733909607, -0.0467977374792099, -0.4504455327987671, 1.1993690729141235, -0.7564328908920288, 0.5010461807250977, 0.04315413534641266, -0.7971311807632446, 0.07916894555091858, -0.8403360843658447, -1.1781063079833984, -0.6383944749832153, 0.43012136220932007, 1.1646785736083984, -0.6807160377502441, 0.2725673019886017, -0.1329766809940338, -0.016701214015483856, -0.9323844909667969, 1.0471251010894775, -0.727706253528595, 0.3943118453025818, -0.024962168186903, -0.21669158339500427, -0.02211889997124672, -0.5436070561408997, 0.24520571529865265, -0.5501837134361267, -0.19031645357608795, 0.8264871835708618, -0.6301430463790894, 1.3493797779083252, -0.05018064007163048, 0.10471466928720474, -0.11170703172683716, -0.3559386432170868, 0.262816458940506, 0.5743883848190308, -0.08737924695014954, 0.03762917220592499, -0.10888278484344482, 0.6625156402587891, -0.7409393787384033, 0.6981654763221741, 1.1540064811706543, 0.8091681003570557, -0.39368560910224915, 0.3812667727470398, 0.5438234806060791, -0.24588827788829803, 0.760279655456543, 0.9611612558364868, 0.7307873368263245, 0.43592190742492676, 0.6037828326225281, -0.25281596183776855, 0.632125973701477, -0.5236130356788635, -0.21689191460609436, 0.2714844346046448, 1.0982387065887451, 0.7314476370811462, 0.1359260380268097, -0.5549947619438171, -0.25154590606689453, 0.4216976463794708, 0.7815893888473511, 1.4135017395019531, -0.010112053714692593, -0.9065089821815491, -0.803723931312561, -0.46149542927742004, -0.2729760706424713, 0.1741781234741211, -0.295062392950058, -0.21075443923473358, -0.9294005036354065, -0.827943742275238, 0.7191911339759827, 0.14279381930828094, 0.6413014531135559, -0.7014178037643433, -0.1554156392812729, 0.13619770109653473, -0.20010003447532654, -0.9356484413146973, -1.0174179077148438, 0.25603070855140686, 0.023515256121754646, -0.12523536384105682, -0.558525025844574, -0.2679423987865448, 0.16102200746536255, -0.7175935506820679, 1.0908863544464111, -0.18198654055595398, -0.27126291394233704, 0.300997257232666, -0.05178689584136009, -0.43265479803085327, -1.165236234664917, -0.008452199399471283, 0.2423580139875412, -0.2825802266597748, 0.3219395875930786, 0.42300063371658325, -0.2934386432170868, -0.18312260508537292, -0.23367618024349213, 0.5449946522712708, 0.0879865512251854, -0.011037684045732021, 0.4951570928096771, -0.11435187608003616, -0.07009958475828171, -0.9075685143470764, 1.1606639623641968, 0.3735477030277252, -0.4845147728919983, 0.43286794424057007, -0.6402355432510376, -0.6058012247085571, 0.8855441212654114, -0.5621297359466553, -0.1538160890340805, -0.8764938712120056, 0.34529635310173035, 0.10120366513729095, -0.05713757500052452, 0.2849022150039673, 0.2776355743408203, 0.1625175029039383, 0.21297338604927063, 1.0567079782485962, -0.09455689042806625, -0.3747088611125946, 0.9844467639923096, -0.9312027096748352, 0.7413285970687866, -0.1900959610939026, 0.20077544450759888, -0.4924016296863556, -0.48239076137542725, -0.31284934282302856, -0.17616567015647888, -0.3121851086616516, -0.13385379314422607, -0.1372828334569931, 0.2901118993759155, -0.8010892868041992, -0.644326388835907, 0.09146485477685928, -1.327316403388977, -0.0037171277217566967, 0.2479071468114853, -0.6306575536727905, -0.39964157342910767, -0.6056821346282959, -1.2689154148101807, -0.46725717186927795, -0.9836324453353882, -0.7137569189071655, 0.4748798906803131, 0.18850238621234894, -0.5840438604354858, -0.23641487956047058, 0.09729137271642685, -0.39644384384155273, 0.4343107342720032, -0.6393631100654602, 0.9803013801574707, -0.05173094570636749, -0.3169776499271393, -0.1593148410320282, 0.27770742774009705, 0.5492541790008545, -0.051180511713027954, 0.4193858802318573, -0.395424485206604, -0.01803533174097538, -0.7579732537269592, -0.26829952001571655, 0.15508387982845306, 0.24001897871494293, 0.48712682723999023, -0.1779511570930481, -0.5143179297447205, 0.504551112651825, 1.1720930337905884, -0.5372329354286194, -0.17455101013183594, 0.23593303561210632, 0.6719805002212524, 0.47288766503334045, 0.04223375394940376, 0.8911377191543579, 0.5140751600265503, 0.34077343344688416, -0.20552965998649597, 0.03913874551653862, -0.083393394947052, -1.1642961502075195, 0.7082089185714722, 1.5263949632644653, 0.5287002325057983, -0.1198391318321228, -0.9120181798934937, 0.7533999085426331, -1.1352933645248413, -0.2313103824853897, 0.8076186776161194, 0.5113096833229065, 0.9456526041030884, -0.5192091464996338, -0.10195271670818329, -0.17245224118232727, 0.21435077488422394, 0.16699165105819702, -0.11199257522821426, -0.48826441168785095, 0.04372420161962509, 0.5434249043464661, 0.29988834261894226, 0.13526783883571625, -0.7093717455863953, 1.1535863876342773, 14.712406158447266, 1.0032671689987183, -0.04524734616279602, 0.029695600271224976, 0.4879051744937897, 0.4577537775039673, -0.5105346441268921, -0.011088470928370953, -1.8481463193893433, 0.11114959418773651, 0.8502727150917053, -0.261047899723053, 0.5519444942474365, 0.007898283191025257, -0.1526302844285965, 0.2436433881521225, -0.37369629740715027, 0.8445018529891968, 0.45541688799858093, -1.8629997968673706, 0.5448493957519531, 0.26920613646507263, 0.47107964754104614, 0.06917988508939743, 0.8492709994316101, 0.711776852607727, 0.6228196024894714, -0.4031580090522766, 0.5468940734863281, 0.14268556237220764, 0.6905075311660767, -0.22607438266277313, -0.002368910936638713, 0.8556598424911499, -0.9230831861495972, -0.4036526083946228, -0.6151198744773865, -1.0144343376159668, 0.41158875823020935, 0.10380951315164566, -0.9917668104171753, -0.23516374826431274, -0.18008825182914734, 0.7486320734024048, 0.09236185252666473, 0.09064850211143494, -0.4820544421672821, 0.6879910230636597, -0.16160424053668976, -0.055966880172491074, 0.31841540336608887, 0.36603155732154846, 0.45120418071746826, 0.09523189067840576, 0.415432333946228, 0.23699066042900085, 0.2007266730070114, 0.686461329460144, -0.3600451350212097, 0.20972563326358795, -0.11564723402261734, -0.949508786201477, 0.3178224563598633, 0.9036769270896912, 0.23500557243824005, 0.20921695232391357, -0.1365380436182022, 0.6808125376701355, 0.29645606875419617, 0.04381720721721649, -0.06534291058778763, -0.030143670737743378, 0.3382451832294464, -0.35796916484832764, 0.21774965524673462, 0.3977825343608856, 0.06659039855003357, -0.4257015883922577, -0.9040242433547974, -0.8985826969146729, 0.30789828300476074, -0.5011399984359741, -0.5612980127334595, 0.66131192445755, -0.1545313000679016, -0.47615846991539, -0.4137061536312103, -0.684445321559906, -0.3706987798213959, 0.8145434260368347, -1.1527349948883057, -1.0832481384277344, 0.6179406642913818, -0.42553281784057617, -0.5660759806632996, -0.3923688232898712, 1.3519095182418823, -0.20267443358898163, 0.07320870459079742, 0.4408344626426697, 0.15722636878490448, 0.02009388618171215, 0.006771555170416832, -0.888026773929596, 1.3858428001403809, 0.46124526858329773, 0.2572125196456909, 0.571820855140686, 0.02355806529521942, -0.46232870221138, -0.8157221078872681, 0.1072782352566719, 0.9618849158287048, -0.9255131483078003, -0.4643814265727997, -0.7534116506576538, -0.48439204692840576, -0.04577687010169029, 0.6366053819656372, -0.8441351056098938, 0.17335648834705353, -0.21053409576416016, -0.2229526937007904, 0.4198092818260193, -0.597690224647522, 0.2308182269334793, 0.252189964056015, -0.6771750450134277, -0.11549022048711777, 0.28747090697288513, 0.8376913070678711, -0.906805694103241, -0.537480354309082, -0.07031911611557007, -0.10017212480306625, 0.17139498889446259, 0.9903400540351868, -0.35448527336120605, 0.805582582950592, 0.7653372287750244, -0.3130491375923157, -0.7881160974502563, -0.2311094105243683, -1.5455948114395142, -0.17092865705490112, 0.10114141553640366, 0.5536543726921082, -0.1393570601940155, 0.5330204963684082, 0.6943891644477844, 0.5711621046066284, -0.5609162449836731, 0.0631658285856247, -0.20619332790374756, 0.5798584222793579, -0.32944631576538086, 0.4244168996810913, -0.07635022699832916, -0.14462243020534515, 0.1073826253414154, 0.04600200802087784, 0.3965378999710083, -0.3763944208621979, -0.7017508745193481, 0.6653737425804138, 0.19330112636089325, -0.8021360635757446, -0.4981376826763153, 0.025851963087916374, -1.58473539352417, -0.04078352823853493, -1.1709402799606323, -0.23223991692066193, -0.6893032193183899, -0.3656565845012665, 0.22695279121398926, -0.029253309592604637, 0.024727217853069305, -0.04531076177954674, -0.3099263906478882, -0.01145188882946968, -0.7283534407615662, -0.10252212733030319, 0.510383129119873, 0.9220506548881531, -0.3336805999279022, 0.1988002508878708, -0.172478586435318, -0.48325324058532715, 0.18033543229103088, 0.2579731345176697, -0.24192537367343903, -0.8731848001480103, -0.9035553932189941, 0.7842454314231873, -0.25202473998069763, 0.06813294440507889, -0.4992583096027374, 0.5458947420120239, 0.5825992822647095, -0.21989086270332336, -0.5375068783760071, -0.031813424080610275, -0.3415185809135437, -0.42940807342529297, -0.14576518535614014, -0.5345840454101562, 0.3522484004497528, 0.39181995391845703, -0.567031741142273, -0.2722982168197632, 0.560783863067627, -0.29813069105148315, -1.2787116765975952, -1.042324423789978, 0.5067605376243591, -0.3774506747722626, 0.030650954693555832, -0.322428822517395, -0.24904033541679382, -0.7426770925521851, -0.7620866894721985, 0.304004967212677, 0.18768596649169922, -0.28853458166122437, 1.1388893127441406, 0.4146375060081482, -1.0335793495178223, -0.2544969320297241, 0.532688558101654, -0.046932969242334366, -0.4577149450778961, 0.218237042427063, 0.2653295695781708, -0.22960303723812103, 0.946887195110321, 0.5734134912490845, 0.9258342385292053, -0.9492229223251343, 0.02696254849433899, 0.460488498210907, -0.8850725889205933, -0.1808737814426422, 1.5909868478775024, -0.009108729660511017, -1.1847906112670898, 0.0825623869895935, -0.9814674258232117, -0.45315787196159363, -0.3931047022342682, 0.8613412976264954, -0.3029715418815613, -0.06011982634663582, -0.07564669847488403, -0.29707884788513184, 0.07004697620868683, -0.31438836455345154, -0.5534974932670593, 0.29405030608177185, -0.03074868954718113, -0.4307049810886383, -0.019505921751260757, 0.8201525211334229, -0.5351060628890991, -0.5894713401794434, -0.6300956606864929, -0.17828591167926788, 0.20880752801895142, 0.20188407599925995, -0.813513457775116, 0.14692643284797668, 0.5513880848884583, 0.022400807589292526, 0.08854468911886215, 0.5245094299316406, -0.24937885999679565, 0.8542678356170654, 0.5712297558784485, 0.1509166657924652, -0.8314307332038879, -0.26759073138237, 1.4453630447387695, 1.1782959699630737, -0.889406144618988, 0.25099924206733704, -0.12484067678451538, -0.7095597982406616, 1.077331304550171, -0.02556391805410385, 0.12522131204605103, 1.056601881980896, -0.16946133971214294, -0.006777091417461634, 0.4696407914161682, -1.127044439315796, 0.01161129679530859, 0.9840046167373657, 0.9611462950706482, 0.9208583235740662, 0.3678203523159027, -0.36060214042663574, 1.2257047891616821, -0.4131629168987274, 0.15922331809997559, 0.28398075699806213, 0.6703798770904541, 0.0013008873211219907, -0.5444825291633606, 0.022451123222708702, 0.4635845720767975, -1.0108757019042969, -1.3388601541519165, -0.41747528314590454, 0.4011214077472687, 0.35733309388160706, 0.3082289695739746, 0.379474937915802, -0.45284202694892883, 0.20035018026828766, 0.3307936191558838, 0.49828803539276123, -0.436251699924469, -0.4163862466812134, -0.027042601257562637, -0.5262985229492188, 0.18029622733592987, 0.058370430022478104, -0.3372719883918762, -0.22523638606071472, -0.3676440715789795, 0.20658497512340546, -0.01392563059926033, 0.2747533917427063, 0.831488311290741, 0.6849939823150635, -0.019684946164488792, -0.14864960312843323, -0.37373805046081543, -0.44433316588401794, -0.8956823348999023, -0.05828793719410896, -0.5809388160705566, -0.5291762948036194, 0.18863491714000702, 0.18700817227363586, 0.01485508307814598]}, "authors": [{"authorId": "2107535909", "name": "Di Wu"}, {"authorId": "38123220", "name": "Wasi Uddin Ahmad"}, {"authorId": "2257127887", "name": "Kai-Wei Chang"}], "references": [{"paperId": "23097f2d2deda9b92544fc2294d0c2f7d57cf12a", "title": "Rethinking Model Selection and Decoding for Keyphrase Generation with Pre-trained Sequence-to-Sequence Models"}, {"paperId": "44279244407a64431810f982be6d0c7da4429dd7", "title": "BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining"}, {"paperId": "ba70b0b9e682acebae598d0f38dae2a988702862", "title": "General-to-Specific Transfer Labeling for Domain Adaptable Keyphrase Generation"}, {"paperId": "1c62647bb8971105c77c1d642991cb1b92a52214", "title": "Retrieval-Augmented Multilingual Keyphrase Generation with Retriever-Generator Iterative Training"}, {"paperId": "5476911896491f32ca123e7030e9bae1116d8de2", "title": "BatteryBERT: A Pretrained Language Model for Battery Database Enhancement"}, {"paperId": "1e76a2298cc43d3cc6621a978731473d4f059852", "title": "Quantifying the advantage of domain-specific pre-training on named entity recognition tasks in materials science"}, {"paperId": "a761e7e9c731ccc98ac1ba60ead15713b077514a", "title": "Representation Learning for Resource-Constrained Keyphrase Generation"}, {"paperId": "699371949bedcdd80cac0fd78b4b59835e5eb594", "title": "Learning Rich Representation of Keyphrases from Text"}, {"paperId": "51819d708e00c0fe7ca3e8befc4f8665ac12ad0e", "title": "Importance Estimation from Multiple Perspectives for Keyphrase Extraction"}, {"paperId": "b146be9e80c66a6e062a1525693311fac65ae19e", "title": "MatSciBERT: A materials domain language model for text mining and information extraction"}, {"paperId": "f9cb7e5fda46c03a1c16eb6e0890d2e408ef8225", "title": "Unsupervised Keyphrase Extraction by Jointly Modeling Local and Global Context"}, {"paperId": "4a398a18825396a2c55003f137cc363278f093cf", "title": "DEGREE: A Data-Efficient Generation-Based Event Extraction Model"}, {"paperId": "73c8cee29fd57097288a6919116b5c8a448f3030", "title": "UniKeyphrase: A Unified Extraction and Generation Framework for Keyphrase Prediction"}, {"paperId": "e08c6f15565c9f70e5e3375e293d9a5cfe888e74", "title": "One2Set: Generating Diverse Keyphrases as a Set"}, {"paperId": "c1c9312025ed7388093ad50a37cf601bdbc5d932", "title": "Experiments with Contextualized Word Embeddings for Keyphrase Extraction"}, {"paperId": "b3e25ca21cc1da92728da3bfba7217343ea672b7", "title": "Keyphrase Generation with Fine-Grained Evaluation-Guided Reinforcement Learning"}, {"paperId": "6e907e0eaaf7fd45a75331efa4b404137207e178", "title": "Redefining Absent Keyphrases and their Effect on Retrieval Effectiveness"}, {"paperId": "3e8f037d1b2c893f4df37deda1da3dcc577a8bac", "title": "Non-Autoregressive Text Generation with Pre-trained Language Models"}, {"paperId": "4a1c615e94b1bc3900041412a8413a8c46ffa951", "title": "Reinforced Keyphrase Generation with BERT-based Sentence Scorer"}, {"paperId": "68b91348a53171887b64d656d5a72af242c252c3", "title": "A Preliminary Exploration of GANs for Keyphrase Generation"}, {"paperId": "9927a15ddf5313d97c98f0111fd191caf507ce72", "title": "HateBERT: Retraining BERT for Abusive Language Detection in English"}, {"paperId": "9ef33af1b2ebda2f2edd6c1394f314d7ac2f00f2", "title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification"}, {"paperId": "95ce6f77e26b496ffb705a0a3b54f2fb7a6d2452", "title": "ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction"}, {"paperId": "6d6595766a35f12a6ad671d05634b5e2159d4f3e", "title": "Bio-Megatron: Larger Biomedical Domain Language Model"}, {"paperId": "166d2087d68b353489447af3db128e9565012bcb", "title": "An Empirical Study on Neural Keyphrase Generation"}, {"paperId": "876d28b9aafc59becc64e4e95758d1e1f273444f", "title": "Select, Extract and Generate: Neural Keyphrase Generation with Layer-wise Coverage Attention"}, {"paperId": "0077fd6a31cf638a316d35d50cb5e7d26c63dfc6", "title": "Keyphrase Generation for Scientific Document Retrieval"}, {"paperId": "df0498605d5131098237e37914b402b67fea3936", "title": "FinBERT: A Pre-trained Financial Language Representation Model for Financial Text Mining"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "72cdd6ebe0221fb568ef20534f44ba5b35190a56", "title": "BERTweet: A pre-trained language model for English Tweets"}, {"paperId": "5625ba43de09cd162fcd0f2f9435fa26497c35fc", "title": "INCORPORATING"}, {"paperId": "ebeed3d81649ab67e6220d6db0c2c361cbc20784", "title": "Privacy at Scale: Introducing the PrivaSeer Corpus of Web Privacy Policies"}, {"paperId": "e816f788767eec6a8ef0ea9eddd0e902435d4271", "title": "Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks"}, {"paperId": "2927f634000be48d3ac93a392dff13595de6de59", "title": "Keyphrase Prediction With Pre-trained Language Model"}, {"paperId": "ba46ece6feba34c408d081a8dce66f0ecf4b7a60", "title": "Exclusive Hierarchical Decoding for Deep Keyphrase Generation"}, {"paperId": "f64e1d6bc13aae99aab5449fc9ae742a9ba7761e", "title": "UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training"}, {"paperId": "f496dca10078a5a12b71da6524014122b0039dcf", "title": "SIFRank: A New Baseline for Unsupervised Keyphrase Extraction Based on Pre-Trained Language Model"}, {"paperId": "395de0bd3837fdf4b4b5e5f04835bcc69c279481", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "b3ea2d9c8e5ea3b87ace121f0bece71565abc187", "title": "Quantifying the Carbon Emissions of Machine Learning"}, {"paperId": "4e3c7891b643acb0849983eb506ae70bf126bc00", "title": "Keyphrase Extraction from Scholarly Articles as Sequence Labeling using Contextualized Embeddings"}, {"paperId": "7402b604f14b8b91c53ed6eed04af92c59636c97", "title": "Well-Read Students Learn Better: On the Importance of Pre-training Compact Models"}, {"paperId": "eb606d9ce65139754232cee62f6ab77f3e0c665f", "title": "Leveraging Pre-trained Checkpoints for Sequence Generation Tasks"}, {"paperId": "3f03c4c337ca4103e7b01657e1065739d00ddcd1", "title": "Incorporating Linguistic Constraints into Keyphrase Generation"}, {"paperId": "272730c72d6c40cf9cd6ca82664fcd273e032192", "title": "Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards"}, {"paperId": "ad7129af0644dbcafa9aa2f111cb76526ea444a1", "title": "Defending Against Neural Fake News"}, {"paperId": "1c71771c701aadfd72c5866170a9f5d71464bb88", "title": "Unified Language Model Pre-training for Natural Language Understanding and Generation"}, {"paperId": "b3c2c9f53ab130f3eb76eaaab3afa481c5a405eb", "title": "ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission"}, {"paperId": "c9573b704088d1d026bf7869030fc4a9d320ab55", "title": "An Integrated Approach for Keyphrase Generation via Exploring the Power of Retrieval and Extraction"}, {"paperId": "2a567ebd78939d0861d788f0fedff8d40ae62bf2", "title": "Publicly Available Clinical BERT Embeddings"}, {"paperId": "156d217b0a911af97fa1b5a71dc909ccef7a8028", "title": "SciBERT: A Pretrained Language Model for Scientific Text"}, {"paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"}, {"paperId": "42919768252f709b789d3a65063bc18db4fb9718", "title": "One Size Does Not Fit All: Generating and Evaluating Variable Number of Keyphrases"}, {"paperId": "19957eb68dff3e6122f2d0802917dea7006dd48b", "title": "Title-Guided Encoding for Keyphrase Generation"}, {"paperId": "6052889f7b62105bca54c5f1a58fd3885d2844b1", "title": "Keyphrase Generation with Correlation Constraints"}, {"paperId": "95ad7d6ef8d22d8d67b5c9e2dc5c176b65a2d271", "title": "Semi-Supervised Learning for Neural Keyphrase Generation"}, {"paperId": "ddcdba3199fd7b298f93dd2d2f1b17d5a3b01f0c", "title": "YAKE! Collection-Independent Automatic Keyword Extractor"}, {"paperId": "05c728cb38f06dccd587beb9b0399157eebfbce8", "title": "Unsupervised Keyphrase Extraction with Multipartite Graphs"}, {"paperId": "ed1e3ba44075329a81a208115066214eff4af8ff", "title": "Simple Unsupervised Keyphrase Extraction using Sentence Embeddings"}, {"paperId": "05e459fad83c8a555749b8dd1949bdbfa9bc16f8", "title": "QALink: Enriching Text Documents with Relevant Q&A Site Contents"}, {"paperId": "b73191adcc938cfcf20ce0327cf5cd1f539f7f81", "title": "Scientific Information Extraction with Semi-supervised Neural Tagging"}, {"paperId": "b0d555a9ea67285fccd2ef8d887907bcc811f67a", "title": "PositionRank: An Unsupervised Approach to Keyphrase Extraction from Scholarly Documents"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "78b47ef088d537702a2e13297d8b58ee55a3a5cd", "title": "Deep Keyphrase Generation"}, {"paperId": "668db48c6a79826456341680ee1175dfc4cced71", "title": "Get To The Point: Summarization with Pointer-Generator Networks"}, {"paperId": "cbcd6ce6b44f729acaf7b0e345c77901177c8ac7", "title": "pke: an open source python-based keyphrase extraction toolkit"}, {"paperId": "2bde9b4149d416614b2866343bb9102a63bd6ae9", "title": "Keyphrase Extraction Using Deep Recurrent Neural Networks on Twitter"}, {"paperId": "9f82d2f5b6222ee7a746691b95bac566ae35512e", "title": "TopicRank: Graph-Based Topic Ranking for Keyphrase Extraction"}, {"paperId": "a4ec724b07f0cd111a8150c8dd65b6384a82fa02", "title": "Applying Graph-based Keyword Extraction to Document Retrieval"}, {"paperId": "d9f430f4fb57236b96b6afe6765791c9cc3aab5e", "title": "Opinion Expression Mining by Exploiting Keyphrase Extraction"}, {"paperId": "f40c8b0124a8081a85a37dce556bedccb5533bf8", "title": "Pattern based keyword extraction for contextual advertising"}, {"paperId": "03589e1917debe6df148cac8963fd008e4140237", "title": "SemEval-2010 Task 5 : Automatic Keyphrase Extraction from Scientific Articles"}, {"paperId": "515da9d3e1e0e6ed4326dc092d02665dc4b53509", "title": "KP-Miner: Participation in SemEval-2"}, {"paperId": "48b5041a24cbf3048c97e85c4fd7c0214da942b5", "title": "CollabRank: Towards a Collaborative Approach to Single-Document Keyphrase Extraction"}, {"paperId": "8a99634e0b418ee61c9bd81f61d334b80486dc53", "title": "Single Document Keyphrase Extraction Using Neighborhood Knowledge"}, {"paperId": "c43895754da99787f95a4be9f68472d747da5ca5", "title": "Keyword extraction for contextual advertisement"}, {"paperId": "1cf65a8c9e9ac8bd1db487004185ad0e15b9b9dd", "title": "Keyphrase Extraction in Scientific Publications"}, {"paperId": "4a775468c42ae34072913fc3e67cd64b2377ec31", "title": "A Study on Automatically Extracted Keywords in Text Categorization"}, {"paperId": "c0c17e89c6eac1d9b1c90c22937ecb47a792fedd", "title": "Keyphrase extraction-based query expansion in digital libraries"}, {"paperId": "9b4876f7313b111074e79a01f570e6e9e02c0dce", "title": "Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis"}, {"paperId": "92527edf0fa6fab3c8c63a0ade08b0cc51359d0a", "title": "CorePhrase: Keyphrase Extraction for Document Clustering"}, {"paperId": "7b95d389bc6affe6a127d53b04bcfd68138f1a1a", "title": "TextRank: Bringing Order into Text"}, {"paperId": "771ca13f78a6cfda9ed99004a386e9e7e187bd34", "title": "Improved Automatic Keyword Extraction Given More Linguistic Knowledge"}, {"paperId": "f4ba954b0412773d047dc41231c733de0c1f4926", "title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"}, {"paperId": "32448280ef3d03af2fb639bbe1b3709c4bb6c78a", "title": "Phrasier: a system for interactive document retrieval using keyphrases"}, {"paperId": "28601432c08850d93c4e2cf546a62c486f9a2c4f", "title": "Language learning"}, {"paperId": "58ece16a50564b6b8793dabe21bd794486630d1d", "title": "Belgium"}, {"paperId": "722ab6384537740fbfe30d10bdd6fa974b553d51", "title": "Keyphrase Generation via Soft and Hard Semantic Corrections"}, {"paperId": null, "title": "Document-level entity-based extraction"}, {"paperId": "5c5751d45e298cea054f32b392c12c61027d2fe7", "title": "S2ORC: The Semantic Scholar Open Research Corpus"}, {"paperId": null, "title": "LEGAL-BERT: The muppets straight out of law school"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "KPTimes: A large-scale dataset"}, {"paperId": "2c56421ff3c2a69894d28b09a656b7157df8eb83", "title": "Large Dataset for Keyphrases Extraction"}, {"paperId": "a011209e0628633b60223311797bc29c3a6902f8", "title": "World Wide Web site summarization"}, {"paperId": null, "title": "An algorithm for suffix strip-ping"}, {"paperId": null, "title": "2022. Domain-specific language model pretraining for biomedical natural language processing"}, {"paperId": null, "title": "extraction from English job postings"}, {"paperId": null, "title": "What is the best parameter allocation strategy for using encoder-decoder PLMs to balance the performance and computational cost?"}]}