{"paperId": "82460f7995f66f3f035f34ecbd2c82b024282529", "abstract": "While many contemporary large language models (LLMs) can process lengthy input, they still struggle to fully utilize information within the long context, known as the lost-in-the-middle challenge. We hypothesize that it stems from insufficient explicit supervision during the long-context training, which fails to emphasize that any position in a long context can hold crucial information. Based on this intuition, our study presents information-intensive (IN2) training, a purely data-driven solution to overcome lost-in-the-middle. Specifically, IN2 training leverages a synthesized long-context question-answer dataset, where the answer requires (1) fine-grained information awareness on a short segment (~128 tokens) within a synthesized long context (4K-32K tokens), and (2) the integration and reasoning of information from two or more short segments. Through applying this information-intensive training on Mistral-7B, we present FILM-7B (FILl-in-the-Middle). To thoroughly assess the ability of FILM-7B for utilizing long contexts, we design three probing tasks that encompass various context styles (document, code, and structured-data context) and information retrieval patterns (forward, backward, and bi-directional retrieval). The probing results demonstrate that FILM-7B can robustly retrieve information from different positions in its 32K context window. Beyond these probing tasks, FILM-7B significantly improves the performance on real-world long-context tasks (e.g., 23.5->26.9 F1 score on NarrativeQA), while maintaining a comparable performance on short-context tasks (e.g., 59.3->59.2 accuracy on MMLU). Github Link: https://github.com/microsoft/FILM.", "venue": "arXiv.org", "year": 2024, "citationCount": 9, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This study presents information-intensive (IN2) training, a purely data-driven solution to overcome lost-in-the-middle challenge and presents FILM-7B (FILl-in-the-Middle), a purely data-driven solution to overcome lost-in-the-middle challenge."}, "embedding": {"model": "specter_v2", "vector": [0.023402925580739975, 0.5573863387107849, -0.6850336194038391, -0.3527645170688629, -0.37052538990974426, -0.5173342227935791, 0.42856377363204956, -0.09020553529262543, -0.42901280522346497, -0.05754014477133751, 0.5733347535133362, -0.493069052696228, 0.5404993295669556, 0.5024440884590149, -0.008943921886384487, 0.5141119956970215, -0.8618831038475037, 0.23897743225097656, -0.11978556215763092, -0.42311474680900574, 0.0038463652599602938, -0.7438485026359558, -0.3641909658908844, 0.7296579480171204, 0.5909631848335266, 0.03409889340400696, 0.4141780138015747, 1.0420981645584106, -0.5096930265426636, 0.6200564503669739, 0.19418956339359283, -0.49538782238960266, -0.16232752799987793, 0.09315815567970276, -0.6217501759529114, -0.12987519800662994, 0.4465012848377228, -0.6775045394897461, -0.21353109180927277, 0.024130621924996376, -0.1291661113500595, 0.06442207843065262, 0.48253998160362244, -0.2997295558452606, -0.5457665324211121, 0.9757909774780273, 0.6796205043792725, 0.5989107489585876, 0.05832899361848831, -0.6748021245002747, 1.747186303138733, -1.8086066246032715, 0.5904439091682434, 1.322414517402649, 0.31810927391052246, 0.6954566240310669, -0.2045910507440567, -0.26460129022598267, 0.8064032196998596, 0.18151763081550598, -0.7811110615730286, -0.4946541488170624, -0.3097597658634186, -0.09538932144641876, 1.932397484779358, -0.3483227789402008, -0.08874081820249557, 0.6705071926116943, -0.293332576751709, 1.7737936973571777, -0.4238896667957306, -0.8776944875717163, -0.4780294895172119, 0.10029194504022598, 0.35082030296325684, 0.6221518516540527, -0.5251157283782959, 0.18770258128643036, -0.6901294589042664, 0.21346896886825562, 0.49185627698898315, 0.014507729560136795, -0.19788016378879547, 0.14889942109584808, -0.4543505907058716, 0.5501662492752075, 0.1500682830810547, 1.1242913007736206, 0.22623710334300995, 0.30559042096138, 0.11345740407705307, 0.5151256918907166, 0.03376617655158043, 0.4464293122291565, -0.47795137763023376, 0.286016583442688, -1.2661291360855103, 0.4787614345550537, 0.12807117402553558, 0.7610437273979187, -0.28842276334762573, -0.32297956943511963, -0.845718264579773, 0.19738109409809113, 1.117157220840454, -0.11923959106206894, 0.352455198764801, -0.9028844833374023, 0.6093857288360596, -0.42461705207824707, 0.4050886631011963, -0.21349172294139862, -0.4364384710788727, -0.3698916435241699, -0.24053220450878143, -1.4904181957244873, -0.09372204542160034, -0.23276373744010925, -0.25384819507598877, 0.8575074076652527, -0.09063638746738434, 0.029471028596162796, 0.4588586390018463, 0.7581684589385986, 1.0060747861862183, 0.8543941378593445, 0.06407259404659271, 0.23055040836334229, 0.6656218767166138, -0.9649620652198792, -0.8151987791061401, -1.4333298206329346, 1.2842103242874146, -0.3635494112968445, 0.6082329750061035, -0.3737361431121826, -1.3087199926376343, -1.0858805179595947, -1.1981223821640015, -0.4340577721595764, -0.5311606526374817, 0.6154402494430542, 0.8782589435577393, 0.3191520571708679, -0.9364331960678101, 0.6810994148254395, 0.16835066676139832, -0.05797308310866356, -0.18605996668338776, -0.2218804657459259, 0.052090149372816086, -1.1657793521881104, -1.493140459060669, 0.21898016333580017, -0.04559045657515526, -0.3919696807861328, -0.24152030050754547, -0.612032949924469, -1.3899657726287842, -0.26605960726737976, 0.6210460662841797, -0.42010006308555603, 1.4676125049591064, 0.06983597576618195, -0.914946436882019, 0.5993869304656982, -0.5317969918251038, 0.4920040965080261, 0.1204335168004036, -0.26797908544540405, -0.5969308614730835, -0.271984338760376, -0.10577383637428284, 0.6259347200393677, 0.06098662316799164, -0.11054818332195282, -0.31842905282974243, 0.06012219935655594, -0.07055243849754333, 0.04687720909714699, 0.16157148778438568, 0.7743790745735168, -0.4710809588432312, -0.20755618810653687, 0.41486889123916626, 0.7912793159484863, 0.21401722729206085, -0.1956440955400467, -0.23748593032360077, -1.1439566612243652, 0.6054279208183289, -0.04861025512218475, 1.3795363903045654, -0.8351343274116516, -0.7286888957023621, -0.7016103267669678, -0.33689412474632263, -0.09725216031074524, -0.8574570417404175, 1.0345375537872314, -0.003865578444674611, 0.6022886037826538, -0.2970646917819977, -1.5265973806381226, 0.12786279618740082, -0.14936551451683044, -0.5872783064842224, -0.5804921388626099, 0.4057726562023163, 1.1794906854629517, -0.7899887561798096, -0.23324911296367645, -0.5095108151435852, 0.10700985789299011, -0.9342580437660217, 1.2564796209335327, -0.7730626463890076, 0.32104969024658203, -0.047931768000125885, -0.023700976744294167, -0.08459065854549408, -0.27510663866996765, 0.3441973924636841, -0.19184550642967224, -0.20567163825035095, 0.6055408120155334, -0.432263046503067, 1.736778974533081, -0.5061320066452026, 0.45935919880867004, 0.009894788265228271, -0.2600136995315552, -0.3395008444786072, 0.7657051682472229, -0.37534433603286743, -0.24914352595806122, -0.14410527050495148, 0.540543258190155, -0.5672934055328369, -0.267443984746933, 1.0805598497390747, 0.6704615354537964, -0.4566851556301117, 0.35131874680519104, 0.3502686619758606, -0.32911717891693115, 0.43813660740852356, 0.5765690803527832, 0.7513052225112915, 0.6090136766433716, 0.046488575637340546, 0.09260302037000656, 0.4106627404689789, -0.6305009722709656, -0.04703805595636368, 0.3566295802593231, 0.690136194229126, 0.9133004546165466, 0.4772954285144806, -0.43639254570007324, -0.25186967849731445, 0.26953673362731934, 0.535939633846283, 1.7571965456008911, -0.09194202721118927, -0.2957776188850403, -0.8007178902626038, -0.42292454838752747, -0.28594714403152466, 0.4080488681793213, -0.49713075160980225, 0.025660673156380653, -0.605870246887207, -0.43157944083213806, 0.7611366510391235, 0.43646910786628723, 0.7866208553314209, -0.5609533190727234, -0.10671425610780716, -0.11892774701118469, -0.022365685552358627, -0.9912381172180176, -0.6382111310958862, 0.03319147974252701, -0.662031352519989, -0.31006214022636414, 0.1236119419336319, -0.5924152135848999, 0.00047010203707031906, -0.5730025768280029, 1.2737858295440674, -0.11021415144205093, -0.0680156797170639, 0.18018750846385956, 0.23181860148906708, -0.15462493896484375, -0.6206077933311462, 0.3333362340927124, -0.4604024589061737, -0.5138705968856812, 0.26097118854522705, 0.7791954874992371, -0.2007601410150528, 0.3699212670326233, -0.5423195958137512, 0.5364067554473877, 0.3448702394962311, -0.08244316279888153, 0.5744448304176331, -0.3834962844848633, 0.3758013844490051, -1.499030590057373, 0.7643488049507141, -0.07712996006011963, -0.11405210196971893, 0.5954481363296509, -0.5824567079544067, -0.5075955986976624, 0.4981662929058075, -0.6093763709068298, -0.2321026474237442, -1.1861947774887085, 0.33355775475502014, 0.14664368331432343, -0.028813166543841362, 0.5352898240089417, -0.1500391662120819, 0.7919543385505676, 0.14168867468833923, 0.008969827555119991, 0.0520266629755497, -0.35437875986099243, 0.81036376953125, -0.6756458878517151, 0.3819707930088043, -0.008105400018393993, -0.1571146845817566, -0.276535302400589, -0.30986133217811584, -0.41274407505989075, -0.6953026056289673, -0.6106771230697632, -0.2866671085357666, -0.15551280975341797, 0.2620868980884552, -0.46621882915496826, -0.5891669392585754, -0.21761305630207062, -1.1493022441864014, -0.5147007703781128, 0.054049402475357056, -0.4810193181037903, 0.10523246973752975, -1.2184436321258545, -1.4085361957550049, -0.3478754758834839, -0.27503249049186707, -0.9595114588737488, 0.6405109763145447, -0.2171231359243393, -0.475772887468338, -0.8784167766571045, -0.02909955568611622, -0.016139119863510132, 0.6906251907348633, -0.5887919664382935, 1.0859483480453491, 0.1505875289440155, -0.1549132913351059, -0.4788089692592621, 0.15070903301239014, 0.33653247356414795, -0.2977690100669861, 0.21214714646339417, -0.8459923267364502, 0.17342594265937805, 0.11946725100278854, -0.4422243535518646, 0.03395875543355942, 0.15596644580364227, 0.20874761044979095, -0.019744908437132835, -0.43595969676971436, 0.23159033060073853, 1.4734774827957153, -0.7316741347312927, -0.09519271552562714, -0.31553494930267334, 1.0000032186508179, 0.8166514039039612, 0.13768772780895233, 0.2832334339618683, 0.48775994777679443, 0.07766371220350266, 0.21583911776542664, 0.20413687825202942, 0.06240662559866905, -0.7455494999885559, 0.7230659127235413, 1.5241836309432983, 0.5550721287727356, -0.1551199108362198, -0.9650358557701111, 0.798729658126831, -1.2424594163894653, -0.24253597855567932, 0.6217045783996582, 0.6237416863441467, 0.7906249165534973, -0.456986665725708, -0.5874807834625244, -0.40049803256988525, 0.1158219650387764, 0.5146012902259827, -0.4504442512989044, -0.6335216164588928, -0.10178978741168976, 0.1450844556093216, -0.2895863652229309, 0.8804184794425964, -0.21004636585712433, 0.6725165247917175, 14.55156421661377, 0.8517516255378723, 0.3325864374637604, 0.5317701101303101, 0.876673698425293, 0.10145610570907593, -0.8463086485862732, -0.07180110365152359, -1.5854156017303467, -0.38947615027427673, 1.313092589378357, 0.5665168762207031, 0.3206850588321686, -0.011813840828835964, 0.13279415667057037, -0.06968916952610016, -1.0992579460144043, 0.4460534453392029, 0.5895319581031799, -1.278361439704895, 0.4610118865966797, 0.18088962137699127, 0.17780062556266785, 0.030207695439457893, 0.898253858089447, 0.9705548286437988, 0.09268162399530411, -0.7430106997489929, 0.6768501996994019, 0.16922445595264435, 1.2634263038635254, -0.06479759514331818, 0.5954743027687073, 0.7753027081489563, -0.677438497543335, -0.443403959274292, -0.6166075468063354, -1.0668312311172485, 0.14456845819950104, -0.19718483090400696, -0.8287476897239685, -0.5410078763961792, -0.5894094705581665, 0.4962586760520935, -0.21548138558864594, -0.043376777321100235, -0.3286885917186737, 0.7492235898971558, 0.4163341522216797, -0.07297579199075699, 0.511491060256958, 0.4128984808921814, 0.28423255681991577, -0.07659798115491867, 0.00011364884267095476, 0.12481962889432907, 0.08404182642698288, 0.5233062505722046, -0.6379477977752686, 0.1952040046453476, -0.35664018988609314, -0.1518389731645584, -0.02765701338648796, 0.4745699465274811, 0.6332264542579651, 0.3421277105808258, -0.6777701377868652, 0.38698112964630127, 0.816329300403595, 0.19057169556617737, 0.30507993698120117, 0.2357521951198578, 0.2223915308713913, -0.07481908053159714, -0.03755287081003189, 0.30183619260787964, -0.14559721946716309, -0.503754734992981, -0.335260808467865, -0.2631778419017792, 0.31404054164886475, -0.7899980545043945, -0.6639965772628784, 0.6909471154212952, -0.28802770376205444, -0.7170702815055847, -0.3101377487182617, -0.7295807003974915, -0.04059731587767601, 0.3914570212364197, -1.6058260202407837, -0.9493650197982788, 0.49438202381134033, -0.24823549389839172, 0.027843741700053215, 0.29322025179862976, 1.4497953653335571, 0.2558169364929199, -0.5671242475509644, 0.11123601347208023, 0.32503920793533325, 0.2951704263687134, 0.22181212902069092, -1.1477172374725342, 0.808475136756897, 0.29556891322135925, -0.1425599753856659, 0.4215155243873596, -0.1394970417022705, 0.13013899326324463, -0.7899771928787231, -0.0628342404961586, 1.0551471710205078, -1.2436437606811523, -0.68730628490448, -0.770802915096283, -0.8998194336891174, 0.17508797347545624, 0.7403703331947327, -0.22131231427192688, 0.9076846241950989, 0.10637975484132767, -0.38248971104621887, -0.16641151905059814, -0.8450528383255005, 0.17345862090587616, 0.5823058485984802, -0.6820728778839111, -0.5234933495521545, -0.028967205435037613, 0.8410758376121521, -0.9071172475814819, -0.4910602867603302, -0.2110133320093155, 0.16215863823890686, -0.1367999017238617, 0.5880710482597351, -0.48222002387046814, 0.9388603568077087, 0.9697297215461731, -0.517037570476532, -0.7082275152206421, 0.30282506346702576, -0.8345025777816772, -0.08727593719959259, 0.36290979385375977, 1.0139652490615845, -0.010003733448684216, 0.162180557847023, 1.1276546716690063, 0.31579867005348206, -1.0992259979248047, -0.38758179545402527, 0.011180159635841846, 0.4024384915828705, -0.48990246653556824, 0.4159747064113617, -0.05276912450790405, 0.06293043494224548, 0.4321155548095703, 0.8542062044143677, 0.6288679242134094, -0.5131670236587524, -0.37867438793182373, 0.2791259288787842, 0.06010139733552933, -0.18639974296092987, -0.2177293449640274, -0.10411433130502701, -1.669620394706726, -0.2070818394422531, -0.8777540326118469, -0.04499059543013573, -1.1241044998168945, -0.6598150134086609, -0.03762265294790268, -0.13476459681987762, -0.3176494240760803, 0.058507706969976425, -0.4825093746185303, -0.6056870222091675, -0.6182082891464233, -0.5936551094055176, 0.5585296154022217, 1.147331953048706, -0.42033272981643677, 0.38135650753974915, 0.031155500560998917, -0.13630376756191254, -0.041042111814022064, 0.2106119990348816, 0.04950356483459473, -1.173433542251587, -1.7335786819458008, 0.71451336145401, 0.3296017348766327, -0.4340658187866211, -0.5194646120071411, 0.43013060092926025, 0.37378501892089844, -0.06091584265232086, -0.31236720085144043, 0.3197524845600128, -0.799611508846283, -0.8692848682403564, -0.19169141352176666, -0.9364774227142334, 0.3116946816444397, 0.2416369765996933, -0.8941044211387634, -0.5508186221122742, 0.1615568846464157, -0.3887968957424164, -1.1348904371261597, -0.8134275078773499, 0.32429200410842896, -0.6103993058204651, 0.3267596662044525, -0.6514846682548523, -0.10542801767587662, -1.0334632396697998, -0.5024012923240662, -0.02443564124405384, 0.5887343287467957, -0.05032293125987053, 0.7995104193687439, 0.6275673508644104, -0.9591196179389954, -0.14949831366539001, 0.2160995453596115, 0.02450632117688656, 0.678523063659668, 0.625486433506012, 0.028373070061206818, -0.4145044684410095, 0.5173452496528625, 0.6200902462005615, 0.23333945870399475, -0.7666535973548889, 0.017819639295339584, 0.7232189774513245, -0.7553732395172119, 0.09478196501731873, 1.3486151695251465, -0.4262751340866089, -1.0871623754501343, 0.2144029438495636, -1.5083431005477905, -0.7891329526901245, -0.39954400062561035, 0.845058262348175, -0.06029968336224556, -0.014144782908260822, -0.09978906810283661, -0.3669764995574951, 0.29315242171287537, -0.06442410498857498, -0.8411757946014404, 0.512532651424408, -0.5285342335700989, -0.27258506417274475, 0.9794294238090515, 1.0845052003860474, -0.32604509592056274, -0.8725647926330566, -0.6536431908607483, -0.16342777013778687, 0.11336982250213623, 0.12321866303682327, -0.7853790521621704, -0.07667345553636551, 1.0411605834960938, 0.10557741671800613, 0.3212187588214874, 0.014773242175579071, -0.17843842506408691, 0.6231395602226257, 0.7475089430809021, -0.15656818449497223, -0.5250017642974854, -0.49743497371673584, 1.2444943189620972, 1.3265100717544556, -1.2015976905822754, 0.1876329630613327, 0.06829778105020523, -0.7823671102523804, 0.8073360919952393, 0.519410252571106, 0.2599729895591736, 0.8665564656257629, -0.3863387405872345, 0.42383459210395813, 0.03353500738739967, -1.1500883102416992, 0.09896358102560043, 0.9335542917251587, 0.9129465222358704, 1.0120726823806763, 0.2324269711971283, 0.18706759810447693, 1.2254208326339722, 0.02688339166343212, -0.17055347561836243, 0.49088478088378906, 0.6363475322723389, -0.03755621239542961, -0.3286552429199219, 0.2576036751270294, 0.12750045955181122, -0.6998828053474426, -0.6366681456565857, -0.023174792528152466, 0.5430587530136108, 0.36291220784187317, 0.9082998037338257, 0.6358712315559387, 0.3574792742729187, 0.47005006670951843, 0.4999764859676361, 0.46255815029144287, -0.8484978079795837, -0.3380454182624817, -0.30525311827659607, -0.5693696141242981, -0.13971662521362305, -0.10160573571920395, -0.45726096630096436, -0.4390687644481659, 0.03175126761198044, 0.3872081935405731, 0.13181737065315247, 0.40285977721214294, 1.2276595830917358, 0.5834124088287354, 0.23848111927509308, -0.204929381608963, -0.09888996183872223, -0.27425506711006165, -1.23614501953125, 0.03581782802939415, -0.43775874376296997, 0.0025842678733170033, 0.13357508182525635, -0.12010423839092255, -0.2894105911254883]}, "authors": [{"authorId": "2119217081", "name": "Shengnan An"}, {"authorId": "2264290103", "name": "Zexiong Ma"}, {"authorId": "2277149729", "name": "Zeqi Lin"}, {"authorId": "2263567225", "name": "Nanning Zheng"}, {"authorId": "153249455", "name": "Jian-Guang Lou"}], "references": [{"paperId": "7b2470f0f53fcd79b82ed6a0e6062f39b07c27d6", "title": "Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs"}, {"paperId": "d8b51d518f2dd62943762ceaa8961d3b1bfbcc1a", "title": "RULER: What's the Real Context Size of Your Long-Context Language Models?"}, {"paperId": "75b2ae5ee35611ecfbd3dc2c3d0799cfb4fd98e4", "title": "InternLM2 Technical Report"}, {"paperId": "c0b454e0a6aa51ff3ba56778787d0c43932ef6ba", "title": "Yi: Open Foundation Models by 01.AI"}, {"paperId": "82f041ed71f8ef1cf462fa03a7e732e440259bd7", "title": "LongWanjuan: Towards Systematic Measurement for Long Text Quality"}, {"paperId": "f05e84702562cb693dd68d3d1c88072519a7bd71", "title": "\u221eBench: Extending Long Context Evaluation Beyond 100K Tokens"}, {"paperId": "c9603ec967879c24973b5bd48861df2e5555932e", "title": "LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens"}, {"paperId": "ec9203f6c25a353325dd23ed38e5036b79d9e79b", "title": "LongAlign: A Recipe for Long Context Alignment of Large Language Models"}, {"paperId": "0484f05b6b3c11a9344cb623649ae867f172046f", "title": "LooGLE: Can Long-Context Language Models Understand Long Contexts?"}, {"paperId": "9015c9813b6ef8f05040a7b1340909c57d600e38", "title": "S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Model"}, {"paperId": "d395c771f6537259610497ba218cce5b9bfc2c50", "title": "In-Context Pretraining: Language Modeling Beyond Document Boundaries"}, {"paperId": "db633c6b1c286c0386f0078d8a2e6224e03a6227", "title": "Mistral 7B"}, {"paperId": "539fadfb615ef84c240f4741061c44eeda540091", "title": "Scaling Laws of RoPE-based Extrapolation"}, {"paperId": "2b35b946a8ad64e018c24b283bc1c6c65d36fb67", "title": "Retrieval meets Long Context Large Language Models"}, {"paperId": "819bbdc2dac9e13d9ca3e2508a6e063186ce5e40", "title": "YaRN: Efficient Context Window Extension of Large Language Models"}, {"paperId": "b31a5884a8ebe96b6300839b28608b97f8f8ef76", "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding"}, {"paperId": "b0db25e317cf856f1ec1ca3df0e573d850ed4696", "title": "L-Eval: Instituting Standardized Evaluation for Long Context Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "1733eb7792f7a43dd21f51f4d1017a1bffd217b5", "title": "Lost in the Middle: How Language Models Use Long Contexts"}, {"paperId": "b069c32fcd77160f944ab3ba71ab6f0cfb782c68", "title": "Focused Transformer: Contrastive Training for Context Scaling"}, {"paperId": "f5afaccfe90268485a9961c5771ec5e71e9b806c", "title": "Extending Context Window of Large Language Models via Positional Interpolation"}, {"paperId": "60b35c6d68acced19b0c66edcfc0ee0a2c11efed", "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers"}, {"paperId": "eb511ae6b9f04e4936891d26787f274b48b99d57", "title": "ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding"}, {"paperId": "026b3396a63ed5772329708b7580d633bb86bec9", "title": "RWKV: Reinventing RNNs for the Transformer Era"}, {"paperId": "3e4085e5869f1b7959707a1e1d7d273b6057eb4e", "title": "StarCoder: may the source be with you!"}, {"paperId": "a0e7c31d723608e03f30fc92ffc2a604a7a039da", "title": "PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "f75d05e759447c2aedb7097728f29f9a520d9bc1", "title": "Do Long-Range Language Models Actually Use Long-Range Context?"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "ec307b17f193b14292206b65a1bcc95bfd8f02ed", "title": "\u266b MuSiQue: Multihop Questions via Single-hop Question Composition"}, {"paperId": "4e3935ef7da6bcbb202ec7f8b285c313cadcd044", "title": "A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers"}, {"paperId": "9dc624d7258d1a56117ca720aea953ce46b66b21", "title": "Efficient Attentions for Long Document Summarization"}, {"paperId": "aa28873534c24e4a8c5deb7bff723cd5fc69a6f0", "title": "QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization"}, {"paperId": "50796b0f3edf9cb5ff1e447c298b33755378aa4f", "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling"}, {"paperId": "57d1e7ac339e783898f2c3b1af55737cbeee9fc5", "title": "Measuring Mathematical Problem Solving With the MATH Dataset"}, {"paperId": "9001eb3c3d5a96ad3d804410c2437e6f60feade9", "title": "Constructing A Multi-hop QA Dataset for Comprehensive Evaluation of Reasoning Steps"}, {"paperId": "814a4f680b9ba6baba23b93499f4b48af1a27678", "title": "Measuring Massive Multitask Language Understanding"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "cc27ec53160d88c25fc5096c0df65536eb780de4", "title": "Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model"}, {"paperId": "9770fff7379a7ab9006b48939462354dda9a2053", "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"}, {"paperId": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad", "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"}, {"paperId": "22655979df781d222eaf812b0d325fa9adf11594", "title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering"}, {"paperId": "88bb0a28bb58d847183ec505dda89b63771bb495", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"}, {"paperId": "d91043f0d48b9b2c8ff7ee321abb8fd7efafff7a", "title": "The NarrativeQA Reading Comprehension Challenge"}, {"paperId": "636a79420d838eabe4af7fb25d6437de45ab64e8", "title": "RACE: Large-scale ReAding Comprehension Dataset From Examinations"}, {"paperId": "80b0711ec6073e0cc62f169f39c0c52e7d225d1a", "title": "Prediction with a short memory"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "91dbf1349706c05e24c74596d7f4e5f8ed222a7b", "title": "Learning from mistakes"}, {"paperId": "c21a4d70d83e0f6eb2a9e1c41d034842dd561e47", "title": "CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge"}, {"paperId": null, "title": "How long can context length of open-source llms truly promise?"}, {"paperId": null, "title": "Model card and evaluations for claude models"}, {"paperId": null, "title": "Together Team"}, {"paperId": null, "title": "Introducing mpt-30b: Raising the bar for open-source foundation"}, {"paperId": null, "title": "for scaling language models to 128k"}]}