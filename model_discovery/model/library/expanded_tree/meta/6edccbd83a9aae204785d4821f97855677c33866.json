{"paperId": "6edccbd83a9aae204785d4821f97855677c33866", "abstract": "There have been a lot of interest in the scaling properties of Transformer models. However, not much has been done on the front of investigating the effect of scaling properties of different inductive biases and model architectures. Do model architectures scale differently? If so, how does inductive bias affect scaling behaviour? How does this influence upstream (pretraining) and downstream (transfer)? This paper conducts a systematic study of scaling behaviour of ten diverse model architectures such as Transformers, Switch Transformers, Universal Transformers, Dynamic convolutions, Performers, and recently proposed MLP-Mixers. Via extensive experiments, we show that (1) architecture is an indeed an important consideration when performing scaling and (2) the best performing model can fluctuate at different scales. We believe that the findings outlined in this work has significant implications to how model architectures are currently evaluated in the community.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2022, "citationCount": 73, "influentialCitationCount": 2, "openAccessPdf": {"url": "http://arxiv.org/pdf/2207.10551", "status": "GREEN"}, "tldr": null, "embedding": {"model": "specter_v2", "vector": [0.5860839486122131, 0.5177413821220398, -0.4321657419204712, -0.1457972228527069, -0.04285908862948418, -0.1448560208082199, 0.2799184024333954, -0.21915856003761292, -0.36173921823501587, -0.32067522406578064, 0.44179201126098633, 0.03409651666879654, -0.16855742037296295, -0.2071550488471985, -0.09058200567960739, -0.32321038842201233, -1.1748087406158447, 0.11850068718194962, 0.01439578551799059, -0.3244302272796631, -0.25984910130500793, -0.018340161070227623, -1.0620957612991333, 0.1412665694952011, 0.37748903036117554, 1.3641725778579712, -0.2773601710796356, 0.9469623565673828, -0.3588123023509979, 0.8436653017997742, 0.5113795399665833, -0.13146932423114777, 0.3346582353115082, -0.09258454293012619, -0.07389169186353683, -0.4138118624687195, 0.8068188428878784, -0.5326343178749084, -0.8878249526023865, 0.6405421495437622, 0.12620949745178223, -0.045824624598026276, 0.30298149585723877, -1.0295628309249878, 0.0012169696856290102, 0.7293921709060669, 0.8060584664344788, 1.1713050603866577, -0.8553645014762878, -0.5468597412109375, 1.168248176574707, -0.5424227714538574, -0.4811863303184509, 1.4744547605514526, 0.9713824391365051, 0.3721255958080292, -0.7974626421928406, -0.9625476598739624, 0.43132108449935913, -0.4241360127925873, -0.21827608346939087, -0.24443161487579346, 0.17695380747318268, -0.13133753836154938, 1.2966680526733398, -0.2997925579547882, -0.20798195898532867, 0.4721944332122803, 0.1811150759458542, 1.1340816020965576, 0.8790102601051331, -0.658577561378479, -0.033395905047655106, 0.6177125573158264, 0.500792384147644, 0.494045615196228, -0.426724910736084, 0.3624131977558136, -0.913823127746582, -0.27146366238594055, 0.6074110865592957, -0.19617198407649994, -0.03970964252948761, -0.041615042835474014, -0.306133896112442, 0.6629588603973389, 0.7368006706237793, 0.8001004457473755, -0.4737708866596222, 1.096938133239746, 0.7448160648345947, 1.0094846487045288, -0.014890557155013084, 0.7077376246452332, -0.11144182831048965, 0.7204157710075378, -0.6878378987312317, -0.21045398712158203, 0.09440590441226959, 0.9077979326248169, -0.3808809518814087, 0.6634144186973572, -0.37627333402633667, 0.49215301871299744, 1.1587743759155273, 0.16389286518096924, 0.5821044445037842, -0.5711220502853394, 0.3530072569847107, -0.4938202202320099, -0.09246420860290527, -0.4314194917678833, -0.48623988032341003, -0.9182440042495728, -0.7072927951812744, -0.995959997177124, -0.3940179646015167, 0.21225684881210327, -0.8375256061553955, 0.6786149740219116, -0.8718394637107849, -0.14057810604572296, 0.19900333881378174, -0.054338954389095306, 0.26783937215805054, 0.25169119238853455, 0.7931268811225891, -0.0480877049267292, 0.8722984194755554, -0.38909202814102173, -0.4111723303794861, -0.7540770769119263, 0.05841555446386337, -0.21528516709804535, 0.21897000074386597, -0.3143313229084015, -0.9985430836677551, -1.180978536605835, -0.9156055450439453, 0.508348286151886, -0.28242993354797363, -0.05411144345998764, 1.2644577026367188, 0.3863758146762848, -1.2345198392868042, 1.1214675903320312, -0.2378046065568924, -0.5479596853256226, 0.41729357838630676, 0.8945038318634033, 0.7490684986114502, 0.259483277797699, -1.1396937370300293, 0.4615655839443207, 0.2532542645931244, -0.9625741243362427, -0.09857864677906036, -0.9714296460151672, -0.3728299140930176, 0.08388879150152206, -0.2832089364528656, -0.7934786677360535, 0.906448483467102, -0.5807206034660339, -0.9207977652549744, 0.19309286773204803, 0.4268140196800232, -0.09921623021364212, 0.12927427887916565, 0.3650856912136078, -1.007517695426941, 0.1009131520986557, -0.48335760831832886, 0.6835049390792847, 0.4635315239429474, -0.707847535610199, -0.40820422768592834, 0.12024465203285217, -0.010028396733105183, -0.1510346233844757, -0.8366862535476685, 0.7733860611915588, 0.4356602132320404, -0.3485202491283417, 0.6530397534370422, 0.5394755005836487, -0.10719072073698044, 0.06564046442508698, -0.02187773771584034, -0.230979785323143, 0.29050418734550476, -0.13499882817268372, 1.2543375492095947, -0.8818848729133606, -1.0178372859954834, 0.2648391127586365, -0.1292393058538437, -0.3053555190563202, -0.6058840751647949, 0.6248766779899597, -0.49711284041404724, -0.1266581118106842, 0.11042270809412003, -0.4678347110748291, 0.020209161564707756, -0.22052106261253357, -0.9827711582183838, -0.44415557384490967, -0.14134564995765686, 0.8439549803733826, -0.6778911352157593, 0.16305093467235565, 0.11765258014202118, 0.613027036190033, -0.5594326257705688, 0.9796618223190308, 0.2236258089542389, 0.0762992724776268, 0.09851929545402527, 0.04778193682432175, 0.034952666610479355, -0.4273247718811035, 0.41759055852890015, -0.9341447949409485, 0.30894768238067627, 0.2635881006717682, -0.24798400700092316, 0.7137817740440369, -0.6640752553939819, 0.5397748351097107, 0.08934588730335236, -0.7479243278503418, 0.2752276360988617, 0.5660792589187622, -0.04957054555416107, -0.6983676552772522, 0.7106273174285889, 0.7718364596366882, -0.24674731492996216, 0.4570278227329254, 0.30285322666168213, 0.2686646580696106, -0.20201881229877472, -0.12328238785266876, 1.2704646587371826, -0.2606491446495056, 0.3357619345188141, 0.08486327528953552, 0.5938062071800232, -0.022982193157076836, 0.03682558983564377, -0.6167858839035034, 0.05576120689511299, -1.0015299320220947, -0.2844833731651306, 0.506778359413147, 0.519334077835083, 0.4686690866947174, 0.29617923498153687, -0.4328112006187439, -0.3317212164402008, -0.708777129650116, 0.24445746839046478, 1.6079566478729248, -0.28225091099739075, 0.5464189052581787, -0.5015543699264526, -0.02487700805068016, -0.12815509736537933, 0.21255150437355042, -0.47885313630104065, -0.26800867915153503, -0.4396214485168457, -1.192460298538208, 0.8979755640029907, 0.8562949895858765, 0.780942976474762, -0.41772785782814026, -0.338024377822876, 0.035718657076358795, 0.6400758028030396, -0.4582712650299072, -0.12662650644779205, 1.045961856842041, -1.4288356304168701, -0.08975891768932343, 0.020641835406422615, -0.17019492387771606, 0.28894808888435364, -0.7847761511802673, 0.7363064289093018, -0.703538715839386, 0.02863043174147606, 0.44283416867256165, 1.1660232543945312, -0.7605307698249817, -1.019558310508728, 0.24158088862895966, 0.13046041131019592, -0.07207636535167694, 0.03676210343837738, -0.5534629225730896, -0.3017168641090393, 0.26767805218696594, -0.33849066495895386, -0.3334920108318329, 0.3622174561023712, -0.09207264333963394, 0.4055574834346771, -0.13736002147197723, 0.43427902460098267, -0.9139567017555237, 1.6148364543914795, 0.42931070923805237, -0.16915230453014374, 0.5543936491012573, -0.7148164510726929, -0.15282434225082397, 0.7027295231819153, -0.7878778576850891, 0.009275391697883606, -1.3640189170837402, 0.5265355706214905, -0.2329719513654709, 0.06720256060361862, -0.2861291170120239, 0.4897565245628357, -0.6090754270553589, 0.5516777634620667, 0.03624412417411804, 0.43188974261283875, 0.1241857185959816, 0.20205417275428772, -0.16761451959609985, 0.23577891290187836, 0.38167592883110046, 0.16828027367591858, -0.005969085730612278, 0.04354282096028328, -0.5629774928092957, -0.442078173160553, 0.019230978563427925, -0.10675901174545288, -0.2655467689037323, -0.35087913274765015, -0.8013797402381897, -0.6950457692146301, -0.025086719542741776, -0.07235731184482574, -0.15452352166175842, -0.15757828950881958, -0.19945192337036133, -0.2187061756849289, -1.6893600225448608, -1.6216824054718018, -0.5217201113700867, -0.8017165660858154, -0.8476536273956299, -0.21152067184448242, 0.39271098375320435, -0.6362371444702148, -0.8964739441871643, -0.6935362219810486, -0.5119743943214417, 1.651220440864563, -0.21446728706359863, 0.9760220646858215, -0.26957929134368896, 0.3045644760131836, -0.07132875174283981, 0.13481436669826508, 0.9713078737258911, -0.20079946517944336, 0.14320780336856842, -1.4941009283065796, -0.05193584784865379, 0.04002014175057411, -0.14894641935825348, 0.1270613670349121, 0.4275353252887726, 0.6289007067680359, 0.1557215303182602, -0.26688671112060547, 0.23891501128673553, 1.3590019941329956, -0.32074683904647827, -0.2192017287015915, 0.1048794612288475, 0.5700749158859253, 0.10148455202579498, -0.5255275964736938, 0.13358788192272186, -0.18836307525634766, -0.052136991173028946, -0.1633242964744568, -0.49219945073127747, -0.3485104441642761, -0.5419767498970032, 0.02637968398630619, 1.5102105140686035, 0.16996876895427704, 0.11274770647287369, -0.6536469459533691, 0.15752878785133362, -0.55536288022995, -0.3466836214065552, 1.0941170454025269, 0.6805107593536377, 0.3169631361961365, 0.02942829392850399, -0.3657873570919037, 0.6850079894065857, 0.4197971820831299, 0.23811836540699005, -0.20170234143733978, -0.6822923421859741, 0.17357662320137024, 0.7333945631980896, 0.7885758280754089, 0.46657654643058777, -0.22459717094898224, -0.08268485963344574, 15.10704231262207, 0.3707579970359802, -0.4712602198123932, 0.5253154635429382, 0.691400408744812, 0.5066290497779846, -0.30781471729278564, -0.15992102026939392, -0.7599934935569763, 0.29894858598709106, 1.3031693696975708, 0.3075014352798462, 0.8663814663887024, 0.3020889461040497, -0.362524151802063, 0.22874683141708374, -0.4352884888648987, 0.2252652943134308, 0.3372035622596741, -1.041409969329834, 0.2601182460784912, 0.022157393395900726, 0.5815677046775818, 0.49285849928855896, 0.7098827362060547, 0.7357574105262756, 0.05777871236205101, 0.004853060934692621, 0.2892248332500458, 0.11723822355270386, 0.6702255010604858, -0.1910075545310974, 0.2406599372625351, -0.13956138491630554, -0.7209985256195068, -0.8238993883132935, -0.10287938266992569, -0.8859617114067078, 0.007353339809924364, -0.005896563176065683, -0.3952987790107727, -0.8509492874145508, -0.2596469223499298, 0.1022445410490036, 0.053960591554641724, 0.2982977628707886, -0.3443373143672943, 1.0320947170257568, -0.2608407735824585, -0.0017187593039125204, -0.041014671325683594, 0.7694367170333862, -0.1357334703207016, -0.11056790500879288, -0.1384354680776596, -0.23122212290763855, 0.01284185703843832, 0.08821818977594376, -0.5221043229103088, -0.24999238550662994, 0.1439685821533203, -0.4438486695289612, 0.1488521546125412, 0.8760444521903992, -0.13421282172203064, 0.21330907940864563, 0.008739220909774303, -0.07252471894025803, -0.05729706957936287, 0.5703139305114746, -0.5899216532707214, -0.5130451917648315, 0.49077606201171875, -0.08029080927371979, -0.40971532464027405, 0.8561611771583557, -0.5473743081092834, 0.039151880890131, -0.9670760631561279, -0.38521069288253784, 0.12074968218803406, -0.9182859063148499, -0.9633110761642456, 0.9308654069900513, -0.0576845146715641, -0.4108264744281769, 0.9990372061729431, -0.8203188180923462, -0.38584959506988525, 0.32798880338668823, -1.4408941268920898, -0.8402265906333923, 0.01383547019213438, -0.5191646218299866, -0.841088593006134, -0.2169630229473114, 1.0032780170440674, 0.17435120046138763, 0.1338716745376587, 0.2861165404319763, -0.14652113616466522, -0.042532406747341156, -0.2927757203578949, -0.7153019309043884, 0.7099370360374451, -0.08713270723819733, -0.1689627319574356, 0.4149913787841797, 0.25726819038391113, 0.8209134340286255, -0.38846540451049805, 0.11980687826871872, 0.476822167634964, -0.27822229266166687, 0.5304116010665894, -0.6083158254623413, -0.781576931476593, 0.25238099694252014, 0.4478546380996704, -0.02208118699491024, 0.43923601508140564, 0.19408631324768066, -0.47642987966537476, -0.8460549712181091, -0.8073488473892212, -0.19287413358688354, 0.5566927790641785, -0.9955816268920898, -0.31663236021995544, -0.335814505815506, 0.2045409381389618, -1.0161306858062744, -1.0910338163375854, 0.09875423461198807, 0.03156924247741699, -0.16446790099143982, 0.9452427625656128, -0.4647737145423889, 0.2708483636379242, 0.8163403272628784, -0.33662399649620056, -0.9364433884620667, -0.052349191159009933, -0.7517045736312866, 0.1630016565322876, 0.42248281836509705, 0.5264562368392944, -1.2154107093811035, 0.020951004698872566, 0.48260509967803955, 0.12866710126399994, -0.5490354299545288, -0.4463874399662018, 0.06601323187351227, -0.33258333802223206, -0.43279922008514404, 0.40903395414352417, -0.17048731446266174, -0.2450776994228363, 0.1168316975235939, 0.8713833689689636, 0.4673386216163635, -0.06061221659183502, -0.45365768671035767, -0.3219289481639862, -0.28759920597076416, -0.28034892678260803, -0.6326566934585571, -0.7199211120605469, -1.0811477899551392, -0.2271343469619751, -1.0489579439163208, -0.24648398160934448, -0.8032811284065247, -0.5965589284896851, -0.5165508389472961, -0.9151216149330139, 0.053793441504240036, 0.5611324310302734, -0.15908657014369965, -0.43649134039878845, -0.35927262902259827, -0.08594021946191788, 0.32243233919143677, 0.6731418967247009, -0.4831549823284149, -0.030769258737564087, 0.12776561081409454, -0.27771663665771484, 0.3967437148094177, 0.6868734359741211, -0.3333148956298828, -1.066731333732605, -1.0476815700531006, 0.2468877136707306, -0.36481237411499023, -0.4108836054801941, -1.215275764465332, 0.6409465074539185, 0.41782891750335693, 0.1977931708097458, 0.7540382146835327, 0.35744714736938477, -1.1517666578292847, -0.22759532928466797, 0.37068039178848267, -1.031290054321289, 0.09117957204580307, 0.4126824140548706, -0.5164439678192139, -0.2696456015110016, 0.6991045475006104, 0.344633013010025, -0.5927798748016357, -0.3811352252960205, 0.1393260806798935, -0.3822074234485626, 0.24879689514636993, -0.2244875729084015, -0.2885161340236664, -0.9617806077003479, 0.2436871975660324, -0.27060210704803467, 0.1429060846567154, -0.5748262405395508, 0.9111343026161194, -0.20549997687339783, -1.167252540588379, 0.5447810888290405, 0.5480499267578125, -0.31147313117980957, -0.8590431809425354, 0.19202500581741333, 0.7170148491859436, -0.2964198887348175, 0.25265392661094666, -0.19903293251991272, 0.18027624487876892, -0.8236278891563416, -0.5489678978919983, 0.8488603830337524, -0.16349653899669647, 0.3415132164955139, 1.301064133644104, -0.40554821491241455, -1.0426263809204102, 0.6283472180366516, -1.5300830602645874, -0.3936298191547394, 0.17255134880542755, 0.2662127912044525, 0.24639108777046204, -0.15968073904514313, 0.3233264684677124, -0.046164125204086304, 0.2390594184398651, 0.296610563993454, -0.17511910200119019, 0.39693763852119446, -0.1269730031490326, -0.18922832608222961, 0.90104079246521, 0.5688883662223816, -1.1217896938323975, -0.6434261798858643, -0.5110683441162109, -0.31802132725715637, -0.0388229675590992, 0.4500699043273926, -0.3543645143508911, -1.0963118076324463, 0.9144118428230286, 1.173525094985962, 0.47525063157081604, 0.6240315437316895, -0.319089412689209, -0.2062918245792389, 0.0744989737868309, 0.5158726572990417, -0.8632199764251709, -0.4899647831916809, 0.5284600257873535, 1.0312907695770264, -0.603654682636261, 0.32625144720077515, -0.315530925989151, -0.5010848641395569, 0.8287413120269775, 0.18238615989685059, -0.04460042715072632, 0.9214827418327332, 0.20286265015602112, 0.45457181334495544, 0.3737685978412628, -0.7275086045265198, 0.0429227314889431, 0.3161119520664215, 0.8845512270927429, 0.8836049437522888, 0.38339656591415405, 0.29062792658805847, 0.6627339720726013, -0.06480741500854492, 0.44897469878196716, 0.16539810597896576, 0.6544609665870667, -0.2023972123861313, 0.011503957211971283, 0.16526132822036743, 1.093765377998352, -0.6571604013442993, -0.4158327281475067, 0.34650740027427673, 0.8726291656494141, 0.2743143141269684, 0.5809077620506287, 0.9486649632453918, -0.3112308979034424, 0.9082755446434021, -0.010773289017379284, 0.9558998942375183, -0.04959603771567345, -0.8469822406768799, -0.20284129679203033, -0.4666633903980255, 0.26721927523612976, -0.38787874579429626, -0.05411836877465248, -0.39696621894836426, -0.10348805785179138, 0.040356118232011795, -0.020598797127604485, 0.6687017679214478, 0.41820228099823, 0.41748425364494324, 1.0078421831130981, 0.03920900076627731, -0.6067020893096924, -0.8754026889801025, -1.0076696872711182, -0.016311196610331535, -0.49182114005088806, -0.37800779938697815, -0.14329524338245392, -0.6517955660820007, -0.5619234442710876]}, "authors": [{"authorId": "144447820", "name": "Yi Tay"}, {"authorId": "3226635", "name": "Mostafa Dehghani"}, {"authorId": "2786352", "name": "Samira Abnar"}, {"authorId": "3351938", "name": "Hyung Won Chung"}, {"authorId": "26958176", "name": "W. Fedus"}, {"authorId": "30586030", "name": "J. Rao"}, {"authorId": "46617804", "name": "Sharan Narang"}, {"authorId": "2057663102", "name": "Vinh Q. Tran"}, {"authorId": "1755465", "name": "Dani Yogatama"}, {"authorId": "1680617", "name": "Donald Metzler"}], "references": [{"paperId": "9e16d8cc6096ec0d2733a4ecf41ce09d9a4bd19c", "title": "Scaling Data-Constrained Language Models"}, {"paperId": "dac3a172b504f4e33c029655e9befb3386e5f63a", "title": "Emergent Abilities of Large Language Models"}, {"paperId": "b21670e8061a06ab97e7d6052c9345a326e84ff8", "title": "UL2: Unifying Language Learning Paradigms"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "68f141724814839d556a989646194be88641b143", "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher"}, {"paperId": "66d735987a31d666a6459566ae026c40ab9a1c3a", "title": "The Efficiency Misnomer"}, {"paperId": "c206a6e7f51f5e1b6bfc479a174b66ad88ada2db", "title": "Exploring the Limits of Large Scale Pre-training"}, {"paperId": "2d4f66046bb436864cd6bf589e3a931c405f9f44", "title": "Scale Efficiently: Insights from Pre-training and Fine-tuning Transformers"}, {"paperId": "e7735be4f0fc427515fd7206ebc714356b97e71a", "title": "The Benchmark Lottery"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "c553280c1fc1d0bc7b94683bb75910e309b0d579", "title": "Larger-Scale Transformers for Multilingual Masked Language Modeling"}, {"paperId": "79b4ec1aaf67a04a9afa0d8138f84b7be66c00cb", "title": "Do Transformer Modifications Transfer Across Implementations and Applications?"}, {"paperId": "6b2b5d3d9a2ca4bc4fbd81551a62370be2fbff1b", "title": "Explaining neural scaling laws"}, {"paperId": "4383a975c09b72ba2f1a77cd779bb6965dbfb2fb", "title": "Scaling Laws for Transfer"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "3efbcfeeb0ea1051a71101d3318da4411081f0b8", "title": "Scaling Laws for Autoregressive Generative Modeling"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "4ca3b0ea12f02e2dea01a4aa505956bae5500a09", "title": "Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing"}, {"paperId": "5335fe1bf347f7ad1dce1611ea4b60bd8391a090", "title": "Transferring Inductive Biases through Knowledge Distillation"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "6fec3e579c7cd4f13bdabbee2b6ac2e8ff5941c6", "title": "Unsupervised Cross-lingual Representation Learning at Scale"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "7a064df1aeada7e69e5173f7d4c8606f4470365b", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"}, {"paperId": "d9f6ada77448664b71128bb19df15765336974a6", "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"}, {"paperId": "16c844fd4d97f3c6eb38b0d6527c87d184efedc3", "title": "The Evolved Transformer"}, {"paperId": "fea820b7d953d32069e189af2961c28fd213470b", "title": "Pay Less Attention with Lightweight and Dynamic Convolutions"}, {"paperId": "2270b8628fd8ca67ae39d277f45bc3c38ac63d5f", "title": "Mesh-TensorFlow: Deep Learning for Supercomputers"}, {"paperId": "b5246fa284f86b544a7c31f050b3bd0defd053fd", "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"}, {"paperId": "ac4dafdef1d2b685b7f28a11837414573d39ff4e", "title": "Universal Transformers"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "54a13bcc9613dcaa76fb25fbe96572f376cfcca9", "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost"}, {"paperId": "ef9ddbc35676ce8ffc2a8067044473727839dbac", "title": "Breaking the Softmax Bottleneck: A High-Rank RNN Language Model"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d", "title": "Sequence to Sequence Learning with Neural Networks"}, {"paperId": "f40aeae3e522ada1f6a9f326841b01ef5c8657b6", "title": "Unifying Language Learning Paradigms"}, {"paperId": null, "title": "Are pre-trained convolutions better"}, {"paperId": null, "title": "2022b. Chain-of-thought prompting elicits reasoning in large language models"}, {"paperId": null, "title": "key-value vector"}, {"paperId": null, "title": "Model N L d ff d model d kv N H N E #Params Tiny 4 1024 512 64 12 32 173M Small 6 2048 512 64 12 32 460M Base 12 3072 768 64 12 32 2B Large 24 3072 768 64 12 32 8B XL 48 3072 768 64 12 128 30B"}, {"paperId": null, "title": "2021a. Are pre-trained convolutions better than pre-trained trans-formers?"}, {"paperId": null, "title": "Table 4: Scaling for Switch Transformer. N E is the number of experts. Scaling for Universal Transformer Scaling UTs are generally difficult as described in the main"}]}