{"paperId": "1470b23c089db20c222094d2d155853a2bd26f3c", "abstract": "Contextualised word vectors obtained via pre-trained language models encode a variety of knowledge that has already been exploited in applications. Complementary to these language models are probabilistic topic models that learn thematic patterns from the text. Recent work has demonstrated that conducting clustering on the word-level contextual representations from a language model emulates word clusters that are discovered in latent topics of words from Latent Dirichlet Allocation. The important question is how such topical word clusters are automatically formed, through clustering, in the language model when it has not been explicitly designed to model latent topics. To address this question, we design different probe experiments. Using BERT and DistilBERT, we find that the attention framework plays a key role in modelling such word topic clusters. We strongly believe that our work paves way for further research into the relationships between probabilistic topic models and pre-trained language models.", "venue": "European Conference on Information Retrieval", "year": 2023, "citationCount": 2, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2301.04339", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "Using BERT and DistilBERT, this work finds that the attention framework plays a key role in modelling word topic clusters in probabilistic topic models and pre-trained language models."}, "embedding": {"model": "specter_v2", "vector": [-0.1924295425415039, 0.4364655911922455, -0.5534130930900574, -0.24949884414672852, -0.8184617161750793, -0.13738985359668732, 0.7722851037979126, -0.2566305994987488, -0.3813902735710144, -0.3967001438140869, 1.1855978965759277, 0.20918959379196167, -0.004336643498390913, 0.29190465807914734, -0.08830440789461136, -0.5587697625160217, -1.0881301164627075, 0.20819424092769623, -0.17807801067829132, -0.1736852377653122, -0.18786929547786713, -1.385581374168396, -0.9116973876953125, 0.5760436058044434, -0.02538684755563736, -0.07645782828330994, 0.3759654760360718, 0.7599202990531921, -0.3609638214111328, -0.17609624564647675, 0.36746135354042053, 0.017921099439263344, 0.04376015067100525, -0.07560408860445023, -0.043754175305366516, 0.01351938396692276, 0.3735944628715515, 0.01901235803961754, -0.32584136724472046, 0.5678676962852478, -0.40666472911834717, 0.14039750397205353, 0.5766441226005554, -0.48006343841552734, -0.33919963240623474, 0.9792209267616272, 0.3352177143096924, 0.8440285921096802, 0.017178112640976906, -0.8962433934211731, 1.6943764686584473, -0.9915971159934998, 0.4517609477043152, 1.3932362794876099, 0.0749984011054039, 0.245048388838768, -0.6993516683578491, -0.34047046303749084, 1.143593192100525, 0.43122488260269165, -0.6884045600891113, 0.17553411424160004, 0.33288103342056274, -0.5795491933822632, 1.7714849710464478, -0.5060147047042847, 0.4347901940345764, 0.8779120445251465, -0.050996024161577225, 1.620411992073059, -0.3869788348674774, -1.4322654008865356, -0.1833241581916809, 0.6938949823379517, 0.8844913244247437, 0.10177779197692871, -0.39232417941093445, 0.24823157489299774, -0.4993107318878174, -0.3375995457172394, -0.2684897184371948, 0.09991869330406189, 0.024017976596951485, -0.3403432369232178, -0.47909998893737793, 1.0877052545547485, 0.17171384394168854, 1.0187495946884155, -0.38629305362701416, 0.8785400390625, 0.5603737235069275, -0.12595514953136444, 0.15695247054100037, 0.40058326721191406, -0.11955062299966812, 0.1672976315021515, -1.0146640539169312, 0.12950772047042847, 0.04404674842953682, 0.5825467109680176, 0.14194725453853607, 0.024761421605944633, -0.6400400996208191, 0.4256002604961395, 1.4739271402359009, -0.18308958411216736, 0.6194905042648315, -0.39888373017311096, 0.11062346398830414, -0.5089740753173828, 0.428594708442688, -1.0889335870742798, 0.021946432068943977, 0.1925925314426422, -0.019853033125400543, -1.4936273097991943, -0.3923686742782593, -0.1490589827299118, -0.5896388292312622, 0.7149530053138733, 0.10557715594768524, 0.19952310621738434, 0.02588578313589096, 0.4349000155925751, -0.2011622041463852, 1.0788580179214478, 0.4849589467048645, 0.033401042222976685, 1.1786874532699585, -0.03692198172211647, -0.696872889995575, -1.0540834665298462, 0.750223696231842, -0.4601689577102661, 0.5277636051177979, -0.18450473248958588, -0.837557315826416, -0.7396128177642822, -0.9794696569442749, 0.6581763029098511, -0.6321092247962952, 0.21284490823745728, 0.9188909530639648, 0.9929692149162292, -0.8929538726806641, 0.39096248149871826, -0.6382898688316345, -0.6418706178665161, 0.30624645948410034, -0.21853575110435486, 0.6280720829963684, -0.38985440135002136, -1.2334160804748535, 0.20709192752838135, 0.4087412357330322, -0.785785973072052, -0.2351975291967392, -0.559808611869812, -1.1512598991394043, -0.2689659297466278, 0.17254668474197388, 0.288155198097229, 1.1872162818908691, 0.14775598049163818, -0.7930766344070435, 0.7267288565635681, -0.6623328328132629, 0.17446279525756836, -0.3870481252670288, -0.2875366508960724, -0.5157663226127625, -0.4039705693721771, 0.12387809157371521, 0.3311726748943329, 0.281385600566864, -0.40186381340026855, -0.08407097309827805, -0.1655673384666443, -0.5063676238059998, -0.16501189768314362, -0.9475064873695374, 0.5802642107009888, -0.4580097198486328, -0.3722275197505951, 0.08551086485385895, 0.7492815256118774, 0.044363584369421005, -0.887265682220459, -0.1693667769432068, -1.2229191064834595, 0.7642656564712524, 0.029443180188536644, 1.1172188520431519, -0.7998923063278198, -0.6700860261917114, 0.01871844008564949, -0.598911702632904, -0.11083011329174042, -0.7771442532539368, 0.8846394419670105, -0.47709548473358154, 0.30421918630599976, 0.18572205305099487, -0.8280470967292786, 0.21494799852371216, -0.033235710114240646, -0.8392844796180725, -0.36160963773727417, -0.32780465483665466, 0.8627961277961731, -0.7592586874961853, 0.2016618698835373, 0.22758634388446808, 0.39095211029052734, -0.9190797209739685, 0.8853405714035034, -0.7202222943305969, -0.09066565334796906, -0.19396251440048218, -0.33528223633766174, 0.05284881591796875, 0.16600286960601807, 0.5700568556785583, -0.05231158062815666, -0.26444563269615173, 0.5205898284912109, -0.310640424489975, 1.1118183135986328, -0.24831441044807434, 0.7847933769226074, 0.10514001548290253, -1.2849702835083008, 0.01063744630664587, 0.6428953409194946, -0.17664477229118347, -0.4676978588104248, 0.17006053030490875, -0.16220682859420776, -1.0181686878204346, 0.05870186910033226, 0.9528226852416992, 0.8675049543380737, -0.6054503321647644, 0.4847269356250763, 0.34588727355003357, -0.24253080785274506, 0.39067143201828003, 0.48855048418045044, 0.21600767970085144, 0.314391553401947, 0.2035825401544571, -0.4202025532722473, -0.1993822306394577, -0.3941698670387268, -0.1273779720067978, 0.11228049546480179, 0.7417364716529846, 0.28475961089134216, 0.9006863832473755, -0.7405455708503723, -0.44911834597587585, 0.1536046266555786, 0.17847920954227448, 1.503633737564087, -0.5534193515777588, -0.7440690994262695, -0.6824515461921692, -0.24486687779426575, -0.5335916876792908, 0.5701322555541992, -0.790709912776947, 0.21136651933193207, -0.5966155529022217, -1.305035948753357, 0.11370191723108292, 0.3985210061073303, 0.24636690318584442, -0.5473134517669678, -0.36757200956344604, -0.0010069389827549458, 0.38273879885673523, -0.3801138997077942, -0.5109292268753052, 0.5397306084632874, -0.3179906904697418, -0.16669327020645142, 0.22461026906967163, -0.20962578058242798, -0.017005158588290215, -0.31277596950531006, 1.0879595279693604, -0.2664185166358948, -0.560865581035614, 0.6492279171943665, -0.1147545874118805, -0.9665593504905701, 0.0517454519867897, 0.24661917984485626, -0.061577506363391876, -0.3420940041542053, 1.052647590637207, 0.5280166864395142, -0.33395931124687195, 0.2438817322254181, -0.6614609360694885, -0.24078397452831268, -0.4756145179271698, 0.2502126097679138, 0.34545785188674927, -0.14008048176765442, -0.131811261177063, -0.9576011300086975, 0.8090136051177979, -0.36983612179756165, -0.5878180265426636, 0.15301479399204254, -0.4453637897968292, -0.5759494304656982, -0.08513619750738144, -0.5982657670974731, -0.12641878426074982, -0.8137301802635193, 0.2975181043148041, 0.2268405258655548, -0.4296320974826813, 0.6774665117263794, 0.2682642638683319, 0.5808005332946777, 0.572076141834259, -0.1850242167711258, 0.11743441969156265, 0.14822256565093994, 0.5603803396224976, -0.5305733680725098, -0.19767066836357117, 0.07030115276575089, -0.19762000441551208, -0.1411631554365158, -0.7108519077301025, -1.1673352718353271, -0.4654932916164398, -0.45331040024757385, -0.06276389956474304, -0.33742621541023254, 0.3055269718170166, -0.5624244809150696, -0.6948775053024292, -0.49056896567344666, -0.8595602512359619, -0.5336890816688538, 0.13778239488601685, 0.10946031659841537, 0.03530224412679672, -1.1001081466674805, -0.8432601094245911, -0.7758560180664062, -0.09650672227144241, -1.0940357446670532, 0.5937981605529785, -0.17454062402248383, -0.9434157609939575, -1.0369712114334106, 0.581058144569397, -0.6090047955513, 0.7759465575218201, -0.1229550838470459, 1.1734950542449951, 0.10871490836143494, -0.21825747191905975, -0.5611938238143921, 0.6971303224563599, 0.151912122964859, -0.3411248028278351, 0.26635369658470154, -0.7150030136108398, 0.0995246171951294, -0.07700899243354797, -0.2648477554321289, 0.08255597949028015, 0.7080862522125244, 0.509257972240448, 0.06233729422092438, -1.0301008224487305, 0.012155123054981232, 1.471619963645935, -0.17507949471473694, 0.26905137300491333, 0.12800921499729156, 0.7509835362434387, 0.6339661478996277, -0.0733698159456253, 0.26326921582221985, 0.48603135347366333, 0.7733761072158813, 0.0032410460989922285, 0.22135236859321594, 0.2663477659225464, -0.38720494508743286, 0.49236875772476196, 1.6873600482940674, 0.6068638563156128, 0.08427214622497559, -1.2455469369888306, 1.2556231021881104, -1.413874626159668, -0.5728316903114319, 0.6294069886207581, 0.42650264501571655, 0.22341570258140564, -0.8764378428459167, -0.19438183307647705, -0.07875129580497742, 0.5127537846565247, 0.4067138135433197, -0.027439944446086884, -0.4332769811153412, 0.5202182531356812, 0.5306622385978699, -0.251347154378891, 1.0540090799331665, -0.524556040763855, 0.7170870900154114, 14.870282173156738, 0.599157989025116, 0.485298752784729, 0.4671398997306824, 0.5072886943817139, 0.015010924078524113, -0.5594566464424133, -0.09187692403793335, -1.3102564811706543, 0.06946415454149246, 1.5171719789505005, 0.3919939696788788, 0.6180922985076904, -0.016264716163277626, -0.01825796626508236, -0.3478355407714844, -0.44182032346725464, 0.21797508001327515, 0.7608816623687744, -0.8652039766311646, 0.1012437641620636, 0.5367369055747986, 0.44871556758880615, 0.40672367811203003, 0.7679463624954224, 0.7178952693939209, 0.8359725475311279, -0.2922331392765045, 0.05198374390602112, 0.13841058313846588, 0.31913524866104126, -0.3573654890060425, 0.3261575996875763, 0.3402106463909149, -0.7738770842552185, -0.14550118148326874, -0.9774688482284546, -0.8764033317565918, 0.2363629937171936, 0.3092385530471802, -0.5435011386871338, -0.6620092988014221, 0.041339751332998276, 0.5852210521697998, 0.4508615732192993, 0.1833721399307251, -0.4765947759151459, 0.8467978239059448, 0.05222376063466072, -0.451839804649353, 0.6596421003341675, 0.5849000811576843, 0.39051204919815063, 0.05322753265500069, 0.15994225442409515, -0.10787633061408997, 0.18863710761070251, 0.04314587265253067, 0.12111730128526688, 0.07751898467540741, -0.6878865361213684, -0.4874642491340637, 0.0744536891579628, 0.925529420375824, 0.5584010481834412, 0.085403673350811, -0.311208575963974, -0.0030923574231565, 0.49414005875587463, 0.3825856149196625, 0.1733434945344925, -0.07020995765924454, 0.7519364953041077, -0.47463634610176086, 0.5132970809936523, 0.17975015938282013, -0.12917150557041168, -0.5173013806343079, -0.8148940801620483, 0.0913366973400116, 0.6806663870811462, -0.9415475130081177, -1.0620605945587158, 0.8812177777290344, 0.2731055021286011, -0.12636859714984894, -0.21926788985729218, -1.1087950468063354, -0.4936542212963104, 0.48997312784194946, -0.940968930721283, -0.2451920062303543, 0.019606858491897583, -0.12017719447612762, -0.47664105892181396, 0.00460610818117857, 1.7536660432815552, -0.4327358603477478, -0.6442916989326477, -0.0638662576675415, 0.31429925560951233, -0.08535192161798477, 0.13840480148792267, -1.172292709350586, 0.6995007395744324, 0.06037422642111778, 0.3036760985851288, 0.6313195824623108, 0.11403694748878479, -0.01901080459356308, -0.4674223065376282, 0.13694605231285095, 0.4999047815799713, -1.5281766653060913, -0.2119559347629547, -0.9348911046981812, -0.9267450571060181, 0.34363800287246704, 1.2361184358596802, -0.7769010066986084, 0.9470475316047668, 0.8031219840049744, -0.3861441910266876, -0.10287903249263763, -0.659828782081604, 0.13516302406787872, -0.16727587580680847, -0.5726715922355652, -0.8861451745033264, 0.09296779334545135, 0.265490859746933, -0.6215426325798035, -0.34488701820373535, -0.47392016649246216, 0.055619705468416214, 0.10518141090869904, 0.9635531902313232, -0.4589657783508301, 0.5665321350097656, 0.808646559715271, -0.5814131498336792, -1.3834242820739746, -0.06575371325016022, -0.5654236674308777, -0.02799138054251671, 0.49995750188827515, 0.6095380783081055, -0.1148451566696167, 0.620347261428833, 1.1778299808502197, 0.5933654308319092, -0.37618309259414673, -0.3721945583820343, 0.3478369414806366, 0.37615469098091125, -0.8352012634277344, 0.583844780921936, 0.40081387758255005, 0.5620018839836121, -0.16424022614955902, 0.5685859322547913, 0.507024884223938, -0.12338580936193466, -0.8855934143066406, 0.3369075655937195, -0.05062978342175484, 0.17270180583000183, -0.2619327902793884, -0.6896010637283325, -0.8698714971542358, 0.050066862255334854, -0.8912630677223206, 0.026650909334421158, -0.9755713939666748, -0.698273241519928, 0.10539212077856064, -0.35106751322746277, 0.004864023998379707, 0.04366091266274452, -0.2768346071243286, -0.8905774354934692, -0.794745147228241, -0.3295864760875702, 0.5121640563011169, 0.18570576608181, -0.5912590622901917, -0.327657014131546, -0.3363804817199707, -0.543367862701416, 0.45538511872291565, 0.5874654054641724, -0.3208690583705902, -0.7462199926376343, -1.6025259494781494, 0.39706918597221375, -0.4506341516971588, -0.20194056630134583, -0.24555836617946625, 0.7049014568328857, 0.543026328086853, -0.049955397844314575, -0.2086857110261917, 0.4007147550582886, -0.9861558079719543, -0.7355830073356628, -0.3922596275806427, -0.5892193913459778, -0.0335891917347908, 0.31301987171173096, -0.08199938386678696, -0.283220499753952, 0.5679489970207214, -0.2291375696659088, -1.0557187795639038, -0.6244065165519714, -0.013393471948802471, -1.0638163089752197, 0.04540199786424637, 0.25810545682907104, -0.2176525592803955, -0.9840211868286133, -0.23471304774284363, -0.12751789391040802, 0.6009672284126282, -0.43824565410614014, 0.750398576259613, -0.005355725064873695, -1.4543184041976929, 0.42088091373443604, 0.16085384786128998, 0.2901752293109894, -0.13986414670944214, 0.607784628868103, 0.04221773520112038, 0.10491187125444412, 0.7574787139892578, 0.4339944124221802, -0.3019932508468628, -0.7019635438919067, -0.06538607180118561, 0.19058895111083984, -0.035502247512340546, -0.26169368624687195, 0.8080323934555054, -0.19732744991779327, -0.70051509141922, 0.4538169503211975, -0.8875209093093872, -0.8286599516868591, 0.49057114124298096, 1.0884889364242554, 0.018020842224359512, -0.30370867252349854, 0.06874817609786987, -0.26837506890296936, 0.6912460923194885, -0.32575923204421997, -0.5402740836143494, 0.8646568655967712, -0.17651665210723877, -0.34161871671676636, 1.0295429229736328, 0.7230314016342163, -0.7037836909294128, -0.6302891373634338, -0.6963786482810974, -0.1018444374203682, -0.6380990743637085, 0.6421308517456055, -0.2709626257419586, -0.2763935923576355, 0.8945602774620056, 0.821782112121582, 0.8705284595489502, -0.22174933552742004, 0.20325423777103424, -0.05333706736564636, 0.44719672203063965, 0.0809771940112114, -0.6963659524917603, -0.3343871235847473, 1.2394981384277344, 1.061542272567749, -0.4413253664970398, 0.35330313444137573, 0.09879118204116821, -0.9034650325775146, 0.6325571537017822, 0.2698426842689514, -0.2265443056821823, 1.097225308418274, -0.2584800124168396, 0.6296669840812683, -0.36163029074668884, -1.0036903619766235, -0.1717275083065033, 0.5973709225654602, 1.1852253675460815, 0.6849576830863953, 0.7150975465774536, 0.1418263018131256, 0.8869335651397705, -0.04557468742132187, -0.4201616048812866, 0.38273927569389343, 0.5108845829963684, -0.2635538876056671, -0.49290528893470764, -0.2569116950035095, 0.42384713888168335, -0.7775590419769287, -0.3882015347480774, -0.005832157097756863, 1.0351433753967285, -0.053849175572395325, 0.511326253414154, 1.0012760162353516, -0.17634673416614532, 0.4135487675666809, 0.6723282933235168, 0.0743877962231636, -0.6803455948829651, -0.16338476538658142, 0.0886474996805191, -0.32532182335853577, -0.01259698998183012, -0.5390487313270569, -0.856604278087616, 0.3486921787261963, 0.10605508089065552, 0.48449990153312683, 0.28977349400520325, 0.4231622517108917, 1.0189555883407593, 0.5391027331352234, 0.3607705533504486, -0.5103829503059387, -0.7772886753082275, 0.21461904048919678, -1.102461576461792, -0.03607363626360893, -0.8045436143875122, -0.3244710862636566, -0.36960354447364807, -0.26483094692230225, -0.3471654951572418]}, "authors": [{"authorId": "2199939913", "name": "Mozhgan Talebpour"}, {"authorId": "2031669", "name": "A. G. S. D. Herrera"}, {"authorId": "38797620", "name": "Shoaib Jameel"}], "references": [{"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "0548ce902968c09fc14e2734c834a5d2b33720f7", "title": "mcBERT: Momentum Contrastive Learning with BERT for Zero-Shot Slot Filling"}, {"paperId": "7c2db7da4a2c8580bc68ac4f38dfb7fb7a2baced", "title": "KG-ZESHEL: Knowledge Graph-Enhanced Zero-Shot Entity Linking"}, {"paperId": "c23d9d44e8bc68408cea9f305d1f24d915bc0d0d", "title": "Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey"}, {"paperId": "c5258ed58bd9062d9df467a09392aad8b54f4d20", "title": "Is Automated Topic Model Evaluation Broken?: The Incoherence of Coherence"}, {"paperId": "61ab5ca109134aacfe8555fbd2b3c0549f89a02d", "title": "Deriving Word Vectors from Contextualized Language Models using Topic-Aware Mention Selection"}, {"paperId": "9fce00ceb510a5baff43470ed9aa495f6f23aad3", "title": "Topic Modelling Meets Deep Neural Networks: A Survey"}, {"paperId": "e9aa703d07e945d3e59b86786bd01f721e54caa8", "title": "Neural ranking models for document retrieval"}, {"paperId": "9d29f15164fcd21c164b3e679d6c91045b856a7a", "title": "Unsupervised extractive multi-document summarization method based on transfer learning from BERT multi-task fine-tuning"}, {"paperId": "1551a502edf7d6d9bbf18ebecae1ca8c5de1caf0", "title": "Context Analysis for Pre-trained Masked Language Models"}, {"paperId": "b103e87c7727134927d3ffb06934a95c10c02fc0", "title": "GPT-3: Its Nature, Scope, Limits, and Consequences"}, {"paperId": "5a7f3719decfa4eb4dfeed9af004a5e176db0987", "title": "Topic Modeling with Contextualized Word Representation Clusters"}, {"paperId": "a680b32d65ee1139f584391f050aa3246be6ebdf", "title": "Distilling the Knowledge of BERT for Sequence-to-Sequence ASR"}, {"paperId": "fe4f32633bd762c3071071c96d2ad6be7d67a187", "title": "tBERT: Topic Models and BERT Joining Forces for Semantic Similarity Detection"}, {"paperId": "e14fa05f41dbd26a406eb64ded1369b4953312e7", "title": "Tired of Topic Models? Clusters of Pretrained Word Embeddings Make for Fast and Good Topics Too!"}, {"paperId": "07d85a6c8a31f43ee6e128f7ef0a1bf1494567cd", "title": "Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence"}, {"paperId": "bd20069f5cac3e63083ecf6479abc1799db33ce0", "title": "A Primer in BERTology: What We Know About How BERT Works"}, {"paperId": "743d39f81ae653c0d5ebf6e8ef3d0a4d17dfe75e", "title": "A BERT-Based Transfer Learning Approach for Hate Speech Detection in Online Social Media"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "7402b604f14b8b91c53ed6eed04af92c59636c97", "title": "Well-Read Students Learn Better: On the Importance of Pre-training Compact Models"}, {"paperId": "5744f56d3253bd7c4341d36de40a93fceaa266b3", "title": "Semantics-aware BERT for Language Understanding"}, {"paperId": "3cd331c997e90f737810aad6fcce4d993315189f", "title": "Investigating BERT\u2019s Knowledge of Language: Five Analysis Methods with NPIs"}, {"paperId": "112fd54ee193237b24f2ce7fce79e399609a29c5", "title": "The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives"}, {"paperId": "93d63ec754f29fa22572615320afe0521f7ec66d", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"}, {"paperId": "1fe62a928bf5cfac0f373728f3a4de3cefe0951d", "title": "On Identifiability in Transformers"}, {"paperId": "8271311ceeabe333d4555deedcd3926b2145314a", "title": "Self-Knowledge Distillation in Natural Language Processing"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c", "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"}, {"paperId": "95a251513853c6032bdecebd4b74e15795662986", "title": "What Does BERT Look at? An Analysis of BERT\u2019s Attention"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "12ae4d4428963d98346e8b16d76c8e165e33a094", "title": "Large-Scale Multi-Label Text Classification on EU Legislation"}, {"paperId": "97906df07855b029b7aae7c2a1c6c5e8df1d531c", "title": "BERT Rediscovers the Classical NLP Pipeline"}, {"paperId": "1a9954d86466a7e4de6f98ddee452ceb50e15d86", "title": "DocBERT: BERT for Document Classification"}, {"paperId": "ea57734824426a427f8b9139da1ae574cc929543", "title": "Simple Applications of BERT for Ad Hoc Document Retrieval"}, {"paperId": "b5aa927c906101b3f8854a29f374551e3ea64474", "title": "Pre-trained language model representations for language generation"}, {"paperId": "156d217b0a911af97fa1b5a71dc909ccef7a8028", "title": "SciBERT: A Pretrained Language Model for Scientific Text"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "ffd0ba45cc6b0c8f72a09617144786ffb26be771", "title": "Data-Free Knowledge Distillation for Deep Neural Networks"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "0c25e5f544167840756950e0ff3edd238a19cfd1", "title": "Autoencoding Variational Inference For Topic Models"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "9618c5812e144b43ceb34b80ce6854126c54b3bd", "title": "On the equivalence between algorithms for Non-negative Matrix Factorization and Latent Dirichlet Allocation"}, {"paperId": "40e4b215b810f671b4c55b02e92573060945f4a4", "title": "Exploring the Space of Topic Coherence Measures"}, {"paperId": "f4c018bcc8ea707b83247866bdc8ccb87cd9f5da", "title": "Neural Word Embedding as Implicit Matrix Factorization"}, {"paperId": "10f984a209124fb8eebd0c53b83fa265f18776b7", "title": "Nonnegative Matrix Factorization: A Comprehensive Review"}, {"paperId": "c1f2a6e281ec8b7a1282708fc050b48852d7a371", "title": "A Survey of Non-Exchangeable Priors for Bayesian Nonparametric Models"}, {"paperId": "8deeb6091710caab295d66a1d9fa2485a83b7eac", "title": "Probabilistic topic models"}, {"paperId": "ef2d64e448ee5ed2dc26179c8570803ded123a5e", "title": "Optimizing Semantic Coherence in Topic Models"}, {"paperId": "cfdd423c8672a7b178ea85d56079328df4eea647", "title": "Steven Bird, Ewan Klein and Edward Loper: Natural Language Processing with Python, Analyzing Text with the Natural Language Toolkit"}, {"paperId": "e5554c9d5fa92af69992d72ed1fdfbe953b03fb4", "title": "Rethinking LDA: Why Priors Matter"}, {"paperId": "94a8ace25d5112e22f7235bbba26570b008a73e9", "title": "LDA-based document models for ad-hoc retrieval"}, {"paperId": "09ba4b8f612f8593280ce3862d88890de9c3846b", "title": "Pattern Recognition"}, {"paperId": "365dc9be9e45cff8cf45c0fb7741b9a24b89d24b", "title": "Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science): Preface"}, {"paperId": "7dbe05f65a3129826efe0eeea4dca0d82b833035", "title": "Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science): Preface"}, {"paperId": "66a6dde6a6a20f77ce52cb2464a52777837bd81e", "title": "Document clustering based on non-negative matrix factorization"}, {"paperId": "29bae9472203546847ec1352a604566d0f602728", "title": "Learning the parts of objects by non-negative matrix factorization"}, {"paperId": "a99e5bf7273da127be1fcdf4f3cb911f17550304", "title": "Probabilistic Latent Semantic Analysis"}, {"paperId": "33151c9905102c47d431f59fc9a5a7667960507a", "title": "A Language Modeling Approach to Information Retrieval"}, {"paperId": "164125a65d42a791d2c1e108559344caef96d08b", "title": "Indexing by Latent Semantic Analysis"}, {"paperId": "e969778bced13a339f3d0465cea4e10c489ee1cc", "title": "Is Attention Explanation? An Introduction to the Debate"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "Gensim\u2013python framework for vector space modelling"}, {"paperId": "4574d77fff19e093782178595a8988a7f3aa1969", "title": "Latent Dirichlet Allocation"}, {"paperId": null, "title": "Topics in Contextualised Attention"}]}