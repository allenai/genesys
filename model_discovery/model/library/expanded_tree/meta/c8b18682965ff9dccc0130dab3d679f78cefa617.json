{"paperId": "c8b18682965ff9dccc0130dab3d679f78cefa617", "abstract": "Large Language Models (LLMs) have garnered remarkable advancements across diverse code-related tasks, known as Code LLMs, particularly in code generation that generates source code with LLM from natural language descriptions. This burgeoning field has captured significant interest from both academic researchers and industry professionals due to its practical significance in software development, e.g., GitHub Copilot. Despite the active exploration of LLMs for a variety of code tasks, either from the perspective of natural language processing (NLP) or software engineering (SE) or both, there is a noticeable absence of a comprehensive and up-to-date literature review dedicated to LLM for code generation. In this survey, we aim to bridge this gap by providing a systematic literature review that serves as a valuable reference for researchers investigating the cutting-edge progress in LLMs for code generation. We introduce a taxonomy to categorize and discuss the recent developments in LLMs for code generation, covering aspects such as data curation, latest advances, performance evaluation, and real-world applications. In addition, we present a historical overview of the evolution of LLMs for code generation and offer an empirical comparison using the widely recognized HumanEval and MBPP benchmarks to highlight the progressive enhancements in LLM capabilities for code generation. We identify critical challenges and promising opportunities regarding the gap between academia and practical development. Furthermore, we have established a dedicated resource website (https://codellm.github.io) to continuously document and disseminate the most recent advances in the field.", "venue": "arXiv.org", "year": 2024, "citationCount": 4, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "A taxonomy is introduced to categorize and discuss the recent developments in LLMs for code generation, covering aspects such as data curation, latest advances, performance evaluation, and real-world applications, and identifies critical challenges and promising opportunities regarding the gap between academia and practical development."}, "embedding": {"model": "specter_v2", "vector": [0.0024639545008540154, 0.5178800821304321, -0.38421860337257385, 0.3564431965351105, -0.6684348583221436, -0.733992874622345, 0.41046690940856934, 0.13788673281669617, -0.04289741814136505, -0.008999716490507126, 0.2441251426935196, -0.372936487197876, 0.3015563189983368, 0.1503356695175171, -0.5391258597373962, 0.3964728116989136, -0.5942928194999695, 0.11498904973268509, -0.255634069442749, -0.110227569937706, -0.06507321447134018, -0.8448663949966431, -1.0583645105361938, 0.36631840467453003, 0.9543172121047974, -0.14561164379119873, 0.19653049111366272, 0.7026384472846985, -0.6565985679626465, 0.4997192621231079, 0.5145110487937927, -0.5627565383911133, 0.21732640266418457, -0.29632312059402466, -0.3873003423213959, 0.16404245793819427, 0.10506580770015717, -0.1343323290348053, 0.10057361423969269, 0.8423845767974854, -0.36177828907966614, 0.016509825363755226, 0.3407652676105499, -0.869564414024353, -0.5607227683067322, 1.3484070301055908, 0.2900128960609436, 0.3566015660762787, 0.3045770227909088, -0.07409988343715668, 0.9942390322685242, -1.1934030055999756, 0.5805149078369141, 1.3384549617767334, 0.5081488490104675, 0.5977385640144348, -0.4558238685131073, -0.5764903426170349, -0.0974569097161293, -0.7110939025878906, -1.2747316360473633, -0.28077536821365356, -0.37928080558776855, -0.7026246190071106, 2.159742832183838, -0.4514228403568268, -0.3684384226799011, 0.23462320864200592, 0.0941484123468399, 1.0684736967086792, -0.22603924572467804, -0.9922110438346863, -0.09020978212356567, 0.28114596009254456, -0.16036896407604218, 1.141857385635376, 0.0648936778306961, 0.15739047527313232, -0.7435173392295837, -0.5349107980728149, 0.3647443354129791, -0.461033433675766, -0.27938321232795715, -0.39641955494880676, -0.3304941952228546, 0.7367316484451294, -0.16715008020401, 0.827335774898529, -0.10148768126964569, 0.5571852922439575, 0.3447254002094269, 0.27019453048706055, -0.08176170289516449, 0.7761016488075256, -0.35480767488479614, 0.16489003598690033, -0.847099244594574, 0.487481951713562, 0.3454527258872986, 1.1834245920181274, 0.07250452041625977, 0.34994977712631226, -1.0058822631835938, 0.2342301607131958, 1.025072455406189, 0.1378105729818344, 0.702940046787262, -0.6188823580741882, 0.7151384353637695, -0.034764617681503296, 0.3877667784690857, -0.07952296733856201, 0.012363972142338753, 0.013746602460741997, -0.41490039229393005, -0.811259388923645, -0.5174779891967773, -0.41483673453330994, -0.6777935028076172, 0.5909529328346252, -0.4830300509929657, -0.4852962791919708, 0.6330906748771667, 0.3897824287414551, 0.5250257253646851, 0.4684908390045166, 0.1348962038755417, -0.1635054498910904, 0.5456828474998474, -0.6327765583992004, -0.1997169405221939, -1.2108776569366455, 0.9697733521461487, -0.38325759768486023, 0.1267053484916687, -0.5034995675086975, -1.4670475721359253, -0.7391400933265686, -0.6548739671707153, 0.1420995146036148, -0.3868999481201172, 0.8136467337608337, 1.1846684217453003, 0.4478473365306854, -1.13539457321167, 0.5122274160385132, -0.020178036764264107, -0.2511449456214905, 0.10843359678983688, -0.132016122341156, 0.1073479875922203, -0.39576658606529236, -1.0953600406646729, -0.15170259773731232, 0.3342977464199066, -0.9774993062019348, -0.6603292226791382, -0.2365756779909134, -1.6206576824188232, -0.5828935503959656, 0.15183141827583313, -0.27094998955726624, 1.5530058145523071, -0.13741984963417053, -0.8253954648971558, 0.733099102973938, -0.29074886441230774, -0.018229372799396515, 0.3327566981315613, 0.005451131612062454, -0.4420185685157776, -0.7229532599449158, 0.2716106176376343, 0.4316920340061188, 0.3028404116630554, -0.34792348742485046, -0.32762813568115234, 0.890651524066925, 0.32116976380348206, -0.4958663582801819, -0.25619813799858093, 1.46953547000885, -0.4589306712150574, -0.11007583141326904, -0.018200350925326347, 0.5958600640296936, -0.43338194489479065, -0.22580839693546295, -0.5441991686820984, -0.7099324464797974, 0.11898189783096313, -0.3528226613998413, 1.3055351972579956, -0.7430856823921204, -0.8210296630859375, -0.404442697763443, -0.4205763339996338, -0.023970406502485275, -0.9051696062088013, 0.960281491279602, -0.6635432839393616, 0.87925124168396, -0.6287193298339844, -0.7781584858894348, -0.05394131690263748, -0.7160747051239014, -0.40896517038345337, -0.2477196902036667, 0.3264448642730713, 0.8871821761131287, -0.9173330068588257, 0.1992923617362976, -0.34562817215919495, -0.14013127982616425, -0.9749413728713989, 1.1715208292007446, -0.36488357186317444, 0.0833725780248642, 0.03303111344575882, -0.15549488365650177, 0.16633062064647675, -0.18322080373764038, 0.2621611952781677, 0.10490468144416809, -0.6555901169776917, 0.25767454504966736, -0.29762470722198486, 1.7846488952636719, -0.5868924856185913, 0.11288854479789734, -0.09402251988649368, 0.0776558667421341, 0.13344675302505493, 0.9194708466529846, -0.3916786313056946, 0.056611958891153336, -0.04651644825935364, 0.6654655337333679, -0.3373147249221802, -0.3724948763847351, 0.42541152238845825, 0.6343473792076111, -0.37716636061668396, 0.8126792311668396, 0.576854407787323, -0.5329092741012573, 1.3183355331420898, 0.2624594569206238, 0.8633703589439392, 0.3214148283004761, 0.7019643187522888, 0.012862014584243298, 0.7055829167366028, -0.24264216423034668, -0.1437586545944214, 0.3224475383758545, 1.1622207164764404, 1.118762731552124, 0.32404106855392456, -0.6684993505477905, -0.06489253789186478, 0.20910361409187317, 1.038317084312439, 1.1578775644302368, -0.07001186907291412, -0.3901190757751465, -1.1019389629364014, -0.7269333004951477, -0.24046868085861206, 0.7025046944618225, -0.37254798412323, -0.27996814250946045, -0.6082591414451599, -0.8857746124267578, 0.9014409780502319, 0.16090671718120575, 0.5106196999549866, -0.8596752285957336, -0.40827175974845886, -0.19371826946735382, -0.031199583783745766, -0.5606305599212646, -0.7517574429512024, 0.008193432353436947, -0.4477922320365906, -0.41000741720199585, 0.09843599051237106, -0.2902146279811859, 0.6939811706542969, -0.5996283292770386, 0.9707123637199402, -0.17672881484031677, -0.6310561299324036, -0.1958686113357544, 0.36071231961250305, -0.5073670744895935, -1.5536537170410156, 0.07859671115875244, -0.07783013582229614, -0.7033699750900269, 0.3345191478729248, 0.5558721423149109, 0.6891970634460449, 0.016206415370106697, -0.8136487603187561, 0.31348171830177307, 0.20243355631828308, -0.247660830616951, 0.37984463572502136, -0.07906214147806168, -0.4005149304866791, -1.3373085260391235, 1.3255144357681274, 0.0014027288416400552, -0.6692006587982178, 0.3879179358482361, -0.6251634955406189, -0.17021960020065308, 0.6362853050231934, -0.4838915169239044, -0.5631011724472046, -0.7105966210365295, 0.6458479762077332, 0.2763567566871643, -0.37845104932785034, 0.5925664901733398, 0.5005915760993958, 0.064068503677845, 0.5184841752052307, 0.6642558574676514, 0.17182305455207825, -0.604895830154419, 0.6336697340011597, -0.6201236844062805, 0.022468890994787216, 0.21928741037845612, 0.7945065498352051, -0.3480816185474396, -0.9602745175361633, 0.13641832768917084, -0.0880538672208786, 0.005866644438356161, -0.06973973661661148, -0.03026045858860016, 0.09455306828022003, -0.606016218662262, -0.19679002463817596, -0.24155893921852112, -1.648282766342163, 0.02886825054883957, 0.2180020958185196, -0.45840057730674744, 0.027021100744605064, -0.6988255381584167, -0.9441954493522644, -0.5958555340766907, -0.7981617450714111, -1.0630271434783936, 0.5476200580596924, -0.1224081739783287, -0.5815744400024414, -0.1430107206106186, 0.38727521896362305, -0.1977999359369278, 0.7681715488433838, -0.5953716039657593, 1.4915205240249634, 0.18506161868572235, -0.0740247517824173, -0.29164478182792664, 0.32645225524902344, 0.3048778474330902, 0.05136688053607941, 0.7277645468711853, -0.15261806547641754, -0.01674182154238224, -0.204091414809227, -0.47239720821380615, -0.3922320008277893, 0.1981588751077652, 0.476151704788208, 0.0639396533370018, -0.4953591823577881, 0.2836586833000183, 1.5714033842086792, -0.45831960439682007, -0.37492915987968445, 0.1746920943260193, 0.7824380993843079, 0.5901052355766296, -0.22013109922409058, 0.6574580073356628, 0.17912255227565765, 0.10681115835905075, 0.24230988323688507, -0.21437415480613708, 0.010423651896417141, -0.3894873559474945, 0.7046709060668945, 1.3731598854064941, 0.15027420222759247, -0.20817230641841888, -1.5912150144577026, 1.0274657011032104, -1.1850711107254028, 0.016381405293941498, 0.3044813871383667, 0.7089561223983765, 0.800347626209259, -0.6626431941986084, -0.6706744432449341, -0.28416937589645386, 0.7323570251464844, 0.0365825854241848, 0.01924256980419159, -0.773522138595581, 0.09875325858592987, 0.024459747597575188, -0.01994655281305313, 0.2951818108558655, -0.5008657574653625, 0.39439672231674194, 14.56106185913086, 0.9790768027305603, 0.30343514680862427, 0.5435593724250793, 0.025905387476086617, 0.28037554025650024, -0.6322237849235535, -0.09585264325141907, -1.2336329221725464, -0.4458317160606384, 0.9240988492965698, -0.7431303858757019, 0.7930870056152344, 0.5692163109779358, 0.24761483073234558, 0.06181037798523903, -0.3881266415119171, 0.5751909017562866, 0.6027331352233887, -1.2623225450515747, 0.8529167771339417, 0.1590442657470703, 0.8425902724266052, 0.4181321859359741, 0.2756026089191437, 0.8792252540588379, 0.6886267066001892, -0.6921254396438599, 0.75286465883255, -0.20758311450481415, 0.9458842277526855, -0.18950779736042023, 0.8387765288352966, 0.9648086428642273, -1.1042839288711548, -0.43711501359939575, -0.72576504945755, -1.2177726030349731, 0.262446790933609, 0.35304123163223267, -0.7801966071128845, -0.11192925274372101, -0.5148680210113525, 0.6392261981964111, -0.16304393112659454, 0.5584533214569092, -0.5983856320381165, 0.3809633255004883, 0.4769929051399231, 0.25847628712654114, -0.1648111492395401, 0.5366514325141907, 0.32958313822746277, -2.706783197936602e-05, 0.3678935170173645, -0.4395447075366974, 0.33697304129600525, 0.7957562804222107, -0.667746365070343, 0.31104788184165955, -0.6276400685310364, -0.6673904061317444, -0.23164132237434387, 0.7270907163619995, 0.26251283288002014, 0.5226515531539917, -0.6281200647354126, 0.0676637664437294, 0.7856941223144531, 0.17152342200279236, -0.31652531027793884, -0.21495506167411804, 0.4048285186290741, 0.051415711641311646, -0.010686209425330162, 0.413648396730423, -0.007787798531353474, -0.507964015007019, -0.5844889879226685, -0.5681161880493164, 0.1736794114112854, -0.5035786032676697, -0.6931090950965881, 1.3454787731170654, -0.14722073078155518, -1.1687414646148682, -0.1461869180202484, -0.4201531708240509, -0.04791548103094101, 0.5219537615776062, -1.2549471855163574, -0.8363540768623352, 0.4648467004299164, -0.5315744876861572, -0.1912153661251068, -0.281310111284256, 1.4005991220474243, -0.11403767019510269, -0.4475584328174591, -0.20885340869426727, 0.16642320156097412, 0.2076278179883957, -0.2835901081562042, -0.516577959060669, 1.173732042312622, 0.794404149055481, -0.17173108458518982, 0.8007040619850159, 0.011577638797461987, -0.3827362060546875, -0.6749055981636047, -0.7024351358413696, 1.0570660829544067, -0.7872668504714966, -0.28272944688796997, -1.0846019983291626, -0.6308498382568359, 0.027689585462212563, 0.6070238351821899, -0.6072004437446594, 0.39375045895576477, -0.3884355127811432, -0.4543469250202179, 0.35248035192489624, -1.0278103351593018, -0.1719239205121994, 0.5868077874183655, -0.8126066327095032, -0.1383356899023056, 0.2417445331811905, 0.5796833634376526, -0.8385140299797058, -0.2661239206790924, -0.3393825590610504, -0.22785785794258118, 0.10195504873991013, 0.3203384280204773, -0.4031802713871002, 1.0602062940597534, 0.2947692275047302, 0.29088303446769714, -0.7166197299957275, -0.0963074266910553, -1.1014013290405273, 0.35328084230422974, 0.30653417110443115, 1.5039278268814087, -0.24345703423023224, -0.12241742759943008, 1.163343906402588, 0.5390902161598206, 0.0031861597672104836, -0.49571022391319275, -0.5183184742927551, 0.11975685507059097, -0.601321816444397, 0.6523692607879639, -0.2754034101963043, 0.1755634993314743, -0.34099236130714417, 0.3163459300994873, 0.6329460144042969, -0.35291600227355957, -0.10632780194282532, 0.7810282707214355, 0.10643771290779114, -0.18577396869659424, -0.30720266699790955, -0.04909168556332588, -0.8440830111503601, 0.37702640891075134, -1.2610372304916382, 0.6403446793556213, -1.133116364479065, -0.051776960492134094, 0.5475254058837891, 0.21150679886341095, 0.3228970170021057, 0.6481161117553711, -0.3726826608181, -0.8267403841018677, -0.4081451892852783, -0.36194148659706116, 0.6881181597709656, 0.5986918807029724, -0.6560382843017578, 0.04934089630842209, -0.11476383358240128, -0.038885489106178284, 0.26363489031791687, 0.24425144493579865, -1.0440211296081543, -0.916061282157898, -1.6690512895584106, 0.6822121739387512, -0.1392742395401001, -0.3191251754760742, -0.5457436442375183, 0.4484877586364746, 0.23460720479488373, -0.7223771810531616, 0.6683797240257263, -0.5337552428245544, -0.4169933795928955, -0.21571558713912964, 0.43486514687538147, -0.6411501169204712, 0.2955024838447571, 0.5907099843025208, -0.8470404744148254, -0.6863335371017456, 0.06561397761106491, -0.3843402564525604, -1.295181155204773, -0.42517155408859253, 0.4657226800918579, -1.0493875741958618, -0.027135910466313362, 0.1366841197013855, -0.06292851269245148, -0.9507141709327698, -0.3860851228237152, 0.41827085614204407, 0.29710468649864197, 0.10282470285892487, 1.4474537372589111, 0.36194804310798645, -0.7391034960746765, -0.26753348112106323, 0.3355347216129303, 0.24383452534675598, -0.44336628913879395, 0.15971586108207703, 0.209267720580101, -0.7436407208442688, 0.4882027804851532, 0.502031683921814, 0.6522788405418396, -0.8427488207817078, -0.13316047191619873, 0.64711594581604, -0.3354930579662323, 0.09644713252782822, 1.3314355611801147, -0.11949716508388519, -1.2228114604949951, -0.390420138835907, -1.2728618383407593, -0.6060788035392761, -1.0213572978973389, 0.9578126072883606, -0.13088087737560272, 0.091489277780056, -0.3611612319946289, -0.5785673260688782, 0.11500555276870728, 0.13037152588367462, -0.41802462935447693, 0.7196685075759888, -0.13167236745357513, -0.9773491621017456, 0.3244682848453522, 0.43022361397743225, -0.24691729247570038, -0.39477330446243286, 0.12909886240959167, -0.23724770545959473, -0.15669670701026917, -0.13491149246692657, -0.4789182245731354, -0.6229144334793091, 0.6146413087844849, 0.08636437356472015, 0.3429892063140869, 0.06455603241920471, -0.21511556208133698, 0.11734816431999207, 0.34929585456848145, 0.5492094159126282, -0.4557257890701294, -0.9303675889968872, 1.0249929428100586, 1.4627468585968018, -1.065980076789856, -0.025592226535081863, -0.518100380897522, -0.8371666669845581, 1.0550097227096558, 0.41230347752571106, 0.32390299439430237, 0.6648277044296265, -0.03416818380355835, 0.1205860823392868, 0.1641266644001007, -1.0720628499984741, 0.10950630903244019, 0.5000684857368469, 1.0956676006317139, 1.437125563621521, 0.18327805399894714, -0.4137483239173889, 1.1228997707366943, 0.17680837213993073, 0.36519473791122437, 1.0706506967544556, 0.6874058246612549, -0.044606395065784454, -0.48849257826805115, 0.07856321334838867, 0.6946194767951965, -0.6215519309043884, -0.979755699634552, -0.07427960634231567, 0.4617774188518524, 0.7979663014411926, 0.8711299300193787, 0.10986402630805969, 0.2707580626010895, 0.4608670473098755, 0.30650565028190613, 0.14412206411361694, -1.3147079944610596, -0.4560483694076538, -0.37010103464126587, -0.1809144914150238, -0.18100504577159882, -0.12205665558576584, -0.4419684410095215, -0.49614080786705017, 0.0784316286444664, 0.17950841784477234, 0.44406577944755554, 0.615066409111023, 0.9547954797744751, 0.6873841285705566, -0.025238770991563797, -0.5694576501846313, -0.18121372163295746, -0.12712788581848145, -1.107677936553955, -0.22293758392333984, -0.5995640158653259, -0.521083652973175, -0.01842564344406128, -0.25256648659706116, 0.2789498567581177]}, "authors": [{"authorId": "2294682530", "name": "Juyong Jiang"}, {"authorId": "2304542351", "name": "Fan Wang"}, {"authorId": "2305041631", "name": "Jiasi Shen"}, {"authorId": "2304525068", "name": "Sungju Kim"}, {"authorId": "2257349580", "name": "Sunghun Kim"}], "references": [{"paperId": "dd3268b6fb685b7e31ca576f2a629467da90d662", "title": "CodeGemma: Open Code Models Based on Gemma"}, {"paperId": "abdceff7d7983cdede9a5aabe6a476d4c72e41a3", "title": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone"}, {"paperId": "b617b4f744bcb077a94328392fc8c630e17e4af0", "title": "Evaluating Large Language Models in Class-Level Code Generation"}, {"paperId": "aa51dece70f90faa0cb49d8b108c8a382ff15489", "title": "The Fact Selection Problem in LLM-Based Program Repair"}, {"paperId": "3940c3071e343e00d0a1d8c129854eee9430e3fb", "title": "Shortcut-connected Expert Parallelism for Accelerating Mixture-of-Experts"}, {"paperId": "c5cb68ac59f98fafc7cb96b86fca27e662e0cba8", "title": "Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization"}, {"paperId": "a6b624ada5db7bfc7e074eff35e246c08a940576", "title": "Stable Code Technical Report"}, {"paperId": "f3c339ab479cbd4782807bf47254961bc60bf293", "title": "EvoCodeBench: An Evolving Code Generation Benchmark Aligned with Real-World Code Repositories"}, {"paperId": "eabd317bf33a636b099a38f4b49aecca97202661", "title": "sDPO: Don't Use Your Data All at Once"}, {"paperId": "9aa6a885754a27fe42a87e4dfaed87d618fd8518", "title": "Iterative Refinement of Project-Level Code Context for Precise Code Generation with Compiler Feedback"}, {"paperId": "030522cc114b93ec6cec078697caf241c407c4ce", "title": "Robustness, Security, Privacy, Explainability, Efficiency, and Usability of Large Language Models for Code"}, {"paperId": "d7fc8fc5510f31469ba263253ec54edd7821cf8d", "title": "RepoHyper: Better Context Retrieval Is All You Need for Repository-Level Code Completion"}, {"paperId": "cf841544a9cb18f9fee3ed632862e08f6667815e", "title": "IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators"}, {"paperId": "18e7ab056c16928d8f9539509a4b366889106d97", "title": "StarCoder 2 and The Stack v2: The Next Generation"}, {"paperId": "c6c584ea3983627329eebff7c78951938b227351", "title": "Debug like a Human: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step"}, {"paperId": "5eac2a40422a7085cb6f03285ad08210b6f6744b", "title": "OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement"}, {"paperId": "91e2eb23fd65a294467c8dba1931fe01a4ecc05b", "title": "ARKS: Active Retrieval in Knowledge Soup for Code Generation"}, {"paperId": "34efdeaf0a78d6906b4da7335afc7182df11f639", "title": "QuRating: Selecting High-Quality Data for Training Language Models"}, {"paperId": "08e84c939b88fc50aaa74ef76e202e61a1ad940b", "title": "StepCoder: Improve Code Generation with Reinforcement Learning from Compiler Feedback"}, {"paperId": "78fbb6e7a1c568a04e8c935aa9909d0c942ea5f6", "title": "Executable Code Actions Elicit Better LLM Agents"}, {"paperId": "1f2a20a6efaf83214861dddae4a38a83ae18fe32", "title": "DeepSeek-Coder: When the Large Language Model Meets Programming - The Rise of Code Intelligence"}, {"paperId": "e8ee8dc3a806495c6084389323ca09aca3238836", "title": "LangProp: A code optimization framework using Large Language Models applied to driving"}, {"paperId": "fef0393e997ec51b184e39c712be63197d99fd46", "title": "RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture"}, {"paperId": "1566d96346927ad4dced85de4d55356f6aee6fb6", "title": "Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering"}, {"paperId": "9b7324a56ecb5600a9701c34028af2e5953d7275", "title": "Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code Generation"}, {"paperId": "fbd1b4f09b19bd23c16b54525347c6643bb06322", "title": "AST-T5: Structure-Aware Pretraining for Code Generation and Understanding"}, {"paperId": "8554b7c4ec2466326f5bd55335082edd83183f94", "title": "Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models"}, {"paperId": "ab7d320cbae173aef86c31faa087780cba44551f", "title": "SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling"}, {"paperId": "15a764731c3ecd4e43cdefbed717527f5e0b7cc8", "title": "Traces of Memorisation in Large Language Models for Code"}, {"paperId": "46f9f7b8f88f72e12cbdb21e3311f995eb6e65c5", "title": "Retrieval-Augmented Generation for Large Language Models: A Survey"}, {"paperId": "b512451d431df9e411bea4c99f7135d010275445", "title": "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"}, {"paperId": "392e5714da57d522040c6d4f394fee1874e66a16", "title": "Refactoring Programs Using Large Language Models with Few-Shot Examples"}, {"paperId": "c3b8fbdd0ee1cd663a9b308d067d40c90c05095f", "title": "Evaluating In-Context Learning of Libraries for Code Generation"}, {"paperId": "f3e83c544a001f72ebd0e8131368cbf52070ab2b", "title": "Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code"}, {"paperId": "0a27dde07d28ca8d92ed46cecc71585e1c9693f2", "title": "MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning"}, {"paperId": "1bfe2a9a40a5f34c5c6b99c182d37a6e93f95aa9", "title": "CodeFusion: A Pre-trained Diffusion Model for Code Generation"}, {"paperId": "42016f91e5b1da63174d45acb96bc89b64aa124d", "title": "Knowledge Editing for Large Language Models: A Survey"}, {"paperId": "f1bd7ea3a63b78a60b5d90d91fdb4a1d7ac0de8e", "title": "CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion"}, {"paperId": "94a5f96308729e31c1ffbc0f0618db87795092fe", "title": "SWE-bench: Can Language Models Resolve Real-World GitHub Issues?"}, {"paperId": "700bd9681f1b9e9e2212e10415d27b11c7e6836b", "title": "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models"}, {"paperId": "0e0e706e13f160e74cac9556f28ab9a358c148d2", "title": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!"}, {"paperId": "12db3efff4cc9e16822dd64bb1cad66f3f034f3b", "title": "L2CEval: Evaluating Language-to-Code Generation Capabilities of Large Language Models"}, {"paperId": "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0", "title": "Qwen Technical Report"}, {"paperId": "f81a1b4510631d14b5b565c4701ee056f8d5c72f", "title": "CodePlan: Repository-level Coding using LLMs and Planning"}, {"paperId": "0c72450890a54b68d63baa99376131fda8f06cf9", "title": "The Rise and Potential of Large Language Model Based Agents: A Survey"}, {"paperId": "e26888285436bc7998e5c95102a9beb60144be5e", "title": "Textbooks Are All You Need II: phi-1.5 technical report"}, {"paperId": "cb587eaea753ee38013afb7e5b6bc8fba1248d04", "title": "RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback"}, {"paperId": "0b0debb710366cdff461938c80763eace1651af6", "title": "Code Llama: Open Foundation Models for Code"}, {"paperId": "28c6ac721f54544162865f41c5692e70d61bccab", "title": "A Survey on Large Language Model based Autonomous Agents"}, {"paperId": "f0950a3f27c0fefffba60ae1c9a8ee360d5eb55f", "title": "Instruction Tuning for Large Language Models: A Survey"}, {"paperId": "703035b483c181953de1b55b5fd59cd4cd4cf211", "title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework"}, {"paperId": "e0ca43a635d35fd0414ee76ca1e7c287715f5b00", "title": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "a669ea57529f4db630043c8c75d8f840c485d24d", "title": "RLTF: Reinforcement Learning from Unit Test Feedback"}, {"paperId": "2a09ebbfcca1a6994eeb472cd4159f5f3858dbf9", "title": "LongCoder: A Long-Range Pre-trained Language Model for Code Completion"}, {"paperId": "2922768fd451ecdb45f48c1a83eb57f54a91221b", "title": "Textbooks Are All You Need"}, {"paperId": "2bbb16eb8e85c64608af9712724951f070e01910", "title": "RepoFusion: Training Code Models to Understand Your Repository"}, {"paperId": "454c8fef2957aa2fb13eb2c7a454393a2ee83805", "title": "WizardCoder: Empowering Code Large Language Models with Evol-Instruct"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "a4929de687f3c6937dabbf733258af635781d3c4", "title": "StudentEval: A Benchmark of Student-Written Prompts for Large Language Models of Code"}, {"paperId": "f97413a497d47c739d41d237917e6566154647b4", "title": "RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems"}, {"paperId": "0d1c76d45afa012ded7ab741194baf142117c495", "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"}, {"paperId": "5dbffedcabe3fa43060ebbe2b1789500edfd871f", "title": "Reasoning with Language Model is Planning with World Model"}, {"paperId": "32ac52069e562d4f900afee70bdca63f53461481", "title": "QLoRA: Efficient Finetuning of Quantized LLMs"}, {"paperId": "546d0624adfc6e18fb87d8cc77e7705bb9ea7445", "title": "LIMA: Less Is More for Alignment"}, {"paperId": "5deaacd4c1a3ae6691a7ae9f4442bc8e3c09b6b2", "title": "Synthetic data, real errors: how (not) to publish and use synthetic data"}, {"paperId": "9ada8fa11b1cdece31f253acae50b62df8d5f823", "title": "CodeT5+: Open Code Large Language Models for Code Understanding and Generation"}, {"paperId": "886e0962479ec6dac563666399ca4c96a468fcaa", "title": "CodeGen2: Lessons for Training LLMs on Programming and Natural Languages"}, {"paperId": "b45ec1cb2ba6b2d1ac24723fa836aee06a3db97a", "title": "Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation"}, {"paperId": "1c44e9ec5d2ed0b486f22fcb5a54923096b3591b", "title": "Duetcs: Code Style Transfer through Generation and Retrieval"}, {"paperId": "19ea368b7f88279899c40813a797dda7adc50c07", "title": "Outline, Then Details: Syntactically Guided Coarse-To-Fine Code Generation"}, {"paperId": "fbe90d2864ffdbefd1fc0a7c6f65ac10452052f2", "title": "ICE-Score: Instructing Large Language Models to Evaluate Code"}, {"paperId": "131f499e4d3503da93022d07fcf804a18483bea9", "title": "WizardLM: Empowering Large Language Models to Follow Complex Instructions"}, {"paperId": "0ffd57884d7957f6b5634b9fa24843dc3759668f", "title": "Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study"}, {"paperId": "ae736662f64d56f3ab1894fbd9c45f8f37251843", "title": "OpenAssistant Conversations - Democratizing Large Language Model Alignment"}, {"paperId": "748698bd4387afd08594e0dc8150c2afa210d9ae", "title": "RRHF: Rank Responses to Align Language Models with Human Feedback without tears"}, {"paperId": "9e3c493fb09dcd61bb05e8c5659f23327b7b6340", "title": "Teaching Large Language Models to Self-Debug"}, {"paperId": "bafe023fb072045dc0cd50316382a61c8dcb9fae", "title": "CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X"}, {"paperId": "3aaf6a2cbad5850ad81ab5c163599cb3d523436f", "title": "Self-Refine: Iterative Refinement with Self-Feedback"}, {"paperId": "af5c7848417882012203ac21399977ebda695a2b", "title": "RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation"}, {"paperId": "0671fd553dd670a4e820553a974bc48040ba0819", "title": "Reflexion: language agents with verbal reinforcement learning"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "59fe7cb560651281cfc5db6b8940da0e3ba9dea6", "title": "LEVER: Learning to Verify Language-to-Code Generation with Execution"}, {"paperId": "74013b7cfa0fc524803350fca51341004565eb22", "title": "Data Selection for Language Models via Importance Resampling"}, {"paperId": "30c0cdc414f68211d5d0514df027cec22e005174", "title": "A Survey on In-context Learning"}, {"paperId": "e965e93e76a9e6c4e4863d145b5c007b540d575d", "title": "OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization"}, {"paperId": "7b00c4deb35471194bbbbd338191165d53167fe5", "title": "CoCoMIC: Code Completion by Jointly Modeling In-file and Cross-file Context"}, {"paperId": "e65b346d442e9962a4276dc1c1af2956d9d5f1eb", "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions"}, {"paperId": "db4ab91d5675c37795e719e997a2827d3d83cd45", "title": "Towards Reasoning in Large Language Models: A Survey"}, {"paperId": "269df328eec08b56b7b1f38a7555797fe2b999b6", "title": "ReCode: Robustness Evaluation of Code Generation Models"}, {"paperId": "1bed34f2c23b97fd18de359cf62cd92b3ba612c3", "title": "Execution-Based Evaluation for Open-Domain Code Generation"}, {"paperId": "4f939f0751e5484f54089f6a97598e39afdcb3b5", "title": "Large Language Models Meet NL2Code: A Survey"}, {"paperId": "3936fd3c6187f606c6e4e2e20b196dbc41cc4654", "title": "Constitutional AI: Harmlessness from AI Feedback"}, {"paperId": "e1b732e02cd6f41e4e1eb793ec4b356cee2587f1", "title": "ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages"}, {"paperId": "e4f8cb7bb933d95bec8d6eaeeb9d1815ed095f21", "title": "Benchmarking Large Language Models for Automated Verilog RTL Code Generation"}, {"paperId": "f3a6115e5fb2237df938976e005468f0b18da797", "title": "The Stack: 3 TB of permissively licensed source code"}, {"paperId": "8a4fc5f00cd4aca61e148e46a2125c3a406719f1", "title": "DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation"}, {"paperId": "e402dd77eba504ea93bc38e2a052398bb95db351", "title": "Execution-based Evaluation for Data Science Code Generation Models"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "2577d053f8aab912d29b424e1f09133d83740fd2", "title": "Multi-lingual Evaluation of Code Generation Models"}, {"paperId": "b070174f9d955ec52e6852314dde0cb64d02ba28", "title": "Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming"}, {"paperId": "99832586d55f540f603637e458a292406a0ed75d", "title": "ReAct: Synergizing Reasoning and Acting in Language Models"}, {"paperId": "06ea568379211ffa07d9605f66f26f6f736ea5e0", "title": "PanGu-Coder: Program Synthesis with Function-Level Language Modeling"}, {"paperId": "876eb375cb7b365475040046df669c039ad54202", "title": "CodeT: Code Generation with Generated Tests"}, {"paperId": "0a39442979d6e678dd36bb443ad529c14e86a86e", "title": "DocPrompting: Generating Code by Retrieving the Docs"}, {"paperId": "8dd412cd31592ba633b5dac8b2e7b4c679ec1c0a", "title": "Grounded Copilot: How Programmers Interact with Code-Generating Models"}, {"paperId": "1aa206426a20b0b549cda5068b90b8da353b3434", "title": "Repository-Level Prompt Generation for Large Language Models of Code"}, {"paperId": "a08a3b08a5a1de6462a7da2906b1cd81691d6c18", "title": "CERT: Continual Pre-Training on Sketches for Library-Oriented Code Generation"}, {"paperId": "7cdaa08890895e1ad92afb5fad429690ad7b1dac", "title": "Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning"}, {"paperId": "65fd4085a8498928e675d4cb50c0a31092f410fb", "title": "Unleashing the Power of Compiler Intermediate Representation to Enhance Neural Program Embeddings"}, {"paperId": "e37018d3cfab9cfc29a7b78404e6c86ea18a907e", "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model"}, {"paperId": "5288b9f3a9f575543f44c39e1d3b78b3ca4c99da", "title": "InCoder: A Generative Model for Code Infilling and Synthesis"}, {"paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb", "title": "PaLM: Scaling Language Modeling with Pathways"}, {"paperId": "9a6730534295335247eebdec59b7decdeb83d59a", "title": "On the Transferability of Pre-trained Language Models for Low-Resource Programming Languages"}, {"paperId": "38115e80d805fb0fb8f090dc88ced4b24be07878", "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis"}, {"paperId": "5f19ae1135a9500940978104ec15a5b8751bc7d2", "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"}, {"paperId": "2b556fcf2ac634f03c1fb0ace5e602e829418e65", "title": "ReACC: A Retrieval-Augmented Code Completion Framework"}, {"paperId": "7a1069dafaeb484e22f2473d5545f1e45ce30656", "title": "Compilable Neural Code Generation with Compiler Feedback"}, {"paperId": "4b27f18bff43d605805c92696a979714ced0b805", "title": "UniXcoder: Unified Cross-Modal Pre-training for Code Representation"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "b32a6f6ef7dd775e0f876b4713ceccebc56e651e", "title": "A systematic evaluation of large language models of code"}, {"paperId": "23c265ba884b92ecbd9d18641078d964697e4590", "title": "Generating Training Data with Language Models: Towards Zero-Shot Language Understanding"}, {"paperId": "5cbe278b65a81602a864184bbca37de91448a5f5", "title": "Competition-level code generation with AlphaCode"}, {"paperId": "55ad5e818cfed72317576027fb33a9609210d592", "title": "Training and Evaluating a Jupyter Notebook Data Science Assistant"}, {"paperId": "d6045d2ccc9c09ca1671348de86d07da6bc28eea", "title": "Training Verifiers to Solve Math Word Problems"}, {"paperId": "17dd3555fd1ccf1141cf984347fa1b3fd6b009ca", "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"}, {"paperId": "ce828f9986b196308a3e40b1de58af1e8e68d728", "title": "Towards Continual Knowledge Learning of Language Models"}, {"paperId": "1561cdeb6dd7000f3810aabb9e6828f14799464c", "title": "Fake it till you make it: face analysis in the wild using synthetic data alone"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "a30f912f8c5e2a2bfb06351d4578e1ba3fa37896", "title": "CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation"}, {"paperId": "9ca329408813d209b1dcb36936f7f9cba82506bd", "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation"}, {"paperId": "c56aced0f0c5cfebefadb530cb08d736c3ac5c05", "title": "Retrieval Augmented Code Generation and Summarization"}, {"paperId": "a38e0f993e4805ba8a9beae4c275c91ffcec01df", "title": "Program Synthesis with Large Language Models"}, {"paperId": "4f68e07c6c3173480053fd52391851d6f80d651b", "title": "On the Opportunities and Risks of Foundation Models"}, {"paperId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "title": "Evaluating Large Language Models Trained on Code"}, {"paperId": "339b2b711fb5b228d097b03ebc3e62a521779235", "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "7ccd7de2f17bc0afad46492ac7c4ee9323fce95b", "title": "Transitioning from Real to Synthetic data: Quantifying the bias in model"}, {"paperId": "70c3be778323b896f5575a5770f934ee6f399441", "title": "Program Comprehension and Code Complexity Metrics: An fMRI Study"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "7e5008713c404445dd8786753526f1a45b93de12", "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow"}, {"paperId": "560d4747ed94786cf96ef542a1a3f2b9089f0145", "title": "Code Completion by Modeling Flattened Abstract Syntax Trees as Graphs"}, {"paperId": "0646bb09db4d1ba24150e69b71edcd4aff691b3c", "title": "Unified Pre-training for Program Understanding and Generation"}, {"paperId": "57d1e7ac339e783898f2c3b1af55737cbeee9fc5", "title": "Measuring Mathematical Problem Solving With the MATH Dataset"}, {"paperId": "171440398a1c0f43063a7689e3b385280336fb68", "title": "CURE: Code-Aware Neural Machine Translation for Automatic Program Repair"}, {"paperId": "3cb7ef02ed8c1b9983e110386fa5168eb9cb992a", "title": "Representations"}, {"paperId": "69a72ff5b30642d11c96635e99aadad3140d33a7", "title": "CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "df7d26339adf4eb0c07160947b9d2973c24911ba", "title": "Extracting Training Data from Large Language Models"}, {"paperId": "1c6970dc9d4da9f5e94399e344fe8ba901d8fe81", "title": "PyMT5: Multi-mode Translation of Natural Language and Python Code with Transformers"}, {"paperId": "f23a0e443fe931aa2fed932421bf47c1a4fcf619", "title": "CodeBLEU: a Method for Automatic Evaluation of Code Synthesis"}, {"paperId": "4083958684292f6fa2f5c7fd4f9be975e80145b6", "title": "GraphCodeBERT: Pre-training Code Representations with Data Flow"}, {"paperId": "f820283830d8978dd6d5accad2402c40cce165c2", "title": "A Tool-Based Perspective on Software Code Maintainability Metrics: A Systematic Literature Review"}, {"paperId": "7c0b558bf433c5aaaf774cd5d3c767bfd3dbe123", "title": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN"}, {"paperId": "df56748cd4f52a58973b4ac52c0bf9156c5f52f0", "title": "Unsupervised Translation of Programming Languages"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "58ed1fbaabe027345f7bb3a6312d41c5aac63e22", "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"}, {"paperId": "8ee2351221b72fca5eef4c42147ed67071903d93", "title": "IntelliCode compose: code generation using transformer"}, {"paperId": "0fe2636446cd686830da3d971b31a004d6094b3c", "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages"}, {"paperId": "e6c561d02500b2596a230b341a8eb8b921ca5bf2", "title": "Scaling Laws for Neural Language Models"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "fbe25e4f069a19dc63daca27b7c98cff338663b9", "title": "CodeSearchNet Challenge: Evaluating the State of Semantic Code Search"}, {"paperId": "eef7cfe8267954adbb4675576072a1d80ca7a3a8", "title": "MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms"}, {"paperId": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1", "title": "The Curious Case of Neural Text Degeneration"}, {"paperId": "7f9b874d77ee2d0974908448cbead7a4b0af11cd", "title": "Style-Analyzer: Fixing Code Style Inconsistencies with Interpretable Unsupervised Algorithms"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "8e773b1840b894603c06b677a0f15ebcf0f26378", "title": "Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task"}, {"paperId": "3cac56572497ba51c71da66bd207e7a48b2c758f", "title": "Mapping Language to Code in Programmatic Context"}, {"paperId": "1a53e7446274016f737236bdd48e3ff05d966384", "title": "Learning to Mine Aligned Code and Natural Language Pairs from Stack Overflow"}, {"paperId": "c8efcc854d97dfc2a42b83316a2109f9d166e43f", "title": "Self-Attention with Relative Position Representations"}, {"paperId": "6c6170ffb39cdc8cfffbeda9c7a2259eda5875f2", "title": "Tree-to-tree Neural Networks for Program Translation"}, {"paperId": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b", "title": "Proximal Policy Optimization Algorithms"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "510e26733aaff585d65701b9f1be7ca9d5afc586", "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "eea4f7f3167e4c7e3430bdc5f57383040c58e133", "title": "Survey"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "cb670415715d331af5097e46890f524ac1d82ac6", "title": "The Attack of the Clones: A Study of the Impact of Shared Code on Vulnerability Patching"}, {"paperId": "3c902294cb3230f81c504b63afffbad41cc302a1", "title": "TBCNN: A Tree-Based Convolutional Neural Network for Programming Language Processing"}, {"paperId": "7f013f172a45824d907f68481e92a22e0188ea0b", "title": "Mining idioms from source code"}, {"paperId": "d34b626663d672d42fcde50569050b35f7e43925", "title": "Measuring software library stability through historical version analysis"}, {"paperId": "18b8ef71bc01b8658b4ef2c8b9a9e4e6e5c2a07b", "title": "Dimensions in program synthesis"}, {"paperId": "1a2b8aa0ed7f24ca001508654f506ea010b18a5e", "title": "Learning a Metric for Code Readability"}, {"paperId": "b24df4edc61dcb50b53814baaeb54d85e3590817", "title": "Oracle-guided component-based program synthesis"}, {"paperId": "fd07159f48b358e912d0bd6b81ca87710f463734", "title": "Inducing Tree-Substitution Grammars"}, {"paperId": "3960dda299e0f8615a7db675b8e6905b375ecf8a", "title": "Z3: An Efficient SMT Solver"}, {"paperId": "77479ca664947420f85f0818953a693602db1c4e", "title": "Mining Internet-Scale Software Repositories"}, {"paperId": "7533d30329cfdbf04ee8ee82bfef792d08015ee5", "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"}, {"paperId": "60b05f32c32519a809f21642ef1eb3eaf3848008", "title": "ROUGE: A Package for Automatic Evaluation of Summaries"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "8d350f2d767a70d55275a17d0b3dfcc80b2e0fee", "title": "Perplexity\u2014a measure of the difficulty of speech recognition tasks"}, {"paperId": null, "title": "Position Paper: Agent AI Towards a Holistic Intelligence"}, {"paperId": "1db56be01aeb44ca0f3fcebb45180cab1e4cd82e", "title": "AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation"}, {"paperId": "1a4c6856292b8c64d19a812a77f0aa6fd47cb96c", "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework"}, {"paperId": "5ef82a8c8aa50f99285f2143b57ca4e82da1af80", "title": "Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning"}, {"paperId": "3b01b5b497e1f359b11da45af029281ee6f64c2c", "title": "Towards Enhancing In-Context Learning for Code Generation"}, {"paperId": "4cbe5288b7bedf88ea188f536214778325fda311", "title": "L2MAC: Large Language Model Automatic Computer for Unbounded Code Generation"}, {"paperId": "362cae35fb65710af8230a4ee8e1aad1f275a4e7", "title": "WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation"}, {"paperId": "3689b7ca7b07924b6135b8a71b9f1b7937b0a3d5", "title": "Length Extrapolation of Transformers: A Survey from the Perspective of Position Encoding"}, {"paperId": "ac771182d1780c863954243809d1e144433919f9", "title": "Aligning Large Language Models with Human: A Survey"}, {"paperId": "1012d2a3281dbb40c22e25652b57fc532180f59d", "title": "xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval"}, {"paperId": null, "title": "An overview of Bard: an early experiment with generative AI"}, {"paperId": null, "title": "2023. LLM-powered Autonomous Agents"}, {"paperId": null, "title": ". Phi-2: The surprising power of small language models"}, {"paperId": null, "title": ". Chatgpt: Optimizing language models for dialogue"}, {"paperId": "1b4c19168410fb2690d285b205ab2281793db81a", "title": "A Scalable and Extensible Approach to Benchmarking NL2Code for 18 Programming Languages"}, {"paperId": null, "title": ". Natural language processing with transformers"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": null, "title": "AI Code Completions"}, {"paperId": null, "title": "GitHub on BigQuery: Analyze all the open source code"}, {"paperId": null, "title": "Idea to software, fast"}, {"paperId": "1459ed38b154648d1375b29f39891f94d459c64c", "title": "A Formalism for Dependency Grammar Based on Tree Adjoining Grammar"}, {"paperId": "469c4f553ddf7b5195530d4cf10adbbcc9b18df8", "title": "Evaluation Metrics For Language Models"}, {"paperId": null, "title": "2023. Magicoder: Source code is all you need"}, {"paperId": null, "title": "2024. StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation"}, {"paperId": null, "title": "2022. Coderl: Mastering code generation through pretrained models and deep reinforcement learning"}, {"paperId": null, "title": "2024. AutoCodeRover: Autonomous Program Improvement"}, {"paperId": null, "title": "2024. Introducing OpenDevin CodeAct 1.0, a new State-of-the-art in Coding Agents"}, {"paperId": "de8ba9b01c9ab7cbabf5c33b80b7bbc618857627", "title": "The Claude 3 Model Family: Opus, Sonnet, Haiku"}, {"paperId": null, "title": "2023. Selfevolve: A code evolution framework via large language models"}, {"paperId": null, "title": "2023. AutoGPT is the vision of accessible AI for everyone, to use and to build on"}, {"paperId": null, "title": "2023. Knowledge Transfer from High-Resource to Low-Resource Programming"}, {"paperId": null, "title": "Google DeepMind AlphaCode Team. 2023. AlphaCode 2 Technical Report"}, {"paperId": null, "title": "2022. Taking Flight with Copilot: Early insights and opportunities of AI-powered pair-programming tools"}, {"paperId": null, "title": "2022. A methodology for controlling bias and fairness in synthetic data generation"}, {"paperId": null, "title": "2022. Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models"}, {"paperId": null, "title": "2022. Are Code Pre-trained Models Powerful to Learn Code Syntax and Semantics?"}, {"paperId": null, "title": "2022. The bigscience roots corpus: A 1.6 tb composite multilingual dataset"}, {"paperId": null, "title": "2023. AgentGPT: Assemble, configure, and deploy autonomous AI Agents in your browser"}, {"paperId": null, "title": "2023. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing"}, {"paperId": null, "title": "2022. What is CodeWhisperer?"}, {"paperId": null, "title": "Codeium"}, {"paperId": null, "title": "2024. Synthetic data: save money, time and carbon with open source"}, {"paperId": null, "title": "2023. Siren\u2019s song in the AI ocean: a survey on hallucination in large language models"}, {"paperId": null, "title": "2024. Gemma: Open models based on gemini research and technology"}, {"paperId": null, "title": "2024. Tree of thoughts: Deliberate problem solving with large language models"}, {"paperId": null, "title": "2023. CodeUp: A Multilingual Code Generation Llama2 Model with Parameter-Efficient Instruction-Tuning"}, {"paperId": null, "title": "2024. Code with CodeQwen1.5"}, {"paperId": null, "title": "2024. Repoformer: Selective Retrieval for Repository-Level Code Completion. arXiv preprint arXiv:2403.10059 (2024)"}, {"paperId": null, "title": "2023. Stanford Alpaca: An Instruction-following LLaMA model"}]}