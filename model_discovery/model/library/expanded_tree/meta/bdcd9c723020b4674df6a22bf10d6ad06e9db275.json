{"paperId": "bdcd9c723020b4674df6a22bf10d6ad06e9db275", "abstract": "The recent success of multiple neural architectures like CNNs, Transformers, and MLP-Mixers motivated us to look for similarities and differences between them. We found that these architectures can be interpreted through the lens of a general concept of dimension mixing. Research on coupling flows and the butterfly transform shows that partial and hierarchical signal mixing schemes are sufficient for efficient and expressive function approximation. In this work, we study group-wise sparse, non-linear, multi-layered and learnable mixing schemes of inputs and find that they are complementary to many standard neural architectures. Following our observations and drawing inspiration from the Fast Fourier Transform, we generalize Butterfly Structure to use non-linear mixer function allowing for MLP as mixing function called Butterfly MLP. We were also able to mix along sequence dimension for Transformer-based architectures called Butterfly Attention. Experiments on CIFAR and LRA datasets demonstrate that the proposed Non-Linear Butterfly Mixers are efficient and scale well when the host architectures are used as mixing function. Additionally, we propose Patch-Only MLP-Mixer for processing spatial 2D signals demonstrating a different dimension mixing strategy.", "venue": "arXiv.org", "year": 2023, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work studies group-wise sparse, non-linear, multi-layered and learnable mixing schemes of inputs and finds that they are complementary to many standard neural architectures and propose Patch-Only MLP-Mixer for processing spatial 2D signals demonstrating a different dimension mixing strategy."}, "embedding": {"model": "specter_v2", "vector": [-0.11323689669370651, 0.5367221832275391, -0.344830721616745, 0.03241884708404541, -0.45636099576950073, -0.04863416776061058, 0.7150425910949707, -0.4619443714618683, 0.29741114377975464, -0.28806838393211365, 1.3303853273391724, 0.46668657660484314, 0.14310535788536072, 0.009239550679922104, -0.12087327241897583, -0.2625115215778351, -0.7550051212310791, -0.18717430531978607, -0.3038226366043091, -0.23040778934955597, 0.052559416741132736, -0.37417617440223694, -0.8436317443847656, 0.7351141571998596, -0.17494039237499237, 1.1198416948318481, -0.13096384704113007, 0.9157028794288635, -0.42274051904678345, 1.2109389305114746, 0.5272704362869263, -0.01030904334038496, 0.790530264377594, -0.5369568467140198, 0.17667610943317413, -0.09765210002660751, 0.9972586035728455, -0.3680451512336731, -0.7453390955924988, 0.7590234279632568, -0.19392934441566467, 0.03847597911953926, 0.3412564694881439, -0.8394866585731506, 0.2880915105342865, 0.8241952657699585, 0.7489004731178284, 0.8585777878761292, -0.5964831709861755, -0.6217057108879089, 1.2605767250061035, -1.0924227237701416, -0.10500290244817734, 1.7117589712142944, 0.9647783041000366, 0.17174915969371796, -0.4634314477443695, -1.0355421304702759, 0.3262880742549896, -0.1424529254436493, 0.03060672990977764, -0.3075391948223114, 0.6551142334938049, -0.3880510628223419, 1.2526980638504028, -0.49846357107162476, 0.14107650518417358, 0.7583541870117188, 0.1627558022737503, 1.042195439338684, 0.6432247757911682, -0.4818551242351532, -0.13850119709968567, 0.27557599544525146, 0.4926304519176483, 0.6891376972198486, -0.47880861163139343, 0.45780450105667114, -1.3288748264312744, -0.07620837539434433, 0.7826446890830994, 0.3547450602054596, 0.0847475454211235, -0.036754459142684937, -0.4728962779045105, 0.7858051657676697, 0.6875524520874023, 1.06113600730896, -0.5499049425125122, 0.879883885383606, 0.5380577445030212, 0.4009207785129547, -0.16504904627799988, 0.6758982539176941, 0.2969191372394562, 0.7033975124359131, -1.021145224571228, -0.1100931391119957, 0.16277976334095, 0.3133416771888733, -0.035024769604206085, 0.3283921480178833, -0.2524964511394501, -0.0072416746988892555, 1.2977818250656128, -0.35762861371040344, 0.2624627947807312, -1.1878201961517334, 0.1673024743795395, -0.8968081474304199, -0.2914542555809021, -1.4043668508529663, -0.055980030447244644, -0.7678462862968445, -1.2568624019622803, -0.7696658968925476, -0.24737372994422913, 0.5439224243164062, -0.4418290853500366, 0.5931323766708374, -0.7246333956718445, 0.6274243593215942, -0.006688214838504791, 0.3089376389980316, 0.28984543681144714, 0.8483095765113831, 0.11924703419208527, 0.19181935489177704, 0.9301194548606873, -1.1554467678070068, -0.6496707797050476, -0.4452700614929199, -0.3199644386768341, -0.14782872796058655, 0.027090415358543396, 0.348941832780838, -1.2635573148727417, -1.4062000513076782, -1.0167945623397827, 0.21363095939159393, -0.3216809630393982, -0.13022516667842865, 1.3092721700668335, 0.32175135612487793, -0.7646486759185791, 0.945183277130127, -0.5541949272155762, -0.12395932525396347, 0.7509742975234985, -0.010950814932584763, 0.23694497346878052, 0.014611036516726017, -0.6997819542884827, -0.13364183902740479, 0.0393255390226841, -0.6669484972953796, -0.37787050008773804, -1.217758059501648, -0.44084832072257996, 0.40004557371139526, -0.3850422203540802, -0.8188932538032532, 0.5793149471282959, -0.31497856974601746, -0.7742963433265686, 0.2161511778831482, 0.16007226705551147, -0.15133267641067505, -0.18463954329490662, -0.0012124859495088458, -0.6067470908164978, 0.1335805505514145, 0.06249053776264191, 0.41694292426109314, 0.5343379974365234, -0.4413872957229614, -0.03193541616201401, 0.17351873219013214, -0.4691942632198334, -0.2756653130054474, -0.21708211302757263, 0.4383155107498169, 0.12033703178167343, -0.5158448815345764, 0.5433445572853088, 0.915229320526123, 0.1023683100938797, -0.3655683398246765, -0.31753894686698914, -0.09428799897432327, 0.7572873830795288, 0.22766785323619843, 0.48029959201812744, -1.143599033355713, -0.9406706094741821, 0.04298469424247742, 0.5265175104141235, -0.22806169092655182, -0.7773855924606323, 0.6282256245613098, -0.5591415166854858, 0.027911260724067688, 0.11118020117282867, -0.7737315893173218, -0.19802087545394897, -0.36572834849357605, -1.208042860031128, -0.2293165773153305, 0.01723303273320198, 0.7726549506187439, -0.6492253541946411, 0.36641639471054077, 0.1434820592403412, 0.4943299889564514, -1.4993271827697754, 1.1344091892242432, -0.013508740812540054, 0.473131388425827, 0.22506986558437347, 0.08197376877069473, 0.2002837359905243, -0.43676629662513733, 0.3377830386161804, -1.2201287746429443, 0.1679280400276184, 0.5836523175239563, -0.7741305828094482, 1.3157826662063599, -0.22474506497383118, 1.1290950775146484, 0.3690069615840912, -1.171597957611084, 0.33429428935050964, 0.4511210322380066, 0.2625204920768738, -0.4824124574661255, 0.3786080777645111, 0.5188469886779785, -0.7303827404975891, 0.3127100467681885, 0.39631810784339905, 0.4651821255683899, -0.08274441212415695, -0.2018972784280777, 1.3323829174041748, -0.3993728756904602, -0.07514648884534836, 0.5704641342163086, 0.6114107370376587, -0.33390146493911743, 0.2480301856994629, -0.5932319760322571, -0.04009132459759712, -1.1373543739318848, -0.2622944414615631, 0.6183237433433533, 0.5935634970664978, 1.060563087463379, 0.7717904448509216, -0.7892577052116394, -0.4505271315574646, -0.158121258020401, 0.9269481301307678, 0.8654425144195557, -0.2949223220348358, -0.32511892914772034, -0.331925630569458, -0.33883681893348694, -0.3088008165359497, -0.7183049917221069, -0.3411403000354767, -0.0660383552312851, -0.5279890894889832, -0.5768595337867737, 0.769410252571106, 0.2692558765411377, 1.3729140758514404, -0.24643263220787048, -0.06519974023103714, -0.23595137894153595, 0.2848530113697052, -0.7302168011665344, -0.5510406494140625, 0.5265762209892273, -0.7019097805023193, -0.4584144651889801, -0.08806357532739639, -0.26174598932266235, 0.04154682531952858, -0.2452632486820221, 1.0403423309326172, -0.7539476752281189, -0.11936960369348526, 0.3970923125743866, 0.8571780323982239, -0.3956092298030853, -0.30265581607818604, -0.1795492172241211, 0.0491722971200943, 0.1512211710214615, 0.1610126942396164, -0.5585184097290039, -0.37095993757247925, -0.015773268416523933, -0.4503098726272583, -0.2541586756706238, -0.004570541903376579, 0.30411550402641296, 0.6797600984573364, -0.04830911010503769, 0.08562841266393661, -0.9899172186851501, 1.1563040018081665, -0.16923388838768005, 0.012545643374323845, -0.17959065735340118, -0.24298270046710968, 0.022137578576803207, 0.5512571930885315, -0.6195480823516846, 0.2531913220882416, -1.0173118114471436, 0.3644302189350128, -0.6906265020370483, -0.5270946025848389, -0.08876915276050568, 0.2831132411956787, -0.24563419818878174, 0.6997164487838745, 0.036719441413879395, 0.3525277376174927, -0.13531222939491272, 0.5736439824104309, -1.0235565900802612, 0.7816846966743469, 0.3897647559642792, 0.002803480252623558, 0.44235658645629883, 0.38090062141418457, -0.9949453473091125, -0.7998176217079163, -0.4593532383441925, 0.12484908849000931, -0.2810625731945038, 0.29839128255844116, -0.7588541507720947, -1.1065312623977661, 0.005851061549037695, -0.8184632658958435, 0.10952915251255035, -0.3980885446071625, 0.23339754343032837, -0.39549538493156433, -1.3229249715805054, -1.346796989440918, -0.5068956017494202, -0.2743723690509796, -0.7945975661277771, -0.05425861477851868, 0.1090315654873848, -0.1851813942193985, -0.5535386800765991, 0.1304197907447815, -0.5951539278030396, 1.413931965827942, -0.1509028673171997, 0.6888027787208557, -0.3157990872859955, -0.4898379445075989, 0.30538177490234375, -0.10321354120969772, 0.8608875870704651, -0.18316662311553955, -0.14128120243549347, -0.9027243256568909, 0.561369001865387, 0.19221653044223785, -0.4763711988925934, 0.45248574018478394, 0.7709037065505981, 0.3788852095603943, -0.2724773585796356, -0.029443053528666496, 0.873783528804779, 1.3438934087753296, -0.2837074398994446, 0.16699104011058807, -0.3348291516304016, 0.8693041801452637, 0.3610851764678955, -0.9153008460998535, 0.4115009009838104, 0.02365799807012081, -0.12903088331222534, 0.17808808386325836, -0.20289012789726257, -1.009515404701233, -0.9942587614059448, -0.2928580641746521, 1.5187673568725586, 0.3264339864253998, 0.34557828307151794, -0.600966215133667, 0.43297702074050903, -1.030545949935913, -1.0690929889678955, 0.7835687398910522, 0.3262566924095154, -0.10668463259935379, -0.372531920671463, -0.05521655082702637, 0.33517736196517944, 0.31712406873703003, 0.5529776811599731, 0.08262365311384201, -0.12017908692359924, -0.020905114710330963, 0.6513242125511169, 0.31140056252479553, 0.8145086765289307, -0.2587199807167053, -0.06724303215742111, 14.792556762695312, 0.5035536289215088, -0.4331302344799042, 0.3503000736236572, 0.6489696502685547, 0.16023604571819305, -0.2882978022098541, 0.15024808049201965, -0.9966156482696533, 0.2993081212043762, 0.8445108532905579, 1.0356111526489258, 0.9221087098121643, -0.06624902784824371, -0.5984424948692322, 0.4670712351799011, -0.38524115085601807, 1.3161524534225464, 0.35893136262893677, -1.7542190551757812, -0.04909341037273407, 0.15091067552566528, 0.6567672491073608, 0.29432883858680725, 0.7765457034111023, 0.5595750212669373, 0.10953734070062637, -0.1767917424440384, 0.2996792197227478, 0.3760753571987152, 0.40386244654655457, 0.1749405413866043, -0.3143301010131836, 0.2834208011627197, -1.0111069679260254, -0.32835081219673157, -0.17410656809806824, -1.0404351949691772, 0.20261643826961517, 0.5451099872589111, 0.057028669863939285, -0.6589301824569702, 0.05924347788095474, 1.1090047359466553, 0.5619019865989685, 0.41415882110595703, -0.11278648674488068, 0.460602730512619, -0.2769980728626251, 0.2836873233318329, 0.4693653881549835, 0.6593125462532043, 0.6015151143074036, -0.0912441685795784, 0.04408581554889679, 0.027023661881685257, -0.10201308876276016, 0.2862080931663513, -0.6643350720405579, -0.4773913323879242, -0.3641588091850281, -0.3461828827857971, -0.006866231095045805, 0.8446789383888245, 0.12049229443073273, -0.01618533581495285, -0.10953386127948761, 0.049666475504636765, 0.22094763815402985, 0.26313498616218567, -0.04162915050983429, -0.36411234736442566, 0.4427647590637207, -0.21261100471019745, 0.12112518399953842, 0.3768801689147949, -0.5325497388839722, -0.6293959617614746, -1.0384407043457031, -0.6281433701515198, 0.2742924690246582, -0.6894581913948059, -1.0725297927856445, 1.250264048576355, -0.1878175288438797, -0.47426676750183105, 0.6613187789916992, -0.5840054154396057, -0.38519763946533203, 0.17895059287548065, -1.1843492984771729, -0.32661759853363037, -0.18976423144340515, -0.006033429875969887, -0.3920842707157135, -0.6566714644432068, 0.589726984500885, 0.39263641834259033, 0.15781836211681366, -0.3885519802570343, -0.5032908916473389, -0.11596530675888062, -0.0535665787756443, -0.614690899848938, 0.366177499294281, 0.11952424049377441, 0.37719884514808655, 0.19901534914970398, 0.11932212114334106, 0.44212013483047485, -0.3183992803096771, 0.34749430418014526, 0.449865460395813, -0.43150171637535095, -0.2283710390329361, -0.8663528561592102, -0.6233763098716736, 0.007457686122506857, 0.8202248215675354, 0.37929320335388184, 0.5093201398849487, -0.17798379063606262, -1.1037052869796753, -0.3657814860343933, -0.974112868309021, -0.39809033274650574, -0.04281049221754074, -1.0407384634017944, -0.36476704478263855, -0.38825520873069763, 0.11277441680431366, -0.6828997135162354, -0.4697187840938568, -0.23897869884967804, 0.5089552998542786, -0.8460294604301453, 1.2301195859909058, -0.6415096521377563, 0.716755211353302, 0.885309100151062, -0.8115910291671753, -0.7647565603256226, -0.25463634729385376, -0.8657667636871338, -0.39774322509765625, 0.3493296504020691, -0.09025051444768906, -0.5991620421409607, 0.6010764241218567, 0.1954897791147232, 0.06610862165689468, -0.32196468114852905, -0.14012806117534637, -0.18836624920368195, -0.5110082626342773, -0.3034852147102356, 0.15599475800991058, 0.3028092682361603, -0.16014862060546875, 0.46512117981910706, 0.19908632338047028, 0.3138687312602997, 0.30237287282943726, -0.7018526792526245, 0.07145153731107712, -0.342639297246933, -0.6878253817558289, -0.646163284778595, -0.767833948135376, -1.601143717765808, -0.18781781196594238, -1.1135274171829224, -0.46392297744750977, -0.6202119588851929, -0.9019625186920166, 0.1593187004327774, -0.4796677827835083, -0.30917078256607056, 0.7566779255867004, 0.11501993238925934, 0.06662466377019882, -0.32059547305107117, -0.2527720630168915, 0.4464114010334015, 0.676291286945343, -0.7146190404891968, -0.14084529876708984, -0.16408176720142365, -0.5684491991996765, 0.46933507919311523, 0.32741135358810425, -0.48223811388015747, -0.6763156056404114, -0.8480678200721741, 0.44179531931877136, 0.37207040190696716, -0.10927771776914597, -1.7076619863510132, 0.9037121534347534, 0.8653354048728943, 0.0642620176076889, 0.0182469692081213, 0.6176191568374634, -1.3555411100387573, -0.03647935763001442, 0.331449419260025, -1.0707111358642578, -0.3475654423236847, -0.03923574835062027, -0.3296567499637604, -0.6718446016311646, 1.1610130071640015, 0.1806773692369461, -1.1881777048110962, -0.04798596724867821, 0.21521876752376556, -0.18983601033687592, 0.03751521557569504, -0.2646350860595703, -0.05883712321519852, -1.316451907157898, -0.2766334116458893, -0.21436671912670135, -0.11649368703365326, -0.7547507286071777, 0.5046066045761108, -0.03643733263015747, -1.430751919746399, 0.4505172669887543, 0.7180183529853821, -0.6505457758903503, -0.7740668654441833, 0.6349705457687378, 0.48829466104507446, -0.23051773011684418, 0.640242338180542, -0.3449339270591736, 0.43040722608566284, -0.12756584584712982, 0.17816312611103058, 0.7492003440856934, -0.4115335941314697, 0.14921367168426514, 1.2557218074798584, -0.04000982642173767, -0.39712780714035034, 0.6014679074287415, -1.3469138145446777, -0.37592652440071106, 0.12822160124778748, 0.852177083492279, 0.4412012994289398, -0.20175088942050934, 0.21868574619293213, -0.3141498863697052, 0.451553076505661, 0.30874478816986084, -0.44877907633781433, 0.5849179625511169, 0.15846358239650726, -0.18339693546295166, 0.5762304067611694, 1.3972386121749878, -0.3125123977661133, -0.9544068574905396, -0.6885895133018494, -0.8014407157897949, -0.36892011761665344, 0.3266243040561676, -0.1355317234992981, -1.2494910955429077, 0.9766315221786499, 0.6710173487663269, 0.7931708097457886, 0.5502928495407104, -0.07909335196018219, 0.20838914811611176, 0.2949344217777252, -0.12638115882873535, 0.0775999128818512, 0.07367587834596634, 1.23055100440979, 0.970518171787262, -0.37471744418144226, 0.044870804995298386, -0.2677605450153351, -0.488771915435791, 1.0523655414581299, -0.0642223134636879, -0.9113065600395203, 1.4729000329971313, -0.06372671574354172, -0.17635992169380188, -0.10702794045209885, -0.8095123767852783, -0.15205758810043335, 0.7438087463378906, 1.07376229763031, 0.4664188325405121, -0.25750553607940674, 0.3239734470844269, 1.1536744832992554, 0.2217060923576355, -0.058159615844488144, 0.03619209676980972, 0.387790709733963, -0.14481335878372192, 0.05948847159743309, -0.09777425229549408, 0.5584940314292908, -0.9841431975364685, -0.23400768637657166, 0.2835371792316437, 0.4365730583667755, 0.31406691670417786, 0.47021594643592834, 0.8383402228355408, -0.37724247574806213, 0.682014524936676, -0.2155870944261551, 0.6021777987480164, -0.2854388654232025, -0.7162801027297974, 0.08997039496898651, -0.9306427836418152, -0.5294125080108643, -0.7965160012245178, -0.08561576902866364, 0.21606414020061493, 0.025555964559316635, 0.7076323628425598, 0.12991461157798767, 0.3279189467430115, 0.49190109968185425, 0.6591205596923828, 0.7405939102172852, 0.26791584491729736, -0.8296985030174255, 0.15829311311244965, -0.6311455368995667, -0.18061962723731995, -0.7216823101043701, 0.5938420295715332, -0.023185137659311295, -0.6118045449256897, -0.05843627452850342]}, "authors": [{"authorId": "2091613178", "name": "Suman Sapkota"}, {"authorId": "2256990857", "name": "Binod Bhattarai"}], "references": [{"paperId": "674479ef3ec1bebe8e3bf4ecb801e54c8d21e0da", "title": "Understanding MLP-Mixer as a Wide and Sparse MLP"}, {"paperId": "442ab95eb9cfbc03bb17a27b52313b5d25eaa738", "title": "Discovering faster matrix multiplication algorithms with reinforcement learning"}, {"paperId": "13270b9759cf0296b5a346fbb58b706e8ad0a982", "title": "Adaptable Butterfly Accelerator for Attention-based NNs via Hardware and Algorithm Co-design"}, {"paperId": "d1869155960e4b1b882b39171dbecd25a7eda3cd", "title": "More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "ad7bcec33f5206d4f28687a6a5a950de67010651", "title": "Neighborhood Attention Transformer"}, {"paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc", "title": "MaxViT: Multi-Axis Vision Transformer"}, {"paperId": "8326dba15f6b8ee6e43c23eea3265a05e59e8135", "title": "Monarch: Expressive Structured Matrices for Efficient and Accurate Training"}, {"paperId": "fbaa944e73644ce12ea4a0ac8ffb64c3280f3aff", "title": "Deformable Butterfly: A Highly Structured and Sparse Linear Transform"}, {"paperId": "f6b770ed3ed2d41f37668318b6ca4a04432c5b62", "title": "ViT-P: Rethinking Data-efficient Vision Transformers from Locality"}, {"paperId": "3d5daaa51a8ac3ebca1f823866184fa4ee4d0b0f", "title": "Mixing and Shifting: Exploiting Global and Local Dependencies in Vision MLPs"}, {"paperId": "48e84128b0f288f544176138805a97fbe592a1dd", "title": "DynaMixer: A Vision MLP Architecture with Dynamic Mixing"}, {"paperId": "90b21dbad8969b74d704eed15a3d98722a88e464", "title": "Pixelated Butterfly: Simple and Efficient Sparse training for Neural Network Models"}, {"paperId": "b476c932e959cfe645911786f1a070c70b5375c6", "title": "An Image Patch is a Wave: Phase-Aware Vision MLP"}, {"paperId": "f8a287be26c30b4362f9504ba01e4e7269790c60", "title": "Are we ready for a new paradigm shift? A survey on visual deep MLP"}, {"paperId": "5f895e84c1fea75de07b4f90da518273c2e57291", "title": "Scatterbrain: Unifying Sparse and Low-rank Attention Approximation"}, {"paperId": "58970a426b687bb080b7fed3b4b78ab1ebaa56f4", "title": "Hire-MLP: Vision MLP via Hierarchical Rearrangement"}, {"paperId": "fd547648ded5dd4c45a3594b398844876d93c339", "title": "S2-MLPv2: Improved Spatial-Shift MLP Architecture for Vision"}, {"paperId": "f75cddf2d42ed01b34686704eb3504becef67442", "title": "CycleMLP: A MLP-like Architecture for Dense Prediction"}, {"paperId": "71363797140647ebb3f540584de0a8758d2f7aa2", "title": "AS-MLP: An Axial Shifted MLP Architecture for Vision"}, {"paperId": "2435ffb8ed3212156d6b6f19f633a861399cf30e", "title": "Vision Permutator: A Permutable MLP-Like Architecture for Visual Recognition"}, {"paperId": "2e8149dafb864ec3675087c99bf5572fcf4eb170", "title": "RegionViT: Regional-to-Local Attention for Vision Transformers"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "14014c024674991149f3ecf9314c93f7e029ef1a", "title": "Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges"}, {"paperId": "8f8f73f0f208302546c825ed474432389ed63be4", "title": "EfficientNetV2: Smaller Models and Faster Training"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "0cd82dfae930ac4b57c0e959f744f2d10bf87649", "title": "Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding"}, {"paperId": "4a3acdd9de30b3c5d40eb6ee28dd0061a4bfbb13", "title": "Coupling-based Invertible Neural Networks Are Universal Diffeomorphism Approximators"}, {"paperId": "70e9a09de05aa7ed8a74d56cf2d13ea9e38a6328", "title": "Sparse GPU Kernels for Deep Learning"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "4de08637d620ae781783a91b46f82ee8d9be405f", "title": "Low-Rank Compression of Neural Nets: Learning the Rank of Each Layer"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "8323c591e119eb09b28b29fd6c7bc76bd889df7a", "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"}, {"paperId": "f6390beca54411b06f3bde424fb983a451789733", "title": "Adaptively Sparse Transformers"}, {"paperId": "b1ac64438608aac1a8dfd0adf8fec8c6220f6bfd", "title": "Butterfly Transform: An Efficient FFT Based Neural Architecture Design"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "a6e92f6fa9e91b7e869562a63b30a9a56cf14582", "title": "Learning Fast Algorithms for Linear Transforms Using Butterfly Factorizations"}, {"paperId": "c8b25a128f4bfd0c79de82c174dd403b2ef6eeb1", "title": "Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design"}, {"paperId": "c02b909a514af6b9255315e2d50112845ca5ed0e", "title": "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"}, {"paperId": "21b786b3f870fc7fa247c143aa41de88b1fc6141", "title": "Glow: Generative Flow with Invertible 1x1 Convolutions"}, {"paperId": "0d3c46a3cbfe06cec259fec954b6ff6df6c1a566", "title": "Learning long-range spatial dependencies with horizontal gated-recurrent units"}, {"paperId": "8b354d76813bd5375e7e5c8d17f630bec5936a01", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning"}, {"paperId": "11e7c4182a7813d5acf1be198c8c96d164fb95a2", "title": "i-RevNet: Deep Invertible Networks"}, {"paperId": "3a6d4cd0768ae8768e733280d362bdb4d25924e7", "title": "The Reversible Residual Network: Backpropagation Without Storing Activations"}, {"paperId": "9da734397acd7ff7c557960c62fb1b400b27bd89", "title": "ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "3617ccfec4bed2d8ac15d0ad1a35b589d9b270cb", "title": "Large Kernel Matters \u2014 Improve Semantic Segmentation by Global Convolutional Network"}, {"paperId": "0e779fd59353a7f1f5b559b9d65fa4bfe367890c", "title": "Geometric Deep Learning: Going beyond Euclidean data"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff", "title": "Learning both Weights and Connections for Efficient Neural Network"}, {"paperId": "dc8301b67f98accbb331190dd7bd987952a692af", "title": "NICE: Non-linear Independent Components Estimation"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "1c61f9ef06fe74505775a833ff849185757199e7", "title": "Learning Word Vectors for Sentiment Analysis"}, {"paperId": "e01eae8dea6fbaa1ae7fc83535053932268df430", "title": "The ACL anthology network corpus"}, {"paperId": "cb80b424db4c94cbaf4c3ae0e570ac3eb6f3bcf3", "title": "Gaussian elimination is not optimal"}, {"paperId": "0e6beb95b5150ce99b108acdefabf70ccd3fee30", "title": "An algorithm for the machine calculation of complex Fourier series"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}]}