{"paperId": "a25370452533bf47549243e97852b9cdf7a0ee0e", "abstract": "In this work we introduce KERNELIZED TRANSFORMER, a generic, scalable, data driven framework for learning the kernel function in Transformers. Our framework approximates the Transformer kernel as a dot product between spectral feature maps and learns the kernel by learning the spectral distribution. This not only helps in learning a generic kernel end-to-end, but also reduces the time and space complexity of Transformers from quadratic to linear. We show that KERNELIZED TRANSFORMERS achieve performance comparable to existing efficient Transformer architectures, both in terms of accuracy as well as computational efficiency. Our study also demonstrates that the choice of the kernel has a substantial impact on performance, and kernel learning variants are competitive alternatives to fixed kernel Transformers, both in long as well as short sequence tasks.", "venue": "Trans. Mach. Learn. Res.", "year": 2021, "citationCount": 12, "influentialCitationCount": 1, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "KERNELIZED TRANSFORMER is introduced, a generic, scalable, data driven framework for learning the kernel function in Transformers that approximates the Transformer kernel as a dot product between spectral feature maps and learns the kernel by learning the spectral distribution."}, "embedding": {"model": "specter_v2", "vector": [0.30543357133865356, 0.20944619178771973, -0.3843501806259155, -0.13596174120903015, -0.4648177921772003, -0.22094154357910156, 0.53822261095047, -0.1311996728181839, -0.156728133559227, -0.8461441397666931, 0.38200515508651733, 0.09809494763612747, 0.3961004614830017, -0.05159413814544678, -0.1871413290500641, 0.050105344504117966, -0.7079798579216003, 0.07244012504816055, 0.4107303023338318, -0.34683191776275635, -0.07359818369150162, -0.6909579634666443, -1.006834626197815, -0.06482528150081635, 0.5211357474327087, 1.1062283515930176, 0.05341450124979019, 0.7123213410377502, -0.4083171784877777, 0.27113133668899536, 0.6988204121589661, -0.42396247386932373, 0.47537076473236084, -0.12942536175251007, -0.3691848814487457, 0.012665880843997002, 0.32461676001548767, -0.17096002399921417, -0.5691831707954407, 0.9610856771469116, -0.4202689528465271, 0.37923765182495117, 0.6555020809173584, -0.9683884382247925, -0.36263808608055115, 0.5526465177536011, 0.6910898089408875, 0.5521225333213806, -0.6028205156326294, -0.7078762054443359, 1.4585481882095337, -1.568435788154602, -0.22811871767044067, 0.9992491006851196, 0.9996987581253052, -0.03679549694061279, -0.5106465220451355, -0.5507396459579468, 0.07450232654809952, 0.4082358181476593, -0.8340985774993896, -0.22946211695671082, -0.39174214005470276, -0.4751923680305481, 1.5898674726486206, -0.6497964262962341, 0.42563703656196594, 0.3476058542728424, 0.028286214917898178, 1.371563196182251, -0.033005230128765106, -0.3555850386619568, -0.4590442478656769, 0.06964945048093796, 0.17667314410209656, 0.8919044137001038, -0.8459926247596741, 0.47953444719314575, -1.0938255786895752, -0.341247022151947, 0.32804223895072937, 0.056471873074769974, 0.06042681261897087, -0.7599436640739441, -0.36815282702445984, 0.7925029397010803, 0.5150502324104309, 0.18738025426864624, -0.25334373116493225, 0.809939980506897, 1.096137523651123, 0.31942492723464966, 0.10308896005153656, 0.052783314138650894, 0.17536091804504395, -0.010129474103450775, -0.6236931085586548, 0.1255405694246292, -0.005476226098835468, 0.5877335667610168, 0.02891875058412552, 0.478909969329834, -0.25392118096351624, 0.5926324725151062, 0.8348527550697327, 0.1708197295665741, 0.4201975166797638, -0.20407843589782715, -0.10261885076761246, -0.5448749661445618, -0.026648595929145813, -0.463954895734787, -0.024842271581292152, -0.07186739891767502, -0.5892756581306458, -0.8979095816612244, -0.5996667146682739, 0.4124320447444916, -0.9389064311981201, 0.5539733171463013, -0.4267634153366089, 0.5761047005653381, 0.0011633174726739526, 0.35127687454223633, 0.38916438817977905, 0.5735118389129639, 0.2843078374862671, 0.28577908873558044, 1.0413113832473755, -0.8995822072029114, -0.7800276279449463, -0.21174739301204681, 0.6115859150886536, -0.4603552222251892, 0.3037019968032837, -0.2110828012228012, -0.8028614521026611, -1.1616153717041016, -0.7921536564826965, 0.11772210896015167, -0.5884262323379517, 0.4129944145679474, 1.0485175848007202, 0.45702967047691345, -0.9916211366653442, 0.9014294147491455, -0.2512076497077942, -0.21755068004131317, 0.5095661282539368, 0.10806522518396378, 0.32967400550842285, 0.08911097794771194, -1.3620637655258179, 0.6610365509986877, 0.33507782220840454, -0.7432118654251099, -0.5026167631149292, -1.0015236139297485, -0.9331619739532471, -0.05962708592414856, 0.1366928219795227, -0.10712162405252457, 1.3512943983078003, -0.2392720729112625, -1.2087949514389038, 0.42979496717453003, 0.16053809225559235, -0.14157284796237946, 0.10036298632621765, -0.24978923797607422, -0.4026710093021393, -0.5211275815963745, -0.13723723590373993, 0.11561288684606552, 0.6409060955047607, 0.3879741430282593, -0.5688305497169495, 0.48785072565078735, -0.6493471264839172, 0.16018272936344147, -0.5640313029289246, 0.8518015742301941, 0.11770336329936981, -0.6661529541015625, -0.10333911329507828, 0.34171396493911743, 0.21983563899993896, -0.21919843554496765, -0.3539451062679291, -1.0078818798065186, 1.2817234992980957, -0.09069881588220596, 0.8338226675987244, -1.2100353240966797, -0.6834157705307007, 0.09284935891628265, -0.1496516615152359, 0.02832404524087906, -0.49626776576042175, 1.0739898681640625, -0.8312126398086548, -0.30898118019104004, 0.24944627285003662, -0.5486080050468445, 0.1900303214788437, -0.6058733463287354, -0.8809511065483093, -0.055931106209754944, -0.08984127640724182, 1.194345235824585, -0.8340381979942322, 0.7102480530738831, 0.21714161336421967, 0.4589734673500061, -0.2685243785381317, 1.2954156398773193, 0.11791454255580902, -0.5563653111457825, 0.2781251072883606, -0.20983745157718658, 0.06855666637420654, -0.5253872871398926, 0.1993209570646286, -1.0247350931167603, 0.2422235608100891, 0.4820477068424225, -0.2875587046146393, 1.5681999921798706, -0.18813441693782806, 0.48770543932914734, -0.3612113893032074, -1.1339205503463745, 0.5545351505279541, 0.5088011622428894, 0.227306067943573, -0.28960347175598145, 0.13900452852249146, 0.5408642292022705, -0.809816837310791, 0.6001683473587036, 0.43406808376312256, 0.714205801486969, -0.3114509582519531, 0.29544007778167725, 0.7311047315597534, -0.2429136335849762, -0.028722641989588737, 0.37683823704719543, 0.637202262878418, 0.4224932789802551, 0.6425923705101013, -0.1675805300474167, -0.09334832429885864, -0.6209422945976257, -0.3111306428909302, 0.23535917699337006, 0.6449503898620605, 0.5228910446166992, 0.21984952688217163, -0.77032470703125, -0.47296756505966187, -0.9320520162582397, 0.6938704252243042, 1.634490728378296, -0.1380806416273117, -0.4902816116809845, -0.819487452507019, -0.5212474465370178, -0.1071271076798439, -0.3206718862056732, -0.5214715600013733, -0.7433103322982788, -0.19657506048679352, -1.0881597995758057, 1.1340875625610352, 0.46779534220695496, 1.201658010482788, -0.2708948850631714, -0.38678041100502014, -0.20539793372154236, 0.06558156758546829, -0.6829814910888672, -1.194933295249939, 0.9215690493583679, -0.6588168144226074, -0.40203526616096497, 0.12703295052051544, 0.07948912680149078, -0.222062885761261, -0.5894522070884705, 0.6047403812408447, -0.9708325266838074, -0.6380508542060852, 0.19632846117019653, 0.3566058278083801, -0.7657188773155212, -0.587992250919342, 0.27531903982162476, 0.19947780668735504, 0.019632333889603615, 0.2740704119205475, 0.24044625461101532, 0.093732550740242, 0.345121294260025, -0.436244934797287, 0.13192300498485565, 0.15611650049686432, 0.35554268956184387, 0.3960636258125305, -0.05033339187502861, 0.16702550649642944, -0.8331956267356873, 1.1323745250701904, 0.21924307942390442, -0.272119402885437, 0.25683507323265076, -1.0337762832641602, -0.33568477630615234, 0.36458727717399597, -0.7348769903182983, -0.029051413759589195, -0.2013639509677887, 0.33738476037979126, -0.653849184513092, 0.17009581625461578, 0.1501321643590927, 0.623654305934906, -0.13536861538887024, 0.8436471819877625, 0.7611926794052124, 0.7057404518127441, 0.14806844294071198, 0.48417729139328003, -0.7820577025413513, 0.6864680051803589, 0.41014567017555237, 0.5446601510047913, -0.24738501012325287, -0.2483915537595749, -0.48767194151878357, -0.24080197513103485, -0.604901134967804, -0.24799741804599762, -0.4410378932952881, 0.11078374832868576, -0.5970109701156616, -1.0232452154159546, 0.08211764693260193, -0.5646522045135498, -0.0724073201417923, -0.015415344387292862, -0.35476261377334595, -0.6921319961547852, -1.0340769290924072, -1.2864899635314941, -0.43897008895874023, -0.9201677441596985, -0.898543119430542, 0.16359470784664154, 0.028726020827889442, -0.30683469772338867, -0.5810545682907104, -0.32151317596435547, -0.5523320436477661, 1.060633897781372, -0.5575446486473083, 0.5824849009513855, -0.24147967994213104, -0.2846136689186096, -0.04633674398064613, 0.08497539907693863, 0.9167099595069885, 0.2054804563522339, 0.00505335908383131, -0.9519171714782715, 0.24035930633544922, -0.6966530084609985, -0.19135302305221558, 0.2995961904525757, 0.35928717255592346, 0.6407720446586609, 0.4320516884326935, -0.4183006286621094, 0.4207759499549866, 1.2071137428283691, -0.33226871490478516, -0.15755124390125275, 0.07234369218349457, 0.9994897246360779, -0.02589242346584797, -0.051581792533397675, 0.35593166947364807, 0.3021400272846222, 0.86979079246521, -0.06278897821903229, -0.23666726052761078, -0.06795042008161545, -0.7406471967697144, 0.7271531820297241, 1.0342121124267578, 0.3953290581703186, 0.49817124009132385, -0.9332256317138672, 0.7345638275146484, -1.6065016984939575, -0.7949935793876648, 0.6651561260223389, 0.7320019006729126, 0.24793018400669098, -0.5220822095870972, 0.49274420738220215, -0.17687585949897766, 0.42317691445350647, 0.15762144327163696, -0.5413439869880676, -0.6079996824264526, 0.2841000556945801, 0.7592756748199463, 0.4183485507965088, -0.029085494577884674, -0.7037227749824524, 0.4904516935348511, 15.099040031433105, 1.3341909646987915, -0.27152374386787415, 0.5531323552131653, 0.14876602590084076, 0.4890853464603424, 0.13597920536994934, -0.18299630284309387, -0.8417872786521912, 0.08122966438531876, 1.2781747579574585, -0.1641698181629181, 0.8181703686714172, 0.3958769738674164, -0.06334880739450455, 0.31952178478240967, -0.49784401059150696, 1.1454873085021973, 0.33159521222114563, -1.4483155012130737, 0.14297181367874146, 0.28800976276397705, -0.1078435629606247, 0.553230881690979, 0.9617977738380432, 0.548116147518158, 0.4047526717185974, -0.7156558632850647, 0.5547402501106262, 0.17526502907276154, 0.9493449926376343, -0.4011560380458832, 0.3073291480541229, 0.36549851298332214, -1.5496283769607544, -0.0679175853729248, -0.23593804240226746, -0.47576043009757996, 0.24900086224079132, 0.46278390288352966, -1.0818358659744263, -0.20632222294807434, 0.020309705287218094, 1.1743038892745972, 0.31489378213882446, 0.24859508872032166, 0.07528725266456604, 0.5375865697860718, -0.03269946202635765, 0.2279001772403717, 0.13321898877620697, 0.22931990027427673, -0.14789074659347534, 0.4466465413570404, 0.15614566206932068, -0.32219189405441284, 0.3528374135494232, 0.3819954991340637, -0.15816335380077362, 0.03983655944466591, -0.30716416239738464, -0.49735885858535767, -0.3520146906375885, 1.1096075773239136, 0.3214930295944214, 0.26661163568496704, -0.4381750226020813, 0.61465984582901, 0.44915536046028137, 0.21048498153686523, -0.6693817973136902, -0.4352291226387024, 0.7436949014663696, -0.31947335600852966, 0.141732856631279, 0.6771735548973083, 0.004297382198274136, -0.5704312324523926, -0.9169092178344727, -0.2197772115468979, 0.544160783290863, -0.6726269125938416, -1.0435909032821655, 0.6789981722831726, -0.2341010421514511, -0.513222873210907, 0.4161578416824341, -0.8439940810203552, -0.07861850410699844, 0.855679988861084, -1.2583867311477661, -0.7104413509368896, 0.0021028677001595497, 0.023243196308612823, -0.3693293631076813, -0.20025648176670074, 1.131523609161377, 0.2765122056007385, 0.14375069737434387, -0.013020296581089497, -0.22935205698013306, 0.11181769520044327, 0.0003158968174830079, -0.9658944010734558, 1.167587399482727, -0.19368980824947357, 0.10565714538097382, 0.2694461941719055, -0.09719632565975189, 0.03428171947598457, -0.22336219251155853, -0.056314028799533844, 0.06870122998952866, -0.5498232245445251, 0.11803402751684189, -0.7996436953544617, -1.0687204599380493, 0.11298544704914093, 0.2683631479740143, -0.04384063556790352, 0.7480266094207764, 0.1655094027519226, -0.8668650984764099, -0.33766427636146545, -0.4637655019760132, -0.5171758532524109, 0.43992891907691956, -1.2425572872161865, -0.1142827570438385, -0.23886050283908844, -0.12330156564712524, -0.9951589703559875, -0.6156008839607239, -0.04561968520283699, 0.2887072265148163, -0.24702860414981842, 1.2052124738693237, -0.20324957370758057, 0.11529821902513504, 0.5578649044036865, 0.07238896936178207, -1.3702101707458496, -0.052236415445804596, -0.6434195041656494, 0.20696260035037994, -0.31920114159584045, 0.32405373454093933, -0.4291732609272003, 0.41926109790802, 0.059543780982494354, 0.09483703970909119, -0.4797186255455017, -0.32925355434417725, -0.26206108927726746, -0.6024899482727051, -0.33472171425819397, -0.09144769608974457, -0.07545007020235062, 0.08023952692747116, 0.11546111851930618, 0.16980189085006714, -0.07345623522996902, -0.020709874108433723, -0.7364013195037842, 0.09106390923261642, -0.34544119238853455, -0.06241064891219139, -0.5414782166481018, -0.8418211936950684, -1.3374077081680298, 0.07540372759103775, -1.4925954341888428, 0.05723445490002632, -0.6019153594970703, -0.12640830874443054, 0.22523801028728485, -0.35765540599823, 0.11032003909349442, 0.22871524095535278, -0.5626251101493835, -0.3654010593891144, -0.6329614520072937, -0.12870046496391296, 0.7640606164932251, 0.7470131516456604, -0.4472467303276062, 0.17570343613624573, 0.006074442062526941, 0.255744993686676, 0.08536487817764282, 0.21689602732658386, -0.16222596168518066, -1.3132524490356445, -0.22328831255435944, -0.02453966625034809, -0.029027070850133896, 0.15838010609149933, -0.5351232886314392, 0.6720265746116638, 0.28977400064468384, -0.09967812150716782, 0.16172076761722565, 0.4142673909664154, -0.7535503506660461, -0.04132790118455887, 0.2252303510904312, -0.6741315126419067, 0.22316429018974304, 0.024417685344815254, -0.3307512402534485, -0.37340641021728516, 1.0756220817565918, 0.38339778780937195, -0.8175300359725952, -0.8785937428474426, 0.6564059257507324, -0.509266197681427, 0.03800956904888153, 0.06743767857551575, -0.4319913387298584, -0.8618890047073364, -0.3355151116847992, -0.15529459714889526, 0.12634801864624023, -0.4438938796520233, 0.9307127594947815, 0.7047895789146423, -1.6866072416305542, 0.374167799949646, 0.47128722071647644, 0.3746241331100464, -0.4946150779724121, 0.42760002613067627, 0.6637597680091858, 0.019886044785380363, 0.06852403283119202, -0.09832044690847397, 0.14072026312351227, -1.0561517477035522, -0.09862342476844788, 1.109375238418579, -0.06395445019006729, -0.4343735873699188, 0.8956496119499207, -0.14591097831726074, -1.2268208265304565, 0.011884818784892559, -0.9398626089096069, -0.13437265157699585, -0.14123177528381348, 0.5668240189552307, 0.14393699169158936, 0.31978723406791687, -0.06770282983779907, -0.27663499116897583, 0.1878470629453659, 0.06096271052956581, -0.48109170794487, 0.23120427131652832, 0.15770450234413147, -0.10353898257017136, 0.8318936824798584, 0.8436102867126465, -1.136103868484497, -0.6985783576965332, -0.8617597818374634, -0.2238427847623825, -0.3503618538379669, 0.06588109582662582, -0.1418987363576889, -0.5088338255882263, 0.6927719712257385, 0.9059978723526001, 0.3636986315250397, 0.37763240933418274, -0.11309400945901871, 0.37311312556266785, 0.6725936532020569, -0.06765908747911453, -0.8246645927429199, -0.11085901409387589, 1.2738364934921265, 0.8323551416397095, -0.4770665764808655, -0.03790628910064697, -0.5942491292953491, -0.8690803647041321, 1.2442197799682617, -0.04183746129274368, -0.2614811062812805, 1.335191249847412, 0.08160441368818283, 0.18592418730258942, 0.07053646445274353, -0.9073430299758911, -0.44082382321357727, 1.0291452407836914, 1.3804559707641602, 0.4737071692943573, 0.4179302453994751, 0.6795225143432617, 0.338218092918396, 0.1745898276567459, 0.07132008671760559, 0.24361753463745117, 0.2881162464618683, -0.5884503126144409, -0.28557151556015015, 0.22742950916290283, 1.0418776273727417, -0.6413423418998718, -0.4153177738189697, 0.17151480913162231, 0.4850251078605652, 0.12221841514110565, 0.08170174807310104, 0.7008899450302124, -0.531108558177948, 0.9025482535362244, 0.34119221568107605, 0.35071679949760437, -0.4942099153995514, -0.34664201736450195, -0.0885402113199234, -0.5243633389472961, -0.18307314813137054, -0.3021695017814636, -0.5586774945259094, -0.614016056060791, -0.33665376901626587, 0.2966766059398651, 0.1965271681547165, 0.28641989827156067, 0.7696097493171692, 0.2564886212348938, 0.3814640939235687, -0.17336051166057587, -0.19435164332389832, -0.6617453098297119, -0.7967696189880371, -0.5190874338150024, -0.21353375911712646, -0.08201374858617783, -0.6079249978065491, 0.0061910925433039665, 0.005824785679578781]}, "authors": [{"authorId": "2105636395", "name": "Sankalan Pal Chowdhury"}, {"authorId": "2133327863", "name": "Adamos Solomou"}, {"authorId": "89890133", "name": "Kumar Avinava Dubey"}, {"authorId": "2790926", "name": "Mrinmaya Sachan"}], "references": [{"paperId": "94e46e18d2628343a926acf6c3d0817e11d35d58", "title": "ERNIE-SPARSE: Learning Hierarchical Efficient Transformer Through Regularized Self-Attention"}, {"paperId": "e2ee883fca5f8f32a1dfa2dc06c742d57f2c38b9", "title": "Linearizing Transformer with Key-Value Memory"}, {"paperId": "1900de2b966ca55ee5ca24ec94d5debe66e80c5b", "title": "Dynamic N:M Fine-Grained Structured Sparse Attention Mechanism"}, {"paperId": "dc0102a51a9d33e104a4a3808a18cf17f057228c", "title": "Transformer Quality in Linear Time"}, {"paperId": "c49ac1f916d6d2edeb187e6619c8d23acd95eb21", "title": "cosFormer: Rethinking Softmax in Attention"}, {"paperId": "a68ab49816d5729435c3d994b434c75c6f162da0", "title": "Sketching as a Tool for Understanding and Accelerating Self-attention for Long Sequences"}, {"paperId": "2e644c67a697073d561da4f4dad35e5ad5316cfd", "title": "SOFT: Softmax-free Transformer with Linear Complexity"}, {"paperId": "f27e8c4731c575bd5f5db4c93ad8588f684dcbd0", "title": "Hybrid Random Features"}, {"paperId": "605c69f22a2be97e18478987c69be29d596a3dd2", "title": "Redesigning the Transformer Architecture with Insights from Multi-particle Dynamical Systems"}, {"paperId": "bb363c8c5bc1c473f0801c647c88d0c071792858", "title": "PermuteFormer: Efficient Relative Position Encoding for Long Sequences"}, {"paperId": "37abe53ed31caa23ae833b2e67bb4aa1892e8d25", "title": "FMMformer: Efficient and Flexible Transformer via Decomposed Near-field and Far-field Attention"}, {"paperId": "1a883522f3c0051d70be1f8cbdb8989a77395006", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision"}, {"paperId": "0d508600d77d8a7e6a655cdb6d139779732f649f", "title": "Stable, Fast and Accurate: Kernelized Attention with Relative Positional Encoding"}, {"paperId": "c1a4278f969acfc6682a924e31b95e1ade9703ee", "title": "Memory-efficient Transformers via Top-k Attention"}, {"paperId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "title": "Luna: Linear Unified Nested Attention"}, {"paperId": "e32a12b14e212506115cc6804667b3d8297917e1", "title": "Poolingformer: Long Document Modeling with Pooling Attention"}, {"paperId": "988a1ab0c1ebd7eb4817fbc8ce41f962dd519998", "title": "An introduction to deep generative modeling"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "1a703f08da01cf737cce3fb9064259b3f4b44e9c", "title": "Linear Transformers Are Secretly Fast Weight Programmers"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "7e5709d81558d3ef4265de29ea75931afeb1f2dd", "title": "Efficient Transformers: A Survey"}, {"paperId": "e7559868430aa50748d38c4c9edaeeae6907a57f", "title": "End-to-end Kernel Learning via Generative Random Fourier Features"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "e3794413679237f7a9a2f7e03eb7ea2ccac0ae93", "title": "Synthesizer: Rethinking Self-Attention for Transformer Models"}, {"paperId": "a238109c3969ae681eee0d4f1bf2012f28850593", "title": "Synthesizer: Rethinking Self-Attention in Transformer Models"}, {"paperId": "7adfcbbe8b2e38c18ebab891826957da515d1261", "title": "Random Features for Kernel Approximation: A Survey on Algorithms, Theory, and Beyond"}, {"paperId": "baed71eed57ad462f3ab138d4b1700a738cd5414", "title": "ETC: Encoding Long and Structured Data in Transformers"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "c5f7074a264356c9a022a8dff24df79d1db8c3d3", "title": "ProGen: Language Modeling for Protein Generation"}, {"paperId": "34a4e6818d680875ff0bef9a76de0376118446d1", "title": "Sparse Sinkhorn Attention"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "2e14e84ccec924ed770b58108ad1d9de6f0ca295", "title": "BP-Transformer: Modelling Long-Range Context via Binary Partitioning"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "8cef9900c04d7f661c08f4b5b1ed4337ace042a3", "title": "Transformer Dissection: An Unified Understanding for Transformer\u2019s Attention via the Lens of Kernel"}, {"paperId": "65a9c7b0800c86a196bc14e7621ff895cc6ab287", "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "18a93dc1558bf9d7534d0b416633cebaf75c1145", "title": "Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "a9ec03dbe702f6909acd1f1f14a3395d0141043b", "title": "Generative Models for Graph-Based Protein Design"}, {"paperId": "ceffe91d252f8b56088f4f90cda9855402c38de3", "title": "Implicit Kernel Learning"}, {"paperId": "3694381e74445a8b9f8cb8d373e39626e47191b5", "title": "On the Turing Completeness of Modern Neural Network Architectures"}, {"paperId": "c48277b4dee7d975e3b00afde590e6bf1f95e8e1", "title": "Harmonizable mixture kernels with variational Fourier features"}, {"paperId": "de8a2fc8f9727511c521fd8a35a35063cce3739d", "title": "But How Does It Work in Theory? Linear SVM with Random Features"}, {"paperId": "348695bf8ee095877dc619ab4962059275b604f9", "title": "Learning Data-adaptive Nonparametric Kernels"}, {"paperId": "a4347c48b9ac5ed5bc521e30694f752c87d07c83", "title": "Towards a Unified Analysis of Random Fourier Features"}, {"paperId": "e48c537c997ff46632dcce888dca72bcc89d72d1", "title": "On GANs and GMMs"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "8691706ad0cf5e83969658b2e6bfffdc379440c9", "title": "Generating Wikipedia by Summarizing Long Sequences"}, {"paperId": "40dc2de4f461b0a673d35df49cd4d54b4c9865a5", "title": "Not-So-Random Features"}, {"paperId": "169895d3a9ed3c4383bb71f27ade94e94695b172", "title": "Gaussian Quadrature for Kernel Features"}, {"paperId": "b6e7cce12b7b0327c164602b5a328fb209506296", "title": "Spherical Structured Feature Maps for Kernel Approximation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "8763d92426ef10f87047c73a6639ed54f4e982ed", "title": "Non-Stationary Spectral Kernels"}, {"paperId": "5394da74498e00597295d18cd0557bd47e3fc341", "title": "The Unreasonable Effectiveness of Structured Random Orthogonal Embeddings"}, {"paperId": "32e934094c4d17fe4d734b2e169ba5e3cd0ee05e", "title": "Orthogonal Random Features"}, {"paperId": "efbd381493bb9636f489b965a2034d529cd56bcd", "title": "Pointer Sentinel Mixture Models"}, {"paperId": "c6850869aa5e78a107c378d2e8bfa39633158c0c", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"}, {"paperId": "559faf4b49ef3f317e894f7ba3947d1769bdeb8c", "title": "Recycling Randomness with Structure for Sublinear time Kernel Expansions"}, {"paperId": "da0d28ce5dec996020e15243ad6099de717ca3b9", "title": "Linearized GMM Kernels and Normalized Random Fourier Features"}, {"paperId": "a04434c379f03cb4db02f71c313a417b363a31dc", "title": "Random Feature Mapping with Signed Circulant Matrix Projection"}, {"paperId": "0887e7721f526e75488babf464bee51c5cbbcbda", "title": "Bayesian Nonparametric Kernel-Learning"}, {"paperId": "78e95099ec2ac3cb087eb47ba7c87ddb01a19405", "title": "On the Error of Random Fourier Features"}, {"paperId": "3b941fb8827a4436474b202eba28cfef4ac446c7", "title": "Generalized Spectral Kernels"}, {"paperId": "08d8758581af226e678a6b0dd9d4646d129f205d", "title": "A la Carte - Learning Fast Kernels"}, {"paperId": "2b55f034a3874ad4a4b7f389e6f89e3bf2d1801e", "title": "Quasi-Monte Carlo Feature Maps for Shift-Invariant Kernels"}, {"paperId": "5f5dc5b9a2ba710937e2c413b37b053cd673df02", "title": "Auto-Encoding Variational Bayes"}, {"paperId": "a3b39efea137930d7534baa40c480324fba1e84c", "title": "A Divide-and-Conquer Solver for Kernel Support Vector Machines"}, {"paperId": "8685982bef8a77d48b25baf7b531481470075c13", "title": "Divide and Conquer Kernel Ridge Regression"}, {"paperId": "8ce9de8009d7186a16804e55ad7d2d8ce595d350", "title": "Fastfood - Computing Hilbert Space Expansions in loglinear time"}, {"paperId": "71ec2c3f28e5833fbf2b29967982969ac4ddc24e", "title": "Gaussian Process Kernels for Pattern Discovery and Extrapolation"}, {"paperId": "7a59fde27461a3ef4a21a249cc403d0d96e4a0d7", "title": "Random Features for Large-Scale Kernel Machines"}, {"paperId": "d37fc9e9c4fedc32865b08661e7fb950df1f8fbe", "title": "Kernel methods in machine learning"}, {"paperId": "fc8cda36a0972e7de1ac3a7bcb81dc32da79bee4", "title": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond"}, {"paperId": "36aa0d0936b2cf128c646c36a1981807b5a27aaf", "title": "On Kernel-Target Alignment"}, {"paperId": "9ded923a192ffbf13e4466c6b7d2ede55724b716", "title": "Sparse Greedy Matrix Approximation for Machine Learning"}, {"paperId": "3f600e6c6cf93e78c9e6e690443d6d22c4bf18b9", "title": "Nonlinear Component Analysis as a Kernel Eigenvalue Problem"}, {"paperId": "43ffa2c1a06a76e58a333f2e7d0bd498b24365ca", "title": "Support Vector Method for Function Approximation, Regression Estimation and Signal Processing"}, {"paperId": "52b7bf3ba59b31f362aa07f957f1543a29a4279e", "title": "Support-Vector Networks"}, {"paperId": "87d57bdc1ca3f0d715f4230246596669bfda7690", "title": "Nomenclature for the presentation of results of chemical analysis (IUPAC Recommendations 1994)"}, {"paperId": "729cb7a620b4e81b63b281627474020cdfbadd39", "title": "Density Estimation for Statistics and Data Analysis"}, {"paperId": "7838d046f296235cb0bbab0a190d539e8debb25a", "title": "Fourier Analysis on Groups."}, {"paperId": "92d5f6f2d13484c688ca4c08c1279229ba266089", "title": "Handbook of Mathematical Functions With Formulas, Graphs and Mathematical Tables (National Bureau of Standards Applied Mathematics Series No. 55)"}, {"paperId": "c49c292e1fb1d215c88828a52134b7ccfa52be44", "title": "Sparse Attention with Learning to Hash"}, {"paperId": null, "title": "Simpletron: Eliminating softmax from attention computation, 2021"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035", "title": "Improving Language Understanding by Generative Pre-Training"}, {"paperId": "c68796f833a7151f0a63d1d1608dc902b4fdc9b6", "title": "GENERATIVE ADVERSARIAL NETS"}, {"paperId": "1b3f270394b386d3dc994e2a4b78cd05872bcfca", "title": "Learning Kernels with Random Features"}, {"paperId": "07d51270eeec0aee3f50a085c2e75b3ed04221a1", "title": "Laws of Large Numbers"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "b6fff8b8ea77f157913986e7af53951d9fc1128e", "title": "Using the Nystr\u00f6m Method to Speed Up Kernel Machines"}, {"paperId": "267d384a9a5b348cd6073e49f8b5bc288a21712f", "title": "Handbook of Mathematical Functions with Formulas, Graphs,"}, {"paperId": null, "title": ": Rethinking softmax"}]}