{"paperId": "f6390beca54411b06f3bde424fb983a451789733", "abstract": "Attention mechanisms have become ubiquitous in NLP. Recent architectures, notably the Transformer, learn powerful context-aware word representations through layered, multi-headed attention. The multiple heads learn diverse types of word relationships. However, with standard softmax attention, all attention heads are dense, assigning a non-zero weight to all context words. In this work, we introduce the adaptively sparse Transformer, wherein attention heads have flexible, context-dependent sparsity patterns. This sparsity is accomplished by replacing softmax with alpha-entmax: a differentiable generalization of softmax that allows low-scoring words to receive precisely zero weight. Moreover, we derive a method to automatically learn the alpha parameter \u2013 which controls the shape and sparsity of alpha-entmax \u2013 allowing attention heads to choose between focused or spread-out behavior. Our adaptively sparse Transformer improves interpretability and head diversity when compared to softmax Transformers on machine translation datasets. Findings of the quantitative and qualitative analysis of our approach include that heads in different layers learn different sparsity preferences and tend to be more diverse in their attention distributions than softmax Transformers. Furthermore, at no cost in accuracy, sparsity in attention heads helps to uncover different head specializations.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2019, "citationCount": 206, "influentialCitationCount": 19, "openAccessPdf": {"url": "https://arxiv.org/pdf/1909.00015", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "This work introduces the adaptively sparse Transformer, wherein attention heads have flexible, context-dependent sparsity patterns, accomplished by replacing softmax with alpha-entmax: a differentiable generalization of softmax that allows low-scoring words to receive precisely zero weight."}, "embedding": {"model": "specter_v2", "vector": [0.23977722227573395, 0.938378632068634, -0.8836583495140076, -0.13558807969093323, -0.1828801929950714, -0.1846444308757782, 0.6173096895217896, -0.3225538432598114, 0.010425704531371593, 0.030391104519367218, 0.9306859374046326, -0.13833089172840118, 0.20873507857322693, 0.25770822167396545, -0.1468752920627594, 0.0008640607120469213, -0.4972061514854431, 0.5769785046577454, -0.15060704946517944, -0.5941924452781677, -0.21116752922534943, -1.09846031665802, -0.5178872346878052, 0.11779476702213287, 0.4979957938194275, 0.39104974269866943, 0.5460073947906494, 0.7207583785057068, -0.66212397813797, 0.3983081579208374, 0.37133848667144775, -0.6286989450454712, 0.026844004169106483, -0.1007128655910492, -0.043687496334314346, -0.15270785987377167, 0.382630854845047, 0.03941627964377403, -0.15264351665973663, 0.9816747903823853, -0.4328954517841339, -0.05509102717041969, 0.593844473361969, -0.324482262134552, -0.7446982860565186, 1.3548271656036377, 0.5625286102294922, 0.9051280617713928, -0.031205790117383003, -0.6910821199417114, 1.8439092636108398, -1.4273910522460938, 0.21512047946453094, 1.5358432531356812, 0.28345978260040283, 0.0787893757224083, -0.03283604979515076, -0.48745644092559814, 0.7761884927749634, 0.4227529466152191, -0.840043306350708, -0.5632907748222351, -0.14900784194469452, 0.05050713196396828, 2.05898118019104, -0.3831261396408081, -0.20862853527069092, 0.6308059692382812, 0.23108477890491486, 1.448225975036621, -0.009260443039238453, -1.0548382997512817, -0.33868488669395447, -0.05442240461707115, 0.02309020794928074, 0.6631860733032227, -0.3624345660209656, -0.04141613095998764, -1.080244541168213, -0.1891910433769226, 0.37404197454452515, -0.1424330770969391, -0.3319467306137085, 0.12541106343269348, -0.34325486421585083, 0.6694196462631226, 0.4490859806537628, 0.8340305089950562, -0.530073344707489, 0.4237397313117981, 0.15764497220516205, 0.26934418082237244, 0.011648951098322868, 0.48700663447380066, -0.6066165566444397, 0.48515409231185913, -1.0932236909866333, 0.020107220858335495, 0.3632446825504303, 1.1345734596252441, -0.3292330205440521, 0.13249675929546356, -0.8260934352874756, 0.2141459584236145, 1.525752305984497, 0.3586641252040863, 0.42942285537719727, -0.14660634100437164, 0.26601681113243103, -0.49784883856773376, 0.03315744921565056, -0.8945717215538025, -0.18490026891231537, -0.5398859977722168, -0.5303675532341003, -1.3751312494277954, -0.5162795186042786, -0.032666098326444626, -0.8035690784454346, 0.8487568497657776, -0.47433188557624817, -0.08306140452623367, -0.29043954610824585, 0.6383877992630005, 0.30217280983924866, 0.6705451011657715, 0.2960749864578247, 0.025259504094719887, 0.9920157790184021, -0.49956613779067993, -1.0930509567260742, -1.357912540435791, 0.7353824973106384, -0.5713457465171814, 0.3907708525657654, -0.2894616723060608, -1.2023223638534546, -0.29842573404312134, -0.6615706086158752, -0.1464737057685852, -0.409680038690567, 0.485501766204834, 0.8342742323875427, 0.40926265716552734, -0.851577877998352, 0.3739723265171051, -0.17005854845046997, -0.1286221295595169, 0.5452969670295715, 0.22760064899921417, 0.4260203540325165, -0.47400057315826416, -1.3235268592834473, 0.6575223207473755, 0.1890995055437088, -0.6340919733047485, 0.20849037170410156, -0.5061628222465515, -1.224754810333252, 0.3616607189178467, 0.4598813056945801, -0.5682294964790344, 1.2875553369522095, -0.5651863813400269, -1.3513553142547607, 0.5800538063049316, -0.7009628415107727, 0.5234473943710327, -0.3038488030433655, -0.392770916223526, -0.4859284460544586, -0.9109607934951782, 0.11029797792434692, 0.11273743957281113, 0.5745577812194824, 0.09854816645383835, -0.33177244663238525, 0.18763777613639832, -0.34481802582740784, -0.13041792809963226, -0.32358595728874207, 1.1097760200500488, -0.27211281657218933, -0.30459970235824585, 0.0012722847750410438, 0.813554584980011, 0.27999308705329895, -0.43575888872146606, -0.3857647180557251, -1.204976201057434, 0.5229215025901794, -0.02050965465605259, 1.22987961769104, -0.653271496295929, -0.021186528727412224, -0.010163974016904831, -0.11889731884002686, -0.06147237867116928, -0.5786226391792297, 0.4279170334339142, -0.2659120559692383, 0.20977917313575745, -0.29231926798820496, -1.0249971151351929, 0.24348925054073334, 0.2753395736217499, -0.6627024412155151, -0.16655971109867096, 0.19731201231479645, 1.2713098526000977, -0.7308229804039001, -0.04660847410559654, 0.008695203810930252, 0.20863477885723114, -0.9337324500083923, 1.1187080144882202, -0.6228817701339722, -0.18484362959861755, -0.0910467579960823, 0.3078695237636566, -0.12144695967435837, -0.5660698413848877, 0.42089855670928955, -0.3726096749305725, 0.10227219760417938, 0.5019786357879639, -0.18124447762966156, 1.0320242643356323, -0.393283873796463, 0.6196604371070862, 0.10855399817228317, -0.6678454875946045, -0.02554463967680931, 0.5834835767745972, -0.5440752506256104, -0.5425252318382263, 0.5178506970405579, 0.6486834287643433, -0.6449344754219055, 0.11545241624116898, 0.8305531740188599, 0.5815477967262268, -0.25378307700157166, -0.3262774348258972, 0.9109479784965515, -0.10166087746620178, 0.17128035426139832, 0.18234826624393463, 0.5069082975387573, 0.29530441761016846, 0.7417004704475403, -0.28328123688697815, 0.059526026248931885, -0.7170021533966064, -0.012447601184248924, 0.17546521127223969, 0.9867748022079468, 0.7279318571090698, 0.6390163898468018, -0.4804231524467468, -0.2850925028324127, 0.44541484117507935, 0.6007969975471497, 2.1195321083068848, -0.23580199480056763, -0.30431750416755676, -0.5075637102127075, -0.30670708417892456, -0.40838220715522766, 0.26717543601989746, -0.40962061285972595, 0.08173567056655884, -0.6724868416786194, -1.0315865278244019, 0.5366268157958984, 0.12508754432201385, 0.39573729038238525, -0.4138216972351074, 0.06509662419557571, -0.2857643663883209, 0.024047430604696274, -0.9886596202850342, -0.7572713494300842, 0.5368674993515015, -0.15088129043579102, -0.03350518271327019, -0.15362827479839325, -0.30339041352272034, 0.05382100120186806, -0.9994133710861206, 1.4775257110595703, -0.5645712614059448, 0.29996490478515625, 0.014406059868633747, 0.21305465698242188, -0.8363416194915771, -0.2863893210887909, 0.41367530822753906, 0.09357713907957077, -0.05687791109085083, 0.7220476865768433, 0.42139777541160583, 0.10099241137504578, 0.08451742678880692, -0.33627140522003174, -0.0938320979475975, 0.23098008334636688, 0.08150401711463928, 0.6572096943855286, -0.7110874652862549, 0.049292754381895065, -1.15351140499115, 0.6914879083633423, -0.4627564251422882, -0.37613898515701294, 0.3098579943180084, -0.43131884932518005, -0.4574807584285736, 0.540720522403717, -0.6024599671363831, -0.4034160375595093, -0.7763492465019226, 0.30169162154197693, -0.14762240648269653, -0.018414143472909927, 0.6405659317970276, 0.09828584641218185, 0.25921326875686646, 0.4624612033367157, 0.38017648458480835, 0.03609349951148033, -0.10818412154912949, 0.6847720146179199, -0.5372371673583984, 0.3995419144630432, 0.4345513880252838, -0.12143529206514359, -0.4960781931877136, -0.32224705815315247, -0.7940694093704224, -0.5635855793952942, -0.34557318687438965, 0.11762165278196335, 0.11650702357292175, 0.318177193403244, -0.3623538613319397, -0.5723157525062561, -0.4298008680343628, -1.1198434829711914, -0.13805601000785828, 0.12032704055309296, -0.1395677924156189, 0.09151452034711838, -1.23490309715271, -1.0630674362182617, -0.2839773893356323, -0.4360556900501251, -0.7526525855064392, 0.7446511387825012, 0.21290691196918488, -0.6624544262886047, -0.9147491455078125, -0.014209541492164135, -0.5293262600898743, 1.2247182130813599, -0.8151174783706665, 0.9362075924873352, -0.0801924392580986, -0.2958372235298157, -0.2783510386943817, 0.30707910656929016, 0.1330525428056717, -0.16428124904632568, 0.03192855045199394, -0.5777001976966858, 0.5538309216499329, -0.31908032298088074, -0.20482048392295837, -0.23165220022201538, 0.852178156375885, 0.21828310191631317, -0.40205299854278564, -0.5977429747581482, 0.5160813927650452, 1.2201662063598633, -1.0269750356674194, -0.08404605090618134, 0.20986664295196533, 0.957155704498291, 0.22769229114055634, -0.5130054950714111, 0.532830536365509, 0.6690207123756409, 0.5520076751708984, 0.6235182881355286, -0.2057318240404129, -0.25713875889778137, -0.5481036901473999, 0.6703022122383118, 1.653584361076355, 0.05854983255267143, -0.3048936426639557, -0.9029203057289124, 0.772707462310791, -1.3740887641906738, -0.6336965560913086, 0.21399295330047607, 0.3758917450904846, 0.5153152346611023, -0.6996262073516846, -0.5591272115707397, -0.7276284694671631, 0.30200469493865967, 0.18333545327186584, -0.1061028242111206, -0.5799689292907715, -0.2562392055988312, 0.6465845704078674, 0.5020889639854431, 0.8236509561538696, -0.09987269341945648, 0.7908862829208374, 14.881635665893555, 0.824148416519165, -0.028309503570199013, 0.8091980218887329, 0.36093494296073914, 0.07792060077190399, -0.5535063743591309, -0.14689278602600098, -1.4337286949157715, 0.17236432433128357, 0.6781986951828003, 0.18962447345256805, 0.4554256796836853, 0.14835825562477112, -0.0643865317106247, 0.4256201386451721, -0.44787952303886414, 0.7987774610519409, 0.7715612053871155, -1.2003881931304932, 0.40350082516670227, 0.11830268800258636, 0.5852985978126526, 0.6384793519973755, 0.6191953420639038, 0.7423260807991028, 0.5592619776725769, -0.7555735111236572, 0.5093546509742737, 0.30789363384246826, 0.6478695869445801, 0.2584819197654724, 0.6578776240348816, 0.5441836714744568, -0.6875373125076294, -0.23243264853954315, -0.5520370602607727, -1.2571690082550049, 0.4521559774875641, 0.46365541219711304, -0.34104281663894653, -0.5635080933570862, -0.3471827208995819, 0.750582754611969, 0.2704392671585083, 0.19845406711101532, -0.69325852394104, 0.8890710473060608, -0.310130774974823, -0.16835834085941315, 0.44834837317466736, 0.685044527053833, 0.5822242498397827, 0.4486374855041504, 0.2706487774848938, -0.05853112414479256, 0.1956801414489746, 0.6985955834388733, -0.6172138452529907, 0.14798085391521454, -0.10967466980218887, -0.31483832001686096, 0.005522037856280804, 0.7567728757858276, 0.6891874074935913, 0.03580234944820404, -0.4953921139240265, 0.4610598683357239, 0.5571238994598389, 0.24792104959487915, 0.20821981132030487, -0.09243281930685043, 0.28113263845443726, -0.23574396967887878, 0.14423196017742157, 0.6491210460662842, -0.5253060460090637, -0.6490904092788696, -0.5840194821357727, -0.4795728623867035, 0.5512311458587646, -0.9297168254852295, -0.9845519661903381, 0.6118678450584412, -0.24464206397533417, -0.22014859318733215, 0.02463962882757187, -1.0298519134521484, -0.052912116050720215, 0.6910131573677063, -1.3988239765167236, -0.8969007134437561, 0.363777756690979, -0.1430933177471161, -0.10792146623134613, -0.27369824051856995, 1.3224633932113647, -0.042067527770996094, -0.2694740295410156, 0.16710884869098663, 0.015864066779613495, -0.1678537130355835, -0.17625173926353455, -1.0483627319335938, 0.5472990274429321, 0.1729399859905243, -0.24439674615859985, 0.4605005979537964, 0.3414519429206848, 0.03657906502485275, -0.7335788607597351, 0.4047008156776428, 1.338657259941101, -1.0205719470977783, -0.3353540897369385, -0.36601611971855164, -0.8195629119873047, 0.6000673174858093, 0.9322188496589661, -0.23099148273468018, 0.5296034812927246, 0.5984068512916565, -0.3368648886680603, 0.2915273606777191, -0.6785319447517395, -0.04228191077709198, 0.1995583474636078, -0.5606057643890381, -0.9157763719558716, 0.06606490910053253, 0.24649254977703094, -1.0527268648147583, -0.3255736827850342, -0.40514862537384033, 0.032913509756326675, 0.340705543756485, 0.6403050422668457, -0.5873590707778931, 0.7670514583587646, 0.765592634677887, -0.5152198672294617, -1.1398906707763672, -0.35512280464172363, -0.8251542448997498, -0.48059991002082825, -0.10963629931211472, 0.9738702774047852, -0.44323375821113586, -0.008200078271329403, 0.7593610882759094, 0.02056235820055008, -0.4566711485385895, -0.6930086016654968, -0.026689382269978523, -0.004234632942825556, -0.27804461121559143, 0.24945397675037384, 0.3802424371242523, 0.268634557723999, 0.3564372956752777, 0.3503066599369049, 0.652719259262085, -0.09388125687837601, -0.9755575060844421, -0.1282162219285965, -0.10452506691217422, -0.3612132966518402, -0.6607275009155273, -0.5574804544448853, -1.7457484006881714, -0.0016009529354050756, -1.142826795578003, 0.012490039691329002, -0.9781399965286255, -0.4144692122936249, 0.30772334337234497, -0.2758483588695526, 0.3749431371688843, 0.029285116121172905, -0.19955311715602875, -0.5395446419715881, -0.37775272130966187, -0.3177124261856079, 0.801879346370697, 0.8222761154174805, -0.45175084471702576, 0.20904003083705902, 0.04869818687438965, -0.3224726617336273, 0.47001752257347107, 0.35186856985092163, -0.46656545996665955, -0.43740713596343994, -1.533687949180603, 0.9304258227348328, -0.30765479803085327, -0.08961499482393265, 0.005905988160520792, 0.69163978099823, 0.2232188880443573, -0.15440794825553894, 0.2692277133464813, 0.2619480788707733, -1.0572439432144165, -0.7590450644493103, -0.22157759964466095, -0.6180406212806702, 0.12604780495166779, -0.08517368137836456, -0.7034922242164612, -0.28315165638923645, 0.6255381107330322, -0.2241637408733368, -1.1067965030670166, -0.41121262311935425, 0.2529832124710083, -0.4593866169452667, 0.2869790196418762, -0.4277417063713074, -0.2792007327079773, -1.1022791862487793, -0.4946611523628235, 0.08429419994354248, 0.32240059971809387, -0.4091053605079651, 0.907758891582489, 0.1761268526315689, -1.1406736373901367, -0.07066083699464798, 0.39070799946784973, -0.0038875374011695385, 0.08061131089925766, -0.0480680987238884, 0.5090473294258118, -0.1191716268658638, 0.591715931892395, 0.4601811170578003, 0.010028720833361149, -0.7399148941040039, -0.47315311431884766, 0.7963239550590515, -0.219918355345726, -0.2423739731311798, 1.192880392074585, -0.31744587421417236, -0.9671039581298828, -0.015986045822501183, -1.3961290121078491, -0.5362724661827087, -0.302423894405365, 0.6229738593101501, -0.17589467763900757, -0.041333071887493134, -0.43014636635780334, -0.6524586081504822, 0.32541441917419434, 0.08455706387758255, -0.18311884999275208, 0.726093590259552, -0.2701764404773712, -0.56569504737854, 0.3353481590747833, 0.5373424887657166, -0.5355231165885925, -0.2672905921936035, -0.9676691889762878, -0.15281076729297638, -0.14256557822227478, 0.6241037249565125, -0.6124275326728821, -0.4359806180000305, 0.48346900939941406, 0.21023999154567719, 0.35425424575805664, 0.17265239357948303, 0.39473459124565125, 0.025875817984342575, 0.5513741970062256, -0.08790667355060577, -0.551577627658844, -0.8613731861114502, 1.6862298250198364, 1.3700672388076782, -0.9349443912506104, 0.040765948593616486, -0.2686031758785248, -0.6798567771911621, 0.8552976846694946, -0.038324836641550064, 0.2526358366012573, 0.8378539681434631, 0.020539416000247, 0.0239081010222435, -0.2929564416408539, -0.8454261422157288, -0.36374005675315857, 1.031383752822876, 0.9480839371681213, 1.1276941299438477, 0.5220703482627869, -0.044912368059158325, 0.9343419671058655, -0.2200651466846466, 0.3160897493362427, 0.31919440627098083, 0.334344744682312, -0.4128884971141815, -0.09395081549882889, -0.11969629675149918, 0.6023554801940918, -0.9611104726791382, -0.8908074498176575, -0.34043067693710327, 0.28799137473106384, 0.1638297438621521, 0.5437095761299133, 0.5112270712852478, 0.34711235761642456, 0.7255251407623291, 0.2609139680862427, 0.30740708112716675, -0.7410553097724915, -0.10499516874551773, -0.2953481078147888, -0.7218891978263855, -0.18168407678604126, -0.15510888397693634, -0.17250864207744598, -0.023723440244793892, -0.23602770268917084, 0.11734333634376526, -0.3470974266529083, 0.31499743461608887, 1.4365103244781494, 0.5674108266830444, 0.42207497358322144, -0.4289923906326294, -0.5660702586174011, -0.258721262216568, -1.2504770755767822, 0.10885798931121826, -0.5591542720794678, -0.0048234108835458755, -0.13207529485225677, -0.21508845686912537, -0.23226022720336914]}, "authors": [{"authorId": "146783606", "name": "Gon\u00e7alo M. Correia"}, {"authorId": "2114966", "name": "Vlad Niculae"}, {"authorId": "145644643", "name": "Andr\u00e9 F. T. Martins"}], "references": [{"paperId": "07a64686ce8e43ac475a8d820a8a9f1d87989583", "title": "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"}, {"paperId": "f4238bd2385a52413ccbacfd9e409a650235bd13", "title": "Adaptive Attention Span in Transformers"}, {"paperId": "97906df07855b029b7aae7c2a1c6c5e8df1d531c", "title": "BERT Rediscovers the Classical NLP Pipeline"}, {"paperId": "3cee801d10f410f0feb1a2390776a01ba2765001", "title": "Sparse Sequence-to-Sequence Models"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "17298b0b53c0b62b737f8c7c086b428f4f3b5057", "title": "Selective Attention for Context-aware Neural Machine Translation"}, {"paperId": "8eabed69bbebd83d90c7c27b731ff76edcd6b0a9", "title": "SSN: Learning Sparse Switchable Normalization via SparsestMax"}, {"paperId": "1e83c20def5c84efa6d4a0d80aa3159f55cb9c3f", "title": "Attention is not Explanation"}, {"paperId": "fea820b7d953d32069e189af2961c28fd213470b", "title": "Pay Less Attention with Lightweight and Dynamic Convolutions"}, {"paperId": "49400b3a3ea01772e321e3e010b7b891c3d6cb88", "title": "Extracting Syntactic Trees from Transformer Encoder Self-Attentions"}, {"paperId": "fdbdd4e0461d23905104460a02a176907d945f44", "title": "Multi-Head Attention with Disagreement Regularization"}, {"paperId": "e3ee61f49cd2639c15c8662a45f1d0c2b83a60c1", "title": "Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures"}, {"paperId": "01ffd50b3b82c7adac54d15cb84944b87c32525f", "title": "Latent Alignment and Variational Attention"}, {"paperId": "bf8fe437f779f2098f9af82b534aa51dc9edb06f", "title": "Scaling Neural Machine Translation"}, {"paperId": "ad796bf779c8617d1e0d8111913ac3f8eaaf6532", "title": "Context-Aware Neural Machine Translation Learns Anaphora Resolution"}, {"paperId": "c9552f9e2a7a7656c4c9ef9569a824dffa1fd181", "title": "Learning Classifiers with Fenchel-Young Losses: Generalized Entropies, Margins, and Algorithms"}, {"paperId": "520ddb38b59b8fae2209ddc7c6640462cf153eec", "title": "Sparse and Constrained Attention for Neural Machine Translation"}, {"paperId": "03f8754ab20732ebda02ce6e65ec9bfcce17528a", "title": "Marian: Cost-effective High-Quality Neural Machine Translation in C++"}, {"paperId": "2ec7156913117949ab933f27f492d0149bc0031f", "title": "Learning Sparse Neural Networks through L0 Regularization"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "ba6b48ef52e2432a0d6342381e0863fd82a8687b", "title": "A Regularized Framework for Sparse and Structured Neural Attention"}, {"paperId": "0076b232181e4e5be58dce8354a813ad2bbf663a", "title": "OptNet: Differentiable Optimization as a Layer in Neural Networks"}, {"paperId": "1a327709cc53ff9e52454e50a643abf4a0ac92af", "title": "Findings of the 2016 Conference on Machine Translation"}, {"paperId": "46f281810693e7c4c9741817ce2ebe021cf4be04", "title": "On Differentiating Parameterized Argmin and Argmax Problems with Application to Bi-level Optimization"}, {"paperId": "c1e3a26fb88c6720f4e84b7118e6f2df7dc8efa3", "title": "From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification"}, {"paperId": "1518039b5001f1836565215eb047526b3ac7f462", "title": "Neural Machine Translation of Rare Words with Subword Units"}, {"paperId": "93499a7c7f699b6630a86fad964536f9423bb6d0", "title": "Effective Approaches to Attention-based Neural Machine Translation"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "5ec85a0d88adcc4344bb5cc81b0d1aef9bcd8dcc", "title": "Findings of the 2014 Workshop on Statistical Machine Translation"}, {"paperId": "7de66a09cd23f05859a95fa55616b515acab71e9", "title": "Findings of the 2013 Workshop on Statistical Machine Translation"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "b20c0758a38bd5a4083f64eff53af924499a8e29", "title": "Possible generalization of Boltzmann-Gibbs statistics"}, {"paperId": "0054d6bb763b29b6f21ee6aabf7cf39bfa13682b", "title": "Validation of subgradient optimization"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "94238dead40b12735d79ed63e29ead70730261a2", "title": "An Analysis of Encoder Representations in Transformer-Based Machine Translation"}, {"paperId": "cb0ab255c4079e2082ba6e3a807529527d96687c", "title": "Overview of the IWSLT 2017 Evaluation Campaign"}, {"paperId": null, "title": "The Kyoto free translation task"}, {"paperId": "849a2f9fff249cb5c7356aa6b8f4a7c43ce74746", "title": "Optimization And Nonsmooth Analysis"}]}