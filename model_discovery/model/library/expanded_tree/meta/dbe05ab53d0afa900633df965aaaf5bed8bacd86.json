{"paperId": "dbe05ab53d0afa900633df965aaaf5bed8bacd86", "abstract": "The choice of input text prompt plays a critical role in the performance of Vision-Language Pretrained (VLP) models such as CLIP. We present APoLLo, a unified multi-modal approach that combines Adapter and Prompt learning for Vision-Language models. Our method is designed to substantially improve the generalization capabilities of VLP models when they are fine-tuned in a few-shot setting. We introduce trainable cross-attention-based adapter layers in conjunction with vision and language encoders to strengthen the alignment between the two modalities. We enforce consistency between the respective encoder branches (receiving augmented inputs) to prevent overfitting in downstream tasks. Our method is evaluated on three representative tasks: generalization to novel classes, cross-dataset evaluation, and unseen domain shifts. In practice, APoLLo achieves a relative gain up to 6.03% over MaPLe (SOTA) on novel classes for 10 diverse image recognition datasets.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "citationCount": 7, "influentialCitationCount": 1, "openAccessPdf": {"url": "https://aclanthology.org/2023.emnlp-main.629.pdf", "status": "HYBRID"}, "tldr": {"model": "tldr@v2.0.0", "text": "APoLLo, a unified multi-modal approach that combines Adapter and Prompt learning for Vision-Language models is presented, designed to substantially improve the generalization capabilities of VLP models when they are fine-tuned in a few-shot setting."}, "embedding": {"model": "specter_v2", "vector": [0.4425572156906128, 0.3056109845638275, -0.1414727419614792, -0.1171414703130722, -0.6164146065711975, 0.014215588569641113, 1.0544651746749878, -0.05591382086277008, -0.5571417808532715, -0.6772726774215698, 0.4787188172340393, 0.4330178499221802, 0.48947346210479736, 0.3193870782852173, -0.11082950234413147, 0.44116416573524475, -0.5669656991958618, 0.300070583820343, 0.25745365023612976, -0.7830309867858887, -0.04661894217133522, -0.7440165281295776, -1.0413252115249634, 0.15019197762012482, -0.021440861746668816, 0.6741094589233398, 0.4187839925289154, 1.2372009754180908, -0.25211331248283386, 0.2204493135213852, 0.5441035628318787, -0.27126747369766235, 0.27495095133781433, -0.20349068939685822, -0.39786261320114136, 0.38485094904899597, 0.8762714266777039, -0.6254199743270874, -0.42061492800712585, 0.5681318044662476, -0.022024989128112793, 0.34665530920028687, 0.7169392108917236, -0.5019702315330505, -0.9438127875328064, 0.1977613866329193, 0.46750661730766296, 0.5815199017524719, 0.0018969933735206723, 0.13953609764575958, 1.21610426902771, -1.59635329246521, 0.35468101501464844, 1.4311736822128296, 0.27042356133461, 0.8296664953231812, -0.2210593819618225, -0.24985812604427338, 1.084275245666504, 0.04862749204039574, -0.5331688523292542, -0.21260501444339752, 0.14394962787628174, -0.1738554835319519, 1.7117170095443726, -0.8306663036346436, -0.3815405070781708, 1.141080379486084, 0.22776366770267487, 1.421937346458435, -0.31691664457321167, -0.7916343808174133, -0.5876633524894714, -0.07126039266586304, 0.4209118187427521, 0.7295405268669128, -1.0325427055358887, 0.6584874987602234, -0.72525554895401, 0.44568678736686707, 0.30740654468536377, 0.027776062488555908, -0.12730884552001953, 0.0841178297996521, -0.38453367352485657, 0.5037178993225098, 0.6509957313537598, 0.47189226746559143, -0.1459297090768814, 0.35844549536705017, 0.6555494666099548, 0.41106948256492615, -0.3670487701892853, 0.33072635531425476, 0.21235345304012299, 0.632411777973175, -0.3615870177745819, 0.33948343992233276, -0.28978466987609863, 1.4953362941741943, -0.33468371629714966, -0.12699010968208313, -1.0903303623199463, 0.19950494170188904, 1.3203388452529907, -0.015752749517560005, 0.32325345277786255, -0.6236739158630371, 0.1312856823205948, -0.8016871213912964, -0.0035210195928812027, -0.872133731842041, -0.025163959711790085, -0.04672106355428696, -0.5613726377487183, -1.0742266178131104, -0.2676355540752411, 0.5848846435546875, -1.1835014820098877, 0.897691011428833, -0.5866767764091492, -0.019966060295701027, 0.2813156843185425, 0.4561835527420044, 0.8663652539253235, 0.6873781681060791, 0.8576294779777527, 0.5251583456993103, 0.8920459747314453, -1.4232884645462036, -0.2757805585861206, -1.2640516757965088, 0.37517571449279785, -0.5855072736740112, 0.9044280648231506, -0.2299019992351532, -1.118526577949524, -1.408628225326538, -0.7600480914115906, -0.4841602146625519, -0.6798049807548523, 0.3980447053909302, 0.9399836659431458, 0.009502643719315529, -0.8479300141334534, 0.5621671080589294, 0.2523152232170105, -0.670084536075592, 0.4389503300189972, -0.06594453006982803, 0.002690030261874199, -0.7855724096298218, -0.9123941659927368, 0.16373544931411743, -0.027453921735286713, -0.629446268081665, -0.5278169512748718, -0.47839879989624023, -1.2589261531829834, -0.3867464065551758, 0.40789568424224854, -0.6798534393310547, 1.4708634614944458, -0.9130709767341614, -1.1010842323303223, 1.0910521745681763, -0.27246883511543274, 0.28477275371551514, 0.14328157901763916, -0.33418288826942444, -0.6145173907279968, -0.0998106449842453, -0.07282451540231705, 1.4217127561569214, 0.5202946066856384, 0.07196091115474701, -0.08697168529033661, 0.44578924775123596, 0.06665581464767456, -0.13163591921329498, -0.1688777506351471, 0.9065061211585999, -0.507277250289917, -0.16240134835243225, 0.0008903240668587387, 0.8359102010726929, 0.1159883365035057, 0.052770864218473434, -0.06576430797576904, -1.1448917388916016, 0.9920849204063416, 0.29456931352615356, 0.18969608843326569, -1.4045019149780273, -0.5591913461685181, -0.9088010787963867, -0.2645864486694336, -0.15047714114189148, -1.6531411409378052, 0.6326850056648254, -0.14296671748161316, -0.051391974091529846, -0.09924963861703873, -1.5553911924362183, -0.09867838025093079, -0.28434813022613525, -0.6546765565872192, -0.4774473011493683, 0.9607033729553223, 1.3633166551589966, -1.0609960556030273, -0.08550416678190231, -0.42733681201934814, 0.16411539912223816, -1.039658784866333, 1.481358528137207, -0.6901236176490784, 0.23679667711257935, -0.043417345732450485, 0.19395656883716583, -0.17725883424282074, -0.37000027298927307, -0.4045782685279846, -0.6517545580863953, 0.09649595618247986, 0.16313786804676056, 0.32034969329833984, 1.7205766439437866, -0.3667937219142914, 0.6655433773994446, -0.4936271905899048, -0.4295245110988617, 0.6631394028663635, 0.4070623517036438, -0.6442989706993103, -0.7955801486968994, 0.5647841691970825, 0.3615775406360626, -0.9084511399269104, -0.23666706681251526, 0.9296717047691345, 0.5884776711463928, -0.41609737277030945, -0.2951783239841461, 0.9537363648414612, -0.19918876886367798, 0.4028891324996948, 0.5390843749046326, 0.4687431752681732, 0.4938294589519501, 0.12642131745815277, 0.06372390687465668, 0.47901082038879395, -0.7349541187286377, -0.4168488383293152, 0.640143632888794, 0.3397379517555237, 1.4425008296966553, 0.37232860922813416, -0.7292098999023438, -0.3090757131576538, -0.47047242522239685, 0.9103522896766663, 1.3952635526657104, 0.1632567197084427, 0.16124452650547028, -0.5435155034065247, -0.3041642904281616, -0.6567089557647705, 0.014172377996146679, -0.43135887384414673, -0.5986334681510925, 0.07754240185022354, -0.650310754776001, 0.43337246775627136, 0.7623124718666077, 1.2733434438705444, -0.7578091621398926, -0.35631033778190613, -0.4406474232673645, 0.16999956965446472, -0.8292255401611328, -1.382927656173706, 0.0348634198307991, -0.014532816596329212, -0.28414058685302734, -0.3381265103816986, -0.4135151207447052, 0.21824443340301514, -0.38795608282089233, 0.9813929200172424, -0.804707944393158, -0.8078120946884155, 1.1483814716339111, 0.3775373101234436, -0.658317506313324, -0.8170442581176758, 0.046347394585609436, 0.008146142587065697, 0.3347058892250061, 0.7982902526855469, 0.5932273268699646, 0.033931512385606766, 0.03661487251520157, -0.5602983236312866, 0.31023380160331726, 0.08233948796987534, 0.251982718706131, 1.0199862718582153, -1.0634814500808716, 0.3340145945549011, -0.5921155214309692, 0.7793537378311157, 0.13353681564331055, -0.357206791639328, 0.32501035928726196, -0.247151717543602, -0.7044042348861694, 0.25502878427505493, -0.9646738767623901, -0.5211143493652344, -0.4991396963596344, 0.46287447214126587, -0.5279071927070618, -0.6304848194122314, 0.29159677028656006, 0.1295342594385147, 0.34141284227371216, 0.5592694878578186, 0.23205560445785522, 0.45076316595077515, -0.08268984407186508, 0.6071766018867493, -0.7737165093421936, 1.217610478401184, 0.12418413162231445, -0.1289358288049698, -0.1112648993730545, 0.06801438331604004, -0.7970335483551025, -0.705988883972168, -0.6754763722419739, -0.44247302412986755, -0.7720803022384644, 0.7609742879867554, -0.6170747876167297, -0.629837691783905, 0.193062886595726, -1.4521993398666382, -0.3707979917526245, -0.14071860909461975, -0.49350327253341675, -0.6244729161262512, -1.2184611558914185, -0.6396453380584717, -0.3107166886329651, -0.2740215063095093, -0.8897786736488342, 0.44726255536079407, 0.7544608116149902, -0.3505376875400543, -0.5089352130889893, 0.03435847908258438, -0.4733389914035797, 0.8707427978515625, -0.3128909170627594, 0.4485299289226532, -0.05369638651609421, -0.5716859698295593, -0.4938727617263794, -0.037489913403987885, 0.7366549372673035, -0.17147254943847656, 0.24909524619579315, -1.1692487001419067, 0.22768203914165497, -0.5639674067497253, -0.7349647879600525, 0.39385807514190674, -0.048589758574962616, 0.1497262418270111, 0.5025407671928406, -0.334629625082016, 0.29766276478767395, 1.5654720067977905, -0.5550141930580139, -0.03137137368321419, 0.03910069912672043, 0.6164449453353882, 0.39614182710647583, -0.09620518237352371, 0.1459435075521469, 0.6292897462844849, 0.26190802454948425, 0.10674748569726944, -0.13888093829154968, -0.5484773516654968, -0.9998770952224731, 0.5973949432373047, 1.1482020616531372, 0.46612897515296936, 0.1149861142039299, -1.253840684890747, 0.9897918105125427, -0.9843466877937317, -0.3784199357032776, 0.5950441360473633, 0.5647810101509094, 0.1815209984779358, -0.5379654765129089, -0.11197590827941895, -1.0408693552017212, 0.33986103534698486, 0.2355462610721588, -0.219307541847229, -0.5644516348838806, -0.33775436878204346, 0.11408098042011261, -0.15313120186328888, 0.7634414434432983, -0.6383479237556458, 0.5375698804855347, 14.086836814880371, 0.2843904495239258, -0.23056618869304657, 0.6765784025192261, 0.5702517032623291, 0.34182244539260864, -0.25876474380493164, -0.058547213673591614, -1.1020649671554565, -0.797832190990448, 0.9790401458740234, 0.21939897537231445, 0.3652072846889496, 0.13289102911949158, -0.2627306878566742, 0.12263192981481552, -1.168999195098877, 0.8875551223754883, 1.1328784227371216, -1.0219630002975464, 0.47041329741477966, -0.356763631105423, 0.4564570188522339, 0.6098831295967102, 1.1100223064422607, 0.8712443709373474, -0.14848726987838745, -0.2236965447664261, 0.3407195806503296, 0.7501320242881775, 0.7347509860992432, 0.33745211362838745, -0.11662933230400085, 0.13045844435691833, -0.5638167262077332, -0.25049617886543274, -0.6656137108802795, -0.9570007920265198, 0.4783632159233093, -0.6739721894264221, -0.16345223784446716, -0.2819845378398895, -0.02757531777024269, 0.9359572529792786, -0.17747096717357635, 0.5203778147697449, 0.010806368663907051, 0.26145246624946594, 0.11398785561323166, -0.06198086589574814, 0.6567668318748474, 0.7764102816581726, 0.544501781463623, 0.1347564160823822, -0.24578362703323364, 0.07380412518978119, 0.3551793396472931, 0.782610297203064, -0.426649272441864, -0.05765789374709129, -0.546068549156189, -0.13163235783576965, -0.6336146593093872, 0.565073549747467, 0.4383290410041809, 0.2844869792461395, -0.8284808993339539, 0.36418798565864563, 0.1367257982492447, 0.5805343985557556, -0.11915484070777893, -0.022138820961117744, -0.05765138939023018, -0.49757811427116394, -0.039191536605358124, 0.4353926479816437, 0.16199101507663727, -0.3125196099281311, -0.5840283036231995, -0.06822049617767334, 0.5236931443214417, -1.2687053680419922, -1.2045483589172363, 1.0368889570236206, -0.029066279530525208, -0.45529231429100037, 0.25153136253356934, -1.1155197620391846, -0.5976502895355225, 0.6056194305419922, -1.4250938892364502, -0.969666600227356, -0.3299981355667114, -0.25423121452331543, 0.2043331116437912, -0.6124357581138611, 1.211193561553955, 0.19899339973926544, 0.007205011323094368, 0.4164612889289856, -0.6037294864654541, -0.15601015090942383, 0.2396431565284729, -0.45166724920272827, 0.6421734690666199, 0.2693779170513153, -0.15129558742046356, -0.32057347893714905, 0.022968288511037827, 0.19974075257778168, -0.60017991065979, -0.1821305900812149, 0.8237482905387878, -0.9896473288536072, -0.5144845247268677, -0.34882017970085144, -0.8999872207641602, 0.33936288952827454, 0.8911100029945374, -0.029598595574498177, 0.3340020775794983, 0.14326868951320648, -1.1718567609786987, -0.02542191557586193, -0.5921258330345154, 0.3641369938850403, 0.15738753974437714, -0.9055334329605103, -0.5421043038368225, 0.07366909831762314, 0.6205452084541321, -0.9314279556274414, 0.02690005674958229, -0.4104272425174713, 0.02747316099703312, -0.24334146082401276, 0.8983805179595947, -0.7895753383636475, 0.9433237910270691, 0.7100332975387573, -0.3563336730003357, -0.49203023314476013, 0.1437835991382599, -0.8925241231918335, 0.502165675163269, 0.6305606365203857, 0.4947742223739624, -0.2950950562953949, -0.5929386615753174, 0.7741912603378296, 0.15161816775798798, -0.45692989230155945, -0.4085874855518341, -0.6600425839424133, 0.3130125403404236, -0.30753767490386963, -0.008246569894254208, -0.2947874367237091, -0.258652001619339, 0.5692440271377563, 0.47115516662597656, 0.46599850058555603, -0.32812073826789856, -0.8332417011260986, 0.5903447866439819, -0.01870943419635296, -0.25385281443595886, -0.48723122477531433, -0.5067333579063416, -1.7147552967071533, -0.10145771503448486, -1.2464230060577393, 0.010212931782007217, -0.5936967134475708, -0.2548043727874756, 0.6054012179374695, -0.3951365649700165, 0.17851798236370087, 0.36293670535087585, -0.1838066279888153, 0.052683234214782715, -0.6335728764533997, -0.7902461290359497, 1.0096430778503418, 0.9480299949645996, -1.1070891618728638, -0.1396438032388687, -0.36292728781700134, -0.18802055716514587, 0.196496844291687, 0.11252004653215408, -0.09032192826271057, -0.784395694732666, -1.4233967065811157, 0.20690025389194489, -0.10729572921991348, 0.6525993943214417, -1.132821798324585, 0.7416391968727112, 0.4944784641265869, -0.4082081615924835, 0.035418856889009476, 0.4293796122074127, -0.7922536730766296, -0.8865967988967896, -0.1308235228061676, -1.0130654573440552, 0.36967790126800537, 0.6573897004127502, -0.24938265979290009, -0.5322460532188416, 0.8307604193687439, 0.2359740436077118, -0.886416494846344, -1.0192183256149292, 0.5822799205780029, -0.16448725759983063, 0.257782518863678, -0.2776073217391968, 0.12319771945476532, -1.146142840385437, -0.5156139731407166, -0.040521495044231415, 0.6843476891517639, -0.6145897507667542, 1.3837623596191406, 0.857293426990509, -1.3621513843536377, -0.11693715304136276, 0.38184884190559387, 0.6499567627906799, 0.09002234786748886, 0.9658413529396057, 0.6882557272911072, 0.05255226790904999, 0.15134695172309875, -0.0585460364818573, 0.0597049817442894, -0.6985633969306946, 0.5301755666732788, 1.0660483837127686, -0.01358609739691019, -0.2347467839717865, 1.2853339910507202, 0.17833977937698364, -0.8323739767074585, 0.3324618637561798, -0.5722032785415649, -0.26844218373298645, -0.2589455544948578, 0.8545878529548645, -0.3608461022377014, -0.4586978852748871, -0.30700984597206116, -0.14073869585990906, 0.61453777551651, -0.6676554679870605, -0.5407848358154297, 0.18584099411964417, -0.1704896092414856, 0.07656428217887878, 0.8006528615951538, 1.05402672290802, -1.248368263244629, -1.1514980792999268, -0.8699949979782104, -0.7313171029090881, 0.1360733062028885, -0.15678951144218445, -0.6829819083213806, -0.549834132194519, 1.05179762840271, 0.7300690412521362, -0.22822488844394684, 0.6586861610412598, 0.2665979266166687, 0.0015377008821815252, 0.6501620411872864, -0.39134499430656433, -0.6761436462402344, 0.19802600145339966, 1.2493796348571777, 1.5542633533477783, -1.139614462852478, -0.3428373634815216, -0.3377297818660736, -0.7380479574203491, 0.7671778202056885, 0.7058298587799072, -0.11771157383918762, 0.7482903003692627, -0.6821096539497375, 0.4869145452976227, 0.3690841794013977, -1.016287088394165, -0.3212554454803467, 1.0437783002853394, 1.6559031009674072, 0.5280884504318237, 0.05194377154111862, 0.08459214121103287, 0.8851165771484375, 0.5221642851829529, 0.14320236444473267, 0.7722386121749878, -0.0014033183688297868, -0.10078655928373337, -0.15836936235427856, 0.24966008961200714, 0.24769365787506104, -0.19110247492790222, -0.4049064517021179, 0.08516544848680496, 0.5278477072715759, 0.14144331216812134, 0.6353751420974731, 0.9327719807624817, 0.2617816925048828, 1.0559102296829224, 0.5192566514015198, 0.5644941926002502, -0.482085645198822, -0.0278679970651865, -0.31066346168518066, -1.0965241193771362, 0.068151094019413, -0.4141802489757538, -0.8227912783622742, -0.11270754039287567, 0.5367517471313477, 0.8316254615783691, -0.7692831158638, -0.05810866504907608, 1.2185853719711304, 0.6248259544372559, 0.6180380582809448, -0.5717027187347412, -0.42626717686653137, -0.2822909355163574, -0.8484243154525757, 0.43877920508384705, -0.32988619804382324, 0.17201271653175354, -0.5798128843307495, 0.017229681834578514, 0.10446467250585556]}, "authors": [{"authorId": "2147230645", "name": "Sanjoy Chowdhury"}, {"authorId": "2269464026", "name": "Sayan Nag"}, {"authorId": "2257190172", "name": "Dinesh Manocha"}], "references": [{"paperId": "ed8ac4ff13d32a291bbe74f3e5a138800bba47fd", "title": "Image as a Foreign Language: BEIT Pretraining for Vision and Vision-Language Tasks"}, {"paperId": "2c0fdb6b380b7e12c3245482f288889d898e3d19", "title": "GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks"}, {"paperId": "91b2b47cabd800ef658b65bfe1f52b7293a740c3", "title": "LLM-powered Data Augmentation for Enhanced Crosslingual Performance"}, {"paperId": "a17d4a542bcdd1d5ade9b64cef093fa76437f96a", "title": "Consolidator: Mergeable Adapter with Grouped Connections for Visual Adaptation"}, {"paperId": "dce62170e8be820bcec51aae2eceed3943ca6c9a", "title": "TTIDA: Controllable Generative Data Augmentation via Text-to-Text and Text-to-Image Models"}, {"paperId": "4538e353dd98f396c8facc29ebb72e9b1ba5f7c2", "title": "Synthetic Data from Diffusion Models Improves ImageNet Classification"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "88779e873b7ec860d6b6a4c2ddfc28dd67c86b67", "title": "Visual-Language Prompt Tuning with Knowledge-Guided Context Optimization"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "4049d388b8487e4d6c5adafbcdaa867d5f87a1a6", "title": "Diversity is Definitely Needed: Improving Model-Agnostic Zero-shot Classification via Stable Diffusion"}, {"paperId": "1e05c5427d6a35a3b1bf37fb955f2ea94995a71d", "title": "Effective Data Augmentation With Diffusion Models"}, {"paperId": "8165c92e8794cc197b5f9909487b79d1bcf2c0b2", "title": "Position-Guided Text Prompt for Vision-Language Pre-Training"}, {"paperId": "cfca7eedc6ede9d363d1662280a74d78dcdc9d4a", "title": "Scaling Language-Image Pre-Training via Masking"}, {"paperId": "30a3731f09e7a391e79a28fa736fa6bdd8331866", "title": "Uni-Perceiver v2: A Generalist Model for Large-Scale Vision and Vision-Language Tasks"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "d3461268e1153b1abec8f999f6375378a33e0061", "title": "Bridging the Gap between Object and Image-level Representations for Open-Vocabulary Detection"}, {"paperId": "42a6ee55b8fc4000c5ae3f4d942f8754ba16362b", "title": "Prompt-aligned Gradient for Prompt Tuning"}, {"paperId": "a09cbcaac305884f043810afc4fa4053099b5970", "title": "Exploring Plain Vision Transformer Backbones for Object Detection"}, {"paperId": "403ad5d6e78fcf29f1ac526fbc9ff6cbfea555eb", "title": "Open-Vocabulary DETR with Conditional Matching"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "86b42cac364985919987789795be7c3a577ee3de", "title": "Detecting Twenty-thousand Classes using Image-level Supervision"}, {"paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d", "title": "High-Resolution Image Synthesis with Latent Diffusion Models"}, {"paperId": "55a19318cc93714802c7ac59e07651789749b20c", "title": "VL-ADAPTER: Parameter-Efficient Transfer Learning for Vision-and-Language Tasks"}, {"paperId": "22312f763328cf540791de8c2449ea1e7436f476", "title": "UniTAB: Unifying Text and Box Outputs for Grounded Vision-Language Modeling"}, {"paperId": "21ec90872abd986c12afe39bebe807732ffa70c9", "title": "Florence: A New Foundation Model for Computer Vision"}, {"paperId": "e70b7eb3b22f0a49eb5e645be646d5f35d1e693a", "title": "Tip-Adapter: Training-free CLIP-Adapter for Better Vision-Language Modeling"}, {"paperId": "94ff111c4d81bd03f159321728ceec8b4711c89d", "title": "An Empirical Study of Training End-to-End Vision-and-Language Transformers"}, {"paperId": "f3a332ff1b73acda482e5d83696b2c701f487819", "title": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"}, {"paperId": "c04067f03fba2df0c14ea51a170f213eb2983708", "title": "CLIP-Adapter: Better Vision-Language Models with Feature Adapters"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "8a9d84d86ac0d76e63914802f9738325c3bece9c", "title": "Barlow Twins: Self-Supervised Learning via Redundancy Reduction"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "141a5033d9994242b18bb3b217e79582f1ee9306", "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"}, {"paperId": "b6f54f6d3a0cb9d3f1244c63773c40b0f5a1e224", "title": "CO2: Consistent Contrast for Unsupervised Visual Representation Learning"}, {"paperId": "022622e024890d6e044ac50e2da6b44c59bdf418", "title": "The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "7af72a461ed7cda180e7eab878efd5f35d79bbf4", "title": "A Simple Framework for Contrastive Learning of Visual Representations"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "4ae0c4a511697e960c477ea3e37b3e11bf3e0e02", "title": "Learning Robust Global Representations by Penalizing Local Predictive Power"}, {"paperId": "4e0bb8c1c683b43357c5d5216f6b74ff2cb32434", "title": "Do ImageNet Classifiers Generalize to ImageNet?"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "162cad5df347bdac469331df540440b320b5aa21", "title": "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks"}, {"paperId": "4081de7e0f94e7e0d7b645c298d7768698d05774", "title": "Efficient Parametrization of Multi-domain Deep Neural Networks"}, {"paperId": "d89ee98810039d2061ed42ee8026da49c503d16b", "title": "Learning multiple visual domains with residual adapters"}, {"paperId": "96420cbe466f840c835e96fb7704269a6dc7ad43", "title": "Incremental Learning Through Deep Adaptation"}, {"paperId": "8e3f12804882b60ad5f59aad92755c5edb34860e", "title": "Food-101 - Mining Discriminative Components with Random Forests"}, {"paperId": "a83cec6a91701bd8500f8c43ad731d4353c71d55", "title": "3D Object Representations for Fine-Grained Categorization"}, {"paperId": "522d65a3db7431015aeaa201a7fc4450a57e40c3", "title": "Fine-Grained Visual Classification of Aircraft"}, {"paperId": "da9e411fcf740569b6b356f330a1d0fc077c8d7c", "title": "UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild"}, {"paperId": "84b50ebe85f7a1721800125e7882fce8c45b5c5a", "title": "Cats and dogs"}, {"paperId": "908091b4a8757c3b2f7d9cfa2c4f616ee12c5157", "title": "SUN database: Large-scale scene recognition from abbey to zoo"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "02b28f3b71138a06e40dbd614abf8568420ae183", "title": "Automated Flower Classification over a Large Number of Classes"}, {"paperId": "ed9db7b20e019cdb1c7db8b7921221ee2d9f36e2", "title": "Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories"}, {"paperId": "520711a1e93e6c4221f2a7c97c27a508379e8e37", "title": "Flan-MoE: Scaling Instruction-Finetuned Language Models with Sparse Mixture of Experts"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": null, "title": "How to adapt your large-scale vision-and-language model"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": null, "title": "Efficientnet: Re-thinking model scaling for convolutional neural networks"}, {"paperId": null, "title": "De-scribing textures in the wild"}, {"paperId": null, "title": "2023. Maple: Multi-modal prompt learning"}, {"paperId": null, "title": "2022. Test-time prompt tuning for zero-shot generalization in vision-language models"}, {"paperId": null, "title": "2022. Vision trans-former adapter for dense predictions"}, {"paperId": null, "title": "2022. Prompt distribution learning"}, {"paperId": null, "title": "2021b. Natural adversarial examples"}, {"paperId": null, "title": "2022. Exploring visual prompts for adapting large-scale models"}]}