{"paperId": "3d473cbb7a377cf960abff31748a1a39bb6c7d7c", "abstract": "This work aims at decreasing the end-to-end generation latency of large language models (LLMs). One of the major causes of the high generation latency is the sequential decoding approach adopted by almost all state-of-the-art LLMs. In this work, motivated by the thinking and writing process of humans, we propose \u201cSkeleton-of-Thought\u201d (SoT), which guides LLMs to first generate the skeleton of the answer, and then conducts parallel API calls or batched decoding to complete the contents of each skeleton point in parallel . Not only does SoT provide considerable speed-up (up to 2.39 \u00d7 across 11 different LLMs), but it can also potentially improve the answer quality on several question categories in terms of diversity and relevance. SoT is an initial attempt at data-centric optimization for efficiency, and reveal the potential of pushing LLMs to think more like a human for answer quality.", "venue": "arXiv.org", "year": 2023, "citationCount": 51, "influentialCitationCount": 4, "openAccessPdf": {"url": "https://arxiv.org/pdf/2307.15337", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": "Skeleton-of-Thought (SoT), which guides LLMs to first generate the skeleton of the answer, and then conducts parallel API calls or batched decoding to complete the contents of each skeleton point in parallel, is proposed."}, "embedding": {"model": "specter_v2", "vector": [-0.06528384983539581, 0.8485792279243469, -0.0864928588271141, -0.18353603780269623, -0.16283182799816132, -0.37233734130859375, 0.49905675649642944, -0.1307917982339859, -0.15275658667087555, -0.3004899322986603, 0.3714161813259125, -0.3165455758571625, 0.18586896359920502, -0.15596871078014374, -0.2056756615638733, 0.6690230965614319, -0.5866217613220215, 0.6297147870063782, -0.13038480281829834, -0.2585505545139313, 0.03740011155605316, -0.8379403352737427, -1.1131290197372437, 0.3184582591056824, 0.73725825548172, 0.10533876717090607, -0.021980147808790207, 1.2935267686843872, -0.25824475288391113, 0.31718578934669495, 0.14853009581565857, -0.5143616795539856, -0.058591753244400024, -0.03842125087976456, -0.2803911566734314, -0.2789689898490906, 0.1505221277475357, -0.4936046302318573, 0.07909942418336868, 0.41192346811294556, -0.09907820075750351, 0.11975893378257751, 0.2551478445529938, -0.6878697872161865, -0.5133142471313477, 0.7813267707824707, 0.6579140424728394, 0.39387694001197815, 0.4654077887535095, -0.31220579147338867, 1.3149477243423462, -1.5353797674179077, 0.2551848292350769, 1.9348424673080444, 0.10270221531391144, 0.4782100319862366, -0.2264062613248825, -0.46389108896255493, 0.5386661887168884, -0.3463647663593292, -0.894952654838562, -0.5270097851753235, -0.3537852168083191, -0.08361472934484482, 1.8349025249481201, -0.30186378955841064, -0.16372497379779816, 0.14580176770687103, -0.06090451404452324, 1.4130945205688477, -0.45745527744293213, -0.7242848873138428, -0.035944391041994095, 0.09976625442504883, 0.2695852518081665, 0.861290693283081, -0.09170763939619064, -0.2208900898694992, -0.9902523756027222, -0.4392355680465698, 0.5722387433052063, -0.3426789343357086, -0.241037517786026, -0.16702227294445038, -0.5863279700279236, 0.8735634088516235, -0.012011909857392311, 0.45115160942077637, 0.015746403485536575, 0.4178765118122101, 0.2297201156616211, 0.4355461299419403, -0.026861820369958878, 0.437599778175354, -0.3317197859287262, 0.43564555048942566, -0.8609391450881958, 0.7092325091362, 0.816466748714447, 0.8579973578453064, -0.32552555203437805, -0.3272404372692108, -0.9513053297996521, 0.12259972840547562, 1.4863542318344116, 0.14593686163425446, 0.6138880848884583, -0.765856921672821, 0.5069103240966797, -0.4766988456249237, 0.3674420118331909, -0.3153931796550751, -0.2620667517185211, -0.1799905002117157, -0.277001291513443, -1.34847092628479, -0.111554816365242, -0.20140913128852844, -0.5820669531822205, 0.589647650718689, -0.12305187433958054, -0.23011915385723114, 0.13805952668190002, 0.6203365921974182, 0.8877115249633789, 0.669053852558136, 0.09853207319974899, 0.22015248239040375, 1.009091854095459, -0.9882088303565979, -0.2766075134277344, -1.204817295074463, 0.750571072101593, -0.49865037202835083, 0.39797329902648926, -0.1516401767730713, -1.5542974472045898, -1.1873079538345337, -0.8042715787887573, -0.08717592805624008, -0.21438191831111908, 0.40668246150016785, 1.0761102437973022, 0.4510848820209503, -1.2951310873031616, 0.6088042259216309, 0.12107724696397781, -0.41039741039276123, -0.24878926575183868, 0.28204992413520813, 0.43832188844680786, -0.5774009227752686, -1.0231006145477295, -0.09177076071500778, -0.34345924854278564, -0.8021953105926514, 0.032577257603406906, -0.22876977920532227, -1.201414942741394, -0.234352245926857, -0.008804281242191792, -1.1408472061157227, 1.6708608865737915, 0.23920504748821259, -1.3343507051467896, 0.447513222694397, -0.5763261914253235, 0.38549289107322693, -0.015638113021850586, -0.09506446123123169, -0.6175976991653442, -0.2743357717990875, -0.05097378417849541, 0.9464467763900757, 0.5386609435081482, 0.13335512578487396, -0.0648643895983696, 0.07678072899580002, 0.017244771122932434, -0.08646342903375626, 0.06519542634487152, 1.1231213808059692, -0.6418509483337402, 0.00457626162096858, 0.46704423427581787, 0.7394019961357117, -0.23837141692638397, -0.23463855683803558, -0.3139082193374634, -1.298671007156372, 0.3666035830974579, -0.0027944487519562244, 1.1541239023208618, -0.7015973925590515, -0.6242050528526306, -0.33852776885032654, -0.009099091403186321, -0.3336395025253296, -0.9248049855232239, 0.6814998388290405, -0.21682259440422058, 0.6509591341018677, -0.03454017639160156, -1.1003057956695557, 0.052466630935668945, -0.5950099229812622, -0.6997543573379517, -0.4500611126422882, 0.09183665364980698, 1.0037868022918701, -0.6327604651451111, 0.09308410435914993, -0.6256630420684814, -0.14390380680561066, -1.0917140245437622, 1.3105885982513428, -0.9499984979629517, 0.34433573484420776, -0.29093050956726074, -0.06597237288951874, 0.12392475455999374, -0.4514176845550537, -0.11644726991653442, -0.1275090128183365, -0.2779894471168518, 0.37115588784217834, -0.29659438133239746, 1.4533430337905884, 0.02637140452861786, -0.061332039535045624, -0.1897158920764923, 0.0826672613620758, 0.16386641561985016, 0.6106864213943481, -0.654399573802948, -0.4005449414253235, -0.17757049202919006, 0.822849690914154, -0.27387377619743347, 0.08763735741376877, 0.7222434878349304, 0.9985672831535339, -0.5651900172233582, 0.6197981834411621, 0.3167763352394104, -0.5091755390167236, 0.9530560970306396, 0.34336236119270325, 0.6642907857894897, 0.4627596139907837, 0.07706867158412933, 0.24036158621311188, 0.873404860496521, -0.6119332909584045, -0.3052782714366913, 0.6103661060333252, 1.0885690450668335, 1.0162408351898193, 0.37607941031455994, -0.9377591609954834, -0.03030327707529068, 0.1325525939464569, 0.9709495306015015, 1.5319339036941528, -0.1292809247970581, -0.42124488949775696, -0.9331687688827515, -0.3887034058570862, -0.11737849563360214, 0.5161407589912415, -0.02692629024386406, 0.020551716908812523, -0.643410861492157, -1.0106931924819946, 0.9033309817314148, -0.08607892692089081, 0.6118238568305969, -0.5074639320373535, -0.30504104495048523, -0.31210586428642273, 0.289802223443985, -0.7682843208312988, -0.6264438033103943, -0.16875912249088287, -0.7706259489059448, -0.16851916909217834, -0.27575501799583435, -0.23205628991127014, 0.23993580043315887, -0.49393007159233093, 0.9994010329246521, -0.14110568165779114, -0.3172374963760376, 0.2835201919078827, 0.6449347138404846, -0.5311773419380188, -0.9706497192382812, -0.21270906925201416, -0.13817963004112244, -0.39782169461250305, 0.34075427055358887, 0.48269039392471313, -0.21264538168907166, 0.3012925386428833, -0.3940946161746979, 0.42153000831604004, 0.09064963459968567, -0.7184129953384399, 0.42298299074172974, -0.6494588255882263, -0.015872059389948845, -0.9538778066635132, 1.315029501914978, 0.05735986679792404, -0.48843327164649963, 0.43164947628974915, -0.6957157254219055, -0.18657462298870087, 0.6181421875953674, -0.5270209908485413, -0.21447321772575378, -1.149437665939331, 0.5114755630493164, 0.41160112619400024, -0.36784589290618896, 0.10912276059389114, 0.316045343875885, 0.11626360565423965, 0.1772913783788681, 0.31773921847343445, 0.4598149061203003, -0.4859533905982971, 0.8486806154251099, -0.7837473154067993, 0.13595932722091675, 0.16883394122123718, 0.02182587794959545, -0.30876317620277405, -0.5208597779273987, -0.34883514046669006, -0.05839962139725685, -0.27344346046447754, 0.04568980261683464, -0.11219175904989243, 0.16293874382972717, -0.7067601084709167, -0.6485143303871155, -0.2813951075077057, -1.7911889553070068, 0.10555561631917953, 0.28551021218299866, -0.41398316621780396, 0.013409740291535854, -0.7483247518539429, -1.1269057989120483, -0.19766345620155334, -0.8306935429573059, -0.9958428144454956, 0.7725358009338379, 0.0680350810289383, -0.9546729922294617, -0.2415667176246643, 0.35610538721084595, 0.07364644855260849, 1.0043038129806519, -1.0516687631607056, 1.4463181495666504, -0.16613151133060455, -0.42653414607048035, -0.4040611982345581, 0.08529797196388245, 0.06641929596662521, -0.6455774903297424, 0.08606238663196564, -0.449467271566391, 0.1836404949426651, 0.0598699226975441, -0.17151996493339539, -0.1304430514574051, 0.12896797060966492, 0.33562105894088745, -0.02259807288646698, -0.5269611477851868, 0.2081083059310913, 1.042805790901184, -0.8430298566818237, -0.18826496601104736, -0.12033895403146744, 0.9286454916000366, 0.6953942179679871, -0.4803787171840668, 0.7127094268798828, 0.7935879826545715, 0.35207825899124146, -0.06784945726394653, -0.19066330790519714, -0.3795238137245178, -0.5108548402786255, 1.105210304260254, 1.7181355953216553, 0.532749354839325, -0.279602974653244, -0.9169366359710693, 0.22884538769721985, -1.3791197538375854, 0.13190588355064392, -0.08934159576892853, 0.9454885721206665, 0.12180645018815994, -0.7229887843132019, -0.3325757682323456, -0.5854300260543823, 0.5319294333457947, 0.05596216022968292, -0.3420076370239258, -1.0582443475723267, 0.08888006210327148, 0.3972969651222229, -0.17413116991519928, 0.39404457807540894, 0.12158119678497314, 0.5151411294937134, 14.630532264709473, 0.6413801908493042, 0.3665546774864197, 0.5884557366371155, 0.6859555244445801, 0.330672949552536, -0.695106029510498, 0.10084538161754608, -1.426824927330017, -0.19626231491565704, 1.3353590965270996, -0.20596326887607574, 0.5314434170722961, 0.011174416169524193, 0.29576170444488525, -0.10303361713886261, -0.9598544836044312, 0.6288811564445496, 0.820629358291626, -0.955539882183075, 0.9100136160850525, 0.29015451669692993, 0.14540675282478333, 0.4448632597923279, 0.5855711102485657, 0.9318420886993408, 0.23749621212482452, -0.5633361339569092, 0.49702057242393494, 0.24038837850093842, 0.602084219455719, 0.0389636866748333, 0.3576589524745941, 1.0017774105072021, -0.6902621984481812, -0.3257710337638855, -0.6694861054420471, -1.4331456422805786, 0.2865811288356781, 0.2460259348154068, -0.7379937171936035, -0.5475168824195862, -0.7421461343765259, 0.29000821709632874, -0.26477107405662537, 0.5419389605522156, -0.4002000391483307, 0.5693645477294922, -0.12850621342658997, -0.3219465911388397, -0.13163632154464722, 0.4389055371284485, 0.28243714570999146, -0.38348427414894104, 0.5285583138465881, -0.31373903155326843, -0.08242227137088776, 0.9733834862709045, -0.46027010679244995, 0.24938368797302246, -0.31715428829193115, -0.21807117760181427, -0.20051610469818115, 0.5132725834846497, 0.28433743119239807, 0.4278305172920227, -0.5618303418159485, 0.500260591506958, 0.5621514320373535, 0.1706460416316986, -0.010406591929495335, 0.13693304359912872, 0.048162613064050674, -0.2449449598789215, -0.028257660567760468, 0.44150757789611816, -0.20919637382030487, -0.7672878503799438, -0.5082026124000549, -0.7513670325279236, 0.42495712637901306, -0.7672474384307861, -0.630277156829834, 0.6799809336662292, -0.2391984611749649, -0.4619270861148834, -0.2746012508869171, -0.7573260068893433, -0.6024384498596191, 0.5217264890670776, -1.0013870000839233, -0.7527176141738892, 0.5875088572502136, -0.3428463935852051, -0.025442857295274734, -0.0022003930062055588, 1.5762712955474854, -0.10337462276220322, -0.4261954426765442, -0.06942025572061539, -0.2543156147003174, -0.3533114194869995, -0.0950898826122284, -0.5589013695716858, 1.2495293617248535, 0.39181020855903625, -0.04993830621242523, 0.5483931303024292, -0.10696122795343399, -0.11541870981454849, -1.1753883361816406, 0.15836890041828156, 1.416341781616211, -0.9639574289321899, -0.5668112635612488, -0.777754008769989, -0.44517579674720764, -0.27020755410194397, 0.5209363698959351, -0.7913921475410461, 0.5317206382751465, 0.020520588383078575, -0.395920991897583, 0.07256229966878891, -0.6787503361701965, 0.29031720757484436, 0.29154881834983826, -0.49033868312835693, -0.10583342611789703, 0.3242102861404419, 0.7751290798187256, -0.6912649869918823, -0.0769994854927063, -0.20146633684635162, 0.09442612528800964, 0.018434816971421242, 0.6943577527999878, -0.0927426740527153, 0.7622071504592896, 0.5373305082321167, 0.049626465886831284, -0.42950642108917236, 0.2364443838596344, -1.125240683555603, -0.03798528388142586, -0.11660102754831314, 1.3089553117752075, -0.3721005916595459, 0.06711030751466751, 1.5672682523727417, 0.7130089998245239, -0.28023579716682434, -0.24764055013656616, -0.02912057749927044, 0.15572096407413483, -0.6282525658607483, 0.6810413002967834, -0.8585234880447388, 0.21271957457065582, 0.4077416658401489, 0.6975151300430298, 0.6955348253250122, -0.10088411718606949, -0.44628092646598816, 1.0528987646102905, -0.1831565499305725, -0.381149560213089, -0.5396985411643982, -0.04149031639099121, -1.7703392505645752, -0.41471800208091736, -1.1353325843811035, -0.11471368372440338, -1.1680521965026855, -0.4212316870689392, 0.5094248652458191, 0.2908523380756378, -0.46178996562957764, 0.4311554431915283, -0.33251917362213135, -0.5395324230194092, -0.3637900650501251, -0.9540473818778992, 0.48259735107421875, 1.004841685295105, -0.3830180764198303, 0.14172646403312683, 0.23462554812431335, -0.03725171089172363, 0.49221372604370117, 0.15707524120807648, -0.4483105540275574, -0.8717066645622253, -1.6565860509872437, 0.8685373663902283, 0.16468945145606995, -0.07959216088056564, -0.5829581618309021, 0.9485741257667542, 0.8806842565536499, -0.11369633674621582, -0.015882674604654312, -0.14551356434822083, -0.179696723818779, -0.43142542243003845, 0.27406570315361023, -0.7401592135429382, 0.3248542249202728, 0.13695551455020905, -0.7915837168693542, -0.37176263332366943, 0.4176759421825409, -0.7048916816711426, -1.3235670328140259, -0.48887360095977783, 0.27465909719467163, -0.5441694259643555, -0.0028050043620169163, -0.6217097640037537, -0.22583390772342682, -0.7931432723999023, -0.5567525029182434, 0.2618918716907501, 0.45568761229515076, -0.0911795124411583, 1.1225775480270386, 0.6509220600128174, -0.656085729598999, -0.04993746057152748, 0.6470302939414978, -0.13793353736400604, -0.04266354441642761, 0.3681466579437256, 0.28391146659851074, -0.5047445297241211, 0.6429752111434937, 0.9137446284294128, 0.2617528736591339, -0.7563411593437195, -0.15090471506118774, 0.3753311038017273, -0.5231553316116333, 0.0025689348112791777, 1.431161642074585, -0.2239426225423813, -1.4153966903686523, -0.07014875113964081, -1.3698395490646362, -0.5612521171569824, -0.6956362724304199, 0.8826776146888733, 0.17451059818267822, 0.09774891287088394, 0.11571799963712692, -0.5463085174560547, 0.33777451515197754, 0.10114526003599167, -0.8109173774719238, 0.19477100670337677, -0.3615453839302063, -1.0749279260635376, 0.1758585125207901, 0.6828657388687134, -0.3789371848106384, -0.11431002616882324, -0.17786428332328796, -0.09312069416046143, 0.25370892882347107, 0.0006204078672453761, -0.5479785203933716, 0.13984766602516174, 0.8474048972129822, 0.08972445130348206, 0.2681528329849243, -0.07724503427743912, -0.013273213058710098, 0.7194964289665222, 0.5055341720581055, 0.23164884746074677, -0.3611793518066406, -0.648729681968689, 1.3128560781478882, 1.3174455165863037, -0.8955420851707458, 0.027258489280939102, -0.12505562603473663, -0.5897724628448486, 1.322171688079834, 0.3056044578552246, 0.22286280989646912, 0.5590776205062866, -0.26038604974746704, 0.055149417370557785, 0.015717679634690285, -1.2761023044586182, 0.14594385027885437, 1.0929203033447266, 0.572173535823822, 1.2788456678390503, 0.3213095963001251, -0.2518148422241211, 1.2477582693099976, -0.010780335403978825, 0.535754382610321, 0.5814588069915771, 0.17418214678764343, -0.2816486656665802, -0.37997445464134216, -0.2387549728155136, 0.3021896481513977, -0.42460352182388306, -0.8411900997161865, -0.03206317499279976, 0.33579879999160767, 0.444759339094162, 1.0773478746414185, 0.4398522973060608, 0.36878982186317444, 0.5845828056335449, 0.4743804633617401, 0.5840810537338257, -0.994127631187439, -0.2745712399482727, -0.15057134628295898, -0.3673892617225647, -0.03952488303184509, 0.2681209146976471, -0.16997461020946503, -0.529884397983551, -0.15937569737434387, 0.44198739528656006, 0.11339374631643295, 0.45055991411209106, 0.9806157946586609, 0.8695658445358276, -0.1080775260925293, -0.2965015769004822, -0.38686925172805786, -0.5778960585594177, -0.922848641872406, 0.3053494989871979, -0.7575117349624634, -0.5743846893310547, 0.3566528260707855, -0.4572227895259857, -0.3261728882789612]}, "authors": [{"authorId": "6636914", "name": "Xuefei Ning"}, {"authorId": "3354281", "name": "Zinan Lin"}, {"authorId": "2112253370", "name": "Zixuan Zhou"}, {"authorId": "2177314863", "name": "Huazhong Yang"}, {"authorId": "40457242", "name": "Yu Wang"}], "references": [{"paperId": "ea1f648988c632a6dbab6d8b88432456aa021cfb", "title": "SpecTr: Fast Speculative Decoding via Optimal Transport"}, {"paperId": "83b90f4a0ae4cc214eb3cc140ccfef9cd99fac05", "title": "Efficient Memory Management for Large Language Model Serving with PagedAttention"}, {"paperId": "aade40af0d85b0b4fe15c97f6222d5c2e4d6d9b3", "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models"}, {"paperId": "507acddb0b7f36b83fd7c8bff2f121eb506ac8fb", "title": "Cumulative Reasoning with Large Language Models"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "db9507cdd3e2d7d9c90ed185bd831e55c62dcec9", "title": "AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration"}, {"paperId": "c695c4e68561347564ea0daa50dc339dff73d8c5", "title": "Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory"}, {"paperId": "a122863d239643453195424c04067e89406246e1", "title": "Enhancing Chat Language Models by Scaling High-quality Instructional Conversations"}, {"paperId": "546d0624adfc6e18fb87d8cc77e7705bb9ea7445", "title": "LIMA: Less Is More for Alignment"}, {"paperId": "2f3822eb380b5e753a6d579f31dfc3ec4c4a0820", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models"}, {"paperId": "3556722b4703a21abafd2f9388743202943f4503", "title": "Accelerating Transformer Inference for Translation via Parallel Decoding"}, {"paperId": "131f499e4d3503da93022d07fcf804a18483bea9", "title": "WizardLM: Empowering Large Language Models to Follow Complex Instructions"}, {"paperId": "1b2fbd2a1e68749a5239bc8b6210d614ecdbe1d4", "title": "Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels"}, {"paperId": "12c6be503e4e5b7c9cb1810152d4364f26628a8d", "title": "Data-centric Artificial Intelligence: A Survey"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "42a14d824caa3348046eb34c37e2ab7985faa7a3", "title": "High-throughput Generative Inference of Large Language Models with a Single GPU"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "53d128ea815bcc0526856eb5a9c42cc977cb36a7", "title": "Toolformer: Language Models Can Teach Themselves to Use Tools"}, {"paperId": "a1f8082505c7e90b0a033e1b9da0a97d67aad66c", "title": "Accelerating Large Language Model Decoding with Speculative Sampling"}, {"paperId": "d8e9f8c8a37cb4cd26b92ad0d942d641cd512644", "title": "Fast Inference from Transformers via Speculative Decoding"}, {"paperId": "6c943670dca38bfc7c8b477ae7c2d1fba1ad3691", "title": "Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks"}, {"paperId": "2c994fadbb84fb960d8306ee138dbeef41a5b323", "title": "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models"}, {"paperId": "7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6", "title": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers"}, {"paperId": "3fa70115248377c3d1517c9f978791a296fbc1dd", "title": "Large Language Models Can Self-Improve"}, {"paperId": "cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1", "title": "Scaling Instruction-Finetuned Language Models"}, {"paperId": "e070ff286709db28312e08b52b05539debe88146", "title": "Measuring and Narrowing the Compositionality Gap in Language Models"}, {"paperId": "22b58dce1a13382418b8372bbd50ed3b2533f899", "title": "ByteTransformer: A High-Performance Transformer Boosted for Variable-Length Inputs"}, {"paperId": "99832586d55f540f603637e458a292406a0ed75d", "title": "ReAct: Synergizing Reasoning and Acting in Language Models"}, {"paperId": "e826ac71dad8c4ce36d82fb7add43e3d306bb7e1", "title": "Making Language Models Better Reasoners with Step-Aware Verifier"}, {"paperId": "87c5b281fa43e6f27191b20a8dd694eda1126336", "title": "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"}, {"paperId": "e7ad08848d5d7c5c47673ffe0da06af443643bda", "title": "Large Language Models are Zero-Shot Reasoners"}, {"paperId": "67dc33f02c8b5f24cd213b6b5fb5c74cead581aa", "title": "A Survey on Non-Autoregressive Generation for Neural Machine Translation and Beyond"}, {"paperId": "23dd78e424d32f6a48660dcd67ce994b8a7db8be", "title": "STaR: Bootstrapping Reasoning With Reasoning"}, {"paperId": "5f19ae1135a9500940978104ec15a5b8751bc7d2", "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "1900de2b966ca55ee5ca24ec94d5debe66e80c5b", "title": "Dynamic N:M Fine-Grained Structured Sparse Attention Mechanism"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "ff0b2681d7b05e16c46dfb71d980cc2f605907cd", "title": "Finetuned Language Models Are Zero-Shot Learners"}, {"paperId": "28692beece311a90f5fa1ca2ec9d0c2ce293d069", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"}, {"paperId": "509b16378deec0fb6bbec1d7aeb32a4bdeedddb1", "title": "GSPMD: General and Scalable Parallelization for ML Computation Graphs"}, {"paperId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "title": "The Power of Scale for Parameter-Efficient Prompt Tuning"}, {"paperId": "90d5e6f8d3b9f2617b3a3cf00fb02e730eb011cb", "title": "Accelerating Sparse Deep Neural Networks"}, {"paperId": "50796b0f3edf9cb5ff1e447c298b33755378aa4f", "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling"}, {"paperId": "040ad14a2c97e51510889ae6a0c3c23b29da801d", "title": "TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale Language Models"}, {"paperId": "12b71736392209b4292471b7da0aed71ba2aa545", "title": "ZeRO-Offload: Democratizing Billion-Scale Model Training"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "73e0f38ab49b19b86321016b773e15f1d02e3a72", "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"}, {"paperId": "0c775d7ed34fb4690b4291490778649ae75c48d2", "title": "TurboTransformers: an efficient GPU serving system for transformer models"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "3836ccb33191799e748e8e96f85a813eaf650ff8", "title": "Data Movement Is All You Need: A Case Study on Optimizing Transformers"}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"}, {"paperId": "ac04ed0f3ae0f5b269c9b3e0d1232007d60dbf7e", "title": "Memory-Efficient Pipeline-Parallel DNN Training"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "738215a396f6eee1709c6b521a6199769f0ce674", "title": "Compressing Large-Scale Transformer-Based Models: A Case Study on BERT"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "dc52b09089704ebd6f471177474bc29741c50023", "title": "Fast Transformer Decoding: One Write-Head is All You Need"}, {"paperId": "3fd7c9ba742dd2b435afa75217847e5087e2f2a8", "title": "PipeDream: generalized pipeline parallelism for DNN training"}, {"paperId": "70fe1f854bc59092ded4bf2939a6624a80e5e4c3", "title": "ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"}, {"paperId": "7823292e5c4b05c47af91ab6ddf671a0da709e82", "title": "Once for All: Train One Network and Specialize it for Efficient Deployment"}, {"paperId": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"}, {"paperId": "d79a26226393f687ddbc375e32055b40b8ad8d38", "title": "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"}, {"paperId": "5e04881e91bff952d102d967c4ffb498ec30d4af", "title": "Blockwise Parallel Decoding for Deep Autoregressive Models"}, {"paperId": "3d8b62c060f8444907e7c975c6ae590373b51ed4", "title": "Quantizing deep convolutional networks for efficient inference: A whitepaper"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "15e81c8d1c21f9e928c72721ac46d458f3341454", "title": "Non-Autoregressive Neural Machine Translation"}, {"paperId": "aa959e6402dce927b46988e50f1662d8762bcd1c", "title": "Software-Hardware Codesign for Efficient Neural Network Acceleration"}, {"paperId": "ce6403e99465e5e8a48d5c2017fc23976e29fe59", "title": "FlexFlow: A Flexible Dataflow Accelerator Architecture for Convolutional Neural Networks"}, {"paperId": "67d968c7450878190e45ac7886746de867bf673d", "title": "Neural Architecture Search with Reinforcement Learning"}, {"paperId": "7601b995303f953955004db7b9b8b206c0e02ff8", "title": "Learning Structured Sparsity in Deep Neural Networks"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "642d0f49b7826adcf986616f4af77e736229990f", "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"}, {"paperId": "80d800dfadbe2e6c7b2367d9229cc82912d55889", "title": "One weird trick for parallelizing convolutional neural networks"}, {"paperId": "e5ae8ab688051931b4814f6d32b18391f8d1fa8d", "title": "Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation"}, {"paperId": "d1120d67b700e4dfe8b39eb1e48fbdea4e1a0c43", "title": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face"}, {"paperId": null, "title": "Llm zoo: democratizing chatgpt"}, {"paperId": null, "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023"}, {"paperId": "7ca954844bc1dd405bc43445b1c990e42d865095", "title": "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society"}, {"paperId": "d1a6b3a5efde3783b53f822dc8dd00aaac934b95", "title": "SpecInfer: Accelerating Generative LLM Serving with Speculative Inference and Token Tree Verification"}, {"paperId": null, "title": "Openllms: Less is more for open-source models, July 2023a. URL https://github.com/imoneoi/openchat"}, {"paperId": null, "title": "Alpacaeval: An automatic evaluator of instruction-following models. https://github.com/tatsu-lab/alpaca_eval, 2023b"}, {"paperId": "9d7a75601e0e50dd68d40cfb8ef0e891dad797a6", "title": "Orca: A Distributed Serving System for Transformer-Based Generative Models"}, {"paperId": "afb989488eb1801111553006c01e99441b205bc7", "title": "PetS: A Unified Framework for Parameter-Efficient Transformers Serving"}, {"paperId": null, "title": "Various model parallelism (Lu et"}, {"paperId": null, "title": "LangChain, October 2022. URL https://github.com/hwchase17/ langchain"}, {"paperId": "53d8b356551a2361020a948f64454a6d599af69f", "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation"}, {"paperId": null, "title": "Triton inference server"}, {"paperId": null, "title": "Tensorflow serving"}, {"paperId": null, "title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts"}, {"paperId": null, "title": "NVIDIA"}, {"paperId": null, "title": "Question: (Knowledge) What are some potential implications of using a single-use plastic bottle versus a reusable bottle on both the environment and human health?"}, {"paperId": "014a4b733d14afcd46cb86707f3a6404cae2f348", "title": "[\"Less is more\"]."}, {"paperId": "6a630ac89d7c0a57eb7bf4cb30dd5946bcf3ccce", "title": "google,\u6211,\u8428\u5a1c"}, {"paperId": null, "title": "SenseTime"}, {"paperId": null, "title": "Military feats. I have led my men to great victories against the kingdom's enemies, winning many battles through strength of arms and tactical cunning"}, {"paperId": null, "title": "OpenChat-13B (a) Metric: general quality (FastChat)"}, {"paperId": null, "title": "Free jazz emerged in the late 1950s and 1960s as musicians explored free improvisation and atonality, moving away from traditional jazz structures"}, {"paperId": null, "title": "Research has suggested that some individuals may have a genetic predisposition towards seeking out thrilling or risky experiences, which may include enjoying the sensation of being scared"}, {"paperId": null, "title": "Eliminate distractions: Try to limit distractions as much as possible, such as by turning off your phone or closing your email"}, {"paperId": null, "title": "Creating a schedule helps you allocate time for each task and ensures that you complete them within the allotted time"}, {"paperId": null, "title": "Over the decades"}, {"paperId": null, "title": "communicated, sharedideas, andgainedknowledge"}, {"paperId": null, "title": "Some cultures place a greater emphasis on seeking excitement and thrill, while others may prioritize safety and security, which can impact whether individuals enjoy scary experiences or avoid them"}, {"paperId": null, "title": "Distractions such as social media, emails, and phone notifications can waste a lot of time. Try to limit them by turning off notifications or setting specific times to check them"}, {"paperId": null, "title": "Communicative agents"}, {"paperId": null, "title": "Single-use plastic bottles may release harmful chemicals such as bisphenol A (BPA) and phthalates into the water or liquid they contain, posing a risk to human health"}, {"paperId": null, "title": "There are a variety of time management tools available, such as calendars, to-do lists, and productivity apps, that can help you stay organized and on track with your tasks"}, {"paperId": null, "title": "Your Highness, it would be the greatest honor to join your exalted table and share in this magnificent feast with my fellow knights and loyal subjects"}, {"paperId": null, "title": "If you have too many tasks to handle, consider delegating some of them to others who can help you. This will allow you to focus on more important tasks and manage your time more effectively"}, {"paperId": null, "title": "Taking breaks can actually improve productivity and help prevent burnout. It's important to schedule short breaks throughout the day to recharge and refocus"}, {"paperId": null, "title": "Single-use plastic bottles contribute to the accumulation of microplastics in the environment, which can be ingested by humans through food and water, leading to potential health risks"}, {"paperId": null, "title": "Harrison Chase"}, {"paperId": null, "title": "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding"}, {"paperId": null, "title": "SoT answers the question from five aspects, whereas the normal answer only mentions one aspect"}, {"paperId": null, "title": "It's important to prioritize your own tasks and not take on too much at once. Saying no to requests that don't align with your goals or schedule can help you manage your time more effectively"}, {"paperId": null, "title": "Delegate tasks: If possible, delegate tasks to others to free up time for more important activities"}, {"paperId": null, "title": "The Jazz Age was the period during the 1920s when jazz music and dance styles like the Charleston became popular cultural phenomena in American and European society"}, {"paperId": null, "title": "Bebop emerged in the early 1940s with artists like Dizzy Gillespie and Charlie Parker experimenting with faster tempos, complex chord changes, and unpredictable melodic phrasing"}, {"paperId": null, "title": "Single-use plastic bottles can harbor harmful bacteria, leading to an increased risk of disease if not disposed of properly. Reusable bottles, when cleaned regularly, pose a lower risk"}, {"paperId": null, "title": "Allegiance to king. I pledge my sword, my loyalty, and my life to serve and protect my noble king and this great kingdom"}, {"paperId": null, "title": "If the person asks follow-up questions and seems genuinely interested in what you're saying, then they are likely interested in the conversation and not just being polite"}, {"paperId": null, "title": "Remember, improving time management skills takes practice and perseverance. Be patient with yourself and keep trying until you find strategies that work well for you"}, {"paperId": null, "title": "My name is Sir Percival of Camelot, knight of the Round Table and protector of King Arthur's realm. 2. Lands and titles. I hold fiefdom over the lands of Westmarch and Ravenshire"}, {"paperId": null, "title": "SoT's answer (Claude) (Orange texts are the skeleton"}, {"paperId": null, "title": "Introducing claude, May 2023"}, {"paperId": null, "title": "Automating inter-and { Intra-Operator } parallelism for distributed deep learning"}, {"paperId": null, "title": "Overthedecades,jazzhasbecomewovenintothefabricofAmericansociety"}, {"paperId": null, "title": "Stablevicuna-13b,"}, {"paperId": null, "title": "Assisted generation: a new direction toward low-latency text generation"}, {"paperId": null, "title": "Alpaca: A strong, replicable instruction-following model"}, {"paperId": null, "title": "Emerging in the late 1940s and early 1950s, cool jazz was a more subdued, mellow style that broke from the high-energy virtuosic improvisation of bebop"}]}