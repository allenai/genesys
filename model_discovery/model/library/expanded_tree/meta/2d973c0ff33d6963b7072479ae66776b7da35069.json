{"paperId": "2d973c0ff33d6963b7072479ae66776b7da35069", "abstract": "Deep learning is computationally intensive, with significant efforts focused on reducing arithmetic complexity, particularly regarding energy consumption dominated by data movement. While existing literature emphasizes inference, training is considerably more resource-intensive. This paper proposes a novel mathematical principle by introducing the notion of Boolean variation such that neurons made of Boolean weights and inputs can be trained -- for the first time -- efficiently in Boolean domain using Boolean logic instead of gradient descent and real arithmetic. We explore its convergence, conduct extensively experimental benchmarking, and provide consistent complexity evaluation by considering chip architecture, memory hierarchy, dataflow, and arithmetic precision. Our approach achieves baseline full-precision accuracy in ImageNet classification and surpasses state-of-the-art results in semantic segmentation, with notable performance in image super-resolution, and natural language understanding with transformer-based models. Moreover, it significantly reduces energy consumption during both training and inference.", "venue": "arXiv.org", "year": 2024, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This paper proposes a novel mathematical principle by introducing the notion of Boolean variation such that neurons made of Boolean weights and inputs can be trained efficiently in Boolean domain using Boolean logic instead of gradient descent and real arithmetic."}, "embedding": {"model": "specter_v2", "vector": [0.41186338663101196, 0.6139944791793823, -0.24463780224323273, -0.14531636238098145, -0.25399234890937805, 0.012212023138999939, 0.2955528199672699, -0.36366724967956543, -0.4306033253669739, -0.1544281393289566, 0.05039547011256218, 0.20947617292404175, 0.6286755800247192, -0.3162532150745392, -0.1448485553264618, -0.15319305658340454, -0.6553506255149841, -0.093998983502388, 0.3924318253993988, -0.09634809195995331, 0.06551001965999603, -0.06770943105220795, -0.8489197492599487, 0.2308540642261505, -0.1838546246290207, 1.5209065675735474, -0.2587939202785492, 0.8594558238983154, -0.5076924562454224, 0.6344635486602783, 0.24171309173107147, -0.32716989517211914, 0.4868108928203583, 0.08140764385461807, -0.5438153147697449, -0.372743159532547, 0.6929248571395874, -0.49051085114479065, -0.8961581587791443, 1.4148085117340088, -0.3296869099140167, -0.023878445848822594, 0.24055977165699005, -0.7277209162712097, 0.04301876574754715, 0.7089099287986755, 0.44070273637771606, 0.8756546974182129, -0.7299020290374756, -0.2716693580150604, 1.2348451614379883, -0.9839335083961487, 0.11067617684602737, 1.5503711700439453, 0.769766628742218, 0.49789753556251526, -0.3764229416847229, -0.3650808036327362, 0.5261566638946533, 0.2674916386604309, -0.9362130165100098, -0.24665355682373047, 0.15225376188755035, -0.040821850299835205, 1.636869192123413, -0.44185253977775574, 0.34310367703437805, 0.3584485352039337, 0.23319482803344727, 1.2650644779205322, 0.4793449342250824, -0.5985828638076782, 0.2041170299053192, -0.2516745924949646, 0.5504197478294373, 0.9719100594520569, 0.10529522597789764, -0.22105979919433594, -0.9692894816398621, 0.2798522710800171, 0.28815335035324097, 0.33261430263519287, 0.2657003700733185, -0.20968097448349, -0.1690293550491333, 0.29032421112060547, 0.7374969124794006, 0.45834508538246155, -0.23306787014007568, 1.4696013927459717, 0.4730505049228668, 0.24642592668533325, -0.19841931760311127, 0.44477081298828125, -0.12020571529865265, 0.6046512722969055, -1.1282328367233276, 0.08406143635511398, -0.11949490010738373, 0.7556455731391907, -0.27715396881103516, 0.5596330761909485, -0.41025641560554504, 0.05314299091696739, 0.9273001551628113, 0.13207027316093445, 0.2690214216709137, -0.7312182784080505, 0.14953485131263733, -0.5507333278656006, -0.18768684566020966, -0.7566796541213989, -0.09472460299730301, -0.3655744791030884, -1.166797161102295, -0.6320409178733826, -0.2635960876941681, 0.3644059896469116, -1.194563627243042, 0.5561373233795166, -0.7896250486373901, 0.32846599817276, 0.18898695707321167, 0.4427529573440552, 0.5879679918289185, 0.5578209757804871, -0.035082586109638214, 0.3906548321247101, 1.28835928440094, -0.8872196078300476, -0.3911111354827881, -0.823516309261322, -0.11976103484630585, 0.34655818343162537, -0.05347547307610512, 0.2583812177181244, -1.3205347061157227, -1.0716840028762817, -1.0690664052963257, -0.1062503382563591, -0.9625134468078613, -0.22925342619419098, 1.1317431926727295, 0.7841284275054932, -1.3305721282958984, 0.6195240616798401, -0.4804929792881012, 0.08940386772155762, 1.1288472414016724, 0.4447551667690277, 0.7770438194274902, -0.17724819481372833, -1.0630004405975342, 0.3865543603897095, 0.15227219462394714, -0.39586779475212097, -0.4396062195301056, -0.3496900796890259, -1.0737918615341187, 0.3590107858181, 0.037890005856752396, -0.7286297082901001, 1.0475594997406006, -0.5444221496582031, -0.9435444474220276, 0.9091949462890625, -0.365632027387619, -0.585781991481781, 0.29218873381614685, 0.16007502377033234, -0.31508108973503113, 0.08171790093183517, -0.7404147982597351, 0.9555818438529968, 0.8072572350502014, -0.07635364681482315, -0.028293171897530556, 0.0320996530354023, -0.07935721427202225, -0.5928731560707092, -0.48816320300102234, 0.6691638827323914, -0.46910184621810913, -0.40956929326057434, 0.9473698735237122, 0.8417961597442627, -0.31457334756851196, 0.11907973885536194, -0.25837939977645874, -0.7273280620574951, 0.7324669361114502, -0.053346674889326096, 0.5225237607955933, -0.9538042545318604, -0.7941576242446899, 0.14163686335086823, 0.2291250377893448, -0.4267691373825073, -0.32927340269088745, -0.6713308691978455, -0.36968812346458435, 0.5170549154281616, -0.05347415432333946, -0.5568228363990784, 0.023072760552167892, -0.5231914520263672, -0.655344545841217, 0.26134034991264343, 0.5262991786003113, 1.2664252519607544, -0.5725721716880798, -0.11747357249259949, -0.05503120273351669, 0.26645785570144653, -0.8690460324287415, 0.6947645545005798, -0.39516469836235046, -0.28589314222335815, -0.006943400949239731, 0.6477598547935486, 0.26328352093696594, -0.2540934085845947, 0.6516185998916626, -1.0692143440246582, 0.24243305623531342, 0.6257998943328857, -0.3757517635822296, 1.2255046367645264, -0.2410450577735901, 1.013845443725586, 0.10974052548408508, -1.2032277584075928, 0.5296128988265991, -0.04685317724943161, -0.10575615614652634, -0.5764043927192688, 0.6226656436920166, 0.012879638932645321, -0.5423547029495239, 0.3612717092037201, 0.7170167565345764, 0.9342831969261169, -0.6616289019584656, -0.3611137866973877, 0.9199344515800476, -0.8569403290748596, 0.15705591440200806, 0.10905662924051285, 1.092586874961853, 0.18426372110843658, 0.344503790140152, -0.19083262979984283, 0.17095334827899933, -0.7240930795669556, 0.22025035321712494, 0.9771410226821899, 0.04687647521495819, 0.9121610522270203, 0.9804192781448364, -0.7982321977615356, -0.6368013620376587, -0.14040151238441467, 0.3964279592037201, 0.9080401659011841, 0.1569901406764984, 0.45297545194625854, -1.0112746953964233, -0.5777913331985474, -0.3361677825450897, -0.5220828056335449, -0.1431528478860855, 0.01795363612473011, -0.365018755197525, -1.1578807830810547, 0.9767187833786011, 0.49439409375190735, 1.5220004320144653, -0.3331737518310547, -0.45431211590766907, -0.6121084094047546, 0.52748042345047, -1.101927638053894, 0.13247451186180115, 0.8716256022453308, -0.5631527900695801, 0.0738958865404129, 0.35963475704193115, -0.2476205974817276, 0.6097772717475891, -0.8245877027511597, 1.0914418697357178, -0.7551403641700745, -0.6970134973526001, 0.1991189867258072, 0.8951278328895569, -0.3963804244995117, -0.22430375218391418, -0.005165868438780308, -0.29360342025756836, -0.15073418617248535, 0.5094292163848877, 0.23455244302749634, -0.12565776705741882, -0.082868792116642, -0.29758894443511963, -0.02597680687904358, 0.17328931391239166, 0.42578041553497314, 1.0124260187149048, 0.25453129410743713, 0.22455565631389618, -0.8568991422653198, 0.27385419607162476, 0.28839656710624695, -0.5682308077812195, 0.17388053238391876, -0.1894327849149704, -0.19721221923828125, 0.5555372834205627, -0.40654951333999634, -0.2220565676689148, -0.7102997899055481, 0.18865154683589935, -0.6688671112060547, -0.4212368130683899, -0.19468903541564941, 0.06498252600431442, -0.35027891397476196, 0.14675849676132202, -0.05460204929113388, 0.15067358314990997, 0.3873074948787689, 0.4967724084854126, -0.798530638217926, 0.9020817875862122, 0.2719494104385376, -0.010870961472392082, 0.33280545473098755, 0.2437841147184372, -0.47893473505973816, -0.40189656615257263, 0.01441541500389576, -0.5022969841957092, -0.4462948739528656, 0.57912278175354, -0.46711012721061707, -0.5887337923049927, 0.188628688454628, -0.9043945670127869, -0.30771905183792114, -0.10029517114162445, -0.6992567777633667, 0.030488241463899612, -1.4066390991210938, -1.2105424404144287, -0.42752981185913086, -0.7382944226264954, -1.2521934509277344, 0.08958964049816132, 0.41055047512054443, -0.2564813792705536, -0.4315647482872009, -1.110399603843689, -0.40839242935180664, 0.8916745185852051, -0.10722663998603821, 0.7226400375366211, -0.292751282453537, -0.6674688458442688, -0.32962465286254883, -0.08918308466672897, 0.7798603773117065, -0.640150249004364, 0.23313091695308685, -0.9999443292617798, 0.4868002235889435, -0.2809127867221832, -0.6765775084495544, 0.7613986134529114, 0.4247005581855774, 1.5144126415252686, 0.4825423061847687, -0.2722121775150299, 0.5318554043769836, 1.6583269834518433, -0.7075991034507751, 0.3411727249622345, -0.00788887869566679, 0.6593479514122009, -0.29240235686302185, -0.4601473808288574, 0.26685094833374023, -0.1273193657398224, 0.11182934790849686, 0.4652971029281616, -0.16518226265907288, -0.5418011546134949, -0.002636120654642582, 0.18686702847480774, 0.6160582304000854, 0.726618230342865, 0.04966270551085472, -1.020230770111084, 0.753978967666626, -0.6694427132606506, -0.8651114106178284, 0.8217159509658813, 0.5661469101905823, 0.1613166481256485, 0.5505768656730652, -0.7105127573013306, 0.18209685385227203, 0.6833466291427612, 0.7245392799377441, -0.7978762984275818, -0.8163681030273438, -0.3097935616970062, 1.1022727489471436, 0.7438364028930664, 0.30555498600006104, -0.6866182088851929, 0.5262786149978638, 14.678656578063965, 0.8152055740356445, -0.6007457375526428, 0.546254575252533, 1.2590831518173218, 0.15460900962352753, -0.2805728614330292, -0.17515257000923157, -1.2047841548919678, -0.17229485511779785, 0.8174857497215271, 0.9117587208747864, 0.4237126410007477, 0.6200177669525146, -0.17198790609836578, 0.03449385240674019, -0.5642665028572083, 0.7328488230705261, 0.7027814984321594, -1.6511662006378174, -0.038621269166469574, -0.2673667073249817, 0.5957192182540894, 0.3377387821674347, 0.6327931880950928, 0.6183679103851318, 0.22269640862941742, -0.6725504398345947, 0.5905614495277405, 0.21378548443317413, 1.1517200469970703, 0.1814059317111969, 0.5870446562767029, -0.09463556110858917, -0.9669462442398071, -0.4437880218029022, -0.3798648715019226, -0.7974422574043274, -0.09097851812839508, 0.36755019426345825, -0.3968665599822998, -0.6979270577430725, 0.239200621843338, 0.7451212406158447, 0.05178258195519447, 0.16020219027996063, -0.27527084946632385, 0.6829017400741577, -0.13858790695667267, -0.1318446695804596, 0.17389851808547974, 0.5707330703735352, -0.04420396313071251, 0.241164430975914, -0.45400261878967285, -0.03110688552260399, 0.20680643618106842, 0.6796436309814453, -0.9100469350814819, -0.8708968162536621, 0.048846837133169174, -0.2541992664337158, -0.007626401260495186, 0.8373534083366394, -0.36827361583709717, 0.06194913387298584, -0.37521976232528687, 0.28534290194511414, 0.10840655863285065, 0.10112961381673813, -0.6821528077125549, -0.42160460352897644, 0.2529676854610443, -0.7027060985565186, 0.4018746018409729, 0.5676398873329163, -1.1655895709991455, -0.5335093140602112, -0.705424427986145, -0.33327481150627136, 0.41089844703674316, -0.8999737501144409, -0.3366957902908325, 0.6558658480644226, -0.4985966384410858, 0.17482048273086548, 0.8919587135314941, -1.3144667148590088, -0.10682442039251328, 0.3493606448173523, -1.3116949796676636, -0.4401744604110718, -0.3966676592826843, -0.40846896171569824, -0.1370227038860321, -0.1526576727628708, 0.6487460136413574, -0.1041383445262909, -0.4570678174495697, 0.05517633259296417, -0.33055734634399414, 0.39948463439941406, -0.5392871499061584, -0.8276078104972839, 0.7835444211959839, 0.40179556608200073, -0.29331985116004944, -0.34524819254875183, -0.23282381892204285, 0.543626606464386, -0.8240058422088623, -0.02808072790503502, 0.04963647201657295, -0.1751282811164856, -0.2637866139411926, -0.7415656447410583, -0.531204879283905, 0.457782119512558, 0.21461601555347443, 0.24725012481212616, -0.21716365218162537, -0.357621431350708, -0.7301629781723022, -0.5722869038581848, -1.3435215950012207, -0.004260664340108633, 0.3139258027076721, -0.7433162331581116, -0.3611553907394409, -0.3086177408695221, 0.09132968634366989, -0.9739673733711243, -0.4664708077907562, 0.24327154457569122, 0.11877941340208054, -0.28274890780448914, 1.4254603385925293, -0.2902596592903137, 0.880977988243103, 0.6282137036323547, -0.3571259081363678, -0.043146394193172455, 0.1935955286026001, -0.7171816229820251, 0.0524861142039299, 0.12970611453056335, 0.25082120299339294, -0.5263336896896362, 0.6727357506752014, 0.5306313037872314, 0.20953024923801422, -0.6859769821166992, -1.0874942541122437, 0.1402139812707901, -0.17833010852336884, -0.5635656714439392, 0.232183039188385, -0.11561823636293411, -0.28704139590263367, -0.3601824641227722, 0.8983078598976135, 0.6886339783668518, -0.20013774931430817, -0.2936810553073883, -0.046364959329366684, 0.005549753084778786, -0.031712017953395844, -1.0891239643096924, -1.3792657852172852, -1.8181620836257935, 0.35425499081611633, -0.9703840613365173, 0.018861448392271996, -0.705030620098114, -0.4279453158378601, 0.15925827622413635, -0.4941202998161316, 0.30798399448394775, 0.6120766401290894, 0.23452402651309967, -0.8131688833236694, -0.7493144869804382, -0.6776713132858276, 0.30705198645591736, 0.37323904037475586, -1.1038264036178589, 0.42023542523384094, -0.3457200229167938, 0.20187753438949585, 0.770072877407074, 0.4583963453769684, -0.10918934643268585, -0.542900562286377, -0.9881329536437988, 0.20197813212871552, 0.01266525499522686, 0.07305289059877396, -1.2693902254104614, 0.7147513031959534, 0.3985159993171692, 0.2566296458244324, 0.026369452476501465, 0.46719980239868164, -0.9261283278465271, -0.7474426031112671, 0.6183730959892273, -0.8203619122505188, -0.2553970217704773, 0.2622235417366028, -0.6404831409454346, -0.20777848362922668, 0.3716440796852112, 0.5116606950759888, -1.0210505723953247, -1.2512000799179077, -0.06245821714401245, -0.5650163888931274, 0.13728640973567963, 0.011373142711818218, -0.35505369305610657, -1.3214811086654663, -0.013455251231789589, -0.31066250801086426, 0.23292316496372223, -0.48679235577583313, 0.3643556237220764, 0.5439593195915222, -0.7003239393234253, 0.3529081344604492, 0.23052969574928284, -0.6818501353263855, 0.37034520506858826, 0.3546752333641052, 0.539064347743988, -0.9449113607406616, 0.3004412055015564, 0.013185170479118824, 0.14614972472190857, -0.8330382108688354, -0.1555211842060089, 1.4420095682144165, -0.38343024253845215, -0.20610114932060242, 1.3018395900726318, -0.553284227848053, -0.5582685470581055, 0.5615693926811218, -1.5149049758911133, -0.20201033353805542, -0.18951639533042908, 0.3315630853176117, 0.042349059134721756, 0.22958393394947052, 0.6965810656547546, -0.45110973715782166, 0.057793647050857544, 0.2648313045501709, -0.6126044988632202, 0.31581634283065796, 0.1713242083787918, -0.8126974105834961, 0.5187129378318787, 0.6190054416656494, -1.010972023010254, -0.8626363277435303, -0.7786321043968201, -0.2122436761856079, 0.024669116362929344, 0.689123809337616, -0.4622054696083069, -1.1673789024353027, 0.8249590992927551, 0.6578677296638489, 0.359840452671051, 0.5985015630722046, -0.18898622691631317, 0.17793776094913483, 0.8573883175849915, 0.22464148700237274, -0.5051043033599854, -0.2130824476480484, 1.1715645790100098, 0.8098101615905762, -0.6796740293502808, 0.454037070274353, -0.46121132373809814, -0.09793667495250702, 1.0968080759048462, 0.5222678184509277, -0.22174224257469177, 1.0962872505187988, 0.37358763813972473, -0.4067763090133667, 0.1480529010295868, -0.657367467880249, -0.14491339027881622, 0.524779200553894, 0.7774672508239746, 0.4662097096443176, 0.03914427012205124, 0.36869603395462036, 1.1413562297821045, 0.21121764183044434, -0.10314130783081055, 0.4068058133125305, 0.5189422369003296, -0.2767319679260254, 0.6251212358474731, -0.2356138378381729, 0.5764870643615723, -0.9126009941101074, -0.43790364265441895, 0.11522205173969269, 0.587834894657135, 0.5762686729431152, 0.44556674361228943, 1.3116008043289185, 0.06357018649578094, 0.43283140659332275, 0.2475002110004425, 0.798244833946228, -0.28713130950927734, -0.2373184859752655, -0.37264323234558105, -0.6890512108802795, -0.05637509375810623, -0.13770227134227753, -0.4745353162288666, -0.5302109718322754, -0.29725125432014465, 0.4948987662792206, -0.38220489025115967, 0.5968753099441528, 0.7753506302833557, 0.31275877356529236, 1.204106092453003, -0.2372399866580963, -0.7309733033180237, -0.4110817313194275, -0.5584540963172913, 0.1724531203508377, -0.6845381855964661, -0.1372009813785553, -0.0026839792262762785, -0.137264221906662, 0.004785657860338688]}, "authors": [{"authorId": "2265731720", "name": "Van Minh Nguyen"}, {"authorId": "2303404711", "name": "Cristian Ocampo"}, {"authorId": "51295156", "name": "Aymen Askri"}, {"authorId": "2265680527", "name": "Louis Leconte"}, {"authorId": "2303376744", "name": "Ba-Hien Tran"}], "references": [{"paperId": "f39f01f39813fd8ed791f88ec7378a44dbf2a175", "title": "BiBench: Benchmarking and Analyzing Network Binarization"}, {"paperId": "f47ae084b19cd872996fc046a9b3745ab5b5a47e", "title": "Join the High Accuracy Club on ImageNet with A Binary Neural Network Ticket"}, {"paperId": "2c994fadbb84fb960d8306ee138dbeef41a5b323", "title": "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models"}, {"paperId": "13d17ec511b6119424b296f5b79797ae5d11412b", "title": "Towards Accurate Binary Neural Networks via Modeling Contextual Dependencies"}, {"paperId": "e1541e4a18df4957719d04cb0abad6e1db5f3446", "title": "RB-Net: Training Highly Accurate and Efficient Binary Neural Networks With Reshaped Point-Wise Convolution and Balanced Activation"}, {"paperId": "eacbc5a026a966beb4e648bb0cfeca299c73c5af", "title": "AdaBin: Improving Binary Neural Networks with Adaptive Binary Sets"}, {"paperId": "a47326d7996def2cd015c4d2558b63073bb6846d", "title": "Low-Precision Stochastic Gradient Langevin Dynamics"}, {"paperId": "85167901371c71519241f8681db13fd85ba961e2", "title": "BiT: Robustly Binarized Multi-distilled Transformer"}, {"paperId": "faaecac0fb0b92463c4254b6f7ba7800ee03956b", "title": "INSTA-BNN: Binary Neural Network with INSTAnce-aware Threshold"}, {"paperId": "fb2307f7ce7c6868429ee3ee15d6eaf311ecba5c", "title": "BiBERT: Accurate Fully Binarized BERT"}, {"paperId": "a71f7b8cabb00175a1dd0e094b69cd03c398b95a", "title": "Neural Network Training on In-Memory-Computing Hardware With Radix-4 Gradients"}, {"paperId": "d31a2a1b1d2378030aed23f6888bce02897e20e7", "title": "F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization"}, {"paperId": "f03c10c618f116db293afd316db949c5a822b49b", "title": "Binary Neural Networks as a general-propose compute paradigm for on-device computer vision"}, {"paperId": "693d1b61112ef52f096f2586f7fe4080bae83c99", "title": "Accurate Neural Training with 4-bit Matrix Multiplications at Standard Formats"}, {"paperId": "a8ae13b550a7f56a8f02d45150f1790cec808a2b", "title": "PokeBNN: A Binary Pursuit of Lightweight Accuracy"}, {"paperId": "f6282d4bbd942f7f08ceb549cb4ee647a22aaa50", "title": "DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation"}, {"paperId": "04e283adccf66742130bde4a4dedcda8f549dd7e", "title": "A Survey of Quantization Methods for Efficient Neural Network Inference"}, {"paperId": "29c0aac2059bd5afefbe6861bec90c2f75a7383f", "title": "Enabling Binary Neural Network Training on the Edge"}, {"paperId": "344953cc0367ccd91fa7f6bd5497d2b4e3b6d3bf", "title": "Ascend: a Scalable and Unified Architecture for Ubiquitous Deep Neural Network Computing : Industry Track Paper"}, {"paperId": "6359ac3411fc183284d6f2c61f2312c1a001a53f", "title": "MeliusNet: An Improved Network Architecture for Binary Neural Networks"}, {"paperId": "c375e121926db9551f224ff235018ea38bb159b7", "title": "BinaryBERT: Pushing the Limit of BERT Quantization"}, {"paperId": "24d93e81ebfa7764411a3db15c14503e6af3bc38", "title": "Estimating GPU memory consumption of deep learning models"}, {"paperId": "c6b5ecf84e304cda4dbd1687cf1902790d65cc6e", "title": "A Statistical Framework for Low-bitwidth Training of Deep Neural Networks"}, {"paperId": "ede693be48dc0a3572f267e75989e4a54d95ff74", "title": "Rotated Binary Neural Network"}, {"paperId": "b0349a32497cf2586d784b639999c38d6a167c9d", "title": "Searching for Low-Bit Weights in Quantized Neural Networks"}, {"paperId": "c7fe98e2d70519e19080b3a3de1e22a5dcacb802", "title": "How to Evaluate Deep Neural Network Processors: TOPS/W (Alone) Considered Harmful"}, {"paperId": "295034bdd68163b1ad845b30c5e68fe99ba02b6b", "title": "Bidirectional compression in heterogeneous settings for distributed or federated learning with partial participation: tight convergence guarantees"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "1f4d63653ab845330dc804b542f0b0f8926ca7f3", "title": "Binary DAD-Net: Binarized Driveable Area Detection Network for Autonomous Driving"}, {"paperId": "bc3706d600729f1b9007c91052258c7c22864f69", "title": "Binary Neural Networks: A Survey"}, {"paperId": "0ff02cddd42e0434ff0e768ab1117ff326e3db6c", "title": "Memory devices and applications for in-memory computing"}, {"paperId": "ed9aef35fd6b96f0f357d703143c0941331b5968", "title": "Training Binary Neural Networks with Real-to-Binary Convolutions"}, {"paperId": "1fab639219c601ddaf73430249035c827fbc1d7f", "title": "ReActNet: Towards Precise Binary Neural Network with Generalized Activation Functions"}, {"paperId": "ac7859ad7a0a93597774ef7c3da48a516db4937e", "title": "Proximity Preserving Binary Code using Signed Graph-Cut"}, {"paperId": "5bfd582327a0c60c925f714d2df2171fc4dec201", "title": "An Energy-Efficient Deep Convolutional Neural Network Inference Processor With Enhanced Output Stationary Dataflow in 65-nm CMOS"}, {"paperId": "70f04285f1af8b0dc41a9339f2512ae6dcc41266", "title": "AdderNet: Do We Really Need Multiplications in Deep Learning?"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "d1faad340b63ac3c507701cb72ce5fef6c911c77", "title": "Estimation of energy consumption in machine learning"}, {"paperId": "272427c548378d28723a45a255a2d3cb1c4a0c95", "title": "Mirror Descent View for Neural Network Quantization"}, {"paperId": "c304745c22b4cc70578eb1b86714d358565ca102", "title": "Forward and Backward Information Retention for Accurate Binary Neural Networks"}, {"paperId": "176df808669b51ad2d07b6defdb46d6300ba399e", "title": "In-Memory Computing: Advances and prospects"}, {"paperId": "c0aaee2337e5af680e5dca1bfc349a737dfec573", "title": "Fixing the train-test resolution discrepancy"}, {"paperId": "d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea", "title": "Energy and Policy Considerations for Deep Learning in NLP"}, {"paperId": "c1e8d9df347b8de53fc2116615b1343ba327040d", "title": "Latent Weights Do Not Exist: Rethinking Binarized Neural Network Optimization"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "0cdef47d342cae516f67efd6e4991f4825043b70", "title": "Regularizing Activation Distribution for Training Binarized Deep Networks"}, {"paperId": "7c22a6a07e89461178b794681c675b209332ee15", "title": "Error Feedback Fixes SignSGD and other Gradient Compression Schemes"}, {"paperId": "e76daf581e9ece87a08eac16e033b3459930a17c", "title": "Proximal Mean-Field for Neural Network Quantization"}, {"paperId": "78e1c397fe469ae4dfce3770c8352c397d63fc43", "title": "Structured Binary Neural Networks for Accurate Image Classification and Semantic Segmentation"}, {"paperId": "6045cccf284bf2d0ca407b4146ada29c1df038ad", "title": "Benchmark Analysis of Representative Deep Neural Network Architectures"}, {"paperId": "7c42d7ff616efc45a42b264b0da6c74e8141a9ed", "title": "ProxQuant: Quantized Neural Networks via Proximal Operators"}, {"paperId": "117fd3a77f887f827e7f3521964b51eb788d33c5", "title": "Interstellar: Using Halide's Scheduling Language to Analyze DNN Accelerators"}, {"paperId": "4bd23d951846832bdf550df574cdec07bc08dec1", "title": "Bi-Real Net: Enhancing the Performance of 1-bit CNNs With Improved Representational Capability and Advanced Training Algorithm"}, {"paperId": "a8e1b91b0940a539aca302fb4e5c1f098e4e3860", "title": "LQ-Nets: Learned Quantization for Highly Accurate and Compact Deep Neural Networks"}, {"paperId": "16f1e6a02f180c6f42b35e68dd8f07a8e0a07190", "title": "Bridging the Accuracy Gap for 2-bit Quantized Neural Networks (QNN)"}, {"paperId": "1f0bbcbcea15b60b39012e9aedf4dac42dff9411", "title": "Understanding Reuse, Performance, and Hardware Cost of DNN Dataflow: A Data-Centric Approach"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "0bd9716274618e4f81677be43bf7a452412aa71f", "title": "High-Accuracy Low-Precision Training"}, {"paperId": "710bcef2c7c2e6a1ba455c136cb0aaa5580fb8e5", "title": "Model Compression and Acceleration for Deep Neural Networks: The Principles, Progress, and Challenges"}, {"paperId": "d07284a6811f1b2745d91bdb06b040b57f226882", "title": "Decoupled Weight Decay Regularization"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "2fd67bc7d239b26d9e2453fecd29e88cc7a8627d", "title": "A method to estimate the energy consumption of deep neural networks"}, {"paperId": "6aeb583c084ad2eb709154ec91f22ca8d6de4425", "title": "NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study"}, {"paperId": "7ba5d3808e117e7a68dc40331ce1d483ceeedcb2", "title": "Enhanced Deep Residual Networks for Single Image Super-Resolution"}, {"paperId": "5054edca22325ddd3507b860f9af4a961baea009", "title": "NTIRE 2017 Challenge on Single Image Super-Resolution: Methods and Results"}, {"paperId": "ee4a012a4b12d11d7ab8c0e79c61e807927a163c", "title": "Rethinking Atrous Convolution for Semantic Image Segmentation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "5690cae43495be52bab835023e34997ea2784abf", "title": "Training Quantized Nets: A Deeper Understanding"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "3f116042f50a499ab794bcc1255915bee507413c", "title": "Efficient Processing of Deep Neural Networks: A Tutorial and Survey"}, {"paperId": "3ac1df952ffb63abb4231a4410f6f8375ccdfe79", "title": "Designing Energy-Efficient Convolutional Neural Networks Using Energy-Aware Pruning"}, {"paperId": "43e2519d094bff2fc10c3b9ea944a2457e3884be", "title": "Loss-aware Binarization of Deep Networks"}, {"paperId": "c9d64aaa2007b60ef7814acc895dd90f15578a20", "title": "QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding"}, {"paperId": "d2e4147eecae6f914e9e1e9aece8fdd2eaed809f", "title": "Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations"}, {"paperId": "7ad92444a3b2f8b88042dfdfa975650f0c8f7c84", "title": "Simple Evolutionary Optimization Can Rival Stochastic Gradient Descent in Neural Networks"}, {"paperId": "7f7c2e6cf49d88825e79b66f9ae8108fcb64d11a", "title": "Emerging Memory Technologies: Recent Trends and Prospects"}, {"paperId": "5ec594e9f5ca4b629be28625cd78c882514ea3be", "title": "Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks"}, {"paperId": "9a786d1ecf77dfba3459a83cd3fa0f1781bbcba4", "title": "An Analysis of Deep Neural Network Models for Practical Applications"}, {"paperId": "c8c494ee5488fe20e0aa01bddf3fc4632086d654", "title": "The Cityscapes Dataset for Semantic Urban Scene Understanding"}, {"paperId": "b649a98ce77ece8cd7638bb74ab77d22d9be77e7", "title": "XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks"}, {"paperId": "ffdaa12ef011de9dbf43be46d45a3abcc8288965", "title": "Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "a5733ff08daff727af834345b9cfff1d0aa109ec", "title": "BinaryConnect: Training Deep Neural Networks with binary weights during propagations"}, {"paperId": "642d0f49b7826adcf986616f4af77e736229990f", "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"}, {"paperId": "599e769b65ab64f247926f38c9c080c45a12271a", "title": "Subdominant Dense Clusters Allow for Simple Learning and High Computational Performance in Neural Networks with Discrete Synapses."}, {"paperId": "bd6507b5c9deaf87bda81e59ce15b2309df0bf37", "title": "ShiDianNao: Shifting vision processing closer to the sensor"}, {"paperId": "2946c4e29b057d3543f09b89f547965895676d19", "title": "Single image super-resolution from transformed self-exemplars"}, {"paperId": "e0dc99255a62a1856d6e0f7871d76b4672b6e021", "title": "A Max-Sum algorithm for training discrete neural networks"}, {"paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e", "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"}, {"paperId": "b7cf49e30355633af2db19f35189410c8515e91f", "title": "Deep Learning with Limited Numerical Precision"}, {"paperId": "feaa7e295c7a43ec52091ed9ade1a9a1e5d9bed2", "title": "Expectation Backpropagation: Parameter-Free Training of Multilayer Neural Networks with Continuous or Discrete Weights"}, {"paperId": "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "title": "Fully convolutional networks for semantic segmentation"}, {"paperId": "888d4ade3a7552ebafe997988a82cdd16128961e", "title": "Benchmarking the Memory Hierarchy of Modern GPUs"}, {"paperId": "eb42cf88027de515750f230b23b1a057dc782108", "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition"}, {"paperId": "da802f3afe64c2f238de14766f5754d8a7772d93", "title": "Adult Neuroplasticity: More Than 40 Years of Research"}, {"paperId": "947620a1854655ed91a86b90d12695e05be85983", "title": "1.1 Computing's energy problem (and what we can do about it)"}, {"paperId": "260d0adfad93dfd02c7a945dee48c60f8fb938e1", "title": "Energy characterization and instruction-level energy model of Intel's Xeon Phi processor"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "c7338140c446bb1b8c1a2c24aa380890214dc0d7", "title": "Low-Complexity Single-Image Super-Resolution based on Nonnegative Neighbor Embedding"}, {"paperId": "e83def3979608b59d1b99860a6204efc0d6599cd", "title": "Dynamic binary neural networks and evolutionary learning"}, {"paperId": "d1dce9ad419d8c7037980a9ea28506ed0e640bba", "title": "On Single Image Scale-Up Using Sparse-Representations"}, {"paperId": "046b512b5a561d8009e5f01b504ac834c570cdcd", "title": "Generalization Learning in a Perceptron with Binary Synapses"}, {"paperId": "092217c2267f6e0673590aa151d811e579ff7760", "title": "Roofline: an insightful visual performance model for multicore architectures"}, {"paperId": "9a1ed876196ec9733acb1daa6d65e35ff0414291", "title": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics"}, {"paperId": "b9164335be5808ddd59786869a9f992331af5218", "title": "The organization of behavior: A neuropsychological theory"}, {"paperId": "3c61e6b55597cf37b19d2e4b38fc66b9c85c97b9", "title": "Ultra-Low Precision 4-bit Training of Deep Neural Networks"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "00d1d3e5335a8d08ea3e4cf629b54b7c1f47ca80", "title": "Dimension-Free Bounds for Low-Precision Training"}, {"paperId": "5d7911c93ddcb34cac088d99bd0cae9124e5dcd1", "title": "Derivation of Backpropagation in Convolutional Neural Network ( CNN )"}, {"paperId": "28135fd3e80dda50a673cd556f10b9b972005d27", "title": "Binarized Neural Networks"}, {"paperId": "4f8d648c52edf74e41b0996128aa536e13cc7e82", "title": "Deep Learning"}, {"paperId": null, "title": "A Method for Stochastic Optimization"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}]}