{"paperId": "934942934a6a785e2a80daa6421fa79971558b89", "abstract": "Recent works have demonstrated that transformer can achieve promising performance in computer vision, by exploiting the relationship among image patches with self-attention. They only consider the attention in a single feature layer, but ignore the complementarity of attention in different layers. In this article, we propose broad attention to improve the performance by incorporating the attention relationship of different layers for vision transformer (ViT), which is called BViT. The broad attention is implemented by broad connection and parameter-free attention. Broad connection of each transformer layer promotes the transmission and integration of information for BViT. Without introducing additional trainable parameters, parameter-free attention jointly focuses on the already available attention information in different layers for extracting useful information and building their relationship. Experiments on image classification tasks demonstrate that BViT delivers superior accuracy of 75.0%/81.6% top-1 accuracy on ImageNet with 5M/22M parameters. Moreover, we transfer BViT to downstream object recognition benchmarks to achieve 98.9% and 89.9% on CIFAR10 and CIFAR100, respectively, that exceed ViT with fewer parameters. For the generalization test, the broad attention in Swin Transformer, T2T-ViT and LVT also brings an improvement of more than 1%. To sum up, broad attention is promising to promote the performance of attention-based models. Code and pretrained models are available at https://github.com/DRL/BViT.", "venue": "IEEE Transactions on Neural Networks and Learning Systems", "year": 2022, "citationCount": 10, "influentialCitationCount": 0, "openAccessPdf": {"url": "https://arxiv.org/pdf/2202.06268", "status": "GREEN"}, "tldr": {"model": "tldr@v2.0.0", "text": null}, "embedding": {"model": "specter_v2", "vector": [0.3472113609313965, 0.42747762799263, 0.06856735050678253, 0.6223198771476746, -0.205862358212471, 0.16880464553833008, 0.7768495678901672, -0.3789452314376831, -0.14242246747016907, -0.5501134395599365, 0.2830122113227844, 0.41713011264801025, 0.3507118821144104, -0.036464154720306396, -0.3005395829677582, -0.10606549680233002, -0.32172733545303345, 0.1077483743429184, 0.7145271301269531, -0.6566072106361389, 0.09068918228149414, -0.6634815335273743, -0.9380541443824768, 0.21269096434116364, 0.10885039716959, 1.4637545347213745, 0.7237915396690369, 0.8544374704360962, -0.06766220927238464, 0.44105735421180725, 0.4004748463630676, -0.4606957733631134, 0.33285290002822876, -0.10875208675861359, -0.6354449391365051, -0.03242963179945946, 0.8174225091934204, -0.1878042072057724, -0.545462429523468, 0.9256823658943176, -0.17753684520721436, 0.19180332124233246, 0.49096494913101196, -0.9067943096160889, -0.402553915977478, 0.15956614911556244, 0.32458311319351196, 1.031063437461853, -0.7401943206787109, -0.38314372301101685, 1.218461513519287, -1.0812482833862305, -0.07563355565071106, 1.3923368453979492, 0.3973003029823303, 0.35582056641578674, -0.1239515170454979, -0.5054857730865479, 0.8607516884803772, 0.27159613370895386, -0.5841152667999268, -0.06745607405900955, 0.31521984934806824, -0.27157309651374817, 1.9414925575256348, -0.8395161032676697, 0.3867410123348236, 0.676136314868927, 0.29993268847465515, 1.2288265228271484, -0.2403721809387207, -0.7353946566581726, -0.5524676442146301, -0.012557042762637138, 0.7482331395149231, 0.7261236906051636, -0.05912752449512482, 0.1171855479478836, -0.7850853204727173, -0.024546785280108452, 0.8346480131149292, 0.02759455144405365, 0.16231341660022736, -0.3846546709537506, -0.32618772983551025, 0.7278918027877808, 0.992678701877594, 0.4211873412132263, -0.4239780008792877, 1.0366768836975098, 0.44903337955474854, 0.003443777095526457, -0.34360945224761963, 0.39650025963783264, 0.27334997057914734, 1.1307505369186401, -0.3838712275028229, -0.0233421940356493, -0.6193137168884277, 1.2942743301391602, 0.19933348894119263, 0.4722423851490021, -0.7049106955528259, 0.3842035233974457, 1.216561198234558, 0.41562819480895996, 0.26748400926589966, -0.5758494734764099, 0.052979975938797, -0.6828715801239014, -0.40225622057914734, -1.001417875289917, 0.3360985815525055, -0.40709197521209717, -0.7885771989822388, -0.6036024689674377, -0.49966731667518616, 0.6749168634414673, -1.095005750656128, 0.4945369064807892, -0.2959405183792114, -0.23035939037799835, -0.3258615732192993, 0.41306987404823303, 0.8171311616897583, 0.12751343846321106, 0.30538949370384216, 0.5776783227920532, 1.4920257329940796, -1.0454256534576416, -0.4003286063671112, -0.9411147236824036, -0.53459632396698, -0.17055678367614746, 0.27300727367401123, -0.003292685141786933, -1.0839507579803467, -1.326828956604004, -1.0472089052200317, -0.1789463311433792, -0.5109952688217163, -0.10809929668903351, 0.9861213564872742, 0.15031839907169342, -0.9399752020835876, 0.6409226059913635, -0.22587038576602936, -0.42168399691581726, 0.8495970964431763, 0.3236779570579529, 0.49558570981025696, 0.03008328005671501, -1.0750447511672974, 0.2311282604932785, -0.01350149791687727, -0.5610378980636597, -0.89198237657547, -0.5410324335098267, -1.027714729309082, 0.07681075483560562, 0.10553848743438721, -1.0216789245605469, 1.075661540031433, -0.7751626968383789, -0.6087493300437927, 0.6518729329109192, -0.3039289712905884, -0.07372550666332245, -0.12577122449874878, -0.13909263908863068, 0.052512090653181076, -0.01373637281358242, -0.060432158410549164, 0.7623454928398132, 0.942934513092041, -0.17560921609401703, -0.2692466080188751, 0.03800554573535919, -0.46477603912353516, -0.2868442237377167, -0.6931689977645874, 0.8786190152168274, -0.723572850227356, -0.34583497047424316, 0.22178272902965546, 0.6492529511451721, 0.3947998583316803, -0.2099398970603943, -0.27329352498054504, -1.0574486255645752, 0.9774662256240845, 0.37928882241249084, 0.21610422432422638, -0.908357560634613, -0.9274904727935791, -0.3554190397262573, 0.21745577454566956, -0.11687303334474564, -0.7995221018791199, 0.34252867102622986, -0.37484312057495117, 0.03038910962641239, 0.18440082669258118, -0.5909777879714966, -0.10016679018735886, -0.5185946822166443, -0.8782467246055603, -0.03140760585665703, 0.4126947224140167, 1.147459626197815, -0.5904332399368286, -0.2652679681777954, 0.10004974901676178, 0.3400631248950958, -0.8208089470863342, 1.0735070705413818, -0.2643202543258667, -0.008185240440070629, -0.28852036595344543, 0.04444632679224014, -0.031784649938344955, -0.5393940210342407, 0.0644243061542511, -0.9887568354606628, 0.3826201260089874, 0.4543532431125641, 0.08975868672132492, 1.1596544981002808, -0.08799399435520172, 0.902988612651825, -0.04101447016000748, -0.9784954786300659, 0.4957219362258911, 0.2542833387851715, -0.27954694628715515, -0.9076404571533203, 0.4432215988636017, -0.2050553858280182, -0.6535903215408325, 0.3841879367828369, 0.34083014726638794, 1.2686141729354858, -0.15145547688007355, -0.11566824465990067, 1.0629286766052246, -0.28719818592071533, -0.3307538330554962, 0.692994236946106, 0.5161421298980713, 0.4443088471889496, 0.4528266489505768, -0.33355024456977844, -0.053931817412376404, -0.6336070895195007, -0.1931249052286148, 0.7880402207374573, 0.302484393119812, 1.1839001178741455, 0.5096701979637146, -0.8817110657691956, -0.46637043356895447, 0.026212379336357117, 0.6662519574165344, 1.3276418447494507, 0.2986795902252197, 0.16338303685188293, -0.7949193716049194, -0.30820146203041077, -0.4630219638347626, -0.5264628529548645, -0.7780866026878357, -0.4477810859680176, -0.1832749992609024, -0.9519526958465576, 0.7263022661209106, 0.22210903465747833, 1.497820496559143, -0.9710189700126648, -0.6522895693778992, -0.4337976574897766, 0.22251850366592407, -1.0176104307174683, -0.7965327501296997, 0.37477433681488037, -0.3515060544013977, -0.35488730669021606, -0.11953798681497574, -0.2822149395942688, 0.1273210644721985, 0.10968763381242752, 0.940361499786377, -0.6852155327796936, -0.6558213829994202, 0.598088264465332, 0.6609806418418884, -1.074614405632019, -0.11674786359071732, 0.2183595448732376, -0.20996876060962677, 0.16435077786445618, 0.06524818390607834, 0.306630939245224, -0.3094025254249573, 0.3256801962852478, -0.34541231393814087, -0.023809067904949188, -0.036532316356897354, 0.4610462188720703, 0.8702351450920105, -0.5538766980171204, 0.21109093725681305, -0.8569912910461426, 0.5554742217063904, 0.24206559360027313, -0.47334378957748413, 0.24224337935447693, -0.4680185914039612, -0.2568702697753906, 0.1877373605966568, -0.5865979790687561, -0.22002087533473969, -0.7227458953857422, 0.4783531725406647, -0.9055248498916626, -0.17420831322669983, -0.2930600047111511, 0.09852636605501175, -0.389221727848053, 0.5151637196540833, 0.3753097355365753, 0.15990929305553436, 0.2447589933872223, -0.02544519491493702, -1.130811333656311, 0.6827644109725952, 0.23448997735977173, -0.14866949617862701, 0.12182387709617615, -0.026833388954401016, -0.884380578994751, -0.808068573474884, -0.5278318524360657, -0.2086702138185501, -0.3376125395298004, 0.4859156608581543, -0.563766598701477, -0.9986283183097839, 0.1741548329591751, -0.8558302521705627, -0.3892025053501129, 0.13536497950553894, -0.21927925944328308, -0.4296512007713318, -1.0577558279037476, -0.4918256103992462, -0.1487494707107544, -0.99794602394104, -1.1987850666046143, 0.20060309767723083, 0.42579466104507446, -0.18934565782546997, -0.6733706593513489, -0.3731892704963684, -0.26177698373794556, 0.9963526129722595, -0.2685394883155823, 0.4266020953655243, -0.25147363543510437, -0.4769883155822754, 0.02745908685028553, -0.22940677404403687, 0.5247874855995178, -0.14382758736610413, -0.00235678069293499, -1.3078969717025757, 0.3665617108345032, -0.21884530782699585, -0.5227474570274353, 0.8621315956115723, 0.6038891077041626, 0.7014822959899902, 0.4336596429347992, -0.5411702394485474, 0.8609121441841125, 1.4293200969696045, -0.6714111566543579, 0.3097389340400696, 0.4569282531738281, 1.2413893938064575, -0.07769569754600525, -0.2936249375343323, 0.2852656841278076, 0.4828759729862213, 0.3167548179626465, 0.9015347957611084, -0.6260936856269836, -0.9684080481529236, -0.46069979667663574, -0.14844664931297302, 0.32207614183425903, 0.28426745533943176, 0.08475121110677719, -1.0553640127182007, 1.1122459173202515, -1.0973719358444214, -0.8031632900238037, 0.7627747654914856, 0.8529629111289978, 0.12452661991119385, -0.4219408631324768, -0.3060026466846466, -0.4685609042644501, 0.7683316469192505, 0.11494830250740051, -0.481095552444458, -0.509701132774353, -0.16272033751010895, 0.5033711194992065, 0.2598928213119507, 0.5721170902252197, -0.6013473272323608, 0.7932332158088684, 14.637116432189941, 0.7361891865730286, -0.281454473733902, 0.7001844644546509, 0.6145132184028625, 0.30858176946640015, -0.11896894127130508, -0.049914419651031494, -1.3158782720565796, -0.41165682673454285, 0.3445688784122467, 0.5261989235877991, 0.5479180216789246, 0.15249213576316833, -0.619003415107727, 0.20815247297286987, -0.32408422231674194, 1.071476936340332, 0.7733490467071533, -1.1687911748886108, 0.5438656806945801, 0.3364538550376892, 0.30122724175453186, 0.7890004515647888, 0.7828808426856995, 0.5836513042449951, 0.3640548288822174, -0.31117916107177734, 0.4541260600090027, 0.2217421978712082, 0.898967444896698, 0.14855287969112396, 0.14551986753940582, 0.10508307069540024, -0.9824265241622925, -0.0697518065571785, -0.7948575615882874, -0.8187230825424194, -0.4558589458465576, -0.059898052364587784, -0.29879122972488403, -0.5947529673576355, 0.3882288932800293, 0.6677470803260803, -0.11185212433338165, 0.3941258490085602, -0.04148728772997856, 0.3664287328720093, 0.08781981468200684, -0.08380674570798874, 0.34623152017593384, 0.9205270409584045, 0.42955517768859863, 0.08435177057981491, -0.16859012842178345, 0.12623144686222076, 0.1808222383260727, 0.5809088349342346, -0.4394354522228241, -0.45997223258018494, -0.2626808285713196, 0.2999188303947449, -0.17990390956401825, 1.244131326675415, 0.18742625415325165, 0.24731269478797913, -0.1527649611234665, 0.04482867941260338, 0.40536150336265564, 0.37737059593200684, -0.660315752029419, -0.35057613253593445, 0.32210084795951843, -0.335122287273407, 0.6143060922622681, 0.7387571334838867, -0.3823641538619995, -0.34018412232398987, -0.9414588809013367, -0.35783547163009644, 0.48630625009536743, -1.0864077806472778, -0.631241500377655, 1.2086963653564453, -0.08219657093286514, 0.04508938267827034, 0.8278368711471558, -0.7238682508468628, -0.32047179341316223, 0.6878173351287842, -1.4957727193832397, -1.1313663721084595, -0.4458826780319214, 0.28592216968536377, -0.13462255895137787, -0.4023744761943817, 0.5850188732147217, -0.31380292773246765, -0.08157352358102798, 0.32489845156669617, -0.7489712238311768, 0.07555434852838516, 0.03124220483005047, -0.4401874840259552, 0.769433856010437, 0.2372344732284546, 0.0027800551615655422, -0.1486145555973053, -0.197099968791008, 0.3304746747016907, -0.721060037612915, -0.10491013526916504, 0.17605403065681458, -0.7696885466575623, -0.42014071345329285, -0.7517794966697693, -0.8688150644302368, 0.2889125943183899, 1.0622650384902954, 0.28272390365600586, -0.16880543529987335, 0.3351246118545532, -1.0046045780181885, -0.5581831932067871, -0.6654340624809265, -0.22528298199176788, -0.025514014065265656, -0.6225699186325073, -0.580409586429596, -0.2760471701622009, 0.28340062499046326, -0.7317647337913513, -0.21852733194828033, -0.3175376057624817, 0.44061630964279175, -0.43385371565818787, 1.4175705909729004, -0.29064926505088806, 0.1902795433998108, 0.9483957886695862, -0.33968913555145264, -0.6183140873908997, -0.49650317430496216, -0.8709542751312256, 0.2283688634634018, 0.3402915298938751, 0.2240489274263382, -0.809951901435852, -0.12065824866294861, 0.36819198727607727, 0.0813407450914383, -0.3340955376625061, -0.33147671818733215, -0.23341940343379974, -0.07506496459245682, -0.4636867642402649, 0.18903036415576935, -0.22104650735855103, -0.20576779544353485, 0.3072366714477539, 0.6364508271217346, 0.4665188193321228, 0.2386641651391983, -0.606674313545227, 0.49652644991874695, -0.3290773630142212, -0.032292094081640244, -0.8058599829673767, -0.6693490147590637, -1.3575470447540283, -0.36263853311538696, -1.0152521133422852, -0.1941964477300644, -1.0743824243545532, -0.01997186616063118, 0.3284917175769806, -0.5985191464424133, 0.4355965852737427, 0.11304089426994324, 0.18210965394973755, -0.21462246775627136, -0.4087335467338562, -0.60749351978302, 0.6878174543380737, 1.19527006149292, -0.9469619393348694, 0.25781184434890747, -0.26797735691070557, -0.6086375713348389, 0.535248339176178, 0.29154887795448303, -0.5432807803153992, -0.7858980298042297, -1.2525296211242676, 0.2578515112400055, -0.2854135036468506, 0.6071728467941284, -1.1395426988601685, 1.065577745437622, 0.6566709876060486, 0.3024020791053772, -0.1115448847413063, 0.6492602825164795, -0.5931156277656555, -0.8298196792602539, 0.3569908142089844, -0.5750450491905212, -0.17280806601047516, 0.5640232563018799, -0.476624071598053, -0.39703720808029175, 0.9284005761146545, 0.3698519766330719, -1.1692063808441162, -0.862618088722229, 0.6665700674057007, -0.3697555661201477, 0.49736499786376953, -0.127617746591568, -0.457070916891098, -1.4770429134368896, -0.2764260470867157, -0.023827780038118362, 0.229409858584404, -0.8185750842094421, 0.6204306483268738, 0.7972327470779419, -1.0749226808547974, 0.12935729324817657, 0.5939353704452515, -0.09221655130386353, -0.15907078981399536, 0.5169898271560669, 0.487657755613327, -0.07554032653570175, 0.5742425918579102, -0.16230057179927826, -0.04293517395853996, -0.7387670874595642, 0.5703139305114746, 1.2408281564712524, -0.0001336761488346383, -0.35357651114463806, 1.2085392475128174, 0.7167251706123352, -0.5050773620605469, 0.18024861812591553, -0.913364052772522, -0.5409967303276062, -0.0038549622986465693, 0.6275445222854614, -0.055027227848768234, 0.05163198709487915, 0.08559946715831757, -0.6417734622955322, 0.6816993355751038, -0.038737911731004715, -0.6244463324546814, 0.19849583506584167, -0.13545146584510803, -0.15620915591716766, 0.33027949929237366, 0.6422458291053772, -1.0221171379089355, -1.0927481651306152, -0.9941134452819824, -0.8433608412742615, 0.18492162227630615, 0.5182603001594543, -0.303872287273407, -1.1407614946365356, 1.0995796918869019, 0.5906206965446472, 0.5543264150619507, 0.6657326221466064, 0.017042126506567, -0.18035711348056793, 0.781219482421875, -0.08127565681934357, -0.28159260749816895, -0.08917105197906494, 1.4535590410232544, 1.5988510847091675, -1.016047716140747, 0.1960592269897461, -0.24078886210918427, -0.8911975026130676, 0.6681138277053833, 0.5026376247406006, -0.7383272051811218, 0.9418401718139648, -0.4690486788749695, -0.1708490252494812, -0.05177658796310425, -1.1542425155639648, -0.6571303606033325, 1.1889011859893799, 1.623252511024475, 0.26940426230430603, -0.27220216393470764, 0.8299583792686462, 0.7707677483558655, 0.2857329249382019, -0.2939620912075043, 0.357746422290802, -0.2712728679180145, -0.4658755958080292, 0.6214160919189453, -0.404565691947937, 0.24203376471996307, -0.7965261340141296, -0.6056772470474243, -0.1165550947189331, 0.8824589848518372, 0.1437031626701355, 0.6929298639297485, 0.9023716449737549, 0.23234610259532928, 0.6983252167701721, -0.23746585845947266, 0.8575395941734314, -0.4323369860649109, -0.49985453486442566, 0.229890376329422, -0.8951835036277771, -0.2105952650308609, -0.12456188350915909, -0.772907018661499, 0.006407110020518303, 0.1989096701145172, 0.25519415736198425, -0.20300564169883728, 0.3065284490585327, 0.7125856280326843, 0.5469036102294922, 1.0586373805999756, -0.3005948066711426, -0.5819215774536133, -0.10138316452503204, -0.9830781817436218, 0.22468651831150055, -0.7029616236686707, 0.3147197365760803, -0.559522807598114, 0.2226950079202652, -0.06455972790718079]}, "authors": [{"authorId": "145099446", "name": "Nannan Li"}, {"authorId": "47557528", "name": "Yaran Chen"}, {"authorId": "2108752271", "name": "Weifan Li"}, {"authorId": "83352946", "name": "Zixiang Ding"}, {"authorId": "2110995913", "name": "Dong Zhao"}], "references": [{"paperId": "83c0353a25e2c675d013581ae9775324757f51f4", "title": "BNAS-v2: Memory-Efficient and Performance-Collapse-Prevented Broad Neural Architecture Search"}, {"paperId": "72e81bc41ffae1d414836169107910025aaacb75", "title": "Lite Vision Transformer with Enhanced Self-Attention"}, {"paperId": "8d46f84f16ee5cb586c6ede28c0d09df5464c1bd", "title": "Stacked BNAS: Rethinking Broad Convolutional Neural Network for Neural Architecture Search"}, {"paperId": "3becf4642b6b5bb24c914993a7f3ed088acea16f", "title": "ABCP: Automatic Blockwise and Channelwise Network Pruning via Joint Search"}, {"paperId": "cbb9446dcb53bb5efda262942f7c7b0f5b3b7195", "title": "UniNet: Unified Architecture Search with Convolution, Transformer, and MLP"}, {"paperId": "24e291fba483071eeeb49ed534fcc76b95142ee5", "title": "CNN-G: Convolutional Neural Network Combined With Graph for Image Segmentation With Theoretical Analysis"}, {"paperId": "39b492db00faead70bc3f4fb4b0364d94398ffdb", "title": "Do Vision Transformers See Like Convolutional Neural Networks?"}, {"paperId": "d645bd08fc19d52164695f9cd5ae863345459a06", "title": "AutoFormer: Searching Transformers for Visual Recognition"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "68f080e0ac836ea230cb5316fbed273c70422d75", "title": "Segmenter: Transformer for Semantic Segmentation"}, {"paperId": "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5", "title": "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training"}, {"paperId": "67571d29190faea9fbd104acd16274f8c4edf254", "title": "MLP-Mixer: An all-MLP Architecture for Vision"}, {"paperId": "9b3caaebd64a29ea068df9923603c30d6cdec85d", "title": "BNAS: Efficient Neural Architecture Search Using Broad Scalable Architecture"}, {"paperId": "e775e649d815a02373eac840cf5e33a04ff85c95", "title": "CvT: Introducing Convolutions to Vision Transformers"}, {"paperId": "421fba3813d04684b42dd667e16ed22a64f50752", "title": "BossNAS: Exploring Hybrid CNN-transformers with Block-wisely Self-supervised Neural Architecture Search"}, {"paperId": "0ae67202f0584afccefa770865d14a46655d2975", "title": "Transformer in Transformer"}, {"paperId": "dbe077f8521ecbe0a1477d6148c726d4f053d9c9", "title": "Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet"}, {"paperId": "16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78", "title": "Bottleneck Transformers for Visual Recognition"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "d21806115a79c960298cfca45a49b24682cac71a", "title": "Do Wide and Deep Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "0be032a81fda05ebb7b6da552f5efa6147563ebf", "title": "Heuristic rank selection with progressively searching tensor ring network"}, {"paperId": "672aef6f84f240005a09cf4f31ab6880584c1491", "title": "Feature Pyramid Transformer"}, {"paperId": "a581cd6010ec5ece77f1a93ca56ce6796a2308b3", "title": "A spatial-temporal attention model for human trajectory prediction"}, {"paperId": "13da774fe604027bff2951ba82f4c3d9be7e415e", "title": "Augment Your Batch: Improving Generalization Through Instance Repetition"}, {"paperId": "962dc29fdc3fbdc5930a10aba114050b82fe5a3e", "title": "End-to-End Object Detection with Transformers"}, {"paperId": "76a9f336481b39515d6cea2920696f11fb686451", "title": "Quantifying Attention Flow in Transformers"}, {"paperId": "4b3376001392ee41f901220b53f2bc9c8ca19619", "title": "ModuleNet: Knowledge-Inherited Neural Architecture Search"}, {"paperId": "9fd23345c2a516a21e19055c0640f3ca0c323f5a", "title": "Completely Automated CNN Architecture Design Based on Blocks"}, {"paperId": "2709167f1c3a03fa5b970a665ea48ed243aab582", "title": "Designing Network Design Spaces"}, {"paperId": "87f6a7c014ce206ac5b57299c07e10667d194b39", "title": "Randaugment: Practical automated data augmentation with a reduced search space"}, {"paperId": "263d5c0e8e346b794fe97bb1972ef6944da7a69d", "title": "AttnSense: Multi-level Attention Mechanism For Multimodal Human Activity Recognition"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "ed17929e66da7f8fbc3666bf5eb613d302ddde0c", "title": "CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features"}, {"paperId": "5e19eba1e6644f7c83f607383d256deea71f87ae", "title": "Searching for MobileNetV3"}, {"paperId": "66143960c0325c70329a3869cc8052f0416b87aa", "title": "GCNet: Non-Local Networks Meet Squeeze-Excitation Networks and Beyond"}, {"paperId": "8b069be51c20ac10e8ca055a111c981fbbac44d1", "title": "Universal Approximation Capability of Broad Learning System and Its Structural Variations"}, {"paperId": "ac7c74c6b8c1b41aa8f81b5593256947e13e7317", "title": "Morphological Convolutional Neural Network Architecture for Digit Recognition"}, {"paperId": "ad655c25e052fa4eeed53421344aca6f239c4c9d", "title": "Dual Attention Network for Scene Segmentation"}, {"paperId": "fe9b8aac9fa3bfd9724db5a881a578e471e612d7", "title": "Efficient Neural Architecture Search via Parameter Sharing"}, {"paperId": "537ec9c862600a9e8ac8e0a2f4aa89f2cdeef867", "title": "Deep Reinforcement Learning With Visual Attention for Vehicle Classification"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "4feef0fd284feb1233399b400eb897f59ec92755", "title": "mixup: Beyond Empirical Risk Minimization"}, {"paperId": "2788a2461ed0067e2f7aaa63c449a24a237ec341", "title": "Random Erasing Data Augmentation"}, {"paperId": "e33bc5c83f2cea403a5521385ee8e2794b311275", "title": "MAM-RNN: Multi-level Attention Model Based RNN for Video Captioning"}, {"paperId": "d0611891b9e8a7c5731146097b6f201578f47b2f", "title": "Learning Transferable Architectures for Scalable Image Recognition"}, {"paperId": "8760bc7631c0cb04e7138254e9fd6451b7def8ca", "title": "Revisiting Unreasonable Effectiveness of Data in Deep Learning Era"}, {"paperId": "d740d0a960368633ed32fc84877b8391993acdca", "title": "Multi-level Attention Networks for Visual Question Answering"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "36158edac846d8fbf0dd04a2289055d55b33e5de", "title": "Stroke Sequence-Dependent Deep Convolutional Neural Network for Online Handwritten Chinese Character Recognition"}, {"paperId": "5694e46284460a648fe29117cbc55f6c9be3fa3c", "title": "Densely Connected Convolutional Networks"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "455afd748e8834ef521e4b67c7c056d3c33429e2", "title": "Hierarchical Attention Networks for Document Classification"}, {"paperId": "51db1f3c8dfc7d4077da39c96bb90a6358128111", "title": "Deep Networks with Stochastic Depth"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58", "title": "Rethinking the Inception Architecture for Computer Vision"}, {"paperId": "a6cb366736791bcccc5c8639de5a8f9636bf87e8", "title": "Adam: A Method for Stochastic Optimization"}, {"paperId": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5", "title": "Neural Machine Translation by Jointly Learning to Align and Translate"}, {"paperId": "8a756d4d25511d92a45d0f4545fa819de993851d", "title": "Recurrent Models of Visual Attention"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "d2c733e34d48784a37d717fe43d9e93277a8c53e", "title": "ImageNet: A large-scale hierarchical image database"}, {"paperId": "0d86fbca1fbdb7c8e5a10c2d2c5a0ff3e07eea15", "title": "A Kernel Statistical Test of Independence"}, {"paperId": "6dc61f37ecc552413606d8c89ffbc46ec98ed887", "title": "Acceleration of stochastic approximation by averaging"}, {"paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7", "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}, {"paperId": "f2c5a5b90a4c271a783e97af7427db647ca5b9f9", "title": "Broad Learning System: An Effective and Efficient Incremental Learning System Without the Need for Deep Architecture"}, {"paperId": null, "title": "She is currently pursuing a Ph.D. degree in control theory and control engineering at The State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}]}