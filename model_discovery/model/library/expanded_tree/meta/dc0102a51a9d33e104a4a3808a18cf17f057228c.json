{"paperId": "dc0102a51a9d33e104a4a3808a18cf17f057228c", "abstract": "We revisit the design choices in Transformers, and propose methods to address their weaknesses in handling long sequences. First, we propose a simple layer named gated attention unit, which allows the use of a weaker single-head attention with minimal quality loss. We then propose a linear approximation method complementary to this new layer, which is accelerator-friendly and highly competitive in quality. The resulting model, named FLASH, matches the perplexity of improved Transformers over both short (512) and long (8K) context lengths, achieving training speedups of up to 4.9$\\times$ on Wiki-40B and 12.1$\\times$ on PG-19 for auto-regressive language modeling, and 4.8$\\times$ on C4 for masked language modeling.", "venue": "International Conference on Machine Learning", "year": 2022, "citationCount": 152, "influentialCitationCount": 36, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work revisit the design choices in Transformers, and proposes a simple layer named gated attention unit, which allows the use of a weaker single-head attention with minimal quality loss, and a linear approximation method complementary to this new layer, which is accelerator-friendly and highly competitive in quality."}, "embedding": {"model": "specter_v2", "vector": [0.37777629494667053, 0.6789783239364624, -0.18646474182605743, 0.0023338336031883955, -0.3540271818637848, -0.1425779163837433, 0.5489311814308167, -0.47687533497810364, -0.5328121185302734, -0.45807716250419617, 0.3475286662578583, -0.32778632640838623, 0.7301506996154785, 0.07272335886955261, -0.05072299391031265, 0.21847765147686005, -0.9528473615646362, 0.2509404420852661, 0.25970980525016785, -0.3455362617969513, -0.32349342107772827, -0.34681862592697144, -1.0924384593963623, 0.2707544267177582, 0.3610265254974365, 0.5552791357040405, 0.38920149207115173, 0.9453577995300293, -0.5896708369255066, 0.7584967613220215, 0.5001133680343628, -0.25199466943740845, -0.0308064017444849, 0.04852129891514778, -0.22116807103157043, -0.34263765811920166, 0.39220261573791504, -0.08897827565670013, -0.441145122051239, 0.5638318657875061, -0.16862133145332336, 0.08710986375808716, 0.1337958425283432, -0.8236277103424072, -0.30756157636642456, 1.049696922302246, 0.6899498701095581, 0.8321923613548279, -0.43681600689888, -0.4394054710865021, 1.5489667654037476, -1.5187007188796997, -0.10106758028268814, 1.6172206401824951, 0.5570783019065857, 0.5056439638137817, -0.06957865506410599, -0.5517597198486328, 1.0672760009765625, 0.16090290248394012, -0.7529556751251221, -0.563942015171051, -0.15034976601600647, 0.04708702489733696, 2.0546562671661377, -0.3571918308734894, 0.030532244592905045, 0.585890531539917, 0.09539138525724411, 1.2099958658218384, -0.023255206644535065, -0.6111708879470825, -0.30327966809272766, -0.06383016705513, 0.4440600574016571, 0.8857331871986389, -0.4102417230606079, 0.2620032727718353, -0.9752762317657471, 0.05436069890856743, 0.3392706513404846, 0.02564351260662079, 0.09469833970069885, -0.05751686915755272, -0.36679384112358093, 0.5622830390930176, 0.5271145105361938, 0.9886290431022644, -0.08518531918525696, 0.8449445366859436, 0.666220486164093, 0.2926604151725769, -0.09255190193653107, 0.30387797951698303, -0.054765768349170685, 0.28615158796310425, -0.8915350437164307, 0.14619867503643036, -0.3224349021911621, 1.1257632970809937, -0.23274610936641693, 0.7237353324890137, -0.7213587164878845, 0.006404715124517679, 1.1371957063674927, 0.43929508328437805, 0.3231443762779236, -0.6045641899108887, 0.2623138725757599, -0.671386182308197, -0.2374744713306427, -0.3768887519836426, -0.24657227098941803, -0.32021817564964294, -1.044379711151123, -1.0629146099090576, -0.44420546293258667, 0.3288654386997223, -0.84791499376297, 0.6625010967254639, -0.5454020500183105, 0.24624206125736237, -0.14120326936244965, 0.3080940544605255, 0.40397414565086365, 0.8065975308418274, 0.2844231426715851, 0.00511495815590024, 1.0184204578399658, -1.0585832595825195, -0.6443608999252319, -1.3551605939865112, 0.659115195274353, -0.03689170628786087, 0.4512067437171936, 0.13282205164432526, -1.2055891752243042, -1.0926129817962646, -0.8757491111755371, -0.19451361894607544, -0.3381134569644928, 0.20529122650623322, 0.9259600043296814, 0.5192047953605652, -1.5066171884536743, 0.5238054990768433, -0.41676560044288635, 0.12952229380607605, 0.28898322582244873, 0.16064995527267456, 0.42581894993782043, -0.44886961579322815, -1.3864169120788574, 0.26588740944862366, 0.11550059169530869, -0.5377234816551208, -0.4328560531139374, -1.0062665939331055, -1.1404895782470703, 0.1391637921333313, 0.42639046907424927, -0.2149166762828827, 1.485050916671753, -0.0691441223025322, -1.1630825996398926, 0.5762736797332764, -0.5979688763618469, 0.10387446731328964, 0.14999869465827942, -0.3018830716609955, -0.5577943921089172, -0.6240238547325134, -0.37616023421287537, 0.3485994040966034, 0.5621721148490906, 0.034724000841379166, -0.46048012375831604, 0.1261783242225647, -0.31381332874298096, -0.3780286908149719, -0.24820072948932648, 1.2008247375488281, -0.40143707394599915, -0.040977004915475845, 0.22054721415042877, 0.5337802171707153, -0.39765170216560364, -0.42367294430732727, -0.3235277831554413, -1.0281097888946533, 0.7106435298919678, -0.31252118945121765, 1.15337073802948, -1.0103051662445068, -0.7009727954864502, -0.15909944474697113, 0.09939997643232346, -0.11066365987062454, -0.693603515625, 0.4308025538921356, -0.5422366261482239, 0.28008294105529785, -0.05629642680287361, -1.0872951745986938, 0.1588554084300995, -0.28733137249946594, -0.8021947741508484, -0.2506629526615143, 0.15911799669265747, 1.0422732830047607, -1.1797906160354614, 0.09654523432254791, -0.1771133542060852, 0.5288738012313843, -1.0790941715240479, 1.3341208696365356, -0.22357605397701263, 0.00047530964366160333, 0.14526817202568054, -0.17001456022262573, -0.06254105269908905, -0.1799585372209549, 0.6652496457099915, -0.3934563100337982, -0.1381341516971588, 0.6442397236824036, -0.2072753608226776, 1.1792882680892944, -0.6032329797744751, 0.6165401339530945, 0.011732462793588638, -0.6277911067008972, 0.13545890152454376, 0.4259403944015503, -0.44806450605392456, -0.5667632222175598, 0.28422003984451294, 0.42271527647972107, -0.468415230512619, 0.5477720499038696, 0.8509554862976074, 0.8642253279685974, -0.312084823846817, -0.10584861040115356, 0.7308939099311829, -0.02774862013757229, 0.24362684786319733, 0.56321120262146, 0.8227885961532593, 0.3956426680088043, 0.2614881694316864, -0.27935782074928284, 0.20365141332149506, -0.8169887065887451, 0.1640208661556244, 0.6927089691162109, 0.635489821434021, 0.7280936241149902, 0.5679372549057007, -0.7458604574203491, -0.6989632844924927, 0.19020625948905945, 0.9991055130958557, 1.6031880378723145, -0.4567409157752991, -0.3928377628326416, -0.7086398601531982, -0.24583996832370758, -0.647305965423584, 0.2710370421409607, -0.16837003827095032, -0.1401248276233673, -0.8129702806472778, -0.7070780396461487, 1.0100352764129639, 0.5573710203170776, 0.7931510806083679, -0.5547037124633789, -0.35626116394996643, -0.3057211637496948, 0.4390421211719513, -1.2030917406082153, -0.5876852869987488, 0.710392415523529, -0.5475173592567444, -0.06756162643432617, 0.2135736346244812, -0.12838733196258545, 0.049235641956329346, -0.599984347820282, 1.1484571695327759, -0.3032483160495758, -0.14754962921142578, 0.013619402423501015, 0.5932689309120178, -0.38107672333717346, -0.7430900931358337, 0.34288138151168823, 0.2862951457500458, -0.24353843927383423, 0.27545493841171265, 0.2013573795557022, 0.28702160716056824, 0.11930330842733383, -0.20690594613552094, 0.07542236894369125, 0.24822455644607544, -0.05637339875102043, 0.4833519458770752, -0.3775865137577057, -0.28247952461242676, -1.271183967590332, 0.6732951402664185, 0.46296173334121704, -0.6204062700271606, 0.19084735214710236, -0.844565749168396, -0.268071711063385, 0.8083500266075134, -0.49801957607269287, -0.015531664714217186, -0.7858578562736511, 0.09976190328598022, -0.5963926911354065, -0.010545795783400536, -0.04433730989694595, -0.09925124794244766, 0.33058297634124756, 0.1876162588596344, 0.6698476076126099, 0.20861737430095673, -0.12154324352741241, 0.5146338939666748, -0.8377403020858765, 0.4747651219367981, 0.4495886266231537, 0.2661355137825012, -0.4720475673675537, -0.1837744116783142, -0.7304297089576721, -0.3716695308685303, -0.27356618642807007, -0.2283850759267807, -0.31186553835868835, 0.15615390241146088, -0.6840963363647461, -0.8692893981933594, -0.14096999168395996, -1.189516544342041, -0.3529243469238281, 0.33900195360183716, -0.6258218288421631, 0.10779498517513275, -1.1624454259872437, -1.1874994039535522, -0.8010910749435425, -0.5897647142410278, -1.1462467908859253, 0.4763961434364319, -0.1789141297340393, -0.13987621665000916, -0.4250652492046356, -0.33156678080558777, -0.49248775839805603, 1.1215386390686035, -0.7816079258918762, 0.815372109413147, -0.06875251978635788, -0.4218277931213379, -0.08234649151563644, 0.2898450195789337, 0.5715488195419312, -0.431336373090744, 0.2726597487926483, -1.184494972229004, 0.0965188518166542, -0.4667385518550873, 0.00302792526781559, 0.3851853907108307, 0.1693553924560547, 0.625758171081543, -0.19930864870548248, -0.6223745346069336, 0.26589807868003845, 1.2865068912506104, -0.5046821236610413, 0.38069188594818115, -0.12974585592746735, 1.2877509593963623, -0.12845073640346527, -0.22437967360019684, 0.24642235040664673, 0.04002627357840538, 0.3577237129211426, 0.163133904337883, -0.09312193095684052, -0.01699795201420784, -0.5432857275009155, 0.8591777682304382, 1.4312678575515747, 0.14405250549316406, -0.01714973710477352, -1.054876446723938, 0.6956795454025269, -1.0044015645980835, -0.7809526920318604, 0.4504188597202301, 0.5846004486083984, 0.15739379823207855, -0.05117035284638405, -0.1478709876537323, 0.2084793746471405, 0.5021916031837463, 0.41267648339271545, -0.060477662831544876, -0.9199166893959045, 0.012280489318072796, 0.598406970500946, 0.30873972177505493, 0.8876495957374573, 0.05136852338910103, 0.7459499835968018, 14.981698036193848, 0.8243781328201294, -0.34167322516441345, 0.655149519443512, 0.7177451848983765, 0.20469635725021362, -0.5147546529769897, 0.006612177938222885, -1.2326321601867676, -0.2929973304271698, 1.3471226692199707, 0.20733098685741425, 0.7921692728996277, 0.356148898601532, 0.15030686557292938, 0.6056132316589355, -0.6108101010322571, 0.6351050734519958, 0.33825746178627014, -1.139301061630249, 0.28590628504753113, 0.09834127128124237, -0.21040113270282745, 0.4992939829826355, 0.6933037042617798, 1.0434356927871704, 0.47039616107940674, -0.6125968098640442, 0.5847936868667603, -0.0015742783434689045, 0.9696758389472961, -0.23312044143676758, 0.16721488535404205, 0.3424116373062134, -0.9951779246330261, -0.22266721725463867, -0.45913398265838623, -1.171724796295166, 0.10854649543762207, 0.3415791392326355, -0.9073448181152344, -0.4788268506526947, -0.1273578405380249, 0.6284536123275757, 0.04876365512609482, 0.07477223128080368, -0.40696847438812256, 0.9483312368392944, 0.023340128362178802, -0.1150473803281784, 0.26185861229896545, 0.5487499237060547, 0.11960016191005707, 0.14405561983585358, 0.08441323041915894, 0.007454177364706993, 0.13411663472652435, 0.25763335824012756, -0.3406265377998352, -0.19524236023426056, -0.17778229713439941, -0.38936060667037964, -0.08638583868741989, 0.954283595085144, 0.5083860754966736, 0.20692776143550873, -0.3781135380268097, 0.1605471819639206, 0.6208616495132446, 0.19738562405109406, -0.4585709869861603, -0.027760732918977737, 0.3907056152820587, -0.2697884142398834, 0.1486111432313919, 0.5031208992004395, 0.034052811563014984, -0.43413683772087097, -0.8346787691116333, -0.5753433704376221, 0.2688765227794647, -0.7329784035682678, -0.2927617132663727, 1.1410250663757324, -0.42131441831588745, -0.09564992040395737, 0.303666889667511, -0.831953227519989, -0.10338815301656723, 0.4489644169807434, -1.3942610025405884, -0.7557284832000732, 0.035336922854185104, -0.43727031350135803, -0.29374998807907104, 0.12160611152648926, 1.202707052230835, 0.41272789239883423, -0.32083314657211304, 0.16441753506660461, -0.1924108862876892, 0.10700548440217972, -0.44524678587913513, -0.8060595989227295, 1.130623459815979, 0.6671782732009888, -0.05640092492103577, 0.15909439325332642, 0.1731506586074829, 0.5257530808448792, -0.6846691370010376, -0.1951819509267807, 0.967930257320404, -0.6226180791854858, -0.3004591464996338, -1.2204116582870483, -0.9134837985038757, 0.6384357213973999, 0.48149675130844116, -0.13401028513908386, 0.12539322674274445, 0.18392884731292725, -0.739824116230011, -0.341165155172348, -0.3808097839355469, 0.15240013599395752, 0.7728902101516724, -0.8967137932777405, 0.0074826451018452644, -0.45959991216659546, 0.7521339654922485, -1.0682392120361328, -0.23348060250282288, -0.3857136070728302, 0.06791813671588898, -0.20937539637088776, 0.8881028294563293, -0.5605037212371826, 0.6317451000213623, 0.8779060244560242, -0.11611384153366089, -0.49908092617988586, -0.3876412808895111, -0.8474125862121582, 0.03662441670894623, 0.25747159123420715, 0.5821484923362732, -0.33371782302856445, 0.15099042654037476, 0.5936434268951416, 0.05572912096977234, -0.4081347584724426, -0.7430088520050049, -0.18242572247982025, -0.1488228142261505, -0.8005502223968506, 0.4220951497554779, -0.23345106840133667, -0.09548269957304001, 0.3607639968395233, 0.29371878504753113, 0.5985711216926575, -0.33304542303085327, -0.744092583656311, 0.08600123226642609, -0.04427789896726608, 0.11766614019870758, -0.649771511554718, -0.6202419400215149, -1.376915454864502, 0.1160980686545372, -0.9413235783576965, 0.18262866139411926, -0.7501994967460632, -0.6398035287857056, 0.04459969699382782, -0.36023467779159546, 0.39526301622390747, 0.06936055421829224, -0.24825961887836456, -0.34657028317451477, -0.8443012833595276, -0.5976393222808838, 0.6496206521987915, 0.5607478618621826, -0.8441913723945618, 0.3627834916114807, -0.19216565787792206, 0.05108865350484848, 0.05196818709373474, 0.22801664471626282, -0.35803064703941345, -0.8859880566596985, -1.2924396991729736, 0.41036659479141235, -0.06533250212669373, -0.10699626058340073, -0.8440240621566772, 0.6033132076263428, 0.3880371153354645, -0.3213908076286316, 0.11694114655256271, 0.22249817848205566, -0.8663034439086914, -0.4385736584663391, 0.3132275938987732, -0.7610173225402832, 0.441324919462204, 0.378397136926651, -0.8038313388824463, -0.194656103849411, 0.7724584937095642, 0.00489042280241847, -1.1952717304229736, -0.8931775689125061, 0.5091050267219543, -0.7359715104103088, 0.23772431910037994, -0.5910308957099915, -0.10755739361047745, -0.8673052191734314, -0.22589413821697235, 0.10387500375509262, 0.2592327892780304, -0.3462768793106079, 0.9416583776473999, 0.41361987590789795, -1.0022717714309692, 0.019384492188692093, 0.20971886813640594, -0.33664828538894653, 0.0022316263057291508, 0.3316290080547333, 0.5602265000343323, -0.2226283997297287, 0.6130275726318359, 0.330678254365921, 0.19213441014289856, -1.174806833267212, 0.283840537071228, 0.9177665114402771, -0.5501281023025513, -0.28263434767723083, 1.1514912843704224, -0.28854766488075256, -0.8090068101882935, 0.24290607869625092, -1.624685287475586, -0.5536851286888123, -0.34169450402259827, 0.836703360080719, -0.020883526653051376, 0.23500646650791168, 0.0999872088432312, -0.8138797283172607, -0.18001993000507355, 0.06378170102834702, -0.542117178440094, 0.5369241237640381, 0.21491360664367676, -0.43876031041145325, 0.7823655605316162, 0.6626113653182983, -0.48985275626182556, -0.534895658493042, -0.658463716506958, -0.31912320852279663, 0.07240892946720123, 0.3991016745567322, -0.07045767456293106, -0.7437866926193237, 1.081931233406067, 0.41823041439056396, 0.31031933426856995, 0.26675790548324585, -0.35653021931648254, 0.010947605594992638, 0.4596360921859741, 0.37433892488479614, -0.2449144721031189, -0.6039751172065735, 1.4283615350723267, 1.0945905447006226, -0.469943106174469, 0.08564046025276184, -0.41278600692749023, -0.7787468433380127, 0.6077216863632202, 0.298284113407135, -0.1199789047241211, 0.772697925567627, 0.07128523290157318, 0.1305663138628006, 0.3648485243320465, -1.2944378852844238, -0.21341845393180847, 0.6994514465332031, 1.0118393898010254, 0.895149290561676, 0.05700719356536865, 0.3939366638660431, 1.155732274055481, 0.05719703435897827, -0.003862091340124607, 0.281383216381073, 0.33635029196739197, -0.12659066915512085, 0.10747004300355911, 0.11520399898290634, 0.26117122173309326, -0.7171839475631714, -0.857795774936676, 0.3759394586086273, 0.5337483882904053, 0.12191417813301086, 0.5957170724868774, 0.7022944092750549, -0.00324905663728714, 0.7109909653663635, 0.23959389328956604, 0.6138841509819031, -0.4315447211265564, -0.4430571496486664, -0.2623368203639984, -0.5575212240219116, -0.42941951751708984, 0.13563016057014465, -0.3349754214286804, -0.4731823801994324, -0.3755395710468292, 0.4291166365146637, 0.22520799934864044, -0.06070789694786072, 1.0676225423812866, 0.49761611223220825, 0.8294984698295593, -0.2625739872455597, -0.4504644572734833, -0.2961804270744324, -0.9492578506469727, 0.07205966114997864, -0.8072984218597412, 0.11286786943674088, 0.011775976978242397, -0.16438327729701996, -0.23880313336849213]}, "authors": [{"authorId": "37794086", "name": "Weizhe Hua"}, {"authorId": "3422912", "name": "Zihang Dai"}, {"authorId": "2391802", "name": "Hanxiao Liu"}, {"authorId": "2827616", "name": "Quoc V. Le"}], "references": [{"paperId": "b3848d32f7294ec708627897833c4097eb4d8778", "title": "LaMDA: Language Models for Dialog Applications"}, {"paperId": "80d0116d77beeded0c23cf48946d9d10d4faee14", "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"}, {"paperId": "4a8964ea0de47010fb458021b68fa3ef5c4b77b2", "title": "Primer: Searching for Efficient Transformers for Language Modeling"}, {"paperId": "5d032bd2632b6f5847767f39ce247098c6bbc563", "title": "Combiner: Full Attention Transformer with Sparse Computation Cost"}, {"paperId": "e3a3e85c5a32af29e13b3561f6cf070de70651de", "title": "Pay Attention to MLPs"}, {"paperId": "66c10bf1f11bc1b2d92204d8f8391d087f6de1c4", "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding"}, {"paperId": "b3bf9fe13195e9aa70e1dac04e01fcff7008e812", "title": "Perceiver: General Perception with Iterative Attention"}, {"paperId": "9ed25f101f19ea735ca300848948ed64064b97ca", "title": "Random Feature Attention"}, {"paperId": "79b4ec1aaf67a04a9afa0d8138f84b7be66c00cb", "title": "Do Transformer Modifications Transfer Across Implementations and Applications?"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3", "title": "Big Bird: Transformers for Longer Sequences"}, {"paperId": "6f68e1bb253925d8431588555d3010419f322e04", "title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "01203341a8b5b7df21dec5359afe8cc388786ebf", "title": "Wiki-40B: Multilingual Language Model Dataset"}, {"paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2", "title": "Longformer: The Long-Document Transformer"}, {"paperId": "657329c633709dd1ac34a30d57341b186b1a47c2", "title": "Efficient Content-Based Sparse Attention with Routing Transformers"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "bdbf780dfd6b3eb0c9e980887feae5f23af15bc4", "title": "GLU Variants Improve Transformer"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "f51497f463566581874c941353dd9d80069c5b77", "title": "Compressive Transformers for Long-Range Sequence Modelling"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "703685e969fed715e13937c11d7ecc5cc7c4dfd0", "title": "Transformers without Tears: Improving the Normalization of Self-Attention"}, {"paperId": "366244acdd930e488ae224ab6e2a92dc24aa7e06", "title": "Axial Attention in Multidimensional Transformers"}, {"paperId": "36e30516683032634975c53e60f3737b6e35ff80", "title": "Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting"}, {"paperId": "21da617a0f79aabf94272107184606cefe90ab75", "title": "Generating Long Sequences with Sparse Transformers"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "5132500b23d2da47129b3f4f68dd30947a29e502", "title": "CCNet: Criss-Cross Attention for Semantic Segmentation"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "43428880d75b3a14257c3ee9bda054e61eb869c0", "title": "Convolutional Sequence to Sequence Learning"}, {"paperId": "f010affab57b5fcf1cd6be23df79d8ec98c7289c", "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"}, {"paperId": "b587ee7c802a5bd222a69090f59285e0dfdb29f1", "title": "Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning"}, {"paperId": "88caa4a0253a8b0076176745ebc072864eab66e1", "title": "Language Modeling with Gated Convolutional Networks"}, {"paperId": "97fb4e3d45bb098e27e0071448b6152217bd35a5", "title": "Layer Normalization"}, {"paperId": "de5e7320729f5d3cbb6709eb6329ec41ace8c95d", "title": "Gaussian Error Linear Units (GELUs)"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "c8c4ab59ac29973a00df4e5c8df3773a3c59995a", "title": "Searching for Activation Functions"}, {"paperId": "13167f9cd8c7906ca808b01d28dca6dd951da8a5", "title": "of the Association for Computational Linguistics"}]}