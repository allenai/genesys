{"paperId": "3e6a9b9bb793458ca0e97eab78251ab38f8fd417", "abstract": "The evolution from Large Language Models (LLMs) to Multimodal Large Language Models (MLLMs) has spurred research into extending In-Context Learning (ICL) to its multimodal counterpart. Existing such studies have primarily concentrated on image-to-text ICL. However, the Text-to-Image ICL (T2I-ICL), with its unique characteristics and potential applications, remains underexplored. To address this gap, we formally define the task of T2I-ICL and present CoBSAT, the first T2I-ICL benchmark dataset, encompassing ten tasks. Utilizing our dataset to benchmark six state-of-the-art MLLMs, we uncover considerable difficulties MLLMs encounter in solving T2I-ICL. We identify the primary challenges as the inherent complexity of multimodality and image generation, and show that strategies such as fine-tuning and Chain-of-Thought prompting help to mitigate these difficulties, leading to notable improvements in performance. Our code and dataset are available at https://github.com/UW-Madison-Lee-Lab/CoBSAT.", "venue": "arXiv.org", "year": 2024, "citationCount": 1, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This work formally defines the task of T2I-ICL and presents CoBSAT, the first T2I-ICL benchmark dataset, encompassing ten tasks, and uncovers considerable difficulties MLLMs encounter in solving T2I-ICL."}, "embedding": {"model": "specter_v2", "vector": [0.6945969462394714, 0.21180255711078644, -0.033035553991794586, -0.20905067026615143, -0.7837797999382019, -0.302772581577301, 1.0404423475265503, -0.0845186859369278, -0.5255635380744934, -0.0920238196849823, 0.5659135580062866, -0.07123246788978577, 0.3661902844905853, 0.29576173424720764, -0.3089931905269623, 0.08727868646383286, -0.8519562482833862, 0.44006145000457764, -0.31388401985168457, -0.27260321378707886, -0.08571110665798187, -0.8400675058364868, -0.6953040957450867, 0.33660995960235596, 0.16679728031158447, 0.5079603791236877, 0.6063623428344727, 1.1941965818405151, -0.50368332862854, 0.3923225998878479, 0.4151042103767395, -0.32556629180908203, 0.23269569873809814, -0.1259113997220993, -0.43142879009246826, 0.4134930968284607, 0.6253935694694519, -0.39172181487083435, -0.32640233635902405, 0.4559057652950287, 0.1590782105922699, 0.3280135989189148, 0.8008700013160706, -0.39639008045196533, -0.4651881456375122, 0.5965914130210876, 0.2839491069316864, 0.16585072875022888, 0.07899826765060425, -0.548117458820343, 1.4686532020568848, -1.7178658246994019, 0.4070820212364197, 1.8110835552215576, 0.18520291149616241, 0.8073014616966248, -0.3318602442741394, -0.6976296901702881, 0.9640190601348877, -0.08530553430318832, -0.7675923705101013, -0.14412932097911835, -0.3473649322986603, -0.022722143679857254, 1.5320489406585693, -0.4932692348957062, 0.023106331005692482, 0.9813236594200134, 0.012382068671286106, 1.8123900890350342, -0.307913601398468, -1.0939167737960815, -0.5153721570968628, -0.1240234300494194, -0.4720240831375122, 0.7960410714149475, -0.8190134763717651, 0.5164064168930054, -0.7323755025863647, 0.3354366719722748, 0.2154669314622879, -0.1491803377866745, -0.07709280401468277, -0.04254872724413872, -0.6902715563774109, 0.8903468251228333, 0.47192686796188354, 0.8851412534713745, 0.37950006127357483, 0.887084424495697, 0.365660160779953, -0.044364120811223984, -0.046302009373903275, 0.32469794154167175, 0.050712015479803085, 0.6409279704093933, -0.8491620421409607, 0.40766164660453796, 0.08213920891284943, 1.053313136100769, -0.3969631493091583, -0.24388286471366882, -0.8921982645988464, 0.1952897310256958, 1.37064528465271, -0.01098486129194498, 0.5540247559547424, -0.6681526899337769, 0.8020588159561157, -0.9448117017745972, 0.03393859043717384, -0.4569520652294159, -0.10510900616645813, -0.11099930107593536, -0.4447057545185089, -1.1999413967132568, -0.3594420254230499, -0.0373523123562336, -0.6619346141815186, 0.9364327788352966, -0.25264841318130493, 0.1800805777311325, 0.33486616611480713, 0.378103643655777, 0.43938201665878296, 0.8299967050552368, 0.3563142716884613, 0.24281206727027893, 0.7049767971038818, -1.1234920024871826, -0.3803073763847351, -1.2362107038497925, 0.7160173654556274, -0.6564623713493347, 0.5084898471832275, -0.2902270257472992, -0.9865036010742188, -0.8854433298110962, -0.9627992510795593, -0.38836658000946045, -0.5418887138366699, 0.535668671131134, 0.6820804476737976, 0.2609153985977173, -1.0513384342193604, 0.37799564003944397, 0.033919718116521835, -0.3329654633998871, 0.2297978550195694, 0.1154404729604721, 0.09493926912546158, -0.756903350353241, -1.1136269569396973, 0.09529553353786469, 0.08036596328020096, -0.5119884610176086, -0.7022954225540161, -0.15874308347702026, -1.3784186840057373, -0.3829346001148224, 0.38168764114379883, -0.5393454432487488, 1.3760286569595337, -0.39563825726509094, -0.9270403981208801, 0.693899393081665, -0.46588441729545593, 0.23038585484027863, 0.6261336207389832, -0.10296749323606491, -0.2944175899028778, -0.36162060499191284, -0.06299395859241486, 1.5145624876022339, 0.49559611082077026, -0.26507097482681274, -0.381907194852829, -0.027131611481308937, -0.3320399820804596, 0.32376542687416077, -0.160946324467659, 0.699944257736206, -0.5262929797172546, -0.41999223828315735, 0.24008019268512726, 0.42364373803138733, -0.22179970145225525, -0.035711877048015594, -0.5185188055038452, -1.0734857320785522, 1.1706525087356567, 0.25377899408340454, 0.31553468108177185, -0.741618812084198, -0.7089031934738159, -0.7269794940948486, -0.13816851377487183, -0.4824848175048828, -1.4155316352844238, 1.099718689918518, -0.31127825379371643, 0.46429550647735596, -0.13166578114032745, -1.7107844352722168, 0.07270078361034393, -0.16437233984470367, -0.5998092889785767, -0.46913719177246094, 0.5442551970481873, 1.0956952571868896, -0.960749089717865, -0.2815682888031006, -0.1924181878566742, 0.32237011194229126, -0.851506233215332, 0.9622117877006531, -0.8644088506698608, 0.5805811882019043, -0.3166181147098541, -0.38466164469718933, -0.17679066956043243, -0.42242106795310974, 0.37273308634757996, -0.5501313805580139, 0.023190531879663467, 0.1788015216588974, 0.12137730419635773, 1.836296558380127, -0.5285817980766296, 0.6722493767738342, -0.46301141381263733, -0.6605514287948608, -0.09601740539073944, 0.5747984647750854, -0.18898425996303558, -0.19516606628894806, 0.17641277611255646, 0.11460983753204346, -0.6941565275192261, 0.08992757648229599, 0.7437877058982849, 0.5036771297454834, -0.3347378373146057, 0.2852301597595215, 0.2809625566005707, -0.7154889702796936, 0.6399616003036499, 0.803945779800415, 0.5878964066505432, 0.5733634233474731, 0.1587839424610138, 0.20399481058120728, 0.5244869589805603, -1.0017499923706055, -0.7275480031967163, 0.8189362287521362, 0.6010137796401978, 1.2489559650421143, 0.27129048109054565, -0.7928293943405151, -0.2303222119808197, 0.034561142325401306, 0.7588865160942078, 1.4669822454452515, -0.04724618047475815, -0.14779485762119293, -0.9877426624298096, -0.5632531642913818, -0.4249337315559387, 0.21570877730846405, -0.6513867974281311, 0.11470118165016174, -0.00326003460213542, -1.0501512289047241, 0.5673599243164062, 0.3301864266395569, 0.8305721879005432, -0.7429401278495789, -0.0454949289560318, -0.15712083876132965, -0.2680811882019043, -1.1705589294433594, -1.305954933166504, 0.21217729151248932, -0.4613620340824127, -0.1913449764251709, -0.22169175744056702, -0.3815973997116089, 0.3749234676361084, -0.6111891269683838, 0.9367752075195312, -0.5510823130607605, -0.7908151745796204, 0.6255372166633606, 0.35880571603775024, -0.6595507264137268, -0.9722476005554199, 0.02457454800605774, -0.21763582527637482, 0.017748041078448296, 0.030029358342289925, 0.8238431811332703, -0.0378580316901207, 0.02554650418460369, -0.6921109557151794, 0.6428160667419434, 0.24598579108715057, -0.16567231714725494, 0.8946813344955444, -0.5585542917251587, 0.23111221194267273, -0.9959961175918579, 1.0222620964050293, 0.1748867630958557, -0.18108950555324554, 0.5051227807998657, -0.614293098449707, -0.6416538953781128, 0.22766827046871185, -0.8288998007774353, -0.4025867283344269, -0.2327180951833725, 0.3325210213661194, -0.1524657905101776, -0.4950527548789978, 0.2071642130613327, 0.38372233510017395, 0.4091944396495819, 0.20007997751235962, 0.49818044900894165, 0.37770602107048035, 0.12826991081237793, 0.9669777750968933, -1.056381106376648, 0.6185630559921265, -0.12887908518314362, 0.051557011902332306, 0.11179733276367188, -0.03265802934765816, -0.36213430762290955, -0.7340509295463562, -0.18487268686294556, -0.6467787623405457, -0.6525974869728088, 0.7109116315841675, -0.7575057148933411, -0.5782248973846436, -0.23971302807331085, -1.0758872032165527, -0.2248138040304184, 0.38066941499710083, -0.47425687313079834, -0.5410715937614441, -0.8413912653923035, -0.9709120988845825, -0.2187562733888626, -0.6178954243659973, -1.243876576423645, 0.7302724719047546, 0.05121704190969467, -0.4464949369430542, -0.8513611555099487, -0.20591069757938385, -0.04982897266745567, 0.631057620048523, -0.5093533396720886, 0.8640965819358826, 0.06305642426013947, -0.3463725745677948, -0.5926045775413513, 0.10130413621664047, 0.27225756645202637, 0.1643090397119522, 0.33244752883911133, -0.9076164960861206, -0.02331128716468811, -0.5877493023872375, -0.6651833653450012, 0.046201784163713455, 0.17508840560913086, 0.7108796238899231, 0.31656041741371155, -0.7542742490768433, 0.22480975091457367, 1.459915280342102, -0.4577721059322357, -0.23483863472938538, -0.21298064291477203, 0.8425282835960388, 0.5201466083526611, -0.18426188826560974, 0.40161922574043274, 0.4613664746284485, 0.16630999743938446, 0.17611150443553925, 0.032896921038627625, -0.295835018157959, -0.8513826131820679, 0.7255573868751526, 1.2317407131195068, 0.7760899066925049, -0.3266131281852722, -0.99189692735672, 0.7684246897697449, -1.292565941810608, -0.5263369679450989, 0.8473753333091736, 0.5270146131515503, 0.4679358899593353, -0.7757380604743958, -0.3475054204463959, -0.6982387900352478, 0.3826722800731659, 0.3220137357711792, -0.24705471098423004, -0.2729509770870209, -0.06223287060856819, 0.06841439008712769, -0.3528732359409332, 0.7026211619377136, -0.6920406818389893, 0.6281949877738953, 14.38046646118164, 1.016593337059021, 0.08436731994152069, 0.5289962887763977, 0.9028183817863464, -0.03389909490942955, -0.567732572555542, -0.24250470101833344, -1.2446411848068237, -0.4236738383769989, 0.6584188938140869, 0.6611001491546631, 0.6316015720367432, -0.13614504039287567, 0.2656232714653015, 0.009970594197511673, -1.0306460857391357, 0.7213017344474792, 0.8853506445884705, -1.2148622274398804, 0.7492868900299072, 0.07813425362110138, 0.6564143896102905, 0.6014221906661987, 0.9277523756027222, 0.7421440482139587, 0.21207191050052643, -0.4967872202396393, 0.7115722298622131, 0.11293412744998932, 0.8943219184875488, 0.13460557162761688, 0.05026064068078995, 0.6797409653663635, -1.02504563331604, -0.4097272753715515, -0.6521072387695312, -0.8070803880691528, 0.38699430227279663, -0.1860748529434204, -0.7825473546981812, -0.3328310251235962, -0.19760146737098694, 0.9010672569274902, -0.1744127869606018, 0.06905056536197662, -0.04195224493741989, 0.48750919103622437, 0.09273162484169006, -0.049672506749629974, 0.7899155020713806, 0.14970889687538147, 0.17283500730991364, 0.16123446822166443, 0.2841412127017975, -0.1541585922241211, 0.3121964633464813, 0.5491040945053101, -0.5691933631896973, 0.21620284020900726, -0.7240779995918274, 0.009692955762147903, -0.30646106600761414, 0.7614875435829163, 0.15144991874694824, 0.40495380759239197, -0.7615802884101868, 0.3366113007068634, 0.5123658776283264, 0.37962663173675537, -0.017338989302515984, 0.3218723237514496, -0.24356979131698608, -0.8063989877700806, 0.211568683385849, 0.6447305679321289, 0.17819972336292267, -0.5140290856361389, -0.7849715352058411, -0.39622727036476135, 0.3470986485481262, -0.9209496378898621, -1.2675981521606445, 0.8721156716346741, -0.15433959662914276, -0.6313573122024536, 0.22735431790351868, -0.5177199244499207, -0.3978235423564911, 0.4731231927871704, -1.3906359672546387, -0.9896484613418579, 0.2791312336921692, -0.16589869558811188, 0.20203319191932678, -0.20184096693992615, 1.0348436832427979, 0.2117062658071518, -0.19502219557762146, 0.15588273108005524, 0.20858731865882874, 0.0056478045880794525, 0.17228250205516815, -0.7878961563110352, 0.7172659635543823, 0.0810021236538887, 0.3757879436016083, -0.1005619689822197, -0.3011874854564667, 0.10980577766895294, -0.6689180135726929, -0.19465772807598114, 0.706677258014679, -1.1489742994308472, -0.6578243970870972, -0.796502411365509, -0.229829803109169, 0.2681833505630493, 0.9537229537963867, -0.38844040036201477, 0.5227850675582886, -0.21346351504325867, -0.5614595413208008, -0.07563876360654831, -0.6914068460464478, 0.4483868479728699, 0.3958771526813507, -0.5879598259925842, 0.17616984248161316, 0.458563894033432, 0.5017904043197632, -0.7540199756622314, -0.21468482911586761, -0.4075392782688141, 0.2709743082523346, 0.15250852704048157, 1.0225272178649902, -0.479335218667984, 1.1890166997909546, 0.6753305196762085, -0.48433995246887207, -0.6696842312812805, 0.3265508711338043, -0.997369647026062, 0.5390664339065552, 0.09892866760492325, 0.8713033199310303, -0.13439583778381348, 0.25013959407806396, 0.5719399452209473, 0.7790241837501526, -0.6584866046905518, -0.33556270599365234, -0.05634354054927826, 0.38584524393081665, -0.6788285374641418, 0.12916411459445953, -0.33517831563949585, -0.2976117432117462, 0.4432834982872009, 0.3639969825744629, 0.5296199917793274, -0.06759875267744064, -0.6688977479934692, 0.6651485562324524, 0.32946836948394775, -0.18213258683681488, -0.549887478351593, -0.051033005118370056, -1.6357002258300781, 0.04245969280600548, -1.5269769430160522, 0.0778779685497284, -0.9671715497970581, 0.032963670790195465, 0.21615812182426453, 0.15915459394454956, 0.023158587515354156, 0.23443563282489777, -0.29990988969802856, 0.21296407282352448, -0.7655665278434753, -0.6798485517501831, 0.883335530757904, 1.4451196193695068, -1.0744670629501343, 0.5504984259605408, 0.0869700014591217, 0.12908600270748138, 0.04278047755360603, 0.1279880255460739, -0.2509702742099762, -1.3256579637527466, -1.4628342390060425, 0.4451001286506653, 0.16749702394008636, -0.07525812089443207, -0.7869062423706055, 0.5028850436210632, 0.5228132009506226, 0.1787632405757904, -0.2686164379119873, 0.3921189606189728, -0.9583948850631714, -0.7177125215530396, 0.0801144689321518, -1.4075604677200317, 0.1629297435283661, 0.1354580819606781, -0.17786672711372375, -0.6005092859268188, 0.27006015181541443, -0.14014050364494324, -1.192336916923523, -0.5210620164871216, 0.6060618162155151, -0.6250895261764526, 0.11647875607013702, -0.20431677997112274, 0.12812469899654388, -0.7836083769798279, -1.0717517137527466, -0.13468171656131744, 0.6037778258323669, -0.6697320342063904, 1.1871668100357056, 0.8390945196151733, -1.1777883768081665, -0.21650958061218262, 0.04351246729493141, 0.30275586247444153, 0.24387630820274353, 0.6257805228233337, 0.21286199986934662, -0.2517167627811432, 0.4625163972377777, 0.6252292394638062, 0.1803371161222458, -0.9747414588928223, 0.15587913990020752, 1.0748951435089111, -0.6595272421836853, 0.1452804058790207, 1.2009261846542358, 0.3208490312099457, -1.5986552238464355, 0.12241067737340927, -0.7337893843650818, -0.6910592913627625, -0.5058708786964417, 0.7975473999977112, -0.30548301339149475, -0.25509271025657654, 0.0725623071193695, -0.17902454733848572, 0.6819403767585754, -0.10857322067022324, -1.039402723312378, 0.2960382103919983, -0.5401358008384705, -0.3049143850803375, 0.37415918707847595, 1.3399951457977295, -0.6924759149551392, -0.9715596437454224, -0.6912959814071655, -0.6328551769256592, -0.05055952072143555, 0.011301619000732899, -0.8151163458824158, -0.7325168251991272, 1.0065538883209229, 0.6220693588256836, 0.009771930053830147, 0.20363210141658783, 0.09805503487586975, 0.4270116984844208, 0.8104963302612305, -0.1913292407989502, -0.5270841717720032, 0.04293832182884216, 1.0746965408325195, 1.4762259721755981, -1.1243257522583008, 0.20343433320522308, -0.07100030779838562, -0.8556386828422546, 1.1498185396194458, 0.35712626576423645, 0.3121877908706665, 0.8456214070320129, -0.22028689086437225, 0.3517219126224518, 0.3405337929725647, -1.37091064453125, 0.06521902233362198, 1.0528017282485962, 1.2199212312698364, 0.9323065876960754, 0.37684130668640137, 0.0649293065071106, 0.5345451235771179, 0.2338208556175232, 0.08437483757734299, 0.5347778797149658, 0.254588782787323, 0.024124838411808014, -0.46919646859169006, 0.062417153269052505, 0.36293458938598633, -0.6654078364372253, -0.6282986998558044, 0.1477971076965332, 0.38280099630355835, 0.37133684754371643, 0.8576511740684509, 0.728961706161499, 0.21272538602352142, 0.17641401290893555, 0.16190600395202637, 0.780120313167572, -0.5224685668945312, 0.016929620876908302, -0.09072791785001755, -0.9752642512321472, 0.15192444622516632, -0.2548461854457855, -0.7148305177688599, -0.45034059882164, 0.43521711230278015, 0.5796552896499634, -0.42203885316848755, 0.5926694273948669, 1.1701898574829102, 0.46213066577911377, 0.29729098081588745, -0.38583317399024963, -0.5035682916641235, -0.286203533411026, -0.8256293535232544, 0.4853651225566864, -0.2395971119403839, -0.28537532687187195, 0.12773631513118744, 0.031884703785181046, 0.22342698276042938]}, "authors": [{"authorId": "2111186856", "name": "Yuchen Zeng"}, {"authorId": "2282472476", "name": "Wonjun Kang"}, {"authorId": "2282505483", "name": "Yicong Chen"}, {"authorId": "2282471620", "name": "Hyung Il Koo"}, {"authorId": "2262083609", "name": "Kangwook Lee"}], "references": [{"paperId": "689c358c5f9b5b1693a8bcc7e6e0460012f5cf9e", "title": "Sequential Modeling Enables Scalable Learning for Large Vision Models"}, {"paperId": "4b08aaa03f6998236407d61612c7e55f01c308e8", "title": "Understanding and Improving In-Context Learning on Vision-language Models"}, {"paperId": "d45805349623c1389d5861d8263fb06df922e05b", "title": "GPT-4V(ision) as a Generalist Evaluator for Vision-Language Tasks"}, {"paperId": "297211bc86653d9ebbe694a75141c9a1c6c11e69", "title": "In-Context Learning Creates Task Vectors"}, {"paperId": "ffa05cb5504ba08254f498223f613b3ebcf87692", "title": "LauraGPT: Listen, Attend, Understand, and Regenerate Audio with GPT"}, {"paperId": "124d4d374fbef2016fa9880489871a58a7450644", "title": "Improved Baselines with Visual Instruction Tuning"}, {"paperId": "b8ee0b5322382807e687c95cc87b059d3f348495", "title": "MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation"}, {"paperId": "e7d09b6f2bc878cf2c993acf675f409d0b55f35a", "title": "MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens"}, {"paperId": "5ba1525dc6d382ee0a4a1ca3c64fc5907ca64c67", "title": "Making LLaMA SEE and Draw with SEED Tokenizer"}, {"paperId": "5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0", "title": "Qwen Technical Report"}, {"paperId": "7b689adb8c156d6158660f90d1c86888ee281f63", "title": "DreamLLM: Synergistic Multimodal Comprehension and Creation"}, {"paperId": "3803d1f291e162bdaa4678a2c5a2bbcf63c050f4", "title": "MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning"}, {"paperId": "1a735015a1f7ef4f2ba2273ce5fcaaacfa9d1ea2", "title": "Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning"}, {"paperId": "fc6a2f7478f68adefd69e2071f27e38aa1647f2f", "title": "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond"}, {"paperId": "7fbc502441d66daf1f53765d5d86a8dfba9ab0ce", "title": "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"}, {"paperId": "f4c62aa336de45273e0fdfcfbd65b3c2e552ad56", "title": "Visual Instruction Inversion: Image Editing via Visual Prompting"}, {"paperId": "40298b8d50109c52fc10763eddc64a07cf8acb31", "title": "Planting a SEED of Vision in Large Language Model"}, {"paperId": "94053805cd59f2e9a47fe3f080c7e7afefb337cc", "title": "Generative Pretraining in Multimodality"}, {"paperId": "e418bddc14666671c4df6a9747f39f0f522a1bad", "title": "Large Language Models as General Pattern Machines"}, {"paperId": "3b6179c293df29e31d31cea46476f104ab6950f2", "title": "Kosmos-2: Grounding Multimodal Large Language Models to the World"}, {"paperId": "948e8cfae92c2004f2dd5c9316f5972f8baaea21", "title": "OBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents"}, {"paperId": "4a7530bbaee7563ee244f3ffed6b706bd96f08a8", "title": "Trained Transformers Learn Linear Models In-Context"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "70c3d5ab03a54281be91709b19e3f50a2e4be0e3", "title": "Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection"}, {"paperId": "31e28e7f32645e844dd543d5daeeeb9215443698", "title": "MetaVL: Transferring In-Context Learning Ability From Language Models to Vision-Language Models"}, {"paperId": "f5e9337477d7a9eb6267d0310549fdefafbb7fe2", "title": "Transformers learn to implement preconditioned gradient descent for in-context learning"}, {"paperId": "6fb5c0eff3696ef252aca9638e10176ecce7cecb", "title": "Generating Images with Multimodal Language Models"}, {"paperId": "5cac6430bd379c9d2fe13137dfd6ae7721a2679f", "title": "SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities"}, {"paperId": "2f3822eb380b5e753a6d579f31dfc3ec4c4a0820", "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models"}, {"paperId": "8bc617c9139648d7a92991d70c671230bac7b2e2", "title": "AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head"}, {"paperId": "ca6a2bc279be5a3349a22bfd6866ed633d18734b", "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"}, {"paperId": "a5036f31f0e629dc661f120b8c3b1f374d479ab8", "title": "Visual Instruction Tuning"}, {"paperId": "df958800014d310b6df34ad83d771314d68fbb2d", "title": "Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved With Text"}, {"paperId": "9cef5a098486aeab6ed3700c5e3d29488488d16f", "title": "Exploring Effective Factors for Improving Visual In-Context Learning"}, {"paperId": "1f02ba1c6fae779ec3d003340e72eaf82351cfb9", "title": "TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering"}, {"paperId": "163b4d6a79a5b19af88b8585456363340d9efd04", "title": "GPT-4 Technical Report"}, {"paperId": "da3aca9d7b50da823f669c983edeb60445720fe0", "title": "The Learnability of In-Context Learning"}, {"paperId": "38fe8f324d2162e63a967a9ac6648974fc4c66f3", "title": "PaLM-E: An Embodied Multimodal Language Model"}, {"paperId": "57e849d0de13ed5f91d086936296721d4ff75a75", "title": "LLaMA: Open and Efficient Foundation Language Models"}, {"paperId": "fbfef4723d8c8467d7bd523e1d0b703cce0e0f9c", "title": "Language Is Not All You Need: Aligning Perception with Language Models"}, {"paperId": "5f61ddc37476acf3741b0bfe5fcb59639cadbb86", "title": "What Makes Good Examples for Visual In-Context Learning?"}, {"paperId": "525d93a382f6e7873b5d8a2e0713eb3dff7fb250", "title": "Transformers learn in-context by gradient descent"}, {"paperId": "9ceaeff7117965832f4c05fd6355d021862d0a82", "title": "Images Speak in Images: A Generalist Painter for In-Context Visual Learning"}, {"paperId": "7aa801b907b59b8ee4cfb1296d9dac22c5164c5d", "title": "What learning algorithm is in-context learning? Investigations with linear models"}, {"paperId": "78281482c1fdad8e167bab39cc9955c73d58ae8f", "title": "EVA: Exploring the Limits of Masked Visual Representation Learning at Scale"}, {"paperId": "b8bd29a6104d26a16687400049a4e7e026ae6258", "title": "Active Example Selection for In-Context Learning"}, {"paperId": "e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9", "title": "LAION-5B: An open large-scale dataset for training next generation image-text models"}, {"paperId": "8c870bef01a4fbb20f60722ffc2f6bee3870b18b", "title": "AudioLM: A Language Modeling Approach to Audio Generation"}, {"paperId": "86d0d3855f94105e25d81cab9f3d269c6062a9c4", "title": "Selective Annotation Makes Language Models Better Few-Shot Learners"}, {"paperId": "0a25c137edc7c9752aa6d99ae4084683c3fe6b56", "title": "Visual Prompting via Image Inpainting"}, {"paperId": "5b19bf6c3f4b25cac96362c98b930cf4b37f6744", "title": "DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation"}, {"paperId": "de32da8f5c6a50a6c311e9357ba16aa7d05a1bc9", "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"}, {"paperId": "b92628d13e8d090d042232fe6ae0b8998634b893", "title": "LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks"}, {"paperId": "a8fd9c1625011741f74401ff9bdc1c584e25c86d", "title": "Language Models are General-Purpose Interfaces"}, {"paperId": "c539f6ab5818bde96f61298856cb0c38f6268369", "title": "On Aliased Resizing and Surprising Subtleties in GAN Evaluation"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "26218bdcc3945c7edae7aa2adbfba4cd820a2df3", "title": "Flamingo: a Visual Language Model for Few-Shot Learning"}, {"paperId": "c57293882b2561e1ba03017902df9fc2f289dea2", "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents"}, {"paperId": "341bdbcfc3febef7691a97c216ad394653211095", "title": "Can language models learn from explanations in context?"}, {"paperId": "5f19ae1135a9500940978104ec15a5b8751bc7d2", "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"}, {"paperId": "f4df78183261538e718066331898ee5cad7cad05", "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"}, {"paperId": "1b6e810ce0afd0dd093f789d2b2742d047e316d5", "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"}, {"paperId": "a3b42a83669998f65df60d7c065a70d07ca95e99", "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"}, {"paperId": "c783e1fb3ce8514f981925ee590c00884660ee4e", "title": "CM3: A Causal Masked Multimodal Model of the Internet"}, {"paperId": "400d619cbabeb669115bb7281a889ab869829ef5", "title": "MERLOT RESERVE: Neural Script Knowledge through Vision and Language and Sound"}, {"paperId": "c10075b3746a9f3dd5811970e93c8ca3ad39b39d", "title": "High-Resolution Image Synthesis with Latent Diffusion Models"}, {"paperId": "f9838a3be5c94bb2674a0e224de349b50e18f3c4", "title": "Learning To Retrieve Prompts for In-Context Learning"}, {"paperId": "10bd4160b44803ada6a3d2e366c44b7e2a4ffe90", "title": "An Explanation of In-context Learning as Implicit Bayesian Inference"}, {"paperId": "47df3fd32d00220c85c2c51a571254fd99b2ecc7", "title": "MetaICL: Learning to Learn In Context"}, {"paperId": "6bd91a3183ddb844641acb9f3fe9faec6a9ff617", "title": "Meta-learning via Language Model In-context Tuning"}, {"paperId": "3ac5aa6ac59253611ef3cb72a95cbe21ef5dda1b", "title": "Reframing Instructional Prompts to GPTk\u2019s Language"}, {"paperId": "01b5412f3d17e90e09226d7c40ad4d4468a1414d", "title": "Multimodal Few-Shot Learning with Frozen Language Models"}, {"paperId": "38b0567e83386ddc294d6c81b541deacbd8e3c2a", "title": "CLIPScore: A Reference-free Evaluation Metric for Image Captioning"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "394be105b87e9bfe72c20efe6338de10604e1a11", "title": "Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts"}, {"paperId": "59641c10ed7431a3cf841f308367dc2dc0281b74", "title": "What Makes Good In-Context Examples for GPT-3?"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "b40bfcf339de3f0dba08fabb2b58b9368ff4c51a", "title": "DocVQA: A Dataset for VQA on Document Images"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "43f2ad297941db230c089ba353efc3f281ab678c", "title": "5\u5206\u3067\u5206\u304b\u308b!? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "1097cf8cf5961589ff693b069002e7181e24e631", "title": "OCR-VQA: Visual Question Answering by Reading Text in Images"}, {"paperId": "a7ac99d7cf3f568ab1a741392144b646b856ae0c", "title": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering"}, {"paperId": "b4df354db88a70183a64dbc9e56cf14e7669a6c0", "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"}, {"paperId": "7289a240c9425bc7cad87b3b835e5f0cac22f488", "title": "DVQA: Understanding Data Visualizations via Question Answering"}, {"paperId": "f466157848d1a7772fb6d02cdac9a7a5e7ef982e", "title": "Neural Discrete Representation Learning"}, {"paperId": "7e232313a59d735ef7c8a9f4cc7bc980a29deb5e", "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"}, {"paperId": "afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d", "title": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations"}, {"paperId": "e65142010431ffc089b272a1174214e00693e503", "title": "Generation and Comprehension of Unambiguous Object Descriptions"}, {"paperId": "6364fdaa0a0eccd823a779fcdd489173f938e91a", "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation"}, {"paperId": "696ca58d93f6404fea0fc75c62d1d7b378f47628", "title": "Microsoft COCO Captions: Data Collection and Evaluation Server"}, {"paperId": "2dcef55a07f8607a819c21fe84131ea269cc2e3c", "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"}, {"paperId": "92c141447f51b6732242376164ff961e464731c8", "title": "ReferItGame: Referring to Objects in Photographs of Natural Scenes"}, {"paperId": "8e080b98efbe65c02a116439205ca2344b9f7cd4", "title": "Im2Text: Describing Images Using 1 Million Captioned Photographs"}, {"paperId": "eae2e0fa72e898c289365c0af16daf57a7a6cf40", "title": "Image quality assessment: from error visibility to structural similarity"}, {"paperId": "d198b0b155313afe350e91a77c3d73cffa39d2a9", "title": "Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "LAION COCO: 600M synthetic cap-tions from laion2b-en"}, {"paperId": "cfee1826dd4743eab44c6e27a0cc5970effa4d80", "title": "Improving Image Generation with Better Captions"}, {"paperId": null, "title": ": An open-source chatbot impressing GPT-4 with 90%* ChatGPT"}, {"paperId": null, "title": "Frozen in time: A joint video and image encoder for end-to-end 17"}, {"paperId": null, "title": "A theoretical analysis of in-context task retrieval and learning"}, {"paperId": null, "title": "Unsplash Team"}]}