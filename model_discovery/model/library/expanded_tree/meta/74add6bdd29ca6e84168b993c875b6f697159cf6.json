{"paperId": "74add6bdd29ca6e84168b993c875b6f697159cf6", "abstract": "In this paper, we investigate the interplay between attention heads and specialized\"next-token\"neurons in the Multilayer Perceptron that predict specific tokens. By prompting an LLM like GPT-4 to explain these model internals, we can elucidate attention mechanisms that activate certain next-token neurons. Our analysis identifies attention heads that recognize contexts relevant to predicting a particular token, activating the associated neuron through the residual connection. We focus specifically on heads in earlier layers consistently activating the same next-token neuron across similar prompts. Exploring these differential activation patterns reveals that heads that specialize for distinct linguistic contexts are tied to generating certain tokens. Overall, our method combines neural explanations and probing isolated components to illuminate how attention enables context-dependent, specialized processing in LLMs.", "venue": "arXiv.org", "year": 2024, "citationCount": 2, "influentialCitationCount": 0, "openAccessPdf": null, "tldr": {"model": "tldr@v2.0.0", "text": "This method combines neural explanations and probing isolated components to illuminate how attention enabling context-dependent, specialized processing in LLMs enables context-dependent, specialized processing in LLMs."}, "embedding": {"model": "specter_v2", "vector": [0.5334336757659912, 1.0250788927078247, -0.5099753737449646, 0.144074946641922, -0.2027636170387268, 0.16306428611278534, 0.6257298588752747, 0.001528608612716198, 0.23868198692798615, -0.26999950408935547, 0.6643489003181458, -0.12113277614116669, 0.26088783144950867, 0.09623599052429199, -0.1077817752957344, -0.34987106919288635, -1.0774468183517456, -0.199497789144516, -0.28079092502593994, 0.2481769621372223, 0.5112094283103943, -0.34504279494285583, -1.2347848415374756, 0.5644843578338623, -0.1284874975681305, 0.6909863948822021, 0.19291909039020538, 1.006379246711731, -0.3852217495441437, 1.1026554107666016, 0.2917390465736389, -0.12498065084218979, -0.04556718468666077, -0.00695510720834136, -0.7499811053276062, -0.11382458359003067, 0.4648914337158203, -0.08849458396434784, -0.35385560989379883, 0.5340029001235962, -0.3261459469795227, -0.0361369252204895, 0.30074840784072876, -0.6793004870414734, -0.2525632977485657, 1.478971004486084, 0.726360559463501, 0.6992993950843811, -0.2459837943315506, -0.023614391684532166, 1.8136736154556274, -1.1493474245071411, -0.1026587188243866, 1.6535979509353638, 0.5432856678962708, 0.33736085891723633, -0.273516446352005, -0.11672709882259369, 1.0366003513336182, 0.2312721461057663, -0.3172948360443115, -0.6326009631156921, 0.4594990015029907, 0.20834073424339294, 1.910736083984375, -0.4630481004714966, -0.0430668443441391, 0.6964738368988037, 0.4935506582260132, 1.8109378814697266, 0.2729390859603882, -1.1335794925689697, -0.02986454777419567, 0.24604694545269012, 0.31728628277778625, 0.46431446075439453, -0.5838527679443359, 0.21846163272857666, -0.9966033697128296, 0.09263963997364044, 0.7690423727035522, -0.05463995784521103, 0.24611693620681763, 0.30129146575927734, -0.3067651689052582, 0.3252929747104645, 0.3438703417778015, 1.0027520656585693, -1.0052496194839478, 0.8600394129753113, 0.28769776225090027, -0.08628208190202713, -0.4637516438961029, 0.317066490650177, -0.06994805485010147, 0.38847029209136963, -0.48957911133766174, -0.08449047058820724, 0.09011419117450714, 0.46150222420692444, 0.10724388062953949, 0.49448662996292114, -1.125718116760254, 0.15570664405822754, 1.4343345165252686, -0.17536962032318115, 0.3780656158924103, -0.9171893000602722, 0.3402598798274994, -0.6756805181503296, -0.050244834274053574, -0.6122311949729919, 0.10101088136434555, -0.6949754953384399, -0.344111829996109, -0.9394330978393555, -0.25141510367393494, 0.1731875091791153, -0.7376564741134644, 0.6653628349304199, -0.5769940614700317, 0.2219705879688263, 0.20540699362754822, 0.2284313291311264, 0.05669492855668068, 0.4097452759742737, 0.7903256416320801, 0.29395076632499695, 0.8341193795204163, -0.5283711552619934, -0.4174412488937378, -1.0918269157409668, 0.13643065094947815, -0.07937698066234589, 0.2355586439371109, -0.16608905792236328, -1.0452958345413208, -1.028288722038269, -0.5800844430923462, 0.34000030159950256, 0.02065950632095337, 0.12033572793006897, 1.0756604671478271, -0.024999447166919708, -1.34662663936615, 1.2100497484207153, -0.1495082527399063, -0.24790635704994202, 0.2572806477546692, 0.45081400871276855, 0.6908830404281616, 0.02992146648466587, -1.1120997667312622, 0.3361642062664032, 0.11732835322618484, -0.23758766055107117, -0.0009557594894431531, -0.30896157026290894, -0.8170887231826782, 0.49289241433143616, 0.10005812346935272, -0.6659836173057556, 1.6783040761947632, -0.16708427667617798, -1.3189117908477783, 0.40612760186195374, -0.4167041778564453, 0.32027724385261536, -0.5082452297210693, 0.3841509521007538, -0.5443216562271118, -0.07339200377464294, 0.2053830325603485, 0.8705736994743347, 0.5306231379508972, -0.4426793158054352, -0.5817673206329346, -0.12005593627691269, -0.37564942240715027, -0.16261233389377594, -0.11433319002389908, 0.5429159998893738, -0.04221546649932861, 0.03856051713228226, 0.4191623032093048, 1.1346009969711304, 0.16981413960456848, -0.5612248182296753, -0.6804535984992981, -1.395409107208252, 0.3629037141799927, 0.1888970583677292, 0.8497840166091919, -0.751721978187561, -1.1773836612701416, -0.22958149015903473, -0.35398533940315247, -0.4413726329803467, -0.7034851908683777, 0.5754786729812622, -0.41215789318084717, 0.35409387946128845, 0.18465390801429749, -1.0653473138809204, -0.05645514652132988, 0.06704966723918915, -0.6729562282562256, -0.8231547474861145, 0.5715197920799255, 0.8510640263557434, -0.9990128874778748, -0.3523154556751251, -0.012399831786751747, 0.2799779176712036, -0.5003952383995056, 1.020041584968567, -0.08108379691839218, 0.056588560342788696, -0.34669196605682373, -0.058317989110946655, -0.07172698527574539, -0.1762569099664688, 0.3089427351951599, -0.3573329746723175, -0.35031363368034363, 0.9014129042625427, -0.39364516735076904, 0.7836369276046753, -0.3095399737358093, 0.6712735295295715, 0.08489325642585754, -0.6059050559997559, 0.1143430545926094, 0.5688909888267517, -0.6838229894638062, -0.5644809007644653, 0.3143662214279175, 0.4351213276386261, -0.6220980286598206, -0.12547165155410767, 0.854955792427063, 0.6405750513076782, -0.4917990565299988, -0.04219968244433403, 0.7347671985626221, -0.026990234851837158, 0.010941937565803528, 0.07295366376638412, 0.5379519462585449, 0.5896673798561096, 0.4747663736343384, -0.017904864624142647, 0.03945315256714821, -0.8987868428230286, 0.31954875588417053, 0.7612773180007935, 0.5501255393028259, 0.6196591258049011, 0.7185670137405396, -0.7258879542350769, 0.23226942121982574, 0.23090426623821259, 0.2797490358352661, 1.3417476415634155, -0.4371919631958008, 0.3417726159095764, -0.5116298794746399, 0.021390613168478012, -0.2604432702064514, 0.5711166858673096, -0.19188502430915833, -0.10021211206912994, -0.47983962297439575, -0.6806577444076538, 0.9063236117362976, 0.5034887790679932, 0.6753773093223572, -1.6436564922332764, -0.438762366771698, 0.202243372797966, 0.5229828953742981, -0.665003776550293, -0.2900243401527405, 1.1394492387771606, -0.8364453315734863, -0.039272490888834, 0.41144639253616333, -0.6273545622825623, 0.026566864922642708, -0.9737346768379211, 0.7532234787940979, -0.20816631615161896, -0.07641381770372391, 0.10348674654960632, 1.0127941370010376, -0.5830395817756653, -0.4791583716869354, 0.17788559198379517, -0.07626975327730179, 0.0012561092153191566, 0.5087622404098511, 0.3041883111000061, -0.056648917496204376, -0.45838674902915955, -0.078211210668087, 0.06281346827745438, 0.3233742117881775, -0.001816222327761352, 0.6503332257270813, -0.19303597509860992, 0.0641086995601654, -0.9604178071022034, 0.9981539845466614, -0.016783561557531357, -0.11813011020421982, 0.1345750242471695, -0.8513143062591553, 0.02816343866288662, 0.7968165278434753, -0.21390888094902039, -0.32835623621940613, -0.8914458751678467, 0.549203097820282, 0.02641157992184162, -0.9334522485733032, 0.2197187840938568, 0.14000871777534485, 0.1328813135623932, -0.11947236955165863, 0.30819860100746155, -0.1756853610277176, -0.004206566140055656, 0.22718001902103424, -0.5769101977348328, 0.8444671034812927, -0.052701134234666824, -0.48466894030570984, -0.6630582809448242, -0.01707724668085575, -0.603370189666748, -0.34804826974868774, -0.1328122317790985, -0.1994367092847824, -0.2940863072872162, -0.14640535414218903, -0.08591434359550476, -1.3431514501571655, 0.26835161447525024, -1.0312292575836182, -0.6436970829963684, -0.3473255932331085, -0.32301267981529236, -0.09008581936359406, -1.244925856590271, -1.3920363187789917, -0.9335272312164307, -0.41454628109931946, -0.6837618350982666, 0.06119343265891075, 0.4831646978855133, -0.35089150071144104, -0.8105888366699219, -0.18966931104660034, -0.6677842736244202, 0.9976747632026672, -0.7025427222251892, 0.9373292326927185, -0.04472285881638527, -0.49830031394958496, 0.01980123296380043, 0.33996930718421936, 0.21159954369068146, 0.058112796396017075, 0.15574002265930176, -1.4726535081863403, 0.8258562684059143, 0.044160395860672, -0.0720963329076767, 0.10025381296873093, 0.4998821020126343, 0.7638477683067322, -0.39368322491645813, -0.5289974808692932, -0.022639025002717972, 1.3521316051483154, -0.44085508584976196, 0.007713630795478821, 0.13651956617832184, 0.8057658672332764, 0.6490224599838257, -0.589656412601471, 0.4858706593513489, 0.5248568654060364, 0.18260137736797333, 0.587898850440979, -0.11666984856128693, -0.3449957072734833, -0.7323450446128845, 0.4434426724910736, 1.1933706998825073, 0.2201867401599884, 0.05858050659298897, -1.030916452407837, 0.8284125328063965, -1.2330373525619507, -0.6779373288154602, 0.5485376715660095, 0.5864766836166382, 0.22061853110790253, -0.18173359334468842, -0.9120872020721436, 0.2663745582103729, 0.7015169858932495, 0.08339913934469223, -0.339599609375, -1.0952142477035522, 0.14572864770889282, 0.5671074390411377, 0.04669604450464249, 0.9037386775016785, -0.024167608469724655, 0.6015613079071045, 14.573905944824219, 0.20293991267681122, -0.1617153286933899, -0.01917790248990059, 0.7953041791915894, 0.7307851314544678, -0.3953041434288025, 0.34715819358825684, -1.5185739994049072, -0.1660342812538147, 1.4258784055709839, 0.6871429085731506, 0.6199069619178772, -0.07961577922105789, -0.009599960409104824, -0.006314447149634361, -0.7943639755249023, 0.24165894091129303, 0.3546636998653412, -1.1006077527999878, 0.4907858669757843, 0.2697121500968933, 0.014349184930324554, 0.37241828441619873, 0.7582525610923767, 0.8643758893013, 0.545562744140625, -0.22205881774425507, 0.8830265402793884, 0.2862216830253601, 0.4952943027019501, 0.19749897718429565, 0.2969479560852051, 0.3001309633255005, -0.9702404141426086, -0.6562626957893372, -0.5045896768569946, -1.4412463903427124, 0.03905384615063667, 0.08495165407657623, -0.8631635308265686, -0.7661994695663452, -0.1246984675526619, 0.30605700612068176, 0.12572099268436432, 0.4624001085758209, -0.9553784728050232, 0.7960638999938965, 0.07518785446882248, 0.07063750922679901, 0.16246621310710907, 1.1545038223266602, 0.19009776413440704, -0.01642797142267227, 0.07419420778751373, -0.05164225399494171, -0.02243923582136631, 0.8185378313064575, -0.3546353578567505, -0.41910189390182495, -0.10154874622821808, 0.046643033623695374, 0.33150553703308105, 1.0194529294967651, 0.3892737925052643, 0.4331496059894562, 0.04987392574548721, 0.28710344433784485, 0.43617063760757446, 0.43545809388160706, 0.4924181401729584, -0.40244781970977783, 0.5134357213973999, -0.464560329914093, 0.29738888144493103, 1.0805168151855469, -0.3394193649291992, -0.16441509127616882, -0.8730909824371338, 0.006849044933915138, 0.0891612321138382, -1.1355129480361938, -0.8837452530860901, 0.730870246887207, -0.3217337131500244, -0.09146001189947128, -0.14068029820919037, -1.0128346681594849, -1.124502182006836, 0.6120503544807434, -1.7088208198547363, -0.8769879937171936, 0.3783261775970459, -0.020807912573218346, -0.6102356314659119, 0.22783717513084412, 1.305097222328186, -0.572602391242981, -0.7152314782142639, -0.11033189296722412, -0.5733513832092285, -0.043115176260471344, -0.38059818744659424, -1.3152981996536255, 0.8049109578132629, 0.5585097670555115, -0.09325731545686722, 0.4354152977466583, 0.022946182638406754, 0.5442951321601868, -0.38814735412597656, 0.08273638039827347, 1.538833737373352, -0.7847247123718262, -0.5401443243026733, -0.26844263076782227, -0.8990909457206726, 0.4558054208755493, 1.0445373058319092, -0.1466224044561386, 0.2538333833217621, 0.42039036750793457, -0.16630594432353973, -0.41384437680244446, -0.7921716570854187, 0.0548659972846508, 0.11628814786672592, -0.843733549118042, -0.8067148923873901, -0.5147063136100769, 0.15902763605117798, -0.775338351726532, -0.37357160449028015, -0.6786127686500549, -0.14757423102855682, -0.20439469814300537, 0.7152379155158997, -0.24775294959545135, 0.33833810687065125, 0.7070814371109009, -0.059599533677101135, -0.9230301976203918, -0.5433441996574402, -0.7619308233261108, 0.07071735709905624, 0.8494448661804199, 0.7096866965293884, -0.7348778247833252, 0.13740356266498566, 1.1748449802398682, -0.056744955480098724, -0.32154542207717896, -0.668464183807373, 0.34233975410461426, -0.10315721482038498, -0.7725014686584473, 0.9899120926856995, 0.0895012617111206, 0.42472729086875916, 0.09651259332895279, 0.8617014288902283, 0.848289966583252, 0.16328541934490204, -0.558070182800293, -0.3463667333126068, -0.35932114720344543, -0.10951854288578033, -0.5868781805038452, -0.23348602652549744, -1.2880545854568481, -0.10323933511972427, -1.0673590898513794, 0.4843840003013611, -1.2294280529022217, -0.4992353022098541, -0.21418525278568268, -1.1710152626037598, 0.9582761526107788, 0.15489353239536285, -0.6107774376869202, -0.3028465509414673, -0.16751307249069214, -0.3115595579147339, 0.30857643485069275, 0.677831768989563, -0.43597978353500366, -0.1087963730096817, 0.150838240981102, -0.5924603939056396, 0.2215362936258316, 0.5417165160179138, -0.6609445214271545, -0.2583847939968109, -1.40376877784729, 0.26692503690719604, 0.15356574952602386, 0.1646965891122818, -1.030086874961853, 0.898428201675415, 0.45502904057502747, 0.14729678630828857, 0.10085245966911316, 0.03711123391985893, -0.6648833155632019, -0.8244240283966064, -0.05964255705475807, -0.8910714387893677, -0.1402677297592163, 0.2290716916322708, -0.7120916843414307, -0.3623086214065552, 0.4540616571903229, -0.5559399724006653, -1.1667672395706177, -1.0495808124542236, 0.11805642396211624, -0.9787523150444031, -0.2895113527774811, -0.5710320472717285, -0.4472321569919586, -1.0906214714050293, 0.24495986104011536, 0.007735119201242924, 0.34975531697273254, -0.4870801866054535, 0.8552335500717163, 0.4722107946872711, -0.8693114519119263, 0.18131563067436218, 0.6074128150939941, -0.28253114223480225, -0.03470609337091446, 0.13228504359722137, 0.23358790576457977, 0.20820288360118866, 0.833707332611084, -0.12777402997016907, -0.07237280905246735, -0.34245818853378296, -0.42531561851501465, 0.5192695260047913, -0.5177549719810486, -0.17866025865077972, 0.9294904470443726, -0.5335398316383362, -1.1279335021972656, 0.3337748050689697, -1.971587061882019, -0.9294315576553345, -0.38391146063804626, 0.4285610318183899, -0.20089788734912872, -0.36041387915611267, -0.09508652985095978, -0.44270604848861694, 0.2773863971233368, 0.1512335240840912, -0.24807707965373993, 0.2258588671684265, -0.16600336134433746, -0.1433175504207611, 0.7287226319313049, 0.1829770803451538, -0.8740705847740173, -1.189038872718811, -0.4074377119541168, -0.11528398096561432, 0.24952268600463867, 0.5482444763183594, -0.205051451921463, -0.6207752227783203, 1.2417597770690918, 0.4701313078403473, 0.4300326406955719, -0.008530132472515106, 0.0433511920273304, -0.28156962990760803, 0.2944248616695404, 0.25746116042137146, -0.44378626346588135, -0.48370885848999023, 1.1289583444595337, 0.9090984463691711, -0.5232682228088379, -0.10598232597112656, 0.30944570899009705, -0.6929344534873962, 1.2784570455551147, 0.6061280369758606, 0.23179005086421967, 0.4731825590133667, -0.3710090219974518, 0.32252568006515503, 0.055764395743608475, -1.2241252660751343, 0.06810011714696884, 0.025433490052819252, 1.1615368127822876, 0.8319686651229858, 0.5453910827636719, 0.6846146583557129, 0.9887852668762207, 0.21126125752925873, 0.28484803438186646, 0.6457324028015137, 0.5722838640213013, -0.3298291862010956, -0.26255977153778076, -0.2773481607437134, 0.522305965423584, -0.8602662682533264, -0.9061070680618286, 0.3092004954814911, 0.5118687152862549, 0.36719581484794617, 0.9307021498680115, 0.8104657530784607, 0.02648501843214035, 0.7866480946540833, 0.42709431052207947, 0.39636462926864624, -0.8652072548866272, -0.8810709714889526, -0.20856817066669464, -0.6167967319488525, -0.13738085329532623, -0.1611122041940689, -0.6044299602508545, -0.7337419390678406, 0.14988474547863007, 0.16947190463542938, -0.07278803735971451, 0.23566633462905884, 0.9196227192878723, 0.6856550574302673, 0.702278196811676, -0.06830353289842606, -1.0925062894821167, -0.5440077185630798, -0.91974276304245, -0.04966851323843002, -0.8443427681922913, 0.21925219893455505, 0.31769663095474243, -0.49220600724220276, -0.1877303421497345]}, "authors": [{"authorId": "2282539568", "name": "Clement Neo"}, {"authorId": "2277600097", "name": "Shay B. Cohen"}, {"authorId": "2143198655", "name": "Fazl Barez"}], "references": [{"paperId": "61039ce0c0f079b90ecca7d8c659340aee9ee932", "title": "Neuron to Graph: Interpreting Language Model Neurons at Scale"}, {"paperId": "cc57a02307b77585f69779cca2937dedc69006d6", "title": "Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark"}, {"paperId": "4631398b0d61061b9ca9489d76ded4dd05bcf1ec", "title": "The Larger They Are, the Harder They Fail: Language Models do not Recognize Identifier Swaps in Python"}, {"paperId": "01a659968a6511e590f0e37a81eb25e53fa2c752", "title": "Explaining How Transformers Use Context to Build Predictions"}, {"paperId": "be55e8ec4213868db08f2c3168ae666001bea4b8", "title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"}, {"paperId": "2fe1ac0b09cc0f50eb83eef6c7c6b45ac8b12413", "title": "Mass-Editing Memory in a Transformer"}, {"paperId": "c90a99eeb57019732a6cc996bb9eaf13faedf00f", "title": "In-context Learning and Induction Heads"}, {"paperId": "cf36236015c9f93f15bfafbf282f69e08bdc9c16", "title": "Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space"}, {"paperId": "996445d847f06e99b0bd259345408a0cf1bce87e", "title": "Locating and Editing Factual Associations in GPT"}, {"paperId": "2c871df72c52b58f05447fcb3afc838168d94505", "title": "Knowledge Neurons in Pretrained Transformers"}, {"paperId": "9b9dc2b3d95d2f4e4269a9818c14c70c1f801384", "title": "An Interpretability Illusion for BERT"}, {"paperId": "db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e", "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling"}, {"paperId": "4a54d58a4b20e4f3af25cea3c188a12082a95e02", "title": "Transformer Feed-Forward Layers Are Key-Value Memories"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "135112c7ba1762d65f39b1a61777f26ae4dfd8ad", "title": "Is Attention Interpretable?"}, {"paperId": "1e83c20def5c84efa6d4a0d80aa3159f55cb9c3f", "title": "Attention is not Explanation"}, {"paperId": "3c0059824db37740c2acad1d3d746d31e2a8a692", "title": "Technologies"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "664ec878de4b7170712baae4a7821fc2602bba25", "title": "Learning to Generate Reviews and Discovering Sentiment"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "The findings have the potential to improve the efficiency and interpretability of language models"}, {"paperId": null, "title": "A mathematical framework for transformer circuits"}, {"paperId": null, "title": "2023. Towards monosemanticity: Decomposing language models with dictionary learning"}, {"paperId": null, "title": "2023. We found an neuron in GPT-2"}, {"paperId": null, "title": "potential forms of misuse"}, {"paperId": null, "title": "2023. Language models can explain neurons in language models"}, {"paperId": null, "title": "classification (Figure 9), as well as a GPT-4 to explain induction heads (Figure D Pseudocode of our Methodology"}, {"paperId": null, "title": "This paper investigates the attention heads and specialized"}, {"paperId": null, "title": "OpenAI. 2023."}]}