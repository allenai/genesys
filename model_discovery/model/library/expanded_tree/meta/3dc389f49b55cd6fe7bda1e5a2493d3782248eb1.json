{"paperId": "3dc389f49b55cd6fe7bda1e5a2493d3782248eb1", "abstract": "The capabilities and adoption of deep neural networks (DNNs) grow at an exhilarating pace: Vision models accurately classify human actions in videos and identify cancerous tissue in medical scans as precisely than human experts; large language models answer wide-ranging questions, generate code, and write prose, becoming the topic of everyday dinner-table conversations. Even though their uses are exhilarating, the continually increasing model sizes and computational complexities have a dark side. The economic cost and negative environmental externalities of training and serving models is in evident disharmony with financial viability and climate action goals. Instead of pursuing yet another increase in predictive performance, this dissertation is dedicated to the improvement of neural network efficiency. Specifically, a core contribution addresses the efficiency aspects during online inference. Here, the concept of Continual Inference Networks (CINs) is proposed and explored across four publications. CINs extend prior state-of-the-art methods developed for offline processing of spatio-temporal data and reuse their pre-trained weights, improving their online processing efficiency by an order of magnitude. These advances are attained through a bottom-up computational reorganization and judicious architectural modifications. The benefit to online inference is demonstrated by reformulating several widely used network architectures into CINs, including 3D CNNs, ST-GCNs, and Transformer Encoders. An orthogonal contribution tackles the concurrent adaptation and computational acceleration of a large source model into multiple lightweight derived models. Drawing on fusible adapter networks and structured pruning, Structured Pruning Adapters achieve superior predictive accuracy under aggressive pruning using significantly fewer learned weights compared to fine-tuning with pruning.", "venue": "arXiv.org", "year": 2023, "citationCount": 0, "influentialCitationCount": 0, "openAccessPdf": {"url": "http://arxiv.org/pdf/2306.13474", "status": "CLOSED"}, "tldr": {"model": "tldr@v2.0.0", "text": "This dissertation is dedicated to the improvement of neural network efficiency and proposes and explores the concept of Continual Inference Networks (CINs), a core contribution addresses the efficiency aspects during online inference."}, "embedding": {"model": "specter_v2", "vector": [0.40252551436424255, 0.5909936428070068, -0.9368682503700256, -0.15912476181983948, 0.007038928102701902, 0.3948398530483246, 0.711374044418335, -0.5392186641693115, -0.40468892455101013, -0.39961162209510803, 0.5209879279136658, 0.10162119567394257, 0.22337111830711365, -0.18235477805137634, 0.23203377425670624, 0.15114594995975494, -1.137008547782898, 0.377149760723114, 0.5248168706893921, -0.03526654466986656, -0.38316917419433594, -0.2812262773513794, -1.3923074007034302, 0.07560061663389206, -0.12401891499757767, 1.129685640335083, -0.19652032852172852, 1.221341609954834, -0.27911168336868286, 0.48497843742370605, 0.6625569462776184, -0.1224917322397232, 0.4961000680923462, -0.126820370554924, -0.4596260190010071, -0.05728968232870102, 0.26568368077278137, -0.6447802782058716, -0.7443622350692749, 0.7239402532577515, -0.6700534224510193, 0.23596838116645813, 0.4439660310745239, -0.6421979069709778, -0.18153676390647888, 0.1307108998298645, 0.7207428216934204, 1.2164123058319092, -0.2741512358188629, -0.3075743019580841, 1.2047958374023438, -0.7903748154640198, 0.5531572103500366, 1.4652128219604492, 0.9571363925933838, 0.33039334416389465, 0.1036907434463501, -0.5654130578041077, 0.6318103075027466, 0.016061976552009583, -0.3985968828201294, 0.0037155202589929104, -0.13571685552597046, -0.3203863799571991, 1.4240978956222534, -0.42311444878578186, 0.5751986503601074, 1.1151007413864136, 0.07174082100391388, 1.2437708377838135, -0.5107419490814209, -0.8040802478790283, -0.1963048130273819, -0.11943896114826202, 0.16992264986038208, 0.9576061367988586, -0.5150896906852722, 0.5279436707496643, -1.0097801685333252, 0.18679487705230713, 0.37660449743270874, 0.5377609133720398, 0.37247607111930847, 0.20372501015663147, -0.13523365557193756, 0.6343716382980347, 0.7609072923660278, 0.5872233510017395, -0.47463303804397583, 0.6532925367355347, 0.5890149474143982, 0.17858074605464935, 0.1934601068496704, -0.019923947751522064, 0.17263884842395782, 0.40825802087783813, -0.7897539138793945, -0.2274744212627411, 0.0785825252532959, 0.9540165662765503, -0.5338250994682312, -0.06644909828901291, -0.30708661675453186, 0.17008563876152039, 0.9078711867332458, -0.18030206859111786, 0.5010286569595337, -0.8151788711547852, 0.0981270894408226, -0.4869551658630371, -0.03332396224141121, -0.7723172307014465, -0.37330567836761475, -0.6150517463684082, -1.0474954843521118, -0.9404853582382202, -0.5108751058578491, 0.30418524146080017, -0.9921150207519531, 0.2780681550502777, -0.2323264479637146, 0.20360825955867767, -0.06970664858818054, 0.21581783890724182, 0.04442036151885986, 0.4697389304637909, 0.3636840283870697, 0.26606354117393494, 0.9069754481315613, -0.972077488899231, -0.5415050983428955, -1.0032703876495361, 0.03813933581113815, 0.2670266926288605, -0.06330224126577377, -0.00644676061347127, -0.9488279223442078, -1.147983431816101, -0.5256087183952332, -0.09592526406049728, -0.7129045128822327, 0.26329758763313293, 1.446283221244812, -0.1609295755624771, -0.9697179198265076, 1.1113791465759277, -0.674866795539856, -0.7412205338478088, 0.8769122362136841, -0.027544787153601646, 0.35510846972465515, -0.08153674006462097, -0.7786638736724854, 0.28029945492744446, 0.26477500796318054, -0.24455475807189941, -0.32293835282325745, -0.36559340357780457, -0.6904686093330383, -0.11419045180082321, 0.16079387068748474, -0.6492105722427368, 1.3872742652893066, -0.698419451713562, -0.855551540851593, 0.9027953147888184, -0.05979510024189949, -0.40684908628463745, 0.9260770082473755, -0.2656611204147339, -0.804513156414032, 0.14036832749843597, -0.2174825817346573, 0.5216037631034851, 0.4828094244003296, 0.4260765016078949, -0.7252365946769714, 0.11711274087429047, -0.2653471827507019, -0.4398612976074219, -0.49710673093795776, 0.9095796942710876, -0.8026635646820068, -0.12621662020683289, 0.48266690969467163, 0.5362039804458618, -0.3257593810558319, 0.8561566472053528, -0.17157882452011108, -0.833220899105072, 1.004132628440857, -0.25490209460258484, 0.5928393006324768, -0.9231123328208923, -0.9243582487106323, 0.03601805493235588, -0.03317931666970253, -0.2478971779346466, -0.6616122722625732, 0.08229964971542358, -0.20086464285850525, 0.2694685161113739, 0.23352813720703125, -0.9259470105171204, -0.548626184463501, 0.16315264999866486, -0.4690072238445282, -0.12580817937850952, 0.045099612325429916, 1.2854937314987183, -1.108809471130371, -0.11426250636577606, -0.17573514580726624, 0.21807220578193665, -0.8903834223747253, 1.1141586303710938, -0.624666154384613, -0.15173481404781342, -0.24859033524990082, 0.2820303738117218, -0.2643437087535858, -0.4320010542869568, 0.6962631344795227, -0.6535198092460632, -0.0020393843296915293, 0.2639291286468506, 0.19459137320518494, 1.123108983039856, -0.14417992532253265, 0.9430991411209106, -0.035985253751277924, -0.9056404829025269, 0.06862283498048782, 0.4157404899597168, -0.010331708006560802, -0.6162607073783875, 0.5428498983383179, 0.12425204366445541, -0.777729332447052, -0.07500020414590836, 0.6177670359611511, 0.9703684449195862, -0.14057740569114685, -0.10396838188171387, 0.7111903429031372, 0.09961427748203278, 0.26799994707107544, 0.2554534673690796, 0.7038330435752869, 0.4637819528579712, 0.22574986517429352, 0.03540502488613129, -0.0971037745475769, -0.8493265509605408, 0.23711524903774261, 0.7515941262245178, 0.31715768575668335, 0.6613958477973938, 0.5600907206535339, -1.0050694942474365, -0.5970421433448792, 0.08957606554031372, 0.5776974558830261, 1.081433653831482, -0.19951166212558746, 0.20361633598804474, -0.5167173743247986, -0.6932076215744019, -0.20443500578403473, -0.2115161418914795, -0.9115785956382751, -0.1128244698047638, -0.3603614568710327, -1.0085428953170776, 0.7787973880767822, 0.6633363366127014, 1.198581576347351, -0.5458223819732666, -0.5015912652015686, -0.18411317467689514, 0.09353537112474442, -0.8558070659637451, -0.10072959959506989, 0.3863356411457062, -0.9417010545730591, -0.43831977248191833, 0.2955752909183502, 0.25949305295944214, 0.28352564573287964, -0.4406719207763672, 0.8331579566001892, -0.15686458349227905, -0.8996037244796753, 0.573905885219574, 0.4486687183380127, -0.7643334269523621, -0.5243152976036072, 0.2011003941297531, -0.1334037333726883, -0.17993071675300598, 0.5034120082855225, 0.1718408167362213, -0.3629601001739502, 0.13080434501171112, -0.3375920355319977, 0.1762186735868454, 0.12559013068675995, 0.017812594771385193, 0.8286641836166382, -0.27897176146507263, 0.11388818174600601, -1.228201985359192, 0.3606478273868561, -0.508146345615387, -0.5634547472000122, 0.03236503526568413, -0.565395176410675, -0.3486827611923218, 0.5199620723724365, -0.6615458726882935, -0.37830767035484314, -0.9121325016021729, 0.28643661737442017, -0.8080247640609741, -0.5098209381103516, 0.1890578269958496, 0.8763577342033386, 0.26491039991378784, 0.7391432523727417, 0.09766344726085663, 0.626732349395752, -0.053824737668037415, 0.12527717649936676, -0.9403513669967651, 1.1025713682174683, 0.5363434553146362, 0.23682090640068054, 0.46470755338668823, 0.12420806288719177, -0.6347996592521667, -1.1262433528900146, -0.700275719165802, -0.7144162654876709, -0.6167230010032654, 0.3345089256763458, -0.4454873502254486, -0.42336928844451904, -0.2779353857040405, -0.8561732769012451, -0.5025331377983093, 0.13582982122898102, -0.2248411774635315, 0.026367276906967163, -1.1578090190887451, -0.8563541769981384, -0.6477656960487366, -0.7651020288467407, -0.4427882730960846, 0.27665722370147705, 0.3975229263305664, -0.43227720260620117, -0.8569418787956238, -0.29653894901275635, -0.3128252625465393, 0.9989345669746399, 0.03741570934653282, 0.4256134331226349, 0.024585168808698654, -0.2619537115097046, -0.48024848103523254, -0.16526782512664795, 0.43105605244636536, -0.17871658504009247, 0.633179247379303, -0.8236581683158875, 0.7451732754707336, -0.6060912013053894, -0.03341299667954445, 0.31500402092933655, 0.1881672590970993, 1.2802810668945312, 0.09963003545999527, -0.6746629476547241, 0.4791417717933655, 1.332011103630066, -0.7580201625823975, 0.09324508160352707, -0.029242854565382004, 0.45779645442962646, -0.06613357365131378, -0.14053033292293549, 0.5854564905166626, -0.03581780567765236, 0.1750318706035614, 0.45116156339645386, -0.2910592257976532, -0.6148572564125061, -0.6964316368103027, 0.2567713260650635, 0.9885245561599731, -0.2035558521747589, 0.09732203930616379, -1.0346754789352417, 0.7248003482818604, -1.169191598892212, -0.8954163789749146, 0.7094573974609375, 0.487341046333313, -0.02216031588613987, -0.1065419614315033, -0.23741215467453003, -0.4390125870704651, 0.3838699460029602, 0.17615295946598053, -0.5825543403625488, -0.19790984690189362, 0.14376643300056458, 0.3366018831729889, 0.3788466155529022, 0.2081642597913742, -0.7970682382583618, 0.223985493183136, 15.064221382141113, 0.6003539562225342, -0.15112993121147156, 0.6125370264053345, 0.7179076075553894, 0.09148535132408142, -0.11803092807531357, -0.23362654447555542, -1.1210945844650269, -0.13851875066757202, 1.432704210281372, 0.6163856983184814, 0.5058953762054443, 0.5245130658149719, 0.23716899752616882, 0.02122386358678341, -0.7568271160125732, 0.6459261178970337, 0.5047788023948669, -1.5134837627410889, 0.0828162133693695, -0.05643768981099129, 0.17267486453056335, 0.9133977293968201, 0.6505310535430908, 0.7613475322723389, 0.5651444792747498, -0.2947961390018463, 0.5577682256698608, 0.622711181640625, 1.1454800367355347, 0.3516223728656769, 0.6124950647354126, 0.38179776072502136, -0.9926026463508606, -0.5160204172134399, -0.43281158804893494, -0.8258201479911804, 0.16226635873317719, 0.03993532806634903, -0.5763413906097412, -0.22970890998840332, 0.16845814883708954, 1.1203052997589111, 0.023048533126711845, 0.6591678857803345, -0.5808640122413635, 0.5415375232696533, -0.18727174401283264, 0.20413576066493988, 0.48275500535964966, 0.28939011693000793, 0.025196190923452377, 0.17469735443592072, -0.0758838802576065, 0.15242785215377808, 0.11442537605762482, 0.40571892261505127, -0.67454993724823, -0.6820921897888184, -0.4965205788612366, -0.09121467918157578, -0.3707706034183502, 0.70927894115448, 0.16846579313278198, 0.07865393161773682, -0.38613462448120117, 0.4912840723991394, 0.47452113032341003, 0.21784116327762604, -0.6128557920455933, 0.02845236100256443, 0.1893087923526764, -0.3179616928100586, 0.14720314741134644, 0.6517633199691772, -0.09627249836921692, -0.5324373245239258, -0.7779415249824524, -0.02191111072897911, 0.8556764125823975, -0.8982568979263306, -0.9964291453361511, 0.8959167003631592, -0.30099114775657654, -0.4415680766105652, 0.19868415594100952, -1.0216832160949707, -0.5117006897926331, -0.0019429102540016174, -1.4719129800796509, -0.5959818363189697, -0.4872133433818817, -0.009756159968674183, -0.03209802508354187, 0.03139767050743103, 1.1630990505218506, 0.361782044172287, -0.5752614736557007, 0.04705532267689705, -0.15280170738697052, 0.19244571030139923, -0.3569040596485138, -0.5052430033683777, 0.3765103220939636, 0.5649687647819519, -0.2285943627357483, -0.30032408237457275, -0.28330397605895996, 0.06792456656694412, -0.31258103251457214, -0.6113144159317017, 0.3254457712173462, -0.5198515057563782, -0.171552374958992, -0.7320879697799683, -0.7217178344726562, 0.7524459362030029, 0.14731232821941376, 0.19371023774147034, 0.07261507213115692, 0.28359588980674744, -0.6344396471977234, -0.3417009115219116, -0.8480691909790039, 0.1328059881925583, 0.7556745409965515, -0.8315607309341431, -0.3110024929046631, 0.26324662566185, 0.31087541580200195, -0.8350991606712341, -0.39949724078178406, -0.2221541404724121, 0.4545519948005676, -0.1619495004415512, 1.1517553329467773, -0.6529553532600403, 0.8163581490516663, 1.0650392770767212, 0.024228578433394432, -0.24408072233200073, -0.03430524468421936, -0.6905558109283447, -0.20486648380756378, -0.36066171526908875, 0.4465440511703491, -0.554996132850647, 0.6781729459762573, 0.8544600605964661, 0.23866908252239227, -0.46631988883018494, -0.3919132947921753, -0.3747386634349823, -0.3673743009567261, -0.8165055513381958, -0.004598763771355152, -0.44361674785614014, -0.36480003595352173, -0.2851897180080414, 0.4838148057460785, 0.5873776078224182, -0.0037321290001273155, -0.42814767360687256, 0.05908377468585968, -0.5010335445404053, -0.13989010453224182, -0.3534451723098755, -0.7352698445320129, -1.3642152547836304, -0.1668935865163803, -1.1110471487045288, -0.033964358270168304, -0.6180287003517151, -0.5153732299804688, 0.0036434947978705168, -0.1428309977054596, 0.21007010340690613, 0.738706111907959, -0.23372481763362885, -0.6815699934959412, -0.28545081615448, -0.713916540145874, 0.7065761089324951, 0.6446973085403442, -0.7554594278335571, 0.29162299633026123, 0.3319038450717926, 0.37779501080513, 0.9165234565734863, 0.45750054717063904, -0.2676751911640167, -0.7351759076118469, -1.0548310279846191, 0.024688316509127617, -0.18947219848632812, 0.48749348521232605, -0.9126303195953369, 0.8273093104362488, 0.2878519296646118, 0.15871325135231018, -0.21852624416351318, 0.4069608449935913, -1.0840789079666138, -0.3356180191040039, 0.3588062524795532, -0.7535922527313232, -0.28553497791290283, 0.11647281795740128, -0.012220381759107113, -0.31395766139030457, 0.6685805320739746, 0.2293810397386551, -0.90985506772995, -1.1000226736068726, 0.7454245686531067, -0.5437706112861633, -0.12546144425868988, -0.2012738436460495, -0.24220319092273712, -0.8666066527366638, -0.29238927364349365, -0.39944806694984436, 0.40605297684669495, -0.910096287727356, 0.9137400984764099, 0.5486513376235962, -1.0799893140792847, 0.32650014758110046, 0.2983815670013428, -0.22858372330665588, 0.29726529121398926, 0.5302174091339111, 0.6937785744667053, -0.31498605012893677, 0.34959548711776733, 0.15977774560451508, 0.16332963109016418, -0.7412669062614441, 0.159882590174675, 1.3802142143249512, -0.367524653673172, -0.5540755987167358, 0.9086512923240662, -0.3995784521102905, -0.8319001197814941, 0.53745037317276, -1.2283377647399902, -0.5547742247581482, -0.1896548867225647, 0.597292423248291, 0.2111780196428299, -0.10783886909484863, 0.5881425738334656, -0.2633838653564453, -0.05219312384724617, -0.10776150226593018, -0.2279082089662552, 0.7641441822052002, -0.047637853771448135, 0.01059066690504551, 0.6018006205558777, 0.7959277033805847, -1.1635838747024536, -1.2119060754776, -1.0505664348602295, -0.39928725361824036, -0.22878098487854004, 0.096959188580513, -0.3370712697505951, -1.0644137859344482, 0.4871726334095001, 0.7765665054321289, 0.1337425261735916, 0.42203599214553833, 0.21715952455997467, 0.12433846294879913, 0.7118129134178162, -0.13585397601127625, -0.8045127391815186, -0.10018109530210495, 1.0817558765411377, 1.3135567903518677, -0.8404282331466675, 0.5192707777023315, -0.4819211959838867, -0.24371246993541718, 1.2230777740478516, 0.39891141653060913, -0.20032010972499847, 1.2566946744918823, -0.40613245964050293, -0.3564748466014862, -0.020488165318965912, -1.0178261995315552, -0.009792900644242764, 0.7208274602890015, 0.9193909168243408, 0.03365730494260788, 0.3022032082080841, 0.5321002006530762, 0.8968243598937988, 0.28608837723731995, 0.4649214744567871, 0.16294215619564056, 0.24674242734909058, 0.04933219403028488, 0.33209049701690674, 0.26535120606422424, 1.0135302543640137, -0.5665592551231384, -0.10424909740686417, 0.4982866942882538, 0.8568572402000427, 0.5516124367713928, 0.4001082479953766, 1.3107879161834717, 0.10937763750553131, 0.4949837625026703, -0.0719132348895073, 0.1575593650341034, -0.5205450057983398, -0.17759960889816284, -0.33250662684440613, -0.3878045976161957, -0.4027184844017029, -0.376071035861969, -0.9344913959503174, -0.1364215910434723, -0.09199749678373337, 0.6014406085014343, -0.4713652729988098, -0.06312758475542068, 1.0165375471115112, 0.5573668479919434, 0.7327022552490234, -0.40211769938468933, -0.4637460708618164, -0.2313321828842163, -0.6983451247215271, 0.25791189074516296, -0.44692984223365784, -0.08694863319396973, -0.3118148148059845, -0.3908490836620331, -0.16202829778194427]}, "authors": [{"authorId": "1557388851", "name": "Lukas Hedegaard"}], "references": [{"paperId": "45066d7ba783374e10fb6f4e91655796694a90a7", "title": "Adaptive Parameterization of Deep Learning Models for Federated Learning"}, {"paperId": "ca34bb5a158349937c0ad3f3031aad60d5dfbcd6", "title": "Structured Pruning Adapters"}, {"paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e", "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"}, {"paperId": "86fb2ee92569d35a8b471d814fa4c7653728536f", "title": "Wide Attention Is The Way Forward For Transformers"}, {"paperId": "9695824d7a01fad57ba9c01d7d76a519d78d65e7", "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"}, {"paperId": "b988f7cc5dd8b38234b4627f7ceba3a2603eb134", "title": "Continual Inference: A Library for Efficient Online Inference with Deep Neural Networks in PyTorch"}, {"paperId": "0c9b23c4550b8aad25a394e757439dd9738ad0e8", "title": "Delta Distillation for Efficient Video Processing"}, {"paperId": "e3b82e4dac603b57b63d538a908d6a329e93db0f", "title": "OpenDR: An Open Toolkit for Enabling High Performance, Low Footprint Deep Learning for Robotics"}, {"paperId": "6296aa7cab06eaf058f7291040b320b5a83c0091", "title": "Generative Adversarial Networks"}, {"paperId": "b51fa25bf1ce7fd18737a36b72e80f8e5808973e", "title": "MeMViT: Memory-Augmented Multiscale Vision Transformer for Efficient Long-Term Video Recognition"}, {"paperId": "d10864946d1733444f0472acf1294f15b350e65e", "title": "Continual Transformers: Redundancy-Free Attention for Online Inference"}, {"paperId": "80d0116d77beeded0c23cf48946d9d10d4faee14", "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"}, {"paperId": "9137efc758f80dd22bb56f82cca5c94f78a5db3e", "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and Detection"}, {"paperId": "01b1293ddea9bcd6df1185b0b934503de01d6561", "title": "Block Pruning For Faster Transformers"}, {"paperId": "c672e86e3f56e8b154b68413a4914c583df20ec5", "title": "Extremely Lightweight Skeleton-Based Action Recognition With ShiftGCN++"}, {"paperId": "dc32a984b651256a8ec282be52310e6bd33d9815", "title": "Highly accurate protein structure prediction with AlphaFold"}, {"paperId": "ab7fff96e2cacb5a183ad23fe4ca50df942c17d2", "title": "Long Short-Term Transformer for Online Action Detection"}, {"paperId": "1fb10189c500e4902cd1b5afd406f57323d21be8", "title": "VOLO: Vision Outlooker for Visual Recognition"}, {"paperId": "12f9e3261cbf353c56077883f6345e656b6df21b", "title": "OadTR: Online Action Detection with Transformers"}, {"paperId": "a8ca46b171467ceb2d7652fbfb67fe701ad86092", "title": "LoRA: Low-Rank Adaptation of Large Language Models"}, {"paperId": "656ed155c2d345c19d9bff4b50f2ae00db8407cc", "title": "Compacter: Efficient Low-Rank Hypercomplex Adapter Layers"}, {"paperId": "fe88f322ca3fe937aa3785bec294f250748c1ed8", "title": "Continual 3D Convolutional Neural Networks for Real-time Processing of Videos"}, {"paperId": "2d2d18d5197a118648224807d085436802b901b7", "title": "Single-Layer Vision Transformers for More Accurate Early Exits with Less Overhead"}, {"paperId": "18863dbfa32eaa1ccdb56ff180e6ab079a7f1ec6", "title": "Multiscale Vision Transformers"}, {"paperId": "17ed0114f03dcc019e9fdce13b86cfbedcc16d0b", "title": "Temporally smooth online action detection using cycle-consistent future anticipation"}, {"paperId": "af5d212bbfbeaa76d884de140f5248d666d13312", "title": "Counter-Interference Adapter for Multilingual Machine Translation"}, {"paperId": "90d5e6f8d3b9f2617b3a3cf00fb02e730eb011cb", "title": "Accelerating Sparse Deep Neural Networks"}, {"paperId": "b6382a7351c0c595f91472ac71d3b2d87b3c4844", "title": "ViViT: A Video Vision Transformer"}, {"paperId": "04e283adccf66742130bde4a4dedcda8f549dd7e", "title": "A Survey of Quantization Methods for Efficient Neural Network Inference"}, {"paperId": "0820694e95d1a9bfe364727a5f568f139cf5a980", "title": "MoViNets: Mobile Video Networks for Efficient Video Recognition"}, {"paperId": "9efe8dbde586d6248ecfc69f08b918012e2ac478", "title": "Revisiting ResNets: Improved Training and Scaling Strategies"}, {"paperId": "86e69494bfc8e8156a7f4cc42d9052b57b6e4241", "title": "Temporal filtering networks for online action detection"}, {"paperId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "title": "Learning Transferable Visual Models From Natural Language Supervision"}, {"paperId": "2cd605106b88c85d7d8b865b1ef0f8c8293debf1", "title": "Zero-Shot Text-to-Image Generation"}, {"paperId": "fa08b41ccdfc5d8771adfbc34c176fa237d4646c", "title": "Is Space-Time Attention All You Need for Video Understanding?"}, {"paperId": "ca4b945ad7d109c3cbc2170a942ca3b0ecf6fcf5", "title": "Wake Word Detection with Streaming Transformers"}, {"paperId": "5e38dc1ccf33ac1df09b8eb6476f110cb3d1966f", "title": "Learning N: M Fine-grained Structured Sparse Neural Networks From Scratch"}, {"paperId": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85", "title": "Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention"}, {"paperId": "94b69cf199fa0b6c842e17fe5d6174a9d161c3df", "title": "Video Transformer Network"}, {"paperId": "fdacf2a732f55befdc410ea927091cad3b791f13", "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"}, {"paperId": "ad7ddcc14984caae308c397f1a589aae75d4ab71", "title": "Training data-efficient image transformers & distillation through attention"}, {"paperId": "42b6d63416f46e9ac2bcdda9a7065f4682f18e93", "title": "Privileged Knowledge Distillation for Online Action Detection"}, {"paperId": "140b0e3a584a3157889ebcd7a39250739e492570", "title": "Progressive Spatio-Temporal Graph Convolutional Network for Skeleton-Based Human Action Recognition"}, {"paperId": "042a11f51ff81dd122bcf6fedef863e9da65d659", "title": "Temporal Attention-Augmented Graph Convolutional Network for Efficient Skeleton-Based Human Action Recognition"}, {"paperId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"paperId": "5a88a2efc00d0c75715329513db3c2894132399d", "title": "Dissected 3D CNNs: Temporal Skip Connections for Efficient Online Video Processing"}, {"paperId": "3fbf6339273c50b04e886fa9bd4ad18c952a683d", "title": "Rethinking Attention with Performers"}, {"paperId": "afd9e44d7d7b3a947bade59bb1bd000e5271a48b", "title": "Skeleton-based action recognition via spatial and temporal transformer networks"}, {"paperId": "575f71d8ab6aeccf17ef3295b48221f04f7eac64", "title": "HMQ: Hardware Friendly Mixed Precision Quantization Block for CNNs"}, {"paperId": "91cfd15b587c5ed604e7e49326db6d045276c2a5", "title": "The Computational Limits of Deep Learning"}, {"paperId": "5c126ae3421f05768d8edd97ecd44b1364e2c99a", "title": "Denoising Diffusion Probabilistic Models"}, {"paperId": "4ffc126a5262b888d7fd961dbf0a9b7ce2c9d2bc", "title": "Protonic solid-state electrochemical synapse for physical neural networks"}, {"paperId": "1728cb805a9573b59330890ba9723e73d6c3c974", "title": "Knowledge Distillation: A Survey"}, {"paperId": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87", "title": "Linformer: Self-Attention with Linear Complexity"}, {"paperId": "1d41090ba8e597380e7353b6b1f42d6a7d9f83b4", "title": "Skeleton-Based Action Recognition With Shift Graph Convolutional Network"}, {"paperId": "7ea2a78a8d8a6327bd13aa4f2d9ace9231bd9662", "title": "Revisiting Knowledge Distillation via Label Smoothing Regularization"}, {"paperId": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0", "title": "Language Models are Few-Shot Learners"}, {"paperId": "66f0f35fc78bdf2af9de46093d49a428970cde2e", "title": "Movement Pruning: Adaptive Sparsity by Fine-Tuning"}, {"paperId": "98ef0db84e62aef969629264c9de1f4d0013f3b9", "title": "AdapterFusion: Non-Destructive Task Composition for Transfer Learning"}, {"paperId": "2238dda06c345a5f1ed87681a10d246c0fac0587", "title": "Why Should We Add Early Exits to Neural Networks?"}, {"paperId": "9fb0d8c62546ae0adfa12af260679d0f5e21de9c", "title": "Supervised Domain Adaptation: A Graph Embedding Perspective and a Rectified Experimental Protocol"}, {"paperId": "c9d3c181d999b0e11c6e4c51b3f9aefd01489e0f", "title": "Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation"}, {"paperId": "908cca0abefc35acc38033603714fbb1bcadc49d", "title": "X3D: Expanding Architectures for Efficient Video Recognition"}, {"paperId": "be9e1f4d698055d3cbc9dfa7f8d52ca1f8a96e0c", "title": "EfficientPS: Efficient Panoptic Segmentation"}, {"paperId": "3950b578a93674d7a8dc6829581058f76823136e", "title": "Disentangling and Unifying Graph Convolutions for Skeleton-Based Action Recognition"}, {"paperId": "8361346478a8994f4253fb15bbaa171d7dc63d34", "title": "Progressive Operational Perceptrons with Memory"}, {"paperId": "e31318ede6342e5726c8081b4273bd01adc13283", "title": "Post-training Piecewise Linear Quantization for Deep Neural Networks"}, {"paperId": "055fd6a9f7293269f1b22c1470e63bd02d8d9500", "title": "Reformer: The Efficient Transformer"}, {"paperId": "ec68678a737ce0e4ee51560fdc9aa86a8a917aee", "title": "Pruning by Explaining: A Novel Criterion for Deep Neural Network Pruning"}, {"paperId": "907029f249a118422954f2130a3d729644b4ce72", "title": "Learning to Discriminate Information for Online Action Detection"}, {"paperId": "ea415809bf87ef4b99966c6c50de6cb996a02a97", "title": "Deep double descent: where bigger models and more data hurt"}, {"paperId": "3c8a456509e6c0805354bd40a35e3f2dbf8069b1", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library"}, {"paperId": "e9fd2dd3852cd9f628ada316bc6c134800576fff", "title": "Discovering Low-Precision Networks Close to Full-Precision Networks for Efficient Inference"}, {"paperId": "7a87ab984ca45aae2c5768d22cd6df3b5fd509f9", "title": "What\u2019s Hidden in a Randomly Weighted Neural Network?"}, {"paperId": "20ba55ee3229db5cb190a00e788c59f08d2a767d", "title": "Self-Training With Noisy Student Improves ImageNet Classification"}, {"paperId": "3b8076846879dc6e113d934a05b10ef49a34e6a3", "title": "Learning Graph Convolutional Network for Skeleton-based Human Action Recognition by Neural Searching"}, {"paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"}, {"paperId": "63a814b779997759acbfb5968dee4ea5ce7e927a", "title": "Compressing by Learning in a Low-Rank and Sparse Decomposition Form"}, {"paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"}, {"paperId": "0cbf97173391b0430140117027edcaf1a37968c7", "title": "TinyBERT: Distilling BERT for Natural Language Understanding"}, {"paperId": "4fb8fd55b476909a26a8dc594e0ae98d4923ad4d", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"}, {"paperId": "7823292e5c4b05c47af91ab6ddf671a0da709e82", "title": "Once for All: Train One Network and Specialize it for Efficient Deployment"}, {"paperId": "b48606f226ab6b9a4c391a0bd0e60987de818de4", "title": "Lifelong GAN: Continual Learning for Conditional Image Generation"}, {"paperId": "d77123b54dcc8014949584ab624e97298617bcad", "title": "Data-Free Quantization Through Weight Equalization and Bias Correction"}, {"paperId": "68a024d7b70ef3989a6751678f635cbe754440fc", "title": "Skeleton-Based Action Recognition With Directed Graph Neural Networks"}, {"paperId": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9", "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"}, {"paperId": "1b632712cd0d1f14784ba938f135960f71a52e5c", "title": "NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding"}, {"paperId": "1a858b96d2fdfeadf8c0f7126cbd55825223fb9d", "title": "HAWQ: Hessian AWare Quantization of Neural Networks With Mixed-Precision"}, {"paperId": "d712fdf54d2d4c56afdc89e779208113b6edeafb", "title": "Resource Efficient 3D Convolutional Neural Networks"}, {"paperId": "a08293b2c9c5bcddb023cc7eb3354d4d86bfae89", "title": "Distilling Task-Specific Knowledge from BERT into Simple Neural Networks"}, {"paperId": "8659bf379ca8756755125a487c43cfe8611ce842", "title": "To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks"}, {"paperId": "dc160709bbe528b506a37ead334f60d258413357", "title": "Learned Step Size Quantization"}, {"paperId": "bc6dfc6bda2d929fec91042dce1831fd07999b39", "title": "Improved Knowledge Distillation via Teacher Assistant"}, {"paperId": "29ddc1f43f28af7c846515e32cc167bc66886d0c", "title": "Parameter-Efficient Transfer Learning for NLP"}, {"paperId": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6", "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"}, {"paperId": "f86f1748d1b6d22870f4347fd5d65314ba800583", "title": "Reconciling modern machine-learning practice and the classical bias\u2013variance trade-off"}, {"paperId": "9e8db1519245426f3a78752a3d8360484f4626b1", "title": "OpenPose: Realtime Multi-Person 2D Pose Estimation Using Part Affinity Fields"}, {"paperId": "8b47b9c3c35b2b2a78bff7822605b3040f87d699", "title": "SlowFast Networks for Video Recognition"}, {"paperId": "f9717d29840f4d8f1cc19d1b1e80c5d12ec40608", "title": "A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play"}, {"paperId": "3cc6c2db24a2a14560f151867f2ac0b681ec3238", "title": "Synetgy: Algorithm-hardware Co-design for ConvNet Accelerators on Embedded FPGAs"}, {"paperId": "4152d2c8585f7e3f85d3b3d84036171de104cbd7", "title": "Rethinking ImageNet Pre-Training"}, {"paperId": "4bbfd46721c145852e443ae4aad35148b814bf91", "title": "TSM: Temporal Shift Module for Efficient Video Understanding"}, {"paperId": "bcaa81e2150dffcb5dc7bc785285444570443b80", "title": "Temporal Recurrent Networks for Online Action Detection"}, {"paperId": "718418a88461c44a77bc4c0a1bdc9f3e6434fbab", "title": "Recurrent Convolutions for Causal 3D CNNs"}, {"paperId": "f789425a7af1d012675118d7d10cd50afad09074", "title": "Post training 4-bit quantization of convolutional networks for rapid-deployment"}, {"paperId": "815fc84787688ab0c3618a24fff282da8926bb22", "title": "The jamming transition as a paradigm to understand the loss landscape of deep neural networks"}, {"paperId": "3cd3f1585ced02cbb56a9e1428176a6c2b211da2", "title": "Learning to Quantize Deep Networks by Optimizing Quantization Intervals With Task Loss"}, {"paperId": "693c97ecedb0a84539b7162c95e89fa3cd84ca73", "title": "MnasNet: Platform-Aware Neural Architecture Search for Mobile"}, {"paperId": "0682bfa5cca15726aab6c00ecfac91eb44379626", "title": "Eyeriss v2: A Flexible Accelerator for Emerging Deep Neural Networks on Mobile Devices"}, {"paperId": "3d8b62c060f8444907e7c975c6ae590373b51ed4", "title": "Quantizing deep convolutional networks for efficient inference: A whitepaper"}, {"paperId": "55be861931d147d8bf91abcfe73af6a151283955", "title": "Constructing Fast Network through Deconstruction of Convolution"}, {"paperId": "8a8cfa45b4c0d071fbffa091c02670b19c94b693", "title": "Do Better ImageNet Models Transfer Better?"}, {"paperId": "e48f36aacb72adb74cef077c87d2351121124137", "title": "Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action Recognition"}, {"paperId": "451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"}, {"paperId": "4081de7e0f94e7e0d7b645c298d7768698d05774", "title": "Efficient Parametrization of Multi-domain Deep Neural Networks"}, {"paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329", "title": "Image Transformer"}, {"paperId": "3febb2bed8865945e7fddc99efd791887bb7e14f", "title": "Deep Contextualized Word Representations"}, {"paperId": "f6a4bf043af1a9ec7f104a7b7ab56806b241ceda", "title": "Model compression via distillation and quantization"}, {"paperId": "df013a17ab84d5403361da4538a04d574f58be83", "title": "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning"}, {"paperId": "fe9b8aac9fa3bfd9724db5a881a578e471e612d7", "title": "Efficient Neural Architecture Search via Parameter Sharing"}, {"paperId": "904decf94f5495d1488e2bf22e3ed4df500ce4d5", "title": "Shift-Net: Image Inpainting via Deep Feature Rearrangement"}, {"paperId": "efeaa6e3114d6d6ae5c3041b66ac9a9ae9bf52bf", "title": "Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition"}, {"paperId": "d5bb3faa48b83469da1a01ef267886e71f4a931a", "title": "Piggyback: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights"}, {"paperId": "1e077413b25c4d34945cc2707e17e46ed4fe784a", "title": "Universal Language Model Fine-tuning for Text Classification"}, {"paperId": "59d0d7ccec2db66cad20cac5721ce54a8a058294", "title": "Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference"}, {"paperId": "89c3050522a0bb9820c32dc7444e003ef0d3e2e4", "title": "A Closer Look at Spatiotemporal Convolutions for Action Recognition"}, {"paperId": "70c810ba62c5ee40d611e134b2ac2ca61c4de16b", "title": "Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions"}, {"paperId": "8899094797e82c5c185a0893896320ef77f60e64", "title": "Non-local Neural Networks"}, {"paperId": "7b8d67593c4ab1b1e3eccc158daee76703b328aa", "title": "Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy"}, {"paperId": "8c2a7047cfd87268b8f480e5ba6472974beb66b4", "title": "On Lower Bounds for Statistical Learning Theory"}, {"paperId": "6104568e318f140d7adcf646412f182906db69b1", "title": "High-dimensional dynamics of generalization error in neural networks"}, {"paperId": "e7fd6848cb29ca221a7e17d823e06fb566f1f135", "title": "Mixed Precision Training"}, {"paperId": "3b4d671a8c7018c0b42673ba581e5ff3ae762d6c", "title": "To prune, or not to prune: exploring the efficacy of pruning for model compression"}, {"paperId": "42ec4e41cf76159ef0be1a9a7af164400ff508a6", "title": "Improving Efficiency in Convolutional Neural Network with Multilinear Filters"}, {"paperId": "2a8b6f990a5ddf0122aae82a46359b03031f302b", "title": "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm"}, {"paperId": "d0611891b9e8a7c5731146097b6f201578f47b2f", "title": "Learning Transferable Architectures for Scalable Image Recognition"}, {"paperId": "9806871bdcf0a9f926f6b4aebd20ee4580d69f00", "title": "On Compressing Deep Models by Low Rank and Sparse Decomposition"}, {"paperId": "fa3cd1f68783c160f7acf9ef857f1e3254ff95db", "title": "Theoretical Insights Into the Optimization Landscape of Over-Parameterized Shallow Neural Networks"}, {"paperId": "9da734397acd7ff7c557960c62fb1b400b27bd89", "title": "ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"}, {"paperId": "7ace4330a28ef74f489e581b62cfe21cc9bbc986", "title": "RED: Reinforced Encoder-Decoder Networks for Action Anticipation"}, {"paperId": "231af7dc01a166cac3b5b01ca05778238f796e41", "title": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium"}, {"paperId": "e0614fbad47536be524d5b9e6bea4f0a3153d71d", "title": "meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting"}, {"paperId": "204e3073870fae3d05bcbc2f6a8e263d9b72e776", "title": "Attention is All you Need"}, {"paperId": "f06a12928307e17b1aff2b9f4a6c11791f19b6a7", "title": "Deep Mutual Learning"}, {"paperId": "b61a3f8b80bbd44f24544dc915f52fd30bbdf485", "title": "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset"}, {"paperId": "d89ee98810039d2061ed42ee8026da49c503d16b", "title": "Learning multiple visual domains with residual adapters"}, {"paperId": "37c970a2f27810987e2b47dd5b8e0cc9bb976a38", "title": "Temporal Segment Networks for Action Recognition in Videos"}, {"paperId": "3647d6d0f151dc05626449ee09cc7bce55be497e", "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"paperId": "5b68cdb5eee1b5db18398efb0d2c5d727285e5e4", "title": "View Adaptive Recurrent Neural Networks for High Performance Human Action Recognition from Skeleton Data"}, {"paperId": "1a0912bb76777469295bb2c059faee907e7f3258", "title": "Mask R-CNN"}, {"paperId": "fd2a8edf482d96fcaf432a943ce0888d49bb4525", "title": "A New Representation of Skeleton Sequences for 3D Action Recognition"}, {"paperId": "3db8730c203f88d7f08a6a99e8c02a077dc9b011", "title": "Pruning Convolutional Neural Networks for Resource Efficient Inference"}, {"paperId": "67d968c7450878190e45ac7886746de867bf673d", "title": "Neural Architecture Search with Reinforcement Learning"}, {"paperId": "85aefde69e916523d9587b6abd01419420039474", "title": "Performance Measures and a Data Set for Multi-target, Multi-camera Tracking"}, {"paperId": "c2a1cb1612ba21e067a5c3ba478a8d73b796b77a", "title": "Pruning Filters for Efficient ConvNets"}, {"paperId": "b022f2a277a4bf5f42382e86e4380b96340b9e86", "title": "SGDR: Stochastic Gradient Descent with Warm Restarts"}, {"paperId": "05dd7254b632376973f3a1b4d39485da17814df5", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"}, {"paperId": "3dd906bc0947e56d2b7bf9530b11351bbdff2358", "title": "The THUMOS challenge on action recognition for videos \"in the wild\""}, {"paperId": "fbfb0ede13691804ec5a17babe443c223deb0b9a", "title": "Online Action Detection"}, {"paperId": "091e4d3c85dc0a8212afea875cd3b162d273d46b", "title": "NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis"}, {"paperId": "21334d1aac5422da88780f8e24e181bfa15ef0e1", "title": "Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding"}, {"paperId": "846aedd869a00c09b40f1f1f35673cb22bc87490", "title": "Mastering the game of Go with deep neural networks and tree search"}, {"paperId": "2c03df8b48bf3fa39054345bafabfeff15bfd11d", "title": "Deep Residual Learning for Image Recognition"}, {"paperId": "4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0", "title": "SSD: Single Shot MultiBox Detector"}, {"paperId": "a5733ff08daff727af834345b9cfff1d0aa109ec", "title": "BinaryConnect: Training Deep Neural Networks with binary weights during propagations"}, {"paperId": "ae708bf2cd98fb583c92bd05b5584e117c5b273a", "title": "Very deep convolutional neural network based image classification using small training sample size"}, {"paperId": "f8e79ac0ea341056ef20f2616628b3e964764cfd", "title": "You Only Look Once: Unified, Real-Time Object Detection"}, {"paperId": "0a28efacb92d16e6e0dd4d87b5aca91b28be8853", "title": "ActivityNet: A large-scale video benchmark for human activity understanding"}, {"paperId": "7ffdbc358b63378f07311e883dddacc9faeeaf4b", "title": "Fast R-CNN"}, {"paperId": "5418b2a482720e013d487a385c26fae0f017c6a6", "title": "Beyond short snippets: Deep networks for video classification"}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network"}, {"paperId": "d25c65d261ea0e6a458be4c50c40ffe5bc508f77", "title": "Learning Spatiotemporal Features with 3D Convolutional Networks"}, {"paperId": "f01fc808592ea7c473a69a6e7484040a435f36d9", "title": "Long-term recurrent convolutional networks for visual recognition and description"}, {"paperId": "6fc6803df5f9ae505cae5b2f178ade4062c768d0", "title": "Fully convolutional networks for semantic segmentation"}, {"paperId": "081651b38ff7533550a3adfc1c00da333a8fe86c", "title": "How transferable are features in deep neural networks?"}, {"paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd", "title": "ImageNet Large Scale Visual Recognition Challenge"}, {"paperId": "e5ae8ab688051931b4814f6d32b18391f8d1fa8d", "title": "Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation"}, {"paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff", "title": "ImageNet classification with deep convolutional neural networks"}, {"paperId": "03911c85305d42aa2eeb02be82ef6fb7da644dd0", "title": "Algorithms for Hyper-Parameter Optimization"}, {"paperId": "87e43e9eba01a4eb03436c9946bf6aa031a5d5af", "title": "Tensor Decompositions and Applications"}, {"paperId": "02b28f3b71138a06e40dbd614abf8568420ae183", "title": "Automated Flower Classification over a Large Number of Classes"}, {"paperId": "2258e01865367018ed6f4262c880df85b94959f8", "title": "Evaluating Multiple Object Tracking Performance: The CLEAR MOT Metrics"}, {"paperId": "8c10a7d51d8c33a3daf2c39e16f2e11bf51de55e", "title": "Asirra: a CAPTCHA that exploits interest-aligned manual image categorization"}, {"paperId": "30c9bb327b7f2b9f1d1e5b69b9d0c97b410948d9", "title": "Model compression"}, {"paperId": "9c842b2926fd60b9e6ff80fee28c65e7c1ae5f1d", "title": "A non-local algorithm for image denoising"}, {"paperId": "602f31242e577d2d05f918a3080fd50095e7faed", "title": "Factors in automatic musical genre classification of audio signals"}, {"paperId": "d7da009f457917aa381619facfa5ffae9329a6e9", "title": "Bleu: a Method for Automatic Evaluation of Machine Translation"}, {"paperId": "eb82d3035849cd23578096462ba419b53198a556", "title": "The PageRank Citation Ranking : Bringing Order to the Web"}, {"paperId": "9dd0d3342dc8d751301f28f49c2f921b04dde799", "title": "Understanding Digital Signal Processing"}, {"paperId": null, "title": "The carbon footprint of chatgpt"}, {"paperId": "1e9d557e92b676d279d3b8548ebe9f5e9af6f6cf", "title": "Deep Learning for Robot Perception and Cognition"}, {"paperId": null, "title": "Chapter 14 - human activity recognition"}, {"paperId": null, "title": "Chapter 4 - graph convolutional networks"}, {"paperId": null, "title": "PyTorch-Benchmark"}, {"paperId": null, "title": "GitHub, https://github.com/ lukashedegaard/ride"}, {"paperId": "121c3860d5e3917c658dfac7e1f56ba297e87a6c", "title": "Channel Permutations for N: M Sparsity"}, {"paperId": null, "title": "Co-rider"}, {"paperId": null, "title": "Alphafold is the most important achievement in ai-ever"}, {"paperId": "df2b0e26d0599ce3e70df8a9da02e51594e0e992", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"paperId": "9405cc0d6169988371b2755e573cc28650d14dfe", "title": "Language Models are Unsupervised Multitask Learners"}, {"paperId": null, "title": "Onnx: Open neural network exchange. https://github.com/onnx/onnx, 2019"}, {"paperId": null, "title": "The kinetics human action video"}, {"paperId": "a07609c2ed39d049d3e59b61408fb600c6ab0950", "title": "GPU Kernels for Block-Sparse Weights"}, {"paperId": null, "title": "Nvidia 8-bit inference with tensorrt"}, {"paperId": "28135fd3e80dda50a673cd556f10b9b972005d27", "title": "Binarized Neural Networks"}, {"paperId": null, "title": "Another way of looking at lee sedol vs alphago, March 2016"}, {"paperId": null, "title": "TensorFlow: Large-scale machine learning on heterogeneous systems"}, {"paperId": "9277707a5213775277f47cc152fff1349900f473", "title": "Greedy Bilateral Sketch, Completion & Smoothing"}, {"paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086", "title": "Learning Multiple Layers of Features from Tiny Images"}, {"paperId": "afca5f0b9462c1aa246f7a6a51a81031f0c461ac", "title": "The Maximum of Utility Given by Free Competition"}, {"paperId": "6d12a1d23b21a9b170118a56386552bc5d4727de", "title": "A Mathematical Theory of Communication"}, {"paperId": "23729ae655799ed2baa40ad77a2d4344453754f6", "title": "Artificial intelligence - a modern approach, 2nd Edition"}, {"paperId": "95c4ebb6df40abc74c9cf36994c0f914be3b04bd", "title": "ASSOCIATION FOR COMPUTING MACHINERY"}, {"paperId": "090c5a5df345ab60c41d6de02b3e366e1a27cf43", "title": "A logical calculus of the ideas immanent in nervous activity"}, {"paperId": null, "title": "The perceptron - a perceiving and recognizing automaton"}, {"paperId": "8a50ec51a6c752cd2559ce974f8a9db8a6aecaa6", "title": "Ueber die Darstellbarkeit einer Function durch eine trigonometrische Reihe"}, {"paperId": null, "title": "Graduate School of Technical Sciences. Rules and Regulations"}, {"paperId": null, "title": "Chatgpt reaches 100 million users two months after launch, 2023. The Guardian"}, {"paperId": null, "title": "Openvino toolkit repository"}, {"paperId": null, "title": "Optimizing language models for dialogue"}, {"paperId": null, "title": "TFLite developers"}, {"paperId": null, "title": "Parameter counts in machine learning"}, {"paperId": null, "title": "Publication 4"}]}