{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "index_dir='library_index.csv'\n",
    "\n",
    "\n",
    "headers = {'x-api-key': 'api_key'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get paper id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "match_api='https://api.semanticscholar.org/graph/v1/paper/search/match?query={title}'\n",
    "\n",
    "index_csv=pd.read_csv(index_dir)\n",
    "index_dict=index_csv.to_dict(orient='records')\n",
    "index={}\n",
    "for i in index_dict:\n",
    "    index[i['acronym'].lower()]=i['title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:55<00:00,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "papers={}\n",
    "for i in tqdm(index):\n",
    "    papers[i]=requests.get(match_api.format(title=index[i]), headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_csv['acronym']=index_csv['acronym'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: ntk\n",
      "Error: longnet\n",
      "Error: feedbackmem\n",
      "Error: srt\n",
      "Error: kangpt\n",
      "Error: s4pp\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "unmatched=[]\n",
    "\n",
    "for i in papers:\n",
    "    try:\n",
    "        id=papers[i]['data'][0]['paperId']\n",
    "        index_csv.loc[index_csv['acronym']==i,'id']=id\n",
    "    except:\n",
    "        unmatched.append(i)\n",
    "        print('Error:',i)\n",
    "\n",
    "print(len(unmatched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(unmatched):\n",
    "    papers[i]=requests.get(match_api.format(title=index[i])).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntk\n",
      "feedbackmem\n",
      "srt\n",
      "kangpt\n",
      "s4pp\n"
     ]
    }
   ],
   "source": [
    "# index_csv.to_csv('library_index.csv',index=False)\n",
    "for i in index_csv['acronym']:\n",
    "    if index_csv.loc[index_csv['acronym']==i,'id'].isnull().values.any():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct metadata & references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 6236.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: hopfield Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:00<00:00, 6248.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Forbidden'}\n",
      "Error: hopfield Forbidden\n"
     ]
    }
   ],
   "source": [
    "meta={}\n",
    "meta_dir='library_meta.json'\n",
    "if os.path.exists(meta_dir):\n",
    "    with open(meta_dir,'r') as f:\n",
    "        meta=json.load(f)\n",
    "\n",
    "paper_detail='https://api.semanticscholar.org/graph/v1/paper/{paper_id}?fields=year,authors,tldr,venue,abstract,citationCount,influentialCitationCount,references,embedding.specter_v2,openAccessPdf'\n",
    "\n",
    "for i in tqdm(index_csv.index):\n",
    "    acronym=index_csv.loc[i,'acronym']\n",
    "    title=index_csv.loc[i,'title']\n",
    "    if 'detail' in meta.get(acronym,{}):\n",
    "        if not 'message' in meta[acronym]['detail']:\n",
    "            continue\n",
    "    if not pd.isna(index_csv.loc[i,'id']):\n",
    "        paper_id=index_csv.loc[i,'id']\n",
    "        detail=requests.get(paper_detail.format(paper_id=paper_id),headers=headers).json()\n",
    "        if 'message' in detail:\n",
    "            print('Error:',acronym,detail['message'])\n",
    "            continue\n",
    "        meta[acronym]={}\n",
    "        meta[acronym]['title']=title\n",
    "        meta[acronym]['id']=paper_id\n",
    "        meta[acronym]['detail']=detail\n",
    "    else:\n",
    "        meta[acronym]={}\n",
    "        meta[acronym]['title']=title\n",
    "        meta[acronym]['id']=paper_id\n",
    "        meta[acronym]['detail']={}\n",
    "\n",
    "with open(meta_dir,'w') as f:\n",
    "    json.dump(meta,f)\n",
    "        \n",
    "\n",
    "references={}\n",
    "ref_dir='library_ref.json'\n",
    "if os.path.exists(ref_dir):\n",
    "    with open(ref_dir,'r') as f:\n",
    "        references=json.load(f)\n",
    "\n",
    "references_detail='https://api.semanticscholar.org/graph/v1/paper/{paper_id}/references?fields=contextsWithIntent,intents,isInfluential,title,influentialCitationCount'\n",
    "\n",
    "for i in tqdm(index_csv.index):\n",
    "    acronym=index_csv.loc[i,'acronym']\n",
    "    id=index_csv.loc[i,'id']\n",
    "    if acronym in references:\n",
    "        if 'message' not in references[acronym]:\n",
    "            continue\n",
    "    if pd.isna(id):\n",
    "        references[acronym]=[]\n",
    "    else:\n",
    "        ret=requests.get(references_detail.format(paper_id=id),headers=headers).json()\n",
    "        if 'message' in ret:\n",
    "            print('Error:',acronym,ret['message'])\n",
    "            continue\n",
    "        references[acronym]=ret\n",
    "        \n",
    "\n",
    "with open(ref_dir,'w') as f:\n",
    "    json.dump(references,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata to tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 300 300\n"
     ]
    }
   ],
   "source": [
    "index=pd.read_csv('./library_index.csv')\n",
    "with open('./library_meta.json','r') as f:\n",
    "    meta=json.load(f)\n",
    "with open('./library_ref.json','r') as f:\n",
    "    refs=json.load(f)\n",
    "print(len(index),len(meta),len(refs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Hydra: Bidirectional State Space Models Through Generalized Matrix Mixers',\n",
       " 'id': 'ea507df05bb5fe32cd8af80602708713c9bd2ba2',\n",
       " 'detail': {'paperId': 'ea507df05bb5fe32cd8af80602708713c9bd2ba2',\n",
       "  'abstract': 'A wide array of sequence models are built on a framework modeled after Transformers, comprising alternating sequence mixer and channel mixer layers. This paper studies a unifying matrix mixer view of sequence mixers that can be conceptualized as a linear map on the input sequence. This framework encompasses a broad range of well-known sequence models, including the self-attention of Transformers as well as recent strong alternatives such as structured state space models (SSMs), and allows understanding downstream characteristics such as efficiency and expressivity through properties of their structured matrix class. We identify a key axis of matrix parameterizations termed sequence alignment, which increases the flexibility and performance of matrix mixers, providing insights into the strong performance of Transformers and recent SSMs such as Mamba. Furthermore, the matrix mixer framework offers a systematic approach to developing sequence mixers with desired properties, allowing us to develop several new sub-quadratic sequence models. In particular, we propose a natural bidirectional extension of the Mamba model (Hydra), parameterized as a quasiseparable matrix mixer, which demonstrates superior performance over other sequence models including Transformers on non-causal tasks. As a drop-in replacement for attention layers, Hydra outperforms BERT by 0.8 points on the GLUE benchmark and ViT by 2% Top-1 accuracy on ImageNet.',\n",
       "  'venue': '',\n",
       "  'year': 2024,\n",
       "  'citationCount': 0,\n",
       "  'influentialCitationCount': 0,\n",
       "  'openAccessPdf': None,\n",
       "  'tldr': {'model': 'tldr@v2.0.0',\n",
       "   'text': 'This paper proposes a natural bidirectional extension of the Mamba model (Hydra), parameterized as a quasiseparable matrix mixer, which demonstrates superior performance over other sequence models including Transformers on non-causal tasks.'},\n",
       "  'embedding': {'model': 'specter_v2',\n",
       "   'vector': [0.3691936135292053,\n",
       "    0.684001624584198,\n",
       "    -0.8301305174827576,\n",
       "    -0.08957887440919876,\n",
       "    -0.40611547231674194,\n",
       "    -0.2073422521352768,\n",
       "    1.0868765115737915,\n",
       "    -0.1280009001493454,\n",
       "    -0.004888550378382206,\n",
       "    -0.044198185205459595,\n",
       "    0.7469698786735535,\n",
       "    -0.14854228496551514,\n",
       "    0.17087794840335846,\n",
       "    0.17108210921287537,\n",
       "    -0.4217158257961273,\n",
       "    -0.1535896360874176,\n",
       "    -1.1197034120559692,\n",
       "    0.18405748903751373,\n",
       "    -0.14964161813259125,\n",
       "    -0.4996798038482666,\n",
       "    0.18804138898849487,\n",
       "    -0.7420117259025574,\n",
       "    -0.759951114654541,\n",
       "    0.2549353539943695,\n",
       "    0.1619618982076645,\n",
       "    0.48802924156188965,\n",
       "    0.12948745489120483,\n",
       "    0.7568091154098511,\n",
       "    -0.4339103102684021,\n",
       "    1.188706398010254,\n",
       "    0.44512444734573364,\n",
       "    -0.2482149451971054,\n",
       "    0.6505022048950195,\n",
       "    -0.5179876089096069,\n",
       "    -0.33862316608428955,\n",
       "    -0.20644545555114746,\n",
       "    0.596565306186676,\n",
       "    -0.48925042152404785,\n",
       "    -0.9409173130989075,\n",
       "    0.7627272605895996,\n",
       "    -0.6802093386650085,\n",
       "    -0.02843552827835083,\n",
       "    0.2750302851200104,\n",
       "    -1.3059136867523193,\n",
       "    0.010501882992684841,\n",
       "    1.0072637796401978,\n",
       "    0.887083113193512,\n",
       "    0.9099121689796448,\n",
       "    -0.32611650228500366,\n",
       "    -0.3339020609855652,\n",
       "    1.7394038438796997,\n",
       "    -1.0384652614593506,\n",
       "    0.36098384857177734,\n",
       "    1.552544116973877,\n",
       "    0.3755418658256531,\n",
       "    0.35993799567222595,\n",
       "    -0.4990871846675873,\n",
       "    -0.8210407495498657,\n",
       "    0.9077186584472656,\n",
       "    0.5700803995132446,\n",
       "    -0.5254170298576355,\n",
       "    -0.2937619686126709,\n",
       "    -0.08757296204566956,\n",
       "    -0.3813513219356537,\n",
       "    1.2816070318222046,\n",
       "    -0.19429394602775574,\n",
       "    0.2863065302371979,\n",
       "    1.0554360151290894,\n",
       "    0.33234530687332153,\n",
       "    1.200476884841919,\n",
       "    0.45525532960891724,\n",
       "    -0.36319220066070557,\n",
       "    0.16933313012123108,\n",
       "    0.12726040184497833,\n",
       "    0.3952910006046295,\n",
       "    0.8494989275932312,\n",
       "    -0.5700466632843018,\n",
       "    0.7456115484237671,\n",
       "    -1.2640849351882935,\n",
       "    0.1445617526769638,\n",
       "    0.4772484004497528,\n",
       "    -0.0021892318036407232,\n",
       "    0.008463962934911251,\n",
       "    -0.6810616254806519,\n",
       "    -0.6159482598304749,\n",
       "    0.542191207408905,\n",
       "    0.3529750406742096,\n",
       "    0.47143468260765076,\n",
       "    -0.27047351002693176,\n",
       "    0.75678551197052,\n",
       "    0.351297527551651,\n",
       "    0.6935599446296692,\n",
       "    -0.143484964966774,\n",
       "    0.4432375431060791,\n",
       "    0.1999669075012207,\n",
       "    0.21389944851398468,\n",
       "    -0.5899462699890137,\n",
       "    0.2950363755226135,\n",
       "    0.10627260059118271,\n",
       "    0.6911792159080505,\n",
       "    -0.3126291036605835,\n",
       "    0.23055776953697205,\n",
       "    -0.42695021629333496,\n",
       "    -0.3361513018608093,\n",
       "    1.623914122581482,\n",
       "    -0.02168126590549946,\n",
       "    0.17636007070541382,\n",
       "    -0.8503757119178772,\n",
       "    0.3254348933696747,\n",
       "    -0.46538597345352173,\n",
       "    0.40881937742233276,\n",
       "    -1.0154935121536255,\n",
       "    -0.11201851069927216,\n",
       "    -0.3965303599834442,\n",
       "    -0.9217618107795715,\n",
       "    -0.947181224822998,\n",
       "    -0.07130010426044464,\n",
       "    0.9144047498703003,\n",
       "    -0.6691268682479858,\n",
       "    0.8918200135231018,\n",
       "    -0.5330553650856018,\n",
       "    0.47006359696388245,\n",
       "    0.14360539615154266,\n",
       "    0.31939733028411865,\n",
       "    0.08600988239049911,\n",
       "    1.0323340892791748,\n",
       "    0.5495646595954895,\n",
       "    -0.21183909475803375,\n",
       "    0.6382812857627869,\n",
       "    -0.6612985730171204,\n",
       "    -0.8915706872940063,\n",
       "    -1.183188557624817,\n",
       "    0.31522098183631897,\n",
       "    0.3842228949069977,\n",
       "    -0.17294862866401672,\n",
       "    -0.08097640424966812,\n",
       "    -1.2431883811950684,\n",
       "    -1.1135003566741943,\n",
       "    -1.110596776008606,\n",
       "    0.11660007387399673,\n",
       "    -0.30839213728904724,\n",
       "    -0.22196735441684723,\n",
       "    0.9671444296836853,\n",
       "    0.28115925192832947,\n",
       "    -1.0177369117736816,\n",
       "    0.6928073763847351,\n",
       "    -0.8206056356430054,\n",
       "    -0.22518092393875122,\n",
       "    0.44069570302963257,\n",
       "    0.1844542920589447,\n",
       "    0.0923067033290863,\n",
       "    -0.16734878718852997,\n",
       "    -0.9955098628997803,\n",
       "    0.747234046459198,\n",
       "    0.2061186283826828,\n",
       "    -0.14270427823066711,\n",
       "    -0.8324130177497864,\n",
       "    -0.8787321448326111,\n",
       "    -0.982563316822052,\n",
       "    0.1395023763179779,\n",
       "    0.3524397015571594,\n",
       "    -0.7659903764724731,\n",
       "    1.0877140760421753,\n",
       "    0.14469802379608154,\n",
       "    -1.1789392232894897,\n",
       "    0.3022046983242035,\n",
       "    -0.24992448091506958,\n",
       "    -0.3356468379497528,\n",
       "    0.6075679659843445,\n",
       "    -0.031074397265911102,\n",
       "    -0.44077467918395996,\n",
       "    -0.4767872095108032,\n",
       "    -0.18665100634098053,\n",
       "    0.4333716034889221,\n",
       "    0.18402577936649323,\n",
       "    -0.4637882113456726,\n",
       "    -0.5050386786460876,\n",
       "    -0.09994891285896301,\n",
       "    -0.26400113105773926,\n",
       "    -0.26554661989212036,\n",
       "    -0.026407461613416672,\n",
       "    0.6270198822021484,\n",
       "    0.12118139117956161,\n",
       "    0.20639926195144653,\n",
       "    0.4198145866394043,\n",
       "    0.8511907458305359,\n",
       "    -0.3805604577064514,\n",
       "    -0.17018291354179382,\n",
       "    -0.5093436241149902,\n",
       "    -0.557200014591217,\n",
       "    0.36715200543403625,\n",
       "    -0.021219752728939056,\n",
       "    0.8958014249801636,\n",
       "    -0.5604262351989746,\n",
       "    -0.2778532803058624,\n",
       "    -0.22494889795780182,\n",
       "    0.2780224680900574,\n",
       "    -0.46497517824172974,\n",
       "    -0.8171524405479431,\n",
       "    0.798442542552948,\n",
       "    -0.6003956198692322,\n",
       "    0.39986512064933777,\n",
       "    -0.11603352427482605,\n",
       "    -0.795891284942627,\n",
       "    -0.1472007781267166,\n",
       "    -0.2200452834367752,\n",
       "    -0.914918839931488,\n",
       "    -0.05990651994943619,\n",
       "    -0.16354209184646606,\n",
       "    1.0085768699645996,\n",
       "    -1.1771482229232788,\n",
       "    0.13333125412464142,\n",
       "    0.40308597683906555,\n",
       "    -0.25207892060279846,\n",
       "    -0.9696743488311768,\n",
       "    1.381871223449707,\n",
       "    0.12248837947845459,\n",
       "    0.3579663634300232,\n",
       "    0.0690360814332962,\n",
       "    -0.5539422631263733,\n",
       "    -0.29408660531044006,\n",
       "    -0.5364552140235901,\n",
       "    0.7975841760635376,\n",
       "    -0.5276978611946106,\n",
       "    -0.07293987274169922,\n",
       "    0.5487444996833801,\n",
       "    -0.697970986366272,\n",
       "    1.2205090522766113,\n",
       "    -0.2068476676940918,\n",
       "    0.8206208348274231,\n",
       "    -0.07699863612651825,\n",
       "    -1.04485023021698,\n",
       "    0.2599915862083435,\n",
       "    0.589242160320282,\n",
       "    0.12641941010951996,\n",
       "    -0.6916839480400085,\n",
       "    0.24832783639431,\n",
       "    0.026789968833327293,\n",
       "    -0.4544017016887665,\n",
       "    0.11213620752096176,\n",
       "    0.6769008636474609,\n",
       "    0.6352660655975342,\n",
       "    -0.2522996664047241,\n",
       "    -0.20006845891475677,\n",
       "    0.7486072182655334,\n",
       "    -0.21529890596866608,\n",
       "    0.5535796284675598,\n",
       "    0.7357723116874695,\n",
       "    0.7969139814376831,\n",
       "    -0.021663300693035126,\n",
       "    0.8583422899246216,\n",
       "    -0.4257502257823944,\n",
       "    0.08452561497688293,\n",
       "    -0.7830936312675476,\n",
       "    0.09688108414411545,\n",
       "    0.5570152997970581,\n",
       "    0.5007978081703186,\n",
       "    0.40221449732780457,\n",
       "    0.5721371173858643,\n",
       "    -0.6426445841789246,\n",
       "    -0.9234628677368164,\n",
       "    -0.4268138110637665,\n",
       "    0.7655626535415649,\n",
       "    0.662574291229248,\n",
       "    0.36745399236679077,\n",
       "    -0.6317446827888489,\n",
       "    -0.43743428587913513,\n",
       "    0.008626551367342472,\n",
       "    -0.28438612818717957,\n",
       "    -0.02038751356303692,\n",
       "    -0.6772326827049255,\n",
       "    -0.5112977623939514,\n",
       "    -0.542186439037323,\n",
       "    -0.6771332621574402,\n",
       "    0.4796457290649414,\n",
       "    0.8092420101165771,\n",
       "    1.063643217086792,\n",
       "    -0.21006692945957184,\n",
       "    -0.15640093386173248,\n",
       "    -0.037227779626846313,\n",
       "    -0.0429493673145771,\n",
       "    -0.555912971496582,\n",
       "    -0.2522444427013397,\n",
       "    0.24384300410747528,\n",
       "    -0.6760539412498474,\n",
       "    -0.4132993519306183,\n",
       "    0.28932273387908936,\n",
       "    0.12711606919765472,\n",
       "    -0.22937949001789093,\n",
       "    -0.5821810364723206,\n",
       "    0.7875303030014038,\n",
       "    -0.8225140571594238,\n",
       "    -0.18990397453308105,\n",
       "    0.13707099854946136,\n",
       "    0.980606198310852,\n",
       "    -0.5338431596755981,\n",
       "    -0.9648129940032959,\n",
       "    0.020170774310827255,\n",
       "    -0.011605193838477135,\n",
       "    -0.04372526332736015,\n",
       "    0.04144486039876938,\n",
       "    0.14018644392490387,\n",
       "    -0.13446836173534393,\n",
       "    0.2169855237007141,\n",
       "    -0.21157346665859222,\n",
       "    0.5065896511077881,\n",
       "    0.027803795412182808,\n",
       "    0.421802818775177,\n",
       "    0.0504680834710598,\n",
       "    -0.5953892469406128,\n",
       "    -0.019881511107087135,\n",
       "    -0.9184756278991699,\n",
       "    0.7736960053443909,\n",
       "    -0.1921698898077011,\n",
       "    -0.7023217082023621,\n",
       "    0.03272116929292679,\n",
       "    -0.708132266998291,\n",
       "    -0.2526951730251312,\n",
       "    -0.10281985998153687,\n",
       "    -0.5531018972396851,\n",
       "    0.1031978502869606,\n",
       "    -0.8116020560264587,\n",
       "    0.6195265650749207,\n",
       "    -0.34439751505851746,\n",
       "    -0.20305350422859192,\n",
       "    0.15006905794143677,\n",
       "    0.21970829367637634,\n",
       "    0.514247715473175,\n",
       "    0.38875511288642883,\n",
       "    0.5091883540153503,\n",
       "    0.5016087889671326,\n",
       "    0.2213369458913803,\n",
       "    0.7237783670425415,\n",
       "    -0.9598714113235474,\n",
       "    0.6530822515487671,\n",
       "    0.5819408893585205,\n",
       "    0.44525066018104553,\n",
       "    0.09311670064926147,\n",
       "    0.1021319031715393,\n",
       "    -0.6734292507171631,\n",
       "    -0.392659455537796,\n",
       "    -0.38970550894737244,\n",
       "    -0.05118364468216896,\n",
       "    -0.4669820964336395,\n",
       "    0.577372670173645,\n",
       "    -0.7490960359573364,\n",
       "    -1.3667346239089966,\n",
       "    0.07488670945167542,\n",
       "    -0.884134829044342,\n",
       "    -0.507935106754303,\n",
       "    0.13505171239376068,\n",
       "    -0.41729289293289185,\n",
       "    -0.46758267283439636,\n",
       "    -1.2670422792434692,\n",
       "    -1.3836948871612549,\n",
       "    -0.8350905776023865,\n",
       "    0.16637837886810303,\n",
       "    -1.0037466287612915,\n",
       "    0.18910829722881317,\n",
       "    0.036520473659038544,\n",
       "    -0.6483578085899353,\n",
       "    -0.4499979019165039,\n",
       "    0.16151531040668488,\n",
       "    -0.3704656660556793,\n",
       "    1.0539708137512207,\n",
       "    -0.4829094409942627,\n",
       "    0.8185304403305054,\n",
       "    -0.03188863769173622,\n",
       "    -1.0002241134643555,\n",
       "    0.10738053172826767,\n",
       "    0.42098045349121094,\n",
       "    0.412060022354126,\n",
       "    -0.2359565794467926,\n",
       "    0.21756888926029205,\n",
       "    -0.6278212070465088,\n",
       "    0.2730630934238434,\n",
       "    -0.383856862783432,\n",
       "    -0.14338664710521698,\n",
       "    -0.20014676451683044,\n",
       "    0.47080978751182556,\n",
       "    0.3543810546398163,\n",
       "    -0.20803305506706238,\n",
       "    -0.4949774444103241,\n",
       "    0.06405851989984512,\n",
       "    1.2881730794906616,\n",
       "    -0.0160979013890028,\n",
       "    0.281701922416687,\n",
       "    0.3769996464252472,\n",
       "    1.0074794292449951,\n",
       "    0.2710226774215698,\n",
       "    -0.32117244601249695,\n",
       "    0.22038042545318604,\n",
       "    0.537300705909729,\n",
       "    0.4056991636753082,\n",
       "    0.5260348916053772,\n",
       "    -0.14388519525527954,\n",
       "    0.3903680443763733,\n",
       "    -0.7552222609519958,\n",
       "    0.2999410033226013,\n",
       "    1.1570959091186523,\n",
       "    0.24307993054389954,\n",
       "    -0.02653675526380539,\n",
       "    -0.9080274701118469,\n",
       "    0.691370964050293,\n",
       "    -1.3923907279968262,\n",
       "    -1.3004752397537231,\n",
       "    0.49271899461746216,\n",
       "    0.5995123386383057,\n",
       "    0.12155959010124207,\n",
       "    -0.4328676760196686,\n",
       "    -0.031143348664045334,\n",
       "    0.35174956917762756,\n",
       "    0.4405004382133484,\n",
       "    0.455909788608551,\n",
       "    0.06439662724733353,\n",
       "    -0.16239571571350098,\n",
       "    0.1276625394821167,\n",
       "    0.26887041330337524,\n",
       "    0.3187529146671295,\n",
       "    0.9170039892196655,\n",
       "    -0.27177801728248596,\n",
       "    0.2938629686832428,\n",
       "    15.191400527954102,\n",
       "    0.3926241099834442,\n",
       "    -0.059659961611032486,\n",
       "    0.5072054266929626,\n",
       "    0.6188802719116211,\n",
       "    0.10071025788784027,\n",
       "    -0.10266672819852829,\n",
       "    0.29080063104629517,\n",
       "    -0.8958232998847961,\n",
       "    0.138949915766716,\n",
       "    1.390478253364563,\n",
       "    0.029360486194491386,\n",
       "    0.5529000759124756,\n",
       "    -0.03983344882726669,\n",
       "    -0.043838467448949814,\n",
       "    0.18607501685619354,\n",
       "    -1.0603116750717163,\n",
       "    0.6023122072219849,\n",
       "    0.09130289405584335,\n",
       "    -1.4474700689315796,\n",
       "    0.2345486730337143,\n",
       "    0.19180968403816223,\n",
       "    0.29465624690055847,\n",
       "    0.019629893824458122,\n",
       "    0.936850368976593,\n",
       "    0.6747240424156189,\n",
       "    0.6849539279937744,\n",
       "    -0.41929754614830017,\n",
       "    0.9103291630744934,\n",
       "    0.2577875852584839,\n",
       "    0.6972376704216003,\n",
       "    0.16943809390068054,\n",
       "    -0.01932201348245144,\n",
       "    0.446144163608551,\n",
       "    -0.9027016758918762,\n",
       "    -0.6387367248535156,\n",
       "    -0.23629462718963623,\n",
       "    -1.2195284366607666,\n",
       "    0.5062321424484253,\n",
       "    -0.1019752249121666,\n",
       "    -0.2576891779899597,\n",
       "    -0.34879493713378906,\n",
       "    -0.2398453652858734,\n",
       "    0.8716983199119568,\n",
       "    0.5839251279830933,\n",
       "    0.39035528898239136,\n",
       "    -0.08553221821784973,\n",
       "    0.6685584187507629,\n",
       "    0.2771461606025696,\n",
       "    0.4209913909435272,\n",
       "    0.2132316678762436,\n",
       "    0.3682050108909607,\n",
       "    0.1311415284872055,\n",
       "    -0.5345816612243652,\n",
       "    0.015070709399878979,\n",
       "    0.010045909322798252,\n",
       "    0.20582620799541473,\n",
       "    0.4445722997188568,\n",
       "    -0.20606383681297302,\n",
       "    -0.3086830973625183,\n",
       "    -0.4820494055747986,\n",
       "    -0.27113333344459534,\n",
       "    0.1809554398059845,\n",
       "    0.654481828212738,\n",
       "    0.6261212825775146,\n",
       "    -0.1226792261004448,\n",
       "    -0.09701064974069595,\n",
       "    -0.04976344481110573,\n",
       "    0.22021116316318512,\n",
       "    0.23873338103294373,\n",
       "    -0.37293463945388794,\n",
       "    0.22219760715961456,\n",
       "    0.6769681572914124,\n",
       "    -0.5643689632415771,\n",
       "    -0.4616324305534363,\n",
       "    0.5089331865310669,\n",
       "    -0.36730992794036865,\n",
       "    -0.37163737416267395,\n",
       "    -1.0886062383651733,\n",
       "    -0.6420902013778687,\n",
       "    0.28515931963920593,\n",
       "    -0.9985155463218689,\n",
       "    -0.6890302896499634,\n",
       "    0.9961789846420288,\n",
       "    0.02762458845973015,\n",
       "    -0.7685931921005249,\n",
       "    0.24414712190628052,\n",
       "    -0.6636272668838501,\n",
       "    -0.05206826701760292,\n",
       "    0.11405916512012482,\n",
       "    -0.9182068705558777,\n",
       "    -0.3247314393520355,\n",
       "    -0.33980023860931396,\n",
       "    -0.12742459774017334,\n",
       "    -0.15830406546592712,\n",
       "    0.1701962798833847,\n",
       "    0.8708866834640503,\n",
       "    0.07480376213788986,\n",
       "    -0.39624154567718506,\n",
       "    -0.3197038769721985,\n",
       "    -0.08521104604005814,\n",
       "    -0.1630823165178299,\n",
       "    -0.14978204667568207,\n",
       "    -1.099353551864624,\n",
       "    1.0036178827285767,\n",
       "    0.1396532505750656,\n",
       "    0.06827018409967422,\n",
       "    0.41166624426841736,\n",
       "    0.4080562889575958,\n",
       "    0.2518001198768616,\n",
       "    -0.5567165613174438,\n",
       "    0.14431266486644745,\n",
       "    0.4449266791343689,\n",
       "    -1.4013376235961914,\n",
       "    0.15542522072792053,\n",
       "    -1.105742335319519,\n",
       "    -0.7037028074264526,\n",
       "    0.7437500357627869,\n",
       "    0.48216670751571655,\n",
       "    -0.1398155391216278,\n",
       "    -0.053292494267225266,\n",
       "    -0.07144410163164139,\n",
       "    -0.5098815560340881,\n",
       "    -0.27175259590148926,\n",
       "    -0.3710387647151947,\n",
       "    0.04220111295580864,\n",
       "    0.592447817325592,\n",
       "    -0.731228232383728,\n",
       "    -0.5422013401985168,\n",
       "    -0.31204378604888916,\n",
       "    0.07222499698400497,\n",
       "    -1.0997059345245361,\n",
       "    -0.3079826831817627,\n",
       "    -0.2747882604598999,\n",
       "    0.06625672429800034,\n",
       "    -0.1396719366312027,\n",
       "    1.0525716543197632,\n",
       "    -0.7998056411743164,\n",
       "    1.128301739692688,\n",
       "    0.7970582842826843,\n",
       "    -0.04849619045853615,\n",
       "    -0.9780163764953613,\n",
       "    -0.26729467511177063,\n",
       "    -0.9034473896026611,\n",
       "    -0.014412550255656242,\n",
       "    0.20198436081409454,\n",
       "    0.38431671261787415,\n",
       "    -0.545195996761322,\n",
       "    0.46429285407066345,\n",
       "    0.42864927649497986,\n",
       "    0.24438388645648956,\n",
       "    -0.05225931853055954,\n",
       "    -0.5618942975997925,\n",
       "    -0.4450255036354065,\n",
       "    -0.26100972294807434,\n",
       "    -0.28028103709220886,\n",
       "    0.1957421749830246,\n",
       "    0.1893085390329361,\n",
       "    0.23743820190429688,\n",
       "    0.32006070017814636,\n",
       "    -0.023095926269888878,\n",
       "    0.6438095569610596,\n",
       "    -0.08038387447595596,\n",
       "    -0.703554630279541,\n",
       "    0.3963336944580078,\n",
       "    -0.22819852828979492,\n",
       "    0.12030883133411407,\n",
       "    -0.5212392807006836,\n",
       "    -0.8460856080055237,\n",
       "    -1.3725789785385132,\n",
       "    -0.23681429028511047,\n",
       "    -1.0308703184127808,\n",
       "    0.2809838354587555,\n",
       "    -1.1314440965652466,\n",
       "    -0.18033745884895325,\n",
       "    0.2842993438243866,\n",
       "    -0.347970187664032,\n",
       "    -0.31512656807899475,\n",
       "    0.4020253121852875,\n",
       "    -0.4679263234138489,\n",
       "    -0.19699767231941223,\n",
       "    -0.4820859134197235,\n",
       "    -0.27258971333503723,\n",
       "    0.6513597965240479,\n",
       "    0.6616138815879822,\n",
       "    -0.9557768702507019,\n",
       "    0.1965515911579132,\n",
       "    -0.2511197328567505,\n",
       "    -0.039145201444625854,\n",
       "    0.009937502443790436,\n",
       "    0.3341313302516937,\n",
       "    -0.46449002623558044,\n",
       "    -0.8733307123184204,\n",
       "    -0.7379722595214844,\n",
       "    0.25639885663986206,\n",
       "    0.6959357261657715,\n",
       "    0.27155566215515137,\n",
       "    -0.7615846991539001,\n",
       "    0.7247686982154846,\n",
       "    0.06412804871797562,\n",
       "    -0.2997324764728546,\n",
       "    0.2773292362689972,\n",
       "    0.6652359962463379,\n",
       "    -1.0505791902542114,\n",
       "    0.04284784570336342,\n",
       "    0.4592922329902649,\n",
       "    -1.3239169120788574,\n",
       "    0.39150235056877136,\n",
       "    -0.04225075989961624,\n",
       "    0.1189463660120964,\n",
       "    -0.32411012053489685,\n",
       "    1.4239169359207153,\n",
       "    -0.004687837325036526,\n",
       "    -1.0084530115127563,\n",
       "    -0.38261160254478455,\n",
       "    0.343985378742218,\n",
       "    -0.9011849164962769,\n",
       "    -0.09480340033769608,\n",
       "    0.15534688532352448,\n",
       "    -0.1986386775970459,\n",
       "    -1.1711229085922241,\n",
       "    -0.4224136769771576,\n",
       "    -0.12033212929964066,\n",
       "    0.45090940594673157,\n",
       "    -0.6361402869224548,\n",
       "    1.091522216796875,\n",
       "    0.007020039949566126,\n",
       "    -1.1529775857925415,\n",
       "    0.14273755252361298,\n",
       "    0.19270451366901398,\n",
       "    -0.010542983189225197,\n",
       "    -0.3403090834617615,\n",
       "    0.6369494795799255,\n",
       "    0.45846107602119446,\n",
       "    -0.010015217587351799,\n",
       "    0.5616607069969177,\n",
       "    -0.37177619338035583,\n",
       "    0.0039435881190001965,\n",
       "    -0.7691723108291626,\n",
       "    0.28417420387268066,\n",
       "    0.7285143733024597,\n",
       "    -0.3706129193305969,\n",
       "    -0.10739529877901077,\n",
       "    0.8960853219032288,\n",
       "    0.02357887290418148,\n",
       "    -0.6295839548110962,\n",
       "    0.35188785195350647,\n",
       "    -1.1383031606674194,\n",
       "    -0.5704503655433655,\n",
       "    -0.28924769163131714,\n",
       "    0.5575462579727173,\n",
       "    0.6103283166885376,\n",
       "    -0.440617173910141,\n",
       "    0.2980847954750061,\n",
       "    -0.416806161403656,\n",
       "    0.04054425284266472,\n",
       "    0.04500947147607803,\n",
       "    -0.6984517574310303,\n",
       "    0.4260384142398834,\n",
       "    -0.17383533716201782,\n",
       "    -0.14636163413524628,\n",
       "    0.9612223505973816,\n",
       "    0.6804362535476685,\n",
       "    -0.9099113941192627,\n",
       "    -0.8636026382446289,\n",
       "    -0.48958146572113037,\n",
       "    -0.37051767110824585,\n",
       "    -0.3451822102069855,\n",
       "    0.20848248898983002,\n",
       "    -0.2784806489944458,\n",
       "    -0.5835438370704651,\n",
       "    0.9716325402259827,\n",
       "    0.8771578073501587,\n",
       "    0.4903576076030731,\n",
       "    -0.11207035183906555,\n",
       "    -0.3592524230480194,\n",
       "    -0.3997432589530945,\n",
       "    0.3648024797439575,\n",
       "    0.1166822537779808,\n",
       "    -0.2217048853635788,\n",
       "    -0.47252538800239563,\n",
       "    0.5414379835128784,\n",
       "    1.1056067943572998,\n",
       "    -0.39482325315475464,\n",
       "    -0.07009299844503403,\n",
       "    -0.345880925655365,\n",
       "    -0.3651946187019348,\n",
       "    0.721932053565979,\n",
       "    0.490995317697525,\n",
       "    -0.4557178318500519,\n",
       "    0.5040596723556519,\n",
       "    -0.06663470715284348,\n",
       "    0.3093339502811432,\n",
       "    0.00375509075820446,\n",
       "    -1.350938081741333,\n",
       "    0.13699771463871002,\n",
       "    0.42748406529426575,\n",
       "    0.8952794075012207,\n",
       "    0.14795450866222382,\n",
       "    0.03439527004957199,\n",
       "    0.09727739542722702,\n",
       "    0.5015796422958374,\n",
       "    0.20072564482688904,\n",
       "    0.09151297062635422,\n",
       "    0.771967351436615,\n",
       "    0.4640648365020752,\n",
       "    -0.056891873478889465,\n",
       "    0.019636651501059532,\n",
       "    0.22313261032104492,\n",
       "    0.3707960844039917,\n",
       "    -0.33545398712158203,\n",
       "    -0.500997006893158,\n",
       "    0.25071802735328674,\n",
       "    0.8623343110084534,\n",
       "    -0.4137685000896454,\n",
       "    0.7056864500045776,\n",
       "    1.0277466773986816,\n",
       "    -0.11004766076803207,\n",
       "    0.5995330214500427,\n",
       "    0.14400967955589294,\n",
       "    0.5379300117492676,\n",
       "    -0.28232988715171814,\n",
       "    -0.09515170753002167,\n",
       "    -0.41615772247314453,\n",
       "    -0.6184781193733215,\n",
       "    -0.6974004507064819,\n",
       "    -0.4095245897769928,\n",
       "    -0.6016895771026611,\n",
       "    0.2911010980606079,\n",
       "    -0.20655395090579987,\n",
       "    0.3756442368030548,\n",
       "    0.07132132351398468,\n",
       "    0.22608081996440887,\n",
       "    1.1856287717819214,\n",
       "    0.302619993686676,\n",
       "    0.7931621074676514,\n",
       "    -0.057297851890325546,\n",
       "    -0.4652182459831238,\n",
       "    -0.5615044832229614,\n",
       "    -0.9092184901237488,\n",
       "    0.1549060046672821,\n",
       "    -0.580224335193634,\n",
       "    0.16779986023902893,\n",
       "    -0.4136902391910553,\n",
       "    -0.22217920422554016,\n",
       "    -0.03218446299433708]},\n",
       "  'authors': [{'authorId': '2311500924', 'name': 'Sukjun Hwang'},\n",
       "   {'authorId': '2218599184', 'name': 'Aakash Lahoti'},\n",
       "   {'authorId': '2269146652', 'name': 'Tri Dao'},\n",
       "   {'authorId': '2269161650', 'name': 'Albert Gu'}],\n",
       "  'references': [{'paperId': 'ca9f5b3bf0f54ad97513e6175b30497873670fed',\n",
       "    'title': 'Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality'},\n",
       "   {'paperId': '6c1578d9eff8f9d25ddf0398a77ffcc888a4593b',\n",
       "    'title': 'Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling'},\n",
       "   {'paperId': 'cde66097f4123a62bf3e28d48c764648e8c69f72',\n",
       "    'title': 'Simple linear attention language models balance the recall-throughput tradeoff'},\n",
       "   {'paperId': '189fde3f4dfa105bb51472a8945618f395919560',\n",
       "    'title': 'Repeat After Me: Transformers are Better than State Space Models at Copying'},\n",
       "   {'paperId': '38c48a1cd296d16dc9c56717495d6e44cc354444',\n",
       "    'title': 'Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model'},\n",
       "   {'paperId': 'a4715887bd5a4c328ebf1d6ebb18ab94e71ee8d8',\n",
       "    'title': 'MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining'},\n",
       "   {'paperId': '1be73fa3e856c33d0aed1d9e46693523e7fa3c60',\n",
       "    'title': 'Zoology: Measuring and Improving Recall in Efficient Language Models'},\n",
       "   {'paperId': '7bbc7595196a0606a07506c4fb1473e5e87f6082',\n",
       "    'title': 'Mamba: Linear-Time Sequence Modeling with Selective State Spaces'},\n",
       "   {'paperId': 'c85268696fe1435605ae66a18653cfdcf8153753',\n",
       "    'title': 'Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture'},\n",
       "   {'paperId': '240103933ffe3dac2179cc160a2bd91299357a53',\n",
       "    'title': 'Retentive Network: A Successor to Transformer for Large Language Models'},\n",
       "   {'paperId': '067aaf0d1cde4ee21063be137559f2fe50125570',\n",
       "    'title': 'Multi-Head State Space Model for Speech Recognition'},\n",
       "   {'paperId': 'f35f5aedc30e2c5ded210d9c91ba6e84bd029425',\n",
       "    'title': 'Toeplitz Neural Network for Sequence Modeling'},\n",
       "   {'paperId': 'f393aff1593c2d370ec0ae004910d18e40524967',\n",
       "    'title': 'Resurrecting Recurrent Neural Networks for Long Sequences'},\n",
       "   {'paperId': '998ac3e945857cf2676ee7efdbaf443a0c6f820a',\n",
       "    'title': 'Hyena Hierarchy: Towards Larger Convolutional Language Models'},\n",
       "   {'paperId': '29d3b7bc76c673b58a703de1cb5fd069ebfa8307',\n",
       "    'title': 'Exact computations with quasiseparable matrices'},\n",
       "   {'paperId': '5a77b508302771fc083bf24e0bcda8553c9b5421',\n",
       "    'title': 'Hungry Hungry Hippos: Towards Language Modeling with State Space Models'},\n",
       "   {'paperId': 'a128b1c47e6842605fb95bceae930d2135fc38fc',\n",
       "    'title': 'Pretraining Without Attention'},\n",
       "   {'paperId': 'e3fc46d5f4aae2c7a8a86b6bd21ca8db5d40fcbd',\n",
       "    'title': 'The Devil in Linear Transformer'},\n",
       "   {'paperId': 'eaef083b9d661f42cc0d89d9d8156218f33a91d9',\n",
       "    'title': 'Long Range Language Modeling via Gated State Spaces'},\n",
       "   {'paperId': 'ca444821352a4bd91884413d8070446e2960715a',\n",
       "    'title': 'On the Parameterization and Initialization of Diagonal State Space Models'},\n",
       "   {'paperId': '8326dba15f6b8ee6e43c23eea3265a05e59e8135',\n",
       "    'title': 'Monarch: Expressive Structured Matrices for Efficient and Accurate Training'},\n",
       "   {'paperId': 'b55ee75940d24934a54d7f1acfde06e9cb45ac44',\n",
       "    'title': \"It's Raw! Audio Generation with State-Space Models\"},\n",
       "   {'paperId': '177e957f5cd93229c9794ea652c646d2557b4a69',\n",
       "    'title': 'A ConvNet for the 2020s'},\n",
       "   {'paperId': 'ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51',\n",
       "    'title': 'Efficiently Modeling Long Sequences with Structured State Spaces'},\n",
       "   {'paperId': '1f133158a8973fb33fea188f20517cd7e69bfe7f',\n",
       "    'title': 'FNet: Mixing Tokens with Fourier Transforms'},\n",
       "   {'paperId': '67571d29190faea9fbd104acd16274f8c4edf254',\n",
       "    'title': 'MLP-Mixer: An all-MLP Architecture for Vision'},\n",
       "   {'paperId': '7694aae9766d5f1fe74d900cd82aee898cb6e8e9',\n",
       "    'title': 'How to Train BERT with an Academic Budget'},\n",
       "   {'paperId': '1d5c8c6e5a774d2fef8d92bd28670a6345a97f7a',\n",
       "    'title': 'CKConv: Continuous Kernel Convolution For Sequential Data'},\n",
       "   {'paperId': 'ad7ddcc14984caae308c397f1a589aae75d4ab71',\n",
       "    'title': 'Training data-efficient image transformers & distillation through attention'},\n",
       "   {'paperId': '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a',\n",
       "    'title': 'An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale'},\n",
       "   {'paperId': None,\n",
       "    'title': 'Transformers: State-of-the-Art Natural Language Processing'},\n",
       "   {'paperId': '6f68e1bb253925d8431588555d3010419f322e04',\n",
       "    'title': 'Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention'},\n",
       "   {'paperId': 'c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87',\n",
       "    'title': 'Linformer: Self-Attention with Linear Complexity'},\n",
       "   {'paperId': 'a68c3412e60560290400d2707596f82a914b7c00',\n",
       "    'title': 'Kaleidoscope: An Efficient, Learnable Representation For All Structured Linear Maps'},\n",
       "   {'paperId': '6c4b76232bb72897685d19b3d264c6ee3005bc2b',\n",
       "    'title': 'Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer'},\n",
       "   {'paperId': 'a6e92f6fa9e91b7e869562a63b30a9a56cf14582',\n",
       "    'title': 'Learning Fast Algorithms for Linear Transforms Using Butterfly Factorizations'},\n",
       "   {'paperId': '451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c',\n",
       "    'title': 'GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding'},\n",
       "   {'paperId': '204e3073870fae3d05bcbc2f6a8e263d9b72e776',\n",
       "    'title': 'Attention is All you Need'},\n",
       "   {'paperId': '2c03df8b48bf3fa39054345bafabfeff15bfd11d',\n",
       "    'title': 'Deep Residual Learning for Image Recognition'},\n",
       "   {'paperId': 'fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5',\n",
       "    'title': 'Neural Machine Translation by Jointly Learning to Align and Translate'},\n",
       "   {'paperId': 'd2c733e34d48784a37d717fe43d9e93277a8c53e',\n",
       "    'title': 'ImageNet: A large-scale hierarchical image database'},\n",
       "   {'paperId': '35099635bceb88469f25e9c7c1bed19f57d222da',\n",
       "    'title': 'Computations with quasiseparable polynomials and matrices'},\n",
       "   {'paperId': 'cf0f8f585c8822e3c6bcd9527d546eefc8486aea',\n",
       "    'title': 'S4ND: Modeling Images and Videos as Multidimensional Signals with State Spaces'},\n",
       "   {'paperId': 'c8b25fab5608c3e033d34b4483ec47e68ba109b7',\n",
       "    'title': 'Swin Transformer: Hierarchical Vision Transformer using Shifted Windows'},\n",
       "   {'paperId': 'df2b0e26d0599ce3e70df8a9da02e51594e0e992',\n",
       "    'title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'},\n",
       "   {'paperId': '9405cc0d6169988371b2755e573cc28650d14dfe',\n",
       "    'title': 'Language Models are Unsupervised Multitask Learners'},\n",
       "   {'paperId': None, 'title': 'with hardware-efficient training”'}]}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['hydra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "LIBRARY_DIR = './'\n",
    "\n",
    "pjoin=os.path.join\n",
    "pexists=os.path.exists\n",
    "\n",
    "@dataclass\n",
    "class NodeObject:\n",
    "    acronym: str\n",
    "    title: str\n",
    "    seed_ids: List[str]\n",
    "\n",
    "    def to_dict(self) -> Dict:\n",
    "        return asdict(self)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, dict: Dict):\n",
    "        return cls(**dict)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, save_dir: str, acronym:str):\n",
    "        with open(pjoin(save_dir,acronym+'.json'),'r') as f:\n",
    "            return cls.from_dict(json.load(f))\n",
    "\n",
    "    def save(self,save_dir: str):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        with open(pjoin(save_dir,self.acronym+'.json'),'w') as f:\n",
    "            json.dump(self.to_dict(),f,indent=4)\n",
    "\n",
    "    def to_desc(self) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "@dataclass\n",
    "class LibraryReference(NodeObject):\n",
    "    s2id: str = None\n",
    "    abstract: str = None\n",
    "    authors: List[str] = None\n",
    "    venue: str = None\n",
    "    year: int = None\n",
    "    tldr: str = None\n",
    "    # embedding: list\n",
    "    citationCount: int = None\n",
    "    influentialCitationCount: int = None\n",
    "    code: str = None\n",
    "    description: str = None\n",
    "    url: str = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        code_dir=pjoin(LIBRARY_DIR,'base',self.acronym,self.acronym+'_edu.py')\n",
    "        if pexists(code_dir):\n",
    "            self.code=open(code_dir,'r').read()\n",
    "        else:\n",
    "            self.code=None\n",
    "\n",
    "    @property\n",
    "    def type(self) -> str:\n",
    "        if self.code is not None:\n",
    "            return 'ReferenceWithCode'\n",
    "        else:\n",
    "            return 'Reference'\n",
    "\n",
    "    def to_desc(self) -> str:\n",
    "        title=self.title.replace(':',' ')\n",
    "        mdtext=f'# {title}'\n",
    "        if self.s2id:\n",
    "            mdtext+=f'\\n* S2 ID {self.s2id} *'\n",
    "        if self.authors:\n",
    "            authors=', '.join(self.authors)\n",
    "            mdtext+=f'\\n* Authors: {authors} *'\n",
    "        if self.tldr:\n",
    "            tldr=self.tldr.replace(':',' ').replace(',',',\\n')\n",
    "            mdtext+=f'\\n\\n* TL;DR {tldr} *'\n",
    "        if self.abstract:\n",
    "            abstract=self.abstract.replace(':',' ').replace('.','.\\n')\n",
    "            mdtext+=f'\\n\\n## Abstract\\n{abstract}'\n",
    "        if self.venue:\n",
    "            venue=self.venue.replace(':',' ')\n",
    "            mdtext+=f'\\n\\n* Published at {venue} in {self.year} *'\n",
    "            mdtext+=f'\\n* Cited {self.citationCount} times *'\n",
    "            mdtext+=f'\\n* Impactful citations {self.influentialCitationCount} *'\n",
    "        if self.description:\n",
    "            description=self.description.replace(':',' ').replace('.','.\\n')\n",
    "            mdtext+=f'\\n\\n## Description\\n{description}'\n",
    "        return mdtext\n",
    "\n",
    "\n",
    "manual_input={\n",
    "    'srt': {\n",
    "        'title': 'Self Reasoning Tokens',\n",
    "        'authors': ['Felipe Sens Bonetto'],\n",
    "        'year': 2024,\n",
    "        'url': 'https://github.com/lucidrains/self-reasoning-tokens-pytorch',\n",
    "        'description': \"The project \\\"Reasoning Tokens\\\" by Felipe Sens Bonetto aims to enhance the reasoning abilities of language models like GPT by teaching them to plan ahead in a self-supervised way. The core idea is to introduce \\\"reasoning tokens,\\\" where for each token predicted, an additional token is generated that duplicates the input and doesn't receive a gradient from the next token but from future tokens. This approach encourages the model to pre-cache information useful for future predictions. Initial experiments showed a significant reduction in loss, indicating improved performance. The project plans to explore this method further, especially in fine-tuned instruction-following models, potentially replacing the need for step-by-step explanations during training. The ultimate goal is to create models that can reason internally, improving their performance and reducing the need for manually crafted training data.\",\n",
    "        'seed_ids': ['gpt3']\n",
    "    },\n",
    "    'ntk': {\n",
    "        'title': 'NTK-Aware Scaled RoPE',\n",
    "        'authors': ['bloc97'],\n",
    "        'year': 2023,\n",
    "        'url': 'https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have',\n",
    "        'description': \"The \\\"NTK-Aware Scaled RoPE\\\" project aims to extend the context size of LLaMA models beyond 8k tokens without fine-tuning and with minimal perplexity degradation. Traditional methods like RoPE interpolation often fail to distinguish between closely positioned tokens, leading to performance issues. By applying Neural Tangent Kernel (NTK) theory, this new method uses a nonlinear interpolation scheme that changes the RoPE's base rather than its scale, allowing for accurate distinction of token positions. This approach enables the LLaMA 7B model to handle longer contexts (up to 12k tokens) with minimal perplexity degradation, without fine-tuning. Initial tests show promising results, suggesting that further fine-tuning could enhance performance even more. The method provides a new way to extend the context window size efficiently, potentially benefiting tasks like long document summarization. The author encourages further experimentation and innovation in this area.\",\n",
    "        'seed_ids': ['roformer']\n",
    "    },\n",
    "    'feedbackmem': {\n",
    "        'title': 'Addressing Some Limitations of Transformers with Feedback Memory',\n",
    "        'authors': ['Angela Fan', 'Thibaut Lavril', 'Edouard Grave', 'Armand Joulin', 'Sainbayar Sukhbaatar'],\n",
    "        'venue': 'arXiv',\n",
    "        'year': 2020,\n",
    "        'abstract': \"Transformers have been successfully applied to sequential, auto-regressive tasks despite being feedforward networks. Unlike recurrent neural networks, Transformers use attention to capture temporal relations while processing input tokens in parallel. While this parallelization makes them computationally efficient, it restricts the model from fully exploiting the sequential nature of the input. The representation at a given layer can only access representations from lower layers, rather than the higher level representations already available. In this work, we propose the Feedback Transformer architecture that exposes all previous representations to all future representations, meaning the lowest representation of the current timestep is formed from the highest-level abstract representation of the past. We demonstrate on a variety of benchmarks in language modeling, machine translation, and reinforcement learning that the increased representation capacity can create small, shallow models with much stronger performance than comparable Transformers.\",\n",
    "        'tldr': 'Transformers have shortcomings - limited memory and limited state update - but Feedback Memory is a straightforward way to resolve these. ',\n",
    "        'seed_ids': ['transformer','bert']\n",
    "    },\n",
    "    'kangpt': {\n",
    "        'title': 'Generative Pre-trained Transformers (GPTs) using Kolmogorov-Arnold Networks (KANs) for language modeling',\n",
    "        'authors': ['Aditya N Ganesh'],\n",
    "        'year': 2024,\n",
    "        'url': 'https://adityang.github.io/kan-gpt/',\n",
    "        'description': \"Kolmogorov-Arnold Networks (KANs) are promising alternatives of Multi-Layer Perceptrons (MLPs). KANs have strong mathematical foundations just like MLPs: MLPs are based on the universal approximation theorem, while KANs are based on Kolmogorov-Arnold representation theorem. KANs and MLPs are dual: KANs have activation functions on edges, while MLPs have activation functions on nodes. This simple change makes KANs better (sometimes much better!) than MLPs in terms of both model accuracy and interpretability. \",\n",
    "        'seed_ids': ['gpt3','transformer']\n",
    "    },\n",
    "    's4pp': {\n",
    "        'title': 'S4++: Elevating Long Sequence Modeling with State Memory Reply',\n",
    "        'authors': ['Biqing Qi', 'Junqi Gao', 'Dong Li', 'Kaiyan Zhang', 'Jianxing Liu', 'Ligang Wu', 'Bowen Zhou'],\n",
    "        'venue': 'ICLR 2024 Withdrawn Submission',\n",
    "        'year': 2024,\n",
    "        'url': 'https://openreview.net/forum?id=bdnw4qjfH9',\n",
    "        'abstract': \"Recently, state space models (SSMs) have shown significant performance advantages in modeling long sequences. However, in spite of their promising performance, there still exist limitations. 1. Non-Stable-States (NSS): Significant state variance discrepancies arise among discrete sampling steps, occasionally resulting in divergence. 2. Dependency Bias: The unidirectional state space dependency in SSM impedes the effective modeling of intricate dependencies. In this paper, we conduct theoretical analysis of SSM from the even-triggered control (ETC) theory perspective and first propose the presence of NSS Phenomenon. Our findings indicate that NSS primarily results from the sampling steps, and the integration of multi-state inputs into the current state significantly contributes to the mitigation of NSS. Building upon these theoretical analyses and findings, we propose a simple, yet effective, theoretically grounded State Memory Reply (SMR) mechanism that leverages learnable memories to incorporate multi-state information into the current state. This enables the precise modeling of finer state dependencies within the SSM, resulting in the introduction of S4+. Furthermore, we integrate the complex dependency bias into S4+ via interactive cross attentions mechanism, resulting in the development of S4++. Our extensive experiments in autoregressive language modeling and benchmarking against the Long Range Arena demonstrate superior performance in most post-processing tasks.\",\n",
    "        'seed_ids': ['s4']\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for acronym in refs:\n",
    "    if refs[acronym]==[]:\n",
    "        obj=manual_input[acronym]\n",
    "        obj['acronym']=acronym\n",
    "        proj=LibraryReference.from_dict(obj)\n",
    "        proj.save('./tree')\n",
    "        continue   \n",
    "    refdata=refs[acronym]['data']\n",
    "    seed_ids=[]\n",
    "    for ref in refdata:\n",
    "        if 'methodology' in ref['intents']:\n",
    "            if ref['citedPaper']['paperId'] in index['id'].values:\n",
    "                ref_acronym=index.loc[index['id']==ref['citedPaper']['paperId'],'acronym'].values[0]\n",
    "                seed_ids.append(ref_acronym)\n",
    "    title=meta[acronym]['title']\n",
    "    s2id=meta[acronym]['id']\n",
    "    abstract=meta[acronym]['detail']['abstract']\n",
    "    authors=[author['name'] for author in meta[acronym]['detail']['authors']]\n",
    "    if abstract is None:\n",
    "        abstract='N/A'\n",
    "    venue=meta[acronym]['detail']['venue']\n",
    "    if venue is None:\n",
    "        venue='arXiv'\n",
    "    year=meta[acronym]['detail']['year']\n",
    "    if year is None:\n",
    "        year='N/A'\n",
    "    tldr=meta[acronym]['detail']['tldr']\n",
    "    if tldr is None:\n",
    "        tldr='N/A'\n",
    "    else:\n",
    "        tldr=tldr['text']\n",
    "        if tldr is None: tldr='N/A'\n",
    "    embedding=meta[acronym]['detail']['embedding']\n",
    "    if embedding is None:\n",
    "        embedding=[]\n",
    "    else:\n",
    "        embedding=embedding['vector']\n",
    "    citationCount=meta[acronym]['detail']['citationCount']\n",
    "    influentialCitationCount=meta[acronym]['detail']['influentialCitationCount']\n",
    "    paper=LibraryReference(title=title,acronym=acronym,seed_ids=seed_ids,s2id=s2id,abstract=abstract,authors=authors,venue=venue,year=year,tldr=tldr,citationCount=citationCount,influentialCitationCount=influentialCitationCount)\n",
    "    paper.save('./tree')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build 1 hoc impactful cites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 300\n"
     ]
    }
   ],
   "source": [
    "index=pd.read_csv('./library_index.csv')\n",
    "with open('./library_meta.json','r') as f:\n",
    "    meta=json.load(f)\n",
    "print(len(index),len(meta))\n",
    "dir_1hoc='./expanded_tree'\n",
    "get_cite='https://api.semanticscholar.org/graph/v1/paper/{paper_id}/citations?fields=intents,contextsWithIntent,isInfluential,title&offset={offset}&limit=1000'\n",
    "paper_detail='https://api.semanticscholar.org/graph/v1/paper/{paper_id}?fields=year,authors,tldr,venue,abstract,citationCount,influentialCitationCount,references,embedding.specter_v2,openAccessPdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 5802.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cite_1hoc_dir=dir_1hoc+'/cite_1hoc.json'\n",
    "detail_1hoc_dir=dir_1hoc+'/detail_1hoc.json'\n",
    "os.makedirs(dir_1hoc,exist_ok=True)\n",
    "\n",
    "cite_1hoc={}\n",
    "if os.path.exists(cite_1hoc_dir):\n",
    "    with open(cite_1hoc_dir,'r') as f:\n",
    "        cite_1hoc=json.load(f)\n",
    "\n",
    "for acronym in tqdm(index['acronym']):\n",
    "    id=index.loc[index['acronym']==acronym,'id'].values[0]\n",
    "    if pd.isna(id):\n",
    "        cite_1hoc[acronym]=[]\n",
    "        continue\n",
    "    citecount=meta[acronym]['detail']['citationCount']\n",
    "    if acronym in cite_1hoc:\n",
    "        if 'message' not in cite_1hoc[acronym]:\n",
    "            # print('Already done:',acronym,len(cite_1hoc[acronym]),citecount)\n",
    "            continue\n",
    "    cite_1hoc[acronym]=[]\n",
    "    maxoffset=min(citecount,9001)\n",
    "    for offset in range(0,maxoffset,1000):\n",
    "        if offset+1000>=10000:\n",
    "            offset=8999\n",
    "        print(acronym,offset,offset+1000)\n",
    "        cites=requests.get(get_cite.format(paper_id=id,offset=offset),headers=headers).json()\n",
    "        if 'message' in cites:\n",
    "            print('Error:',id,cites['message'])\n",
    "            continue\n",
    "        if 'data' not in cites:\n",
    "            print('Error:',cites)\n",
    "            raise\n",
    "        for c in cites['data']:\n",
    "            paperid=c['citingPaper']['paperId']\n",
    "            if paperid in cite_1hoc[acronym]:\n",
    "                continue\n",
    "            if 'methodology' in c['intents'] and c['isInfluential']:\n",
    "                cite_1hoc[acronym].append(paperid)\n",
    "        time.sleep(0.1)\n",
    "    print('Done',acronym,len(cite_1hoc[acronym]),citecount)\n",
    "    with open(cite_1hoc_dir,'w') as f:\n",
    "        json.dump(cite_1hoc,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 54594676 (char 54594675)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(detail_1hoc_dir):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(detail_1hoc_dir,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m         detail_1hoc\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx,acronym \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(cite_1hoc)):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProgress:\u001b[39m\u001b[38;5;124m'\u001b[39m,idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mlen\u001b[39m(cite_1hoc),acronym) \n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(fp\u001b[38;5;241m.\u001b[39mread(),\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 54594676 (char 54594675)"
     ]
    }
   ],
   "source": [
    "detail_1hoc={}\n",
    "if os.path.exists(detail_1hoc_dir):\n",
    "    with open(detail_1hoc_dir,'r') as f:\n",
    "        detail_1hoc=json.load(f)\n",
    "\n",
    "for idx,acronym in enumerate(tqdm(cite_1hoc)):\n",
    "    print('Progress:',idx+1,'/',len(cite_1hoc),acronym) \n",
    "    for c in cite_1hoc[acronym]:\n",
    "        if c in detail_1hoc:\n",
    "            if 'message' not in detail_1hoc[c]:\n",
    "                continue\n",
    "        detail=requests.get(paper_detail.format(paper_id=c),headers=headers).json()\n",
    "        if 'message' in detail:\n",
    "            print('Error:',c,detail['message'])\n",
    "            continue\n",
    "        detail_1hoc[c]=detail\n",
    "        time.sleep(0.1)\n",
    "    print('Done',acronym,len(detail_1hoc))\n",
    "    with open(detail_1hoc_dir,'w') as f:\n",
    "        json.dump(detail_1hoc,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
