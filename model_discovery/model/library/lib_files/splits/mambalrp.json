{
    "mambalrp-0": "# MambaLRP: Explaining Selective State Space Sequence Models \n\nFarnoush Rezaei Jafari ${ }^{1,2}$ Gr\u00e9goire Montavon ${ }^{3,2,1}$ Klaus-Robert M\u00fcller ${ }^{1,2,4,5,6} \\quad$ Oliver Eberle $^{1,2}$<br>${ }^{1}$ Machine Learning Group, Technische Universit\u00e4t Berlin, 10587 Berlin, Germany<br>${ }^{2}$ BIFOLD - Berlin Institute for the Foundations of Learning and Data, 10587 Berlin, Germany<br>${ }^{3}$ Department of Mathematics and Computer Science, Freie Universit\u00e4t Berlin,<br>Arnimallee 14, 14195 Berlin, Germany<br>${ }^{4}$ Department of Artificial Intelligence, Korea University, Seoul 136-713, South Korea<br>${ }^{5}$ Max Planck Institute for Informatics, Stuhlsatzenhausweg 4, 66123 Saarbr\u00fccken, Germany<br>${ }^{6}$ Google DeepMind, Berlin, Germany<br>Correspondence to: rezaeijafari@campus.tu-berlin.de, oliver.eberle@tu-berlin.de\n\n\n#### Abstract\n\nRecent sequence modeling approaches using Selective State Space Sequence Models, referred to as Mamba models, have seen a surge of interest.",
    "mambalrp-1": "These models allow efficient processing of long sequences in linear time and are rapidly being adopted in a wide range of applications such as language modeling, demonstrating promising performance. To foster their reliable use in real-world scenarios, it is crucial to augment their transparency. Our work bridges this critical gap by bringing explainability, particularly Layer-wise Relevance Propagation (LRP), to the Mamba architecture. Guided by the axiom of relevance conservation, we identify specific components in the Mamba architecture, which cause unfaithful explanations. To remedy this issue, we propose MambaLRP, a novel algorithm within the LRP framework, which ensures a more stable and reliable relevance propagation through these components. Our proposed method is theoretically sound and excels in achieving state-of-the-art explanation performance across a diverse range of models and datasets. Moreover, MambaLRP facilitates a deeper inspection of Mamba architectures, uncovering various biases and evaluating their significance. It also enables the analysis of previous speculations regarding the long-range capabilities of Mamba models. Keywords: Explainable AI, State Space Models, Mamba, Long-Range Dependencies\n\n## 1 Introduction\n\nSequence modeling has demonstrated its effectiveness and versatility across a wide variety of tasks and data types, including text, time series, genomics, audio, and computer vision [21, 72, 28, 8, 23]. Recently, there has been a surge of interest in a new class of sequence modeling architectures, known as structured state space sequence models (SSMs) [31, 56, 29]. This is due to their ability to process sequences in linear time, as opposed to quadratic time required by the more established Transformer architectures [59]. The recent Mamba architecture, a prominent and widely adopted instance of state space models, has demonstrated competitive predictive performance on a variety of sequence modeling tasks across domains and applications [29, 39, 73, 68, 60], while scaling linearly with sequence length. As Mamba models, and more generally SSMs, are rapidly being adopted into real-world applications, ensuring their transparency is crucial. This enables inspection beyond test set accuracy and uncovering various forms of biases, including 'Clever-Hans' effects [35]. It is particularly important in high-risk domains such as medicine, where the prediction behavior must be robust under real-world conditions and aligned with human understanding. The field of Explainable AI [42, 32, 7, 49] focuses on developing faithful model explanations that attribute predictions to relevant features and has shown success in explaining many highly nonlinear models such as convolutional networks [18], or attention-based Transformer models [3, 2]. Explaining the predictions of Mamba models is however challenging due to their highly non-linear and recurrent structure. A recent study [4] suggests viewing these models as attention-based models, enabling the use of attentionbased explanation methods [1, 17]. Yet, the explanations produced by attention-based techniques are often unreliable and exposed to potential misalignment between input features and attention scores 65, 34]. As an alternative,\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_5ac10fa1852cdd44a7d1g-02.jpg?height=436&width=1610&top_left_y=246&top_left_x=261)\n\nFigure 1: Conceptual steps involved in the design of MambaLRP. (a) Take as a starting point a basic LRP procedure, equivalent to Gradient $\\times$ Input. (b) Analyze layers in which the conservation property is violated. (c) Rework the relevance propagation strategy at those layers to achieve conservation. The resulting MambaLRP method enables efficient and faithful explanations. Layer-wise Relevance Propagation (LRP) [9] decomposes the model function with the goal of explicitly identifying the relevance of input features by applying purposely designed propagation rules at each layer. A distinguishing feature of LRP is its adherence to a conservation axiom, which prevents the artificial amplification or suppression of feature relevance in the backward pass. LRP has been demonstrated to produce faithful explanations across various domains (e.g. [6, 3, 18]). Nevertheless, the peculiarities of the Mamba architecture are not addressed by the existing LRP procedures, which may lead to the violation of the conservation property and result in unreliable explanations. In this work, we present MambaLRP, a novel approach to integrate LRP into the Mamba architecture. By examining the relevance propagation process across Mamba layers through the lens of conservation, we pinpoint layers within the Mamba architecture that need to be addressed specifically. We propose a novel relevance propagation strategy for these layers, grounded in the conservation axiom, that is theoretically sound, straightforward to implement and computationally efficient. Through a number of quantitative evaluations, we show that the proposed MambaLRP approach allows to robustly deliver the desired high explanatory performance, exceeding by far the performance of various baseline explanation methods as well as a naive transposition of LRP to the Mamba architecture. We further demonstrate the usefulness of MambaLRP in several areas: gaining concrete insights into the model's prediction mechanism, uncovering undesired decision strategies in image classification, identifying gender bias in language models, and analyzing the long-range capabilities of Mamba. Our code is publicly available 1\n\n## 2 Related Work\n\nStructured State Space Sequence Models (SSMs). Transformers [59] have emerged as the most widely used architectures for sequence modeling. However, their computational limitations, particularly with large sequence lengths, have restricted their applicability in modeling long sequences. Addressing these computational limitations, recent works [30, 31] have introduced structured state space sequence models (SSMs) as an alternative approach. SSMs are a class of sequence modeling methods, leveraging the strengths of recurrent, convolutional, and continuoustime methods, demonstrating promising performance across various domains, including language [26, 40], image [67]. 12, 44], and video [61] processing, and beyond [50, 19, 38]. A recent advancement by Gu and Dao [29] introduced selective SSM, an enhanced data-dependent SSM with a selection mechanism that adjusts its parameters based on the input. Built on this dynamic selection, the Mamba architecture fuses the SSM components with multilayer perceptron (MLP) blocks. This fusion simplifies the architecture while improving its ability to handle various sequence modeling tasks, including applications in language processing [5, 45, 62], computer vision [37, 73, 68], medical imaging [39, 66, 27, 47, 36, 64, 63] and graphs [60, 13]. This fast adoption of SSMs and Mamba models underscores the need for reliable explanations of their predictions. Explainable AI and SSMs. In efforts to explain Mamba models, Ali et al. [4] recently proposed viewing their internal computations as an attention mechanism. This approach builds upon previous works that use attention signal as explanation, including Attention Rollout [1] and variants thereof [17, 16]. While these approaches can provide some insight, they inherit the limitations of using attention as an explanation [65, 34], including their inability to capture potential misalignment between tokens and attention scores, and the limited performance in empirical faithfulness evaluations. Alternative Explainable AI methods, not yet applied to Mamba models but in principle\n\n[^0]applicable to any model, include techniques using input perturbations [71, 74, 25] or leveraging gradient information [10, 54,58,55,53]. Despite their generality, these models have certain drawbacks, such as requiring multiple function evaluations for a single explanation or being susceptible to gradient noise, resulting in subpar performance, as our benchmark experiment will demonstrate. To tackle these challenges, we introduce MambaLRP as an efficient solution for the computation of reliable and faithful explanations that are theoretically grounded in the axiom of relevance conservation. ## 3 Background\n\nBefore delving into the details of our proposed method, we begin with a brief overview of the selective SSM architecture, followed by an introduction to the LRP framework. Selective SSMs (S6) An important component within the Mamba [29] architecture is the selective SSM. It is characterized by parameters, $\\bar{A}, \\bar{B}$, and $C$, and transforms a given input sequence $\\left(x_{t}\\right)_{t=1}^{T}$ into an output sequence of the same size $\\left(y_{t}\\right)_{t=1}^{T}$ via the following equations:\n\n$$\n\\begin{aligned}\nh_{t} & =\\bar{A}_{t} h_{t-1}+\\bar{B}_{t} x_{t} \\\\\ny_{t} & =C_{t} h_{t}\n\\end{aligned}\n$$\n\nwhere the initial state $h_{0}=0$. What distinguishes the selective SSM from the original SSM (S4) [31] is that the evolution parameter, $\\bar{A}_{t}$, and projection parameters, $\\bar{B}_{t}$ and $C_{t}$, are functions of the input $x_{t}$.",
    "mambalrp-2": "This enables dynamic adaptation of the SSM's parameters based on input. This dynamicity facilitates focusing on relevant information while ignoring irrelevant details when processing a sequence. Layer-wise Relevance Propagation Layer-wise Relevance Propagation (LRP) [9] is an Explainable AI method that attributes the model's output to the input features through a single backward pass. This backward pass is specifically designed to identify neurons relevant to the prediction. LRP assigns relevance scores to neurons in a given layer and then propagates these scores to neurons in the preceding layer. The process continues layer by layer, starting from the network's output and terminating once the input features are reached. The LRP backward pass relies on an axiom called 'conservation' requiring that relevance scores are preserved across layers, avoiding to artificially amplify or suppress contributions. For example, let $x$ and $y$ be the input and output of some layer, respectively, and let $\\mathcal{R}(x)$ and $\\mathcal{R}(y)$ represent the sum of relevance scores in the respective layers. The conservation axiom requires that $\\mathcal{R}(x)=\\mathcal{R}(y)$ holds true. ## 4 LRP for Mamba\n\nIn this work, we bring explainability, particularly LRP, to Mamba models, following the conceptual design steps, shown in Fig. 1. We start by applying a basic LRP procedure, specifically one corresponding to Gradient $\\times$ Input (GI), to the Mamba architecture. This serves as an effective initial step for identifying layers where certain desirable explanation properties, like relevance conservation, are violated. We analyze different layers of the Mamba architecture, derive relevance propagation equations and test the fulfillment of the conservation property. Our analysis reveals three components in the Mamba architecture where conservation breaks: the SiLU activation function, the selective SSM, and the multiplicative gating of the SSM's output. Leveraging the analysis above, we propose novel relevance propagation strategies for these three components, which lead to a robust, faithful and computationally efficient explanation approach, called MambaLRP. ### 4.1 Relevance propagation in SiLU layers\n\nWe start by examining the relevance propagation through Mamba's SiLU activation functions. This function is represented by the equation $y=x \\cdot \\sigma(x)$, where $\\sigma$ denotes the logistic sigmoid function. Proposition 4.1 Applying the standard gradient propagation equations yields the following result, which relates the relevance values before and after the activation layer:\n\n$$\n\\underbrace{\\frac{\\partial f}{\\partial x} x}_{\\mathcal{R}(x)}=\\underbrace{\\frac{\\partial f}{\\partial y} y}_{\\mathcal{R}(y)}+\\underbrace{\\frac{\\partial f}{\\partial y} \\cdot \\sigma^{\\prime}(x) \\cdot x^{2}}_{\\varepsilon}\n$$\n\nThe derivation for Eq. 3 can be found in Appendix A.1.",
    "mambalrp-3": "We observe that the conservation property, i.e. $\\mathcal{R}(x)=\\mathcal{R}(y)$, is violated whenever the residual term $\\varepsilon$ is non-zero. We propose to restore the conservation property in the relevance propagation pass by locally expanding the SiLU activation function as:\n\n$$\ny=x \\cdot[\\sigma(x)]_{\\mathrm{cst}}\n$$\n\nwhere $[\\cdot]_{\\text {cst.",
    "mambalrp-4": "}}$ treats the given quantity as constant.",
    "mambalrp-5": "This can be implemented e.g. in PyTorch using the . detach() function. Repeating the derivation above with this modification yields the desired conservation property, $\\mathcal{R}(x)=\\mathcal{R}(y)$. The explicit LRP rule associated to this LRP procedure is provided in Appendix B. ### 4.2 Relevance propagation in selective SSMs (S6)\n\nThe most crucial non-linear component of the Mamba architecture is its selective SSM component. It is designed to selectively retain or discard information throughout the sequence by adjusting its parameters based on the input, enabling dynamic adaptation to each token. To facilitate the analysis, we introduce an inconsequential modification to the original SSM by connecting $C_{t}$ to $h_{t}$ instead of $x_{t}$. To do so, we can redefine $\\bar{A}_{t}, \\bar{B}_{t}$, and $C_{t}$ matrices as blockdiag $\\left(\\bar{A}_{t}, 0\\right),\\left(\\bar{B}_{t}, I\\right)$, and $\\left(C_{t} \\mid 0\\right)$ respectively, such that $x_{t}$ becomes part of the state $h_{t}$ without altering the overall functionality of the SSM. The unfolded SSM, with the aforementioned modification, is illustrated in Fig. 2. The complex relevance propagation procedure in the SSM component can be\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_5ac10fa1852cdd44a7d1g-04.jpg?height=408&width=633&top_left_y=734&top_left_x=1147)\n\nFigure 2: Unfolded view of SSM, highlighting two subsets of nodes, the relevance of which should be conserved throughout relevance propagation. further simplified by considering two groups of units, illustrated in red and orange in Fig. 2. In these two groups, there are no connections within units of the same group, all the relevance propagation signals from the first group are directed towards the second group, and the second group receives no further incoming relevance propagation signal. With these properties, these two groups should, according to the principle of conservation, receive the same relevance scores. Proposition 4.2 Defining $\\theta_{t}=\\left(\\bar{A}_{t}, \\bar{B}_{t}, C_{t-1}\\right)$, and working out the propagation equations between these two groups yields the following relation:\n\n$$\n\\underbrace{\\frac{\\partial f}{\\partial x_{t}} x_{t}+\\frac{\\partial f}{\\partial h_{t-1}} h_{t-1}}_{\\mathcal{R}\\left(x_{t}\\right)+\\mathcal{R}\\left(h_{t-1}\\right)}=\\underbrace{\\frac{\\partial f}{\\partial h_{t}} h_{t}+\\frac{\\partial f}{\\partial y_{t-1}} y_{t-1}}_{\\mathcal{R}\\left(h_{t}\\right)+\\mathcal{R}\\left(y_{t-1}\\right)}+\\underbrace{\\frac{\\partial f}{\\partial \\theta_{t}} \\frac{\\partial \\theta_{t}}{\\partial x_{t}} x_{t}+\\frac{\\partial f}{\\partial \\theta_{t}} \\frac{\\partial \\theta_{t}}{\\partial h_{t-1}} h_{t-1}}_{\\varepsilon}\n$$\n\nThe derivation for Eq.",
    "mambalrp-6": "5] can be found in Appendix A. 2 . We note that the residual term $\\epsilon$, which is typically non-zero, violates conservation. Specifically, conservation fails due to the dependence of $\\theta$ on the input. We propose to rewrite the state-space model at each step in a way that the parameters $\\theta_{t}$ appear constant, i.e.:\n\n$$\n\\begin{aligned}\nh_{t} & =\\left[\\bar{A}_{t}\\right]_{\\text {cst. }} h_{t-1}+\\left[\\bar{B}_{t}\\right]_{\\text {cst. }} x_{t} \\\\\ny_{t} & =\\left[C_{t}\\right]_{\\mathrm{cst} .} h_{t}\n\\end{aligned}\n$$\n\nThese equations can also be interpreted as viewing the selective SSM as a localized non-selective, i.e. standard, SSM. With this modification, conservation holds between the two groups, i.e. $\\mathcal{R}\\left(x_{t}\\right)+\\mathcal{R}\\left(h_{t-1}\\right)=\\mathcal{R}\\left(h_{t}\\right)+\\mathcal{R}\\left(y_{t-1}\\right)$. By repeating the argument for each time step, conservation is also maintained between the input and output of the whole SSM component. Explicit LRP rules are provided in Appendix B\n\n### 4.3 Relevance propagation in multiplicative gates\n\nIn each block within the Mamba architecture, the SSM's output is multiplied by an input-dependent gate. In other words, $y=z_{A} \\cdot z_{B}$, where $z_{A}=\\operatorname{SSM}(x)$ and $z_{B}=\\operatorname{SiLU}(\\operatorname{Linear}(x))$. Assume that the locally linear expansions introduced in Sections 4.1 and 4.2 are applied to the SSM components and SiLU activation functions, the mapping from $x$ to $y$ becomes quadratic. Proposition 4.3 Applying the standard gradient propagation equations establishes the following relation between the relevance values before and after the gating operation:\n\n$$\n\\underbrace{\\frac{\\partial f}{\\partial x} x}_{\\mathcal{R}(x)}=\\underbrace{\\frac{\\partial f}{\\partial y} y}_{\\mathcal{R}(y)}+\\underbrace{\\frac{\\partial f}{\\partial y} y}_{\\varepsilon}\n$$\n\nThe derivation for Eq. 8 and explicit LRP rules can be found in Appendix A.3 and Appendix B, respectively. In this equation, we observe a spurious doubling of relevance in the backward pass. This can be addressed by treating half of the output as constant:\n\n$$\ny=0.5 \\cdot\\left(z_{A} \\cdot z_{B}\\right)+0.5 \\cdot\\left[z_{A} \\cdot z_{B}\\right]_{\\mathrm{cst}}\n$$\n\nAs for the previous examples, this ensures the conservation property $\\mathcal{R}(x)=\\mathcal{R}(y)$. An alternative would have been to make $y$ linear by detaching only one of the terms in the product, as done for the SiLU activation or the SSM component.",
    "mambalrp-7": "However, the strategy of Eq. (9) better maintains the directionality given by the gradient. We further compare these alternatives in an ablation study presented in Appendix C.5. demonstrating empirically that our proposed approach performs better. ### 4.4 Additional modifications and summary\n\nThe propagation strategies developed for the Mamba-specific components complement previously proposed approaches for other layers, including propagation through RMSNorm layers [3] and convolution layers via robust LRP- $\\gamma$ rules [43, 22] and their generalized variants. A summary of these additional enhancements is provided in Appendix C. 2\nOverall, our MambaLRP procedure can be implemented as a sequence of two steps:\n\n1. Perform the detach operations of Eqs. (4), (6), (7), and (9) (as well as similar operations for RMSNorm and convolutions). 2. Retrieve MambaLRP explanations by performing Gradient $\\times$ Input on the detached model. ## 5 Experiments\n\nTo evaluate our proposed approach, we benchmark its effectiveness against various methods previously proposed in the literature for interpreting neural networks. We empirically evaluate our proposed methodology using Mamba-130M and Mamba-1.4B language models [29], which are trained on diverse text datasets. For the vision experiments, we use the Vim-S model [73]. Moreover, we perform several ablation studies to further investigate our proposed method. Datasets In this study, we perform experiments on four text classification datasets, namely SST-2 [57], Medical BIOS [24], Emotion [51], and SNLI [15]. The SST-2 dataset encompasses around 70K English movie reviews, categorized into binary classes, representing positive and negative sentiments. The Medical BIOS dataset consists of short biographies ( 10 K ) with five specific medical occupations as targets. The SNLI corpus (version 1.0) comprises 570k English sentence pairs, with the labels entailment, contradiction, and neutral, used for the natural language inference (NLI) task. The Emotion dataset (20K) is a collection of English tweets, each labeled with one of six basic emotions. For the vision experiments, we use ImageNet dataset [20] with 1.3M images and 1 K classes. Baseline methods We compare our proposed method with several gradient-based, model-agnostic explanation techniques: Gradient $\\times$ Input (GI) [10, 54], SmoothGrad [55], and Integrated Gradients [58]. Furthermore, we evaluate the performance of our proposed method against a naive implementation of LRP, i.e. LRP (LN-rule), where the LRP-0 rule is used in all linear and convolution layers, along with the LN-rule [3] in normalization layers. We also compare the performance of our proposed method with two attention-based explanation techniques, which are Attention Rollout (AttnRoll, [1]) and Gradient $\\times$ Attention Rollout ( $\\mathrm{G} \\times$ AttnRoll, [17]). These approaches were initially developed to explain transformer models and have recently been extended to interpret Mamba models [4]. ### 5.1 Conservation property\n\nTo verify the fulfillment of the conservation property, on which our method is based, we compare the network's output score with the sum of relevance scores attributed to the input features, for both the GI baseline and the proposed\n\nMambaLRP. The analysis is performed for Mamba-130M models trained on the SST-2 and ImageNet datasets. Full conservation is achieved if the output score equals the sum of relevance, as indicated by the blue line in Fig. 3 . Our results show that conservation is severely violated by the GI baseline, and is addressed to a large extent by MambaLRP. Residual lack of conservation is due to the presence of biases in linear and convolution layers, which are typically non-attributable. ![](https://cdn.mathpix.com/cropped/2024_09_12_5ac10fa1852cdd44a7d1g-06.jpg?height=307&width=1303&top_left_y=465&top_left_x=403)\n\nFigure 3: Conservation property. The $x$-axis represents the sum of explanation scores across the input features and the y-axis shows the network's output score. Each point corresponds to one example and its proximity to the blue identity line indicates the extent to which conservation is preserved, with closer alignment suggesting improved conservation. ### 5.2 Qualitative evaluation\n\nIn this section, we qualitatively examine the explanations produced by various explanation methods for Mamba-130M and Vim-S models. Fig. 4 illustrates the explanations generated to interpret the Mamba-130M model's prediction on a sentence from the SST-2 dataset with negative sentiment. We note that all of the explanation methods attribute positive scores to the word 'disgusting', which appears reasonable given the negative sentiment label. However, it is notable that the explanation generated by MambaLRP is more sparse and focuses particularly on the terms 'so' and 'disgusting'. In contrast, the explanations produced by the gradient-based methods and AttnRoll appear to be quite noisy. Furthermore, we show the explanations produced to interpret the Vim-S model's predictions on images of\n\n| MambaLRP | at least one scene is so disgusting that viewers may be hard pressed to retain their lunch : |\n| :---: | :--- | :--- |\n| GI | at least one scene is so disgusting that viewers may be hard pressed to retain their lunch . |\n| SmoothGrad | at least one scene is so disgusting that viewers may be hard pressed to retain their lunch . |\n| IG | at least one scene is so disgusting that viewers may be hard pressed to retain their lunch : |\n| AttnRoll | at least one scene is so disgusting that viewers may be hard pressed to retain their lunch ! |\n| G x AttnRoll | at least one scene is so disgusting that viewers may be hard pressed to retain their lunch |\n\nFigure 4: Explanations generated for a sentence of the SST-2 dataset.",
    "mambalrp-8": "Shades of red represent words that positively influence the model's prediction. Conversely, shades of blue reflect negative contributions. The heatmaps of attentionbased methods are constrained to non-negative values. the ImageNet dataset in Fig. 5. Purely gradient-based explanations tend to identify unspecific noisy features, while both attention-based approaches, AttnRoll and $\\mathrm{G} \\times$ AttnRoll, are more effective at highlighting significant features. Among these methods, MambaLRP stands out for its ability to generate explanations that are particularly focused on key features used by the model to make a prediction. Take, for instance, the first image classified under the 'African elephant' category. We can see that the explanation generated by MambaLRP not only includes all occurrences of the 'African elephant' object but also highlights its distinctive features, such as the tusks. In the second image labeled 'wild boar', despite the presence of multiple objects in the image, MambaLRP's explanation remains focused on the 'wild boar' object, disregarding other objects. Moreover, in the third instance, MambaLRP uncovers a spurious correlation, the presence of a watermark in Chinese, influencing the model's prediction, a subtlety overlooked or not fully represented by other methods. ### 5.3 Quantitative evaluation\n\nTo quantitatively evaluate the faithfulness of explanation methods, we employ an input perturbation approach based on ranking input features by their importance [48], which can be done using either a Most Relevant First (MoRF) or Least Relevant First (LeRF) strategy. Ranked features are iteratively perturbed through a process known as flipping. ![](https://cdn.mathpix.com/cropped/2024_09_12_5ac10fa1852cdd44a7d1g-07.jpg?height=689&width=1332&top_left_y=252&top_left_x=402)\n\nFigure 5: Explanations produced by different explanation methods for images of the ImageNet dataset. Explanations produced by AttnRoll and $\\mathrm{G} \\times$ AttnRoll are limited to non-negative values. We monitor the resulting changes in the output logits, $f_{c}$, for the predicted class $c$, and compute the area under the perturbation curve. The areas under the curves for LeRF and MoRF strategies are denoted by $A_{\\mathrm{LeRF}}^{F}$ and $A_{\\mathrm{MoRF}}^{F}$, respectively. In contrast, the insertion method starts with a fully perturbed input and progressively restores important features. The areas under the curves for this method are indicated by $A_{\\mathrm{MoRF}}^{I}$ and $A_{\\mathrm{LeRF}}^{I}$, for the MoRF and LeRF strategies, respectively. A reliable explanation method is characterized by low values of $A_{\\mathrm{MoRF}}^{F}$ or $A_{\\mathrm{LeRF}}^{I}$, and large values of $A_{\\mathrm{LeRF}}^{F}$ or $A_{\\mathrm{MoRF}}^{I}$. In an effort to minimize the introduction of out-of-distribution manipulations, the recent study by Bl\u00fccher et al. [14] advocates for harnessing both insights to derive a more resilient metric. Therefore, we follow the same strategy as [14, 2] to evaluate explanation methods. The evaluation metrics are defined as $\\Delta A^{F}=A_{\\mathrm{LeRF}}^{F}-A_{\\mathrm{MoRF}}^{F}$ and $\\Delta A^{I}=A_{\\mathrm{MoRF}}^{F}-A_{\\mathrm{LeRF}}^{F}$. In both metrics, a higher score is preferable, as it signifies a more accurate and reliable explanation method. The outcomes of this analysis are represented in Table 1. MambaLRP consistently achieves highest faithfulness scores in comparison to other baseline methods. We observe that GI struggles with noisy attributions, leading to low faithfulness scores. However, methods like Integrated Gradients and G $\\times$ AttnRoll have shown improvements in this regard. We note that LRP (LN-rule) outperforms most methods across the majority of the text classification tasks. Nevertheless, its performance is notably inferior compared to MambaLRP. Overall, we observe that MambaLRP significantly outperforms all other methods by a substantial margin. In both vision and NLP experiments, attentionbased methods have shown superior performance compared to the purely gradient-based approaches.",
    "mambalrp-9": "Results of the complementary insertion experiment are presented in Appendix C. 4 , which consistently confirm the observations from the flipping experiment. Table 1: Evaluating explanation methods. Higher scores $\\Delta A^{F}$ indicate more faithful explanations. | Methods | SST-2 |  | Med-BIOS |  | SNLI |  | Emotion |  | $\\frac{\\text { ImageNet }}{\\text { Vim-S }}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n|  | Mamba <br> 130M | Mamba <br> 1.4 B | Mamba <br> 130 M | Mamba <br> 1.4 B | Mamba <br> 130M | Mamba <br> 1.4 B | Mamba <br> 130 M | Mamba <br> 1.4 B |  |\n| Random | -0.012 | -0.106 | 0.044 | -0.014 | 0.010 | 0.002 | -0.001 | 0.000 | 0.000 |\n| GI [54] | 0.078 | -0.106 | 0.200 | -0.634 | -0.039 | -0.039 | -0.787 | -0.409 | 0.041 |\n| SmoothGrad 55] | 1.377 | -0.383 | 1.661 | -2.300 | 0.486 | -0.687 | 1.808 | -1.852 | 0.121 |\n| IG [58] | 0.857 | 0.216 | 1.296 | 1.065 | 0.453 | 0.218 | 1.808 | 2.010 | 0.328 |\n| AttnRoll [4] | 0.657 | 0.431 | \u4739 | 1.076 | $\\square$ | 0.371 | 0.389 | $\\square$ | 0.714 |\n| G $\\times$ AttnRoll [4] | 1.190 | 0.626 | 3.126 | 3.006 | 0.513 | 0.554 | 2.003 | 4.706 | 0.792 |\n| LRP (LN-rule, [3]) | 0.877 | 0.961 | 2.217 | 3.45 | 0.6 | 0.65 | 3.079 | 5.199 | 0.647 |\n| MambaLRP (ours) | 1.978 | 1.248 | 3.906 | 4.234 | 0.989 | 0.897 | 3.523 | 5.397 | 1.878 |\n\nRuntime comparison We report the runtimes of MambaLRP along with other methods used in this study in Appendix C. 8 As shown in Table 10, our method's runtime is comparable to GI and can be implemented via a single forward and backward pass. Since approaches like Integrated Gradients require multiple function evaluations, their runtimes are considerably higher than MambaLRP. Ablation study In Section 4 , we proposed techniques for handling different non-linear components within the Mamba architecture. This ablation study aims to assess the significance of each technique by testing the effect of their exclusion on faithfulness. Table 2 shows that all three modifications are essential for achieving competitive explanation performance, with our proposed method for handling the SSM component being the most critical. Further experiments, comparing different strategies for handling the Mamba block's multiplicative gate, are detailed in Appendix C. 5\n\nTable 2: Analyzing the impact of ablating the three proposed propagation rules on $\\Delta A^{F}$ for the components in MambaLRP.",
    "mambalrp-10": "| SiLU | SSM | Gate | SST-2 | ImageNet |\n| :---: | :---: | :---: | :---: | :---: |\n| $\\checkmark$ | $\\boldsymbol{x}$ | $\\checkmark$ | 0.577 | 0.453 |\n| $\\checkmark$ | $\\checkmark$ | $x$ | 1.721 | 1.372 |\n| $\\times$ | $\\checkmark$ | $\\checkmark$ | 1.943 | 1.794 |\n| $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\mathbf{1 . 9 7 8}$ | $\\mathbf{1 . 8 7 8}$ |\n\n## 6 Use cases\n\nUncovering gender bias in Mamba. Explanation methods serve as tools to uncover biases in pretrained vision and language models. Using our proposed method, we examine Mamba-130M and Mamba-1.4B models, trained on the Medical BIOS dataset, to investigate the potential presence of gender biases. Following the methodology in [24], we use MambaLRP to identify the top- 5 tokens of highest importance and to quantify the prevalence of gendered words within these tokens. We find that the model exhibits a pronounced preference for female-gendered words in the 'Nurse' class (e.g. the proportion of gender-specific words is 0.058 for females, compared to 0.0 for males in Mamba-130M.). We also compare the results of our analysis with those achieved for the GPT2-base, T5-base, and RoBERTa-base models as mentioned in [24]. As shown in Table 3, both Mamba models are less dependent on gendered tokens compared to GPT2-base, T5-base, and RoBERTa-base models, with the Mamba-1.4B model showing a further decrease in bias compared to the Mamba-130M, suggesting improvements in reducing gender bias with increased model size. Investigating long-range capabilities of Mamba. The ability of SSMs to model long-range dependencies is considered an important improvement over previous sequence models. In this use case, we analyze the extent to which the pretrained Mamba-130M model can use information from the entire context window. We use the HotpotQA [69] subset from the LongBench dataset [11], designed to test long context understanding. After selecting all 127 instances, containing sequences up to 8192 tokens, we prompt the model to summarize the full paragraph by generating ten additional tokens. Fig. 6 shows the distribution of the positional difference between a relevant token and the currently generated token. While we observe a pronounced pattern of attributing to the last few tokens, as seen in prior language generation studies [70, 52], the extracted explanations also identified relevant tokens across the entire context window, as presented for one example in Fig.",
    "mambalrp-11": "6 (right). This suggests that the model is indeed capable of retrieving long-range dependencies. We clearly see that in order to complete the sentence and assign a year to the album release date, the model analyzes previous occurrences of chronological information and MambaLRP identifies evidence supporting the decision for the date being ' 1972 ' as relevant. This demonstrates the previously speculated long-range abilities of the Mamba architecture [29]. Needle-in-a-haystack test. To assess the model's ability in retrieving relevant pieces of information from a broader context, we perform the needle-in-a-haystack test [41]. Our test involves extracting a single passkey (the 'needle') from a collection of repeated noise sentences (the 'haystack'), as described in [33]. We run this test at eleven different document depths with three different context lengths. We use an instruction-finetuned Mamba-2.8B model in this experiment. To analyze the performance of the model, we introduce the explanation-based retrieval accuracy (XRA) metric. In this approach, we first identify the positions of the top-K relevant tokens by MambaLRP, and then, calculate the accuracy by comparing those positions to the needle's position. As shown in Fig. 7. MambaLRP accurately\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_5ac10fa1852cdd44a7d1g-09.jpg?height=502&width=1627&top_left_y=253&top_left_x=257)\n\nFigure 6: Analysis of the position of tokens relevant for next token generation. Left: Distribution of absolute position of the ten most relevant tokens for the prediction of the next word. Right: Long-range dependency between tokens of the input and the predicted next token (here: 1972). ![](https://cdn.mathpix.com/cropped/2024_09_12_5ac10fa1852cdd44a7d1g-09.jpg?height=492&width=1543&top_left_y=936&top_left_x=277)\ncontext: 2048 tokens\n\n![](https://cdn.mathpix.com/cropped/2024_09_12_5ac10fa1852cdd44a7d1g-09.jpg?height=114&width=97&top_left_y=1122&top_left_x=1773)\n\nFigure 7: Explanation-based retrieval accuracy in the needle-in-a-haystack test verifying model reliance on relevant features for different context lengths. captures the information used by the model to retrieve the needle. In this case, the model could accurately retrieve the needle based on relevant information within the text. However, in more realistic and complex scenarios, the model may depend on irrelevant data yet still generate the correct token. This issue can be analyzed using XRA but cannot be evaluated by conventional retrieval accuracy metrics.",
    "mambalrp-12": "Such cases and also further details about this experiment are shown in Appendix C. 7 . ## 7 Discussion and conclusion\n\nMamba models have emerged as an efficient alternative to Transformers. However, there are limited works addressing their interpretability [4]. To address this issue, we proposed MambaLRP within the LRP framework, specifically tailored to the Mamba architecture and built upon the relevance conservation principle. Our evaluations across various models and datasets confirmed that MambaLRP adheres to the conservation property and provides faithful explanations that outperform other methods while being more computationally efficient. Moreover, we demonstrated how MambaLRP can help to debug state-of-the-art ML models and build trust in them through various use cases. Although our experiments focus on applying MambaLRP to vision and language models, its usefulness extends beyond these domains. Future research can explore its potential across a broader range of applications and Mamba architectures, providing reliable insights into sequence models. ## Acknowledgments\n\nThis work was funded by the German Ministry for Education and Research (refs. 01IS14013A-E, 01GQ1115, 01GQ0850, 01IS18025A, 031L0207D, 01IS18037A). K.R.M. was partly supported by the Institute of Information \\& Communications Technology Planning \\& Evaluation (IITP) grants funded by the Korea government (MSIT) (No. 2019-0-00079, Artificial Intelligence Graduate School Program, Korea University and No. 2022-0-00984, Development of Artificial Intelligence Technology for Personalized Plug-and-Play Explanation and Verification of Explanation). ## References\n\n[1] S. Abnar and W. Zuidema. Quantifying attention flow in transformers. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4190-4197, Online, July 2020. Association for Computational Linguistics. [2] R. Achtibat, S.",
    "mambalrp-13": "M. V. Hatefi, M. Dreyer, A. Jain, T. Wiegand, S. Lapuschkin, and W. Samek. AttnLRP: Attention-aware layer-wise relevance propagation for transformers.",
    "mambalrp-14": "arXiv:2402.05602, 2024. [3] A. Ali, T. Schnake, O. Eberle, G. Montavon, K.-R. M\u00fcller, and L. Wolf. XAI for transformers: Better explanations through conservative propagation. In International Conference on Machine Learning, ICML 2022, volume 162 of Proceedings of Machine Learning Research, pages 435-451. PMLR, 2022. [4] A. Ali, I. Zimerman, and L. Wolf. The hidden attention of mamba models. arXiv:2403.01590, 2024. [5] Q. Anthony, Y. Tokpanov, P. Glorioso, and B. Millidge. BlackMamba: Mixture of experts for state-space models.",
    "mambalrp-15": "arXiv:2402.01771, 2024. [6] L. Arras, J. Arjona-Medina, M. Widrich, G. Montavon, M. Gillhofer, K.-R. M\u00fcller, S. Hochreiter, and W. Samek. Explaining and interpreting LSTMs. Explainable AI: Interpreting, explaining and visualizing deep learning, pages 211-238, 2019.",
    "mambalrp-16": "[7] A. B. Arrieta, N. D. Rodr\u00edguez, J. D. Ser, A. Bennetot, S. Tabik, A. Barbado, S. Garc\u00eda, S. Gil-Lopez, D. Molina, R. Benjamins, R. Chatila, and F. Herrera. Explainable artificial intelligence (XAI): concepts, taxonomies, opportunities and challenges toward responsible AI.",
    "mambalrp-17": "Inf. Fusion, 58:82-115, 2020. [8] \u017d. Avsec, V. Agarwal, D. Visentin, J.",
    "mambalrp-18": "R. Ledsam, A. Grabska-Barwinska, K. R. Taylor, Y. Assael, J. Jumper, P. Kohli, and D.",
    "mambalrp-19": "R. Kelley. Effective gene expression prediction from sequence by integrating long-range interactions. Nature methods, 18 (10):1196-1203, 2021. [9] S. Bach, A. Binder, G. Montavon, F. Klauschen, K.-R. M\u00fcller, and W. Samek. On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation. PloS one, 10(7):e0130140, 2015. [10] D. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, and K.-R. M\u00fcller. How to explain individual classification decisions. The Journal of Machine Learning Research, 11:1803-1831, 2010. [11] Y. Bai, X. Lv, J. Zhang, H. Lyu, J. Tang, Z. Huang, Z. Du, X. Liu, A. Zeng, L. Hou, Y. Dong, J. Tang, and J. Li. LongBench: A bilingual, multitask benchmark for long context understanding.",
    "mambalrp-20": "arXiv:2308.14508, 2023. [12] E. Baron, I. Zimerman, and L. Wolf. 2-D SSM: A general spatial layer for visual transformers. arXiv:2306.06635, 2023. [13] A. Behrouz and F. Hashemi. Graph Mamba: Towards learning on graphs with state space models.",
    "mambalrp-21": "arXiv:2402.08678, 2024. [14] S. Bl\u00fccher, J. Vielhaben, and N. Strodthoff. Decoupling pixel flipping and occlusion strategy for consistent XAI benchmarks. arXiv:2401.06654, 2024.",
    "mambalrp-22": "[15] S. R. Bowman, G. Angeli, C. Potts, and C. D. Manning. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 632-642, Lisbon, Portugal, Sept. 2015. Association for Computational Linguistics. [16] H. Chefer, S. Gur, and L. Wolf. Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 397-406, 2021. [17] H. Chefer, S. Gur, and L. Wolf. Transformer interpretability beyond attention visualization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 782-791, 2021. [18] P. Chormai, J. Herrmann, K.-R. M\u00fcller, and G. Montavon. Disentangled explanations of neural network predictions by finding relevant subspaces. IEEE Trans. Pattern Anal. Mach. Intell., 2022. [19] S. B. David, I. Zimerman, E.",
    "mambalrp-23": "Nachmani, and L. Wolf. Decision S4: Efficient sequence-based rl via state spaces layers. In The Eleventh International Conference on Learning Representations, 2022. [20] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierarchical Image Database. In IEEE Computer Vision and Pattern Recognition (CVPR), pages 248-255, 2009. [21] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics, pages 4171-4186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. [22] A.-K. Dombrowski, C. J. Anders, K.-R. M\u00fcller, and P. Kessel. Towards robust explanations for deep neural networks. Pattern Recognition, 121:108194, 2022. ISSN 0031-3203. [23] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In International Conference on Learning Representations, 2021. [24] O. Eberle, I. Chalkidis, L. Cabello, and S. Brandl. Rather a nurse than a physician - contrastive explanations under investigation. In Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6907-6920. Association for Computational Linguistics, 2023. [25] R.",
    "mambalrp-24": "C. Fong and A. Vedaldi. Interpretable explanations of black boxes by meaningful perturbation. In 2017 IEEE International Conference on Computer Vision (ICCV), pages 3449-3457, 2017. [26] D. Y. Fu, T. Dao, K. K. Saab, A. W. Thomas, A. Rudra, and C. R\u00e9. Hungry hungry hippos: Towards language modeling with state space models. arXiv:2212.14052, 2022. [27] H. Gong, L. Kang, Y. Wang, X. Wan, and H. Li. nnMamba: 3D biomedical image segmentation, classification and landmark detection with state space model.",
    "mambalrp-25": "arXiv:2402.03526, 2024. [28] Y. Gong, Y.-A. Chung, and J. Glass. AST: Audio Spectrogram Transformer. In Proc. Interspeech 2021, pages 571-575, 2021. [29] A.",
    "mambalrp-26": "Gu and T. Dao. Mamba: Linear-time sequence modeling with selective state spaces.",
    "mambalrp-27": "arXiv:2312.00752, 2023. [30] A. Gu, I. Johnson, K. Goel, K. Saab, T. Dao, A. Rudra, and C. R\u00e9. Combining recurrent, convolutional, and continuous-time models with linear state space layers. Advances in Neural Information Processing Systems, 34:572-585, 2021. [31] A. Gu, K. Goel, and C. Re. Efficiently modeling long sequences with structured state spaces. In International Conference on Learning Representations, 2022.",
    "mambalrp-28": "[32] D. Gunning. DARPA's explainable artificial intelligence (XAI) program. In Proceedings of the 24th International Conference on Intelligent User Interfaces, IUI '19, page ii. Association for Computing Machinery, 2019. [33] C.-P. Hsieh, S. Sun, S. Kriman, S. Acharya, D. Rekesh, F. Jia, Y. Zhang, and B. Ginsburg. RULER: What's the real context size of your long-context language models?",
    "mambalrp-29": "arXiv:2404.06654, 2024. [34] S. Jain and B. C. Wallace. Attention is not Explanation. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics, pages 3543-3556, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. [35] S. Lapuschkin, S. W\u00e4ldchen, A. Binder, G. Montavon, W. Samek, and K.-R. M\u00fcller. Unmasking clever hans predictors and assessing what machines really learn. Nature communications, 10(1):1096, 2019. [36] J. Liu, H. Yang, H.-Y. Zhou, Y. Xi, L. Yu, Y. Yu, Y. Liang, G. Shi, S.",
    "mambalrp-30": "Zhang, H. Zheng, et al. Swin-UMamba: Mamba-based unet with imagenet-based pretraining.",
    "mambalrp-31": "arXiv:2402.03302, 2024. [37] Y. Liu, Y. Tian, Y. Zhao, H. Yu, L. Xie, Y. Wang, Q.",
    "mambalrp-32": "Ye, and Y. Liu. VMamba: Visual state space model.",
    "mambalrp-33": "arXiv:2401.10166, 2024. [38] C. Lu, Y. Schroecker, A. Gu, E. Parisotto, J. Foerster, S. Singh, and F. Behbahani. Structured state space models for in-context reinforcement learning. Advances in Neural Information Processing Systems, 36, 2024. [39] J. Ma, F. Li, and B. Wang. U-mamba: Enhancing long-range dependency for biomedical image segmentation.",
    "mambalrp-34": "arXiv:2401.04722, 2024. [40] H. Mehta, A. Gupta, A. Cutkosky, and B. Neyshabur. Long range language modeling via gated state spaces. arXiv:2206.13947, 2022. [41] A. Mohtashami and M. Jaggi. Random-access infinite context length for transformers. In Advances in Neural Information Processing Systems, 2023. [42] G. Montavon, W. Samek, and K.-R. M\u00fcller. Methods for interpreting and understanding deep neural networks. Digital signal processing, 73:1-15, 2018. [43] G. Montavon, A. Binder, S. Lapuschkin, W. Samek, and K.-R. M\u00fcller. Layer-wise relevance propagation: An overview. Explainable AI: interpreting, explaining and visualizing deep learning, pages 193-209, 2019. [44] E. Nguyen, K. Goel, A. Gu, G. Downs, P. Shah, T. Dao, S. Baccus, and C. R\u00e9. S4nd: Modeling images and videos as multidimensional signals with state spaces. Advances in Neural Information Processing Systems, 35:2846-2861, 2022. [45] M. Pi\u00f3ro, K. Ciebiera, K. Kr\u00f3l, J. Ludziejewski, and S. Jaszczur. MoE-Mamba: Efficient selective state space models with mixture of experts.",
    "mambalrp-35": "arXiv:2401.04081, 2024. [46] N. Rajani, L. Tunstall, E. Beeching, N. Lambert, A. M. Rush, and T. Wolf. No robots. https://huggingface.co/ datasets/HuggingFaceH4/no_robots 2023.",
    "mambalrp-36": "[47] J.",
    "mambalrp-37": "Ruan and S. Xiang. VM-UNet: Vision mamba UNet for medical image segmentation. arXiv:2402.02491, 2024. [48] W. Samek, A. Binder, G. Montavon, S. Lapuschkin, and K.-R. M\u00fcller. Evaluating the visualization of what a deep neural network has learned. IEEE Transactions on Neural Networks and Learning Systems, 28(11):2660-2673, 2017. [49] W. Samek, G. Montavon, S. Lapuschkin, C. J. Anders, and K.-R. M\u00fcller. Explaining deep neural networks and beyond: A review of methods and applications. Proc. IEEE, 109(3):247-278, 2021. [50] G. Saon, A. Gupta, and X. Cui. Diagonal state space augmented transformers for speech recognition. In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 1-5. IEEE, 2023. [51] E. Saravia, H. T. Liu, Y. Huang, J. Wu, and Y. Chen. CARER: contextualized affect representations for emotion recognition. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018, pages 3687-3697. Association for Computational Linguistics, 2018. [52] G. Sarti, N. Feldhus, L. Sickert, O. van der Wal, M.",
    "mambalrp-38": "Nissim, and A. Bisazza. Inseq: An interpretability toolkit for sequence generation models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations), pages 421-435, Toronto, Canada, July 2023. Association for Computational Linguistics. [53] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and D. Batra. Grad-CAM: Visual explanations from deep networks via gradient-based localization. In 2017 IEEE International Conference on Computer Vision (ICCV), pages $618-626,2017$. [54] A. Shrikumar, P. Greenside, and A. Kundaje. Learning important features through propagating activation differences. In Proceedings of the 34th International Conference on Machine Learning - Volume 70, ICML'17, page 3145-3153, 2017. [55] D. Smilkov, N. Thorat, B. Kim, F. B. Vi\u00e9gas, and M. Wattenberg. SmoothGrad: removing noise by adding noise. arXiv:1706.03825, 2017. [56] J. T. Smith, A. Warrington, and S. Linderman. Simplified state space layers for sequence modeling. In The Eleventh International Conference on Learning Representations, 2023. [57] R. Socher, A. Perelygin, J. Wu, J. Chuang, C. D. Manning, A. Y. Ng, and C. Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Conference on Empirical Methods in Natural Language Processing (EMNLP), pages $1631-1642$. ACL, 2013. [58] M. Sundararajan, A. Taly, and Q. Yan. Axiomatic attribution for deep networks. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, pages 3319-3328. PMLR, 2017. [59] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u. Kaiser, and I. Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. [60] C. Wang, O. Tsepa, J. Ma, and B. Wang. Graph-Mamba: Towards long-range graph sequence modeling with selective state spaces.",
    "mambalrp-39": "arXiv:2402.00789, 2024. [61] J. Wang, W. Zhu, P. Wang, X. Yu, L. Liu, M. Omar, and R. Hamid. Selective structured state-spaces for long-form video understanding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6387-6397, 2023. [62] J. Wang, T. Gangavarapu, J. N. Yan, and A. M. Rush. MambaByte: Token-free selective state space model.",
    "mambalrp-40": "arXiv:2401.13660, 2024. [63] Z. Wang and C. Ma. Semi-Mamba-UNet: Pixel-level contrastive cross-supervised visual mamba-based unet for semisupervised medical image segmentation.",
    "mambalrp-41": "arXiv:2402.07245, 2024. [64] Z. Wang, J.-Q. Zheng, Y. Zhang, G.",
    "mambalrp-42": "Cui, and L. Li. Mamba-UNet: UNet-like pure visual mamba for medical image segmentation.",
    "mambalrp-43": "arXiv:2402.05079, 2024. [65] S. Wiegreffe and Y. Pinter. Attention is not not explanation. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 11-20, Hong Kong, China, 2019. Association for Computational Linguistics. [66] Z. Xing, T. Ye, Y. Yang, G. Liu, and L. Zhu. SegMamba: Long-range sequential modeling mamba for 3d medical image segmentation.",
    "mambalrp-44": "arXiv:2401.13560, 2024.",
    "mambalrp-45": "[67] J. N. Yan, J. Gu, and A.",
    "mambalrp-46": "M. Rush. Diffusion models without attention. arXiv:2311.18257, 2023. [68] Y. Yang, Z. Xing, and L. Zhu. Vivim: a video vision mamba for medical video object segmentation.",
    "mambalrp-47": "arXiv:2401.14168, 2024. [69] Z. Yang, P. Qi, S. Zhang, Y. Bengio, W. W. Cohen, R. Salakhutdinov, and C.",
    "mambalrp-48": "D. Manning. HotpotQA: A dataset for diverse, explainable multi-hop question answering.",
    "mambalrp-49": "In Conference on Empirical Methods in Natural Language Processing (EMNLP), 2018. [70] K. Yin and G. Neubig. Interpreting language models with contrastive explanations. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 184-198, Abu Dhabi, United Arab Emirates, Dec. 2022. Association for Computational Linguistics. [71] M. D. Zeiler and R. Fergus. Visualizing and understanding convolutional networks. In Computer Vision-ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13, pages 818-833. Springer, 2014. [72] H. Zhou, S. Zhang, J. Peng, S. Zhang, J. Li, H. Xiong, and W. Zhang. Informer: Beyond efficient transformer for long sequence time-series forecasting. In The Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Virtual Conference, volume 35, pages 11106-11115. AAAI Press, 2021. [73] L. Zhu, B. Liao, Q. Zhang, X. Wang, W. Liu, and X. Wang. Vision Mamba: Efficient visual representation learning with bidirectional state space model.",
    "mambalrp-50": "arXiv:2401.09417, 2024.",
    "mambalrp-51": "[74] L. M. Zintgraf, T. S. Cohen, T. Adel, and M. Welling. Visualizing deep neural network decisions: Prediction difference analysis. In International Conference on Learning Representations, 2017. ## A Proofs\n\nIn the following, we provide derivations for the conservation analysis performed in Section 4. ## A. 1 Derivations for $\\operatorname{SiLU}$\n\nWe first consider the SiLU activation function. As mentioned in Section 4.1, this function is represented by the equation $y=x \\cdot \\sigma(x)$, with $\\sigma$ being the logistic sigmoid function. By applying the standard gradient propagation equations, we get the conservation equation:\n\n$$\n\\begin{aligned}\n\\frac{\\overbrace{\\partial f}^{\\partial x}}{\\mathcal{R}(x)} & =\\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial x} x \\\\\n& =\\frac{\\partial f}{\\partial y} \\cdot\\left(\\sigma(x)+x \\sigma^{\\prime}(x)\\right) \\cdot x \\\\\n& =\\frac{\\partial f}{\\partial y} \\cdot \\sigma(x) \\cdot x+\\frac{\\partial f}{\\partial y} \\cdot x \\sigma^{\\prime}(x) \\cdot x \\\\\n& =\\underbrace{\\frac{\\partial f}{\\partial y} y}_{\\mathcal{R}(y)}+\\underbrace{\\frac{\\partial f}{\\partial y} \\cdot \\sigma^{\\prime}(x) \\cdot x^{2}}_{\\varepsilon}\n\\end{aligned}\n$$\n\n## A. 2 Derivations for selective SSM\n\nIn Section 4.2. we introduced an inconsequential modification to the original Selective SSM architecture by connecting the matrix $C_{t}$ to the state $h_{t}$ instead of the input $x_{t}$. The unfolded view of the SSM component with this modification is represented in Figure 2. We can observe two subsets of nodes in this figure. The relevance scores of these two subsets should be equal if the conservation property holds. Computing the relevance propagation equation between these two groups, we obtain:\n\n$$\n\\begin{aligned}\n& \\overbrace{\\frac{\\partial f}{\\partial x_{t}} x_{t}+\\frac{\\partial f}{\\partial h_{t-1}} h_{t-1}}^{\\mathcal{R}\\left(x_{t}\\right)+\\mathcal{R}\\left(h_{t-1}\\right)}=\\left(\\frac{\\partial f}{\\partial h_{t}} \\frac{\\partial^{+} h_{t}}{\\partial x_{t}} x_{t}+\\frac{\\partial f}{\\partial \\theta_{t}} \\frac{\\partial \\theta_{t}}{\\partial x_{t}} x_{t}\\right) \\\\\n& +\\left(\\frac{\\partial f}{\\partial y_{t-1}} \\frac{\\partial^{+} y_{t-1}}{\\partial h_{t-1}} h_{t-1}+\\frac{\\partial f}{\\partial h_{t}} \\frac{\\partial h_{t}}{\\partial h_{t-1}} h_{t-1}+\\frac{\\partial f}{\\partial \\theta_{t}} \\frac{\\partial \\theta_{t}}{\\partial h_{t-1}} h_{t-1}\\right) \\\\\n& =\\left(\\frac{\\partial f}{\\partial h_{t}} \\frac{\\partial^{+} h_{t}}{\\partial x_{t}} x_{t}+\\frac{\\partial f}{\\partial h_{t}} \\frac{\\partial h_{t}}{\\partial h_{t-1}} h_{t-1}\\right)+\\left(\\frac{\\partial f}{\\partial y_{t-1}} \\frac{\\partial^{+} y_{t-1}}{\\partial h_{t-1}} h_{t-1}\\right) \\\\\n& +\\left(\\frac{\\partial f}{\\partial \\theta_{t}} \\frac{\\partial \\theta_{t}}{\\partial x_{t}} x_{t}+\\frac{\\partial f}{\\partial \\theta_{t}} \\frac{\\partial \\theta_{t}}{\\partial h_{t-1}} h_{t-1}\\right) \\\\\n& =\\underbrace{\\frac{\\partial f}{\\partial h_{t}} h_{t}+\\frac{\\partial f}{\\partial y_{t-1}} y_{t-1}}_{\\mathcal{R}\\left(h_{t}\\right)+\\mathcal{R}\\left(y_{t-1)}\\right.}+\\underbrace{\\frac{\\partial f}{\\partial \\theta_{t}} \\frac{\\partial \\theta_{t}}{\\partial x_{t}} x_{t}+\\frac{\\partial f}{\\partial \\theta_{t}} \\frac{\\partial \\theta_{t}}{\\partial h_{t-1}} h_{t-1}}_{\\varepsilon}\n\\end{aligned}\n$$\n\n## A. 3 Derivations for multiplicative gate\n\nMamba is composed of several blocks. In each block, the selective SSM's output is multiplied by an input-dependent gate. In other words, $y=z_{A} z_{B}$ with $z_{A}=\\operatorname{SSM}(x)$ and $z_{B}=\\operatorname{SiLU}(\\operatorname{Linear}(x))$. By applying the standard gradient propagation equations, we get the conservation equation:\n\n$$\n\\begin{aligned}\n\\frac{\\overbrace{\\partial f}^{\\partial x} x}{\\mathcal{R}(x)} & =\\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial x} x \\\\\n& =\\frac{\\partial f}{\\partial y} \\cdot\\left(\\frac{\\partial z_{A}}{\\partial x} z_{B}+z_{A} \\frac{\\partial z_{B}}{\\partial x}\\right) x \\\\\n& =\\frac{\\partial f}{\\partial y} \\cdot\\left(z_{A} z_{B}+z_{A} z_{B}\\right) \\\\\n& =\\underbrace{\\frac{\\partial f}{\\partial y} y}_{\\mathcal{R}(y)}+\\underbrace{\\frac{\\partial f}{\\partial y} y}_{\\varepsilon}\n\\end{aligned}\n$$\n\n## B Explicit propagation rules for MambaLRP\n\nWhereas MambaLRP is more easily implemented via the modified gradient-based approach described in the main paper, we provide below explicit relevance propagation equations for better comparability with other works.",
    "mambalrp-52": "We refer to Sections 3 and 4 of the main paper for the definition of the notation. ## B. 1 SiLU\n\nExplicit LRP rule for SiLU layers:\n\n$$\n\\mathcal{R}\\left(x_{i}\\right)=\\mathcal{R}\\left(y_{i}\\right)\n$$\n\n## B. 2 SSM\n\nUsing the shortcut notations $a_{i j}=\\left[A_{t}\\left(x_{t}\\right)\\right]_{j i}, b_{i j}=\\left[B_{t}\\left(x_{t}\\right)\\right]_{j i}$ and $c_{i j}=\\left[C_{t-1}\\left(h_{t-1}\\right)\\right]_{j i}$, we can write the propagation of relevance to the previous state space activations explicitly as:\n\n$$\n\\mathcal{R}\\left(h_{i}^{(t-1)}\\right)=\\sum_{j} \\frac{h_{i}^{(t-1)} c_{i j}}{\\sum_{i} h_{i}^{(t-1)} c_{i j}} \\mathcal{R}\\left(y_{j}^{(t-1)}\\right)+\\sum_{j} \\frac{h_{i}^{(t-1)} a_{i j}}{\\sum_{i} h_{i}^{(t-1)} a_{i j}+\\sum_{i^{\\prime}} x_{i^{\\prime}}^{(t)} b_{i^{\\prime} j}} \\mathcal{R}\\left(h_{j}^{(t)}\\right)\n$$\n\nand the propagation of relevance to the SSM input as:\n\n$$\n\\mathcal{R}\\left(x_{i}^{(t)}\\right)=\\sum_{j} \\frac{x_{i}^{(t)} b_{i j}}{\\sum_{i} x_{i}^{(t)} b_{i j}+\\sum_{i^{\\prime}} h_{i^{\\prime}}^{(t-1)} a_{i^{\\prime} j}} \\mathcal{R}\\left(h_{j}^{(t)}\\right)\n$$\n\n## B. 3 Multiplicative Gate\n\nExplicit LRP rule for the multiplicative gate:\n\n$$\n\\begin{aligned}\n& \\mathcal{R}\\left(\\left[z_{A}\\right]_{i}\\right)=0.5 \\cdot \\mathcal{R}\\left(y_{i}\\right) \\\\\n& \\mathcal{R}\\left(\\left[z_{B}\\right]_{i}\\right)=0.5 \\cdot \\mathcal{R}\\left(y_{i}\\right)\n\\end{aligned}\n$$\n\n## C Experimental details\n\nIn this section, we provide experimental details on our experiments that allow reproducibility of our results. ## C. 1 Models and datasets\n\nFor the NLP experiments, we fine-tuned all parameters of the pretrained Mamba-130M and Mamba-1.4B model ${ }^{2}$ on four text classification datasets: SST-2, SNLI, Medical BIOS, and Emotion. The data statistics can be seen in Table 5 . For the vision experiments, we used the pretrained Vim-S mode $\\sqrt[3]{3}$ trained on the ImageNet dataset. [^1]Training details During training, we used a batch size of 32 . To train the Mamba-1.4B model on the SNLI dataset, a batch size of 64 is used. We employed the \\{EleutherAI/gpt-neox-20b \\} $\\}^{4}$ tokenizer. The models' parameters were optimized using AdamW optimizer with a learning rate set at $7 e-5$. Additionally, we used a linear learning rate scheduler with an initial factor of 0.5 . All models were trained for a maximum of 10 epochs, with an early stopping mechanism in place. The top-1 accuracies of the models on each dataset are detailed in Table 4\nTable 4: The accuracies of Mamba-130M and Mamba-1.4B models on the validation sets of four text classification datasets. | Dataset | Mamba-130M | Mamba-1.4B |\n| :--- | :---: | :---: |\n| SST-2 | 91.97 | 94.15 |\n| Med-BIOS | 89.10 | 90.30 |\n| Emotion | 93.45 | 93.65 |\n| SNLI | 89.57 | 91.05 |\n\nTable 5: Data statistics. | Dataset | Train | Test | Validation |\n| :--- | :---: | :---: | :---: |\n| SST-2 | 68 K | 2 K | 1 K |\n| Med-BIOS | 8 K | 1 K | 1 K |\n| Emotion | 16 K | 2 K | 2 K |\n| SNLI | 550 K | 10 K | 10 K |\n| ImageNet | 1.3 M | 50 K | 100 K |\n\n## C. 2 MambaLRP details\n\nIn this section, we begin by showing how MambaLRP can be implemented through the following algorithms. Then, we explain the generalized LRP- $\\gamma$ rule, provide details regarding hyperparameters used in our implementation, and outline the hyperparameter selection procedure. ## Algorithm 1: MambaLRP in SiLU activation layers\n\nData: Input: $x(\\mathrm{~B}, \\mathrm{~L}, \\mathrm{D})$\n$1 z \\leftarrow \\operatorname{Identity}(x)$\n2 return $z \\odot[\\operatorname{SiLU}(x) \\oslash z] . \\operatorname{detach}()$\n\n## Algorithm 2: MambaLRP in Mamba block\n\nData: Input: $x(\\mathrm{~B}, \\mathrm{~L}, \\mathrm{D})$\nData: Output: $y(\\mathrm{~B}, \\mathrm{~L}, \\mathrm{D})$\n$1 x^{\\prime}:(\\mathrm{B}, \\mathrm{L}, \\mathrm{E}) \\leftarrow \\operatorname{SiLU}(\\operatorname{Conv1d}(x))$\n$2 g:(\\mathrm{B}, \\mathrm{L}, \\mathrm{E}) \\leftarrow \\operatorname{SiLU}(\\operatorname{Linear}(x)) \\quad \\triangleright g$ is an input-dependent gate\n$3 A:(\\mathrm{E}, \\mathrm{N}) \\leftarrow$ Parameter\n$4 B:(\\mathrm{B}, \\mathrm{L}, \\mathrm{N}) \\leftarrow$ Linear $\\left(x^{\\prime}\\right)$\n$5 C:(\\mathrm{B}, \\mathrm{L}, \\mathrm{N}) \\leftarrow$ Linear $\\left(x^{\\prime}\\right) \\quad \\triangleright C$ is input-dependent\n$6 \\Delta:($ B, L, E $) \\leftarrow \\operatorname{Softplus}\\left(\\right.$ Parameter $\\left.+\\operatorname{Linear}\\left(x^{\\prime}\\right)\\right)$\n$7 \\bar{A}, \\bar{B}:(\\mathrm{B}, \\mathrm{L}, \\mathrm{E}, \\mathrm{N}) \\leftarrow \\operatorname{discretize}(\\Delta, A, B) \\quad \\triangleright \\bar{A}$ and $\\bar{B}$ are input-dependent\n$8 y_{\\mathrm{SSM}}:(\\mathrm{B}, \\mathrm{L}, \\mathrm{E}) \\leftarrow \\operatorname{SSM}(\\bar{A} \\cdot \\operatorname{detach}(), \\bar{B} \\cdot \\operatorname{detach}(), C \\cdot \\operatorname{detach}())\\left(x^{\\prime}\\right)$\n$9 y^{\\prime}:(\\mathrm{B}, \\mathrm{L}, \\mathrm{E}) \\leftarrow 0.5\\left(y_{\\mathrm{SSM}} \\odot g\\right)+0.5\\left[y_{\\mathrm{SSM}} \\odot g\\right] . \\operatorname{detach}(\\mathrm{)}$\n$10 y:(\\mathrm{B}, \\mathrm{L}, \\mathrm{D}) \\leftarrow \\operatorname{Linear}\\left(y^{\\prime}\\right)$\n11 return $y$\n\nThe following list represents the hyperparameters of the above-mentioned algorithms:\n\n| B | batch size |\n| :--- | :--- |\n| L | sequence length |\n| D | hidden dimension |\n| E | expanded hidden dimension |\n| N | SSM dimension |\n\nExplanations generated by propagation-based methods rely on gradient computations, which can result in noisy explanations in models with many layers. This is due to the phenomena of gradient shattering and the presence of noisy gradients, which are more common in deep complex models [22, 2]. To mitigate this, we apply the generalized\n\n[^2]LRP- $\\gamma$-rule to the convolution layers of the Vision Mamba model to improve the signal to noise ratio, thereby enhancing explanations. The generalized LRP- $\\gamma$ rule is defined in Eq. 18 . $$\n\\mathcal{R}\\left(x_{i}\\right)=\\left\\{\\begin{array}{l}\n\\sum_{j} \\frac{x_{i}^{+}\\left(w_{i j}+\\gamma w_{i j}^{+}\\right)+x_{i}^{-}\\left(w_{i j}+\\gamma w_{i j}^{-}\\right)}{\\sum_{i} x_{i}^{+}\\left(w_{i j}+\\gamma w_{i j}^{+}\\right)+x_{i}^{-}\\left(w_{i j}+\\gamma w_{i j}^{-}\\right)} \\mathcal{R}\\left(y_{j}\\right) \\quad \\text { if } z_{j}>0 \\\\\n\\sum_{j} \\frac{x_{i}^{+}\\left(w_{i j}+\\gamma w_{i j}^{-}\\right)+x_{i}^{-}\\left(w_{i j}+\\gamma w_{i j}^{+}\\right)}{\\sum_{i} x_{i}^{+}\\left(w_{i j}+\\gamma w_{i j}^{-}\\right)+x_{i}^{-}\\left(w_{i j}+\\gamma w_{i j}^{+}\\right)} \\mathcal{R}\\left(y_{j}\\right) \\quad \\text { else }\n\\end{array}\\right. $$\n\nwhere $(.)^{+}=\\max (0,$.$) and (.)^{-}=\\min (0,$.$) , and z_{j}=\\sum_{i} x_{i} w_{i j}$. In our experiments, the parameter $\\gamma$ is set to 0.25 . Our observations reveal that applying this rule to the language models does not lead to any discernible improvements. Therefore, we use the LRP-0 rule in these models. ## C.2.1 LRP composites for Vision Mamba\n\nAs mentioned in Section C.2, we apply the generalized LRP- $\\gamma$ rule to the convolution layers of the Vim-S model to produce more faithful explanations. In this experiment, we justify this choice. Vision Mamba is composed of a number of blocks and in each block, there are several linear and convolution layers, where the generalized LRP- $\\gamma$ rule can be used. As can be seen in Table 6, the LRP-0 rule is sufficient to produce meaningful explanations. However, we can perform a hyperparameter search by applying the LRP- $\\gamma$ rule across different layers of the model to find the most accurate LRP composite. Table 6: Finding the best LRP composite for Vision Mamba. The layers in which the generalized LRP- $\\gamma$ rule is applied are represented with LRP- $\\gamma$ and the ones in which the basic LRP rule, i.e. LRP-0, is used are represented with LRP-0. | in-proj | out-proj | conv1d | ImageNet <br> $\\left(\\Delta A^{F} \\uparrow\\right)$ |\n| :---: | :---: | :---: | :---: |\n| LRP- $\\gamma$ | LRP- $\\gamma$ | LRP- $\\gamma$ | 1.7173 |\n| LRP- $\\gamma$ | LRP- $\\gamma$ | LRP-0 | 1.7315 |\n| LRP-0 | LRP- $\\gamma$ | LRP- | 1.7736 |\n| LRP-0 | LRP- $\\gamma$ | LRP-0 | 1.7824 |\n| LRP- $\\gamma$ | LRP-0 | LRP-0 | 1.8588 |\n| LRP- $\\gamma$ | LRP-0 | LRP- $\\gamma$ | 1.8646 |\n| LRP-0 | LRP-0 | LRP-0 | 1.8852 |\n| LRP-0 | LRP-0 | LRP- $\\gamma$ | $\\mathbf{1 . 9 1 0 6}$ |\n\nWe apply the LRP- $\\gamma$ rule across different combinations of the input projection (in-proj), output projection (out-proj), and convolution layers of each block. Subsequently, we perform the perturbation experiment to analyze the faithfulness of each combination. We can observe that the best result can be achieved when the LRP- $\\gamma$ rule is only used in convolution layers. In all of these combinations, the value of $\\gamma$ is set to 0.25 . ## C. 3 Further details of other explanation methods\n\nSome of the explanation methods that we used in this study have a set of hyperparameters. Table 7 provides further details on the specific values assigned to these hyperparameters, chosen based on the values suggested in the original papers [58, 55]. Table 7: Hyperparameters of other explanation methods. The parameters $\\mu$ and $\\sigma$ represent the mean and standard deviation of noise, respectively, while the parameter $m$ denotes the sample size. | Method | Hyperparameters |\n| :---: | :---: |\n| SmoothGrad | $\\mu=0, \\sigma=0.15, m=30$ |\n| Integrated Gradients | $m=30$ |\n\nIn the vision experiments, we used the original implementations ${ }^{5}$ of the AttnRoll and $\\mathrm{G} \\times$ AttnRoll methods, provided to explain the Vim-S model. Given the unavailability of code for adapting these approaches to the language models,\n\n[^3]namely Mamba-130M and Mamba-1.4B, we have developed our own implementation. In the vision case, the authors obtain the final relevance map by extracting the row associated with the CLS token in the attention matrix. However, since our language models lack a CLS token, we get the final relevance map from the row associated with the last token in the attention matrix. This is because predictions are based on the last state in these models. For the gradient-based methods, we use the implementations available in the Captum library\n\n## C. 4 Additional quantitative results\n\nThe results of the insertion experiment are shown in Table 8 . Similar to the flipping results, MambaLRP outperforms all baseline methods for all the datasets and models. In the majority of the models and datasets, the $\\mathrm{G} \\times$ AttnRoll method has shown better performance compared to the pure gradient-based approaches. Table 8: Faithfulness score $\\Delta A^{I} \\uparrow$. A higher score indicates more faithful explanations. | Methods | SST-2 |  | Med-BIOS |  | SNLI |  | Emotion |  | ImageNet |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n|  | Mamba <br> 130 M | Mamba <br> 1.4B | Mamba <br> 130 M | Mamba <br> 1.4B | Mamba <br> 130M | Mamba <br> 1.4B | Mamba <br> 130M | Mamba <br> 1.4B | Vim-S |\n| Random | -0.024 | 0.009 | 0.022 | 0.004 | -0.003 | 0.001 | 0.019 | 0.021 | 0.000 |\n| GI [54] | 0.074 | -0.108 | 0.200 | -0.649 | -0.043 | -0.040 | -0.839 | -0.533 | 0.041 |\n| SmoothGrad [58] | 1.399 | -0.405 | 1.655 | -2.295 | 0.497 | -0.709 | 1.904 | -1.982 | 0.121 |\n| IG [55] | 0.880 | 0.223 | 1.312 | 1.065 | 0.465 | 0.224 | 1.909 | 2.181 | 0.328 |\n| AttnRoll [4] | 0.704 | 0.554 | 2.265 | 1.105 | 0.257 | 0.375 | 0.450 | 1.656 | 0.714 |\n| G $\\times$ AttnRoll 4 4] | 1.238 | 0.751 | 3.175 | 3.032 | 0.534 | 0.564 | 2.091 | 4.963 | 0.794 |\n| LRP (LN-rule, [3]) | 0.916 | 1.083 | 2.235 | 3.471 | 0.718 | 0.664 | 3.208 | 5.443 | 0.648 |\n| MambaLRP (ours) | 2.038 | 1.379 | 3.933 | 4.250 | 1.024 | 0.917 | 3.640 | 5.650 | 1.878 |\n\n## C. 5 Further ablation experiments\n\nComparing strategies for managing the Mamba block's multiplicative gate: In Section 4.3, we proposed several strategies to mitigate conservation violation in the the Mamba block's multiplicative gate. In this experiment, we evaluate the proposed approaches. As can be seen in Table 9, detaching the multiplicative gate leads to lower faithfulness scores compared to the half-relevance propagation approach. To retain conservation, an alternative approach is to detach the SSM's output, which limits capturing long-range dependencies, a task for which this branch is designed for.",
    "mambalrp-53": "Detaching it may result in a loss of valuable information used by the model to make predictions. ## C. 6 Additional qualitative results\n\nIn Section 5.2, we qualitatively evaluated the explanations produced by MambaLRP and other baseline methods. In the following, we demonstrate further qualitative results. ## C.6.1 Natural language processing\n\nIn the following figures, we represent explanations produced by MambaLRP and other baseline methods to interpret the Mamba-130M models trained on various datasets. In the visualizations, shades of red represent words that positively influence the model's prediction. Conversely, shades of blue reflect negative contributions. The heatmaps of the AttnRoll and $\\mathrm{G} \\times$ AttnRolll methods are constrained to non-negative values. ## C.6.2 Computer vision\n\nIn this section, we show explanations generated by MambaLRP alongside other baseline methods to interpret the predictions of the Vim-S model on several images of the ImageNet dataset. As can be seen, explanations generated by purely gradient-based explanation methods are very noisy. In contrast, attention-based attribution methods have offered more focused and less noisy heatmaps. However, in the last two images labeled 'paint brush' and 'flag pole', they could not faithfully explain the model's predictions. Among these approaches, MambaLRP stands out with its\n\n[^4]Table 9: Comparing the proposed strategies for managing the Mamba block's multiplicative gate. | Strategies | SST-2 | ImageNet |\n| :--- | :---: | :---: |\n| Detaching multiplicative gate | 1.577 | 1.387 |\n| Half-relevance propagation | $\\mathbf{1 . 9 7 8}$ | $\\mathbf{1 . 8 7 8}$ |\n\n\n| MambaLRP (ours) | women are embracing while holding to go packages . Two woman are holding packages |\n| :---: | :--- | :--- |\n| GI | women are embracing while holding |\n| SmoothGrad | go packages . Two woman are holding packages |\n| women are embracing while holding to go packages I Two woman are holding packages |  |\n| AttnRoll | women are embracing while holding to go packages I. Two woman are holding packages |\n| G x AttnRoll | women are embracing while holding to go packages . Two woman are holding packages |\n\nFigure 8: Explanations generated by different explanation methods for a sentence of the SNLI validation set. This sentence belongs to the 'entailment' class. | MambaLRP (ours) | woman is doing a cart wheel while wearing a b ik ini in the sand next to the beach. A woman is fixing her home |\n| :---: | :--- |\n| GI | woman is doing a cart wheel while wearing a bik ini in the sand next to the beach. A woman is fixing her home |\n| SmoothGrad | woman is doing a cart wheel while wearing a bik ini in the sand next to the beach. A woman is fixing her home |\n| IG | woman is doing a cart wheel while wearing a b ik ini in the sand next to the beach. A woman is fixing home |\n| AttnRoll | woman is doing a cart wheel while wearing a b ik ini in the sand next to the beach. A woman is fixing her home |\n| G x AttnRoll | woman is doing a cart wheel while wearing a bik ini in the sand next to the beach. A woman is fixing her home |\n\nFigure 9: Explanations generated by different explanation methods for a sentence of the SNLI validation set. This sentence belongs to the 'contradiction' class. | MambaLRP (ours) | i am feeling very blessed today that they share such a close bond |\n| :---: | :--- |\n| GI | i am feeling very blessed today that they share such a close bond |\n| SmoothGrad | i am feeling very blessed today that they share such a close ond |\n| IG | iam feeling very blessed today that they share such a close bond |\n| AttnRoll | am feeling very blessed today that they share such a close bond |\n| G x AttnRoll | iam feeling very blessed today that they share such a close bond |\n\nFigure 10: Explanations generated by different explanation methods for a sentence of the Emotion validation set.",
    "mambalrp-54": "This sentence belongs to the 'joy' class. | MambaLRP <br> (ours) | She graduated with honors in 2013 . Having more than 4 years of diverse experiences, especially in $\\mathbf{N}$ UR SE PR ACT ITION ER , Eric a J H oyer affiliates with Swedish American <br> Hospital , and cooper ates with other doctors and specialists in medical group Swedish americ an Hospital \\|Call Eric a J H oyer on phone number ( 779 ) 696 - 8650 for more information <br> and adv ises or to book an appointment |\n| :---: | :---: |\n| GI | She graduated with honors in 2013 . Having more than 4 years of diverse experiences, especially in N UR SE PR ACT ITION ER , Eric a J H oyer affiliates with Swedish American <br> Hospital \\| and cooper ates with other doctors and specialists in medical group Swedish americ an Hospital | Call Eric a J H oyer on phone number ( 779 ) 696 - 8650 for more information <br> and adv ises or to book an appointment |\n| SmoothGrad | She graduated with honors in 2013 Having more than 4 years of diverse experiences, especially in N UR SE PR ACT ITION ER, Eric a J H oyer affiliates with Swedish American <br> Hospital, and cooper ates with other doctors and specialists in medical group Swedish americ an Hospital [Call Eric a J H oyer on phone number ( 779 ) 696 - 8650 for more information <br> and adv ises or to book an appointment |\n| IG | She graduated with honors in 2013 \\| Having more than 4 years of diverse experiences, especially in N UR SE PR ACT ITION ER , Eric a J H oyer affiliates with Swedish American <br> Hospital , and cooper ates with other doctors and specialists in medical group Swedish americ an Hospital Call Eric a $\\mathbf{J} \\mathrm{H}$ oyer on phone number ( 779 ) $696 \\\\| 86$ for more information <br> and adv ises or to book an appointment |\n| AttnRoll | She graduated with honors in 2013 \\| Having more than 4 years of diverse experiences, especially in N UR SE PR ACT ITION ER , Eric a J H oyer affiliates with Swedish American <br> Hospital !and cooper ates with other doctors and specialists in medical group Swedish americ an Hospital . Call Eric a J H oyer on phone number ( 779 ) 696 - 8650 for more information <br> and adv ises or to book an appointment |\n| G $\\times$ AttnRoll | She graduated with honors in 2013 . Having more than 4 years of diverse experiences, especially in N UR SE PR ACT ITION ER , Eric a J H oyer affiliates with Swedish American <br> Hospital, and cooper ates with other doctors and specialists in medical group Swedish americ an Hospital. Call Eric a J H oyer on phone number ( 779 ) 696 - 8650 for more information <br> and adv ises or to book an appointment |\n\nFigure 11: Explanations generated by different explanation methods for a sentence of the Medical BIOS validation set.",
    "mambalrp-55": "This sentence belongs to the 'nurse' class. ![](https://cdn.mathpix.com/cropped/2024_09_12_5ac10fa1852cdd44a7d1g-20.jpg?height=1135&width=1251&top_left_y=270&top_left_x=429)\n\nFigure 12: Explanations produced by different explanation methods for images of the ImageNet dataset. Explanations produced by AttnRoll and $\\mathrm{G} \\times$ AttnRoll are limited to non-negative values, whereas those generated by gradient-based techniques and MambaLRP includes both positive and negative contributions. ability to generate sparse explanations, offering more faithful explanations of how different image patches contribute to the final predictions. ## C. 7 Additional use case results\n\nFor the needle-in-a-haystack experiment in Section 6 , we use a synthetic dataset ${ }^{7}$ In this dataset, a single passkey (the 'needle') is inserted at different locations within a collection of repeated noise sentences (the 'haystack'), as described in [33]. The dataset is composed of sequences with different context lengths. In our experiment, we use sequences with context lengths of 512,1024 , and 2048. We use a Mamba-2.8B model ${ }^{8}$ which is finetuned on the No Robots dataset [46] using a context length of 2048. Then, we prompt the model to extract the passkey hidden among irrelevant text by completing the phrase \"The passkey is $\\qquad$ \". Retrieval accuracy is a metric, which is commonly used in the needle-in-a-haystack experiment to analyze the model's performance. The synthetic dataset used for this experiment can be designed to include misleading information, which may cause the model to generate the correct passkey based on incorrect evidence. In such cases, simply evaluating the retrieval accuracy may be insufficient. This issue can also arise when dealing with more realistic haystacks. Therefore, we introduced explanation-based retrieval accuracy (XRA) in Section 7 MambaLRP and the XRA metric designed upon it can help to better examine the evidence the model relies on to retrieve the needle. In our experiment, we set the value of K to 2 . This is because LRP usually identifies the token immediately preceding the generated token as the most important one and the evidence used for the passkey retrieval is usually the second most important token. [^5]The sample in Fig. 13 represents such scenario. In this case, the next token generated by the model is the second part of the correct passkey (300). However, the model has incorrectly focused on the number 300 in the phrase \"Pass the key to room 6300\" to generate this token. Simply looking at the retrieved token might suggest that the model successfully retrieved the correct information. However, examining the MambaLRP's explanation heatmaps provides deeper insights into the model's behavior. This helps us to debug the model more effectively and design better tests to analyze its capabilities. Next generated token: [300]\ncontext: 2048 tokens\n\n[^6]Figure 13: Detecting Clever-Hans effect in the needle-in-a-haystack test. Given the 2 K context length in this example, visualizing the entire text could be confusing. Therefore, we have removed most of the haystack from the visualization. In this example, the model has generated the correct passkey but the generation is not based on truly relevant information in the text. ## C. 8 Runtime comparison\n\nIn this section, we report the time required for each explanation method to generate its respective explanation. These times, measured in seconds, are averaged over samples from the Medical BIOS dataset. All baseline methods are evaluated on a single A100-40GB GPU with a batch size of 1. All methods are applied to the Mamba-130M model. The results without fast CUDA kernels are shown in Table 10, while the results with fast CUDA kernels are presented in Table 11 . We can observe that the runtime of MambaLRP is comparable to Gradient $\\times$ Input. Since algorithms like Integrated Gradients and SmoothGrad require multiple function evaluations, their runtimes are significantly higher than MambaLRP and Gradient $\\times$ Input.",
    "mambalrp-56": "Table 10: Runtime comparison. The time needed for each baseline method to generate its explanations. The times, measured in seconds, are averaged over the samples from the Medical BIOS dataset. The model used in this experiment is Mamba-130M without using fast CUDA kernels. | Methods | Runtime |\n| :--- | :---: |\n| Gradient $\\times$ Input | 0.7556 |\n| SmoothGrad | 22.9772 |\n| Integrated Gradients | 22.8071 |\n| AttnRoll | 2.1558 |\n| $\\mathrm{G} \\times$ AttnRoll | 2.6661 |\n| MambaLRP | 0.4345 |\n\nTable 11: Runtime comparison. The time needed for each baseline method to generate its explanations. The times, measured in seconds, are averaged over the samples from the Medical BIOS dataset. The model used in this experiment is Mamba-130M using fast CUDA kernels. | Methods | Runtime |\n| :--- | :---: |\n| Gradient $\\times$ Input | 0.0335 |\n| SmoothGrad | 0.9785 |\n| Integrated Gradients | 0.9742 |\n| AttnRoll | - |\n| $\\mathrm{G} \\times$ AttnRoll | - |\n| MambaLRP | 0.3063 |\n\n\n[^0]:    https://github.com/FarnoushRJ/MambaLRP\n\n[^1]:    2 https://github.com/state-spaces/mamba\n    https://github.com/hustvl/Vim\n\n[^2]:    https://github.com/EleutherAI/gpt-neox\n\n[^3]:    https://github.com/AmeenAli/HiddenMambaAttn/\n\n[^4]:    https://captum.ai/\n\n[^5]:    ${ }^{7}$ https://huggingface.co/datasets/lvwerra/needle-llama3-16x512\n    https://huggingface.co/clibrain/mamba-2.8b-chat-no_robots\n\n[^6]:    [1] There is an important info hidden inside a lot of irrelevant text .",
    "mambalrp-57": "Find it and memor ize them. I will quiz you about the important information there . [2]\n    [3] Text : Pass the key to room 6300 .",
    "mambalrp-58": "The grass is green. The sky is blue. The sun is yellow. Here we go . There and back again. The mountain is high. The snow is cold. The air is thin. Up ward we climb. From base to peak. The forest is dense.The trees are tall . The path is winding. Into the woods. Out and back. The river is wide . The current is strong. The banks are muddy. Down the stream. Back and forth . The ocean is vast. The waves are cal ming. The sand is warm . On ward we sail. From coast to coast.Here we go . There and back again. The grass is green. The sky is blue. The sun is yellow. Here we go. There and back again. The mountain is high. The snow is cold. The air is thin . Up ward we climb. From base to peak. The forest is dense. The trees are tall. The path is winding. The pass key is 6300 . Remember it . 6 300 is the pass key. Into the woods. Out and back. The river is wide. The current is strong. The banks are muddy. Down the stream . Back and forth. The ocean is vast . The waves are cal ming. The sand is warm . On ward we sail . From coast to coast . Here we go . There and back\n\n    The air is thin . Up ward we climb . From base to peak. The forest is dense. The trees are tall . The path is winding . Into the woods . Out and back. The river is wide. The current is strong. The banks are muddy. Down the stream . Back and forth. The ocean is vast. The waves are cal ming. The sand is warm . On ward we sail . From coast to coast. Here we go. There and back again. The grass is green. The sky is blue .The sun is yellow. Here we go . There and back again. The mountain is high. The snow is cold . [4]\n    [5] Qu iz: What is the pass key? [6] The pass key is\n\n"
}