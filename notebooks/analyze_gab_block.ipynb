{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static analysis of GAB block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/8TBNVME/home/junyanc/model_discovery/notebooks/../model_discovery/model/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/media/8TBNVME/home/junyanc/model_discovery/notebooks/../model_discovery/model/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Failed to login to HuggingFace Hub, some datasets may not be available to download.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "/home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "/home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "/home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "2024-08-19:19:18:24,404 INFO     [__init__.py:29] Skipping import of cpp extensions\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch.fx import symbolic_trace\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import model_discovery.model.lab as lab\n",
    "from model_discovery.model.library import *\n",
    "from exec_utils import BuildTool\n",
    "from model_discovery.configs.gam_config import ( \n",
    "    GAMConfig,GAMConfig_14M,GAMConfig_31M,GAMConfig_70M,GAMConfig_125M,GAMConfig_350M,GAMConfig_760M,\n",
    "    GAMConfig_1300M,GAMConfig_2700M,GAMConfig_6700M,GAMConfig_13B,GAMConfig_175B,GAMConfig_1T,GAMConfig_debug\n",
    ")\n",
    "\n",
    "\n",
    "def load_gab(model_name: str, scale='14M'):\n",
    "    gab_code = MODEL2CODE[model_name]\n",
    "    checker = BuildTool(tool_type=\"checker\")\n",
    "    try:\n",
    "        checkpass, gab_code = checker._check_format_and_reformat(gab_code)\n",
    "        assert checkpass\n",
    "    except AssertionError as e:\n",
    "        print('Model does not pass the format checker')\n",
    "        raise e\n",
    "    \n",
    "    # Wrap len inside the executed code\n",
    "    gab_code = f\"{gab_code}\"\n",
    "    \n",
    "    module = {}\n",
    "    exec(gab_code.replace(\"class GAB\",\"class GABCustom\"),module)\n",
    "    assert \"GABCustom\" in module, \"Class GAB not found in module. You should never ever change the class name of GAB and it should always inherit from GABBase.\"\n",
    "    GAB = module[\"GABCustom\"]\n",
    "\n",
    "    cfg = eval(f\"GAMConfig_{scale}()\")\n",
    "    gab_config = {} \n",
    "    assert \"gab_config\" in module, \"Dictionary gab_config not found in module.\"\n",
    "    gab_config = module[\"gab_config\"]\n",
    "\n",
    "    gab= GAB(cfg.d_model,block_loc=(0,cfg.n_block),device=None,dtype=None, **gab_config)\n",
    "\n",
    "    return gab,cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenized dataset wikitext-2 from /home/junyanc/model_discovery/data/wikitext-2/tokenized/meta-llama/Llama-2-7b-hf/2048\n",
      "Checking code format...\n",
      "Code after reformatted:\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from model_discovery.model.utils.modules import GABBase\n",
      "from typing import Any, Dict, Optional, Tuple, Union\n",
      "import torch.nn.functional as F\n",
      "import torch.utils.checkpoint\n",
      "from torch.utils._pytree import tree_map\n",
      "from transformers.utils import logging\n",
      "from transformers.activations import ACT2FN\n",
      "try:\n",
      "    from causal_conv1d import causal_conv1d_fn, causal_conv1d_update\n",
      "except:\n",
      "    causal_conv1d_update, causal_conv1d_fn = None, None\n",
      "\n",
      "\n",
      "def rotate_half(x):\n",
      "    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
      "    x1 = x[..., :x.shape[-1] // 2]\n",
      "    x2 = x[..., x.shape[-1] // 2:]\n",
      "    return torch.cat((-x2, x1), dim=-1)\n",
      "\n",
      "\n",
      "def permute_qk(q, k):\n",
      "    bsz, num_head, seq_len, head_dim = q.shape\n",
      "    q = q.reshape(bsz, num_head, seq_len, head_dim // 2, 2).transpose(3, 4\n",
      "        ).reshape(bsz, num_head, seq_len, head_dim)\n",
      "    k = k.reshape(bsz, num_head, seq_len, head_dim // 2, 2).transpose(3, 4\n",
      "        ).reshape(bsz, num_head, seq_len, head_dim)\n",
      "    return q, k\n",
      "\n",
      "\n",
      "def undo_permute_qk(q, k):\n",
      "    bsz, num_head, seq_len, head_dim = q.shape\n",
      "    q = q.reshape(bsz, num_head, seq_len, 2, head_dim // 2).transpose(3, 4\n",
      "        ).reshape(bsz, num_head, seq_len, head_dim)\n",
      "    k = k.reshape(bsz, num_head, seq_len, 2, head_dim // 2).transpose(3, 4\n",
      "        ).reshape(bsz, num_head, seq_len, head_dim)\n",
      "    return q, k\n",
      "\n",
      "\n",
      "def apply_rotary_pos_emb(q, k, cos, sin, unsqueeze_dim=1):\n",
      "    \"\"\"Applies Rotary Position Embedding to the query and key tensors.\n",
      "\n",
      "    Args:\n",
      "        q (`torch.Tensor`): The query tensor.\n",
      "        k (`torch.Tensor`): The key tensor.\n",
      "        cos (`torch.Tensor`): The cosine part of the rotary embedding.\n",
      "        sin (`torch.Tensor`): The sine part of the rotary embedding.\n",
      "        position_ids (`torch.Tensor`, *optional*):\n",
      "            Deprecated and unused.\n",
      "        unsqueeze_dim (`int`, *optional*, defaults to 1):\n",
      "            The 'unsqueeze_dim' argument specifies the dimension along which to unsqueeze cos[position_ids] and\n",
      "            sin[position_ids] so that they can be properly broadcasted to the dimensions of q and k. For example, note\n",
      "            that cos[position_ids] and sin[position_ids] have the shape [batch_size, seq_len, head_dim]. Then, if q and\n",
      "            k have the shape [batch_size, heads, seq_len, head_dim], then setting unsqueeze_dim=1 makes\n",
      "            cos[position_ids] and sin[position_ids] broadcastable to the shapes of q and k. Similarly, if q and k have\n",
      "            the shape [batch_size, seq_len, heads, head_dim], then set unsqueeze_dim=2.\n",
      "    Returns:\n",
      "        `tuple(torch.Tensor)` comprising of the query and key tensors rotated using the Rotary Position Embedding.\n",
      "    \"\"\"\n",
      "    cos = cos.unsqueeze(unsqueeze_dim)\n",
      "    sin = sin.unsqueeze(unsqueeze_dim)\n",
      "    q_embed = q * cos + rotate_half(q) * sin\n",
      "    k_embed = k * cos + rotate_half(k) * sin\n",
      "    return q_embed, k_embed\n",
      "\n",
      "\n",
      "class RMSNorm(nn.Module):\n",
      "\n",
      "    def __init__(self, hidden_size, eps=1e-06):\n",
      "        super().__init__()\n",
      "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
      "        self.variance_epsilon = eps\n",
      "\n",
      "    def forward(self, hidden_states):\n",
      "        input_dtype = hidden_states.dtype\n",
      "        hidden_states = hidden_states.to(torch.float32)\n",
      "        variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
      "        hidden_states = hidden_states * torch.rsqrt(variance + self.\n",
      "            variance_epsilon)\n",
      "        return self.weight * hidden_states.to(input_dtype)\n",
      "\n",
      "\n",
      "class SwiGluMLP(nn.Module):\n",
      "\n",
      "    def __init__(self, hidden_size, intermediate_size):\n",
      "        super().__init__()\n",
      "        self.hidden_size = hidden_size\n",
      "        self.intermediate_size = intermediate_size\n",
      "        self.gate_proj = nn.Linear(self.hidden_size, self.intermediate_size,\n",
      "            bias=False)\n",
      "        self.up_proj = nn.Linear(self.hidden_size, self.intermediate_size,\n",
      "            bias=False)\n",
      "        self.down_proj = nn.Linear(self.intermediate_size, self.hidden_size,\n",
      "            bias=False)\n",
      "        self.act_fn = ACT2FN['silu']\n",
      "\n",
      "    def forward(self, x):\n",
      "        down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.\n",
      "            up_proj(x))\n",
      "        return down_proj\n",
      "\n",
      "\n",
      "class RotaryEmbedding(nn.Module):\n",
      "\n",
      "    def __init__(self, dim, max_position_embeddings=16, base=10000, device=\n",
      "        None, scaling_factor=1.0):\n",
      "        super().__init__()\n",
      "        self.scaling_factor = scaling_factor\n",
      "        self.dim = dim\n",
      "        self.max_position_embeddings = max_position_embeddings\n",
      "        self.base = base\n",
      "        inv_freq = 1.0 / self.base ** (torch.arange(0, self.dim, 2, dtype=\n",
      "            torch.int64).float().to(device) / self.dim)\n",
      "        self.register_buffer('inv_freq', inv_freq, persistent=False)\n",
      "\n",
      "    @torch.no_grad()\n",
      "    def forward(self, x, position_ids):\n",
      "        inv_freq_expanded = self.inv_freq[None, :, None].float().expand(\n",
      "            position_ids.shape[0], -1, 1)\n",
      "        position_ids_expanded = position_ids[:, None, :].float()\n",
      "        device_type = x.device.type\n",
      "        device_type = device_type if isinstance(device_type, str\n",
      "            ) and device_type != 'mps' else 'cpu'\n",
      "        with torch.autocast(device_type=device_type, enabled=False):\n",
      "            freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()\n",
      "                ).transpose(1, 2)\n",
      "            emb = torch.cat((freqs, freqs), dim=-1)\n",
      "            cos = emb.cos()\n",
      "            sin = emb.sin()\n",
      "        return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
      "\n",
      "\n",
      "class Conv(nn.Module):\n",
      "\n",
      "    def __init__(self, hidden_size, conv_kernel, rms_norm_eps):\n",
      "        super().__init__()\n",
      "        self.norm = RMSNorm(hidden_size, eps=rms_norm_eps)\n",
      "        self.conv = nn.Conv1d(hidden_size, hidden_size, bias=True,\n",
      "            kernel_size=conv_kernel, groups=hidden_size, padding=\n",
      "            conv_kernel - 1)\n",
      "\n",
      "    def __call__(self, hidden_states):\n",
      "        seq_len = hidden_states.shape[1]\n",
      "        hidden_states = self.norm(hidden_states)\n",
      "        hidden_states = hidden_states.transpose(1, 2)\n",
      "        if causal_conv1d_fn is None:\n",
      "            hidden_states = self.conv(hidden_states)[..., :seq_len]\n",
      "        else:\n",
      "            conv_weights = self.conv.weight.view(self.conv.weight.size(0),\n",
      "                self.conv.weight.size(2))\n",
      "            hidden_states = causal_conv1d_fn(hidden_states, conv_weights,\n",
      "                self.conv.bias, activation=None)\n",
      "        hidden_states = hidden_states.transpose(1, 2)\n",
      "        return hidden_states\n",
      "\n",
      "\n",
      "def scan(f, init, xs, out, checkpoint_group=0):\n",
      "    \"\"\"Minic jax.lax.scan function.\"\"\"\n",
      "    carry = init\n",
      "    if isinstance(xs, dict):\n",
      "        num_items = len(next(iter(xs.values())))\n",
      "    else:\n",
      "        num_items = len(xs[0])\n",
      "\n",
      "    def scan_fn(carry, i_start, i_end):\n",
      "        for i in range(i_start, i_end):\n",
      "            if isinstance(xs, dict):\n",
      "                x = {key: tensor[i] for key, tensor in xs.items()}\n",
      "            else:\n",
      "                x = [x[i] for x in xs]\n",
      "            carry, y = f(carry, x)\n",
      "            out[i] = y\n",
      "        return carry\n",
      "    if checkpoint_group > 0:\n",
      "        ckpt_every_n = num_items // checkpoint_group\n",
      "        for k in range(0, num_items, ckpt_every_n):\n",
      "            carry = torch.utils.checkpoint.checkpoint(scan_fn, carry, k,\n",
      "                min(k + ckpt_every_n, num_items), use_reentrant=False)\n",
      "    else:\n",
      "        carry = scan_fn(carry, 0, num_items)\n",
      "    return carry, out\n",
      "\n",
      "\n",
      "def ln_fwd(x, gamma, beta, eps=1e-06):\n",
      "    \"\"\"Batch forward for LayerNorm.\"\"\"\n",
      "    mu = x.mean(dim=-1, keepdim=True)\n",
      "    var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
      "    std = torch.sqrt(var + eps)\n",
      "    x_hat = (x - mu) / std\n",
      "    y = gamma * x_hat + beta\n",
      "    return y\n",
      "\n",
      "\n",
      "def ln_fused_l2_bwd(x, l2_target, gamma, beta, eps=1e-06):\n",
      "    \"\"\"Batch backward for LayerNorm fused with L2 loss.\"\"\"\n",
      "    D = x.shape[-1]\n",
      "    mu = x.mean(dim=-1, keepdim=True)\n",
      "    var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
      "    std = torch.sqrt(var + eps)\n",
      "    x_hat = (x - mu) / std\n",
      "    y = gamma * x_hat + beta\n",
      "    grad_output = y - l2_target\n",
      "    grad_x_hat = grad_output * gamma\n",
      "    z = 1.0 / D * (D * grad_x_hat - grad_x_hat.sum(dim=-1, keepdim=True) - \n",
      "        x_hat * (grad_x_hat * x_hat).sum(dim=-1, keepdim=True)) / std\n",
      "    return z\n",
      "\n",
      "\n",
      "class TTTLinear(nn.Module):\n",
      "\n",
      "    def __init__(self, hidden_size, num_attention_heads,\n",
      "        scan_checkpoint_group_size, conv_kernel, mini_batch_size,\n",
      "        rope_theta, ttt_base_lr):\n",
      "        super().__init__()\n",
      "        self.num_heads = num_attention_heads\n",
      "        self.width = hidden_size\n",
      "        self.hidden_size = hidden_size\n",
      "        self.head_dim = self.width // self.num_heads\n",
      "        self.mini_batch_size = mini_batch_size\n",
      "        self.rope_theta = rope_theta\n",
      "        self.ttt_base_lr = ttt_base_lr\n",
      "        token_idx = 1.0 / torch.arange(1, self.mini_batch_size + 1)\n",
      "        self.register_buffer('token_idx', token_idx, persistent=False)\n",
      "        self.learnable_token_idx = nn.Parameter(torch.zeros((self.\n",
      "            mini_batch_size,)))\n",
      "        self.conv_kernel = conv_kernel\n",
      "        self._init_qkvo_proj()\n",
      "        self._init_rope()\n",
      "        self._init_ttt_lr_gate()\n",
      "        self._init_ttt_ln()\n",
      "        self.post_norm = nn.LayerNorm(self.width, eps=1e-06)\n",
      "        self.scan_checkpoint_group_size = scan_checkpoint_group_size\n",
      "        self.W1 = nn.Parameter(torch.normal(0, 0.02, size=(self.num_heads,\n",
      "            self.head_dim, self.head_dim)))\n",
      "        self.b1 = nn.Parameter(torch.zeros(self.num_heads, 1, self.head_dim))\n",
      "\n",
      "    def _init_qkvo_proj(self):\n",
      "        self.q_proj = nn.Linear(self.width, self.num_heads * self.head_dim,\n",
      "            bias=False)\n",
      "        self.k_proj = nn.Linear(self.width, self.num_heads * self.head_dim,\n",
      "            bias=False)\n",
      "        self.v_proj = nn.Linear(self.width, self.num_heads * self.head_dim,\n",
      "            bias=False)\n",
      "        self.o_proj = nn.Linear(self.width, self.num_heads * self.head_dim,\n",
      "            bias=False)\n",
      "\n",
      "    def _init_rope(self):\n",
      "        self.rope_theta = self.rope_theta\n",
      "        self.rotary_emb = RotaryEmbedding(self.head_dim,\n",
      "            max_position_embeddings=self.mini_batch_size, base=self.rope_theta)\n",
      "\n",
      "    def _init_ttt_lr_gate(self):\n",
      "        linear_weight_data = nn.Linear(self.width, 1, bias=True).weight.data\n",
      "        self.learnable_ttt_lr_weight = nn.Parameter(torch.stack([torch.\n",
      "            normal(0, 0.02, size=linear_weight_data.shape) for _ in range(\n",
      "            self.num_heads)], dim=0))\n",
      "        linear_bias_data = nn.Linear(self.width, 1, bias=True).bias.data\n",
      "        self.learnable_ttt_lr_bias = nn.Parameter(torch.stack([torch.\n",
      "            zeros_like(linear_bias_data) for _ in range(self.num_heads)],\n",
      "            dim=0))\n",
      "\n",
      "    def _init_ttt_ln(self):\n",
      "        ln_weight_data = nn.LayerNorm(self.head_dim).weight.data\n",
      "        self.ttt_norm_weight = nn.Parameter(torch.tile(ln_weight_data.\n",
      "            unsqueeze(0), (self.num_heads, 1)))\n",
      "        ln_bias_data = nn.LayerNorm(self.head_dim).bias.data\n",
      "        self.ttt_norm_bias = nn.Parameter(torch.tile(ln_bias_data.unsqueeze\n",
      "            (0), (self.num_heads, 1)))\n",
      "\n",
      "    def get_qkv_projections(self, hidden_states):\n",
      "        XQ, XK, XV = self.q_proj(hidden_states), self.k_proj(hidden_states\n",
      "            ), self.v_proj(hidden_states)\n",
      "        return XQ, XK, XV\n",
      "\n",
      "    def _split_heads(self, hidden_states):\n",
      "        return hidden_states.reshape(hidden_states.shape[:2] + (self.\n",
      "            num_heads, self.head_dim))\n",
      "\n",
      "    def get_eta(self, X, mini_batch_size):\n",
      "        ttt_lr = torch.einsum('bnkc,hdc->bhnkd', X, self.\n",
      "            learnable_ttt_lr_weight) + self.learnable_ttt_lr_bias.reshape(1,\n",
      "            -1, 1, 1, 1)\n",
      "        ttt_lr = F.sigmoid(ttt_lr)\n",
      "        ttt_lr = ttt_lr.permute(0, 1, 2, 4, 3)\n",
      "        ttt_lr_eta = self.ttt_base_lr * ttt_lr / self.head_dim\n",
      "        token_idx = self.token_idx + self.learnable_token_idx\n",
      "        token_idx = token_idx[0:mini_batch_size]\n",
      "        token_idx = torch.clamp_min(token_idx, 0.0)\n",
      "        token_eta = torch.broadcast_to(token_idx.reshape(1, 1, 1,\n",
      "            mini_batch_size, 1), (X.shape[0], self.num_heads, X.shape[1],\n",
      "            mini_batch_size, 1))\n",
      "        return token_eta, ttt_lr_eta\n",
      "\n",
      "    def get_ttt_inputs(self, inputs, mini_batch_size):\n",
      "        XQ = inputs['XQ']\n",
      "        XK = inputs['XK']\n",
      "        XV = inputs['XV']\n",
      "        X = inputs['X']\n",
      "        B, L, C = X.shape\n",
      "        num_mini_batch = L // mini_batch_size\n",
      "        X = X.reshape(B, num_mini_batch, mini_batch_size, self.width)\n",
      "        XQ = XQ.reshape(B, self.num_heads, L // mini_batch_size,\n",
      "            mini_batch_size, self.head_dim)\n",
      "        XK = XK.reshape(B, self.num_heads, L // mini_batch_size,\n",
      "            mini_batch_size, self.head_dim)\n",
      "        XV = XV.reshape(B, self.num_heads, L // mini_batch_size,\n",
      "            mini_batch_size, self.head_dim)\n",
      "        token_eta, ttt_lr_eta = self.get_eta(X, mini_batch_size)\n",
      "        eta = token_eta * ttt_lr_eta\n",
      "        inputs = {'XQ': XQ, 'XK': XK, 'XV': XV, 'eta': eta, 'token_eta':\n",
      "            token_eta, 'ttt_lr_eta': ttt_lr_eta}\n",
      "        return inputs\n",
      "\n",
      "    def ttt(self, inputs, mini_batch_size, last_mini_batch_params_dict):\n",
      "        if mini_batch_size is None:\n",
      "            mini_batch_size = self.mini_batch_size\n",
      "        B = inputs['XV'].shape[0]\n",
      "        num_mini_batch = inputs['XV'].shape[2]\n",
      "        L = inputs['XV'].shape[2] * inputs['XV'].shape[3]\n",
      "        device = inputs['XV'].device\n",
      "        dtype = inputs['XV'].dtype\n",
      "        use_dual_form = True\n",
      "\n",
      "        def compute_mini_batch(params_dict, inputs):\n",
      "            W1_init = params_dict['W1_states']\n",
      "            b1_init = params_dict['b1_states']\n",
      "            XQ_mini_batch = inputs['XQ']\n",
      "            XV_mini_batch = inputs['XV']\n",
      "            XK_mini_batch = inputs['XK']\n",
      "            eta_mini_batch = inputs['eta']\n",
      "            token_eta_mini_batch = inputs['token_eta']\n",
      "            ttt_lr_eta_mini_batch = inputs['ttt_lr_eta']\n",
      "            X1 = XK_mini_batch\n",
      "            Z1 = X1 @ W1_init + b1_init\n",
      "            reconstruction_target = XV_mini_batch - XK_mini_batch\n",
      "            ln_weight = self.ttt_norm_weight.reshape(self.num_heads, 1,\n",
      "                self.head_dim)\n",
      "            ln_bias = self.ttt_norm_bias.reshape(self.num_heads, 1, self.\n",
      "                head_dim)\n",
      "            grad_l_wrt_Z1 = ln_fused_l2_bwd(Z1, reconstruction_target,\n",
      "                ln_weight, ln_bias)\n",
      "            if use_dual_form:\n",
      "                Attn1 = torch.tril(XQ_mini_batch @ X1.transpose(-2, -1))\n",
      "                b1_bar = b1_init - torch.tril(eta_mini_batch) @ grad_l_wrt_Z1\n",
      "                Z1_bar = (XQ_mini_batch @ W1_init - eta_mini_batch * Attn1 @\n",
      "                    grad_l_wrt_Z1 + b1_bar)\n",
      "                last_eta_mini_batch = eta_mini_batch[:, :, -1, :, None]\n",
      "                W1_last = W1_init - (last_eta_mini_batch * X1).transpose(-1, -2\n",
      "                    ) @ grad_l_wrt_Z1\n",
      "                b1_last = b1_init - torch.sum(last_eta_mini_batch *\n",
      "                    grad_l_wrt_Z1, dim=-2, keepdim=True)\n",
      "                grad_W1_last = torch.zeros_like(W1_last)\n",
      "                grad_b1_last = torch.zeros_like(b1_last)\n",
      "            else:\n",
      "                ttt_lr_eta_mini_batch = torch.broadcast_to(\n",
      "                    ttt_lr_eta_mini_batch, (*ttt_lr_eta_mini_batch.shape[:2\n",
      "                    ], mini_batch_size, mini_batch_size))\n",
      "                grad_W1 = torch.einsum('bhki,bhkj->bhkij', X1, grad_l_wrt_Z1)\n",
      "                grad_W1 = torch.einsum('bhnk,bhkij->bhnij', torch.tril(\n",
      "                    ttt_lr_eta_mini_batch), grad_W1)\n",
      "                grad_W1 = grad_W1 + params_dict['W1_grad'].unsqueeze(2)\n",
      "                grad_b1 = torch.einsum('bhnk,bhki->bhni', torch.tril(\n",
      "                    ttt_lr_eta_mini_batch), grad_l_wrt_Z1)\n",
      "                grad_b1 = grad_b1 + params_dict['b1_grad']\n",
      "                W1_bar = W1_init.unsqueeze(2\n",
      "                    ) - grad_W1 * token_eta_mini_batch.unsqueeze(-1)\n",
      "                b1_bar = b1_init - grad_b1 * token_eta_mini_batch\n",
      "                Z1_bar = (XQ_mini_batch.unsqueeze(3) @ W1_bar).squeeze(3\n",
      "                    ) + b1_bar\n",
      "                W1_last = W1_bar[:, :, -1]\n",
      "                b1_last = b1_bar[:, :, -1:]\n",
      "                grad_W1_last = grad_W1[:, :, -1]\n",
      "                grad_b1_last = grad_b1[:, :, -1:]\n",
      "            Z1_bar = ln_fwd(Z1_bar, ln_weight, ln_bias)\n",
      "            XQW_mini_batch = XQ_mini_batch + Z1_bar\n",
      "            last_param_dict = {'W1_states': W1_last, 'b1_states': b1_last,\n",
      "                'W1_grad': grad_W1_last, 'b1_grad': grad_b1_last}\n",
      "            return last_param_dict, XQW_mini_batch\n",
      "        if last_mini_batch_params_dict is not None:\n",
      "            init_params_dict = last_mini_batch_params_dict\n",
      "        else:\n",
      "            init_params_dict = {'W1_states': torch.tile(self.W1.unsqueeze(0\n",
      "                ), dims=(B, 1, 1, 1)), 'b1_states': torch.tile(self.b1.\n",
      "                unsqueeze(0), dims=(B, 1, 1, 1))}\n",
      "            init_params_dict.update(W1_grad=torch.zeros_like(\n",
      "                init_params_dict['W1_states']))\n",
      "            init_params_dict.update(b1_grad=torch.zeros_like(\n",
      "                init_params_dict['b1_states']))\n",
      "        inputs = tree_map(lambda x: x.permute(2, 0, 1, 3, 4), inputs)\n",
      "        XQW_batch = torch.empty((num_mini_batch, B, self.num_heads,\n",
      "            mini_batch_size, self.head_dim), device=device, dtype=dtype)\n",
      "        batch_params_dict, XQW_batch = scan(compute_mini_batch,\n",
      "            init_params_dict, inputs, XQW_batch, self.\n",
      "            scan_checkpoint_group_size if self.training else 0)\n",
      "        XQW_batch = XQW_batch.permute(1, 0, 3, 2, 4)\n",
      "        XQW_batch = XQW_batch.reshape(B, L, self.width)\n",
      "        return XQW_batch, batch_params_dict\n",
      "\n",
      "    def forward(self, hidden_states: torch.Tensor, position_ids: Optional[\n",
      "        torch.LongTensor]=None):\n",
      "        B, L = hidden_states.shape[:2]\n",
      "        reminder_len = L % self.mini_batch_size\n",
      "        num_mini_batch = L // self.mini_batch_size\n",
      "        last_mini_batch_params_dict = None\n",
      "        XQ, XK, XV = self.get_qkv_projections(hidden_states)\n",
      "        XQ = XQ.reshape(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "        XK = XK.reshape(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "        XV = XV.reshape(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n",
      "        cos, sin = self.rotary_emb(XV, position_ids % self.mini_batch_size)\n",
      "        XQ, XK = permute_qk(XQ, XK)\n",
      "        XQ, XK = apply_rotary_pos_emb(XQ, XK, cos, sin)\n",
      "        XQ, XK = undo_permute_qk(XQ, XK)\n",
      "        output_hidden_states = []\n",
      "        if num_mini_batch > 0:\n",
      "            inputs = {'XQ': XQ[:, :, :num_mini_batch * self.mini_batch_size\n",
      "                ], 'XK': XK[:, :, :num_mini_batch * self.mini_batch_size],\n",
      "                'XV': XV[:, :, :num_mini_batch * self.mini_batch_size], 'X':\n",
      "                hidden_states[:, :num_mini_batch * self.mini_batch_size]}\n",
      "            output_mod, last_mini_batch_params_dict = self.ttt(self.\n",
      "                get_ttt_inputs(inputs, self.mini_batch_size),\n",
      "                mini_batch_size=self.mini_batch_size,\n",
      "                last_mini_batch_params_dict=last_mini_batch_params_dict)\n",
      "            output_hidden_states.append(output_mod)\n",
      "        if reminder_len > 0:\n",
      "            inputs = {'XQ': XQ[:, :, -reminder_len:], 'XK': XK[:, :, -\n",
      "                reminder_len:], 'XV': XV[:, :, -reminder_len:], 'X':\n",
      "                hidden_states[:, -reminder_len:]}\n",
      "            output_reminder, _ = self.ttt(self.get_ttt_inputs(inputs,\n",
      "                reminder_len), mini_batch_size=reminder_len,\n",
      "                last_mini_batch_params_dict=last_mini_batch_params_dict)\n",
      "            output_hidden_states.append(output_reminder)\n",
      "        output_hidden_states = torch.cat(output_hidden_states, dim=1)\n",
      "        output_hidden_states = self.post_norm(output_hidden_states)\n",
      "        output_hidden_states = self.o_proj(output_hidden_states)\n",
      "        return output_hidden_states\n",
      "\n",
      "\n",
      "class GAB(GABBase):\n",
      "    \"\"\"Generalized Autoregressive Block\n",
      "        Input:        X: (batch, seqlen, embed_dim)\n",
      "        Output:       Y: (batch, seqlen, embed_dim)\n",
      "        Constraints:  Causal, differentiable, parameter number, complexity, parallelizable\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, embed_dim: int, block_loc, device=None, dtype=None,\n",
      "        scan_checkpoint_group_size=4, conv_kernel=4, mini_batch_size=16,\n",
      "        rope_theta=10000.0, rms_norm_eps=1e-06, ttt_base_lr=1.0, **kwargs):\n",
      "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "        super().__init__(embed_dim, block_loc)\n",
      "        self.hidden_size = embed_dim\n",
      "        num_attention_heads = max(4, embed_dim // 64)\n",
      "        self.seq_modeling_block = TTTLinear(hidden_size=embed_dim,\n",
      "            num_attention_heads=num_attention_heads,\n",
      "            scan_checkpoint_group_size=scan_checkpoint_group_size,\n",
      "            conv_kernel=conv_kernel, mini_batch_size=mini_batch_size,\n",
      "            rope_theta=rope_theta, ttt_base_lr=ttt_base_lr)\n",
      "        self.mlp = SwiGluMLP(embed_dim, int(embed_dim * 2.5))\n",
      "        self.conv = Conv(embed_dim, conv_kernel, rms_norm_eps)\n",
      "        self.seq_norm = RMSNorm(embed_dim, eps=rms_norm_eps)\n",
      "        self.ffn_norm = RMSNorm(embed_dim, eps=rms_norm_eps)\n",
      "        self.seq_modeling_block = self.seq_modeling_block.to(device=device,\n",
      "            dtype=dtype)\n",
      "        self.mlp = self.mlp.to(device=device, dtype=dtype)\n",
      "        self.conv = self.conv.to(device=device, dtype=dtype)\n",
      "        self.seq_norm = self.seq_norm.to(device=device, dtype=dtype)\n",
      "        self.ffn_norm = self.ffn_norm.to(device=device, dtype=dtype)\n",
      "\n",
      "    def _forward(self, X, *Z, **intermediate_vars):\n",
      "        hidden_states = X\n",
      "        position_ids = torch.arange(0, X.shape[1], dtype=torch.long, device\n",
      "            =X.device).unsqueeze(0)\n",
      "        residual = hidden_states\n",
      "        hidden_states = self.conv(hidden_states)\n",
      "        hidden_states = residual + hidden_states\n",
      "        residual = hidden_states\n",
      "        hidden_states = self.seq_norm(hidden_states)\n",
      "        hidden_states = self.seq_modeling_block(hidden_states, position_ids)\n",
      "        hidden_states = residual + hidden_states\n",
      "        residual = hidden_states\n",
      "        hidden_states = self.ffn_norm(hidden_states)\n",
      "        hidden_states = self.mlp(hidden_states)\n",
      "        hidden_states = residual + hidden_states\n",
      "        return hidden_states\n",
      "\n",
      "\n",
      "gab_config = {'scan_checkpoint_group_size': 0, 'conv_kernel': 4,\n",
      "    'mini_batch_size': 16, 'rope_theta': 10000.0, 'rms_norm_eps': 1e-06,\n",
      "    'ttt_base_lr': 1.0}\n",
      "\n",
      "\n",
      "\n",
      "Code format is correct and reformatted.\n",
      "\n",
      "\n",
      "Warnings:\n",
      "\n",
      "The \"__init__\" method of \"GAB\" is missing the \"block_loc\" argument. Automatically added by the reformatter.\n",
      "\n",
      "The super().__init__(embed_dim, block_loc) call in GAB is force overwritten by the reformatter. It may cause error if you modified this line.\n",
      "\n",
      "The \"_forward\" method of \"GAB\" is missing the \"**intermediate_vars\" argument. Automatically adding the argument.\n",
      "\n",
      "The statement \"logger = logging.get_logger(__name__)\" is removed by the reformatter.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/8TBNVME/home/junyanc/model_discovery/notebooks/../model_discovery/model/utils/modules.py:27: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert X.shape[-1] == self.embed_dim\n",
      "<string>:415: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "<string>:162: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "<string>:425: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/media/8TBNVME/home/junyanc/model_discovery/notebooks/../model_discovery/model/utils/modules.py:33: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert Y.shape == X.shape, f\"GAB Output shape must be the same as input shape, got {Y.shape} instead\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.fx\n",
    "from types import MethodType\n",
    "from dataclasses import dataclass\n",
    "import copy\n",
    "from functools import partial\n",
    "\n",
    "torch._dynamo.config.cache_size_limit = 64  # Increase the limit as needed\n",
    "\n",
    "\n",
    "# Redefining the necessary classes with torch imports\n",
    "\n",
    "\n",
    "class ModuleNode:\n",
    "    def __init__(self, name, graph_module=None,kwarg=None):\n",
    "        self.name = name\n",
    "        self.graph_module = graph_module\n",
    "        self.children = []\n",
    "        self.kwargs = kwarg\n",
    "\n",
    "    def print_tree(self, indent=\"\"):\n",
    "        print(indent + self.name)\n",
    "        if self.graph_module:\n",
    "            print(indent + \"  (GraphModule captured)\")#, self.graph_module)\n",
    "        for child in self.children:\n",
    "            child.print_tree(indent + \"  \")\n",
    "\n",
    "@dataclass\n",
    "class BlockAnalysis:\n",
    "    root: ModuleNode\n",
    "    nodes: dict\n",
    "    config: GAMConfig\n",
    "\n",
    "class BlockAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.module_tree_root = None\n",
    "        self.current_inputs = {}  # To store inputs for each module during forward pass\n",
    "        self.current_nodes = {}  # To store ModuleNode instances for each module by path\n",
    "\n",
    "    def track_input_wrapper(self, original_forward, module_path):\n",
    "        # Custom wrapper for the forward method to capture both positional and keyword arguments\n",
    "        def wrapped_forward(module_self, *inputs, **kwargs):\n",
    "            self.current_inputs[module_path] = (inputs, kwargs)\n",
    "            # Call the original forward method without re-binding `self`\n",
    "            return original_forward(*inputs, **kwargs)\n",
    "\n",
    "        return wrapped_forward\n",
    "\n",
    "    def wrap_forward_methods(self, model,wrapper):\n",
    "        # Replace the forward method of each submodule with the custom wrapped version\n",
    "        for module_path, module in self._get_full_module_paths(model):\n",
    "            original_forward = module.forward\n",
    "            module.forward = MethodType(wrapper(original_forward, module_path), module)\n",
    "\n",
    "    def _get_full_module_paths(self, model):\n",
    "        # Recursively generate the full path for each module in the model\n",
    "        module_paths = []\n",
    "\n",
    "        def recursive_collect_modules(parent, prefix):\n",
    "            for name, module in parent.named_children():\n",
    "                full_path = f\"{prefix}.{name}\" if prefix else name\n",
    "                module_paths.append((full_path, module))\n",
    "                recursive_collect_modules(module, full_path)\n",
    "\n",
    "        recursive_collect_modules(model, \"\")\n",
    "        return module_paths\n",
    "\n",
    "    def analyze_submodule(self, module_path, module):\n",
    "        # Retrieve the inputs and kwargs for this module captured during the forward pass\n",
    "        inputs, kwargs = self.current_inputs.get(module_path, (None, None))\n",
    "\n",
    "        module = copy.deepcopy(module)\n",
    "        if inputs is None:\n",
    "            return None\n",
    "        if kwargs:\n",
    "            for key in kwargs:\n",
    "                try:\n",
    "                    kwargs[key] = kwargs[key].detach()\n",
    "                except:\n",
    "                    pass\n",
    "            module.forward=partial(module.forward,**kwargs)\n",
    "\n",
    "        # Trace the current module with the captured inputs and kwargs\n",
    "        if isinstance(inputs,tuple):\n",
    "            new_inputs = []\n",
    "            for inp in inputs:\n",
    "                try:\n",
    "                    new_inputs.append(inp.detach())\n",
    "                except:\n",
    "                    new_inputs.append(inp)\n",
    "            inputs = tuple(new_inputs)\n",
    "        else:\n",
    "            try:\n",
    "                inputs = inputs.detach()\n",
    "            except:\n",
    "                pass\n",
    "        traced_module = torch.jit.trace(module, inputs)\n",
    "        # Create a ModuleNode for the current module\n",
    "        node = ModuleNode(module_path, traced_module, kwargs)\n",
    "        self.current_nodes[module_path] = node\n",
    "\n",
    "        # Recursively trace submodules\n",
    "        for name, submodule in module.named_children():\n",
    "            child_path = f\"{module_path}.{name}\"\n",
    "            child_node = self.analyze_submodule(child_path.replace('root.',''), submodule)\n",
    "            if child_node is not None:\n",
    "                node.children.append(child_node)\n",
    "\n",
    "        return node\n",
    "\n",
    "    def analyze(self, model, cfg):\n",
    "        # Wrap the forward methods to capture both positional and keyword arguments\n",
    "        self.current_inputs = {}\n",
    "        self.current_nodes = {}\n",
    "        model_wrap = copy.deepcopy(model)   \n",
    "        self.wrap_forward_methods(model_wrap,self.track_input_wrapper)\n",
    "\n",
    "        # Run the model with an example input\n",
    "        input_tensor = torch.randn(2, 100, cfg.d_model)\n",
    "        model_wrap(input_tensor)  # This will trigger the wrapped forward methods and capture inputs\n",
    "        del model_wrap\n",
    "        \n",
    "        # Start with the root module and analyze it recursively\n",
    "        self.current_inputs['root'] = (input_tensor, None)\n",
    "        self.module_tree_root = self.analyze_submodule('root', model)\n",
    "\n",
    "        return BlockAnalysis(self.module_tree_root, self.current_nodes, cfg)\n",
    "\n",
    "# This update removes the re-binding of `self` and directly calls the original forward method with the provided inputs and kwargs.\n",
    "\n",
    "# Example usage:\n",
    "gab,cfg = load_gab('ttt')\n",
    "analyzer = BlockAnalyzer()\n",
    "analysis = analyzer.analyze(gab, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.builtins.___torch_mangle_32.TTTLinear,\n",
      "      %hidden_states : Float(2, 100, 128, strides=[12800, 128, 1], requires_grad=0, device=cpu),\n",
      "      %position_ids.1 : Long(1, 100, strides=[100, 1], requires_grad=0, device=cpu)):\n",
      "  %o_proj : __torch__.torch.nn.modules.linear.___torch_mangle_29.Linear = prim::GetAttr[name=\"o_proj\"](%self.1)\n",
      "  %post_norm : __torch__.torch.nn.modules.normalization.___torch_mangle_31.LayerNorm = prim::GetAttr[name=\"post_norm\"](%self.1)\n",
      "  %ttt_norm_bias : Tensor = prim::GetAttr[name=\"ttt_norm_bias\"](%self.1)\n",
      "  %ttt_norm_weight : Tensor = prim::GetAttr[name=\"ttt_norm_weight\"](%self.1)\n",
      "  %b1 : Tensor = prim::GetAttr[name=\"b1\"](%self.1)\n",
      "  %W1 : Tensor = prim::GetAttr[name=\"W1\"](%self.1)\n",
      "  %learnable_token_idx : Tensor = prim::GetAttr[name=\"learnable_token_idx\"](%self.1)\n",
      "  %token_idx : Tensor = prim::GetAttr[name=\"token_idx\"](%self.1)\n",
      "  %learnable_ttt_lr_bias : Tensor = prim::GetAttr[name=\"learnable_ttt_lr_bias\"](%self.1)\n",
      "  %learnable_ttt_lr_weight : Tensor = prim::GetAttr[name=\"learnable_ttt_lr_weight\"](%self.1)\n",
      "  %rotary_emb : __torch__.builtins.___torch_mangle_30.RotaryEmbedding = prim::GetAttr[name=\"rotary_emb\"](%self.1)\n",
      "  %v_proj : __torch__.torch.nn.modules.linear.___torch_mangle_28.Linear = prim::GetAttr[name=\"v_proj\"](%self.1)\n",
      "  %k_proj : __torch__.torch.nn.modules.linear.___torch_mangle_27.Linear = prim::GetAttr[name=\"k_proj\"](%self.1)\n",
      "  %q_proj : __torch__.torch.nn.modules.linear.___torch_mangle_26.Linear = prim::GetAttr[name=\"q_proj\"](%self.1)\n",
      "  %38 : int = prim::Constant[value=0]() # <string>:402:0\n",
      "  %39 : int = aten::size(%hidden_states, %38) # <string>:402:0\n",
      "  %B.1 : Long(device=cpu) = prim::NumToTensor(%39)\n",
      "  %75 : int = aten::Int(%B.1)\n",
      "  %66 : int = aten::Int(%B.1)\n",
      "  %57 : int = aten::Int(%B.1)\n",
      "  %41 : int = prim::Constant[value=1]() # <string>:402:0\n",
      "  %42 : int = aten::size(%hidden_states, %41) # <string>:402:0\n",
      "  %L.1 : Long(device=cpu) = prim::NumToTensor(%42)\n",
      "  %76 : int = aten::Int(%L.1)\n",
      "  %67 : int = aten::Int(%L.1)\n",
      "  %58 : int = aten::Int(%L.1)\n",
      "  %47 : int = prim::Constant[value=16]() # <string>:403:0\n",
      "  %reminder_len : Long(requires_grad=0, device=cpu) = aten::remainder(%L.1, %47) # <string>:403:0\n",
      "  %2073 : int = aten::Int(%reminder_len)\n",
      "  %1962 : int = aten::Int(%reminder_len)\n",
      "  %1929 : int = aten::Int(%reminder_len)\n",
      "  %1922 : int = aten::Int(%reminder_len)\n",
      "  %1890 : int = aten::Int(%reminder_len)\n",
      "  %1882 : int = aten::Int(%reminder_len)\n",
      "  %1874 : int = aten::Int(%reminder_len)\n",
      "  %1867 : int = aten::Int(%reminder_len)\n",
      "  %49 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %num_mini_batch.1 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%L.1, %49) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %2340 : Tensor = prim::CallMethod[name=\"forward\"](%q_proj, %hidden_states)\n",
      "  %2341 : Tensor = prim::CallMethod[name=\"forward\"](%k_proj, %hidden_states)\n",
      "  %2342 : Tensor = prim::CallMethod[name=\"forward\"](%v_proj, %hidden_states)\n",
      "  %59 : int = prim::Constant[value=4]() # <string>:407:0\n",
      "  %60 : int = prim::Constant[value=32]() # <string>:407:0\n",
      "  %61 : int[] = prim::ListConstruct(%57, %58, %59, %60)\n",
      "  %62 : Float(2, 100, 4, 32, strides=[12800, 128, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%2340, %61) # <string>:407:0\n",
      "  %63 : int = prim::Constant[value=1]() # <string>:407:0\n",
      "  %64 : int = prim::Constant[value=2]() # <string>:407:0\n",
      "  %q.1 : Float(2, 4, 100, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::transpose(%62, %63, %64) # <string>:407:0\n",
      "  %68 : int = prim::Constant[value=4]() # <string>:408:0\n",
      "  %69 : int = prim::Constant[value=32]() # <string>:408:0\n",
      "  %70 : int[] = prim::ListConstruct(%66, %67, %68, %69)\n",
      "  %71 : Float(2, 100, 4, 32, strides=[12800, 128, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%2341, %70) # <string>:408:0\n",
      "  %72 : int = prim::Constant[value=1]() # <string>:408:0\n",
      "  %73 : int = prim::Constant[value=2]() # <string>:408:0\n",
      "  %k.1 : Float(2, 4, 100, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::transpose(%71, %72, %73) # <string>:408:0\n",
      "  %77 : int = prim::Constant[value=4]() # <string>:409:0\n",
      "  %78 : int = prim::Constant[value=32]() # <string>:409:0\n",
      "  %79 : int[] = prim::ListConstruct(%75, %76, %77, %78)\n",
      "  %80 : Float(2, 100, 4, 32, strides=[12800, 128, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%2342, %79) # <string>:409:0\n",
      "  %81 : int = prim::Constant[value=1]() # <string>:409:0\n",
      "  %82 : int = prim::Constant[value=2]() # <string>:409:0\n",
      "  %XV.3 : Float(2, 4, 100, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::transpose(%80, %81, %82) # <string>:409:0\n",
      "  %84 : int = prim::Constant[value=16]() # <string>:410:0\n",
      "  %position_ids : Long(1, 100, strides=[100, 1], requires_grad=0, device=cpu) = aten::remainder(%position_ids.1, %84) # <string>:410:0\n",
      "  %2343 : (Tensor, Tensor) = prim::CallMethod[name=\"forward\"](%rotary_emb, %position_ids)\n",
      "  %2338 : Float(1, 100, 32, strides=[3200, 32, 1], requires_grad=0, device=cpu), %2339 : Float(1, 100, 32, strides=[3200, 32, 1], requires_grad=0, device=cpu) = prim::TupleUnpack(%2343)\n",
      "  %158 : int = prim::Constant[value=0]() # <string>:24:0\n",
      "  %159 : int = aten::size(%q.1, %158) # <string>:24:0\n",
      "  %bsz.1 : Long(device=cpu) = prim::NumToTensor(%159)\n",
      "  %200 : int = aten::Int(%bsz.1)\n",
      "  %190 : int = aten::Int(%bsz.1)\n",
      "  %182 : int = aten::Int(%bsz.1)\n",
      "  %172 : int = aten::Int(%bsz.1)\n",
      "  %161 : int = prim::Constant[value=1]() # <string>:24:0\n",
      "  %162 : int = aten::size(%q.1, %161) # <string>:24:0\n",
      "  %num_head.1 : Long(device=cpu) = prim::NumToTensor(%162)\n",
      "  %201 : int = aten::Int(%num_head.1)\n",
      "  %191 : int = aten::Int(%num_head.1)\n",
      "  %183 : int = aten::Int(%num_head.1)\n",
      "  %173 : int = aten::Int(%num_head.1)\n",
      "  %164 : int = prim::Constant[value=2]() # <string>:24:0\n",
      "  %165 : int = aten::size(%q.1, %164) # <string>:24:0\n",
      "  %seq_len.1 : Long(device=cpu) = prim::NumToTensor(%165)\n",
      "  %202 : int = aten::Int(%seq_len.1)\n",
      "  %192 : int = aten::Int(%seq_len.1)\n",
      "  %184 : int = aten::Int(%seq_len.1)\n",
      "  %174 : int = aten::Int(%seq_len.1)\n",
      "  %167 : int = prim::Constant[value=3]() # <string>:24:0\n",
      "  %168 : int = aten::size(%q.1, %167) # <string>:24:0\n",
      "  %head_dim.1 : Long(device=cpu) = prim::NumToTensor(%168)\n",
      "  %203 : int = aten::Int(%head_dim.1)\n",
      "  %185 : int = aten::Int(%head_dim.1)\n",
      "  %170 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %171 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%head_dim.1, %170) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %175 : int = aten::Int(%171)\n",
      "  %176 : int = prim::Constant[value=2]() # <string>:25:0\n",
      "  %177 : int[] = prim::ListConstruct(%172, %173, %174, %175, %176)\n",
      "  %178 : Float(2, 4, 100, 16, 2, strides=[12800, 32, 128, 2, 1], requires_grad=1, device=cpu) = aten::reshape(%q.1, %177) # <string>:25:0\n",
      "  %179 : int = prim::Constant[value=3]() # <string>:25:0\n",
      "  %180 : int = prim::Constant[value=4]() # <string>:25:0\n",
      "  %181 : Float(2, 4, 100, 2, 16, strides=[12800, 32, 128, 1, 2], requires_grad=1, device=cpu) = aten::transpose(%178, %179, %180) # <string>:25:0\n",
      "  %186 : int[] = prim::ListConstruct(%182, %183, %184, %185)\n",
      "  %q.3 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%181, %186) # <string>:26:0\n",
      "  %188 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %189 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%head_dim.1, %188) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %193 : int = aten::Int(%189)\n",
      "  %194 : int = prim::Constant[value=2]() # <string>:27:0\n",
      "  %195 : int[] = prim::ListConstruct(%190, %191, %192, %193, %194)\n",
      "  %196 : Float(2, 4, 100, 16, 2, strides=[12800, 32, 128, 2, 1], requires_grad=1, device=cpu) = aten::reshape(%k.1, %195) # <string>:27:0\n",
      "  %197 : int = prim::Constant[value=3]() # <string>:27:0\n",
      "  %198 : int = prim::Constant[value=4]() # <string>:27:0\n",
      "  %199 : Float(2, 4, 100, 2, 16, strides=[12800, 32, 128, 1, 2], requires_grad=1, device=cpu) = aten::transpose(%196, %197, %198) # <string>:27:0\n",
      "  %204 : int[] = prim::ListConstruct(%200, %201, %202, %203)\n",
      "  %k.3 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%199, %204) # <string>:28:0\n",
      "  %206 : int = prim::Constant[value=1]() # <string>:61:0\n",
      "  %cos : Float(1, 1, 100, 32, strides=[3200, 3200, 32, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%2338, %206) # <string>:61:0\n",
      "  %208 : int = prim::Constant[value=1]() # <string>:62:0\n",
      "  %sin : Float(1, 1, 100, 32, strides=[3200, 3200, 32, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%2339, %208) # <string>:62:0\n",
      "  %210 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::mul(%q.3, %cos) # <string>:63:0\n",
      "  %220 : int = prim::Constant[value=3]() # <string>:18:0\n",
      "  %221 : int = aten::size(%q.3, %220) # <string>:18:0\n",
      "  %222 : Long(device=cpu) = prim::NumToTensor(%221)\n",
      "  %223 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %224 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%222, %223) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %225 : int = aten::Int(%224)\n",
      "  %226 : int = prim::Constant[value=3]() # <string>:18:0\n",
      "  %227 : int = prim::Constant[value=0]() # <string>:18:0\n",
      "  %228 : int = prim::Constant[value=1]() # <string>:18:0\n",
      "  %x1.1 : Float(2, 4, 100, 16, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%q.3, %226, %227, %225, %228) # <string>:18:0\n",
      "  %239 : int = prim::Constant[value=3]() # <string>:19:0\n",
      "  %240 : int = aten::size(%q.3, %239) # <string>:19:0\n",
      "  %241 : Long(device=cpu) = prim::NumToTensor(%240)\n",
      "  %242 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %243 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%241, %242) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %244 : int = aten::Int(%243)\n",
      "  %245 : int = prim::Constant[value=3]() # <string>:19:0\n",
      "  %246 : int = prim::Constant[value=9223372036854775807]() # <string>:19:0\n",
      "  %247 : int = prim::Constant[value=1]() # <string>:19:0\n",
      "  %x2.1 : Float(2, 4, 100, 16, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%q.3, %245, %244, %246, %247) # <string>:19:0\n",
      "  %249 : Float(2, 4, 100, 16, strides=[6400, 1600, 16, 1], requires_grad=1, device=cpu) = aten::neg(%x2.1) # <string>:20:0\n",
      "  %250 : Tensor[] = prim::ListConstruct(%249, %x1.1)\n",
      "  %251 : int = prim::Constant[value=-1]() # <string>:20:0\n",
      "  %252 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::cat(%250, %251) # <string>:20:0\n",
      "  %253 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::mul(%252, %sin) # <string>:63:0\n",
      "  %254 : int = prim::Constant[value=1]() # <string>:63:0\n",
      "  %q : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::add(%210, %253, %254) # <string>:63:0\n",
      "  %256 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::mul(%k.3, %cos) # <string>:64:0\n",
      "  %266 : int = prim::Constant[value=3]() # <string>:18:0\n",
      "  %267 : int = aten::size(%k.3, %266) # <string>:18:0\n",
      "  %268 : Long(device=cpu) = prim::NumToTensor(%267)\n",
      "  %269 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %270 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%268, %269) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %271 : int = aten::Int(%270)\n",
      "  %272 : int = prim::Constant[value=3]() # <string>:18:0\n",
      "  %273 : int = prim::Constant[value=0]() # <string>:18:0\n",
      "  %274 : int = prim::Constant[value=1]() # <string>:18:0\n",
      "  %x1 : Float(2, 4, 100, 16, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%k.3, %272, %273, %271, %274) # <string>:18:0\n",
      "  %285 : int = prim::Constant[value=3]() # <string>:19:0\n",
      "  %286 : int = aten::size(%k.3, %285) # <string>:19:0\n",
      "  %287 : Long(device=cpu) = prim::NumToTensor(%286)\n",
      "  %288 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %289 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%287, %288) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %290 : int = aten::Int(%289)\n",
      "  %291 : int = prim::Constant[value=3]() # <string>:19:0\n",
      "  %292 : int = prim::Constant[value=9223372036854775807]() # <string>:19:0\n",
      "  %293 : int = prim::Constant[value=1]() # <string>:19:0\n",
      "  %x2 : Float(2, 4, 100, 16, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%k.3, %291, %290, %292, %293) # <string>:19:0\n",
      "  %295 : Float(2, 4, 100, 16, strides=[6400, 1600, 16, 1], requires_grad=1, device=cpu) = aten::neg(%x2) # <string>:20:0\n",
      "  %296 : Tensor[] = prim::ListConstruct(%295, %x1)\n",
      "  %297 : int = prim::Constant[value=-1]() # <string>:20:0\n",
      "  %298 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::cat(%296, %297) # <string>:20:0\n",
      "  %299 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::mul(%298, %sin) # <string>:64:0\n",
      "  %300 : int = prim::Constant[value=1]() # <string>:64:0\n",
      "  %k : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::add(%256, %299, %300) # <string>:64:0\n",
      "  %302 : int = prim::Constant[value=0]() # <string>:33:0\n",
      "  %303 : int = aten::size(%q, %302) # <string>:33:0\n",
      "  %bsz : Long(device=cpu) = prim::NumToTensor(%303)\n",
      "  %344 : int = aten::Int(%bsz)\n",
      "  %334 : int = aten::Int(%bsz)\n",
      "  %326 : int = aten::Int(%bsz)\n",
      "  %316 : int = aten::Int(%bsz)\n",
      "  %305 : int = prim::Constant[value=1]() # <string>:33:0\n",
      "  %306 : int = aten::size(%q, %305) # <string>:33:0\n",
      "  %num_head : Long(device=cpu) = prim::NumToTensor(%306)\n",
      "  %345 : int = aten::Int(%num_head)\n",
      "  %335 : int = aten::Int(%num_head)\n",
      "  %327 : int = aten::Int(%num_head)\n",
      "  %317 : int = aten::Int(%num_head)\n",
      "  %308 : int = prim::Constant[value=2]() # <string>:33:0\n",
      "  %309 : int = aten::size(%q, %308) # <string>:33:0\n",
      "  %seq_len : Long(device=cpu) = prim::NumToTensor(%309)\n",
      "  %346 : int = aten::Int(%seq_len)\n",
      "  %336 : int = aten::Int(%seq_len)\n",
      "  %328 : int = aten::Int(%seq_len)\n",
      "  %318 : int = aten::Int(%seq_len)\n",
      "  %311 : int = prim::Constant[value=3]() # <string>:33:0\n",
      "  %312 : int = aten::size(%q, %311) # <string>:33:0\n",
      "  %head_dim : Long(device=cpu) = prim::NumToTensor(%312)\n",
      "  %347 : int = aten::Int(%head_dim)\n",
      "  %329 : int = aten::Int(%head_dim)\n",
      "  %314 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %315 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%head_dim, %314) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %319 : int = aten::Int(%315)\n",
      "  %320 : int = prim::Constant[value=2]() # <string>:34:0\n",
      "  %321 : int[] = prim::ListConstruct(%316, %317, %318, %320, %319)\n",
      "  %322 : Float(2, 4, 100, 2, 16, strides=[12800, 3200, 32, 16, 1], requires_grad=1, device=cpu) = aten::reshape(%q, %321) # <string>:34:0\n",
      "  %323 : int = prim::Constant[value=3]() # <string>:34:0\n",
      "  %324 : int = prim::Constant[value=4]() # <string>:34:0\n",
      "  %325 : Float(2, 4, 100, 16, 2, strides=[12800, 3200, 32, 1, 16], requires_grad=1, device=cpu) = aten::transpose(%322, %323, %324) # <string>:34:0\n",
      "  %330 : int[] = prim::ListConstruct(%326, %327, %328, %329)\n",
      "  %XQ.3 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%325, %330) # <string>:35:0\n",
      "  %332 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %333 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%head_dim, %332) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %337 : int = aten::Int(%333)\n",
      "  %338 : int = prim::Constant[value=2]() # <string>:36:0\n",
      "  %339 : int[] = prim::ListConstruct(%334, %335, %336, %338, %337)\n",
      "  %340 : Float(2, 4, 100, 2, 16, strides=[12800, 3200, 32, 16, 1], requires_grad=1, device=cpu) = aten::reshape(%k, %339) # <string>:36:0\n",
      "  %341 : int = prim::Constant[value=3]() # <string>:36:0\n",
      "  %342 : int = prim::Constant[value=4]() # <string>:36:0\n",
      "  %343 : Float(2, 4, 100, 16, 2, strides=[12800, 3200, 32, 1, 16], requires_grad=1, device=cpu) = aten::transpose(%340, %341, %342) # <string>:36:0\n",
      "  %348 : int[] = prim::ListConstruct(%344, %345, %346, %347)\n",
      "  %XK.3 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%343, %348) # <string>:37:0\n",
      "  %352 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}]() # <string>:416:0\n",
      "  %353 : Long(requires_grad=0, device=cpu) = aten::mul(%num_mini_batch.1, %352) # <string>:416:0\n",
      "  %364 : int = aten::Int(%353)\n",
      "  %354 : int = prim::Constant[value=0]() # <string>:416:0\n",
      "  %355 : int = prim::Constant[value=0]() # <string>:416:0\n",
      "  %356 : int = prim::Constant[value=9223372036854775807]() # <string>:416:0\n",
      "  %357 : int = prim::Constant[value=1]() # <string>:416:0\n",
      "  %358 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%XQ.3, %354, %355, %356, %357) # <string>:416:0\n",
      "  %359 : int = prim::Constant[value=1]() # <string>:416:0\n",
      "  %360 : int = prim::Constant[value=0]() # <string>:416:0\n",
      "  %361 : int = prim::Constant[value=9223372036854775807]() # <string>:416:0\n",
      "  %362 : int = prim::Constant[value=1]() # <string>:416:0\n",
      "  %363 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%358, %359, %360, %361, %362) # <string>:416:0\n",
      "  %365 : int = prim::Constant[value=2]() # <string>:416:0\n",
      "  %366 : int = prim::Constant[value=0]() # <string>:416:0\n",
      "  %367 : int = prim::Constant[value=1]() # <string>:416:0\n",
      "  %XQ.5 : Float(2, 4, 96, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%363, %365, %366, %364, %367) # <string>:416:0\n",
      "  %369 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}]() # <string>:417:0\n",
      "  %370 : Long(requires_grad=0, device=cpu) = aten::mul(%num_mini_batch.1, %369) # <string>:417:0\n",
      "  %381 : int = aten::Int(%370)\n",
      "  %371 : int = prim::Constant[value=0]() # <string>:417:0\n",
      "  %372 : int = prim::Constant[value=0]() # <string>:417:0\n",
      "  %373 : int = prim::Constant[value=9223372036854775807]() # <string>:417:0\n",
      "  %374 : int = prim::Constant[value=1]() # <string>:417:0\n",
      "  %375 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%XK.3, %371, %372, %373, %374) # <string>:417:0\n",
      "  %376 : int = prim::Constant[value=1]() # <string>:417:0\n",
      "  %377 : int = prim::Constant[value=0]() # <string>:417:0\n",
      "  %378 : int = prim::Constant[value=9223372036854775807]() # <string>:417:0\n",
      "  %379 : int = prim::Constant[value=1]() # <string>:417:0\n",
      "  %380 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%375, %376, %377, %378, %379) # <string>:417:0\n",
      "  %382 : int = prim::Constant[value=2]() # <string>:417:0\n",
      "  %383 : int = prim::Constant[value=0]() # <string>:417:0\n",
      "  %384 : int = prim::Constant[value=1]() # <string>:417:0\n",
      "  %XK.5 : Float(2, 4, 96, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%380, %382, %383, %381, %384) # <string>:417:0\n",
      "  %386 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}]() # <string>:418:0\n",
      "  %387 : Long(requires_grad=0, device=cpu) = aten::mul(%num_mini_batch.1, %386) # <string>:418:0\n",
      "  %398 : int = aten::Int(%387)\n",
      "  %388 : int = prim::Constant[value=0]() # <string>:418:0\n",
      "  %389 : int = prim::Constant[value=0]() # <string>:418:0\n",
      "  %390 : int = prim::Constant[value=9223372036854775807]() # <string>:418:0\n",
      "  %391 : int = prim::Constant[value=1]() # <string>:418:0\n",
      "  %392 : Float(2, 4, 100, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::slice(%XV.3, %388, %389, %390, %391) # <string>:418:0\n",
      "  %393 : int = prim::Constant[value=1]() # <string>:418:0\n",
      "  %394 : int = prim::Constant[value=0]() # <string>:418:0\n",
      "  %395 : int = prim::Constant[value=9223372036854775807]() # <string>:418:0\n",
      "  %396 : int = prim::Constant[value=1]() # <string>:418:0\n",
      "  %397 : Float(2, 4, 100, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::slice(%392, %393, %394, %395, %396) # <string>:418:0\n",
      "  %399 : int = prim::Constant[value=2]() # <string>:418:0\n",
      "  %400 : int = prim::Constant[value=0]() # <string>:418:0\n",
      "  %401 : int = prim::Constant[value=1]() # <string>:418:0\n",
      "  %XV.5 : Float(2, 4, 96, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::slice(%397, %399, %400, %398, %401) # <string>:418:0\n",
      "  %403 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}]() # <string>:419:0\n",
      "  %404 : Long(requires_grad=0, device=cpu) = aten::mul(%num_mini_batch.1, %403) # <string>:419:0\n",
      "  %410 : int = aten::Int(%404)\n",
      "  %405 : int = prim::Constant[value=0]() # <string>:419:0\n",
      "  %406 : int = prim::Constant[value=0]() # <string>:419:0\n",
      "  %407 : int = prim::Constant[value=9223372036854775807]() # <string>:419:0\n",
      "  %408 : int = prim::Constant[value=1]() # <string>:419:0\n",
      "  %409 : Float(2, 100, 128, strides=[12800, 128, 1], requires_grad=0, device=cpu) = aten::slice(%hidden_states, %405, %406, %407, %408) # <string>:419:0\n",
      "  %411 : int = prim::Constant[value=1]() # <string>:419:0\n",
      "  %412 : int = prim::Constant[value=0]() # <string>:419:0\n",
      "  %413 : int = prim::Constant[value=1]() # <string>:419:0\n",
      "  %X.1 : Float(2, 96, 128, strides=[12800, 128, 1], requires_grad=0, device=cpu) = aten::slice(%409, %411, %412, %410, %413) # <string>:419:0\n",
      "  %415 : int = prim::Constant[value=0]() # <string>:300:0\n",
      "  %416 : int = aten::size(%X.1, %415) # <string>:300:0\n",
      "  %B.3 : Long(device=cpu) = prim::NumToTensor(%416)\n",
      "  %452 : int = aten::Int(%B.3)\n",
      "  %443 : int = aten::Int(%B.3)\n",
      "  %434 : int = aten::Int(%B.3)\n",
      "  %426 : int = aten::Int(%B.3)\n",
      "  %418 : int = prim::Constant[value=1]() # <string>:300:0\n",
      "  %419 : int = aten::size(%X.1, %418) # <string>:300:0\n",
      "  %420 : Long(device=cpu) = prim::NumToTensor(%419)\n",
      "  %424 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %num_mini_batch.3 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%420, %424) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %427 : int = aten::Int(%num_mini_batch.3)\n",
      "  %428 : int = prim::Constant[value=16]() # <string>:302:0\n",
      "  %429 : int = prim::Constant[value=128]() # <string>:302:0\n",
      "  %430 : int[] = prim::ListConstruct(%426, %427, %428, %429)\n",
      "  %X.3 : Float(2, 6, 16, 128, strides=[12800, 2048, 128, 1], requires_grad=0, device=cpu) = aten::reshape(%X.1, %430) # <string>:302:0\n",
      "  %432 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %433 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%420, %432) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %435 : int = aten::Int(%433)\n",
      "  %436 : int = prim::Constant[value=4]() # <string>:303:0\n",
      "  %437 : int = prim::Constant[value=16]() # <string>:303:0\n",
      "  %438 : int = prim::Constant[value=32]() # <string>:303:0\n",
      "  %439 : int[] = prim::ListConstruct(%434, %436, %435, %437, %438)\n",
      "  %x.1 : Float(2, 4, 6, 16, 32, strides=[12800, 3200, 512, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%XQ.5, %439) # <string>:303:0\n",
      "  %441 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %442 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%420, %441) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %444 : int = aten::Int(%442)\n",
      "  %445 : int = prim::Constant[value=4]() # <string>:305:0\n",
      "  %446 : int = prim::Constant[value=16]() # <string>:305:0\n",
      "  %447 : int = prim::Constant[value=32]() # <string>:305:0\n",
      "  %448 : int[] = prim::ListConstruct(%443, %445, %444, %446, %447)\n",
      "  %x.3 : Float(2, 4, 6, 16, 32, strides=[12800, 3200, 512, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%XK.5, %448) # <string>:305:0\n",
      "  %450 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %451 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%420, %450) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %453 : int = aten::Int(%451)\n",
      "  %454 : int = prim::Constant[value=4]() # <string>:307:0\n",
      "  %455 : int = prim::Constant[value=16]() # <string>:307:0\n",
      "  %456 : int = prim::Constant[value=32]() # <string>:307:0\n",
      "  %457 : int[] = prim::ListConstruct(%452, %454, %453, %455, %456)\n",
      "  %x.5 : Float(2, 4, 6, 16, 32, strides=[12800, 32, 2048, 128, 1], requires_grad=1, device=cpu) = aten::reshape(%XV.5, %457) # <string>:307:0\n",
      "  %459 : str = prim::Constant[value=\"bnkc,hdc->bhnkd\"]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/functional.py:386:0\n",
      "  %460 : Tensor[] = prim::ListConstruct(%X.3, %learnable_ttt_lr_weight)\n",
      "  %461 : NoneType = prim::Constant()\n",
      "  %462 : Float(2, 4, 6, 16, 1, strides=[384, 1, 64, 4, 4], requires_grad=1, device=cpu) = aten::einsum(%459, %460, %461) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/functional.py:386:0\n",
      "  %463 : int = prim::Constant[value=1]() # <string>:282:0\n",
      "  %464 : int = prim::Constant[value=-1]() # <string>:282:0\n",
      "  %465 : int = prim::Constant[value=1]() # <string>:282:0\n",
      "  %466 : int = prim::Constant[value=1]() # <string>:282:0\n",
      "  %467 : int = prim::Constant[value=1]() # <string>:282:0\n",
      "  %468 : int[] = prim::ListConstruct(%463, %464, %465, %466, %467)\n",
      "  %469 : Float(1, 4, 1, 1, 1, strides=[4, 1, 1, 1, 1], requires_grad=1, device=cpu) = aten::reshape(%learnable_ttt_lr_bias, %468) # <string>:282:0\n",
      "  %470 : int = prim::Constant[value=1]() # <string>:281:0\n",
      "  %input.1 : Float(2, 4, 6, 16, 1, strides=[384, 1, 64, 4, 4], requires_grad=1, device=cpu) = aten::add(%462, %469, %470) # <string>:281:0\n",
      "  %ttt_lr.1 : Float(2, 4, 6, 16, 1, strides=[384, 1, 64, 4, 4], requires_grad=1, device=cpu) = aten::sigmoid(%input.1) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/nn/functional.py:2013:0\n",
      "  %473 : int = prim::Constant[value=0]() # <string>:285:0\n",
      "  %474 : int = prim::Constant[value=1]() # <string>:285:0\n",
      "  %475 : int = prim::Constant[value=2]() # <string>:285:0\n",
      "  %476 : int = prim::Constant[value=4]() # <string>:285:0\n",
      "  %477 : int = prim::Constant[value=3]() # <string>:285:0\n",
      "  %478 : int[] = prim::ListConstruct(%473, %474, %475, %476, %477)\n",
      "  %ttt_lr.3 : Float(2, 4, 6, 1, 16, strides=[384, 1, 64, 4, 4], requires_grad=1, device=cpu) = aten::permute(%ttt_lr.1, %478) # <string>:285:0\n",
      "  %480 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # <string>:286:0\n",
      "  %481 : Float(2, 4, 6, 1, 16, strides=[384, 1, 64, 4, 4], requires_grad=1, device=cpu) = aten::mul(%ttt_lr.3, %480) # <string>:286:0\n",
      "  %482 : Long(requires_grad=0, device=cpu) = prim::Constant[value={32}]() # <string>:286:0\n",
      "  %ttt_lr_eta.1 : Float(2, 4, 6, 1, 16, strides=[384, 1, 64, 4, 4], requires_grad=1, device=cpu) = aten::div(%481, %482) # <string>:286:0\n",
      "  %484 : int = prim::Constant[value=1]() # <string>:287:0\n",
      "  %token_idx.1 : Float(16, strides=[1], requires_grad=1, device=cpu) = aten::add(%token_idx, %learnable_token_idx, %484) # <string>:287:0\n",
      "  %486 : int = prim::Constant[value=0]() # <string>:288:0\n",
      "  %487 : int = prim::Constant[value=0]() # <string>:288:0\n",
      "  %488 : int = prim::Constant[value=16]() # <string>:288:0\n",
      "  %489 : int = prim::Constant[value=1]() # <string>:288:0\n",
      "  %token_idx.3 : Float(16, strides=[1], requires_grad=1, device=cpu) = aten::slice(%token_idx.1, %486, %487, %488, %489) # <string>:288:0\n",
      "  %491 : float = prim::Constant[value=0.]() # <string>:289:0\n",
      "  %token_idx.5 : Float(16, strides=[1], requires_grad=1, device=cpu) = aten::clamp_min(%token_idx.3, %491) # <string>:289:0\n",
      "  %493 : int = prim::Constant[value=1]() # <string>:290:0\n",
      "  %494 : int = prim::Constant[value=1]() # <string>:290:0\n",
      "  %495 : int = prim::Constant[value=1]() # <string>:290:0\n",
      "  %496 : int = prim::Constant[value=16]() # <string>:290:0\n",
      "  %497 : int = prim::Constant[value=1]() # <string>:290:0\n",
      "  %498 : int[] = prim::ListConstruct(%493, %494, %495, %496, %497)\n",
      "  %499 : Float(1, 1, 1, 16, 1, strides=[16, 16, 16, 1, 1], requires_grad=1, device=cpu) = aten::reshape(%token_idx.5, %498) # <string>:290:0\n",
      "  %500 : int = prim::Constant[value=0]() # <string>:291:0\n",
      "  %501 : int = aten::size(%X.3, %500) # <string>:291:0\n",
      "  %502 : Long(device=cpu) = prim::NumToTensor(%501)\n",
      "  %524 : int = aten::Int(%502)\n",
      "  %515 : int = prim::Constant[value=1]() # <string>:291:0\n",
      "  %516 : int = aten::size(%X.3, %515) # <string>:291:0\n",
      "  %517 : Long(device=cpu) = prim::NumToTensor(%516)\n",
      "  %525 : int = aten::Int(%517)\n",
      "  %526 : int = prim::Constant[value=4]() # <string>:290:0\n",
      "  %527 : int = prim::Constant[value=16]() # <string>:290:0\n",
      "  %528 : int = prim::Constant[value=1]() # <string>:290:0\n",
      "  %529 : int[] = prim::ListConstruct(%524, %526, %525, %527, %528)\n",
      "  %token_eta.1 : Float(2, 4, 6, 16, 1, strides=[0, 0, 0, 1, 1], requires_grad=1, device=cpu) = aten::broadcast_to(%499, %529) # <string>:290:0\n",
      "  %x.7 : Float(2, 4, 6, 16, 16, strides=[6144, 1, 1024, 4, 64], requires_grad=1, device=cpu) = aten::mul(%token_eta.1, %ttt_lr_eta.1) # <string>:310:0\n",
      "  %532 : int = prim::Constant[value=0]() # <string>:318:0\n",
      "  %533 : int = aten::size(%x.5, %532) # <string>:318:0\n",
      "  %B.5 : Long(device=cpu) = prim::NumToTensor(%533)\n",
      "  %1789 : int = aten::Int(%B.5)\n",
      "  %664 : int = aten::Int(%B.5)\n",
      "  %603 : int = aten::Int(%B.5)\n",
      "  %595 : int = aten::Int(%B.5)\n",
      "  %553 : int = prim::Constant[value=2]() # <string>:319:0\n",
      "  %554 : int = aten::size(%x.5, %553) # <string>:319:0\n",
      "  %num_mini_batch.5 : Long(device=cpu) = prim::NumToTensor(%554)\n",
      "  %663 : int = aten::Int(%num_mini_batch.5)\n",
      "  %568 : int = prim::Constant[value=2]() # <string>:320:0\n",
      "  %569 : int = aten::size(%x.5, %568) # <string>:320:0\n",
      "  %570 : Long(device=cpu) = prim::NumToTensor(%569)\n",
      "  %586 : int = prim::Constant[value=3]() # <string>:320:0\n",
      "  %587 : int = aten::size(%x.5, %586) # <string>:320:0\n",
      "  %588 : Long(device=cpu) = prim::NumToTensor(%587)\n",
      "  %L.3 : Long(requires_grad=0, device=cpu) = aten::mul(%570, %588) # <string>:320:0\n",
      "  %1790 : int = aten::Int(%L.3)\n",
      "  %593 : int = prim::Constant[value=0]() # <string>:383:0\n",
      "  %594 : Float(1, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%W1, %593) # <string>:383:0\n",
      "  %596 : int = prim::Constant[value=1]() # <string>:383:0\n",
      "  %597 : int = prim::Constant[value=1]() # <string>:383:0\n",
      "  %598 : int = prim::Constant[value=1]() # <string>:383:0\n",
      "  %599 : int[] = prim::ListConstruct(%595, %596, %597, %598)\n",
      "  %W1_init : Float(2, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::tile(%594, %599) # <string>:383:0\n",
      "  %601 : int = prim::Constant[value=0]() # <string>:385:0\n",
      "  %602 : Float(1, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%b1, %601) # <string>:385:0\n",
      "  %604 : int = prim::Constant[value=1]() # <string>:384:0\n",
      "  %605 : int = prim::Constant[value=1]() # <string>:384:0\n",
      "  %606 : int = prim::Constant[value=1]() # <string>:384:0\n",
      "  %607 : int[] = prim::ListConstruct(%603, %604, %605, %606)\n",
      "  %b1_init : Float(2, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::tile(%602, %607) # <string>:384:0\n",
      "  %621 : int = prim::Constant[value=2]() # <string>:390:0\n",
      "  %622 : int = prim::Constant[value=0]() # <string>:390:0\n",
      "  %623 : int = prim::Constant[value=1]() # <string>:390:0\n",
      "  %624 : int = prim::Constant[value=3]() # <string>:390:0\n",
      "  %625 : int = prim::Constant[value=4]() # <string>:390:0\n",
      "  %626 : int[] = prim::ListConstruct(%621, %622, %623, %624, %625)\n",
      "  %tensor.1 : Float(6, 2, 4, 16, 32, strides=[512, 12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::permute(%x.1, %626) # <string>:390:0\n",
      "  %628 : int = prim::Constant[value=2]() # <string>:390:0\n",
      "  %629 : int = prim::Constant[value=0]() # <string>:390:0\n",
      "  %630 : int = prim::Constant[value=1]() # <string>:390:0\n",
      "  %631 : int = prim::Constant[value=3]() # <string>:390:0\n",
      "  %632 : int = prim::Constant[value=4]() # <string>:390:0\n",
      "  %633 : int[] = prim::ListConstruct(%628, %629, %630, %631, %632)\n",
      "  %tensor.3 : Float(6, 2, 4, 16, 32, strides=[512, 12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::permute(%x.3, %633) # <string>:390:0\n",
      "  %635 : int = prim::Constant[value=2]() # <string>:390:0\n",
      "  %636 : int = prim::Constant[value=0]() # <string>:390:0\n",
      "  %637 : int = prim::Constant[value=1]() # <string>:390:0\n",
      "  %638 : int = prim::Constant[value=3]() # <string>:390:0\n",
      "  %639 : int = prim::Constant[value=4]() # <string>:390:0\n",
      "  %640 : int[] = prim::ListConstruct(%635, %636, %637, %638, %639)\n",
      "  %tensor.5 : Float(6, 2, 4, 16, 32, strides=[2048, 12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::permute(%x.5, %640) # <string>:390:0\n",
      "  %642 : int = prim::Constant[value=2]() # <string>:390:0\n",
      "  %643 : int = prim::Constant[value=0]() # <string>:390:0\n",
      "  %644 : int = prim::Constant[value=1]() # <string>:390:0\n",
      "  %645 : int = prim::Constant[value=3]() # <string>:390:0\n",
      "  %646 : int = prim::Constant[value=4]() # <string>:390:0\n",
      "  %647 : int[] = prim::ListConstruct(%642, %643, %644, %645, %646)\n",
      "  %tensor.7 : Float(6, 2, 4, 16, 16, strides=[1024, 6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::permute(%x.7, %647) # <string>:390:0\n",
      "  %665 : int = prim::Constant[value=4]() # <string>:391:0\n",
      "  %666 : int = prim::Constant[value=16]() # <string>:391:0\n",
      "  %667 : int = prim::Constant[value=32]() # <string>:391:0\n",
      "  %668 : int[] = prim::ListConstruct(%663, %664, %665, %666, %667)\n",
      "  %669 : int = prim::Constant[value=6]() # <string>:391:0\n",
      "  %670 : NoneType = prim::Constant()\n",
      "  %671 : Device = prim::Constant[value=\"cpu\"]() # <string>:391:0\n",
      "  %672 : bool = prim::Constant[value=0]() # <string>:391:0\n",
      "  %673 : NoneType = prim::Constant()\n",
      "  %out.1 : Float(6, 2, 4, 16, 32, strides=[4096, 2048, 512, 32, 1], requires_grad=0, device=cpu) = aten::empty(%668, %669, %670, %671, %672, %673) # <string>:391:0\n",
      "  %690 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %691 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %XQ_mini_batch.1 : Float(2, 4, 16, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.1, %690, %691) # <string>:169:0\n",
      "  %693 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %694 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %XK_mini_batch.1 : Float(2, 4, 16, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.3, %693, %694) # <string>:169:0\n",
      "  %696 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %697 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %XV_mini_batch.1 : Float(2, 4, 16, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::select(%tensor.5, %696, %697) # <string>:169:0\n",
      "  %699 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %700 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %eta_mini_batch.1 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::select(%tensor.7, %699, %700) # <string>:169:0\n",
      "  %708 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XK_mini_batch.1, %W1_init) # <string>:335:0\n",
      "  %709 : int = prim::Constant[value=1]() # <string>:335:0\n",
      "  %x.9 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%708, %b1_init, %709) # <string>:335:0\n",
      "  %711 : int = prim::Constant[value=1]() # <string>:336:0\n",
      "  %l2_target.1 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::sub(%XV_mini_batch.1, %XK_mini_batch.1, %711) # <string>:336:0\n",
      "  %713 : int = prim::Constant[value=4]() # <string>:337:0\n",
      "  %714 : int = prim::Constant[value=1]() # <string>:337:0\n",
      "  %715 : int = prim::Constant[value=32]() # <string>:337:0\n",
      "  %716 : int[] = prim::ListConstruct(%713, %714, %715)\n",
      "  %gamma.1 : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_weight, %716) # <string>:337:0\n",
      "  %718 : int = prim::Constant[value=4]() # <string>:339:0\n",
      "  %719 : int = prim::Constant[value=1]() # <string>:339:0\n",
      "  %720 : int = prim::Constant[value=32]() # <string>:339:0\n",
      "  %721 : int[] = prim::ListConstruct(%718, %719, %720)\n",
      "  %beta.1 : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_bias, %721) # <string>:339:0\n",
      "  %732 : int = prim::Constant[value=3]() # <string>:197:0\n",
      "  %733 : int = aten::size(%x.9, %732) # <string>:197:0\n",
      "  %D.1 : Long(device=cpu) = prim::NumToTensor(%733)\n",
      "  %735 : int = prim::Constant[value=-1]() # <string>:198:0\n",
      "  %736 : int[] = prim::ListConstruct(%735)\n",
      "  %737 : bool = prim::Constant[value=1]() # <string>:198:0\n",
      "  %738 : NoneType = prim::Constant()\n",
      "  %mu.1 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x.9, %736, %737, %738) # <string>:198:0\n",
      "  %740 : int = prim::Constant[value=-1]() # <string>:199:0\n",
      "  %741 : int[] = prim::ListConstruct(%740)\n",
      "  %742 : bool = prim::Constant[value=0]() # <string>:199:0\n",
      "  %743 : bool = prim::Constant[value=1]() # <string>:199:0\n",
      "  %var.1 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::var(%x.9, %741, %742, %743) # <string>:199:0\n",
      "  %745 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:200:0\n",
      "  %746 : int = prim::Constant[value=1]() # <string>:200:0\n",
      "  %747 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::add(%var.1, %745, %746) # <string>:200:0\n",
      "  %std.1 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%747) # <string>:200:0\n",
      "  %749 : int = prim::Constant[value=1]() # <string>:201:0\n",
      "  %750 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x.9, %mu.1, %749) # <string>:201:0\n",
      "  %x_hat.1 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%750, %std.1) # <string>:201:0\n",
      "  %752 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma.1, %x_hat.1) # <string>:202:0\n",
      "  %753 : int = prim::Constant[value=1]() # <string>:202:0\n",
      "  %y.1 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%752, %beta.1, %753) # <string>:202:0\n",
      "  %755 : int = prim::Constant[value=1]() # <string>:203:0\n",
      "  %grad_output.1 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%y.1, %l2_target.1, %755) # <string>:203:0\n",
      "  %grad_x_hat.1 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_output.1, %gamma.1) # <string>:204:0\n",
      "  %758 : Float(requires_grad=0, device=cpu) = aten::reciprocal(%D.1) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %759 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %760 : Float(requires_grad=0, device=cpu) = aten::mul(%758, %759) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %761 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%D.1, %grad_x_hat.1) # <string>:205:0\n",
      "  %762 : int = prim::Constant[value=-1]() # <string>:205:0\n",
      "  %763 : int[] = prim::ListConstruct(%762)\n",
      "  %764 : bool = prim::Constant[value=1]() # <string>:205:0\n",
      "  %765 : NoneType = prim::Constant()\n",
      "  %766 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sum(%grad_x_hat.1, %763, %764, %765) # <string>:205:0\n",
      "  %767 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %768 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%761, %766, %767) # <string>:205:0\n",
      "  %769 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_x_hat.1, %x_hat.1) # <string>:206:0\n",
      "  %770 : int = prim::Constant[value=-1]() # <string>:206:0\n",
      "  %771 : int[] = prim::ListConstruct(%770)\n",
      "  %772 : bool = prim::Constant[value=1]() # <string>:206:0\n",
      "  %773 : NoneType = prim::Constant()\n",
      "  %774 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sum(%769, %771, %772, %773) # <string>:206:0\n",
      "  %775 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%x_hat.1, %774) # <string>:206:0\n",
      "  %776 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %777 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%768, %775, %776) # <string>:205:0\n",
      "  %778 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%760, %777) # <string>:205:0\n",
      "  %grad_l_wrt_Z1.1 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%778, %std.1) # <string>:205:0\n",
      "  %780 : int = prim::Constant[value=-2]() # <string>:344:0\n",
      "  %781 : int = prim::Constant[value=-1]() # <string>:344:0\n",
      "  %782 : Float(2, 4, 32, 16, strides=[12800, 3200, 1, 32], requires_grad=1, device=cpu) = aten::transpose(%XK_mini_batch.1, %780, %781) # <string>:344:0\n",
      "  %783 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch.1, %782) # <string>:344:0\n",
      "  %784 : int = prim::Constant[value=0]() # <string>:344:0\n",
      "  %Attn1.1 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::tril(%783, %784) # <string>:344:0\n",
      "  %786 : int = prim::Constant[value=0]() # <string>:345:0\n",
      "  %787 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::tril(%eta_mini_batch.1, %786) # <string>:345:0\n",
      "  %788 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%787, %grad_l_wrt_Z1.1) # <string>:345:0\n",
      "  %789 : int = prim::Constant[value=1]() # <string>:345:0\n",
      "  %b1_bar.1 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%b1_init, %788, %789) # <string>:345:0\n",
      "  %791 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch.1, %W1_init) # <string>:346:0\n",
      "  %792 : Float(2, 4, 16, 16, strides=[1024, 1, 4, 64], requires_grad=1, device=cpu) = aten::mul(%eta_mini_batch.1, %Attn1.1) # <string>:346:0\n",
      "  %793 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%792, %grad_l_wrt_Z1.1) # <string>:346:0\n",
      "  %794 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %795 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%791, %793, %794) # <string>:346:0\n",
      "  %796 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %x.11 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%795, %b1_bar.1, %796) # <string>:346:0\n",
      "  %798 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %799 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %800 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %801 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %802 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::slice(%eta_mini_batch.1, %798, %799, %800, %801) # <string>:348:0\n",
      "  %803 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %804 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %805 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %806 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %807 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::slice(%802, %803, %804, %805, %806) # <string>:348:0\n",
      "  %808 : int = prim::Constant[value=2]() # <string>:348:0\n",
      "  %809 : int = prim::Constant[value=-1]() # <string>:348:0\n",
      "  %810 : Float(2, 4, 16, strides=[6144, 1, 64], requires_grad=1, device=cpu) = aten::select(%807, %808, %809) # <string>:348:0\n",
      "  %811 : int = prim::Constant[value=2]() # <string>:348:0\n",
      "  %812 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %813 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %814 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %815 : Float(2, 4, 16, strides=[6144, 1, 64], requires_grad=1, device=cpu) = aten::slice(%810, %811, %812, %813, %814) # <string>:348:0\n",
      "  %816 : int = prim::Constant[value=3]() # <string>:348:0\n",
      "  %last_eta_mini_batch.1 : Float(2, 4, 16, 1, strides=[6144, 1, 64, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%815, %816) # <string>:348:0\n",
      "  %818 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::mul(%last_eta_mini_batch.1, %XK_mini_batch.1) # <string>:349:0\n",
      "  %819 : int = prim::Constant[value=-1]() # <string>:349:0\n",
      "  %820 : int = prim::Constant[value=-2]() # <string>:349:0\n",
      "  %821 : Float(2, 4, 32, 16, strides=[2048, 32, 1, 128], requires_grad=1, device=cpu) = aten::transpose(%818, %819, %820) # <string>:349:0\n",
      "  %822 : Float(2, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%821, %grad_l_wrt_Z1.1) # <string>:349:0\n",
      "  %823 : int = prim::Constant[value=1]() # <string>:349:0\n",
      "  %W1_last.1 : Float(2, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::sub(%W1_init, %822, %823) # <string>:349:0\n",
      "  %825 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::mul(%last_eta_mini_batch.1, %grad_l_wrt_Z1.1) # <string>:351:0\n",
      "  %826 : int = prim::Constant[value=-2]() # <string>:351:0\n",
      "  %827 : int[] = prim::ListConstruct(%826)\n",
      "  %828 : bool = prim::Constant[value=1]() # <string>:351:0\n",
      "  %829 : NoneType = prim::Constant()\n",
      "  %830 : Float(2, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::sum(%825, %827, %828, %829) # <string>:351:0\n",
      "  %831 : int = prim::Constant[value=1]() # <string>:351:0\n",
      "  %b1_last.1 : Float(2, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::sub(%b1_init, %830, %831) # <string>:351:0\n",
      "  %845 : int = prim::Constant[value=-1]() # <string>:187:0\n",
      "  %846 : int[] = prim::ListConstruct(%845)\n",
      "  %847 : bool = prim::Constant[value=1]() # <string>:187:0\n",
      "  %848 : NoneType = prim::Constant()\n",
      "  %mu.3 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x.11, %846, %847, %848) # <string>:187:0\n",
      "  %850 : int = prim::Constant[value=-1]() # <string>:188:0\n",
      "  %851 : int[] = prim::ListConstruct(%850)\n",
      "  %852 : bool = prim::Constant[value=0]() # <string>:188:0\n",
      "  %853 : bool = prim::Constant[value=1]() # <string>:188:0\n",
      "  %var.3 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::var(%x.11, %851, %852, %853) # <string>:188:0\n",
      "  %855 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:189:0\n",
      "  %856 : int = prim::Constant[value=1]() # <string>:189:0\n",
      "  %857 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::add(%var.3, %855, %856) # <string>:189:0\n",
      "  %std.3 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%857) # <string>:189:0\n",
      "  %859 : int = prim::Constant[value=1]() # <string>:190:0\n",
      "  %860 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x.11, %mu.3, %859) # <string>:190:0\n",
      "  %x_hat.3 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%860, %std.3) # <string>:190:0\n",
      "  %862 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma.1, %x_hat.3) # <string>:191:0\n",
      "  %863 : int = prim::Constant[value=1]() # <string>:191:0\n",
      "  %Z1_bar.1 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%862, %beta.1, %863) # <string>:191:0\n",
      "  %865 : int = prim::Constant[value=1]() # <string>:376:0\n",
      "  %y.3 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%XQ_mini_batch.1, %Z1_bar.1, %865) # <string>:376:0\n",
      "  %867 : int = prim::Constant[value=0]() # <string>:173:0\n",
      "  %868 : int = prim::Constant[value=0]() # <string>:173:0\n",
      "  %869 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=0, device=cpu) = aten::select(%out.1, %867, %868) # <string>:173:0\n",
      "  %870 : bool = prim::Constant[value=0]()\n",
      "  %871 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::copy_(%869, %y.3, %870) # <string>:173:0\n",
      "  %872 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %873 : int = prim::Constant[value=1]() # <string>:169:0\n",
      "  %XQ_mini_batch.3 : Float(2, 4, 16, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.1, %872, %873) # <string>:169:0\n",
      "  %875 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %876 : int = prim::Constant[value=1]() # <string>:169:0\n",
      "  %XK_mini_batch.3 : Float(2, 4, 16, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.3, %875, %876) # <string>:169:0\n",
      "  %878 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %879 : int = prim::Constant[value=1]() # <string>:169:0\n",
      "  %XV_mini_batch.3 : Float(2, 4, 16, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::select(%tensor.5, %878, %879) # <string>:169:0\n",
      "  %881 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %882 : int = prim::Constant[value=1]() # <string>:169:0\n",
      "  %eta_mini_batch.3 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::select(%tensor.7, %881, %882) # <string>:169:0\n",
      "  %890 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XK_mini_batch.3, %W1_last.1) # <string>:335:0\n",
      "  %891 : int = prim::Constant[value=1]() # <string>:335:0\n",
      "  %x.13 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%890, %b1_last.1, %891) # <string>:335:0\n",
      "  %893 : int = prim::Constant[value=1]() # <string>:336:0\n",
      "  %l2_target.3 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::sub(%XV_mini_batch.3, %XK_mini_batch.3, %893) # <string>:336:0\n",
      "  %895 : int = prim::Constant[value=4]() # <string>:337:0\n",
      "  %896 : int = prim::Constant[value=1]() # <string>:337:0\n",
      "  %897 : int = prim::Constant[value=32]() # <string>:337:0\n",
      "  %898 : int[] = prim::ListConstruct(%895, %896, %897)\n",
      "  %gamma.3 : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_weight, %898) # <string>:337:0\n",
      "  %900 : int = prim::Constant[value=4]() # <string>:339:0\n",
      "  %901 : int = prim::Constant[value=1]() # <string>:339:0\n",
      "  %902 : int = prim::Constant[value=32]() # <string>:339:0\n",
      "  %903 : int[] = prim::ListConstruct(%900, %901, %902)\n",
      "  %beta.3 : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_bias, %903) # <string>:339:0\n",
      "  %914 : int = prim::Constant[value=3]() # <string>:197:0\n",
      "  %915 : int = aten::size(%x.13, %914) # <string>:197:0\n",
      "  %D.3 : Long(device=cpu) = prim::NumToTensor(%915)\n",
      "  %917 : int = prim::Constant[value=-1]() # <string>:198:0\n",
      "  %918 : int[] = prim::ListConstruct(%917)\n",
      "  %919 : bool = prim::Constant[value=1]() # <string>:198:0\n",
      "  %920 : NoneType = prim::Constant()\n",
      "  %mu.5 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x.13, %918, %919, %920) # <string>:198:0\n",
      "  %922 : int = prim::Constant[value=-1]() # <string>:199:0\n",
      "  %923 : int[] = prim::ListConstruct(%922)\n",
      "  %924 : bool = prim::Constant[value=0]() # <string>:199:0\n",
      "  %925 : bool = prim::Constant[value=1]() # <string>:199:0\n",
      "  %var.5 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::var(%x.13, %923, %924, %925) # <string>:199:0\n",
      "  %927 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:200:0\n",
      "  %928 : int = prim::Constant[value=1]() # <string>:200:0\n",
      "  %929 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::add(%var.5, %927, %928) # <string>:200:0\n",
      "  %std.5 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%929) # <string>:200:0\n",
      "  %931 : int = prim::Constant[value=1]() # <string>:201:0\n",
      "  %932 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x.13, %mu.5, %931) # <string>:201:0\n",
      "  %x_hat.5 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%932, %std.5) # <string>:201:0\n",
      "  %934 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma.3, %x_hat.5) # <string>:202:0\n",
      "  %935 : int = prim::Constant[value=1]() # <string>:202:0\n",
      "  %y.5 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%934, %beta.3, %935) # <string>:202:0\n",
      "  %937 : int = prim::Constant[value=1]() # <string>:203:0\n",
      "  %grad_output.3 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%y.5, %l2_target.3, %937) # <string>:203:0\n",
      "  %grad_x_hat.3 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_output.3, %gamma.3) # <string>:204:0\n",
      "  %940 : Float(requires_grad=0, device=cpu) = aten::reciprocal(%D.3) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %941 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %942 : Float(requires_grad=0, device=cpu) = aten::mul(%940, %941) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %943 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%D.3, %grad_x_hat.3) # <string>:205:0\n",
      "  %944 : int = prim::Constant[value=-1]() # <string>:205:0\n",
      "  %945 : int[] = prim::ListConstruct(%944)\n",
      "  %946 : bool = prim::Constant[value=1]() # <string>:205:0\n",
      "  %947 : NoneType = prim::Constant()\n",
      "  %948 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sum(%grad_x_hat.3, %945, %946, %947) # <string>:205:0\n",
      "  %949 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %950 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%943, %948, %949) # <string>:205:0\n",
      "  %951 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_x_hat.3, %x_hat.5) # <string>:206:0\n",
      "  %952 : int = prim::Constant[value=-1]() # <string>:206:0\n",
      "  %953 : int[] = prim::ListConstruct(%952)\n",
      "  %954 : bool = prim::Constant[value=1]() # <string>:206:0\n",
      "  %955 : NoneType = prim::Constant()\n",
      "  %956 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sum(%951, %953, %954, %955) # <string>:206:0\n",
      "  %957 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%x_hat.5, %956) # <string>:206:0\n",
      "  %958 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %959 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%950, %957, %958) # <string>:205:0\n",
      "  %960 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%942, %959) # <string>:205:0\n",
      "  %grad_l_wrt_Z1.3 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%960, %std.5) # <string>:205:0\n",
      "  %962 : int = prim::Constant[value=-2]() # <string>:344:0\n",
      "  %963 : int = prim::Constant[value=-1]() # <string>:344:0\n",
      "  %964 : Float(2, 4, 32, 16, strides=[12800, 3200, 1, 32], requires_grad=1, device=cpu) = aten::transpose(%XK_mini_batch.3, %962, %963) # <string>:344:0\n",
      "  %965 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch.3, %964) # <string>:344:0\n",
      "  %966 : int = prim::Constant[value=0]() # <string>:344:0\n",
      "  %Attn1.3 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::tril(%965, %966) # <string>:344:0\n",
      "  %968 : int = prim::Constant[value=0]() # <string>:345:0\n",
      "  %969 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::tril(%eta_mini_batch.3, %968) # <string>:345:0\n",
      "  %970 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%969, %grad_l_wrt_Z1.3) # <string>:345:0\n",
      "  %971 : int = prim::Constant[value=1]() # <string>:345:0\n",
      "  %b1_bar.3 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%b1_last.1, %970, %971) # <string>:345:0\n",
      "  %973 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch.3, %W1_last.1) # <string>:346:0\n",
      "  %974 : Float(2, 4, 16, 16, strides=[1024, 1, 4, 64], requires_grad=1, device=cpu) = aten::mul(%eta_mini_batch.3, %Attn1.3) # <string>:346:0\n",
      "  %975 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%974, %grad_l_wrt_Z1.3) # <string>:346:0\n",
      "  %976 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %977 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%973, %975, %976) # <string>:346:0\n",
      "  %978 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %x.15 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%977, %b1_bar.3, %978) # <string>:346:0\n",
      "  %980 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %981 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %982 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %983 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %984 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::slice(%eta_mini_batch.3, %980, %981, %982, %983) # <string>:348:0\n",
      "  %985 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %986 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %987 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %988 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %989 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::slice(%984, %985, %986, %987, %988) # <string>:348:0\n",
      "  %990 : int = prim::Constant[value=2]() # <string>:348:0\n",
      "  %991 : int = prim::Constant[value=-1]() # <string>:348:0\n",
      "  %992 : Float(2, 4, 16, strides=[6144, 1, 64], requires_grad=1, device=cpu) = aten::select(%989, %990, %991) # <string>:348:0\n",
      "  %993 : int = prim::Constant[value=2]() # <string>:348:0\n",
      "  %994 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %995 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %996 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %997 : Float(2, 4, 16, strides=[6144, 1, 64], requires_grad=1, device=cpu) = aten::slice(%992, %993, %994, %995, %996) # <string>:348:0\n",
      "  %998 : int = prim::Constant[value=3]() # <string>:348:0\n",
      "  %last_eta_mini_batch.3 : Float(2, 4, 16, 1, strides=[6144, 1, 64, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%997, %998) # <string>:348:0\n",
      "  %1000 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::mul(%last_eta_mini_batch.3, %XK_mini_batch.3) # <string>:349:0\n",
      "  %1001 : int = prim::Constant[value=-1]() # <string>:349:0\n",
      "  %1002 : int = prim::Constant[value=-2]() # <string>:349:0\n",
      "  %1003 : Float(2, 4, 32, 16, strides=[2048, 32, 1, 128], requires_grad=1, device=cpu) = aten::transpose(%1000, %1001, %1002) # <string>:349:0\n",
      "  %1004 : Float(2, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%1003, %grad_l_wrt_Z1.3) # <string>:349:0\n",
      "  %1005 : int = prim::Constant[value=1]() # <string>:349:0\n",
      "  %W1_last.3 : Float(2, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::sub(%W1_last.1, %1004, %1005) # <string>:349:0\n",
      "  %1007 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::mul(%last_eta_mini_batch.3, %grad_l_wrt_Z1.3) # <string>:351:0\n",
      "  %1008 : int = prim::Constant[value=-2]() # <string>:351:0\n",
      "  %1009 : int[] = prim::ListConstruct(%1008)\n",
      "  %1010 : bool = prim::Constant[value=1]() # <string>:351:0\n",
      "  %1011 : NoneType = prim::Constant()\n",
      "  %1012 : Float(2, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::sum(%1007, %1009, %1010, %1011) # <string>:351:0\n",
      "  %1013 : int = prim::Constant[value=1]() # <string>:351:0\n",
      "  %b1_last.3 : Float(2, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::sub(%b1_last.1, %1012, %1013) # <string>:351:0\n",
      "  %1027 : int = prim::Constant[value=-1]() # <string>:187:0\n",
      "  %1028 : int[] = prim::ListConstruct(%1027)\n",
      "  %1029 : bool = prim::Constant[value=1]() # <string>:187:0\n",
      "  %1030 : NoneType = prim::Constant()\n",
      "  %mu.7 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x.15, %1028, %1029, %1030) # <string>:187:0\n",
      "  %1032 : int = prim::Constant[value=-1]() # <string>:188:0\n",
      "  %1033 : int[] = prim::ListConstruct(%1032)\n",
      "  %1034 : bool = prim::Constant[value=0]() # <string>:188:0\n",
      "  %1035 : bool = prim::Constant[value=1]() # <string>:188:0\n",
      "  %var.7 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::var(%x.15, %1033, %1034, %1035) # <string>:188:0\n",
      "  %1037 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:189:0\n",
      "  %1038 : int = prim::Constant[value=1]() # <string>:189:0\n",
      "  %1039 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::add(%var.7, %1037, %1038) # <string>:189:0\n",
      "  %std.7 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%1039) # <string>:189:0\n",
      "  %1041 : int = prim::Constant[value=1]() # <string>:190:0\n",
      "  %1042 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x.15, %mu.7, %1041) # <string>:190:0\n",
      "  %x_hat.7 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%1042, %std.7) # <string>:190:0\n",
      "  %1044 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma.3, %x_hat.7) # <string>:191:0\n",
      "  %1045 : int = prim::Constant[value=1]() # <string>:191:0\n",
      "  %Z1_bar.3 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1044, %beta.3, %1045) # <string>:191:0\n",
      "  %1047 : int = prim::Constant[value=1]() # <string>:376:0\n",
      "  %y.7 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%XQ_mini_batch.3, %Z1_bar.3, %1047) # <string>:376:0\n",
      "  %1049 : int = prim::Constant[value=0]() # <string>:173:0\n",
      "  %1050 : int = prim::Constant[value=1]() # <string>:173:0\n",
      "  %1051 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::select(%out.1, %1049, %1050) # <string>:173:0\n",
      "  %1052 : bool = prim::Constant[value=0]()\n",
      "  %1053 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::copy_(%1051, %y.7, %1052) # <string>:173:0\n",
      "  %1054 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1055 : int = prim::Constant[value=2]() # <string>:169:0\n",
      "  %XQ_mini_batch.5 : Float(2, 4, 16, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.1, %1054, %1055) # <string>:169:0\n",
      "  %1057 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1058 : int = prim::Constant[value=2]() # <string>:169:0\n",
      "  %XK_mini_batch.5 : Float(2, 4, 16, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.3, %1057, %1058) # <string>:169:0\n",
      "  %1060 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1061 : int = prim::Constant[value=2]() # <string>:169:0\n",
      "  %XV_mini_batch.5 : Float(2, 4, 16, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::select(%tensor.5, %1060, %1061) # <string>:169:0\n",
      "  %1063 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1064 : int = prim::Constant[value=2]() # <string>:169:0\n",
      "  %eta_mini_batch.5 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::select(%tensor.7, %1063, %1064) # <string>:169:0\n",
      "  %1072 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XK_mini_batch.5, %W1_last.3) # <string>:335:0\n",
      "  %1073 : int = prim::Constant[value=1]() # <string>:335:0\n",
      "  %x.17 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1072, %b1_last.3, %1073) # <string>:335:0\n",
      "  %1075 : int = prim::Constant[value=1]() # <string>:336:0\n",
      "  %l2_target.5 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::sub(%XV_mini_batch.5, %XK_mini_batch.5, %1075) # <string>:336:0\n",
      "  %1077 : int = prim::Constant[value=4]() # <string>:337:0\n",
      "  %1078 : int = prim::Constant[value=1]() # <string>:337:0\n",
      "  %1079 : int = prim::Constant[value=32]() # <string>:337:0\n",
      "  %1080 : int[] = prim::ListConstruct(%1077, %1078, %1079)\n",
      "  %gamma.5 : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_weight, %1080) # <string>:337:0\n",
      "  %1082 : int = prim::Constant[value=4]() # <string>:339:0\n",
      "  %1083 : int = prim::Constant[value=1]() # <string>:339:0\n",
      "  %1084 : int = prim::Constant[value=32]() # <string>:339:0\n",
      "  %1085 : int[] = prim::ListConstruct(%1082, %1083, %1084)\n",
      "  %beta.5 : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_bias, %1085) # <string>:339:0\n",
      "  %1096 : int = prim::Constant[value=3]() # <string>:197:0\n",
      "  %1097 : int = aten::size(%x.17, %1096) # <string>:197:0\n",
      "  %D.5 : Long(device=cpu) = prim::NumToTensor(%1097)\n",
      "  %1099 : int = prim::Constant[value=-1]() # <string>:198:0\n",
      "  %1100 : int[] = prim::ListConstruct(%1099)\n",
      "  %1101 : bool = prim::Constant[value=1]() # <string>:198:0\n",
      "  %1102 : NoneType = prim::Constant()\n",
      "  %mu.9 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x.17, %1100, %1101, %1102) # <string>:198:0\n",
      "  %1104 : int = prim::Constant[value=-1]() # <string>:199:0\n",
      "  %1105 : int[] = prim::ListConstruct(%1104)\n",
      "  %1106 : bool = prim::Constant[value=0]() # <string>:199:0\n",
      "  %1107 : bool = prim::Constant[value=1]() # <string>:199:0\n",
      "  %var.9 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::var(%x.17, %1105, %1106, %1107) # <string>:199:0\n",
      "  %1109 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:200:0\n",
      "  %1110 : int = prim::Constant[value=1]() # <string>:200:0\n",
      "  %1111 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::add(%var.9, %1109, %1110) # <string>:200:0\n",
      "  %std.9 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%1111) # <string>:200:0\n",
      "  %1113 : int = prim::Constant[value=1]() # <string>:201:0\n",
      "  %1114 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x.17, %mu.9, %1113) # <string>:201:0\n",
      "  %x_hat.9 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%1114, %std.9) # <string>:201:0\n",
      "  %1116 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma.5, %x_hat.9) # <string>:202:0\n",
      "  %1117 : int = prim::Constant[value=1]() # <string>:202:0\n",
      "  %y.9 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1116, %beta.5, %1117) # <string>:202:0\n",
      "  %1119 : int = prim::Constant[value=1]() # <string>:203:0\n",
      "  %grad_output.5 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%y.9, %l2_target.5, %1119) # <string>:203:0\n",
      "  %grad_x_hat.5 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_output.5, %gamma.5) # <string>:204:0\n",
      "  %1122 : Float(requires_grad=0, device=cpu) = aten::reciprocal(%D.5) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %1123 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %1124 : Float(requires_grad=0, device=cpu) = aten::mul(%1122, %1123) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %1125 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%D.5, %grad_x_hat.5) # <string>:205:0\n",
      "  %1126 : int = prim::Constant[value=-1]() # <string>:205:0\n",
      "  %1127 : int[] = prim::ListConstruct(%1126)\n",
      "  %1128 : bool = prim::Constant[value=1]() # <string>:205:0\n",
      "  %1129 : NoneType = prim::Constant()\n",
      "  %1130 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sum(%grad_x_hat.5, %1127, %1128, %1129) # <string>:205:0\n",
      "  %1131 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %1132 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%1125, %1130, %1131) # <string>:205:0\n",
      "  %1133 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_x_hat.5, %x_hat.9) # <string>:206:0\n",
      "  %1134 : int = prim::Constant[value=-1]() # <string>:206:0\n",
      "  %1135 : int[] = prim::ListConstruct(%1134)\n",
      "  %1136 : bool = prim::Constant[value=1]() # <string>:206:0\n",
      "  %1137 : NoneType = prim::Constant()\n",
      "  %1138 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sum(%1133, %1135, %1136, %1137) # <string>:206:0\n",
      "  %1139 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%x_hat.9, %1138) # <string>:206:0\n",
      "  %1140 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %1141 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%1132, %1139, %1140) # <string>:205:0\n",
      "  %1142 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%1124, %1141) # <string>:205:0\n",
      "  %grad_l_wrt_Z1.5 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%1142, %std.9) # <string>:205:0\n",
      "  %1144 : int = prim::Constant[value=-2]() # <string>:344:0\n",
      "  %1145 : int = prim::Constant[value=-1]() # <string>:344:0\n",
      "  %1146 : Float(2, 4, 32, 16, strides=[12800, 3200, 1, 32], requires_grad=1, device=cpu) = aten::transpose(%XK_mini_batch.5, %1144, %1145) # <string>:344:0\n",
      "  %1147 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch.5, %1146) # <string>:344:0\n",
      "  %1148 : int = prim::Constant[value=0]() # <string>:344:0\n",
      "  %Attn1.5 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::tril(%1147, %1148) # <string>:344:0\n",
      "  %1150 : int = prim::Constant[value=0]() # <string>:345:0\n",
      "  %1151 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::tril(%eta_mini_batch.5, %1150) # <string>:345:0\n",
      "  %1152 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%1151, %grad_l_wrt_Z1.5) # <string>:345:0\n",
      "  %1153 : int = prim::Constant[value=1]() # <string>:345:0\n",
      "  %b1_bar.5 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%b1_last.3, %1152, %1153) # <string>:345:0\n",
      "  %1155 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch.5, %W1_last.3) # <string>:346:0\n",
      "  %1156 : Float(2, 4, 16, 16, strides=[1024, 1, 4, 64], requires_grad=1, device=cpu) = aten::mul(%eta_mini_batch.5, %Attn1.5) # <string>:346:0\n",
      "  %1157 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%1156, %grad_l_wrt_Z1.5) # <string>:346:0\n",
      "  %1158 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %1159 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%1155, %1157, %1158) # <string>:346:0\n",
      "  %1160 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %x.19 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1159, %b1_bar.5, %1160) # <string>:346:0\n",
      "  %1162 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1163 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1164 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %1165 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1166 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::slice(%eta_mini_batch.5, %1162, %1163, %1164, %1165) # <string>:348:0\n",
      "  %1167 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1168 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1169 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %1170 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1171 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::slice(%1166, %1167, %1168, %1169, %1170) # <string>:348:0\n",
      "  %1172 : int = prim::Constant[value=2]() # <string>:348:0\n",
      "  %1173 : int = prim::Constant[value=-1]() # <string>:348:0\n",
      "  %1174 : Float(2, 4, 16, strides=[6144, 1, 64], requires_grad=1, device=cpu) = aten::select(%1171, %1172, %1173) # <string>:348:0\n",
      "  %1175 : int = prim::Constant[value=2]() # <string>:348:0\n",
      "  %1176 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1177 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %1178 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1179 : Float(2, 4, 16, strides=[6144, 1, 64], requires_grad=1, device=cpu) = aten::slice(%1174, %1175, %1176, %1177, %1178) # <string>:348:0\n",
      "  %1180 : int = prim::Constant[value=3]() # <string>:348:0\n",
      "  %last_eta_mini_batch.5 : Float(2, 4, 16, 1, strides=[6144, 1, 64, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%1179, %1180) # <string>:348:0\n",
      "  %1182 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::mul(%last_eta_mini_batch.5, %XK_mini_batch.5) # <string>:349:0\n",
      "  %1183 : int = prim::Constant[value=-1]() # <string>:349:0\n",
      "  %1184 : int = prim::Constant[value=-2]() # <string>:349:0\n",
      "  %1185 : Float(2, 4, 32, 16, strides=[2048, 32, 1, 128], requires_grad=1, device=cpu) = aten::transpose(%1182, %1183, %1184) # <string>:349:0\n",
      "  %1186 : Float(2, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%1185, %grad_l_wrt_Z1.5) # <string>:349:0\n",
      "  %1187 : int = prim::Constant[value=1]() # <string>:349:0\n",
      "  %W1_last.5 : Float(2, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::sub(%W1_last.3, %1186, %1187) # <string>:349:0\n",
      "  %1189 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::mul(%last_eta_mini_batch.5, %grad_l_wrt_Z1.5) # <string>:351:0\n",
      "  %1190 : int = prim::Constant[value=-2]() # <string>:351:0\n",
      "  %1191 : int[] = prim::ListConstruct(%1190)\n",
      "  %1192 : bool = prim::Constant[value=1]() # <string>:351:0\n",
      "  %1193 : NoneType = prim::Constant()\n",
      "  %1194 : Float(2, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::sum(%1189, %1191, %1192, %1193) # <string>:351:0\n",
      "  %1195 : int = prim::Constant[value=1]() # <string>:351:0\n",
      "  %b1_last.5 : Float(2, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::sub(%b1_last.3, %1194, %1195) # <string>:351:0\n",
      "  %1209 : int = prim::Constant[value=-1]() # <string>:187:0\n",
      "  %1210 : int[] = prim::ListConstruct(%1209)\n",
      "  %1211 : bool = prim::Constant[value=1]() # <string>:187:0\n",
      "  %1212 : NoneType = prim::Constant()\n",
      "  %mu.11 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x.19, %1210, %1211, %1212) # <string>:187:0\n",
      "  %1214 : int = prim::Constant[value=-1]() # <string>:188:0\n",
      "  %1215 : int[] = prim::ListConstruct(%1214)\n",
      "  %1216 : bool = prim::Constant[value=0]() # <string>:188:0\n",
      "  %1217 : bool = prim::Constant[value=1]() # <string>:188:0\n",
      "  %var.11 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::var(%x.19, %1215, %1216, %1217) # <string>:188:0\n",
      "  %1219 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:189:0\n",
      "  %1220 : int = prim::Constant[value=1]() # <string>:189:0\n",
      "  %1221 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::add(%var.11, %1219, %1220) # <string>:189:0\n",
      "  %std.11 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%1221) # <string>:189:0\n",
      "  %1223 : int = prim::Constant[value=1]() # <string>:190:0\n",
      "  %1224 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x.19, %mu.11, %1223) # <string>:190:0\n",
      "  %x_hat.11 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%1224, %std.11) # <string>:190:0\n",
      "  %1226 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma.5, %x_hat.11) # <string>:191:0\n",
      "  %1227 : int = prim::Constant[value=1]() # <string>:191:0\n",
      "  %Z1_bar.5 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1226, %beta.5, %1227) # <string>:191:0\n",
      "  %1229 : int = prim::Constant[value=1]() # <string>:376:0\n",
      "  %y.11 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%XQ_mini_batch.5, %Z1_bar.5, %1229) # <string>:376:0\n",
      "  %1231 : int = prim::Constant[value=0]() # <string>:173:0\n",
      "  %1232 : int = prim::Constant[value=2]() # <string>:173:0\n",
      "  %1233 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::select(%out.1, %1231, %1232) # <string>:173:0\n",
      "  %1234 : bool = prim::Constant[value=0]()\n",
      "  %1235 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::copy_(%1233, %y.11, %1234) # <string>:173:0\n",
      "  %1236 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1237 : int = prim::Constant[value=3]() # <string>:169:0\n",
      "  %XQ_mini_batch.7 : Float(2, 4, 16, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.1, %1236, %1237) # <string>:169:0\n",
      "  %1239 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1240 : int = prim::Constant[value=3]() # <string>:169:0\n",
      "  %XK_mini_batch.7 : Float(2, 4, 16, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.3, %1239, %1240) # <string>:169:0\n",
      "  %1242 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1243 : int = prim::Constant[value=3]() # <string>:169:0\n",
      "  %XV_mini_batch.7 : Float(2, 4, 16, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::select(%tensor.5, %1242, %1243) # <string>:169:0\n",
      "  %1245 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1246 : int = prim::Constant[value=3]() # <string>:169:0\n",
      "  %eta_mini_batch.7 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::select(%tensor.7, %1245, %1246) # <string>:169:0\n",
      "  %1254 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XK_mini_batch.7, %W1_last.5) # <string>:335:0\n",
      "  %1255 : int = prim::Constant[value=1]() # <string>:335:0\n",
      "  %x.21 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1254, %b1_last.5, %1255) # <string>:335:0\n",
      "  %1257 : int = prim::Constant[value=1]() # <string>:336:0\n",
      "  %l2_target.7 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::sub(%XV_mini_batch.7, %XK_mini_batch.7, %1257) # <string>:336:0\n",
      "  %1259 : int = prim::Constant[value=4]() # <string>:337:0\n",
      "  %1260 : int = prim::Constant[value=1]() # <string>:337:0\n",
      "  %1261 : int = prim::Constant[value=32]() # <string>:337:0\n",
      "  %1262 : int[] = prim::ListConstruct(%1259, %1260, %1261)\n",
      "  %gamma.7 : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_weight, %1262) # <string>:337:0\n",
      "  %1264 : int = prim::Constant[value=4]() # <string>:339:0\n",
      "  %1265 : int = prim::Constant[value=1]() # <string>:339:0\n",
      "  %1266 : int = prim::Constant[value=32]() # <string>:339:0\n",
      "  %1267 : int[] = prim::ListConstruct(%1264, %1265, %1266)\n",
      "  %beta.7 : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_bias, %1267) # <string>:339:0\n",
      "  %1278 : int = prim::Constant[value=3]() # <string>:197:0\n",
      "  %1279 : int = aten::size(%x.21, %1278) # <string>:197:0\n",
      "  %D.7 : Long(device=cpu) = prim::NumToTensor(%1279)\n",
      "  %1281 : int = prim::Constant[value=-1]() # <string>:198:0\n",
      "  %1282 : int[] = prim::ListConstruct(%1281)\n",
      "  %1283 : bool = prim::Constant[value=1]() # <string>:198:0\n",
      "  %1284 : NoneType = prim::Constant()\n",
      "  %mu.13 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x.21, %1282, %1283, %1284) # <string>:198:0\n",
      "  %1286 : int = prim::Constant[value=-1]() # <string>:199:0\n",
      "  %1287 : int[] = prim::ListConstruct(%1286)\n",
      "  %1288 : bool = prim::Constant[value=0]() # <string>:199:0\n",
      "  %1289 : bool = prim::Constant[value=1]() # <string>:199:0\n",
      "  %var.13 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::var(%x.21, %1287, %1288, %1289) # <string>:199:0\n",
      "  %1291 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:200:0\n",
      "  %1292 : int = prim::Constant[value=1]() # <string>:200:0\n",
      "  %1293 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::add(%var.13, %1291, %1292) # <string>:200:0\n",
      "  %std.13 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%1293) # <string>:200:0\n",
      "  %1295 : int = prim::Constant[value=1]() # <string>:201:0\n",
      "  %1296 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x.21, %mu.13, %1295) # <string>:201:0\n",
      "  %x_hat.13 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%1296, %std.13) # <string>:201:0\n",
      "  %1298 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma.7, %x_hat.13) # <string>:202:0\n",
      "  %1299 : int = prim::Constant[value=1]() # <string>:202:0\n",
      "  %y.13 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1298, %beta.7, %1299) # <string>:202:0\n",
      "  %1301 : int = prim::Constant[value=1]() # <string>:203:0\n",
      "  %grad_output.7 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%y.13, %l2_target.7, %1301) # <string>:203:0\n",
      "  %grad_x_hat.7 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_output.7, %gamma.7) # <string>:204:0\n",
      "  %1304 : Float(requires_grad=0, device=cpu) = aten::reciprocal(%D.7) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %1305 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %1306 : Float(requires_grad=0, device=cpu) = aten::mul(%1304, %1305) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %1307 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%D.7, %grad_x_hat.7) # <string>:205:0\n",
      "  %1308 : int = prim::Constant[value=-1]() # <string>:205:0\n",
      "  %1309 : int[] = prim::ListConstruct(%1308)\n",
      "  %1310 : bool = prim::Constant[value=1]() # <string>:205:0\n",
      "  %1311 : NoneType = prim::Constant()\n",
      "  %1312 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sum(%grad_x_hat.7, %1309, %1310, %1311) # <string>:205:0\n",
      "  %1313 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %1314 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%1307, %1312, %1313) # <string>:205:0\n",
      "  %1315 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_x_hat.7, %x_hat.13) # <string>:206:0\n",
      "  %1316 : int = prim::Constant[value=-1]() # <string>:206:0\n",
      "  %1317 : int[] = prim::ListConstruct(%1316)\n",
      "  %1318 : bool = prim::Constant[value=1]() # <string>:206:0\n",
      "  %1319 : NoneType = prim::Constant()\n",
      "  %1320 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sum(%1315, %1317, %1318, %1319) # <string>:206:0\n",
      "  %1321 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%x_hat.13, %1320) # <string>:206:0\n",
      "  %1322 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %1323 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%1314, %1321, %1322) # <string>:205:0\n",
      "  %1324 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%1306, %1323) # <string>:205:0\n",
      "  %grad_l_wrt_Z1.7 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%1324, %std.13) # <string>:205:0\n",
      "  %1326 : int = prim::Constant[value=-2]() # <string>:344:0\n",
      "  %1327 : int = prim::Constant[value=-1]() # <string>:344:0\n",
      "  %1328 : Float(2, 4, 32, 16, strides=[12800, 3200, 1, 32], requires_grad=1, device=cpu) = aten::transpose(%XK_mini_batch.7, %1326, %1327) # <string>:344:0\n",
      "  %1329 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch.7, %1328) # <string>:344:0\n",
      "  %1330 : int = prim::Constant[value=0]() # <string>:344:0\n",
      "  %Attn1.7 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::tril(%1329, %1330) # <string>:344:0\n",
      "  %1332 : int = prim::Constant[value=0]() # <string>:345:0\n",
      "  %1333 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::tril(%eta_mini_batch.7, %1332) # <string>:345:0\n",
      "  %1334 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%1333, %grad_l_wrt_Z1.7) # <string>:345:0\n",
      "  %1335 : int = prim::Constant[value=1]() # <string>:345:0\n",
      "  %b1_bar.7 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%b1_last.5, %1334, %1335) # <string>:345:0\n",
      "  %1337 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch.7, %W1_last.5) # <string>:346:0\n",
      "  %1338 : Float(2, 4, 16, 16, strides=[1024, 1, 4, 64], requires_grad=1, device=cpu) = aten::mul(%eta_mini_batch.7, %Attn1.7) # <string>:346:0\n",
      "  %1339 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%1338, %grad_l_wrt_Z1.7) # <string>:346:0\n",
      "  %1340 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %1341 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%1337, %1339, %1340) # <string>:346:0\n",
      "  %1342 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %x.23 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1341, %b1_bar.7, %1342) # <string>:346:0\n",
      "  %1344 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1345 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1346 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %1347 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1348 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::slice(%eta_mini_batch.7, %1344, %1345, %1346, %1347) # <string>:348:0\n",
      "  %1349 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1350 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1351 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %1352 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1353 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::slice(%1348, %1349, %1350, %1351, %1352) # <string>:348:0\n",
      "  %1354 : int = prim::Constant[value=2]() # <string>:348:0\n",
      "  %1355 : int = prim::Constant[value=-1]() # <string>:348:0\n",
      "  %1356 : Float(2, 4, 16, strides=[6144, 1, 64], requires_grad=1, device=cpu) = aten::select(%1353, %1354, %1355) # <string>:348:0\n",
      "  %1357 : int = prim::Constant[value=2]() # <string>:348:0\n",
      "  %1358 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1359 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %1360 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1361 : Float(2, 4, 16, strides=[6144, 1, 64], requires_grad=1, device=cpu) = aten::slice(%1356, %1357, %1358, %1359, %1360) # <string>:348:0\n",
      "  %1362 : int = prim::Constant[value=3]() # <string>:348:0\n",
      "  %last_eta_mini_batch.7 : Float(2, 4, 16, 1, strides=[6144, 1, 64, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%1361, %1362) # <string>:348:0\n",
      "  %1364 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::mul(%last_eta_mini_batch.7, %XK_mini_batch.7) # <string>:349:0\n",
      "  %1365 : int = prim::Constant[value=-1]() # <string>:349:0\n",
      "  %1366 : int = prim::Constant[value=-2]() # <string>:349:0\n",
      "  %1367 : Float(2, 4, 32, 16, strides=[2048, 32, 1, 128], requires_grad=1, device=cpu) = aten::transpose(%1364, %1365, %1366) # <string>:349:0\n",
      "  %1368 : Float(2, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%1367, %grad_l_wrt_Z1.7) # <string>:349:0\n",
      "  %1369 : int = prim::Constant[value=1]() # <string>:349:0\n",
      "  %W1_last.7 : Float(2, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::sub(%W1_last.5, %1368, %1369) # <string>:349:0\n",
      "  %1371 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::mul(%last_eta_mini_batch.7, %grad_l_wrt_Z1.7) # <string>:351:0\n",
      "  %1372 : int = prim::Constant[value=-2]() # <string>:351:0\n",
      "  %1373 : int[] = prim::ListConstruct(%1372)\n",
      "  %1374 : bool = prim::Constant[value=1]() # <string>:351:0\n",
      "  %1375 : NoneType = prim::Constant()\n",
      "  %1376 : Float(2, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::sum(%1371, %1373, %1374, %1375) # <string>:351:0\n",
      "  %1377 : int = prim::Constant[value=1]() # <string>:351:0\n",
      "  %b1_last.7 : Float(2, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::sub(%b1_last.5, %1376, %1377) # <string>:351:0\n",
      "  %1391 : int = prim::Constant[value=-1]() # <string>:187:0\n",
      "  %1392 : int[] = prim::ListConstruct(%1391)\n",
      "  %1393 : bool = prim::Constant[value=1]() # <string>:187:0\n",
      "  %1394 : NoneType = prim::Constant()\n",
      "  %mu.15 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x.23, %1392, %1393, %1394) # <string>:187:0\n",
      "  %1396 : int = prim::Constant[value=-1]() # <string>:188:0\n",
      "  %1397 : int[] = prim::ListConstruct(%1396)\n",
      "  %1398 : bool = prim::Constant[value=0]() # <string>:188:0\n",
      "  %1399 : bool = prim::Constant[value=1]() # <string>:188:0\n",
      "  %var.15 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::var(%x.23, %1397, %1398, %1399) # <string>:188:0\n",
      "  %1401 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:189:0\n",
      "  %1402 : int = prim::Constant[value=1]() # <string>:189:0\n",
      "  %1403 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::add(%var.15, %1401, %1402) # <string>:189:0\n",
      "  %std.15 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%1403) # <string>:189:0\n",
      "  %1405 : int = prim::Constant[value=1]() # <string>:190:0\n",
      "  %1406 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x.23, %mu.15, %1405) # <string>:190:0\n",
      "  %x_hat.15 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%1406, %std.15) # <string>:190:0\n",
      "  %1408 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma.7, %x_hat.15) # <string>:191:0\n",
      "  %1409 : int = prim::Constant[value=1]() # <string>:191:0\n",
      "  %Z1_bar.7 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1408, %beta.7, %1409) # <string>:191:0\n",
      "  %1411 : int = prim::Constant[value=1]() # <string>:376:0\n",
      "  %y.15 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%XQ_mini_batch.7, %Z1_bar.7, %1411) # <string>:376:0\n",
      "  %1413 : int = prim::Constant[value=0]() # <string>:173:0\n",
      "  %1414 : int = prim::Constant[value=3]() # <string>:173:0\n",
      "  %1415 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::select(%out.1, %1413, %1414) # <string>:173:0\n",
      "  %1416 : bool = prim::Constant[value=0]()\n",
      "  %1417 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::copy_(%1415, %y.15, %1416) # <string>:173:0\n",
      "  %1418 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1419 : int = prim::Constant[value=4]() # <string>:169:0\n",
      "  %XQ_mini_batch.9 : Float(2, 4, 16, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.1, %1418, %1419) # <string>:169:0\n",
      "  %1421 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1422 : int = prim::Constant[value=4]() # <string>:169:0\n",
      "  %XK_mini_batch.9 : Float(2, 4, 16, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.3, %1421, %1422) # <string>:169:0\n",
      "  %1424 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1425 : int = prim::Constant[value=4]() # <string>:169:0\n",
      "  %XV_mini_batch.9 : Float(2, 4, 16, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::select(%tensor.5, %1424, %1425) # <string>:169:0\n",
      "  %1427 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1428 : int = prim::Constant[value=4]() # <string>:169:0\n",
      "  %eta_mini_batch.9 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::select(%tensor.7, %1427, %1428) # <string>:169:0\n",
      "  %1436 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XK_mini_batch.9, %W1_last.7) # <string>:335:0\n",
      "  %1437 : int = prim::Constant[value=1]() # <string>:335:0\n",
      "  %x.25 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1436, %b1_last.7, %1437) # <string>:335:0\n",
      "  %1439 : int = prim::Constant[value=1]() # <string>:336:0\n",
      "  %l2_target.9 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::sub(%XV_mini_batch.9, %XK_mini_batch.9, %1439) # <string>:336:0\n",
      "  %1441 : int = prim::Constant[value=4]() # <string>:337:0\n",
      "  %1442 : int = prim::Constant[value=1]() # <string>:337:0\n",
      "  %1443 : int = prim::Constant[value=32]() # <string>:337:0\n",
      "  %1444 : int[] = prim::ListConstruct(%1441, %1442, %1443)\n",
      "  %gamma.9 : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_weight, %1444) # <string>:337:0\n",
      "  %1446 : int = prim::Constant[value=4]() # <string>:339:0\n",
      "  %1447 : int = prim::Constant[value=1]() # <string>:339:0\n",
      "  %1448 : int = prim::Constant[value=32]() # <string>:339:0\n",
      "  %1449 : int[] = prim::ListConstruct(%1446, %1447, %1448)\n",
      "  %beta.9 : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_bias, %1449) # <string>:339:0\n",
      "  %1460 : int = prim::Constant[value=3]() # <string>:197:0\n",
      "  %1461 : int = aten::size(%x.25, %1460) # <string>:197:0\n",
      "  %D.9 : Long(device=cpu) = prim::NumToTensor(%1461)\n",
      "  %1463 : int = prim::Constant[value=-1]() # <string>:198:0\n",
      "  %1464 : int[] = prim::ListConstruct(%1463)\n",
      "  %1465 : bool = prim::Constant[value=1]() # <string>:198:0\n",
      "  %1466 : NoneType = prim::Constant()\n",
      "  %mu.17 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x.25, %1464, %1465, %1466) # <string>:198:0\n",
      "  %1468 : int = prim::Constant[value=-1]() # <string>:199:0\n",
      "  %1469 : int[] = prim::ListConstruct(%1468)\n",
      "  %1470 : bool = prim::Constant[value=0]() # <string>:199:0\n",
      "  %1471 : bool = prim::Constant[value=1]() # <string>:199:0\n",
      "  %var.17 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::var(%x.25, %1469, %1470, %1471) # <string>:199:0\n",
      "  %1473 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:200:0\n",
      "  %1474 : int = prim::Constant[value=1]() # <string>:200:0\n",
      "  %1475 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::add(%var.17, %1473, %1474) # <string>:200:0\n",
      "  %std.17 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%1475) # <string>:200:0\n",
      "  %1477 : int = prim::Constant[value=1]() # <string>:201:0\n",
      "  %1478 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x.25, %mu.17, %1477) # <string>:201:0\n",
      "  %x_hat.17 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%1478, %std.17) # <string>:201:0\n",
      "  %1480 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma.9, %x_hat.17) # <string>:202:0\n",
      "  %1481 : int = prim::Constant[value=1]() # <string>:202:0\n",
      "  %y.17 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1480, %beta.9, %1481) # <string>:202:0\n",
      "  %1483 : int = prim::Constant[value=1]() # <string>:203:0\n",
      "  %grad_output.9 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%y.17, %l2_target.9, %1483) # <string>:203:0\n",
      "  %grad_x_hat.9 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_output.9, %gamma.9) # <string>:204:0\n",
      "  %1486 : Float(requires_grad=0, device=cpu) = aten::reciprocal(%D.9) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %1487 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %1488 : Float(requires_grad=0, device=cpu) = aten::mul(%1486, %1487) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %1489 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%D.9, %grad_x_hat.9) # <string>:205:0\n",
      "  %1490 : int = prim::Constant[value=-1]() # <string>:205:0\n",
      "  %1491 : int[] = prim::ListConstruct(%1490)\n",
      "  %1492 : bool = prim::Constant[value=1]() # <string>:205:0\n",
      "  %1493 : NoneType = prim::Constant()\n",
      "  %1494 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sum(%grad_x_hat.9, %1491, %1492, %1493) # <string>:205:0\n",
      "  %1495 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %1496 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%1489, %1494, %1495) # <string>:205:0\n",
      "  %1497 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_x_hat.9, %x_hat.17) # <string>:206:0\n",
      "  %1498 : int = prim::Constant[value=-1]() # <string>:206:0\n",
      "  %1499 : int[] = prim::ListConstruct(%1498)\n",
      "  %1500 : bool = prim::Constant[value=1]() # <string>:206:0\n",
      "  %1501 : NoneType = prim::Constant()\n",
      "  %1502 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sum(%1497, %1499, %1500, %1501) # <string>:206:0\n",
      "  %1503 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%x_hat.17, %1502) # <string>:206:0\n",
      "  %1504 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %1505 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%1496, %1503, %1504) # <string>:205:0\n",
      "  %1506 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%1488, %1505) # <string>:205:0\n",
      "  %grad_l_wrt_Z1.9 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%1506, %std.17) # <string>:205:0\n",
      "  %1508 : int = prim::Constant[value=-2]() # <string>:344:0\n",
      "  %1509 : int = prim::Constant[value=-1]() # <string>:344:0\n",
      "  %1510 : Float(2, 4, 32, 16, strides=[12800, 3200, 1, 32], requires_grad=1, device=cpu) = aten::transpose(%XK_mini_batch.9, %1508, %1509) # <string>:344:0\n",
      "  %1511 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch.9, %1510) # <string>:344:0\n",
      "  %1512 : int = prim::Constant[value=0]() # <string>:344:0\n",
      "  %Attn1.9 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::tril(%1511, %1512) # <string>:344:0\n",
      "  %1514 : int = prim::Constant[value=0]() # <string>:345:0\n",
      "  %1515 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::tril(%eta_mini_batch.9, %1514) # <string>:345:0\n",
      "  %1516 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%1515, %grad_l_wrt_Z1.9) # <string>:345:0\n",
      "  %1517 : int = prim::Constant[value=1]() # <string>:345:0\n",
      "  %b1_bar.9 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%b1_last.7, %1516, %1517) # <string>:345:0\n",
      "  %1519 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch.9, %W1_last.7) # <string>:346:0\n",
      "  %1520 : Float(2, 4, 16, 16, strides=[1024, 1, 4, 64], requires_grad=1, device=cpu) = aten::mul(%eta_mini_batch.9, %Attn1.9) # <string>:346:0\n",
      "  %1521 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%1520, %grad_l_wrt_Z1.9) # <string>:346:0\n",
      "  %1522 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %1523 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%1519, %1521, %1522) # <string>:346:0\n",
      "  %1524 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %x.27 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1523, %b1_bar.9, %1524) # <string>:346:0\n",
      "  %1526 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1527 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1528 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %1529 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1530 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::slice(%eta_mini_batch.9, %1526, %1527, %1528, %1529) # <string>:348:0\n",
      "  %1531 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1532 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1533 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %1534 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1535 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::slice(%1530, %1531, %1532, %1533, %1534) # <string>:348:0\n",
      "  %1536 : int = prim::Constant[value=2]() # <string>:348:0\n",
      "  %1537 : int = prim::Constant[value=-1]() # <string>:348:0\n",
      "  %1538 : Float(2, 4, 16, strides=[6144, 1, 64], requires_grad=1, device=cpu) = aten::select(%1535, %1536, %1537) # <string>:348:0\n",
      "  %1539 : int = prim::Constant[value=2]() # <string>:348:0\n",
      "  %1540 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1541 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %1542 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1543 : Float(2, 4, 16, strides=[6144, 1, 64], requires_grad=1, device=cpu) = aten::slice(%1538, %1539, %1540, %1541, %1542) # <string>:348:0\n",
      "  %1544 : int = prim::Constant[value=3]() # <string>:348:0\n",
      "  %last_eta_mini_batch.9 : Float(2, 4, 16, 1, strides=[6144, 1, 64, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%1543, %1544) # <string>:348:0\n",
      "  %1546 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::mul(%last_eta_mini_batch.9, %XK_mini_batch.9) # <string>:349:0\n",
      "  %1547 : int = prim::Constant[value=-1]() # <string>:349:0\n",
      "  %1548 : int = prim::Constant[value=-2]() # <string>:349:0\n",
      "  %1549 : Float(2, 4, 32, 16, strides=[2048, 32, 1, 128], requires_grad=1, device=cpu) = aten::transpose(%1546, %1547, %1548) # <string>:349:0\n",
      "  %1550 : Float(2, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%1549, %grad_l_wrt_Z1.9) # <string>:349:0\n",
      "  %1551 : int = prim::Constant[value=1]() # <string>:349:0\n",
      "  %W1_last.9 : Float(2, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::sub(%W1_last.7, %1550, %1551) # <string>:349:0\n",
      "  %1553 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::mul(%last_eta_mini_batch.9, %grad_l_wrt_Z1.9) # <string>:351:0\n",
      "  %1554 : int = prim::Constant[value=-2]() # <string>:351:0\n",
      "  %1555 : int[] = prim::ListConstruct(%1554)\n",
      "  %1556 : bool = prim::Constant[value=1]() # <string>:351:0\n",
      "  %1557 : NoneType = prim::Constant()\n",
      "  %1558 : Float(2, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::sum(%1553, %1555, %1556, %1557) # <string>:351:0\n",
      "  %1559 : int = prim::Constant[value=1]() # <string>:351:0\n",
      "  %b1_last.9 : Float(2, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::sub(%b1_last.7, %1558, %1559) # <string>:351:0\n",
      "  %1573 : int = prim::Constant[value=-1]() # <string>:187:0\n",
      "  %1574 : int[] = prim::ListConstruct(%1573)\n",
      "  %1575 : bool = prim::Constant[value=1]() # <string>:187:0\n",
      "  %1576 : NoneType = prim::Constant()\n",
      "  %mu.19 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x.27, %1574, %1575, %1576) # <string>:187:0\n",
      "  %1578 : int = prim::Constant[value=-1]() # <string>:188:0\n",
      "  %1579 : int[] = prim::ListConstruct(%1578)\n",
      "  %1580 : bool = prim::Constant[value=0]() # <string>:188:0\n",
      "  %1581 : bool = prim::Constant[value=1]() # <string>:188:0\n",
      "  %var.19 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::var(%x.27, %1579, %1580, %1581) # <string>:188:0\n",
      "  %1583 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:189:0\n",
      "  %1584 : int = prim::Constant[value=1]() # <string>:189:0\n",
      "  %1585 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::add(%var.19, %1583, %1584) # <string>:189:0\n",
      "  %std.19 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%1585) # <string>:189:0\n",
      "  %1587 : int = prim::Constant[value=1]() # <string>:190:0\n",
      "  %1588 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x.27, %mu.19, %1587) # <string>:190:0\n",
      "  %x_hat.19 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%1588, %std.19) # <string>:190:0\n",
      "  %1590 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma.9, %x_hat.19) # <string>:191:0\n",
      "  %1591 : int = prim::Constant[value=1]() # <string>:191:0\n",
      "  %Z1_bar.9 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1590, %beta.9, %1591) # <string>:191:0\n",
      "  %1593 : int = prim::Constant[value=1]() # <string>:376:0\n",
      "  %y.19 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%XQ_mini_batch.9, %Z1_bar.9, %1593) # <string>:376:0\n",
      "  %1595 : int = prim::Constant[value=0]() # <string>:173:0\n",
      "  %1596 : int = prim::Constant[value=4]() # <string>:173:0\n",
      "  %1597 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::select(%out.1, %1595, %1596) # <string>:173:0\n",
      "  %1598 : bool = prim::Constant[value=0]()\n",
      "  %1599 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::copy_(%1597, %y.19, %1598) # <string>:173:0\n",
      "  %1600 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1601 : int = prim::Constant[value=5]() # <string>:169:0\n",
      "  %XQ_mini_batch.11 : Float(2, 4, 16, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.1, %1600, %1601) # <string>:169:0\n",
      "  %1603 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1604 : int = prim::Constant[value=5]() # <string>:169:0\n",
      "  %XK_mini_batch.11 : Float(2, 4, 16, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.3, %1603, %1604) # <string>:169:0\n",
      "  %1606 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1607 : int = prim::Constant[value=5]() # <string>:169:0\n",
      "  %XV_mini_batch.11 : Float(2, 4, 16, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::select(%tensor.5, %1606, %1607) # <string>:169:0\n",
      "  %1609 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %1610 : int = prim::Constant[value=5]() # <string>:169:0\n",
      "  %eta_mini_batch.11 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::select(%tensor.7, %1609, %1610) # <string>:169:0\n",
      "  %1618 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XK_mini_batch.11, %W1_last.9) # <string>:335:0\n",
      "  %1619 : int = prim::Constant[value=1]() # <string>:335:0\n",
      "  %x.29 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1618, %b1_last.9, %1619) # <string>:335:0\n",
      "  %1621 : int = prim::Constant[value=1]() # <string>:336:0\n",
      "  %l2_target.11 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::sub(%XV_mini_batch.11, %XK_mini_batch.11, %1621) # <string>:336:0\n",
      "  %1623 : int = prim::Constant[value=4]() # <string>:337:0\n",
      "  %1624 : int = prim::Constant[value=1]() # <string>:337:0\n",
      "  %1625 : int = prim::Constant[value=32]() # <string>:337:0\n",
      "  %1626 : int[] = prim::ListConstruct(%1623, %1624, %1625)\n",
      "  %gamma.11 : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_weight, %1626) # <string>:337:0\n",
      "  %1628 : int = prim::Constant[value=4]() # <string>:339:0\n",
      "  %1629 : int = prim::Constant[value=1]() # <string>:339:0\n",
      "  %1630 : int = prim::Constant[value=32]() # <string>:339:0\n",
      "  %1631 : int[] = prim::ListConstruct(%1628, %1629, %1630)\n",
      "  %beta.11 : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_bias, %1631) # <string>:339:0\n",
      "  %1642 : int = prim::Constant[value=3]() # <string>:197:0\n",
      "  %1643 : int = aten::size(%x.29, %1642) # <string>:197:0\n",
      "  %D.11 : Long(device=cpu) = prim::NumToTensor(%1643)\n",
      "  %1645 : int = prim::Constant[value=-1]() # <string>:198:0\n",
      "  %1646 : int[] = prim::ListConstruct(%1645)\n",
      "  %1647 : bool = prim::Constant[value=1]() # <string>:198:0\n",
      "  %1648 : NoneType = prim::Constant()\n",
      "  %mu.21 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x.29, %1646, %1647, %1648) # <string>:198:0\n",
      "  %1650 : int = prim::Constant[value=-1]() # <string>:199:0\n",
      "  %1651 : int[] = prim::ListConstruct(%1650)\n",
      "  %1652 : bool = prim::Constant[value=0]() # <string>:199:0\n",
      "  %1653 : bool = prim::Constant[value=1]() # <string>:199:0\n",
      "  %var.21 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::var(%x.29, %1651, %1652, %1653) # <string>:199:0\n",
      "  %1655 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:200:0\n",
      "  %1656 : int = prim::Constant[value=1]() # <string>:200:0\n",
      "  %1657 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::add(%var.21, %1655, %1656) # <string>:200:0\n",
      "  %std.21 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%1657) # <string>:200:0\n",
      "  %1659 : int = prim::Constant[value=1]() # <string>:201:0\n",
      "  %1660 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x.29, %mu.21, %1659) # <string>:201:0\n",
      "  %x_hat.21 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%1660, %std.21) # <string>:201:0\n",
      "  %1662 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma.11, %x_hat.21) # <string>:202:0\n",
      "  %1663 : int = prim::Constant[value=1]() # <string>:202:0\n",
      "  %y.21 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1662, %beta.11, %1663) # <string>:202:0\n",
      "  %1665 : int = prim::Constant[value=1]() # <string>:203:0\n",
      "  %grad_output.11 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%y.21, %l2_target.11, %1665) # <string>:203:0\n",
      "  %grad_x_hat.11 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_output.11, %gamma.11) # <string>:204:0\n",
      "  %1668 : Float(requires_grad=0, device=cpu) = aten::reciprocal(%D.11) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %1669 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %1670 : Float(requires_grad=0, device=cpu) = aten::mul(%1668, %1669) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %1671 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%D.11, %grad_x_hat.11) # <string>:205:0\n",
      "  %1672 : int = prim::Constant[value=-1]() # <string>:205:0\n",
      "  %1673 : int[] = prim::ListConstruct(%1672)\n",
      "  %1674 : bool = prim::Constant[value=1]() # <string>:205:0\n",
      "  %1675 : NoneType = prim::Constant()\n",
      "  %1676 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sum(%grad_x_hat.11, %1673, %1674, %1675) # <string>:205:0\n",
      "  %1677 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %1678 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%1671, %1676, %1677) # <string>:205:0\n",
      "  %1679 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_x_hat.11, %x_hat.21) # <string>:206:0\n",
      "  %1680 : int = prim::Constant[value=-1]() # <string>:206:0\n",
      "  %1681 : int[] = prim::ListConstruct(%1680)\n",
      "  %1682 : bool = prim::Constant[value=1]() # <string>:206:0\n",
      "  %1683 : NoneType = prim::Constant()\n",
      "  %1684 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sum(%1679, %1681, %1682, %1683) # <string>:206:0\n",
      "  %1685 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%x_hat.21, %1684) # <string>:206:0\n",
      "  %1686 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %1687 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%1678, %1685, %1686) # <string>:205:0\n",
      "  %1688 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%1670, %1687) # <string>:205:0\n",
      "  %grad_l_wrt_Z1.11 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%1688, %std.21) # <string>:205:0\n",
      "  %1690 : int = prim::Constant[value=-2]() # <string>:344:0\n",
      "  %1691 : int = prim::Constant[value=-1]() # <string>:344:0\n",
      "  %1692 : Float(2, 4, 32, 16, strides=[12800, 3200, 1, 32], requires_grad=1, device=cpu) = aten::transpose(%XK_mini_batch.11, %1690, %1691) # <string>:344:0\n",
      "  %1693 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch.11, %1692) # <string>:344:0\n",
      "  %1694 : int = prim::Constant[value=0]() # <string>:344:0\n",
      "  %Attn1.11 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::tril(%1693, %1694) # <string>:344:0\n",
      "  %1696 : int = prim::Constant[value=0]() # <string>:345:0\n",
      "  %1697 : Float(2, 4, 16, 16, strides=[1024, 256, 16, 1], requires_grad=1, device=cpu) = aten::tril(%eta_mini_batch.11, %1696) # <string>:345:0\n",
      "  %1698 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%1697, %grad_l_wrt_Z1.11) # <string>:345:0\n",
      "  %1699 : int = prim::Constant[value=1]() # <string>:345:0\n",
      "  %b1_bar.11 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%b1_last.9, %1698, %1699) # <string>:345:0\n",
      "  %1701 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch.11, %W1_last.9) # <string>:346:0\n",
      "  %1702 : Float(2, 4, 16, 16, strides=[1024, 1, 4, 64], requires_grad=1, device=cpu) = aten::mul(%eta_mini_batch.11, %Attn1.11) # <string>:346:0\n",
      "  %1703 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%1702, %grad_l_wrt_Z1.11) # <string>:346:0\n",
      "  %1704 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %1705 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%1701, %1703, %1704) # <string>:346:0\n",
      "  %1706 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %x.31 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1705, %b1_bar.11, %1706) # <string>:346:0\n",
      "  %1708 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1709 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1710 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %1711 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1712 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::slice(%eta_mini_batch.11, %1708, %1709, %1710, %1711) # <string>:348:0\n",
      "  %1713 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1714 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1715 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %1716 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1717 : Float(2, 4, 16, 16, strides=[6144, 1, 4, 64], requires_grad=1, device=cpu) = aten::slice(%1712, %1713, %1714, %1715, %1716) # <string>:348:0\n",
      "  %1718 : int = prim::Constant[value=2]() # <string>:348:0\n",
      "  %1719 : int = prim::Constant[value=-1]() # <string>:348:0\n",
      "  %1720 : Float(2, 4, 16, strides=[6144, 1, 64], requires_grad=1, device=cpu) = aten::select(%1717, %1718, %1719) # <string>:348:0\n",
      "  %1721 : int = prim::Constant[value=2]() # <string>:348:0\n",
      "  %1722 : int = prim::Constant[value=0]() # <string>:348:0\n",
      "  %1723 : int = prim::Constant[value=9223372036854775807]() # <string>:348:0\n",
      "  %1724 : int = prim::Constant[value=1]() # <string>:348:0\n",
      "  %1725 : Float(2, 4, 16, strides=[6144, 1, 64], requires_grad=1, device=cpu) = aten::slice(%1720, %1721, %1722, %1723, %1724) # <string>:348:0\n",
      "  %1726 : int = prim::Constant[value=3]() # <string>:348:0\n",
      "  %last_eta_mini_batch.11 : Float(2, 4, 16, 1, strides=[6144, 1, 64, 1], requires_grad=1, device=cpu) = aten::unsqueeze(%1725, %1726) # <string>:348:0\n",
      "  %1728 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::mul(%last_eta_mini_batch.11, %XK_mini_batch.11) # <string>:349:0\n",
      "  %1729 : int = prim::Constant[value=-1]() # <string>:349:0\n",
      "  %1730 : int = prim::Constant[value=-2]() # <string>:349:0\n",
      "  %1731 : Float(2, 4, 32, 16, strides=[2048, 32, 1, 128], requires_grad=1, device=cpu) = aten::transpose(%1728, %1729, %1730) # <string>:349:0\n",
      "  %1732 : Float(2, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%1731, %grad_l_wrt_Z1.11) # <string>:349:0\n",
      "  %1733 : int = prim::Constant[value=1]() # <string>:349:0\n",
      "  %W1_last.11 : Float(2, 4, 32, 32, strides=[4096, 1024, 32, 1], requires_grad=1, device=cpu) = aten::sub(%W1_last.9, %1732, %1733) # <string>:349:0\n",
      "  %1735 : Float(2, 4, 16, 32, strides=[2048, 32, 128, 1], requires_grad=1, device=cpu) = aten::mul(%last_eta_mini_batch.11, %grad_l_wrt_Z1.11) # <string>:351:0\n",
      "  %1736 : int = prim::Constant[value=-2]() # <string>:351:0\n",
      "  %1737 : int[] = prim::ListConstruct(%1736)\n",
      "  %1738 : bool = prim::Constant[value=1]() # <string>:351:0\n",
      "  %1739 : NoneType = prim::Constant()\n",
      "  %1740 : Float(2, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::sum(%1735, %1737, %1738, %1739) # <string>:351:0\n",
      "  %1741 : int = prim::Constant[value=1]() # <string>:351:0\n",
      "  %b1_last.11 : Float(2, 4, 1, 32, strides=[128, 32, 32, 1], requires_grad=1, device=cpu) = aten::sub(%b1_last.9, %1740, %1741) # <string>:351:0\n",
      "  %1755 : int = prim::Constant[value=-1]() # <string>:187:0\n",
      "  %1756 : int[] = prim::ListConstruct(%1755)\n",
      "  %1757 : bool = prim::Constant[value=1]() # <string>:187:0\n",
      "  %1758 : NoneType = prim::Constant()\n",
      "  %mu.23 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x.31, %1756, %1757, %1758) # <string>:187:0\n",
      "  %1760 : int = prim::Constant[value=-1]() # <string>:188:0\n",
      "  %1761 : int[] = prim::ListConstruct(%1760)\n",
      "  %1762 : bool = prim::Constant[value=0]() # <string>:188:0\n",
      "  %1763 : bool = prim::Constant[value=1]() # <string>:188:0\n",
      "  %var.23 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::var(%x.31, %1761, %1762, %1763) # <string>:188:0\n",
      "  %1765 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:189:0\n",
      "  %1766 : int = prim::Constant[value=1]() # <string>:189:0\n",
      "  %1767 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::add(%var.23, %1765, %1766) # <string>:189:0\n",
      "  %std.23 : Float(2, 4, 16, 1, strides=[64, 16, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%1767) # <string>:189:0\n",
      "  %1769 : int = prim::Constant[value=1]() # <string>:190:0\n",
      "  %1770 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x.31, %mu.23, %1769) # <string>:190:0\n",
      "  %x_hat.23 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::div(%1770, %std.23) # <string>:190:0\n",
      "  %1772 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma.11, %x_hat.23) # <string>:191:0\n",
      "  %1773 : int = prim::Constant[value=1]() # <string>:191:0\n",
      "  %Z1_bar.11 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%1772, %beta.11, %1773) # <string>:191:0\n",
      "  %1775 : int = prim::Constant[value=1]() # <string>:376:0\n",
      "  %y.23 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::add(%XQ_mini_batch.11, %Z1_bar.11, %1775) # <string>:376:0\n",
      "  %1777 : int = prim::Constant[value=0]() # <string>:173:0\n",
      "  %1778 : int = prim::Constant[value=5]() # <string>:173:0\n",
      "  %1779 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::select(%out.1, %1777, %1778) # <string>:173:0\n",
      "  %1780 : bool = prim::Constant[value=0]()\n",
      "  %1781 : Float(2, 4, 16, 32, strides=[2048, 512, 32, 1], requires_grad=1, device=cpu) = aten::copy_(%1779, %y.23, %1780) # <string>:173:0\n",
      "  %1782 : int = prim::Constant[value=1]() # <string>:396:0\n",
      "  %1783 : int = prim::Constant[value=0]() # <string>:396:0\n",
      "  %1784 : int = prim::Constant[value=3]() # <string>:396:0\n",
      "  %1785 : int = prim::Constant[value=2]() # <string>:396:0\n",
      "  %1786 : int = prim::Constant[value=4]() # <string>:396:0\n",
      "  %1787 : int[] = prim::ListConstruct(%1782, %1783, %1784, %1785, %1786)\n",
      "  %XQW_batch.1 : Float(2, 6, 16, 4, 32, strides=[2048, 4096, 32, 512, 1], requires_grad=1, device=cpu) = aten::permute(%out.1, %1787) # <string>:396:0\n",
      "  %1791 : int = prim::Constant[value=128]() # <string>:397:0\n",
      "  %1792 : int[] = prim::ListConstruct(%1789, %1790, %1791)\n",
      "  %output_mod : Float(2, 96, 128, strides=[12288, 128, 1], requires_grad=1, device=cpu) = aten::reshape(%XQW_batch.1, %1792) # <string>:397:0\n",
      "  %1796 : Long(requires_grad=0, device=cpu) = aten::neg(%reminder_len) # <string>:426:0\n",
      "  %1807 : int = aten::Int(%1796)\n",
      "  %1797 : int = prim::Constant[value=0]() # <string>:426:0\n",
      "  %1798 : int = prim::Constant[value=0]() # <string>:426:0\n",
      "  %1799 : int = prim::Constant[value=9223372036854775807]() # <string>:426:0\n",
      "  %1800 : int = prim::Constant[value=1]() # <string>:426:0\n",
      "  %1801 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%XQ.3, %1797, %1798, %1799, %1800) # <string>:426:0\n",
      "  %1802 : int = prim::Constant[value=1]() # <string>:426:0\n",
      "  %1803 : int = prim::Constant[value=0]() # <string>:426:0\n",
      "  %1804 : int = prim::Constant[value=9223372036854775807]() # <string>:426:0\n",
      "  %1805 : int = prim::Constant[value=1]() # <string>:426:0\n",
      "  %1806 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%1801, %1802, %1803, %1804, %1805) # <string>:426:0\n",
      "  %1808 : int = prim::Constant[value=2]() # <string>:426:0\n",
      "  %1809 : int = prim::Constant[value=9223372036854775807]() # <string>:426:0\n",
      "  %1810 : int = prim::Constant[value=1]() # <string>:426:0\n",
      "  %XQ : Float(2, 4, 4, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%1806, %1808, %1807, %1809, %1810) # <string>:426:0\n",
      "  %1812 : Long(requires_grad=0, device=cpu) = aten::neg(%reminder_len) # <string>:426:0\n",
      "  %1823 : int = aten::Int(%1812)\n",
      "  %1813 : int = prim::Constant[value=0]() # <string>:426:0\n",
      "  %1814 : int = prim::Constant[value=0]() # <string>:426:0\n",
      "  %1815 : int = prim::Constant[value=9223372036854775807]() # <string>:426:0\n",
      "  %1816 : int = prim::Constant[value=1]() # <string>:426:0\n",
      "  %1817 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%XK.3, %1813, %1814, %1815, %1816) # <string>:426:0\n",
      "  %1818 : int = prim::Constant[value=1]() # <string>:426:0\n",
      "  %1819 : int = prim::Constant[value=0]() # <string>:426:0\n",
      "  %1820 : int = prim::Constant[value=9223372036854775807]() # <string>:426:0\n",
      "  %1821 : int = prim::Constant[value=1]() # <string>:426:0\n",
      "  %1822 : Float(2, 4, 100, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%1817, %1818, %1819, %1820, %1821) # <string>:426:0\n",
      "  %1824 : int = prim::Constant[value=2]() # <string>:426:0\n",
      "  %1825 : int = prim::Constant[value=9223372036854775807]() # <string>:426:0\n",
      "  %1826 : int = prim::Constant[value=1]() # <string>:426:0\n",
      "  %XK : Float(2, 4, 4, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::slice(%1822, %1824, %1823, %1825, %1826) # <string>:426:0\n",
      "  %1828 : Long(requires_grad=0, device=cpu) = aten::neg(%reminder_len) # <string>:427:0\n",
      "  %1839 : int = aten::Int(%1828)\n",
      "  %1829 : int = prim::Constant[value=0]() # <string>:427:0\n",
      "  %1830 : int = prim::Constant[value=0]() # <string>:427:0\n",
      "  %1831 : int = prim::Constant[value=9223372036854775807]() # <string>:427:0\n",
      "  %1832 : int = prim::Constant[value=1]() # <string>:427:0\n",
      "  %1833 : Float(2, 4, 100, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::slice(%XV.3, %1829, %1830, %1831, %1832) # <string>:427:0\n",
      "  %1834 : int = prim::Constant[value=1]() # <string>:427:0\n",
      "  %1835 : int = prim::Constant[value=0]() # <string>:427:0\n",
      "  %1836 : int = prim::Constant[value=9223372036854775807]() # <string>:427:0\n",
      "  %1837 : int = prim::Constant[value=1]() # <string>:427:0\n",
      "  %1838 : Float(2, 4, 100, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::slice(%1833, %1834, %1835, %1836, %1837) # <string>:427:0\n",
      "  %1840 : int = prim::Constant[value=2]() # <string>:427:0\n",
      "  %1841 : int = prim::Constant[value=9223372036854775807]() # <string>:427:0\n",
      "  %1842 : int = prim::Constant[value=1]() # <string>:427:0\n",
      "  %XV : Float(2, 4, 4, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::slice(%1838, %1840, %1839, %1841, %1842) # <string>:427:0\n",
      "  %1844 : Long(requires_grad=0, device=cpu) = aten::neg(%reminder_len) # <string>:428:0\n",
      "  %1850 : int = aten::Int(%1844)\n",
      "  %1845 : int = prim::Constant[value=0]() # <string>:428:0\n",
      "  %1846 : int = prim::Constant[value=0]() # <string>:428:0\n",
      "  %1847 : int = prim::Constant[value=9223372036854775807]() # <string>:428:0\n",
      "  %1848 : int = prim::Constant[value=1]() # <string>:428:0\n",
      "  %1849 : Float(2, 100, 128, strides=[12800, 128, 1], requires_grad=0, device=cpu) = aten::slice(%hidden_states, %1845, %1846, %1847, %1848) # <string>:428:0\n",
      "  %1851 : int = prim::Constant[value=1]() # <string>:428:0\n",
      "  %1852 : int = prim::Constant[value=9223372036854775807]() # <string>:428:0\n",
      "  %1853 : int = prim::Constant[value=1]() # <string>:428:0\n",
      "  %X.5 : Float(2, 4, 128, strides=[12800, 128, 1], requires_grad=0, device=cpu) = aten::slice(%1849, %1851, %1850, %1852, %1853) # <string>:428:0\n",
      "  %1855 : int = prim::Constant[value=0]() # <string>:300:0\n",
      "  %1856 : int = aten::size(%X.5, %1855) # <string>:300:0\n",
      "  %B.7 : Long(device=cpu) = prim::NumToTensor(%1856)\n",
      "  %1888 : int = aten::Int(%B.7)\n",
      "  %1880 : int = aten::Int(%B.7)\n",
      "  %1872 : int = aten::Int(%B.7)\n",
      "  %1865 : int = aten::Int(%B.7)\n",
      "  %1858 : int = prim::Constant[value=1]() # <string>:300:0\n",
      "  %1859 : int = aten::size(%X.5, %1858) # <string>:300:0\n",
      "  %1860 : Long(device=cpu) = prim::NumToTensor(%1859)\n",
      "  %num_mini_batch.7 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1860, %reminder_len) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %1866 : int = aten::Int(%num_mini_batch.7)\n",
      "  %1868 : int = prim::Constant[value=128]() # <string>:302:0\n",
      "  %1869 : int[] = prim::ListConstruct(%1865, %1866, %1867, %1868)\n",
      "  %X : Float(2, 1, 4, 128, strides=[12800, 512, 128, 1], requires_grad=0, device=cpu) = aten::reshape(%X.5, %1869) # <string>:302:0\n",
      "  %1871 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1860, %reminder_len) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %1873 : int = aten::Int(%1871)\n",
      "  %1875 : int = prim::Constant[value=4]() # <string>:303:0\n",
      "  %1876 : int = prim::Constant[value=32]() # <string>:303:0\n",
      "  %1877 : int[] = prim::ListConstruct(%1872, %1875, %1873, %1874, %1876)\n",
      "  %x.33 : Float(2, 4, 1, 4, 32, strides=[12800, 3200, 128, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%XQ, %1877) # <string>:303:0\n",
      "  %1879 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1860, %reminder_len) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %1881 : int = aten::Int(%1879)\n",
      "  %1883 : int = prim::Constant[value=4]() # <string>:305:0\n",
      "  %1884 : int = prim::Constant[value=32]() # <string>:305:0\n",
      "  %1885 : int[] = prim::ListConstruct(%1880, %1883, %1881, %1882, %1884)\n",
      "  %x.35 : Float(2, 4, 1, 4, 32, strides=[12800, 3200, 128, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%XK, %1885) # <string>:305:0\n",
      "  %1887 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%1860, %reminder_len) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:995:0\n",
      "  %1889 : int = aten::Int(%1887)\n",
      "  %1891 : int = prim::Constant[value=4]() # <string>:307:0\n",
      "  %1892 : int = prim::Constant[value=32]() # <string>:307:0\n",
      "  %1893 : int[] = prim::ListConstruct(%1888, %1891, %1889, %1890, %1892)\n",
      "  %x.37 : Float(2, 4, 1, 4, 32, strides=[12800, 32, 512, 128, 1], requires_grad=1, device=cpu) = aten::reshape(%XV, %1893) # <string>:307:0\n",
      "  %1895 : str = prim::Constant[value=\"bnkc,hdc->bhnkd\"]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/functional.py:386:0\n",
      "  %1896 : Tensor[] = prim::ListConstruct(%X, %learnable_ttt_lr_weight)\n",
      "  %1897 : NoneType = prim::Constant()\n",
      "  %1898 : Float(2, 4, 1, 4, 1, strides=[16, 1, 16, 4, 4], requires_grad=1, device=cpu) = aten::einsum(%1895, %1896, %1897) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/functional.py:386:0\n",
      "  %1899 : int = prim::Constant[value=1]() # <string>:282:0\n",
      "  %1900 : int = prim::Constant[value=-1]() # <string>:282:0\n",
      "  %1901 : int = prim::Constant[value=1]() # <string>:282:0\n",
      "  %1902 : int = prim::Constant[value=1]() # <string>:282:0\n",
      "  %1903 : int = prim::Constant[value=1]() # <string>:282:0\n",
      "  %1904 : int[] = prim::ListConstruct(%1899, %1900, %1901, %1902, %1903)\n",
      "  %1905 : Float(1, 4, 1, 1, 1, strides=[4, 1, 1, 1, 1], requires_grad=1, device=cpu) = aten::reshape(%learnable_ttt_lr_bias, %1904) # <string>:282:0\n",
      "  %1906 : int = prim::Constant[value=1]() # <string>:281:0\n",
      "  %input.3 : Float(2, 4, 1, 4, 1, strides=[16, 1, 16, 4, 4], requires_grad=1, device=cpu) = aten::add(%1898, %1905, %1906) # <string>:281:0\n",
      "  %ttt_lr.5 : Float(2, 4, 1, 4, 1, strides=[16, 1, 16, 4, 4], requires_grad=1, device=cpu) = aten::sigmoid(%input.3) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/nn/functional.py:2013:0\n",
      "  %1909 : int = prim::Constant[value=0]() # <string>:285:0\n",
      "  %1910 : int = prim::Constant[value=1]() # <string>:285:0\n",
      "  %1911 : int = prim::Constant[value=2]() # <string>:285:0\n",
      "  %1912 : int = prim::Constant[value=4]() # <string>:285:0\n",
      "  %1913 : int = prim::Constant[value=3]() # <string>:285:0\n",
      "  %1914 : int[] = prim::ListConstruct(%1909, %1910, %1911, %1912, %1913)\n",
      "  %ttt_lr : Float(2, 4, 1, 1, 4, strides=[16, 1, 16, 4, 4], requires_grad=1, device=cpu) = aten::permute(%ttt_lr.5, %1914) # <string>:285:0\n",
      "  %1916 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # <string>:286:0\n",
      "  %1917 : Float(2, 4, 1, 1, 4, strides=[16, 1, 16, 4, 4], requires_grad=1, device=cpu) = aten::mul(%ttt_lr, %1916) # <string>:286:0\n",
      "  %1918 : Long(requires_grad=0, device=cpu) = prim::Constant[value={32}]() # <string>:286:0\n",
      "  %ttt_lr_eta : Float(2, 4, 1, 1, 4, strides=[16, 1, 16, 4, 4], requires_grad=1, device=cpu) = aten::div(%1917, %1918) # <string>:286:0\n",
      "  %1920 : int = prim::Constant[value=1]() # <string>:287:0\n",
      "  %token_idx.7 : Float(16, strides=[1], requires_grad=1, device=cpu) = aten::add(%token_idx, %learnable_token_idx, %1920) # <string>:287:0\n",
      "  %1923 : int = prim::Constant[value=0]() # <string>:288:0\n",
      "  %1924 : int = prim::Constant[value=0]() # <string>:288:0\n",
      "  %1925 : int = prim::Constant[value=1]() # <string>:288:0\n",
      "  %token_idx.9 : Float(4, strides=[1], requires_grad=1, device=cpu) = aten::slice(%token_idx.7, %1923, %1924, %1922, %1925) # <string>:288:0\n",
      "  %1927 : float = prim::Constant[value=0.]() # <string>:289:0\n",
      "  %token_idx.11 : Float(4, strides=[1], requires_grad=1, device=cpu) = aten::clamp_min(%token_idx.9, %1927) # <string>:289:0\n",
      "  %1930 : int = prim::Constant[value=1]() # <string>:290:0\n",
      "  %1931 : int = prim::Constant[value=1]() # <string>:290:0\n",
      "  %1932 : int = prim::Constant[value=1]() # <string>:290:0\n",
      "  %1933 : int = prim::Constant[value=1]() # <string>:290:0\n",
      "  %1934 : int[] = prim::ListConstruct(%1930, %1931, %1932, %1929, %1933)\n",
      "  %1935 : Float(1, 1, 1, 4, 1, strides=[4, 4, 4, 1, 1], requires_grad=1, device=cpu) = aten::reshape(%token_idx.11, %1934) # <string>:290:0\n",
      "  %1936 : int = prim::Constant[value=0]() # <string>:291:0\n",
      "  %1937 : int = aten::size(%X, %1936) # <string>:291:0\n",
      "  %1938 : Long(device=cpu) = prim::NumToTensor(%1937)\n",
      "  %1960 : int = aten::Int(%1938)\n",
      "  %1951 : int = prim::Constant[value=1]() # <string>:291:0\n",
      "  %1952 : int = aten::size(%X, %1951) # <string>:291:0\n",
      "  %1953 : Long(device=cpu) = prim::NumToTensor(%1952)\n",
      "  %1961 : int = aten::Int(%1953)\n",
      "  %1963 : int = prim::Constant[value=4]() # <string>:290:0\n",
      "  %1964 : int = prim::Constant[value=1]() # <string>:290:0\n",
      "  %1965 : int[] = prim::ListConstruct(%1960, %1963, %1961, %1962, %1964)\n",
      "  %token_eta : Float(2, 4, 1, 4, 1, strides=[0, 0, 4, 1, 1], requires_grad=1, device=cpu) = aten::broadcast_to(%1935, %1965) # <string>:290:0\n",
      "  %x.39 : Float(2, 4, 1, 4, 4, strides=[64, 1, 64, 4, 16], requires_grad=1, device=cpu) = aten::mul(%token_eta, %ttt_lr_eta) # <string>:310:0\n",
      "  %1968 : int = prim::Constant[value=0]() # <string>:318:0\n",
      "  %1969 : int = aten::size(%x.37, %1968) # <string>:318:0\n",
      "  %B : Long(device=cpu) = prim::NumToTensor(%1969)\n",
      "  %2287 : int = aten::Int(%B)\n",
      "  %2072 : int = aten::Int(%B)\n",
      "  %1989 : int = prim::Constant[value=2]() # <string>:319:0\n",
      "  %1990 : int = aten::size(%x.37, %1989) # <string>:319:0\n",
      "  %num_mini_batch : Long(device=cpu) = prim::NumToTensor(%1990)\n",
      "  %2071 : int = aten::Int(%num_mini_batch)\n",
      "  %2004 : int = prim::Constant[value=2]() # <string>:320:0\n",
      "  %2005 : int = aten::size(%x.37, %2004) # <string>:320:0\n",
      "  %2006 : Long(device=cpu) = prim::NumToTensor(%2005)\n",
      "  %2022 : int = prim::Constant[value=3]() # <string>:320:0\n",
      "  %2023 : int = aten::size(%x.37, %2022) # <string>:320:0\n",
      "  %2024 : Long(device=cpu) = prim::NumToTensor(%2023)\n",
      "  %L : Long(requires_grad=0, device=cpu) = aten::mul(%2006, %2024) # <string>:320:0\n",
      "  %2288 : int = aten::Int(%L)\n",
      "  %2029 : int = prim::Constant[value=2]() # <string>:390:0\n",
      "  %2030 : int = prim::Constant[value=0]() # <string>:390:0\n",
      "  %2031 : int = prim::Constant[value=1]() # <string>:390:0\n",
      "  %2032 : int = prim::Constant[value=3]() # <string>:390:0\n",
      "  %2033 : int = prim::Constant[value=4]() # <string>:390:0\n",
      "  %2034 : int[] = prim::ListConstruct(%2029, %2030, %2031, %2032, %2033)\n",
      "  %tensor.13 : Float(1, 2, 4, 4, 32, strides=[128, 12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::permute(%x.33, %2034) # <string>:390:0\n",
      "  %2036 : int = prim::Constant[value=2]() # <string>:390:0\n",
      "  %2037 : int = prim::Constant[value=0]() # <string>:390:0\n",
      "  %2038 : int = prim::Constant[value=1]() # <string>:390:0\n",
      "  %2039 : int = prim::Constant[value=3]() # <string>:390:0\n",
      "  %2040 : int = prim::Constant[value=4]() # <string>:390:0\n",
      "  %2041 : int[] = prim::ListConstruct(%2036, %2037, %2038, %2039, %2040)\n",
      "  %tensor.15 : Float(1, 2, 4, 4, 32, strides=[128, 12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::permute(%x.35, %2041) # <string>:390:0\n",
      "  %2043 : int = prim::Constant[value=2]() # <string>:390:0\n",
      "  %2044 : int = prim::Constant[value=0]() # <string>:390:0\n",
      "  %2045 : int = prim::Constant[value=1]() # <string>:390:0\n",
      "  %2046 : int = prim::Constant[value=3]() # <string>:390:0\n",
      "  %2047 : int = prim::Constant[value=4]() # <string>:390:0\n",
      "  %2048 : int[] = prim::ListConstruct(%2043, %2044, %2045, %2046, %2047)\n",
      "  %tensor.17 : Float(1, 2, 4, 4, 32, strides=[512, 12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::permute(%x.37, %2048) # <string>:390:0\n",
      "  %2050 : int = prim::Constant[value=2]() # <string>:390:0\n",
      "  %2051 : int = prim::Constant[value=0]() # <string>:390:0\n",
      "  %2052 : int = prim::Constant[value=1]() # <string>:390:0\n",
      "  %2053 : int = prim::Constant[value=3]() # <string>:390:0\n",
      "  %2054 : int = prim::Constant[value=4]() # <string>:390:0\n",
      "  %2055 : int[] = prim::ListConstruct(%2050, %2051, %2052, %2053, %2054)\n",
      "  %tensor.19 : Float(1, 2, 4, 4, 4, strides=[64, 64, 1, 4, 16], requires_grad=1, device=cpu) = aten::permute(%x.39, %2055) # <string>:390:0\n",
      "  %2074 : int = prim::Constant[value=4]() # <string>:391:0\n",
      "  %2075 : int = prim::Constant[value=32]() # <string>:391:0\n",
      "  %2076 : int[] = prim::ListConstruct(%2071, %2072, %2074, %2073, %2075)\n",
      "  %2077 : int = prim::Constant[value=6]() # <string>:391:0\n",
      "  %2078 : NoneType = prim::Constant()\n",
      "  %2079 : Device = prim::Constant[value=\"cpu\"]() # <string>:391:0\n",
      "  %2080 : bool = prim::Constant[value=0]() # <string>:391:0\n",
      "  %2081 : NoneType = prim::Constant()\n",
      "  %out : Float(1, 2, 4, 4, 32, strides=[1024, 512, 128, 32, 1], requires_grad=0, device=cpu) = aten::empty(%2076, %2077, %2078, %2079, %2080, %2081) # <string>:391:0\n",
      "  %2098 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %2099 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %XQ_mini_batch : Float(2, 4, 4, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.13, %2098, %2099) # <string>:169:0\n",
      "  %2101 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %2102 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %XK_mini_batch : Float(2, 4, 4, 32, strides=[12800, 3200, 32, 1], requires_grad=1, device=cpu) = aten::select(%tensor.15, %2101, %2102) # <string>:169:0\n",
      "  %2104 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %2105 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %XV_mini_batch : Float(2, 4, 4, 32, strides=[12800, 32, 128, 1], requires_grad=1, device=cpu) = aten::select(%tensor.17, %2104, %2105) # <string>:169:0\n",
      "  %2107 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %2108 : int = prim::Constant[value=0]() # <string>:169:0\n",
      "  %eta_mini_batch : Float(2, 4, 4, 4, strides=[64, 1, 4, 16], requires_grad=1, device=cpu) = aten::select(%tensor.19, %2107, %2108) # <string>:169:0\n",
      "  %2116 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XK_mini_batch, %W1_last.11) # <string>:335:0\n",
      "  %2117 : int = prim::Constant[value=1]() # <string>:335:0\n",
      "  %x.41 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::add(%2116, %b1_last.11, %2117) # <string>:335:0\n",
      "  %2119 : int = prim::Constant[value=1]() # <string>:336:0\n",
      "  %l2_target : Float(2, 4, 4, 32, strides=[512, 32, 128, 1], requires_grad=1, device=cpu) = aten::sub(%XV_mini_batch, %XK_mini_batch, %2119) # <string>:336:0\n",
      "  %2121 : int = prim::Constant[value=4]() # <string>:337:0\n",
      "  %2122 : int = prim::Constant[value=1]() # <string>:337:0\n",
      "  %2123 : int = prim::Constant[value=32]() # <string>:337:0\n",
      "  %2124 : int[] = prim::ListConstruct(%2121, %2122, %2123)\n",
      "  %gamma : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_weight, %2124) # <string>:337:0\n",
      "  %2126 : int = prim::Constant[value=4]() # <string>:339:0\n",
      "  %2127 : int = prim::Constant[value=1]() # <string>:339:0\n",
      "  %2128 : int = prim::Constant[value=32]() # <string>:339:0\n",
      "  %2129 : int[] = prim::ListConstruct(%2126, %2127, %2128)\n",
      "  %beta : Float(4, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = aten::reshape(%ttt_norm_bias, %2129) # <string>:339:0\n",
      "  %2140 : int = prim::Constant[value=3]() # <string>:197:0\n",
      "  %2141 : int = aten::size(%x.41, %2140) # <string>:197:0\n",
      "  %D : Long(device=cpu) = prim::NumToTensor(%2141)\n",
      "  %2143 : int = prim::Constant[value=-1]() # <string>:198:0\n",
      "  %2144 : int[] = prim::ListConstruct(%2143)\n",
      "  %2145 : bool = prim::Constant[value=1]() # <string>:198:0\n",
      "  %2146 : NoneType = prim::Constant()\n",
      "  %mu.25 : Float(2, 4, 4, 1, strides=[16, 4, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x.41, %2144, %2145, %2146) # <string>:198:0\n",
      "  %2148 : int = prim::Constant[value=-1]() # <string>:199:0\n",
      "  %2149 : int[] = prim::ListConstruct(%2148)\n",
      "  %2150 : bool = prim::Constant[value=0]() # <string>:199:0\n",
      "  %2151 : bool = prim::Constant[value=1]() # <string>:199:0\n",
      "  %var.25 : Float(2, 4, 4, 1, strides=[16, 4, 1, 1], requires_grad=1, device=cpu) = aten::var(%x.41, %2149, %2150, %2151) # <string>:199:0\n",
      "  %2153 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:200:0\n",
      "  %2154 : int = prim::Constant[value=1]() # <string>:200:0\n",
      "  %2155 : Float(2, 4, 4, 1, strides=[16, 4, 1, 1], requires_grad=1, device=cpu) = aten::add(%var.25, %2153, %2154) # <string>:200:0\n",
      "  %std.25 : Float(2, 4, 4, 1, strides=[16, 4, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%2155) # <string>:200:0\n",
      "  %2157 : int = prim::Constant[value=1]() # <string>:201:0\n",
      "  %2158 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x.41, %mu.25, %2157) # <string>:201:0\n",
      "  %x_hat.25 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::div(%2158, %std.25) # <string>:201:0\n",
      "  %2160 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma, %x_hat.25) # <string>:202:0\n",
      "  %2161 : int = prim::Constant[value=1]() # <string>:202:0\n",
      "  %y.25 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::add(%2160, %beta, %2161) # <string>:202:0\n",
      "  %2163 : int = prim::Constant[value=1]() # <string>:203:0\n",
      "  %grad_output : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::sub(%y.25, %l2_target, %2163) # <string>:203:0\n",
      "  %grad_x_hat : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_output, %gamma) # <string>:204:0\n",
      "  %2166 : Float(requires_grad=0, device=cpu) = aten::reciprocal(%D) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %2167 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %2168 : Float(requires_grad=0, device=cpu) = aten::mul(%2166, %2167) # /home/junyanc/.conda/envs/modis/lib/python3.12/site-packages/torch/_tensor.py:966:0\n",
      "  %2169 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::mul(%D, %grad_x_hat) # <string>:205:0\n",
      "  %2170 : int = prim::Constant[value=-1]() # <string>:205:0\n",
      "  %2171 : int[] = prim::ListConstruct(%2170)\n",
      "  %2172 : bool = prim::Constant[value=1]() # <string>:205:0\n",
      "  %2173 : NoneType = prim::Constant()\n",
      "  %2174 : Float(2, 4, 4, 1, strides=[16, 4, 1, 1], requires_grad=1, device=cpu) = aten::sum(%grad_x_hat, %2171, %2172, %2173) # <string>:205:0\n",
      "  %2175 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %2176 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::sub(%2169, %2174, %2175) # <string>:205:0\n",
      "  %2177 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::mul(%grad_x_hat, %x_hat.25) # <string>:206:0\n",
      "  %2178 : int = prim::Constant[value=-1]() # <string>:206:0\n",
      "  %2179 : int[] = prim::ListConstruct(%2178)\n",
      "  %2180 : bool = prim::Constant[value=1]() # <string>:206:0\n",
      "  %2181 : NoneType = prim::Constant()\n",
      "  %2182 : Float(2, 4, 4, 1, strides=[16, 4, 1, 1], requires_grad=1, device=cpu) = aten::sum(%2177, %2179, %2180, %2181) # <string>:206:0\n",
      "  %2183 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::mul(%x_hat.25, %2182) # <string>:206:0\n",
      "  %2184 : int = prim::Constant[value=1]() # <string>:205:0\n",
      "  %2185 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::sub(%2176, %2183, %2184) # <string>:205:0\n",
      "  %2186 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::mul(%2168, %2185) # <string>:205:0\n",
      "  %grad_l_wrt_Z1 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::div(%2186, %std.25) # <string>:205:0\n",
      "  %2188 : int = prim::Constant[value=-2]() # <string>:344:0\n",
      "  %2189 : int = prim::Constant[value=-1]() # <string>:344:0\n",
      "  %2190 : Float(2, 4, 32, 4, strides=[12800, 3200, 1, 32], requires_grad=1, device=cpu) = aten::transpose(%XK_mini_batch, %2188, %2189) # <string>:344:0\n",
      "  %2191 : Float(2, 4, 4, 4, strides=[64, 16, 4, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch, %2190) # <string>:344:0\n",
      "  %2192 : int = prim::Constant[value=0]() # <string>:344:0\n",
      "  %Attn1 : Float(2, 4, 4, 4, strides=[64, 16, 4, 1], requires_grad=1, device=cpu) = aten::tril(%2191, %2192) # <string>:344:0\n",
      "  %2194 : int = prim::Constant[value=0]() # <string>:345:0\n",
      "  %2195 : Float(2, 4, 4, 4, strides=[64, 16, 4, 1], requires_grad=1, device=cpu) = aten::tril(%eta_mini_batch, %2194) # <string>:345:0\n",
      "  %2196 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%2195, %grad_l_wrt_Z1) # <string>:345:0\n",
      "  %2197 : int = prim::Constant[value=1]() # <string>:345:0\n",
      "  %b1_bar : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::sub(%b1_last.11, %2196, %2197) # <string>:345:0\n",
      "  %2199 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%XQ_mini_batch, %W1_last.11) # <string>:346:0\n",
      "  %2200 : Float(2, 4, 4, 4, strides=[64, 1, 4, 16], requires_grad=1, device=cpu) = aten::mul(%eta_mini_batch, %Attn1) # <string>:346:0\n",
      "  %2201 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::matmul(%2200, %grad_l_wrt_Z1) # <string>:346:0\n",
      "  %2202 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %2203 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::sub(%2199, %2201, %2202) # <string>:346:0\n",
      "  %2204 : int = prim::Constant[value=1]() # <string>:346:0\n",
      "  %x : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::add(%2203, %b1_bar, %2204) # <string>:346:0\n",
      "  %2253 : int = prim::Constant[value=-1]() # <string>:187:0\n",
      "  %2254 : int[] = prim::ListConstruct(%2253)\n",
      "  %2255 : bool = prim::Constant[value=1]() # <string>:187:0\n",
      "  %2256 : NoneType = prim::Constant()\n",
      "  %mu : Float(2, 4, 4, 1, strides=[16, 4, 1, 1], requires_grad=1, device=cpu) = aten::mean(%x, %2254, %2255, %2256) # <string>:187:0\n",
      "  %2258 : int = prim::Constant[value=-1]() # <string>:188:0\n",
      "  %2259 : int[] = prim::ListConstruct(%2258)\n",
      "  %2260 : bool = prim::Constant[value=0]() # <string>:188:0\n",
      "  %2261 : bool = prim::Constant[value=1]() # <string>:188:0\n",
      "  %var : Float(2, 4, 4, 1, strides=[16, 4, 1, 1], requires_grad=1, device=cpu) = aten::var(%x, %2259, %2260, %2261) # <string>:188:0\n",
      "  %2263 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}]() # <string>:189:0\n",
      "  %2264 : int = prim::Constant[value=1]() # <string>:189:0\n",
      "  %2265 : Float(2, 4, 4, 1, strides=[16, 4, 1, 1], requires_grad=1, device=cpu) = aten::add(%var, %2263, %2264) # <string>:189:0\n",
      "  %std : Float(2, 4, 4, 1, strides=[16, 4, 1, 1], requires_grad=1, device=cpu) = aten::sqrt(%2265) # <string>:189:0\n",
      "  %2267 : int = prim::Constant[value=1]() # <string>:190:0\n",
      "  %2268 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::sub(%x, %mu, %2267) # <string>:190:0\n",
      "  %x_hat : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::div(%2268, %std) # <string>:190:0\n",
      "  %2270 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::mul(%gamma, %x_hat) # <string>:191:0\n",
      "  %2271 : int = prim::Constant[value=1]() # <string>:191:0\n",
      "  %Z1_bar : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::add(%2270, %beta, %2271) # <string>:191:0\n",
      "  %2273 : int = prim::Constant[value=1]() # <string>:376:0\n",
      "  %y : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::add(%XQ_mini_batch, %Z1_bar, %2273) # <string>:376:0\n",
      "  %2275 : int = prim::Constant[value=0]() # <string>:173:0\n",
      "  %2276 : int = prim::Constant[value=0]() # <string>:173:0\n",
      "  %2277 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=0, device=cpu) = aten::select(%out, %2275, %2276) # <string>:173:0\n",
      "  %2278 : bool = prim::Constant[value=0]()\n",
      "  %2279 : Float(2, 4, 4, 32, strides=[512, 128, 32, 1], requires_grad=1, device=cpu) = aten::copy_(%2277, %y, %2278) # <string>:173:0\n",
      "  %2280 : int = prim::Constant[value=1]() # <string>:396:0\n",
      "  %2281 : int = prim::Constant[value=0]() # <string>:396:0\n",
      "  %2282 : int = prim::Constant[value=3]() # <string>:396:0\n",
      "  %2283 : int = prim::Constant[value=2]() # <string>:396:0\n",
      "  %2284 : int = prim::Constant[value=4]() # <string>:396:0\n",
      "  %2285 : int[] = prim::ListConstruct(%2280, %2281, %2282, %2283, %2284)\n",
      "  %XQW_batch : Float(2, 1, 4, 4, 32, strides=[512, 1024, 32, 128, 1], requires_grad=1, device=cpu) = aten::permute(%out, %2285) # <string>:396:0\n",
      "  %2289 : int = prim::Constant[value=128]() # <string>:397:0\n",
      "  %2290 : int[] = prim::ListConstruct(%2287, %2288, %2289)\n",
      "  %output_reminder : Float(2, 4, 128, strides=[512, 128, 1], requires_grad=1, device=cpu) = aten::reshape(%XQW_batch, %2290) # <string>:397:0\n",
      "  %2292 : Tensor[] = prim::ListConstruct(%output_mod, %output_reminder)\n",
      "  %2293 : int = prim::Constant[value=1]() # <string>:433:0\n",
      "  %input.5 : Float(2, 100, 128, strides=[12800, 128, 1], requires_grad=1, device=cpu) = aten::cat(%2292, %2293) # <string>:433:0\n",
      "  %2344 : Tensor = prim::CallMethod[name=\"forward\"](%post_norm, %input.5)\n",
      "  %2345 : Tensor = prim::CallMethod[name=\"forward\"](%o_proj, %2344)\n",
      "  return (%2345)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# analysis.nodes\n",
    "# # TODO: 1. modularize everything; 2. track the flow of tensor\n",
    "print(analysis.nodes['seq_modeling_block'].graph_module.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
