{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process SmolLM Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import boto3\n",
    "import gzip,os\n",
    "\n",
    "# cv2 = load_dataset(\"HuggingFaceTB/smollm-corpus\", \"cosmopedia-v2\")\n",
    "# fed = load_dataset(\"HuggingFaceTB/smollm-corpus\", \"fineweb-edu-dedup\")\n",
    "# pe = load_dataset(\"HuggingFaceTB/smollm-corpus\", \"python-edu\")\n",
    "\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"]=\"YOURKEY\"\n",
    "# os.environ[\"AWS_ACCESS_KEY_ID\"]=\"YOURKEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed4 = fed.filter(lambda x: x['metadata']['int_score'] >= 4, num_proc=120)\n",
    "# fed4=load_dataset(\"chengjunyan1/smollm-10\", \"fineweb-edu-dedup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe4 = pe.filter(lambda x: x['score'] > 4.16, num_proc=120)\n",
    "pe4['train'].num_rows,pe4['train'].num_rows/pe['train'].num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import dataset_dict\n",
    "\n",
    "cv2_ratio=(fed4['train'].num_rows/fed['train'].num_rows+pe4['train'].num_rows/pe['train'].num_rows)/2\n",
    "cv2_samples=int(cv2.num_rows['train']*cv2_ratio)\n",
    "cv2_10=cv2['train'].shuffle(seed=42).select(range(cv2_samples))\n",
    "cv2_10=dataset_dict.DatasetDict({'train':cv2_10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_all=fed4['train'].num_rows+pe4['train'].num_rows+cv2_10['train'].num_rows\n",
    "len_all_full=fed['train'].num_rows+pe['train'].num_rows+cv2['train'].num_rows\n",
    "print(fed4['train'].num_rows/len_all, pe4['train'].num_rows/len_all, cv2_10['train'].num_rows/len_all)\n",
    "print(fed['train'].num_rows/len_all_full, pe['train'].num_rows/len_all_full, cv2['train'].num_rows/len_all_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pe4.push_to_hub(\"chengjunyan1/smollm-10\",\"python-edu\")\n",
    "# fed4.push_to_hub(\"chengjunyan1/smollm-10\",\"fineweb-edu-dedup\")\n",
    "# cv2_10.push_to_hub(\"chengjunyan1/smollm-10\",\"cosmopedia-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify processed corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,DatasetDict\n",
    "import boto3\n",
    "import gzip,os\n",
    "import functools as ft\n",
    "\n",
    "\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"]=\"YOURKEY\"\n",
    "# os.environ[\"AWS_ACCESS_KEY_ID\"]=\"YOURKEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed10=load_dataset(\"chengjunyan1/smollm-10\",\"fineweb-edu-dedup\")\n",
    "cv10=load_dataset(\"chengjunyan1/smollm-10\",\"cosmopedia-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_NUM_PROC =  os.cpu_count()*4 # Configure it based on your system, it can significantly speed up the download\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    aws_secret_access_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"])\n",
    "s3 = session.client(\"s3\")\n",
    "bucket_name = \"softwareheritage\"\n",
    "\n",
    "def download_contents(blob_id):\n",
    "    key = f\"content/{blob_id}\"\n",
    "    obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "    with gzip.GzipFile(fileobj=obj['Body']) as fin:\n",
    "        content = fin.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "    return {\"text\": content}\n",
    "\n",
    "def download_python_edu():\n",
    "    ds = load_dataset(\"chengjunyan1/smollm-10\", \"python-edu\", split=\"train\", num_proc=DEFAULT_NUM_PROC)\n",
    "    ds = ds.map(download_contents, input_columns=\"blob_id\", num_proc=DEFAULT_NUM_PROC)\n",
    "    ds = DatasetDict({\"train\": ds})\n",
    "    return ds\n",
    "\n",
    "pe10=download_python_edu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets,DatasetDict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def resample_dataset(dataset, weight):\n",
    "    num_samples = int(len(dataset) * weight)\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=True)\n",
    "    return dataset.select(indices)\n",
    "\n",
    "def combine_datasets(dataset_dicts, weights:dict=None): # weights e.g. {'train':[1.5,1.0]}\n",
    "    combined_dict = {}\n",
    "    \n",
    "    # Initialize weights if not provided\n",
    "    for dataset_dict in dataset_dicts:\n",
    "        for key, dataset in dataset_dict.items():\n",
    "            if key in combined_dict:\n",
    "                combined_dict[key] = concatenate_datasets([combined_dict[key], dataset])\n",
    "            else:\n",
    "                combined_dict[key] = dataset\n",
    "\n",
    "    # Apply weights by resampling the datasets\n",
    "    for key in combined_dict:\n",
    "        datasets = []\n",
    "        for idx,dataset in enumerate(dataset_dicts):\n",
    "            if key in dataset:\n",
    "                if weights is None or key not in weights or weights[key][idx] == 1.0:\n",
    "                    datasets.append(dataset[key])\n",
    "                else:\n",
    "                    resampled_dataset = resample_dataset(dataset[key], weights[key][idx])\n",
    "                    datasets.append(resampled_dataset)\n",
    "        combined_dict[key] = concatenate_datasets(datasets)\n",
    "    \n",
    "    return DatasetDict(combined_dict)\n",
    "\n",
    "\n",
    "dataset_dicts=[pe10,fed10,cv10]\n",
    "combined=combine_datasets(dataset_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test split based on the processed corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/junyanc/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset,DatasetDict\n",
    "import boto3\n",
    "import gzip,os\n",
    "from huggingface_hub import login\n",
    "\n",
    "\n",
    "login('YOURKEY')\n",
    "\n",
    "DEFAULT_NUM_PROC =  os.cpu_count()*4 # Configure it based on your system, it can significantly speed up the download\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]=\"YOURKEY\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]=\"YOURKEY\"\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    aws_secret_access_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"])\n",
    "s3 = session.client(\"s3\")\n",
    "bucket_name = \"softwareheritage\"\n",
    "\n",
    "def download_contents(blob_id):\n",
    "    key = f\"content/{blob_id}\"\n",
    "    obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "    with gzip.GzipFile(fileobj=obj['Body']) as fin:\n",
    "        content = fin.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "    return {\"text\": content}\n",
    "\n",
    "def download_python_edu():\n",
    "    ds = load_dataset(\"chengjunyan1/smollm-10\", \"python-edu\", split=\"train\", num_proc=DEFAULT_NUM_PROC)\n",
    "    ds = ds.map(download_contents, input_columns=\"blob_id\", num_proc=DEFAULT_NUM_PROC)\n",
    "    ds = DatasetDict({\"train\": ds})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47d99c1fc184448aa184ac5ab120d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c28b35d1bb49af8abcf869ed54d009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b80bed51e60496290306a8c3ad10fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab4c5cd931e4d58a0a8361df97facd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/1934 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca4ce0cd3f74ee69fca1c004b817f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea6644a99ee4e50abd4cd96054092b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf82c7bdeb84d9f9664d8d6779adf09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a060f986a34e15a923a84f37dfdc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d54559e9c354c60b883cd93e108da3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607be726d85c420998835a2338d4caa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17ebc542c4e4373af44f56f187b0bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c634a92ec84f32947f18a6397b0658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5359db25402e42e8b807924ddd55b569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9394172b23fb49018f258668cd1627a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function download_contents at 0x7f7687a44ae0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e959b46456c54aaaa0024f8d38982059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=512):   0%|          | 0/864074 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pe=load_dataset(\"HuggingFaceTB/smollm-corpus\", \"python-edu\", num_proc=DEFAULT_NUM_PROC//8)\n",
    "fed=load_dataset(\"HuggingFaceTB/smollm-corpus\", \"fineweb-edu-dedup\", num_proc=DEFAULT_NUM_PROC//8)\n",
    "cv=load_dataset(\"HuggingFaceTB/smollm-corpus\", \"cosmopedia-v2\", num_proc=DEFAULT_NUM_PROC//8)\n",
    "fed10=load_dataset(\"chengjunyan1/smollm-10\",\"fineweb-edu-dedup\",num_proc=DEFAULT_NUM_PROC//8)\n",
    "cv10=load_dataset(\"chengjunyan1/smollm-10\",\"cosmopedia-v2\",num_proc=DEFAULT_NUM_PROC//8)\n",
    "pe10=download_python_edu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c569901a63b46f5834a4f857d2772df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=512):   0%|          | 0/11409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8804547db8341a6bf8b3a638142c8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=512):   0%|          | 0/11409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python-Edu: {'train': 864074} 11409 11409\n",
      "FineWeb-Edu-Dedup: {'train': 22701367} 282567 282567\n",
      "Cosmopedia-V2: {'train': 4537737} 58148 58148\n"
     ]
    }
   ],
   "source": [
    "# random sample 2 GB of data from each dataset\n",
    "smollm_size=673\n",
    "test_ratio=1/smollm_size\n",
    "pe_test_lines=int(pe['train'].num_rows*test_ratio)\n",
    "fed_test_lines=int(fed['train'].num_rows*test_ratio)\n",
    "cv_test_lines=int(cv['train'].num_rows*test_ratio)\n",
    "pe_shuffle=pe['train'].shuffle(seed=42)\n",
    "fed_shuffle=fed['train'].shuffle(seed=42)\n",
    "cv_shuffle=cv['train'].shuffle(seed=42)\n",
    "pe_test=pe_shuffle.select(range(pe_test_lines))\n",
    "pe_eval=pe_shuffle.select(range(pe_test_lines,pe_test_lines*2))\n",
    "pe_test=pe_test.map(download_contents, input_columns=\"blob_id\", num_proc=DEFAULT_NUM_PROC)\n",
    "pe_eval=pe_eval.map(download_contents, input_columns=\"blob_id\", num_proc=DEFAULT_NUM_PROC)\n",
    "fed_test=fed_shuffle.select(range(fed_test_lines))\n",
    "fed_eval=fed_shuffle.select(range(fed_test_lines,fed_test_lines*2))\n",
    "cv_test=cv_shuffle.select(range(cv_test_lines))\n",
    "cv_eval=cv_shuffle.select(range(cv_test_lines,cv_test_lines*2))\n",
    "\n",
    "print('Python-Edu:',pe10.num_rows,pe_eval.num_rows,pe_test.num_rows)\n",
    "print('FineWeb-Edu-Dedup:',fed10.num_rows,fed_eval.num_rows,fed_test.num_rows)\n",
    "print('Cosmopedia-V2:',cv10.num_rows,cv_eval.num_rows,cv_test.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['blob_id', 'repo_name', 'path', 'length_bytes', 'score', 'int_score', 'text'],\n",
       "     num_rows: 11409\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['blob_id', 'repo_name', 'path', 'length_bytes', 'score', 'int_score', 'text'],\n",
       "     num_rows: 11409\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'id', 'metadata'],\n",
       "     num_rows: 282567\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'id', 'metadata'],\n",
       "     num_rows: 282567\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'text', 'token_length', 'audience', 'format', 'seed_data'],\n",
       "     num_rows: 58148\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'text', 'token_length', 'audience', 'format', 'seed_data'],\n",
       "     num_rows: 58148\n",
       " }))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_test,pe_eval,fed_test,fed_eval,cv_test,cv_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove verbatims\n",
    "import multiprocessing as mp\n",
    "def get_text(x):\n",
    "    return x['text']\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    pe_text=pool.map(get_text, pe_test)+pool.map(get_text, pe_eval)\n",
    "    fed_text=pool.map(get_text, fed_test)+pool.map(get_text, fed_eval)\n",
    "    cv_text=pool.map(get_text, cv_test)+pool.map(get_text, cv_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898942c9fabb4bd988d21ceab42bf23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=120):   0%|          | 0/864074 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d1b61f7d0b43d1820100ae680ed155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=120):   0%|          | 0/4537737 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efa8bbd14224d139394ce12384d6744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=120):   0%|          | 0/22701367 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pe_train=pe10.filter(lambda x: x['text'] not in pe_text, num_proc=DEFAULT_NUM_PROC//4-8)\n",
    "cv_train=cv10.filter(lambda x: x['text'] not in cv_text, num_proc=DEFAULT_NUM_PROC//4-8)\n",
    "fed_train=fed10.filter(lambda x: x['text'] not in fed_text, num_proc=DEFAULT_NUM_PROC//4-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pe_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpe_train\u001b[49m,pe10,fed_train,fed10,cv_train,cv10\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pe_train' is not defined"
     ]
    }
   ],
   "source": [
    "pe_train,pe10,fed_train,fed10,cv_train,cv10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe10_corpus=DatasetDict({'train':pe10['train'],'eval':pe_eval,'test':pe_test})\n",
    "fed10_corpus=DatasetDict({'train':fed10['train'],'eval':fed_eval,'test':fed_test})\n",
    "cv10_corpus=DatasetDict({'train':cv10['train'],'eval':cv_eval,'test':cv_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe10_corpus.push_to_hub(\"chengjunyan1/smollm-10-corpus\",\"python-edu\")\n",
    "fed10_corpus.push_to_hub(\"chengjunyan1/smollm-10-corpus\",\"fineweb-edu-dedup\")\n",
    "cv10_corpus.push_to_hub(\"chengjunyan1/smollm-10-corpus\",\"cosmopedia-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train and test splits from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset,DatasetDict\n",
    "import boto3\n",
    "import gzip,os\n",
    "from huggingface_hub import login\n",
    "DEFAULT_NUM_PROC =  os.cpu_count()*4 # Configure it based on your system, it can significantly speed up the download\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]=\"YOURKEY\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]=\"YOURKEY\"\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    aws_secret_access_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"])\n",
    "s3 = session.client(\"s3\")\n",
    "bucket_name = \"softwareheritage\"\n",
    "\n",
    "def download_contents(blob_id):\n",
    "    key = f\"content/{blob_id}\"\n",
    "    obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "    with gzip.GzipFile(fileobj=obj['Body']) as fin:\n",
    "        content = fin.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "    return {\"text\": content}\n",
    "\n",
    "def download_python_edu():\n",
    "    ds = load_dataset(\"chengjunyan1/smollm-10\", \"python-edu\", split=\"train\", num_proc=DEFAULT_NUM_PROC)\n",
    "    ds = ds.map(download_contents, input_columns=\"blob_id\", num_proc=DEFAULT_NUM_PROC)\n",
    "    ds = DatasetDict({\"train\": ds})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9eda3ac832c418abe27dfb6cd2daf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f930337b0f24b85859d35de0a557097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3452f928f646829be1bafab42a81a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9729614db76a476386a65498fba217c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/1934 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1cb1ac426f4bc1b46ebce9763aaf5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b5d266340a4c24a5c9eca673b9626b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782f81da3a20446da6022495f157b6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pe=load_dataset(\"HuggingFaceTB/smollm-corpus\", \"python-edu\", num_proc=DEFAULT_NUM_PROC//8)\n",
    "fed=load_dataset(\"HuggingFaceTB/smollm-corpus\", \"fineweb-edu-dedup\", num_proc=DEFAULT_NUM_PROC//8)\n",
    "cv=load_dataset(\"HuggingFaceTB/smollm-corpus\", \"cosmopedia-v2\", num_proc=DEFAULT_NUM_PROC//8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python-Edu: 7655630 11409 11409\n",
      "FineWeb-Edu-Dedup: 189602871 282567 282567\n",
      "Cosmopedia-V2: 39017704 58148 58148\n"
     ]
    }
   ],
   "source": [
    "# random sample 2 GB of data from each dataset\n",
    "smollm_size=673\n",
    "test_ratio=1/smollm_size\n",
    "pe_test_lines=int(pe['train'].num_rows*test_ratio)\n",
    "fed_test_lines=int(fed['train'].num_rows*test_ratio)\n",
    "cv_test_lines=int(cv['train'].num_rows*test_ratio)\n",
    "pe_shuffle=pe['train'].shuffle(seed=42)\n",
    "fed_shuffle=fed['train'].shuffle(seed=42)\n",
    "cv_shuffle=cv['train'].shuffle(seed=42)\n",
    "pe_test=pe_shuffle.select(range(pe_test_lines))\n",
    "pe_eval=pe_shuffle.select(range(pe_test_lines,pe_test_lines*2))\n",
    "pe_train=pe_shuffle.select(range(pe_test_lines*2,pe_shuffle.num_rows))\n",
    "fed_test=fed_shuffle.select(range(fed_test_lines))\n",
    "fed_eval=fed_shuffle.select(range(fed_test_lines,fed_test_lines*2))\n",
    "fed_train=fed_shuffle.select(range(fed_test_lines*2,fed_shuffle.num_rows))\n",
    "cv_test=cv_shuffle.select(range(cv_test_lines))\n",
    "cv_eval=cv_shuffle.select(range(cv_test_lines,cv_test_lines*2))\n",
    "cv_train=cv_shuffle.select(range(cv_test_lines*2,cv_shuffle.num_rows))\n",
    "\n",
    "print('Python-Edu:',pe_train.num_rows,pe_eval.num_rows,pe_test.num_rows)\n",
    "print('FineWeb-Edu-Dedup:',fed_train.num_rows,fed_eval.num_rows,fed_test.num_rows)\n",
    "print('Cosmopedia-V2:',cv_train.num_rows,cv_eval.num_rows,cv_test.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe10 = pe_train.filter(lambda x: x['score'] > 4.16, num_proc=DEFAULT_NUM_PROC//4-8)\n",
    "fed10 = fed_train.filter(lambda x: x['metadata']['int_score'] >= 4, num_proc=DEFAULT_NUM_PROC//4-8)\n",
    "cv2_ratio=(fed10['train'].num_rows/fed_train['train'].num_rows+pe10['train'].num_rows/pe_train['train'].num_rows)/2\n",
    "cv2_samples=int(cv_train.num_rows['train']*cv2_ratio)\n",
    "cv10=cv_train['train'].shuffle(seed=42).select(range(cv2_samples))\n",
    "cv10=dataset_dict.DatasetDict({'train':cv10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe10_corpus=DatasetDict({'train':pe10['train'],'eval':pe_eval,'test':pe_test})\n",
    "fed10_corpus=DatasetDict({'train':fed10['train'],'eval':fed_eval,'test':fed_test})\n",
    "cv10_corpus=DatasetDict({'train':cv10['train'],'eval':cv_eval,'test':cv_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe10_corpus.push_to_hub(\"chengjunyan1/smollm-10-corpus\",\"python-edu\")\n",
    "pe10_corpus.push_to_hub(\"chengjunyan1/smollm-10-corpus\",\"fineweb-edu-dedup\")\n",
    "pe10_corpus.push_to_hub(\"chengjunyan1/smollm-10-corpus\",\"cosmopedia-v2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
