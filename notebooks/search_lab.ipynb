{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test search utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ChengJunyan1\\anaconda3\\envs\\modis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\ChengJunyan1\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13:16:46:45,294 INFO     [model_agent.py:184] Agent name=`designer`, model_details={\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"max_output_tokens\": 8192,\n",
      "    \"temperature\": 0.3\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenized dataset wikitext-2 from C:\\ChengJunyan1\\Research\\model_discovery\\data\\wikitext-2\\tokenized\\meta-llama/Llama-2-7b-hf\\2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13:16:46:45,963 INFO     [model_agent.py:184] Agent name=`debugger`, model_details={\n",
      "    \"model_name\": \"gpt-4o-mini\",\n",
      "    \"max_output_tokens\": 8192\n",
      "}\n",
      "2024-09-13:16:46:46,231 INFO     [model_agent.py:184] Agent name=`claude`, model_details={\n",
      "    \"model_name\": \"gpt-4o\",\n",
      "    \"max_output_tokens\": 8192\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'evoname': 'test_evo_000', 'scales': '14M,31M,70M', 'selection_ratio': '0.25', 'select_method': 'random', 'design_budget': '0'}\n",
      "Evolution system initialized with scales: ['14M', '31M', '70M']\n",
      "Current scale: 0\n",
      "Budgets remaining: {'70M': 1, '31M': 4, '14M': 16}\n",
      "Checkpoint directory: C:\\ChengJunyan1\\Research\\model_discovery\\ckpt\\test_evo_000\n",
      "gpt2 tree loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13:16:46:47,224 INFO     [model_agent.py:184] Agent name=`designer`, model_details={\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"max_output_tokens\": 8192,\n",
      "    \"temperature\": 0.3\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenized dataset wikitext-2 from C:\\ChengJunyan1\\Research\\model_discovery\\data\\wikitext-2\\tokenized\\meta-llama/Llama-2-7b-hf\\2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13:16:46:48,038 INFO     [model_agent.py:184] Agent name=`debugger`, model_details={\n",
      "    \"model_name\": \"gpt-4o-mini\",\n",
      "    \"max_output_tokens\": 8192\n",
      "}\n",
      "2024-09-13:16:46:48,350 INFO     [model_agent.py:184] Agent name=`claude`, model_details={\n",
      "    \"model_name\": \"gpt-4o\",\n",
      "    \"max_output_tokens\": 8192\n",
      "}\n",
      "2024-09-13:16:46:48,652 INFO     [discover_namespace_packages.py:12] Discovering subpackages in _NamespacePath(['c:\\\\Users\\\\ChengJunyan1\\\\anaconda3\\\\envs\\\\modis\\\\Lib\\\\site-packages\\\\pinecone_plugins'])\n",
      "2024-09-13:16:46:48,654 INFO     [discover_plugins.py:9] Looking for plugins in pinecone_plugins.inference\n",
      "2024-09-13:16:46:48,720 INFO     [installation.py:10] Installing plugin inference into PineconeGRPC\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import inspect\n",
    "import importlib\n",
    "import os,sys\n",
    "import importlib\n",
    "import arxiv\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from model_discovery.evolution import BuildEvolution\n",
    "import model_discovery.utils as U\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers={\"X-API-KEY\": os.environ['S2_API_KEY']}\n",
    "paper_detail='https://api.semanticscholar.org/graph/v1/paper/{paper_id}'\n",
    "\n",
    "\n",
    "strparams=[\n",
    "    f\"evoname=test_evo_000\",\n",
    "    \"scales=14M,31M,70M\",\n",
    "    \"selection_ratio=0.25\",\n",
    "    \"select_method=random\",\n",
    "    \"design_budget=0\",\n",
    "]\n",
    "evo_system = BuildEvolution(\n",
    "    strparams=';'.join(strparams),\n",
    "    do_cache=False,\n",
    "    # cache_type='diskcache',\n",
    ")\n",
    "\n",
    "ptree = evo_system.ptree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get paper files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "refs_s2ids={}\n",
    "REF_TYPES=['Reference','ReferenceCore','ReferenceWithCode','ReferenceCoreWithTree']\n",
    "\n",
    "for i in ptree.G.nodes:\n",
    "    node=ptree.G.nodes[i]['data']\n",
    "    if node.type in REF_TYPES:\n",
    "        s2id=node.s2id\n",
    "        if s2id is not None:\n",
    "            refs_s2ids[i]=s2id\n",
    "        else:\n",
    "            print(i)\n",
    "\n",
    "refs=ptree.filter_by_type(REF_TYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get rec and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_rec_papers(s2id):\n",
    "    url=f'https://api.semanticscholar.org/recommendations/v1/papers/forpaper/{s2id}'\n",
    "    rsp=requests.get(url,headers=headers)\n",
    "    results=rsp.json()\n",
    "    if 'error' in results:\n",
    "        print(s2id)\n",
    "        return None\n",
    "    return results['recommendedPapers']\n",
    "\n",
    "recs={}\n",
    "for i in tqdm(refs_s2ids):\n",
    "    s2id=refs_s2ids[i]\n",
    "    rec=get_rec_papers(s2id)\n",
    "    if rec is not None:\n",
    "        recs[i]=rec\n",
    "    time.sleep(0.1)\n",
    "\n",
    "all_recs={}\n",
    "for i in recs:\n",
    "    for j in recs[i]:\n",
    "        all_recs[j['paperId']]=j['title']\n",
    "\n",
    "# all_recs_filtered={}\n",
    "# for i in all_recs:\n",
    "#     if i in refs_s2ids.values():\n",
    "#         continue\n",
    "#     if i in refs2_detail:\n",
    "#         continue\n",
    "#     all_recs_filtered[i]=all_recs[i]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_paper_detail(s2id):\n",
    "    params={\n",
    "        \"fields\": \"title,abstract,venue,year,referenceCount,citationCount,influentialCitationCount,authors,embedding,tldr,openAccessPdf,externalIds,references\",\n",
    "    }\n",
    "    rsp=requests.get(\n",
    "        paper_detail.format(paper_id=s2id),\n",
    "        headers=headers,\n",
    "        params=params\n",
    "    )\n",
    "    results = rsp.json()\n",
    "    return results\n",
    "\n",
    "save_dir=U.pjoin(ptree.lib_dir,'..','tree_ext','plus')\n",
    "refsp_detail={}\n",
    "U.mkdir(save_dir)\n",
    "for s2id in tqdm(all_recs_filtered):\n",
    "    save_path=U.pjoin(save_dir,f'{s2id}.json')\n",
    "    if U.pexists(save_path):\n",
    "        refsp_detail[s2id]=U.load_json(save_path)\n",
    "        continue\n",
    "    ret=get_paper_detail(s2id)\n",
    "    if 'error' not in ret:\n",
    "        U.save_json(ret,save_path)\n",
    "    refsp_detail[s2id]=ret\n",
    "    time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(refsp_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_recs_filtered)\n",
    "\n",
    "refp_arxiv={}\n",
    "refp_pdfs={}\n",
    "for i in refsp_detail:\n",
    "    if 'openAccessPdf' in refsp_detail[i] and refsp_detail[i]['openAccessPdf'] is not None and 'arxiv' not in refsp_detail[i]['openAccessPdf']['url']:\n",
    "        url=refsp_detail[i]['openAccessPdf']\n",
    "        refp_pdfs[i]=url['url']\n",
    "        continue\n",
    "    if 'externalIds' in refsp_detail[i]:\n",
    "        if 'ArXiv' in refsp_detail[i]['externalIds']:\n",
    "            refp_arxiv[i]=refsp_detail[i]['externalIds']['ArXiv']\n",
    "            continue\n",
    "    # print(i)\n",
    "print(len(refp_arxiv))\n",
    "print(len(refp_pdfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar5iv_url='https://ar5iv.labs.arxiv.org/html/{arxiv_id}'\n",
    "htmlsp_dir=U.pjoin(ptree.lib_dir,'..','files','htmlsp')\n",
    "U.mkdir(htmlsp_dir)\n",
    "pdfsp_dir=U.pjoin(ptree.lib_dir,'..','files','pdfsp')\n",
    "U.mkdir(pdfsp_dir)\n",
    "\n",
    "    \n",
    "# for i in tqdm(refp_arxiv):\n",
    "#     DIR=U.pjoin(htmlsp_dir,f'{i}.html')\n",
    "#     if os.path.exists(DIR):\n",
    "#         continue\n",
    "#     url=ar5iv_url.format(arxiv_id=refp_arxiv[i])\n",
    "\n",
    "#     # Send a GET request to the URL\n",
    "#     response = requests.get(url)\n",
    "\n",
    "#     # Check if the request was successful (status code 200)\n",
    "#     if response.status_code == 200:\n",
    "#         # Save the HTML content to a file\n",
    "#         with open(DIR, \"w\", encoding=\"utf-8\") as file:\n",
    "#             file.write(response.text)\n",
    "#     else:\n",
    "#         print(f\"Failed to retrieve {i}. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "\n",
    "failed_pdfs={}\n",
    "for i in tqdm(refp_pdfs):\n",
    "    url=refp_pdfs[i]\n",
    "    save_path=U.pjoin(pdfsp_dir,f'{i}.pdf')\n",
    "    if not os.path.exists(save_path):\n",
    "        try:\n",
    "            pdf=urllib.request.urlretrieve(url, save_path)\n",
    "        except:\n",
    "            failed_pdfs[i]=url\n",
    "            print(f'Failed to download {i}, {url}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get references and files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    \"fields\": \"openAccessPdf,externalIds\",\n",
    "}\n",
    "\n",
    "pdf_urls={}\n",
    "external_ids={}\n",
    "for i in tqdm(refs_s2ids):\n",
    "    s2id=refs_s2ids[i]\n",
    "    rsp=requests.get(\n",
    "        paper_detail.format(paper_id=s2id),\n",
    "        headers=headers,\n",
    "        params=params\n",
    "    )\n",
    "    results = rsp.json()\n",
    "    if 'openAccessPdf' in results and results['openAccessPdf'] is not None:\n",
    "        pdf_urls[i]=results['openAccessPdf']\n",
    "    if 'externalIds' in results and results['externalIds'] is not None:\n",
    "        external_ids[i]=results['externalIds']\n",
    "    time.sleep(0.1)\n",
    "\n",
    "\n",
    "arxiv_ids={}\n",
    "for i,j in external_ids.items():\n",
    "    if 'ArXiv' in j:\n",
    "        arxiv_ids[i]=j['ArXiv']\n",
    "\n",
    "arxiv_ids_add={\n",
    "    'fire':'2310.04418',\n",
    "    'mogrifier':'1909.01792',\n",
    "    'hedgehog':'2402.04347',\n",
    "    'synthesizer':'2005.00743',\n",
    "    'settransformer':'1810.00825',\n",
    "    'infiniteformer':'2109.00301',\n",
    "    'etc':'2004.08483',\n",
    "    'feedbackmem':'2002.09402',\n",
    "    'kangpt':'2408.10205',\n",
    "}\n",
    "\n",
    "arxiv_ids.update(arxiv_ids_add)\n",
    "\n",
    "ar5iv_url='https://ar5iv.labs.arxiv.org/html/{arxiv_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(id):\n",
    "    return ptree.G.nodes[id]['data']\n",
    "\n",
    "\n",
    "def get_references(id):\n",
    "    params={\n",
    "        \"fields\": \"references\",\n",
    "    }\n",
    "    s2id=refs_s2ids[id]\n",
    "    rsp=requests.get(\n",
    "        paper_detail.format(paper_id=s2id),\n",
    "        headers=headers,\n",
    "        params=params\n",
    "    )\n",
    "    results = rsp.json()\n",
    "    return results['references']\n",
    "\n",
    "\n",
    "all_refs={}\n",
    "for i in tqdm(refs_s2ids):\n",
    "    all_refs[i]=get_references(i)\n",
    "\n",
    "refs_set={}\n",
    "for i in all_refs:\n",
    "    for ref in all_refs[i]:\n",
    "        refs_set[ref['paperId']]=ref['title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_detail(s2id):\n",
    "    params={\n",
    "        \"fields\": \"title,abstract,venue,year,referenceCount,citationCount,influentialCitationCount,authors,tldr,embedding,tldr,openAccessPdf,externalIds,references\",\n",
    "    }\n",
    "    rsp=requests.get(\n",
    "        paper_detail.format(paper_id=s2id),\n",
    "        headers=headers,\n",
    "        params=params\n",
    "    )\n",
    "    results = rsp.json()\n",
    "    return results\n",
    "\n",
    "refs_detail={}\n",
    "save_dir=U.pjoin(ptree.lib_dir,'..','tree_ext','refs2')\n",
    "for i in tqdm(refs_set):\n",
    "    save_path=U.pjoin(save_dir,f'{i}.json')\n",
    "    if U.pexists(save_path):\n",
    "        refs_detail[i]=U.load_json(save_path)\n",
    "        continue\n",
    "    ret=get_paper_detail(i)\n",
    "    if 'error' not in ret:\n",
    "        U.save_json(ret,save_path)\n",
    "    refs_detail[i]=ret\n",
    "    time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs2_detail={}\n",
    "ref2_dir=U.pjoin(ptree.lib_dir,'..','tree_ext','secondary')\n",
    "for i in os.listdir(ref2_dir):\n",
    "    refs2_detail[i.split('.')[0]]=U.load_json(U.pjoin(ref2_dir,i))\n",
    "\n",
    "ref2_arxiv={}\n",
    "ref2_pdfs={}\n",
    "for i in refs_detail:\n",
    "    if 'externalIds' in refs2_detail[i]:\n",
    "        if 'ArXiv' in refs2_detail[i]['externalIds']:\n",
    "            ref2_arxiv[i]=refs2_detail[i]['externalIds']['ArXiv']\n",
    "            continue\n",
    "    if 'openAccessPdf' in refs2_detail[i] and refs2_detail[i]['openAccessPdf'] is not None and 'arxiv' not in refs2_detail[i]['openAccessPdf']['url']:\n",
    "        url=refs_detail[i]['openAccessPdf']\n",
    "        ref2_pdfs[i]=url['url']\n",
    "        continue\n",
    "    # print(i)\n",
    "\n",
    "print(len(ref2_arxiv))\n",
    "print(len(ref2_pdfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, urllib.request\n",
    "\n",
    "save_dir=U.pjoin(ptree.lib_dir,'..','pdfs2')\n",
    "arxiv_pdf='https://arxiv.org/pdf/{arxiv_id}'\n",
    "U.mkdir(save_dir)\n",
    "\n",
    "# bar=tqdm(ref2_arxiv)\n",
    "# for i in bar:\n",
    "#     bar.set_description(f'Downloading {i}')\n",
    "#     arxiv_id=ref2_arxiv[i]\n",
    "#     download_arxiv_pdf(arxiv_id,save_dir,f'{i}.pdf')\n",
    "\n",
    "failed_pdfs={}\n",
    "for i in tqdm(ref2_pdfs):\n",
    "    url=ref2_pdfs[i]\n",
    "    save_path=U.pjoin(save_dir,f'{i}.pdf')\n",
    "    if not os.path.exists(save_path):\n",
    "        try:\n",
    "            pdf=urllib.request.urlretrieve(url, save_path)\n",
    "        except:\n",
    "            failed_pdfs[i]=url\n",
    "            print(f'Failed to download {i}, {url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "save_dir=U.pjoin(ptree.lib_dir,'..','htmls2')\n",
    "U.mkdir(save_dir)\n",
    "ar5iv_url='https://ar5iv.labs.arxiv.org/html/{arxiv_id}'\n",
    "\n",
    "for i in tqdm(ref2_arxiv):\n",
    "    DIR=U.pjoin(save_dir,f'{i}.html')\n",
    "    if os.path.exists(DIR):\n",
    "        continue\n",
    "    url=ar5iv_url.format(arxiv_id=ref2_arxiv[i])\n",
    "        \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Save the HTML content to a file\n",
    "        with open(DIR, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(response.text)\n",
    "        # print(f\"HTML content saved to {i}.html\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve {i}. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmls_dir=U.pjoin(ptree.lib_dir,'..','htmls')\n",
    "pdfs_dir=U.pjoin(ptree.lib_dir,'..','pdfs')\n",
    "\n",
    "htmls=[i.split('.')[0] for i in os.listdir(htmls_dir)]\n",
    "pdfs=[i.split('.')[0] for i in os.listdir(pdfs_dir)]\n",
    "\n",
    "print(len(htmls))\n",
    "print(len(pdfs))\n",
    "\n",
    "arxiv_url='https://arxiv.org/abs/{arxiv_id}'\n",
    "\n",
    "for i in pdfs:\n",
    "    if i not in htmls:\n",
    "        if i in arxiv_ids:\n",
    "            arxiv_id=arxiv_ids[i]\n",
    "            url=ar5iv_url.format(arxiv_id=arxiv_id)\n",
    "            arxiv=arxiv_url.format(arxiv_id=arxiv_id)\n",
    "            print(url,arxiv,i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, urllib.request\n",
    "url = 'http://export.arxiv.org/api/query?search_query=\"{query}\"&start=0&max_results=1'\n",
    "title = ptree.G.nodes[refs[0]]['data'].title\n",
    "encoded_title = urllib.parse.quote(title)\n",
    "url=url.format(query=encoded_title)\n",
    "data = urllib.request.urlopen(url)\n",
    "print(data.read().decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdf_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agents.search_utils \n",
    "importlib.reload(agents.search_utils)\n",
    "\n",
    "from agents.search_utils import SuperScholarSearcher\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dev tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13:16:46:55,901 INFO     [discover_namespace_packages.py:12] Discovering subpackages in _NamespacePath(['c:\\\\Users\\\\ChengJunyan1\\\\anaconda3\\\\envs\\\\modis\\\\Lib\\\\site-packages\\\\pinecone_plugins'])\n",
      "2024-09-13:16:46:55,902 INFO     [discover_plugins.py:9] Looking for plugins in pinecone_plugins.inference\n",
      "2024-09-13:16:46:55,902 INFO     [installation.py:10] Installing plugin inference into PineconeGRPC\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "# sys.path.append('..')\n",
    "\n",
    "import model_discovery.agents.search_utils\n",
    "importlib.reload(model_discovery.agents.search_utils)\n",
    "\n",
    "from model_discovery.agents.search_utils import SuperScholarSearcher, pwc_search_patched\n",
    "\n",
    "sss=SuperScholarSearcher(ptree,evo_system.stream)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vector Store for internal Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading splits Primary: 100%|██████████| 294/294 [00:25<00:00, 11.75it/s]\n",
      "Loading splits Secondary:  69%|██████▉   | 1968/2836 [02:28<00:59, 14.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw_texts in internal library...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading splits Secondary:  69%|██████▉   | 1968/2836 [02:40<00:59, 14.58it/s]2024-09-13:16:50:56,379 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:50:57,804 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  69%|██████▉   | 1970/2836 [03:32<2:08:04,  8.87s/it]2024-09-13:16:51:00,029 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:51:03,007 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  69%|██████▉   | 1971/2836 [03:37<2:00:21,  8.35s/it]2024-09-13:16:51:05,542 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:51:10,604 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:51:12,969 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:51:15,130 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|██████▉   | 1973/2836 [03:49<1:49:01,  7.58s/it]2024-09-13:16:51:16,870 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:51:19,469 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|██████▉   | 1974/2836 [03:54<1:42:36,  7.14s/it]2024-09-13:16:51:22,038 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:51:24,584 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|██████▉   | 1975/2836 [03:59<1:34:17,  6.57s/it]2024-09-13:16:51:25,997 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:51:27,631 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|██████▉   | 1976/2836 [04:02<1:22:38,  5.77s/it]2024-09-13:16:51:29,555 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:51:31,650 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|██████▉   | 1977/2836 [04:05<1:14:20,  5.19s/it]2024-09-13:16:51:33,694 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:53:10,696 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|██████▉   | 1978/2836 [05:45<7:07:53, 29.92s/it]2024-09-13:16:53:15,609 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:53:20,140 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|██████▉   | 1979/2836 [05:54<5:46:41, 24.27s/it]2024-09-13:16:53:21,739 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:53:23,124 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|██████▉   | 1980/2836 [05:57<4:21:32, 18.33s/it]2024-09-13:16:53:25,603 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:53:28,732 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|██████▉   | 1981/2836 [06:03<3:29:53, 14.73s/it]2024-09-13:16:53:31,785 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:53:33,567 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:53:36,839 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|██████▉   | 1982/2836 [06:12<3:07:04, 13.14s/it]2024-09-13:16:53:39,686 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:53:41,879 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|██████▉   | 1983/2836 [06:16<2:28:14, 10.43s/it]2024-09-13:16:53:43,954 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:53:45,761 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|██████▉   | 1984/2836 [06:20<2:00:55,  8.52s/it]2024-09-13:16:53:49,825 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:53:51,343 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:53:53,959 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|██████▉   | 1985/2836 [06:28<2:00:07,  8.47s/it]2024-09-13:16:53:57,022 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:00,515 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:05,149 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1986/2836 [06:39<2:10:58,  9.24s/it]2024-09-13:16:54:07,492 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:10,081 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1987/2836 [06:44<1:50:32,  7.81s/it]2024-09-13:16:54:11,843 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:14,881 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1988/2836 [06:49<1:39:29,  7.04s/it]2024-09-13:16:54:17,820 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:22,105 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1989/2836 [06:56<1:38:49,  7.00s/it]2024-09-13:16:54:23,971 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:28,495 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1990/2836 [07:03<1:37:21,  6.91s/it]2024-09-13:16:54:29,988 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:31,699 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1991/2836 [07:05<1:19:33,  5.65s/it]2024-09-13:16:54:33,227 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:36,500 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1992/2836 [07:11<1:17:26,  5.51s/it]2024-09-13:16:54:38,210 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:40,101 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1993/2836 [07:14<1:07:57,  4.84s/it]2024-09-13:16:54:41,212 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:42,853 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1994/2836 [07:18<1:03:56,  4.56s/it]2024-09-13:16:54:45,284 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:47,369 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1995/2836 [07:22<1:03:45,  4.55s/it]2024-09-13:16:54:50,340 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:52,566 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:55,558 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:54:59,340 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1996/2836 [07:34<1:32:27,  6.60s/it]2024-09-13:16:55:01,305 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:55:03,316 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1997/2836 [07:37<1:18:57,  5.65s/it]2024-09-13:16:55:05,007 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:55:07,125 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1998/2836 [07:42<1:14:33,  5.34s/it]2024-09-13:16:55:09,592 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:55:12,170 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  70%|███████   | 1999/2836 [07:46<1:09:49,  5.00s/it]2024-09-13:16:55:12,944 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:55:14,394 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2000/2836 [07:49<1:00:17,  4.33s/it]2024-09-13:16:55:16,318 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:55:19,560 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2001/2836 [07:54<1:02:33,  4.50s/it]2024-09-13:16:55:21,265 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:55:24,956 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2002/2836 [07:59<1:04:54,  4.67s/it]2024-09-13:16:55:26,721 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:55:29,637 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2003/2836 [08:05<1:09:54,  5.04s/it]2024-09-13:16:55:31,984 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:55:33,469 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2004/2836 [08:07<1:00:31,  4.36s/it]2024-09-13:16:55:34,882 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:55:36,441 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2005/2836 [08:10<54:14,  3.92s/it]  2024-09-13:16:55:37,431 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:55:38,893 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2006/2836 [08:13<49:01,  3.54s/it]2024-09-13:16:55:40,863 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:55:45,346 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2007/2836 [08:20<1:04:55,  4.70s/it]2024-09-13:16:55:48,253 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:55:50,053 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2008/2836 [08:24<1:01:42,  4.47s/it]2024-09-13:16:55:52,014 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:55:55,146 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2009/2836 [08:29<1:02:38,  4.54s/it]2024-09-13:16:55:56,738 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:00,172 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2010/2836 [08:34<1:05:03,  4.73s/it]2024-09-13:16:56:02,044 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:04,985 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:07,470 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:11,664 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2011/2836 [08:46<1:34:20,  6.86s/it]2024-09-13:16:56:13,777 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:16,005 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2012/2836 [08:50<1:21:48,  5.96s/it]2024-09-13:16:56:17,127 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:18,601 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2013/2836 [08:53<1:11:17,  5.20s/it]2024-09-13:16:56:20,950 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:23,691 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2014/2836 [08:58<1:09:01,  5.04s/it]2024-09-13:16:56:25,833 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:27,736 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2015/2836 [09:02<1:03:30,  4.64s/it]2024-09-13:16:56:30,391 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:35,338 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2016/2836 [09:10<1:16:50,  5.62s/it]2024-09-13:16:56:37,689 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:39,173 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:40,868 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2017/2836 [09:15<1:17:20,  5.67s/it]2024-09-13:16:56:43,168 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:46,855 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2018/2836 [09:21<1:17:42,  5.70s/it]2024-09-13:16:56:48,932 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:53,156 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2019/2836 [09:28<1:23:54,  6.16s/it]2024-09-13:16:56:56,416 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:56:58,364 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████   | 2020/2836 [09:33<1:16:00,  5.59s/it]2024-09-13:16:57:00,167 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:02,226 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████▏  | 2021/2836 [09:36<1:07:23,  4.96s/it]2024-09-13:16:57:03,262 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:04,403 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████▏  | 2022/2836 [09:38<56:43,  4.18s/it]  2024-09-13:16:57:05,779 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:07,346 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████▏  | 2023/2836 [09:41<50:36,  3.73s/it]2024-09-13:16:57:08,563 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:10,297 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████▏  | 2024/2836 [09:45<51:51,  3.83s/it]2024-09-13:16:57:12,565 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:14,472 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████▏  | 2025/2836 [09:48<48:54,  3.62s/it]2024-09-13:16:57:15,907 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:18,065 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████▏  | 2026/2836 [09:52<49:03,  3.63s/it]2024-09-13:16:57:20,047 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:22,906 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  71%|███████▏  | 2027/2836 [09:57<55:16,  4.10s/it]2024-09-13:16:57:24,612 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:27,461 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2028/2836 [10:02<57:09,  4.24s/it]2024-09-13:16:57:28,767 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:29,832 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2029/2836 [10:04<50:48,  3.78s/it]2024-09-13:16:57:32,604 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:34,702 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2030/2836 [10:09<52:16,  3.89s/it]2024-09-13:16:57:36,217 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:37,827 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2031/2836 [10:12<50:35,  3.77s/it]2024-09-13:16:57:39,838 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:42,258 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2032/2836 [10:16<51:54,  3.87s/it]2024-09-13:16:57:43,221 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:44,129 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2033/2836 [10:18<43:19,  3.24s/it]2024-09-13:16:57:45,261 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:46,501 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2034/2836 [10:21<40:48,  3.05s/it]2024-09-13:16:57:47,986 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:49,538 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2035/2836 [10:23<39:35,  2.97s/it]2024-09-13:16:57:51,272 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:56,442 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2036/2836 [10:31<59:49,  4.49s/it]2024-09-13:16:57:58,623 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:57:59,764 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2037/2836 [10:34<50:37,  3.80s/it]2024-09-13:16:58:01,065 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:58:03,188 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2038/2836 [10:37<49:02,  3.69s/it]2024-09-13:16:58:04,578 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:58:07,161 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2039/2836 [10:42<54:40,  4.12s/it]2024-09-13:16:58:09,361 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:58:10,783 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2040/2836 [10:45<48:33,  3.66s/it]2024-09-13:16:58:12,567 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:58:15,527 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2041/2836 [10:50<53:38,  4.05s/it]2024-09-13:16:58:17,726 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:58:21,222 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2042/2836 [10:55<1:00:22,  4.56s/it]2024-09-13:16:58:23,356 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:58:25,589 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2043/2836 [11:01<1:02:33,  4.73s/it]2024-09-13:16:58:28,937 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:58:30,416 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:58:32,722 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2044/2836 [11:07<1:10:10,  5.32s/it]2024-09-13:16:58:35,457 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:58:38,656 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2045/2836 [11:13<1:11:42,  5.44s/it]2024-09-13:16:58:40,277 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:58:44,753 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2046/2836 [11:19<1:13:19,  5.57s/it]2024-09-13:16:58:46,495 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:58:50,185 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2047/2836 [11:24<1:12:45,  5.53s/it]2024-09-13:16:58:51,903 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:58:57,656 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2048/2836 [11:31<1:19:04,  6.02s/it]2024-09-13:16:58:58,803 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:00,667 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2049/2836 [11:34<1:07:25,  5.14s/it]2024-09-13:16:59:02,161 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:05,495 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2050/2836 [11:40<1:09:16,  5.29s/it]2024-09-13:16:59:07,889 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:10,384 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2051/2836 [11:45<1:08:54,  5.27s/it]2024-09-13:16:59:12,922 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:14,751 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2052/2836 [11:49<1:00:48,  4.65s/it]2024-09-13:16:59:17,687 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:20,731 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2053/2836 [11:55<1:07:37,  5.18s/it]2024-09-13:16:59:22,363 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:24,651 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2054/2836 [11:59<1:01:52,  4.75s/it]2024-09-13:16:59:26,928 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:29,924 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2055/2836 [12:04<1:04:21,  4.94s/it]2024-09-13:16:59:31,865 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:34,760 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  72%|███████▏  | 2056/2836 [12:10<1:06:45,  5.14s/it]2024-09-13:16:59:37,698 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:40,424 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2057/2836 [12:15<1:05:45,  5.06s/it]2024-09-13:16:59:43,205 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:45,480 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:48,070 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2058/2836 [12:23<1:16:46,  5.92s/it]2024-09-13:16:59:49,840 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:51,576 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2059/2836 [12:26<1:07:52,  5.24s/it]2024-09-13:16:59:54,344 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:56,564 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2060/2836 [12:30<1:04:07,  4.96s/it]2024-09-13:16:59:57,575 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:16:59:58,738 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2061/2836 [12:33<53:48,  4.17s/it]  2024-09-13:17:00:00,479 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:00:02,471 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2062/2836 [12:37<55:18,  4.29s/it]2024-09-13:17:00:06,450 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:00:09,838 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2063/2836 [12:44<1:04:32,  5.01s/it]2024-09-13:17:00:11,980 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:00:14,450 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2064/2836 [12:48<1:01:18,  4.76s/it]2024-09-13:17:00:15,489 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:00:19,228 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2065/2836 [12:53<1:02:22,  4.85s/it]2024-09-13:17:00:21,291 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:00:24,166 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2066/2836 [12:59<1:05:57,  5.14s/it]2024-09-13:17:00:26,653 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:00:29,105 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2067/2836 [13:03<1:02:52,  4.91s/it]2024-09-13:17:00:31,175 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:00:32,619 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2068/2836 [13:06<55:06,  4.30s/it]  2024-09-13:17:00:33,577 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:00:34,796 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2069/2836 [13:09<47:53,  3.75s/it]2024-09-13:17:00:35,966 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:00:37,216 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2070/2836 [13:11<41:28,  3.25s/it]2024-09-13:17:00:39,367 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:00:41,745 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2071/2836 [13:16<46:47,  3.67s/it]2024-09-13:17:00:42,844 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:00:45,644 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2072/2836 [13:20<50:30,  3.97s/it]2024-09-13:17:00:47,609 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:00:49,312 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2073/2836 [13:23<46:02,  3.62s/it]2024-09-13:17:00:50,208 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:00:51,804 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2074/2836 [13:26<41:58,  3.31s/it]2024-09-13:17:00:56,112 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:01:02,042 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2075/2836 [13:36<1:10:10,  5.53s/it]2024-09-13:17:01:03,744 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:01:05,028 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2076/2836 [13:39<58:17,  4.60s/it]  2024-09-13:17:01:06,340 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:01:10,176 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2077/2836 [13:45<1:04:52,  5.13s/it]2024-09-13:17:01:12,445 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:01:13,629 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2078/2836 [13:48<54:42,  4.33s/it]  2024-09-13:17:01:16,048 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:01:18,144 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2079/2836 [13:52<54:58,  4.36s/it]2024-09-13:17:01:19,427 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:01:21,715 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2080/2836 [13:55<51:24,  4.08s/it]2024-09-13:17:01:23,089 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:01:26,028 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2081/2836 [14:00<52:28,  4.17s/it]2024-09-13:17:01:27,029 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:01:28,666 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2082/2836 [14:02<46:47,  3.72s/it]2024-09-13:17:01:31,648 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:01:36,960 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:01:41,573 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2083/2836 [14:16<1:23:58,  6.69s/it]2024-09-13:17:01:43,640 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:01:45,331 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  73%|███████▎  | 2084/2836 [14:20<1:11:27,  5.70s/it]2024-09-13:17:01:48,519 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:01:53,093 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▎  | 2085/2836 [14:28<1:22:02,  6.55s/it]2024-09-13:17:01:55,452 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:02:03,825 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▎  | 2086/2836 [14:38<1:34:08,  7.53s/it]2024-09-13:17:02:05,826 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:02:08,993 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▎  | 2087/2836 [14:44<1:28:24,  7.08s/it]2024-09-13:17:02:12,170 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:02:14,659 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▎  | 2088/2836 [14:48<1:18:56,  6.33s/it]2024-09-13:17:02:16,810 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:02:21,563 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▎  | 2089/2836 [14:56<1:22:28,  6.62s/it]2024-09-13:17:02:23,338 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:02:25,366 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▎  | 2090/2836 [14:59<1:11:06,  5.72s/it]2024-09-13:17:02:27,340 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:02:31,910 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▎  | 2091/2836 [15:06<1:12:56,  5.87s/it]2024-09-13:17:02:33,571 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:02:35,503 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2092/2836 [15:10<1:06:07,  5.33s/it]2024-09-13:17:02:37,448 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:02:39,942 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2093/2836 [15:14<1:02:34,  5.05s/it]2024-09-13:17:02:42,117 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:02:43,739 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2094/2836 [15:18<56:46,  4.59s/it]  2024-09-13:17:02:44,701 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:02:45,997 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2095/2836 [15:20<48:02,  3.89s/it]2024-09-13:17:02:47,798 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:02:50,712 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2096/2836 [15:25<52:00,  4.22s/it]2024-09-13:17:02:54,352 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:03:00,361 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:03:05,100 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2097/2836 [15:40<1:31:43,  7.45s/it]2024-09-13:17:03:08,581 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:03:11,455 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2098/2836 [15:46<1:25:59,  6.99s/it]2024-09-13:17:03:13,737 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:03:16,490 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2099/2836 [15:50<1:17:16,  6.29s/it]2024-09-13:17:03:17,706 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:03:19,278 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2100/2836 [15:53<1:04:34,  5.26s/it]2024-09-13:17:03:20,824 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:03:32,539 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2101/2836 [16:06<1:33:07,  7.60s/it]2024-09-13:17:03:33,993 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:03:35,405 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2102/2836 [16:09<1:16:27,  6.25s/it]2024-09-13:17:03:37,172 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:03:42,433 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2103/2836 [16:16<1:18:19,  6.41s/it]2024-09-13:17:03:43,587 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:03:46,521 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2104/2836 [16:20<1:09:38,  5.71s/it]2024-09-13:17:03:47,461 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:03:48,838 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2105/2836 [16:23<57:17,  4.70s/it]  2024-09-13:17:03:50,735 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:03:54,129 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:03:59,583 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2106/2836 [16:34<1:21:19,  6.68s/it]2024-09-13:17:04:01,190 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:04:03,122 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2107/2836 [16:38<1:10:29,  5.80s/it]2024-09-13:17:04:05,555 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:04:09,131 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2108/2836 [16:43<1:09:36,  5.74s/it]2024-09-13:17:04:10,576 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:04:12,145 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2109/2836 [16:46<59:04,  4.88s/it]  2024-09-13:17:04:14,849 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:04:19,522 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:04:21,581 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2110/2836 [16:56<1:17:06,  6.37s/it]2024-09-13:17:04:23,572 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:04:26,439 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2111/2836 [17:01<1:10:28,  5.83s/it]2024-09-13:17:04:28,458 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:04:31,253 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  74%|███████▍  | 2112/2836 [17:06<1:09:29,  5.76s/it]2024-09-13:17:04:33,783 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:04:36,299 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2113/2836 [17:11<1:05:53,  5.47s/it]2024-09-13:17:04:38,777 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:04:41,617 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2114/2836 [17:16<1:02:39,  5.21s/it]2024-09-13:17:04:43,221 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:04:45,764 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2115/2836 [17:20<1:01:24,  5.11s/it]2024-09-13:17:04:47,873 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:04:50,578 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2116/2836 [17:25<1:00:00,  5.00s/it]2024-09-13:17:04:52,494 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:04:54,861 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2117/2836 [17:29<54:16,  4.53s/it]  2024-09-13:17:04:56,279 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:04:58,705 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2118/2836 [17:32<51:50,  4.33s/it]2024-09-13:17:04:59,700 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:05:01,934 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2119/2836 [17:36<48:45,  4.08s/it]2024-09-13:17:05:03,801 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:05:06,290 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2120/2836 [17:41<52:50,  4.43s/it]2024-09-13:17:05:09,085 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:05:11,206 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2121/2836 [17:45<51:52,  4.35s/it]2024-09-13:17:05:13,586 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:05:17,496 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2122/2836 [17:52<1:01:18,  5.15s/it]2024-09-13:17:05:19,990 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:05:21,405 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2123/2836 [17:55<52:32,  4.42s/it]  2024-09-13:17:06:22,102 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 520 \"\n",
      "2024-09-13:17:06:22,110 INFO     [_base_client.py:1069] Retrying request to /embeddings in 0.939976 seconds\n",
      "2024-09-13:17:06:24,547 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:08:18,393 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2124/2836 [20:53<11:08:50, 56.36s/it]2024-09-13:17:08:20,668 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:08:23,286 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2125/2836 [20:57<8:03:36, 40.81s/it] 2024-09-13:17:08:24,699 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:08:26,786 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▍  | 2126/2836 [21:01<5:50:59, 29.66s/it]2024-09-13:17:08:28,426 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:08:30,468 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2127/2836 [21:05<4:18:16, 21.86s/it]2024-09-13:17:08:32,340 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:08:34,140 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2128/2836 [21:08<3:13:28, 16.40s/it]2024-09-13:17:08:37,341 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:08:41,232 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:08:46,003 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2129/2836 [21:20<2:57:45, 15.09s/it]2024-09-13:17:08:47,666 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:08:49,120 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2130/2836 [21:23<2:13:41, 11.36s/it]2024-09-13:17:08:50,422 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:08:52,275 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2131/2836 [21:26<1:45:59,  9.02s/it]2024-09-13:17:08:54,929 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:08:57,222 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2132/2836 [21:31<1:31:04,  7.76s/it]2024-09-13:17:08:58,531 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:00,118 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2133/2836 [21:34<1:12:49,  6.21s/it]2024-09-13:17:09:03,334 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:06,727 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2134/2836 [21:41<1:14:49,  6.39s/it]2024-09-13:17:09:08,184 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:10,122 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2135/2836 [21:44<1:03:37,  5.45s/it]2024-09-13:17:09:11,918 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:13,601 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:15,621 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2136/2836 [21:50<1:04:33,  5.53s/it]2024-09-13:17:09:16,730 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:19,006 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2137/2836 [21:53<57:44,  4.96s/it]  2024-09-13:17:09:21,075 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:23,632 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2138/2836 [21:58<56:23,  4.85s/it]2024-09-13:17:09:25,082 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:26,310 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2139/2836 [22:00<47:18,  4.07s/it]2024-09-13:17:09:27,955 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:30,702 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2140/2836 [22:05<49:49,  4.29s/it]2024-09-13:17:09:32,594 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:35,197 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  75%|███████▌  | 2141/2836 [22:10<52:31,  4.53s/it]2024-09-13:17:09:37,546 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:39,093 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2142/2836 [22:13<47:55,  4.14s/it]2024-09-13:17:09:40,596 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:42,197 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2143/2836 [22:16<42:44,  3.70s/it]2024-09-13:17:09:43,802 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:45,673 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2144/2836 [22:20<43:05,  3.74s/it]2024-09-13:17:09:47,213 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:48,860 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2145/2836 [22:23<41:07,  3.57s/it]2024-09-13:17:09:50,417 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:52,411 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2146/2836 [22:26<41:04,  3.57s/it]2024-09-13:17:09:54,010 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:09:56,758 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2147/2836 [22:32<46:19,  4.03s/it]2024-09-13:17:09:59,726 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:10:02,890 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:10:06,063 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2148/2836 [22:40<1:02:01,  5.41s/it]2024-09-13:17:10:07,642 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:10:09,409 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2149/2836 [22:43<53:26,  4.67s/it]  2024-09-13:17:10:10,841 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:10:13,376 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2150/2836 [22:47<51:55,  4.54s/it]2024-09-13:17:10:15,417 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:10:19,283 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2151/2836 [22:54<59:22,  5.20s/it]2024-09-13:17:10:21,892 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:10:23,752 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2152/2836 [22:58<53:12,  4.67s/it]2024-09-13:17:10:25,462 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:10:27,234 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2153/2836 [23:01<50:20,  4.42s/it]2024-09-13:17:10:29,440 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:10:32,476 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2154/2836 [23:06<51:31,  4.53s/it]2024-09-13:17:10:34,173 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:10:37,341 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2155/2836 [23:12<54:03,  4.76s/it]2024-09-13:17:10:39,231 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:10:41,548 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2156/2836 [23:16<51:40,  4.56s/it]2024-09-13:17:10:43,102 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:10:44,873 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2157/2836 [23:19<47:27,  4.19s/it]2024-09-13:17:10:46,768 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:10:50,209 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2158/2836 [23:24<51:10,  4.53s/it]2024-09-13:17:10:52,047 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:10:55,404 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2159/2836 [23:29<52:32,  4.66s/it]2024-09-13:17:10:58,112 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:00,627 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:04,882 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2160/2836 [23:39<1:09:54,  6.20s/it]2024-09-13:17:11:07,019 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:09,145 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2161/2836 [23:43<1:03:32,  5.65s/it]2024-09-13:17:11:11,655 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:14,008 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▌  | 2162/2836 [23:48<1:00:41,  5.40s/it]2024-09-13:17:11:15,703 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:17,348 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▋  | 2163/2836 [23:51<53:16,  4.75s/it]  2024-09-13:17:11:19,086 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:22,168 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▋  | 2164/2836 [23:57<55:12,  4.93s/it]2024-09-13:17:11:25,332 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:27,634 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:29,636 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▋  | 2165/2836 [24:04<1:02:58,  5.63s/it]2024-09-13:17:11:32,796 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:36,889 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▋  | 2166/2836 [24:12<1:09:38,  6.24s/it]2024-09-13:17:11:39,217 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:40,427 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▋  | 2167/2836 [24:14<57:09,  5.13s/it]  2024-09-13:17:11:43,216 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:46,636 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:52,053 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:55,640 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:11:59,067 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:12:00,437 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:12:08,604 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▋  | 2168/2836 [24:44<2:20:57, 12.66s/it]2024-09-13:17:12:13,414 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:12:17,434 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  76%|███████▋  | 2169/2836 [24:52<2:02:39, 11.03s/it]2024-09-13:17:12:19,643 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:12:22,383 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2170/2836 [24:57<1:42:44,  9.26s/it]2024-09-13:17:12:24,578 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:12:29,463 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2171/2836 [25:03<1:34:00,  8.48s/it]2024-09-13:17:12:30,462 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:12:31,178 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2172/2836 [25:05<1:10:02,  6.33s/it]2024-09-13:17:12:32,606 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:12:34,886 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2173/2836 [25:09<1:02:03,  5.62s/it]2024-09-13:17:12:36,448 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:12:38,356 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2174/2836 [25:12<54:38,  4.95s/it]  2024-09-13:17:12:40,467 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:12:44,179 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2175/2836 [25:19<1:02:01,  5.63s/it]2024-09-13:17:12:46,883 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:12:48,115 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2176/2836 [25:22<51:36,  4.69s/it]  2024-09-13:17:12:49,446 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:12:51,349 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2177/2836 [25:26<50:41,  4.62s/it]2024-09-13:17:12:55,560 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:12:58,398 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2178/2836 [25:32<55:32,  5.07s/it]2024-09-13:17:13:00,549 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:02,799 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2179/2836 [25:37<52:40,  4.81s/it]2024-09-13:17:13:04,540 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:07,337 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2180/2836 [25:41<51:23,  4.70s/it]2024-09-13:17:13:08,444 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:10,205 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2181/2836 [25:44<46:22,  4.25s/it]2024-09-13:17:13:12,228 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:15,079 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2182/2836 [25:49<49:00,  4.50s/it]2024-09-13:17:13:16,859 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:18,803 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2183/2836 [25:53<44:44,  4.11s/it]2024-09-13:17:13:20,311 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:23,863 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2184/2836 [25:58<50:01,  4.60s/it]2024-09-13:17:13:25,908 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:27,719 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2185/2836 [26:01<45:17,  4.17s/it]2024-09-13:17:13:29,909 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:34,636 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2186/2836 [26:09<54:41,  5.05s/it]2024-09-13:17:13:37,007 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:39,133 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:42,930 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2187/2836 [26:18<1:07:21,  6.23s/it]2024-09-13:17:13:44,957 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:46,475 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2188/2836 [26:20<55:52,  5.17s/it]  2024-09-13:17:13:48,486 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:50,119 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:51,926 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2189/2836 [26:26<57:31,  5.33s/it]2024-09-13:17:13:53,372 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:13:55,060 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2190/2836 [26:29<49:18,  4.58s/it]2024-09-13:17:13:58,627 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:14:02,509 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2191/2836 [26:36<59:10,  5.51s/it]2024-09-13:17:14:04,252 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:14:06,692 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2192/2836 [26:41<55:38,  5.18s/it]2024-09-13:17:14:08,998 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:14:11,652 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2193/2836 [26:46<54:02,  5.04s/it]2024-09-13:17:14:13,930 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:14:18,182 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2194/2836 [26:52<59:45,  5.58s/it]2024-09-13:17:14:22,935 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:14:24,861 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:14:28,501 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2195/2836 [27:03<1:14:46,  7.00s/it]2024-09-13:17:14:31,630 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:14:34,803 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2196/2836 [27:09<1:13:15,  6.87s/it]2024-09-13:17:14:37,673 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:14:41,464 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  77%|███████▋  | 2197/2836 [27:16<1:12:03,  6.77s/it]2024-09-13:17:14:43,224 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:14:45,618 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2198/2836 [27:20<1:02:27,  5.87s/it]2024-09-13:17:14:47,357 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:14:49,463 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2199/2836 [27:24<56:32,  5.33s/it]  2024-09-13:17:14:54,384 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:14:59,775 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2200/2836 [27:34<1:11:39,  6.76s/it]2024-09-13:17:15:02,046 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:15:05,231 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2201/2836 [27:40<1:09:59,  6.61s/it]2024-09-13:17:15:08,292 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:15:11,331 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2202/2836 [27:45<1:05:29,  6.20s/it]2024-09-13:17:15:12,655 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:15:15,177 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2203/2836 [27:49<57:22,  5.44s/it]  2024-09-13:17:15:16,409 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:15:17,645 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2204/2836 [27:52<48:42,  4.62s/it]2024-09-13:17:15:19,345 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:15:22,082 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2205/2836 [27:56<48:43,  4.63s/it]2024-09-13:17:15:24,123 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:15:26,513 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2206/2836 [28:00<46:48,  4.46s/it]2024-09-13:17:15:28,679 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:15:31,215 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2207/2836 [28:05<48:31,  4.63s/it]2024-09-13:17:15:33,457 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:15:35,469 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2208/2836 [28:09<45:55,  4.39s/it]2024-09-13:17:15:36,839 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:15:39,005 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2209/2836 [28:13<43:11,  4.13s/it]2024-09-13:17:15:41,856 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:15:45,042 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:15:49,929 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2210/2836 [28:25<1:09:19,  6.64s/it]2024-09-13:17:15:53,447 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:15:56,077 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2211/2836 [28:30<1:04:22,  6.18s/it]2024-09-13:17:15:58,294 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:01,002 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2212/2836 [28:35<1:00:14,  5.79s/it]2024-09-13:17:16:02,708 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:04,956 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2213/2836 [28:40<56:07,  5.41s/it]  2024-09-13:17:16:07,015 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:08,414 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2214/2836 [28:42<47:01,  4.54s/it]2024-09-13:17:16:10,807 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:12,983 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2215/2836 [28:47<47:13,  4.56s/it]2024-09-13:17:16:14,248 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:16,421 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2216/2836 [28:51<44:13,  4.28s/it]2024-09-13:17:16:17,828 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:19,172 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2217/2836 [28:53<39:19,  3.81s/it]2024-09-13:17:16:20,551 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:21,980 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2218/2836 [28:56<35:06,  3.41s/it]2024-09-13:17:16:24,026 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:25,436 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:28,032 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2219/2836 [29:03<45:39,  4.44s/it]2024-09-13:17:16:30,091 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:32,048 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2220/2836 [29:06<42:10,  4.11s/it]2024-09-13:17:16:34,056 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:37,510 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2221/2836 [29:12<47:18,  4.62s/it]2024-09-13:17:16:39,419 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:41,685 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2222/2836 [29:16<44:57,  4.39s/it]2024-09-13:17:16:43,383 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:45,195 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2223/2836 [29:19<42:03,  4.12s/it]2024-09-13:17:16:46,476 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:48,880 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2224/2836 [29:23<40:50,  4.00s/it]2024-09-13:17:16:51,351 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:16:56,251 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2225/2836 [29:31<54:00,  5.30s/it]2024-09-13:17:16:59,922 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:17:03,705 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  78%|███████▊  | 2226/2836 [29:38<57:27,  5.65s/it]2024-09-13:17:17:05,162 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:17:07,563 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▊  | 2227/2836 [29:42<53:05,  5.23s/it]2024-09-13:17:17:09,499 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:17:10,790 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▊  | 2228/2836 [29:45<45:35,  4.50s/it]2024-09-13:17:17:11,926 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:17:13,189 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▊  | 2229/2836 [29:47<38:51,  3.84s/it]2024-09-13:17:17:14,740 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:17:17,162 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▊  | 2230/2836 [29:52<42:35,  4.22s/it]2024-09-13:17:17:20,709 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:17:22,790 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▊  | 2231/2836 [29:57<44:53,  4.45s/it]2024-09-13:17:17:24,199 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:17:26,482 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▊  | 2232/2836 [30:01<43:25,  4.31s/it]2024-09-13:17:17:29,511 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:17:33,059 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▊  | 2233/2836 [30:07<49:13,  4.90s/it]2024-09-13:17:17:34,714 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:17:36,796 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2234/2836 [30:11<46:54,  4.68s/it]2024-09-13:17:17:39,422 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:17:42,305 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2235/2836 [30:16<47:02,  4.70s/it]2024-09-13:17:17:44,077 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:17:46,212 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2236/2836 [30:21<47:44,  4.77s/it]2024-09-13:17:17:48,909 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:17:50,541 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2237/2836 [30:24<43:08,  4.32s/it]2024-09-13:17:17:54,481 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:17:59,495 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2238/2836 [30:34<58:39,  5.89s/it]2024-09-13:17:18:01,677 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:18:04,740 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2239/2836 [30:39<56:02,  5.63s/it]2024-09-13:17:18:06,289 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:18:08,018 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2240/2836 [30:42<48:26,  4.88s/it]2024-09-13:17:18:09,971 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:18:13,711 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2241/2836 [30:48<51:11,  5.16s/it]2024-09-13:17:18:15,487 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:18:17,111 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2242/2836 [30:51<44:38,  4.51s/it]2024-09-13:17:18:18,806 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:18:22,064 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2243/2836 [30:56<45:54,  4.65s/it]2024-09-13:17:19:24,904 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:19:28,450 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:19:33,818 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:19:36,591 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:19:41,586 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:19:45,139 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:19:48,970 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:19:52,190 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:19:57,415 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:19:59,862 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:20:02,825 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:20:06,320 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:20:09,641 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:20:13,029 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:20:31,832 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2244/2836 [33:11<7:11:09, 43.70s/it]2024-09-13:17:20:38,654 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:20:41,895 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2245/2836 [33:16<5:17:20, 32.22s/it]2024-09-13:17:20:43,579 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:20:46,104 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2246/2836 [33:20<3:53:34, 23.75s/it]2024-09-13:17:20:49,044 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:20:52,145 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2247/2836 [33:26<3:01:37, 18.50s/it]2024-09-13:17:20:54,711 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:20:56,975 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2248/2836 [33:31<2:21:11, 14.41s/it]2024-09-13:17:20:58,164 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:20:59,284 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2249/2836 [33:33<1:43:37, 10.59s/it]2024-09-13:17:21:00,605 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:21:02,330 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2250/2836 [33:36<1:22:00,  8.40s/it]2024-09-13:17:21:05,261 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:21:07,797 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:21:10,930 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2251/2836 [33:45<1:24:20,  8.65s/it]2024-09-13:17:21:14,328 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:21:19,461 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2252/2836 [33:54<1:23:20,  8.56s/it]2024-09-13:17:21:21,341 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:21:22,952 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2253/2836 [33:57<1:06:44,  6.87s/it]2024-09-13:17:21:23,873 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:21:25,208 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  79%|███████▉  | 2254/2836 [33:59<53:21,  5.50s/it]  2024-09-13:17:21:26,218 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:21:27,662 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2255/2836 [34:01<44:09,  4.56s/it]2024-09-13:17:21:29,888 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:21:32,557 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2256/2836 [34:07<46:32,  4.82s/it]2024-09-13:17:21:35,512 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:21:38,820 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2257/2836 [34:13<49:43,  5.15s/it]2024-09-13:17:21:40,670 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:21:42,912 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2258/2836 [34:17<46:25,  4.82s/it]2024-09-13:17:21:44,276 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:21:46,279 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2259/2836 [34:20<42:04,  4.37s/it]2024-09-13:17:21:47,335 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:21:48,979 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2260/2836 [34:23<37:42,  3.93s/it]2024-09-13:17:21:52,199 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:21:55,312 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2261/2836 [34:30<47:13,  4.93s/it]2024-09-13:17:21:58,383 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:01,445 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2262/2836 [34:35<47:38,  4.98s/it]2024-09-13:17:22:02,697 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:04,472 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2263/2836 [34:39<42:21,  4.44s/it]2024-09-13:17:22:07,138 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:10,379 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2264/2836 [34:44<46:13,  4.85s/it]2024-09-13:17:22:11,676 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:12,934 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2265/2836 [34:47<39:06,  4.11s/it]2024-09-13:17:22:14,556 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:17,009 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2266/2836 [34:51<39:07,  4.12s/it]2024-09-13:17:22:20,225 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:22,359 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:25,242 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2267/2836 [35:00<52:25,  5.53s/it]2024-09-13:17:22:27,137 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:28,405 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|███████▉  | 2268/2836 [35:02<43:46,  4.62s/it]2024-09-13:17:22:29,844 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:31,920 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2269/2836 [35:07<43:32,  4.61s/it]2024-09-13:17:22:34,393 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:36,444 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2270/2836 [35:11<42:31,  4.51s/it]2024-09-13:17:22:38,274 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:39,789 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2271/2836 [35:14<37:33,  3.99s/it]2024-09-13:17:22:42,532 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:46,985 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2272/2836 [35:21<46:19,  4.93s/it]2024-09-13:17:22:48,413 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:50,249 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2273/2836 [35:24<42:14,  4.50s/it]2024-09-13:17:22:51,889 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:53,164 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2274/2836 [35:27<36:41,  3.92s/it]2024-09-13:17:22:55,416 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:22:58,651 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2275/2836 [35:33<41:22,  4.43s/it]2024-09-13:17:23:00,175 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:02,288 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2276/2836 [35:36<38:27,  4.12s/it]2024-09-13:17:23:03,555 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:05,161 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2277/2836 [35:39<35:14,  3.78s/it]2024-09-13:17:23:07,505 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:10,918 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2278/2836 [35:45<40:52,  4.40s/it]2024-09-13:17:23:12,153 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:13,840 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2279/2836 [35:48<37:06,  4.00s/it]2024-09-13:17:23:16,528 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:20,465 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2280/2836 [35:54<43:50,  4.73s/it]2024-09-13:17:23:22,308 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:25,106 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2281/2836 [35:59<43:12,  4.67s/it]2024-09-13:17:23:26,617 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:28,608 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  80%|████████  | 2282/2836 [36:02<40:08,  4.35s/it]2024-09-13:17:23:30,472 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:33,715 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2283/2836 [36:08<43:22,  4.71s/it]2024-09-13:17:23:36,376 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:39,369 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2284/2836 [36:13<44:51,  4.88s/it]2024-09-13:17:23:41,157 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:43,034 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2285/2836 [36:17<41:09,  4.48s/it]2024-09-13:17:23:44,323 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:45,773 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2286/2836 [36:20<36:15,  3.96s/it]2024-09-13:17:23:48,048 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:50,846 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2287/2836 [36:25<40:27,  4.42s/it]2024-09-13:17:23:53,062 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:55,772 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2288/2836 [36:30<40:58,  4.49s/it]2024-09-13:17:23:57,581 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:23:59,314 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2289/2836 [36:33<37:55,  4.16s/it]2024-09-13:17:24:01,953 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:06,266 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:08,666 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:12,464 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:15,498 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:22,317 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2290/2836 [36:58<1:35:29, 10.49s/it]2024-09-13:17:24:25,978 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:27,588 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2291/2836 [37:01<1:14:50,  8.24s/it]2024-09-13:17:24:28,571 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:29,547 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2292/2836 [37:03<57:26,  6.34s/it]  2024-09-13:17:24:31,398 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:33,792 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2293/2836 [37:08<52:11,  5.77s/it]2024-09-13:17:24:35,322 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:38,049 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2294/2836 [37:12<47:34,  5.27s/it]2024-09-13:17:24:38,933 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:40,614 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2295/2836 [37:15<41:34,  4.61s/it]2024-09-13:17:24:42,144 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:43,562 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2296/2836 [37:17<35:43,  3.97s/it]2024-09-13:17:24:45,476 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:47,580 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2297/2836 [37:21<35:49,  3.99s/it]2024-09-13:17:24:48,974 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:51,122 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2298/2836 [37:25<34:51,  3.89s/it]2024-09-13:17:24:52,690 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:24:54,686 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2299/2836 [37:28<33:16,  3.72s/it]2024-09-13:17:24:56,794 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:25:00,012 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2300/2836 [37:34<39:15,  4.40s/it]2024-09-13:17:25:01,649 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:25:03,302 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2301/2836 [37:37<34:47,  3.90s/it]2024-09-13:17:25:06,521 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:25:10,304 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2302/2836 [37:44<43:07,  4.85s/it]2024-09-13:17:25:11,653 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:25:13,989 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2303/2836 [37:48<40:51,  4.60s/it]2024-09-13:17:25:15,690 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:25:17,384 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████  | 2304/2836 [37:51<36:50,  4.15s/it]2024-09-13:17:25:20,084 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:25:23,816 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:25:26,403 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████▏ | 2305/2836 [38:00<50:06,  5.66s/it]2024-09-13:17:25:28,491 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:25:29,980 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████▏ | 2306/2836 [38:04<44:00,  4.98s/it]2024-09-13:17:25:31,347 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:25:32,804 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████▏ | 2307/2836 [38:07<38:43,  4.39s/it]2024-09-13:17:25:34,566 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:25:37,547 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████▏ | 2308/2836 [38:11<38:53,  4.42s/it]2024-09-13:17:25:39,334 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:25:42,062 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████▏ | 2309/2836 [38:16<40:09,  4.57s/it]2024-09-13:17:25:43,639 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:25:44,977 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████▏ | 2310/2836 [38:19<35:22,  4.03s/it]2024-09-13:17:25:46,754 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:25:48,405 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  81%|████████▏ | 2311/2836 [38:22<33:09,  3.79s/it]2024-09-13:17:25:52,413 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:27:30,249 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2312/2836 [40:04<4:50:31, 33.27s/it]2024-09-13:17:27:31,409 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:27:32,445 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2313/2836 [40:06<3:28:16, 23.89s/it]2024-09-13:17:27:33,878 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:27:35,913 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2314/2836 [40:10<2:35:28, 17.87s/it]2024-09-13:17:27:39,568 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:27:44,666 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2315/2836 [40:19<2:10:45, 15.06s/it]2024-09-13:17:27:46,088 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:27:47,579 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2316/2836 [40:22<1:39:22, 11.47s/it]2024-09-13:17:27:49,367 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:27:51,753 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2317/2836 [40:26<1:21:19,  9.40s/it]2024-09-13:17:27:53,490 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:27:55,154 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2318/2836 [40:29<1:04:12,  7.44s/it]2024-09-13:17:27:57,628 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:27:59,814 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2319/2836 [40:34<56:39,  6.58s/it]  2024-09-13:17:28:01,066 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:02,872 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2320/2836 [40:37<47:50,  5.56s/it]2024-09-13:17:28:05,291 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:08,194 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2321/2836 [40:42<47:35,  5.55s/it]2024-09-13:17:28:12,267 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:17,154 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:19,585 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:23,768 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2322/2836 [40:58<1:13:32,  8.58s/it]2024-09-13:17:28:26,568 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:29,330 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2323/2836 [41:03<1:04:26,  7.54s/it]2024-09-13:17:28:30,576 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:32,696 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2324/2836 [41:06<53:19,  6.25s/it]  2024-09-13:17:28:34,207 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:36,019 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2325/2836 [41:10<45:51,  5.38s/it]2024-09-13:17:28:37,053 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:38,377 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2326/2836 [41:12<37:38,  4.43s/it]2024-09-13:17:28:39,499 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:41,273 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2327/2836 [41:15<33:53,  3.99s/it]2024-09-13:17:28:43,262 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:45,748 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2328/2836 [41:20<35:14,  4.16s/it]2024-09-13:17:28:46,924 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:47,822 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2329/2836 [41:22<29:42,  3.52s/it]2024-09-13:17:28:50,427 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:53,164 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:28:55,920 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2330/2836 [41:30<42:54,  5.09s/it]2024-09-13:17:28:58,567 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:01,659 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2331/2836 [41:37<45:38,  5.42s/it]2024-09-13:17:29:05,084 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:07,857 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2332/2836 [41:42<45:01,  5.36s/it]2024-09-13:17:29:09,342 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:11,498 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2333/2836 [41:46<42:21,  5.05s/it]2024-09-13:17:29:13,390 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:14,797 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2334/2836 [41:49<37:51,  4.53s/it]2024-09-13:17:29:16,833 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:18,713 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2335/2836 [41:53<35:07,  4.21s/it]2024-09-13:17:29:21,930 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:24,007 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:26,255 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2336/2836 [42:01<44:04,  5.29s/it]2024-09-13:17:29:27,847 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:28,883 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2337/2836 [42:03<36:27,  4.38s/it]2024-09-13:17:29:31,182 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:35,537 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2338/2836 [42:10<42:41,  5.14s/it]2024-09-13:17:29:37,275 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:39,444 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  82%|████████▏ | 2339/2836 [42:14<40:09,  4.85s/it]2024-09-13:17:29:41,631 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:44,068 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2340/2836 [42:18<39:13,  4.75s/it]2024-09-13:17:29:45,786 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:46,998 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2341/2836 [42:22<34:55,  4.23s/it]2024-09-13:17:29:48,934 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:50,290 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2342/2836 [42:24<31:18,  3.80s/it]2024-09-13:17:29:51,587 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:29:52,579 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2343/2836 [42:26<26:39,  3.24s/it]2024-09-13:17:29:57,928 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:30:02,385 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2344/2836 [42:38<46:20,  5.65s/it]2024-09-13:17:30:06,357 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:30:09,224 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:30:13,587 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2345/2836 [42:49<1:00:25,  7.38s/it]2024-09-13:17:30:16,203 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:30:17,561 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2346/2836 [42:52<48:38,  5.96s/it]  2024-09-13:17:30:19,865 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:30:23,330 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2347/2836 [42:58<50:16,  6.17s/it]2024-09-13:17:30:26,089 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:30:28,418 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2348/2836 [43:02<44:43,  5.50s/it]2024-09-13:17:30:29,921 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:30:32,731 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2349/2836 [43:07<42:48,  5.27s/it]2024-09-13:17:30:35,005 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:30:37,795 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2350/2836 [43:12<42:14,  5.22s/it]2024-09-13:17:30:39,678 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:30:41,647 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2351/2836 [43:15<37:38,  4.66s/it]2024-09-13:17:30:44,292 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:30:47,269 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:30:51,484 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2352/2836 [43:26<51:24,  6.37s/it]2024-09-13:17:30:53,456 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:30:55,656 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2353/2836 [43:30<45:25,  5.64s/it]2024-09-13:17:30:57,524 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:30:59,548 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2354/2836 [43:34<41:33,  5.17s/it]2024-09-13:17:31:01,373 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:03,006 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2355/2836 [43:37<36:52,  4.60s/it]2024-09-13:17:31:04,544 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:06,709 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2356/2836 [43:41<34:42,  4.34s/it]2024-09-13:17:31:08,457 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:10,352 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2357/2836 [43:44<32:58,  4.13s/it]2024-09-13:17:31:12,377 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:15,713 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2358/2836 [43:50<37:03,  4.65s/it]2024-09-13:17:31:18,478 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:22,474 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2359/2836 [43:56<40:16,  5.07s/it]2024-09-13:17:31:23,737 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:25,009 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2360/2836 [43:59<33:44,  4.25s/it]2024-09-13:17:31:25,878 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:26,800 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2361/2836 [44:00<27:50,  3.52s/it]2024-09-13:17:31:30,735 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:35,634 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2362/2836 [44:10<41:08,  5.21s/it]2024-09-13:17:31:37,225 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:39,134 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2363/2836 [44:13<37:03,  4.70s/it]2024-09-13:17:31:40,691 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:42,204 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2364/2836 [44:16<32:26,  4.12s/it]2024-09-13:17:31:43,690 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:46,018 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2365/2836 [44:20<32:48,  4.18s/it]2024-09-13:17:31:48,322 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:50,152 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2366/2836 [44:24<32:38,  4.17s/it]2024-09-13:17:31:52,346 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:55,340 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2367/2836 [44:29<33:57,  4.35s/it]2024-09-13:17:31:56,823 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:31:59,399 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  83%|████████▎ | 2368/2836 [44:34<34:12,  4.39s/it]2024-09-13:17:32:00,854 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:01,924 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▎ | 2369/2836 [44:36<29:21,  3.77s/it]2024-09-13:17:32:03,440 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:05,488 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▎ | 2370/2836 [44:40<30:14,  3.89s/it]2024-09-13:17:32:08,031 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:10,501 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▎ | 2371/2836 [44:45<32:22,  4.18s/it]2024-09-13:17:32:13,117 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:15,108 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:17,239 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▎ | 2372/2836 [44:51<37:13,  4.81s/it]2024-09-13:17:32:18,736 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:19,835 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▎ | 2373/2836 [44:54<32:35,  4.22s/it]2024-09-13:17:32:22,604 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:27,606 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:29,978 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:33,179 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▎ | 2374/2836 [45:08<54:58,  7.14s/it]2024-09-13:17:32:37,201 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:41,024 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:43,242 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▎ | 2375/2836 [45:18<1:00:34,  7.88s/it]2024-09-13:17:32:45,558 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:47,585 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2376/2836 [45:22<51:08,  6.67s/it]  2024-09-13:17:32:48,845 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:50,784 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2377/2836 [45:25<43:23,  5.67s/it]2024-09-13:17:32:53,424 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:32:58,070 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:33:02,257 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2378/2836 [45:38<59:28,  7.79s/it]2024-09-13:17:33:06,046 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:33:08,544 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2379/2836 [45:43<53:28,  7.02s/it]2024-09-13:17:33:11,299 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:33:14,562 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2380/2836 [45:49<51:04,  6.72s/it]2024-09-13:17:33:17,945 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:33:20,410 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:33:24,666 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2381/2836 [45:59<59:54,  7.90s/it]2024-09-13:17:33:27,292 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:33:29,033 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2382/2836 [46:03<49:23,  6.53s/it]2024-09-13:17:33:30,328 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:33:32,513 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2383/2836 [46:06<42:44,  5.66s/it]2024-09-13:17:33:33,679 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:33:35,894 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2384/2836 [46:10<37:21,  4.96s/it]2024-09-13:17:33:38,202 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:33:41,698 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2385/2836 [46:16<39:39,  5.28s/it]2024-09-13:17:33:43,504 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:33:45,688 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2386/2836 [46:20<37:04,  4.94s/it]2024-09-13:17:33:47,592 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:33:49,792 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2387/2836 [46:24<34:20,  4.59s/it]2024-09-13:17:33:52,308 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:33:55,247 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2388/2836 [46:29<35:41,  4.78s/it]2024-09-13:17:33:56,356 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:33:57,607 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2389/2836 [46:31<30:30,  4.10s/it]2024-09-13:17:33:59,164 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:34:02,633 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2390/2836 [46:37<33:19,  4.48s/it]2024-09-13:17:34:05,200 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:34:07,068 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:34:10,281 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2391/2836 [46:45<41:33,  5.60s/it]2024-09-13:17:34:14,008 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:34:17,784 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:34:22,487 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:34:28,151 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2392/2836 [47:04<1:11:10,  9.62s/it]2024-09-13:17:34:31,210 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:34:32,417 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2393/2836 [47:06<54:13,  7.34s/it]  2024-09-13:17:34:33,191 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:34:34,356 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2394/2836 [47:09<44:05,  5.99s/it]2024-09-13:17:34:36,669 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:34:38,628 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2395/2836 [47:13<39:25,  5.36s/it]2024-09-13:17:34:40,449 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:34:42,719 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  84%|████████▍ | 2396/2836 [47:17<36:34,  4.99s/it]2024-09-13:17:34:44,692 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:34:47,632 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2397/2836 [47:22<36:28,  4.99s/it]2024-09-13:17:34:50,576 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:34:54,567 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2398/2836 [47:29<40:30,  5.55s/it]2024-09-13:17:34:56,474 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:34:58,636 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2399/2836 [47:32<36:27,  5.00s/it]2024-09-13:17:35:00,113 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:35:02,034 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2400/2836 [47:36<32:43,  4.50s/it]2024-09-13:17:35:05,351 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:35:09,854 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:35:12,922 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2401/2836 [47:47<47:57,  6.61s/it]2024-09-13:17:35:15,498 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:35:19,638 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2402/2836 [47:54<47:40,  6.59s/it]2024-09-13:17:35:22,590 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:35:24,697 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:35:28,648 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2403/2836 [48:03<53:55,  7.47s/it]2024-09-13:17:35:31,150 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:35:34,944 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2404/2836 [48:09<50:04,  6.96s/it]2024-09-13:17:35:36,670 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:35:40,046 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2405/2836 [48:14<45:20,  6.31s/it]2024-09-13:17:35:41,920 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:35:44,539 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2406/2836 [48:19<41:34,  5.80s/it]2024-09-13:17:35:45,895 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:35:47,752 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2407/2836 [48:22<35:55,  5.03s/it]2024-09-13:17:35:48,978 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:35:50,234 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2408/2836 [48:24<30:22,  4.26s/it]2024-09-13:17:35:51,669 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:35:53,563 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2409/2836 [48:27<27:47,  3.91s/it]2024-09-13:17:35:54,650 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:35:56,263 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▍ | 2410/2836 [48:30<25:48,  3.64s/it]2024-09-13:17:35:58,414 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:01,133 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2411/2836 [48:35<28:05,  3.96s/it]2024-09-13:17:36:03,017 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:04,839 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2412/2836 [48:39<27:59,  3.96s/it]2024-09-13:17:36:06,461 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:07,897 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2413/2836 [48:42<25:04,  3.56s/it]2024-09-13:17:36:09,293 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:10,477 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2414/2836 [48:44<23:00,  3.27s/it]2024-09-13:17:36:11,622 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:12,918 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2415/2836 [48:47<21:12,  3.02s/it]2024-09-13:17:36:15,390 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:18,400 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2416/2836 [48:52<26:39,  3.81s/it]2024-09-13:17:36:19,595 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:21,128 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2417/2836 [48:55<23:57,  3.43s/it]2024-09-13:17:36:22,895 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:25,926 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2418/2836 [49:00<27:41,  3.97s/it]2024-09-13:17:36:27,492 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:29,669 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2419/2836 [49:03<26:10,  3.77s/it]2024-09-13:17:36:32,528 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:35,988 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:40,057 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2420/2836 [49:14<40:52,  5.90s/it]2024-09-13:17:36:41,358 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:42,372 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2421/2836 [49:16<32:26,  4.69s/it]2024-09-13:17:36:43,935 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:46,771 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2422/2836 [49:21<32:40,  4.74s/it]2024-09-13:17:36:48,211 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:49,448 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2423/2836 [49:24<28:00,  4.07s/it]2024-09-13:17:36:51,033 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:52,911 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  85%|████████▌ | 2424/2836 [49:27<26:05,  3.80s/it]2024-09-13:17:36:54,525 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:56,392 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  86%|████████▌ | 2425/2836 [49:30<25:21,  3.70s/it]2024-09-13:17:36:57,746 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-13:17:36:59,301 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Loading splits Secondary:  86%|████████▌ | 2426/2836 [49:33<24:21,  3.57s/it]2024-09-13:17:37:03,002 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "sss._build_vector_stores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Search \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12:22:40:13,735 INFO     [_client.py:1038] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-12:22:40:14,114 INFO     [_client.py:1038] HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "grouped_docs,metainfo=sss.search_internal('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### 1. LongT5: Efficient text-to-text transformer for long sequences (Avg. Score: 0.02)\n",
      "\n",
      "*Mandy Guo, J. Ainslie, David C. Uthus, Santiago Ontañón, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang*\n",
      "\n",
      "**TL;DR:** A new model, called LongT5, is presented, with which the effects of scaling both the input length and model size at the same time are explored, which mimics ETC's local/global attention mechanism, but without requiring additional side-inputs.\n",
      "\n",
      "**Abstract:** Recent work has shown that either (1) increasing the input length or (2) increasing model size can improve the performance of Transformer-based neural models. In this paper, we present a new model, called LongT5, with which we explore the effects of scaling both the input length and model size at the same time. Specifically, we integrated attention ideas from long-input transformers (ETC), and adopted pre-training strategies from summarization pre-training (PEGASUS) into the scalable T5 architecture. The result is a new attention mechanism we call {\\em Transient Global} (TGlobal), which mimics ETC's local/global attention mechanism, but without requiring additional side-inputs. We are able to achieve state-of-the-art results on several summarization tasks and outperform the original T5 models on question answering tasks.\n",
      "\n",
      "**Venue:** NAACL-HLT\n",
      "\n",
      "**Year:** 2021\n",
      "\n",
      "**Citations:** 227  (*Influential: 40*)**Semantic Scholar ID:** 3dfb1f50f2a34a699c339dabaa6f9b3a977973de\n",
      "\n",
      "###### Related Contents\n",
      "**Excerpt 1 (Score: 0.02)**\n",
      "6 6}$ | $\\mathbf{6 6 .\n",
      "\n",
      "\n",
      "##### 2. Erniesparse: Learning hierarchical efficient transformer through regularized self-attention (Avg. Score: 0.02)\n",
      "\n",
      "*Yang Liu, Jiaxiang Liu, L. Chen, Yuxiang Lu, Shi Feng, Zhida Feng, Yu Sun, Hao Tian, Huancheng Wu, Hai-feng Wang*\n",
      "\n",
      "**TL;DR:** Experimental results demonstrate that ERNIE-Sparse significantly outperforms a variety of strong baseline methods including the dense attention and other efficient sparse attention methods and achieves improvements on classification benchmark and on QA downstream tasks.\n",
      "\n",
      "**Abstract:** Sparse Transformer has recently attracted a lot of attention since the ability for reducing the quadratic dependency on the sequence length. We argue that two factors, information bottleneck sensitivity and inconsistency between different attention topologies, could affect the performance of the Sparse Transformer. This paper proposes a well-designed model named ERNIE-Sparse. It consists of two distinctive parts: (i) Hierarchical Sparse Transformer (HST) to sequentially unify local and global information. (ii) Self-Attention Regularization (SAR) method, a novel regularization designed to minimize the distance for transformers with different attention topologies. To evaluate the effectiveness of ERNIE-Sparse, we perform extensive evaluations. Firstly, we perform experiments on a multi-modal long sequence modeling task benchmark, Long Range Arena (LRA). Experimental results demonstrate that ERNIE-Sparse significantly outperforms a variety of strong baseline methods including the dense attention and other efficient sparse attention methods and achieves improvements by 2.77% (57.78% vs. 55.01%). Secondly, to further show the effectiveness of our method, we pretrain ERNIE-Sparse and verified it on 3 text classification and 2 QA downstream tasks, achieve improvements on classification benchmark by 0.83% (92.46% vs. 91.63%), on QA benchmark by 3.24% (74.67% vs. 71.43%). Experimental results continue to demonstrate its superior performance.\n",
      "\n",
      "**Venue:** arXiv.org\n",
      "\n",
      "**Year:** 2022\n",
      "\n",
      "**Citations:** 9  (*Influential: 1*)**Semantic Scholar ID:** 94e46e18d2628343a926acf6c3d0817e11d35d58\n",
      "\n",
      "###### Related Contents\n",
      "**Excerpt 1 (Score: 0.02)**\n",
      "7 6}$ | $\\mathbf{7 6 .\n",
      "\n",
      "\n",
      "##### 3. Structured Denoising Diffusion Models in Discrete State-Spaces  (Avg. Score: 0.00)\n",
      "\n",
      "*Jacob Austin, Daniel D. Johnson, Jonathan Ho, Daniel Tarlow, Rianne van den Berg*\n",
      "\n",
      "**TL;DR:** D3PMs are diffusion-like generative models for discrete data that generalize the multinomial diffusion model of Hoogeboom et al. 2021, by going beyond corruption processes with uniform transition probabilities and showing that the choice of transition matrix is an important design decision that leads to improved results in image and text domains.\n",
      "\n",
      "**Abstract:** Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown impressive results on image and waveform generation in continuous state spaces. Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs), diffusion-like generative models for discrete data that generalize the multinomial diffusion model of Hoogeboom et al. 2021, by going beyond corruption processes with uniform transition probabilities. This includes corruption with transition matrices that mimic Gaussian kernels in continuous space, matrices based on nearest neighbors in embedding space, and matrices that introduce absorbing states. The third allows us to draw a connection between diffusion models and autoregressive and mask-based generative models. We show that the choice of transition matrix is an important design decision that leads to improved results in image and text domains. We also introduce a new loss function that combines the variational lower bound with an auxiliary cross entropy loss. For text, this model class achieves strong results on character-level text generation while scaling to large vocabularies on LM1B. On the image dataset CIFAR-10, our models approach the sample quality and exceed the log-likelihood of the continuous-space DDPM model.\n",
      "\n",
      "**Venue:** Neural Information Processing Systems\n",
      "\n",
      "**Year:** 2021\n",
      "\n",
      "**Citations:** 530  (*Influential: 83*)**Semantic Scholar ID:** 91b32fc0a23f0af53229fceaae9cce43a0406d2e\n",
      "\n",
      "###### Related Contents\n",
      "**Excerpt 1 (Score: 0.00)**\n",
      "??g? i??t??z??? zero ?wo ha?at??n?ha?ex?en??v?， be?a?e?????n？ｏ？dy ?rch?t?ctu?e ???? f?tur?,v??le rip? ?u ?h?as stevi??pierr?????er?b?t\n",
      "\n",
      "![](https://cdn.mathpix.com/cropped/2024_09_12_d022f2f11ed3ef9cf4ecg-32.jpg?height=34&width=1381&top_left_y=1921&top_left_x=399) g?\n",
      "\n",
      "\n",
      "##### 4. Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence (Avg. Score: 0.00)\n",
      "\n",
      "*Bo Peng, Daniel Goldstein, Quentin Anthony, Alon Albalak, Eric Alcaide, Stella Biderman, Eugene Cheah, Teddy Ferdinan, Haowen Hou, P. Kazienko, G. Kranthikiran, Jan Koco'n, Bartlomiej Koptyra, Satyapriya Krishna, Ronald McClelland, Niklas Muennighoff, Fares Obeid, Atsushi Saito, Guangyu Song, Haoqin Tu, Stanislaw Wo'zniak, Ruichong Zhang, Bingchen Zhao, Qihang Zhao, Peng Zhou, Jian Zhu, Ruijie Zhu*\n",
      "\n",
      "**TL;DR:** This work presents Eagle and Finch, sequence models improving upon the RWKV (RWKV-4) architecture, which introduces a new multilingual corpus with 1.12 trillion tokens and a fast tokenizer based on greedy matching for enhanced multilinguality.\n",
      "\n",
      "**Abstract:** We present Eagle (RWKV-5) and Finch (RWKV-6), sequence models improving upon the RWKV (RWKV-4) architecture. Our architectural design advancements include multi-headed matrix-valued states and a dynamic recurrence mechanism that improve expressivity while maintaining the inference efficiency characteristics of RNNs. We introduce a new multilingual corpus with 1.12 trillion tokens and a fast tokenizer based on greedy matching for enhanced multilinguality. We trained four Eagle models, ranging from 0.46 to 7.5 billion parameters, and two Finch models with 1.6 and 3.1 billion parameters and find that they achieve competitive performance across a wide variety of benchmarks. We release all our models on HuggingFace under the Apache 2.0 license. Models at: https://huggingface.co/RWKV Training code at: https://github.com/RWKV/RWKV-LM Inference code at: https://github.com/RWKV/ChatRWKV Time-parallel training code at: https://github.com/RWKV/RWKV-infctx-trainer\n",
      "\n",
      "**Venue:** arXiv.org\n",
      "\n",
      "**Year:** 2024\n",
      "\n",
      "**Citations:** 16  (*Influential: 1*)**Semantic Scholar ID:** 157ed5647da39a7f5d33a84a90414b2a9e97e301\n",
      "\n",
      "###### Reference Code\n",
      "<details><summary>Click to expand</summary>\n",
      "\n",
      "```\n",
      "# gab.py\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "\n",
      "from model_discovery.model.utils.modules import GABBase # DO NOT CHANGE THIS IMPORT STATEMENT #\n",
      "\n",
      "from einops import rearrange\n",
      "\n",
      "from transformers.activations import ACT2FN\n",
      "from typing import TYPE_CHECKING, Optional, Tuple\n",
      "\n",
      "# YOU CAN IMPORT MORE MODULES HERE #\n",
      "\n",
      "# YOU CAN DEFINE MORE CLASSES OR FUNCTIONS HERE #\n",
      "\n",
      "\n",
      "def naive_recurrent_rwkv6(\n",
      "    q: torch.Tensor,\n",
      "    k: torch.Tensor,\n",
      "    v: torch.Tensor,\n",
      "    w: torch.Tensor,\n",
      "    u: torch.Tensor,\n",
      "    scale: Optional[float] = None,\n",
      "):\n",
      "    orig_dtype = q.dtype\n",
      "    B, H, T, K, V = *q.shape, v.shape[-1]\n",
      "    q, k, v, w, u = map(lambda x: x.float(), (q, k, v, w, u))\n",
      "    h = torch.zeros(B, H, K, V, dtype=torch.float32, device=q.device)\n",
      "    o = torch.zeros_like(v)\n",
      "\n",
      "    if scale is None:\n",
      "        scale = K ** -0.5\n",
      "\n",
      "    for i in range(T):\n",
      "        q_i = q[:, :, i, :] * scale\n",
      "        k_i = k[:, :, i]\n",
      "        v_i = v[:, :, i, :]\n",
      "        w_i = w[:, :, i].exp()\n",
      "        kv_i = k_i[..., None] * v_i[..., None, :]\n",
      "        o_i = (h + u[None, ..., None] * kv_i) * q_i[..., None]\n",
      "        o[:, :, i] = o_i.sum(-2)\n",
      "        h = h * w_i[..., None] + kv_i\n",
      "    return o.to(orig_dtype)\n",
      "\n",
      "class RWKV6Attention(nn.Module):\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        hidden_size: int = 1024,\n",
      "        num_heads: int = 4,\n",
      "        gate_fn: str = 'swish',\n",
      "        proj_low_rank_dim: int = 32,\n",
      "        gate_low_rank_dim: int = 64,\n",
      "        elementwise_affine: Optional[bool] = True,\n",
      "        norm_eps: float = 1e-5,\n",
      "        device=None,\n",
      "        dtype=None,\n",
      "        **kwargs\n",
      "    ):\n",
      "        super().__init__()\n",
      "\n",
      "        self.hidden_size = hidden_size\n",
      "        self.num_heads = num_heads\n",
      "        self.proj_low_rank_dim = proj_low_rank_dim\n",
      "        self.gate_low_rank_dim = gate_low_rank_dim\n",
      "\n",
      "        self.key_dim = hidden_size // 2\n",
      "        self.value_dim = hidden_size\n",
      "\n",
      "        assert self.key_dim % num_heads == 0, f\"key dim must be divisible by num_heads of {num_heads}\"\n",
      "        assert self.value_dim % num_heads == 0, f\"value dim must be divisible by num_heads of {num_heads}\"\n",
      "\n",
      "        self.head_qk_dim = self.key_dim // num_heads\n",
      "        self.head_v_dim = self.value_dim // num_heads\n",
      "\n",
      "        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n",
      "        self.x_proj = nn.Sequential(\n",
      "            LerpLinear(hidden_size, proj_low_rank_dim * 5, device=device, dtype=dtype),\n",
      "            nn.Tanh(),\n",
      "            nn.Linear(proj_low_rank_dim * 5, hidden_size, bias=False, device=device, dtype=dtype)\n",
      "        )\n",
      "        self.x_bias = nn.Parameter(torch.zeros(5, hidden_size, device=device, dtype=dtype))\n",
      "\n",
      "        self.r_proj = DDLerpLinear(hidden_size, self.key_dim, device=device, dtype=dtype)\n",
      "        self.w_proj = DDLerpLinear(hidden_size, self.key_dim, low_rank_dim=gate_low_rank_dim, device=device, dtype=dtype)\n",
      "        self.k_proj = DDLerpLinear(hidden_size, self.key_dim, device=device, dtype=dtype)\n",
      "        self.v_proj = DDLerpLinear(hidden_size, self.value_dim, device=device, dtype=dtype)\n",
      "        self.g_proj = DDLerpLinear(hidden_size, self.value_dim, low_rank_dim=gate_low_rank_dim, device=device, dtype=dtype)\n",
      "        self.bonus = nn.Parameter(torch.zeros(num_heads, self.head_qk_dim, device=device, dtype=dtype))\n",
      "\n",
      "        # self.g_norm = nn.GroupNorm(self.num_heads, self.value_dim, affine=elementwise_affine, eps=norm_eps, device=device, dtype=dtype) # buggy now\n",
      "        self.g_norm = nn.LayerNorm(self.value_dim, elementwise_affine=elementwise_affine, eps=norm_eps, device=device, dtype=dtype)\n",
      "        self.o_proj = nn.Linear(self.value_dim, hidden_size, bias=False, device=device, dtype=dtype)\n",
      "        self.gate_fn = ACT2FN[gate_fn]\n",
      "\n",
      "        self.apply(self._initialize_weights)\n",
      "\n",
      "    def _initialize_weights(self, module: nn.Module):\n",
      "        if getattr(module, \"_is_hf_initialized\", False):\n",
      "            return\n",
      "        if isinstance(module, nn.Linear):\n",
      "            nn.init.xavier_uniform_(module.weight, gain=2 ** -2.5)\n",
      "            if module.bias is not None:\n",
      "                nn.init.zeros_(module.bias)\n",
      "        if isinstance(module, nn.Parameter):\n",
      "            nn.init.xavier_uniform_(module, gain=2 ** -2.5)\n",
      "        module._is_hf_initialized = True\n",
      "\n",
      "    def forward(\n",
      "        self,\n",
      "        hidden_states: torch.Tensor,\n",
      "        **kwargs\n",
      "    ) -> Tuple[torch.Tensor]:\n",
      "        batch_size, seq_len, hidden_size = hidden_states.shape\n",
      "        # launching the triton kernel for just one token will actually be slower\n",
      "        last_state = None\n",
      "\n",
      "        if hidden_states.shape[1] == 1 and last_state is not None:\n",
      "            shifted = last_state[0].unsqueeze(1)\n",
      "        else:\n",
      "            shifted = self.time_shift(hidden_states)\n",
      "            if last_state is not None:\n",
      "                shifted[:, 0] = last_state[0]\n",
      "\n",
      "        delta = shifted - hidden_states\n",
      "        x = self.x_proj[0](hidden_states, delta).view(batch_size, seq_len, -1, self.proj_low_rank_dim)\n",
      "        x = torch.einsum('b l n r, h n r-> b l n h', self.x_proj[1](x), self.x_proj[2].weight.view(hidden_size, 5, -1))\n",
      "\n",
      "        r, w, k, v, g = x.add_(self.x_bias).unbind(-2)\n",
      "        r = self.r_proj(hidden_states, r, delta)\n",
      "        w = self.w_proj(hidden_states, w, delta)\n",
      "        k = self.k_proj(hidden_states, k, delta)\n",
      "        v = self.v_proj(hidden_states, v, delta)\n",
      "        g = self.g_proj(hidden_states, g, delta)\n",
      "\n",
      "        r, w, k, v = map(lambda x: rearrange(x, 'b l (h d) -> b h l d', h=self.num_heads), (r, w, k, v))\n",
      "        w = -torch.exp(w)\n",
      "        u = self.bonus\n",
      "\n",
      "        o = naive_recurrent_rwkv6(r, k, v, w, u, scale=1.0)\n",
      "\n",
      "        o = rearrange(o, 'b h l d -> b l (h d)')\n",
      "        o = self.g_norm(o)\n",
      "        o = o * self.gate_fn(g)\n",
      "        o = self.o_proj(o)\n",
      "\n",
      "        # o = o[:, :_seqlen]\n",
      "        return o\n",
      "\n",
      "    def init_state(self, batch_size: int) -> Tuple[torch.Tensor]:\n",
      "        param = next(self.parameters())\n",
      "        state = [param.new_zeros(batch_size, self.hidden_size),\n",
      "                 param.new_zeros(batch_size, self.num_heads, self.head_qk_dim, self.head_v_dim)]\n",
      "        return state\n",
      "\n",
      "    def state_size(self, **kwargs) -> int:\n",
      "        state_size = self.key_dim * self.head_v_dim\n",
      "        return state_size\n",
      "\n",
      "\n",
      "class LoRA(nn.Module):\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        input_dim: int,\n",
      "        output_dim: int,\n",
      "        low_rank_dim: int,\n",
      "        bias: Optional[bool] = True,\n",
      "        device=None,\n",
      "        dtype=None,\n",
      "    ):\n",
      "        super().__init__()\n",
      "\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.low_rank_dim = low_rank_dim\n",
      "        self.bias = bias\n",
      "\n",
      "        self.lora = nn.Sequential(\n",
      "            nn.Linear(input_dim, low_rank_dim, bias=False, device=device, dtype=dtype),\n",
      "            nn.Tanh(),\n",
      "            nn.Linear(low_rank_dim, output_dim, bias=bias, device=device, dtype=dtype)\n",
      "        )\n",
      "\n",
      "    def __repr__(self) -> str:\n",
      "        s = f\"{self.__class__.__name__}(\"\n",
      "        s += f\"input_dim={self.input_dim}, low_rank_dim={self.low_rank_dim}, output_dim={self.output_dim}\"\n",
      "        if not self.bias:\n",
      "            s += f\", bias={self.bias}\"\n",
      "        s += \")\"\n",
      "        return s\n",
      "\n",
      "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
      "        return self.lora(x)\n",
      "\n",
      "\n",
      "class LerpLinear(nn.Module):\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        input_dim: int,\n",
      "        output_dim: int,\n",
      "        low_rank_dim: Optional[int] = None,\n",
      "        device=None,\n",
      "        dtype=None,\n",
      "    ):\n",
      "        super().__init__()\n",
      "\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.low_rank_dim = low_rank_dim\n",
      "\n",
      "        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n",
      "        if low_rank_dim is None:\n",
      "            self.linear = nn.Linear(input_dim, output_dim, bias=False, device=device, dtype=dtype)\n",
      "        else:\n",
      "            self.linear = LoRA(input_dim, output_dim, low_rank_dim, device=device, dtype=dtype)\n",
      "        self.mu = nn.Parameter(torch.zeros(input_dim, device=device, dtype=dtype))\n",
      "\n",
      "    def __repr__(self) -> str:\n",
      "        s = f\"{self.__class__.__name__}({self.input_dim}, {self.output_dim}\"\n",
      "        if self.low_rank_dim is not None:\n",
      "            s += f\", low_rank_dim={self.low_rank_dim}\"\n",
      "        s += \")\"\n",
      "        return s\n",
      "\n",
      "    def forward(self, x: torch.Tensor, delta: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
      "        if delta is None:\n",
      "            shifted = self.time_shift(x)\n",
      "            if len(shifted.shape) == 2:\n",
      "                shifted = shifted.unsqueeze(1)\n",
      "            delta = shifted - x\n",
      "        return self.linear(x + delta * self.mu)\n",
      "\n",
      "\n",
      "class DDLerpLinear(nn.Module):\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        input_dim: int,\n",
      "        output_dim: int,\n",
      "        low_rank_dim: Optional[int] = None,\n",
      "        device=None,\n",
      "        dtype=None,\n",
      "    ):\n",
      "        super().__init__()\n",
      "\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.low_rank_dim = low_rank_dim\n",
      "\n",
      "        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n",
      "        if low_rank_dim is None:\n",
      "            self.linear = nn.Linear(input_dim, output_dim, bias=False, device=device, dtype=dtype)\n",
      "        else:\n",
      "            self.linear = LoRA(input_dim, output_dim, low_rank_dim, device=device, dtype=dtype)\n",
      "\n",
      "    def __repr__(self) -> str:\n",
      "        s = f\"{self.__class__.__name__}({self.input_dim}, {self.output_dim}\"\n",
      "        if self.low_rank_dim is not None:\n",
      "            s += f\", low_rank_dim={self.low_rank_dim}\"\n",
      "        s += \")\"\n",
      "        return s\n",
      "\n",
      "    def forward(self, x: torch.Tensor, mu: torch.Tensor, delta: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
      "        if delta is None:\n",
      "            shifted = self.time_shift(x)\n",
      "            if len(shifted.shape) == 2:\n",
      "                shifted = shifted.unsqueeze(1)\n",
      "            delta = shifted - x\n",
      "        return self.linear(x + delta * mu)\n",
      "    \n",
      "\n",
      "class RWKV6FeedForward(nn.Module):\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        hidden_size: int,\n",
      "        device=None,\n",
      "        dtype=None,\n",
      "    ):\n",
      "        super().__init__()\n",
      "\n",
      "        self.hidden_size = hidden_size\n",
      "        hidden_ratio = 3.5\n",
      "        intermediate_size = int(hidden_size * hidden_ratio)\n",
      "        intermediate_size = 32 * ((intermediate_size + 32 - 1) // 32)\n",
      "        self.hidden_ratio = hidden_ratio\n",
      "        self.intermediate_size = intermediate_size\n",
      "\n",
      "        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n",
      "\n",
      "        self.key = LerpLinear(hidden_size, intermediate_size, device=device, dtype=dtype)\n",
      "        self.value = nn.Linear(intermediate_size, hidden_size, bias=False, device=device, dtype=dtype)\n",
      "        self.receptance = LerpLinear(hidden_size, hidden_size, device=device, dtype=dtype)\n",
      "        self.relu=nn.ReLU()\n",
      "\n",
      "    def forward(\n",
      "        self,\n",
      "        x: torch.Tensor,\n",
      "    ) -> torch.Tensor:\n",
      "        shifted = self.time_shift(x)\n",
      "        delta = shifted - x\n",
      "        # key = self.act_fn(self.key(x, delta))\n",
      "        _key=self.key(x,delta)\n",
      "        r=self.relu(_key)\n",
      "        key=r*r\n",
      "        value = self.value(key)\n",
      "        receptance = self.receptance(x, delta)\n",
      "\n",
      "        return receptance.sigmoid() * value\n",
      "\n",
      "\n",
      "class GAB(GABBase):\n",
      "    \"\"\"Generalized Autoregressive Block\n",
      "        Input:        X: (batch, seqlen, embed_dim)\n",
      "        Output:       Y: (batch, seqlen, embed_dim)\n",
      "        Constraints:  Causal, differentiable, parameter number, complexity, parallelizable\n",
      "    \"\"\"\n",
      "    def __init__(\n",
      "            self,\n",
      "            embed_dim: int, \n",
      "            device=None,\n",
      "            dtype=None,\n",
      "            num_heads: int = 4,\n",
      "            proj_low_rank_dim: int = 32,\n",
      "            gate_low_rank_dim: int = 64,\n",
      "            norm_eps: float = 1e-5,\n",
      "            **kwargs,\n",
      "        ): # YOU CAN ADD MORE ARGUMENTS, BUT YOU HAVE TO HAVE embed_dim, device, dtype AS THE ARGUTMENTS #\n",
      "        # argv: list of hyperparameters\n",
      "        factory_kwargs = {\"device\": device, \"dtype\": dtype} # remember to pass it to nn layers\n",
      "        super().__init__(embed_dim) # DO NOT CHANGE THIS LINE #\n",
      "        \n",
      "        # COMPLETING THE CODE HERE #\n",
      "        self.hidden_size = embed_dim\n",
      "\n",
      "        self.attn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=norm_eps, **factory_kwargs)\n",
      "        self.attn = RWKV6Attention(\n",
      "            hidden_size=self.hidden_size,\n",
      "            num_heads=num_heads,\n",
      "            proj_low_rank_dim=proj_low_rank_dim,\n",
      "            gate_low_rank_dim=gate_low_rank_dim,\n",
      "            norm_eps=norm_eps,\n",
      "            **factory_kwargs\n",
      "        )\n",
      "        self.ffn_norm = nn.LayerNorm(self.hidden_size, bias=True, eps=norm_eps, **factory_kwargs)\n",
      "        self.ffn = RWKV6FeedForward(\n",
      "            hidden_size=self.hidden_size,\n",
      "            **factory_kwargs\n",
      "        )\n",
      "\n",
      "\n",
      "    # YOU CAN ADD MORE FUNCTIONS HERE #\n",
      "\n",
      "\n",
      "    def _forward(self,X,**kwargs): # type hints are optional but recommended\n",
      "        # THE CODE HERE MUST BE COMPLETED #\n",
      "        hidden_states = self.attn_norm(X)\n",
      "        X = self.attn(hidden_states) +X\n",
      "        hidden_states = self.ffn_norm(X)\n",
      "        X = self.ffn(hidden_states) + X\n",
      "        return X\n",
      "    \n",
      "    \n",
      "\"\"\" The dictionary of hyperparameters for constructing a GAB layer\n",
      "    embed_dim, device, dtype should NOT be included in gab_config\n",
      "\"\"\"\n",
      "gab_config = {\n",
      "    # THE HYPERPARAMETERS OF ADDITIONAL ARGUMENTS IN GAB CLASS #\n",
      "    'num_heads': 4,\n",
      "    'proj_low_rank_dim': 32,\n",
      "    'gate_low_rank_dim': 64,\n",
      "    'norm_eps': 1e-5,\n",
      "}\n",
      "\n",
      "```\n",
      "\n",
      "</details>\n",
      "\n",
      "###### Related Contents\n",
      "**Excerpt 1 (Score: 0.00)**\n",
      "et al., 2023). As shown in Table 13, the new model consistently outperforms the old one on various tasks. It is to be noted that the new model remains very sensitive to the selected prompt template, just as the old one, as was shown in (Peng et al., 2023). | Dataset | Eagle-7B | Raven-7b |\n",
      "| :--- | :--- | :--- |\n",
      "| Aggression | $\\mathbf{0 . 6 5 8 7}$ | 0.4063 |\n",
      "| MathQA | $\\mathbf{0 . 4 7 6 0}$ | 0.4028 |\n",
      "| Sarcasm | 0.4679 | $\\mathbf{0 . 4 7 8 2}$ |\n",
      "| TweetSent | 0.5355 | $\\mathbf{0 . 5 5 4 1}$ |\n",
      "| Unhealthy | $\\mathbf{0 . 2 9 8 6}$ | 0.2834 |\n",
      "| TweetStance | $\\mathbf{0 . 3 9 3 3}$ | 0.3070 |\n",
      "| Spam | $\\mathbf{0 . 7 2 9 0}$ | 0.4902 |\n",
      "| ColBER | $\\mathbf{0 . 4 0 8 8}$ | 0.2889 |\n",
      "| CoLa | $\\mathbf{0 . 5 2 8 5}$ | 0.4677 |\n",
      "| TextEntail | $\\mathbf{0 . 7 7 6 5}$ | 0.6137 |\n",
      "| GoEmo | $\\mathbf{0 . 0 9 5 6}$ | 0.0814 |\n",
      "| PolEmo | $\\mathbf{0 . 5 0 3 7}$ | 0.2639 |\n",
      "| WNLI | $\\mathbf{0 . 5 2 5 7}$ | 0.4638 |\n",
      "\n",
      "Table 13: Eagle 7B and Raven 7B reasoning performance comparison based on subsets of selected datasets. The used metric is F1-macro (except for MathQA where accuracy is used instead). ## G Hyperparameters\n",
      "\n",
      "All Eagle and Finch models were trained under bfloat 16 format for most parameters, except that float 32 was used to compute $W K V$ for numerical stability. The Adam optimizer was configured with $\\beta_{1}=0.9, \\beta_{2}=0.99$ and 0.001 weight decay applied only to linear layers and\n",
      "embedding weights. The context length for pretraining was 4096 tokens. Learning rate for all models followed a linear 10 step warmup schedule from $20 \\%$ to $100 \\%$ of the maximum learning rate, followed by cosine decay to the minimum learning rate. The time_decay $w$ parameters are placed into a special 2x learning rate multiplier grouping. | Parameters | 0.4 B | $1.5 \\mathrm{~B} / 1.6 \\mathrm{~B}$ | 3 B | 7 B |\n",
      "| :--- | :---: | :---: | :---: | :---: |\n",
      "| Max LR | $4 \\times 10^{-4}$ | $3 \\times 10^{-4}$ | $2 \\times 10^{-4}$ | $1.5 \\times 10^{-4}$ |\n",
      "| Min LR | $2 \\times 10^{-5}$ | $2 \\times 10^{-5}$ | $1.5 \\times 10^{-5}$ | $1 \\times 10^{-5}$ |\n",
      "| Micro Batch Size | 8 | 8 | 4 | 9 |\n",
      "| GPU Count | 24 | 48 | 48 | 64 |\n",
      "| GPU Type | A 100 | A 100 | A100 | H800 |\n",
      "| Batch Size | 786432 | 1572864 | 786432 | 2359296 |\n",
      "\n",
      "Table 14: Learning Rate Hyperparameters for pretrained Eagle and Finch models\n",
      "\n",
      "## H Parameter Initializations\n",
      "\n",
      "Throughout this section, we use $l$ to denote the layer index (layer $l=0$ accepts input embeddings and layer $l=L-1$ produces output), and $i$ the dimension index $(i=0,1, \\cdots, D-1)$. We set $r_{0}=\\frac{l}{L-1}$ and $r_{1}=1-\\frac{l}{L}$ as two parameters for simplicity. The initialization of Eagle is provided as follows:\n",
      "\n",
      "- In the Time Mixing module:\n",
      "- The token-shift coefficients of receptance and gate, $\\mu_{r}$ and $\\mu_{g}$, are initialized to $1-\\left(\\frac{i}{D}\\right)^{r_{1} / 2}$ for i over dimension indices. - The token-shift of key $\\mu_{k}$ is initialized to $1-\\left(\\frac{i}{D}\\right)^{r_{1}}$. - The token-shift of value $\\mu_{\\nu}$ is initialized to $1-\\left(\\frac{i}{D}\\right)^{r_{1}}-0.3 r_{0}$. - The time_decay $w$ is initialized to $-6+5\\left(\\frac{i}{D-1}\\right)^{0.7+1.3 r_{0}}$. - The \"time-first\" $u$ is initialized to $r_{0}\\left(1-\\frac{i}{D-1}\\right)+0.1((i+1) \\bmod 3)$. - The Time Mixing output matrix is initialized to 0. - The WKV GroupNorm weights are initialized with constant value $((1+l) / L)^{0.7}$. - Two-dimensional parameters with the first dimension being larger than the second dimension are initialized with and orthogonal initialization of gain equal to the size of the first dimension divided by the size of the second dimension. - Other parameters are initialized according to PyTorch default. - In the Channel Mixing module:\n",
      "- The token-shift of both key $\\mu_{k}$ and receptance $\\mu_{r}$ are initialized to $1-\\left(\\frac{i}{D}\\right)^{r_{1}}$. - The value and receptance matrices $W_{v}, W_{r}$ are initialized to 0 . - Two-dimensional parameters with the first dimension being larger than the second dimension are initialized with and orthogonal initialization of gain equal to the size of the first dimension divided by the size of the second dimension. - All other parameters are initialized according to PyTorch default. - The input embedding is initialized with a uniform distribution of $\\mathscr{U}(-\\max L R, \\max L R)$, the maximum learning rate. - The output head is initialized with an orthogonal initialization of gain 0.5 . - Bias is set to Fal se for all linear layers. In the Finch architecture, most of the parameters are initialized to the same as Eagle, except for a few changes. In the Time Mixing block, there are several additional parameters initialized as follows:\n",
      "\n",
      "- The token shift of input $\\mu_{x}$ and time decay $\\mu_{w}$ are initialized to $1-\\left(\\frac{i}{D}\\right)^{r_{1}}$. - The lora weights of $\\boldsymbol{A}$ and $\\boldsymbol{B}$ are initialized to uniform distribution of $\\mathscr{U}\\left(-10^{-4}, 10^{-4}\\right)$. ## I Non-English Chat Examples\n",
      "\n",
      "The following are examples of interactions with the base Eagle 7B model in languages other than English. No system prompt was given. Requests are shown in bold. ## RWKV-Eagle\n",
      "\n",
      "User: hi\n",
      "Assistant: Hi.\n",
      "\n",
      "\n",
      "##### 5. GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints (Avg. Score: 0.00)\n",
      "\n",
      "*J. Ainslie, J. Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebr'on, Sumit K. Sanghai*\n",
      "\n",
      "**TL;DR:** This work proposes a recipe for uptraining existing multi-head language model checkpoints into models with MQA using 5% of original pre-training compute, and introduces grouped-query attention (GQA), a generalization of multi- query attention which uses an intermediate number of query heads.\n",
      "\n",
      "**Abstract:** Multi-query attention (MQA), which only uses a single key-value head, drastically speeds up decoder inference. However, MQA can lead to quality degradation, and moreover it may not be desirable to train a separate model just for faster inference. We (1) propose a recipe for uptraining existing multi-head language model checkpoints into models with MQA using 5% of original pre-training compute, and (2) introduce grouped-query attention (GQA), a generalization of multi-query attention which uses an intermediate (more than one, less than number of query heads) number of key-value heads. We show that uptrained GQA achieves quality close to multi-head attention with comparable speed to MQA.\n",
      "\n",
      "**Venue:** Conference on Empirical Methods in Natural Language Processing\n",
      "\n",
      "**Year:** 2023\n",
      "\n",
      "**Citations:** 208  (*Influential: 12*)**Semantic Scholar ID:** 5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200\n",
      "\n",
      "###### Reference Code\n",
      "<details><summary>Click to expand</summary>\n",
      "\n",
      "```\n",
      "from typing import Optional, Tuple, Union\n",
      "\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from einops import einsum, rearrange\n",
      "from torch import Tensor, nn\n",
      "\n",
      "\n",
      "def scaled_dot_product_gqa(\n",
      "    query: Tensor,\n",
      "    key: Tensor,\n",
      "    value: Tensor,\n",
      "    dropout: float = 0.0,\n",
      "    scale: Optional[float] = None,\n",
      "    mask: Optional[Tensor] = None,\n",
      "    is_causal: Optional[bool] = None,\n",
      "    need_weights: bool = False,\n",
      "    average_attn_weights: bool = False,\n",
      "    force_grouped: bool = False,\n",
      "):\n",
      "    \"\"\"Scaled dot product attention with support for grouped queries.\n",
      "\n",
      "    Einstein notation:\n",
      "    - b: batch size\n",
      "    - n / s: sequence length\n",
      "    - h: number of heads\n",
      "    - g: number of groups\n",
      "    - d: dimension of query/key/value\n",
      "\n",
      "    Args:\n",
      "        query: Query tensor of shape (b, n, h, d)\n",
      "        key: Key tensor of shape (b, s, h, d)\n",
      "        value: Value tensor of shape (b, s, h, d)\n",
      "        dropout: Dropout probability (default: 0.0)\n",
      "        scale: Scale factor for query (default: d_query ** 0.5)\n",
      "        mask: Mask tensor of shape (b, n, s) or (b, s). If 'ndim == 2', the mask is\n",
      "            applied to all 'n' rows of the attention matrix. (default: None)\n",
      "        force_grouped: If True, apply grouped-query attention even if the number of\n",
      "            heads is equal for query, key, and value. (default: False)\n",
      "\n",
      "    Returns:\n",
      "        2-tuple of:\n",
      "        - Attention output with shape (b, n, h, d)\n",
      "        - (Optional) Attention weights with shape (b, h, n, s). Only returned if\n",
      "          'need_weights' is True.\n",
      "    \"\"\"\n",
      "    if (mask is not None) and (is_causal is not None):\n",
      "        raise ValueError(\n",
      "            \"Only one of 'mask' and 'is_causal' should be provided, but got both.\"\n",
      "        )\n",
      "    elif not query.ndim == key.ndim == value.ndim == 4:\n",
      "        raise ValueError(\n",
      "            f\"Expected query, key, and value to be 4-dimensional, but got shapes \"\n",
      "            f\"{query.shape}, {key.shape}, and {value.shape}.\"\n",
      "        )\n",
      "\n",
      "    # Move sequence length dimension to axis 2.\n",
      "    # This makes the attention operations below *much* faster.\n",
      "    query = rearrange(query, \"b n h d -> b h n d\")\n",
      "    key = rearrange(key, \"b s h d -> b h s d\")\n",
      "    value = rearrange(value, \"b s h d -> b h s d\")\n",
      "\n",
      "    bq, hq, nq, dq = query.shape\n",
      "    bk, hk, nk, dk = key.shape\n",
      "    bv, hv, nv, dv = value.shape\n",
      "    if not (bq == bk == bv and dq == dk == dv):\n",
      "        raise ValueError(\n",
      "            \"Expected query, key, and value to have the same batch size (dim=0) and \"\n",
      "            f\"embedding dimension (dim=3), but got query: {query.shape}, \"\n",
      "            f\"key: {key.shape}, and value: {value.shape}.\"\n",
      "        )\n",
      "    elif (hk != hv) or (nk != nv):\n",
      "        raise ValueError(\n",
      "            \"Expected key and value to have the same size in dimensions 1 and 2, but \"\n",
      "            f\"got key: {key.shape} and value: {value.shape}.\"\n",
      "        )\n",
      "    elif hq % hk != 0:\n",
      "        raise ValueError(\n",
      "            \"Expected query heads to be a multiple of key/value heads, but got \"\n",
      "            f\"query: {query.shape} and key/value: {key.shape}.\"\n",
      "        )\n",
      "\n",
      "    if scale is None:\n",
      "        scale = query.size(-1) ** 0.5\n",
      "    query = query / scale\n",
      "\n",
      "    num_head_groups = hq // hk\n",
      "    query = rearrange(query, \"b (h g) n d -> b g h n d\", g=num_head_groups)\n",
      "    similarity = einsum(query, key, \"b g h n d, b h s d -> b g h n s\")\n",
      "\n",
      "    if is_causal:\n",
      "        # Mask out the upper triangular portion of the attention matrix. This prevents\n",
      "        # the model from attending to tokens in the future.\n",
      "        mask = torch.ones((bq, nq, nk), device=query.device, dtype=torch.bool).tril_()\n",
      "\n",
      "    if mask is not None:\n",
      "        # Expand mask to match the shape of the attention matrix.\n",
      "        # If mask is 2D, assume that it is applied to the key/value sequence dimension.\n",
      "        # Else if mask is 3D, assume that it is applied to the query/key/value sequence\n",
      "        # dimension for all attention heads.\n",
      "        #\n",
      "        # Users could also provide a 4D mask, which is applied to the query/key/value\n",
      "        # sequence dimension for each attention head (though I don't have a particular\n",
      "        # use case in mind for that).\n",
      "        if mask.ndim == 2:\n",
      "            mask = rearrange(mask, \"b s -> b () () () s\")\n",
      "        elif mask.ndim == 3:\n",
      "            mask = rearrange(mask, \"b n s -> b () () n s\")\n",
      "        # Mask similarity values by setting them to negative infinity.  This guarantees\n",
      "        # that they will not contribute to the softmax computation below.\n",
      "        similarity.masked_fill_(~mask, torch.finfo(similarity.dtype).min)\n",
      "\n",
      "    attention = F.softmax(similarity, dim=-1)\n",
      "    if dropout > 0.0:\n",
      "        attention = F.dropout(attention, p=dropout)\n",
      "\n",
      "    # Apply attention matrix to the value Tensor.\n",
      "    out = einsum(attention, value, \"b g h n s, b h s d -> b g h n d\")\n",
      "    # Move head dimension back to axis 2\n",
      "    out = rearrange(out, \"b g h n d -> b n (h g) d\")\n",
      "\n",
      "    attn_weights: Optional[Tensor] = None\n",
      "    if need_weights:\n",
      "        # Move the sequence dimensions back to positions 1, 2.  Move the head dimension\n",
      "        # to position 3.  This more closely matches the return shape of the attention\n",
      "        # output: (b, n, h, d).\n",
      "        attn_weights = rearrange(attention, \"b g h n s -> b n s (h g)\")\n",
      "        if average_attn_weights:\n",
      "            attn_weights = attn_weights.mean(dim=1)\n",
      "\n",
      "    return out, attn_weights\n",
      "\n",
      "\n",
      "class MultiheadGQA(nn.Module):\n",
      "    \"\"\"Multi-head grouped query attention (GQA) layer.\n",
      "\n",
      "    Reference:\n",
      "        \"GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints\"\n",
      "        https://arxiv.org/pdf/2305.13245v1.pdf\n",
      "\n",
      "    GQA is a variant of multihead attention (MHA) that uses fewer write heads\n",
      "    (key / value) than query heads.  GQA can be viewed as a generalization of\n",
      "    multi-query attention (MQA), which uses a single write head. GQA and MQA give\n",
      "    significant speedups over standard MHA in decoder layers, with minimal loss in\n",
      "    accuracy. In the paper, GQA is shown to be more accurate than MQA, while still\n",
      "    having a significant speedup over MHA.\n",
      "\n",
      "    NOTE: The original authors only benchmark GQA by adapting the T5 (XL or XXL) model\n",
      "    from MHA to GQA.  As a result, they do not mention parameter initialization or\n",
      "    layer normalization strategies.  I follow the best practices laid out in the\n",
      "    MAGNETO paper, which improves Transformer performance through better parameter\n",
      "    initialization and layer norm placement.  See:\n",
      "        https://arxiv.org/pdf/2210.06423.pdf, Fig. 2\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        embed_dim: int,\n",
      "        query_heads: int,\n",
      "        kv_heads: int,\n",
      "        dropout: float = 0.0,\n",
      "        bias: bool = True,\n",
      "        layer_norm: bool = True,\n",
      "        layer_norm_eps: float = 1e-5,\n",
      "        gamma_init: float = 1.0,\n",
      "        device: Optional[Union[torch.device, str]] = None,\n",
      "        dtype: Optional[torch.dtype] = None,\n",
      "    ):\n",
      "        super().__init__()\n",
      "        self.query_heads = query_heads\n",
      "        self.kv_heads = kv_heads\n",
      "        self.dropout = dropout\n",
      "        self.layer_norm = layer_norm\n",
      "        self.gamma_init = gamma_init\n",
      "\n",
      "        if self.query_heads % self.kv_heads != 0:\n",
      "            raise ValueError(\n",
      "                f\"query_heads ({query_heads}) must be divisible by \"\n",
      "                f\"kv_heads ({kv_heads})\"\n",
      "            )\n",
      "        elif (embed_dim % self.query_heads != 0) or (embed_dim % self.kv_heads != 0):\n",
      "            raise ValueError(\n",
      "                f\"embed_dim ({embed_dim}) must be divisible by \"\n",
      "                f\"query_heads ({query_heads}) and kv_heads ({kv_heads})\"\n",
      "            )\n",
      "\n",
      "        head_dim = embed_dim // query_heads\n",
      "        if not head_dim % 8 == 0:\n",
      "            raise ValueError(\n",
      "                f\"head_dim (embed_dim / num_heads = {head_dim}) must be divisible by 8\"\n",
      "            )\n",
      "        if not head_dim <= 128:\n",
      "            raise ValueError(\n",
      "                f\"head_dim (embed_dim / num_heads = {head_dim}) must be <= 128\"\n",
      "            )\n",
      "\n",
      "        # Query projection layer is the same as in vanilla MHA.\n",
      "        self.q_proj = nn.Linear(\n",
      "            embed_dim, embed_dim, bias=bias, device=device, dtype=dtype\n",
      "        )\n",
      "        # Key/value projection layers have a smaller output dimension, so that\n",
      "        # the we have fewer key/value attention heads after reshaping.\n",
      "        kv_embed_dim = embed_dim // query_heads * kv_heads\n",
      "        self.k_proj = nn.Linear(\n",
      "            embed_dim, kv_embed_dim, bias=bias, device=device, dtype=dtype\n",
      "        )\n",
      "        self.v_proj = nn.Linear(\n",
      "            embed_dim, kv_embed_dim, bias=bias, device=device, dtype=dtype\n",
      "        )\n",
      "        self.norm: Optional[nn.LayerNorm] = None\n",
      "        if layer_norm:\n",
      "            self.norm = nn.LayerNorm(\n",
      "                embed_dim, eps=layer_norm_eps, device=device, dtype=dtype\n",
      "            )\n",
      "        # Grouped attention output will have the same embedding dimension as the\n",
      "        # key/value Tensors.  So the output projection layer needs to accept the\n",
      "        # same dimension (kv_embed_dim).\n",
      "        self.out_proj = nn.Linear(\n",
      "            embed_dim, embed_dim, bias=bias, device=device, dtype=dtype\n",
      "        )\n",
      "\n",
      "        self._reset_parameters()\n",
      "\n",
      "    def _reset_parameters(self):\n",
      "        nn.init.xavier_normal_(self.q_proj.weight)\n",
      "        if self.q_proj.bias is not None:\n",
      "            nn.init.constant_(self.q_proj.bias, 0)\n",
      "        nn.init.xavier_normal_(self.k_proj.weight)\n",
      "        if self.k_proj.bias is not None:\n",
      "            nn.init.constant_(self.k_proj.bias, 0)\n",
      "\n",
      "        # NOTE: We follow the initialization strategy from MAGNETO.  See:\n",
      "        # https://arxiv.org/pdf/2210.06423.pdf, Fig. 2\n",
      "        # Gain (self.gamma_init) should be provided as a keyword argument when\n",
      "        # initializing the larger Transformer model, since it requires knowledge\n",
      "        # of the number of encoder/decoder layers in the model.\n",
      "\n",
      "        nn.init.xavier_normal_(self.v_proj.weight, gain=self.gamma_init)\n",
      "        if self.v_proj.bias is not None:\n",
      "            nn.init.constant_(self.v_proj.bias, 0)\n",
      "        nn.init.xavier_normal_(self.out_proj.weight, gain=self.gamma_init)\n",
      "        if self.out_proj.bias is not None:\n",
      "            nn.init.constant_(self.out_proj.bias, 0)\n",
      "\n",
      "    def forward(\n",
      "        self,\n",
      "        query: Tensor,\n",
      "        key: Tensor,\n",
      "        value: Tensor,\n",
      "        need_weights: bool = False,\n",
      "        # TODO\n",
      "        # attn_mask: Optional[Tensor] = None,\n",
      "        is_causal: bool = False,\n",
      "        average_attn_weights: bool = False,\n",
      "    ) -> Tuple[Tensor, Optional[Tensor]]:\n",
      "        # Notation:\n",
      "        #   b - batch size\n",
      "        #   n - sequence length\n",
      "        #   h - number of heads\n",
      "        #   d - embedding dimension\n",
      "        #\n",
      "        # Input shape: (b, n, d)\n",
      "        q: Tensor = self.q_proj(query)\n",
      "        k: Tensor = self.k_proj(key)\n",
      "        v: Tensor = self.v_proj(value)\n",
      "\n",
      "        # Unfold 'd' dimension into 'h' separate attention heads.\n",
      "        q = rearrange(q, \"b n (h d) -> b n h d\", h=self.query_heads)\n",
      "        k = rearrange(k, \"b n (h d) -> b n h d\", h=self.kv_heads)\n",
      "        v = rearrange(v, \"b n (h d) -> b n h d\", h=self.kv_heads)\n",
      "        # Apply attention, then fold 'h' attention heads back into 'd'.\n",
      "        x, attn = scaled_dot_product_gqa(\n",
      "            query=q,\n",
      "            key=k,\n",
      "            value=v,\n",
      "            # TODO\n",
      "            # mask=attn_mask,\n",
      "            is_causal=is_causal,\n",
      "            need_weights=need_weights,\n",
      "            average_attn_weights=average_attn_weights,\n",
      "            force_grouped=False,\n",
      "        )\n",
      "        x = rearrange(x, \"b n h d -> b n (h d)\")\n",
      "\n",
      "        # NOTE: This is different from 'nn.MultiheadAttention'!  We follow the MAGNETO\n",
      "        # architecture (https://arxiv.org/pdf/2210.06423.pdf), which applies an extra\n",
      "        # layer norm before the linear output projection.  The cross-attention layer in\n",
      "        # the MAGNETO decoder does not include this layer norm, so users have the\n",
      "        # option to disable it (layer_norm=False).\n",
      "        if self.layer_norm:\n",
      "            assert self.norm is not None\n",
      "            x = self.norm(x)\n",
      "        # Linear projection on attention outputs.\n",
      "        x = self.out_proj(x)\n",
      "\n",
      "        return x, attn\n",
      "```\n",
      "\n",
      "</details>\n",
      "\n",
      "###### Related Contents\n",
      "**Excerpt 1 (Score: 0.00)**\n",
      "Int.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ppr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
