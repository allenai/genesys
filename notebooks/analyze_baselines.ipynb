{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "BASEDIR='../model_discovery/model/library/core'\n",
    "\n",
    "def read_reports(baseline):\n",
    "    dir = os.path.join(BASEDIR, baseline,'reports')\n",
    "    reports = {}\n",
    "    for file in os.listdir(dir):\n",
    "        if file.startswith('report_'):\n",
    "            scale = file.split('.')[0].split('_')[1]\n",
    "            with open(os.path.join(dir, file), 'r') as f:\n",
    "                reports[scale]=json.load(f)\n",
    "    return reports\n",
    "\n",
    "def read_eval_reports(baseline):\n",
    "    report=read_reports(baseline)\n",
    "    eval_reports={}\n",
    "    for i in report:\n",
    "        eval_reports[i]=report[i]['eval_results.json']\n",
    "    return eval_reports\n",
    "\n",
    "def read_eval_results(baseline,mean_group=None):\n",
    "    reports=read_eval_reports(baseline)\n",
    "    results={}\n",
    "    for i in reports:\n",
    "        results[i]=reports[i]['results']\n",
    "    return results\n",
    "\n",
    "BASELINES = ['gpt2','mamba2','ttt','retnet','rwkv6']\n",
    "\n",
    "GLUE_TASK_LIST = [\"cola\",\"mnli\",\"mrpc\",\"qnli\",\"qqp\",\"rte\",\"sst2\",\"wnli\"]\n",
    "STANDARD_EVAL_TASKS = [\"hellaswag\",\"piqa\",\"arc_easy\",\"arc_challenge\",\"winogrande\", \"openbookqa\",\"lambada_openai\"]\n",
    "MEAN_GROUPS = {\n",
    "    'standard':STANDARD_EVAL_TASKS,\n",
    "    'blimp':None,\n",
    "    'inverse_scaling':None,\n",
    "    'glue':GLUE_TASK_LIST,\n",
    "    'qa4mre': None,\n",
    "    'scrolls':None,\n",
    "}\n",
    "\n",
    "gpt2_eval_reports=read_eval_reports('gpt2')\n",
    "gpt2_results=read_eval_results('gpt2')\n",
    "# random_results=read_eval_results('RANDOM')['0']\n",
    "all_results={}\n",
    "for i in BASELINES:\n",
    "    all_results[i]=read_eval_results(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybridflow_dir='/home/junyanc/model_discovery/ckpt/test_evo_000/ve/hybridflow_14M/report.json'\n",
    "ahan_transformer_dir='/home/junyanc/model_discovery/ckpt/test_evo_000/ve/ahan-transformer_14M/report.json'\n",
    "\n",
    "def read_eval(dir):\n",
    "    with open(dir, 'r') as f:\n",
    "        report = json.load(f)\n",
    "    return report['eval_results.json']['results']\n",
    "\n",
    "hybridflow=read_eval(hybridflow_dir)\n",
    "ahan_transformer=read_eval(ahan_transformer_dir)\n",
    "hybridflow={'14M':hybridflow}\n",
    "ahan_transformer={'14M':ahan_transformer}\n",
    "all_results['*hybridflow*']=hybridflow\n",
    "all_results['*ahan-transformer*']=ahan_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print datasets and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc,none\n",
      "['arc_challenge', 'arc_easy', 'blimp_adjunct_island_filtered', 'blimp_anaphor_gender_agreement_filtered', 'blimp_anaphor_number_agreement_filtered', 'blimp_animate_subject_passive_filtered', 'blimp_animate_subject_trans_filtered', 'blimp_causative_filtered', 'blimp_complex_NP_island_filtered', 'blimp_coordinate_structure_constraint_complex_left_branch_filtered', 'blimp_coordinate_structure_constraint_object_extraction_filtered', 'blimp_determiner_noun_agreement_1_filtered', 'blimp_determiner_noun_agreement_2_filtered', 'blimp_determiner_noun_agreement_irregular_1_filtered', 'blimp_determiner_noun_agreement_irregular_2_filtered', 'blimp_determiner_noun_agreement_with_adj_2_filtered', 'blimp_determiner_noun_agreement_with_adj_irregular_1_filtered', 'blimp_determiner_noun_agreement_with_adj_irregular_2_filtered', 'blimp_determiner_noun_agreement_with_adjective_1_filtered', 'blimp_distractor_agreement_relational_noun_filtered', 'blimp_distractor_agreement_relative_clause_filtered', 'blimp_drop_argument_filtered', 'blimp_ellipsis_n_bar_1_filtered', 'blimp_ellipsis_n_bar_2_filtered', 'blimp_existential_there_object_raising_filtered', 'blimp_existential_there_quantifiers_1_filtered', 'blimp_existential_there_quantifiers_2_filtered', 'blimp_existential_there_subject_raising_filtered', 'blimp_expletive_it_object_raising_filtered', 'blimp_inchoative_filtered', 'blimp_intransitive_filtered', 'blimp_irregular_past_participle_adjectives_filtered', 'blimp_irregular_past_participle_verbs_filtered', 'blimp_irregular_plural_subject_verb_agreement_1_filtered', 'blimp_irregular_plural_subject_verb_agreement_2_filtered', 'blimp_left_branch_island_echo_question_filtered', 'blimp_left_branch_island_simple_question_filtered', 'blimp_matrix_question_npi_licensor_present_filtered', 'blimp_npi_present_1_filtered', 'blimp_npi_present_2_filtered', 'blimp_only_npi_licensor_present_filtered', 'blimp_only_npi_scope_filtered', 'blimp_passive_1_filtered', 'blimp_passive_2_filtered', 'blimp_principle_A_c_command_filtered', 'blimp_principle_A_case_1_filtered', 'blimp_principle_A_case_2_filtered', 'blimp_principle_A_domain_1_filtered', 'blimp_principle_A_domain_2_filtered', 'blimp_principle_A_domain_3_filtered', 'blimp_principle_A_reconstruction_filtered', 'blimp_regular_plural_subject_verb_agreement_1_filtered', 'blimp_regular_plural_subject_verb_agreement_2_filtered', 'blimp_sentential_negation_npi_licensor_present_filtered', 'blimp_sentential_negation_npi_scope_filtered', 'blimp_sentential_subject_island_filtered', 'blimp_superlative_quantifiers_1_filtered', 'blimp_superlative_quantifiers_2_filtered', 'blimp_supplement_hypernym', 'blimp_supplement_qa_congruence_easy', 'blimp_supplement_qa_congruence_tricky', 'blimp_supplement_subject_aux_inversion', 'blimp_supplement_turn_taking', 'blimp_tough_vs_raising_1_filtered', 'blimp_tough_vs_raising_2_filtered', 'blimp_transitive_filtered', 'blimp_wh_island_filtered', 'blimp_wh_questions_object_gap_filtered', 'blimp_wh_questions_subject_gap_filtered', 'blimp_wh_questions_subject_gap_long_distance_filtered', 'blimp_wh_vs_that_no_gap_filtered', 'blimp_wh_vs_that_no_gap_long_distance_filtered', 'blimp_wh_vs_that_with_gap_filtered', 'blimp_wh_vs_that_with_gap_long_distance_filtered', 'hellaswag', 'inverse_scaling_hindsight_neglect_10shot', 'inverse_scaling_into_the_unknown', 'inverse_scaling_memo_trap', 'inverse_scaling_modus_tollens', 'inverse_scaling_neqa', 'inverse_scaling_pattern_matching_suppression', 'inverse_scaling_quote_repetition', 'inverse_scaling_redefine_math', 'inverse_scaling_repetitive_algebra', 'inverse_scaling_sig_figs', 'inverse_scaling_winobias_antistereotype', 'lambada_openai', 'mathqa', 'mnli', 'mnli_mismatch', 'mrpc', 'openbookqa', 'piqa', 'qa4mre_2011', 'qa4mre_2012', 'qa4mre_2013', 'qnli', 'qqp', 'rte', 'sciq', 'scrolls_contractnli', 'scrolls_quality', 'sst2', 'swag', 'tinyTruthfulQA', 'winogrande', 'wnli', 'wsc273']\n",
      "acc_norm,none\n",
      "['arc_challenge', 'arc_easy', 'hellaswag', 'inverse_scaling_hindsight_neglect_10shot', 'inverse_scaling_into_the_unknown', 'inverse_scaling_memo_trap', 'inverse_scaling_modus_tollens', 'inverse_scaling_neqa', 'inverse_scaling_pattern_matching_suppression', 'inverse_scaling_quote_repetition', 'inverse_scaling_redefine_math', 'inverse_scaling_repetitive_algebra', 'inverse_scaling_sig_figs', 'inverse_scaling_winobias_antistereotype', 'mathqa', 'openbookqa', 'piqa', 'qa4mre_2011', 'qa4mre_2012', 'qa4mre_2013', 'sciq', 'scrolls_contractnli', 'scrolls_quality', 'swag', 'tinyMMLU']\n",
      "mcc,none\n",
      "['cola']\n",
      "perplexity,none\n",
      "['lambada_openai']\n",
      "em,none\n",
      "['scrolls_contractnli', 'scrolls_quality']\n",
      "contains,none\n",
      "['squad_completion']\n",
      "exact_match,strict-match\n",
      "['tinyGSM8k']\n",
      "exact_match,flexible-extract\n",
      "['tinyGSM8k']\n"
     ]
    }
   ],
   "source": [
    "# random_results\n",
    "metrics={}\n",
    "for i in random_results:\n",
    "    res=random_results[i]\n",
    "    alias=res['alias']\n",
    "    for m in res:\n",
    "        if m=='alias': continue\n",
    "        if '_stderr' in m: continue\n",
    "        if m not in metrics:\n",
    "            metrics[m]=[]\n",
    "        metrics[m].append(alias)\n",
    "for m in metrics:\n",
    "    print(m)\n",
    "    print(metrics[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readout_results(results,metrics,mean_group={}):\n",
    "    out={}\n",
    "    mean_groups={}\n",
    "    for group in mean_group:\n",
    "        mean_groups[group]=0\n",
    "        out[group]=0\n",
    "    for i in results:\n",
    "        res=results[i]\n",
    "        alias=res['alias']\n",
    "        for metric in metrics:\n",
    "            if metric in res:\n",
    "                mgroup=None\n",
    "                for group in mean_group:\n",
    "                    subtasks=mean_group[group]\n",
    "                    if subtasks is None:\n",
    "                        if group in alias:\n",
    "                            mgroup=group\n",
    "                    else:\n",
    "                        if alias in subtasks:\n",
    "                            mgroup=group\n",
    "                if mgroup:\n",
    "                    out[mgroup]+=res[metric]\n",
    "                    mean_groups[mgroup]+=1\n",
    "                else:\n",
    "                    out[alias]=res[metric]\n",
    "    for group in mean_group:\n",
    "        out[group]=out[group]/mean_groups[group]\n",
    "    return out\n",
    "\n",
    "def readout_allresults(allresults,metrics,mean_group={}):\n",
    "    out={}\n",
    "    for scale in allresults:\n",
    "        results=allresults[scale]\n",
    "        out[scale]=readout_results(results,metrics,mean_group)\n",
    "    return out\n",
    "\n",
    "def avg_results(results,keyword=None):\n",
    "    if keyword:\n",
    "        results=filter_results(results,keyword)\n",
    "    avg=0\n",
    "    for i in results:\n",
    "        avg+=results[i]\n",
    "    return avg/len(results)\n",
    "\n",
    "def filter_results(results,keyword):\n",
    "    out={}\n",
    "    for i in results:\n",
    "        if keyword in i:\n",
    "            out[i]=results[i]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2 dict_keys(['14M', '70M', '31M'])\n",
      "mamba2 dict_keys(['14M', '31M'])\n",
      "ttt dict_keys(['14M', '31M'])\n",
      "retnet dict_keys(['14M'])\n",
      "rwkv6 dict_keys(['14M'])\n",
      "*hybridflow* dict_keys(['14M'])\n",
      "*ahan-transformer* dict_keys(['14M'])\n"
     ]
    }
   ],
   "source": [
    "for i in all_results:\n",
    "    print(i,all_results[i].keys())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_grouped_bar_chart(results, baseline=None, ratio=False, title='Scores by group and metric', width=16, height=6):\n",
    "    \"\"\"\n",
    "    Plot a grouped bar chart.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: A dictionary where keys are group names and values are lists of scores for each metric.\n",
    "    - metrics: A list of metric names.\n",
    "    - groups: A list of group names.\n",
    "    - title: The title of the chart.\n",
    "    \"\"\"\n",
    "    groups = list(results.keys())\n",
    "    metrics = list(results[groups[0]].keys())\n",
    "    data={}\n",
    "    for group in groups:\n",
    "        data[group]=[]\n",
    "        for metric in metrics:\n",
    "            score=results[group][metric]\n",
    "            if baseline:\n",
    "                score-=baseline[metric]\n",
    "                if ratio:\n",
    "                    score/=baseline[metric]\n",
    "            data[group].append(score)\n",
    "    x = np.arange(len(metrics))  # the label locations\n",
    "    bar_width = 0.8 / len(groups)  # the width of the bars, dynamically adjusted based on number of groups\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(width, height))\n",
    "    \n",
    "    for i, group in enumerate(groups):\n",
    "        ax.bar(x + i * bar_width - bar_width * (len(groups) - 1) / 2, data[group], bar_width, label=group)\n",
    "    \n",
    "    # Add some text for labels, title, and custom x-axis tick labels, etc.\n",
    "    \n",
    "    ax.set_xlabel('Metrics')\n",
    "    if baseline:\n",
    "        if ratio:\n",
    "            ax.set_ylabel('Relative Ratio to Baseline')\n",
    "        else:\n",
    "            ax.set_ylabel('Relative Scores to Baseline')\n",
    "    else:\n",
    "        ax.set_ylabel('Scores')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.legend()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "metrics=['acc,none','mcc,none','em,none','contains,none','exact_match,strict-match','exact_match,flexible-extract']#,'perplexity,none']\n",
    "\n",
    "gpt2_accs = readout_allresults(gpt2_results,metrics,mean_group=MEAN_GROUPS)\n",
    "# random_acc = readout_results(random_results,metrics,mean_group=MEAN_GROUPS)\n",
    "all_accs = {}\n",
    "for i in all_results:\n",
    "    all_accs[i]=readout_allresults(all_results[i],metrics,mean_group=MEAN_GROUPS)\n",
    "    \n",
    "all_acc_14M = {}\n",
    "all_acc_14M['random']=random_acc\n",
    "for i in all_accs:\n",
    "    all_acc_14M[i]=all_accs[i]['14M']\n",
    "# gpt2_accs['random']=random_acc\n",
    "\n",
    "\n",
    "# ratio=False\n",
    "# baseline=random_acc\n",
    "# baseline.pop('squad_completion')\n",
    "# print(baseline)\n",
    "# plot_grouped_bar_chart(all_acc_14M,baseline,ratio)\n",
    "# plot_grouped_bar_chart(gpt2_accs,baseline,ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Change from Random, 14M, trained on 280M tokens:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blimp</th>\n",
       "      <th>inverse_scaling</th>\n",
       "      <th>glue</th>\n",
       "      <th>qa4mre</th>\n",
       "      <th>mathqa</th>\n",
       "      <th>wsc273</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>15.25</td>\n",
       "      <td>-10.43</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.98</td>\n",
       "      <td>-3.80</td>\n",
       "      <td>17.23</td>\n",
       "      <td>5.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mamba2</th>\n",
       "      <td>23.90</td>\n",
       "      <td>-2.77</td>\n",
       "      <td>4.71</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>10.87</td>\n",
       "      <td>9.84</td>\n",
       "      <td>9.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ttt</th>\n",
       "      <td>11.36</td>\n",
       "      <td>-7.87</td>\n",
       "      <td>3.97</td>\n",
       "      <td>6.55</td>\n",
       "      <td>2.72</td>\n",
       "      <td>14.77</td>\n",
       "      <td>5.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retnet</th>\n",
       "      <td>17.63</td>\n",
       "      <td>15.96</td>\n",
       "      <td>8.44</td>\n",
       "      <td>-8.33</td>\n",
       "      <td>5.43</td>\n",
       "      <td>4.03</td>\n",
       "      <td>10.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rwkv6</th>\n",
       "      <td>15.25</td>\n",
       "      <td>-10.43</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.98</td>\n",
       "      <td>-3.80</td>\n",
       "      <td>17.23</td>\n",
       "      <td>5.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*hybridflow*</th>\n",
       "      <td>23.90</td>\n",
       "      <td>-2.77</td>\n",
       "      <td>4.71</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>10.87</td>\n",
       "      <td>9.84</td>\n",
       "      <td>9.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*ahan-transformer*</th>\n",
       "      <td>16.78</td>\n",
       "      <td>13.83</td>\n",
       "      <td>6.20</td>\n",
       "      <td>2.38</td>\n",
       "      <td>8.15</td>\n",
       "      <td>8.95</td>\n",
       "      <td>10.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    blimp  inverse_scaling  glue  qa4mre  mathqa  wsc273  \\\n",
       "gpt2                15.25           -10.43  3.47    2.98   -3.80   17.23   \n",
       "mamba2              23.90            -2.77  4.71   -4.17   10.87    9.84   \n",
       "ttt                 11.36            -7.87  3.97    6.55    2.72   14.77   \n",
       "retnet              17.63            15.96  8.44   -8.33    5.43    4.03   \n",
       "rwkv6               15.25           -10.43  3.47    2.98   -3.80   17.23   \n",
       "*hybridflow*        23.90            -2.77  4.71   -4.17   10.87    9.84   \n",
       "*ahan-transformer*  16.78            13.83  6.20    2.38    8.15    8.95   \n",
       "\n",
       "                      avg  \n",
       "gpt2                 5.84  \n",
       "mamba2               9.02  \n",
       "ttt                  5.57  \n",
       "retnet              10.08  \n",
       "rwkv6                5.84  \n",
       "*hybridflow*         9.02  \n",
       "*ahan-transformer*  10.88  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cols=all_acc_14M['gpt2'].keys()\n",
    "rows=all_acc_14M.keys()\n",
    "all_acc_14M_data=[]\n",
    "for i in rows:\n",
    "    all_acc_14M_data.append(all_acc_14M[i])\n",
    "df=pd.DataFrame(all_acc_14M_data,index=rows,columns=cols)\n",
    "# remove low sensitivity metrics or ineffective ones (e.g. all lower than random)\n",
    "df=df.drop(columns=['standard','squad_completion','tinyGSM8k','sciq','mnli_mismatch','scrolls','swag','tinyTruthfulQA'])\n",
    "# precision to 3 decimal places\n",
    "df=df.round(3)\n",
    "# bold the max value in each column\n",
    "# for col in df.columns:\n",
    "#     df.loc[df[col]==df[col].max(),col]=f'<span style=\"font-weight: bold;\">{df[col].max()}</span>'\n",
    "# average the scores for each row besides column scrolls\n",
    "df['avg']=(df.mean(axis=1)).round(3)\n",
    "# normalize the scores to random\n",
    "df_norm = df.div(df.loc['random'])\n",
    "# minus by 1\n",
    "df_norm=df_norm.sub(1)\n",
    "# show percent change\n",
    "df_norm=df_norm.mul(100)\n",
    "df_norm=df_norm.round(2)\n",
    "# drop random row\n",
    "df_norm=df_norm.drop(index=['random'])\n",
    "\n",
    "\n",
    "df.style.format(\"{:.3f}\").to_html('all_acc_14M.html')\n",
    "df.to_csv('all_acc_14M.csv')\n",
    "\n",
    "print('Percent Change from Random, 14M, trained on 280M tokens:')\n",
    "df_norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
