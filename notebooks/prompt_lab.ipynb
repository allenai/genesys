{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Place for experimenting the progressive design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import yaml\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import model_discovery.utils as U\n",
    "from model_discovery.configs.gam_config import GAMConfig, GAMConfig_14M\n",
    "from model_discovery.model.gab_composer import GABTree,ROOT_UNIT_TEMPLATE\n",
    "\n",
    "\n",
    "ckpt_dir = os.environ['CKPT_DIR']\n",
    "db_dir = U.pjoin(ckpt_dir, 'test_composer', 'db')\n",
    "# test_tree = GABTree('test_tree', db_dir)\n",
    "\n",
    "\n",
    "# prompts_dir='../model_discovery/agents/prompts/'\n",
    "# dir_prompt = U.pjoin(prompts_dir, 'gu_prompts.yaml')\n",
    "\n",
    "# with open(dir_prompt, 'r') as file:\n",
    "#    gu_prompts = yaml.safe_load(file)\n",
    "# gab_py = U.read_file(U.pjoin(prompts_dir,'gab_template.py'))\n",
    "# gam_py = U.read_file(U.pjoin(prompts_dir,'gam_prompt.py'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# test_tree.py\\n\\nimport torch\\nimport torch.nn as nn\\n\\nfrom model_discovery.model.utils.modules import GABUnit # DO NOT CHANGE THIS IMPORT STATEMENT #\\n\\n\\n# YOU CAN IMPORT MORE MODULES HERE #\\n\\n# YOU CAN DEFINE MORE CLASSES OR FUNCTIONS HERE #\\n\\n\\nclass test_tree(GABUnit): \\n    \"\"\"Generalized Autoregressive Block\\n        Input:        X: (batch, seqlen, embed_dim), Z: {dict of all current intermediate variables}\\n        Output:       Y: (batch, seqlen, embed_dim), Z_: Optional, {dict of *new* intermediate variables to update the current Z}\\n        Constraints:  Causal, differentiable, parameter number, complexity, parallelizable\\n    \"\"\"\\n    def __init__(self, embed_dim: int, device=None, dtype=None,**kwargs): # YOU CAN ADD MORE ARGUMENTS, BUT YOU HAVE TO HAVE embed_dim, device, dtype AS THE ARGUTMENTS #\\n        # argv: list of hyperparameters\\n        factory_kwargs = {\"device\": device, \"dtype\": dtype} # remember to pass it to all nn layers\\n        super().__init__(embed_dim) # DO NOT CHANGE THIS LINE #\\n        \\n        # COMPLETING THE CODE HERE #\\n\\n\\n    # YOU CAN ADD MORE FUNCTIONS HERE #\\n\\n\\n    def _forward(self, X, **Z): \\n\\n        # COMPLETING THE CODE HERE #\\n        \\n        return X\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_UNIT_TEMPLATE.replace('{name}', 'test_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model_discovery'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_discovery\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgab_composer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GABTree\n\u001b[1;32m      3\u001b[0m ckpt_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCKPT_DIR\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m db_dir \u001b[38;5;241m=\u001b[39m U\u001b[38;5;241m.\u001b[39mpjoin(ckpt_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_composer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model_discovery'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design a novel autoregressive model block by completing the blanks marked in the Python code file gab.py below, which includes the initialization where you can define your custom arguments, the forward function where you can define convenient functions in the GAB class such as caches, the configuration with the hyperparameters that correspond to the arguments you defined:\n",
      "```python {gab_py} ```\n",
      "The GAB is inherited from this GABBase class, you should always import it by \"from model_discovery.model.utils.modules import GABBase\", you should never remove this statement from gab.py and you should never define another GABBase class in gab.py:\n",
      "```python {gab_base} ```\n",
      "This code will be used to construct a gam model in gam.py:\n",
      "```python {gam_py} ```\n",
      "This is the configuration and references for the target model:\n",
      "```python {config} ```\n",
      "Here are some hints: 1. You need to consider the GAM model structure and the default operations like the normalization when designing the GAB block. Always remember that GAB is a part of the GAM model, it should not be designed as a whole model. 2. You need to consider the magnitute of the model based on the reference model size, d_model and n_blocks. The n_blocks can be automatically adjusted so do not need to worry too much. 3. The model should be able to be parallel trained, which means you should not introduce recurrent operators like RNN or LSTM. The model should always be causal and differentiable. 4. The design should be innovative, you are not allowed to copy a previous design such as transformer block, you need to design your own block. 5. All dimensions of your model should always be a function of d_model (e.g., 2.5 times of d_model), you should never ever manually set a dimension of a layer to a fixed number in your config. 6. The GABBase provides a block_loc to help you locate the current block within the network which allows you to implement topology related operations. 7. The forward method allows you to create intermediate variables in intermediate_vars if you need. 8. Only import, import from, class definition, function definition, and gab_config definition can be shown in the code. Do not include any other operations in the code. They will be automatically removed.\n",
      "{instruct}\n",
      "Now, use the information provided above to complete the code. You should strictly follow the instructions in gab.py and do not remove anything suggested by the instructions. \n",
      "Your response should include the full gab.py file with the completed code. Specifically, when providing the full gab.py file, please preserve # gab.py at the beginning of the file. You can write multiple codes during your analysis process, but only one with # gab.py at the beginning will be detected as gab.py, if multiple gab.py are detected in your response, only the last one will be applied. You should derive your design step by step with detailed analysis and explanation before writing your code. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gu_prompts['GU_designer']['init_design'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
