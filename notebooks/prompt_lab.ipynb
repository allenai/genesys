{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Place for experimenting the progressive design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ChengJunyan1\\anaconda3\\envs\\modis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\ChengJunyan1\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import yaml\n",
    "import inspect\n",
    "import importlib\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import model_discovery.utils as U\n",
    "from model_discovery.configs.gam_config import GAMConfig, GAMConfig_14M\n",
    "from model_discovery.model.composer import GABTree,ROOT_UNIT_TEMPLATE,GAUBase\n",
    "# from model_discovery.evolution import BuildEvolution\n",
    "\n",
    "ckpt_dir = os.environ['CKPT_DIR']\n",
    "db_dir = U.pjoin(ckpt_dir, 'test_composer', 'db')\n",
    "test_tree = GABTree('TestTree', db_dir)\n",
    "\n",
    "prompts_dir='../model_discovery/agents/prompts/'\n",
    "gab_py = U.read_file(U.pjoin(prompts_dir,'gab_template.py'))\n",
    "gam_py = U.read_file(U.pjoin(prompts_dir,'gam_prompt.py'))\n",
    "GAU_TEMPLATE = U.read_file(U.pjoin(prompts_dir,'gau_template.py'))\n",
    "GAU_BASE=inspect.getsource(GAUBase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# TestTree.py\\n\\nimport torch\\nimport torch.nn as nn\\n\\nfrom model_discovery.model.utils.modules import GABUnit # DO NOT CHANGE THIS IMPORT STATEMENT #\\n\\n\\n# YOU CAN IMPORT MORE MODULES HERE #\\n\\n# YOU CAN DEFINE MORE CLASSES OR FUNCTIONS HERE #\\n\\n\\nclass TestTree(GABUnit): \\n    \"\"\"Generalized Autoregressive Block\\n        Input:        X: (batch, seqlen, embed_dim), Z: {dict of all current intermediate variables}\\n        Output:       Y: (batch, seqlen, embed_dim), Z_: Optional, {dict of *new* intermediate variables to update the current Z}\\n        Constraints:  Causal, differentiable, parameter number, complexity, parallelizable\\n    \"\"\"\\n    def __init__(self, embed_dim: int, device=None, dtype=None,**kwargs): # YOU CAN ADD MORE ARGUMENTS, BUT YOU HAVE TO HAVE embed_dim, device, dtype AS THE ARGUTMENTS #\\n        # argv: list of hyperparameters\\n        factory_kwargs = {\"device\": device, \"dtype\": dtype} # remember to pass it to all nn layers\\n        super().__init__(embed_dim) # DO NOT CHANGE THIS LINE #\\n        \\n        # COMPLETING THE CODE HERE #\\n\\n\\n    # YOU CAN ADD MORE FUNCTIONS HERE #\\n\\n\\n    def _forward(self, X, **Z): \\n\\n        # COMPLETING THE CODE HERE #\\n        \\n        return X\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tree.path\n",
    "test_tree.get_source('TestTree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_discovery.agents.prompts.prompts as P\n",
    "importlib.reload(P)\n",
    "\n",
    "gu_system_prompt=P.GU_DESIGNER_SYSTEM_prompt.format(GAB_BASE=P.GAB_BASE,GAM_PY=gam_py,GAU_BASE=GAU_BASE,GAU_TEMPLATE=GAU_TEMPLATE)\n",
    "\n",
    "print(gu_system_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "code='''\n",
    "# gau.py   # DO NOT CHANGE OR REMOVE THE MAKK HERE, KEEP IT ALWAYS THE FIRST LINE #\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model_discovery.model.utils.modules import GAUBase # DO NOT CHANGE THIS IMPORT STATEMENT #\n",
    "\n",
    "\n",
    "# YOU CAN IMPORT MORE MODULES HERE #\n",
    "\n",
    "# YOU CAN DEFINE MORE CLASSES OR FUNCTIONS HERE #\n",
    "\n",
    "\n",
    "class GAU(GAUBase): # DO NOT CHANGE THE NAME OF THIS CLASS\n",
    "    \"\"\"Generalized Autoregressive Block Unit\n",
    "        Input:        X: (batch, seqlen, embed_dim), Z: {dict of all current intermediate variables}\n",
    "        Output:       Y: (batch, seqlen, embed_dim), Z_: Optional, {dict of *new* intermediate variables to update the current Z}\n",
    "        Constraints:  Causal, differentiable, parameter number, complexity, parallelizable\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim: int, device=None, dtype=None,**kwargs): # YOU CAN ADD MORE ARGUMENTS WITH OPTIONAL DEFAULT VALUES, BUT YOU HAVE TO HAVE embed_dim, device, dtype AS THE ARGUTMENTS #\n",
    "        # argv: list of hyperparameters\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype} # remember to pass it to all nn layers\n",
    "        super().__init__(embed_dim) # DO NOT CHANGE THIS LINE #\n",
    "\n",
    "        # COMPLETING THE CODE HERE #\n",
    "        self.token_scorer: GAUBase = TokenScoringGAU(embed_dim, **factory_kwargs)\n",
    "        self.dual_path: GAUBase = DualPathGAU(embed_dim, **factory_kwargs)\n",
    "        self.latent_attention: GAUBase = LatentAttentionGAU(embed_dim, **factory_kwargs)\n",
    "\n",
    "\n",
    "    # YOU CAN ADD MORE FUNCTIONS HERE #\n",
    "\n",
    "\n",
    "    def _forward(self, X, **Z): \n",
    "\n",
    "        # THE CODE HERE MUST BE COMPLETED #\n",
    "        # Step 1: Score tokens\n",
    "        X, Z = self.token_scorer(X, **Z)\n",
    "        # Step 2: Route through dual paths\n",
    "        # Step 3: Apply latent attention\n",
    "        Y, Z = self.latent_attention(X, **Z)\n",
    "        X, Z = self.dual_path(X, **Z)\n",
    "\n",
    "        return Y, Z\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reformatted Code:\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from model_discovery.model.utils.modules import GAUBase\n",
      "\n",
      "\n",
      "class XAU(GAUBase):\n",
      "    \"\"\"Generalized Autoregressive Block Unit\n",
      "        Input:        X: (batch, seqlen, embed_dim), Z: {dict of all current intermediate variables}\n",
      "        Output:       Y: (batch, seqlen, embed_dim), Z_: Optional, {dict of *new* intermediate variables to update the current Z}\n",
      "        Constraints:  Causal, differentiable, parameter number, complexity, parallelizable\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, embed_dim: int, device=None, dtype=None, **kwargs):\n",
      "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "        super().__init__(embed_dim)\n",
      "        self.token_scorer: GAUBase = TokenScoringGAU(embed_dim, **\n",
      "            factory_kwargs, embed_dim=embed_dim, device=device, dtype=dtype,\n",
      "            **kwargs)\n",
      "        self.dual_path: GAUBase = DualPathGAU(embed_dim, **factory_kwargs,\n",
      "            embed_dim=embed_dim, device=device, dtype=dtype, **kwargs)\n",
      "        self.latent_attention: GAUBase = LatentAttentionGAU(embed_dim, **\n",
      "            factory_kwargs, embed_dim=embed_dim, device=device, dtype=dtype,\n",
      "            **kwargs)\n",
      "\n",
      "    def _forward(self, X, **Z):\n",
      "        X, Z = self.token_scorer(X, **Z)\n",
      "        Y, Z = self.latent_attention(X, **Z)\n",
      "        X, Z = self.dual_path(X, **Z)\n",
      "        return Y, Z\n",
      "\n",
      "Errors:\n",
      " []\n",
      "Warnings:\n",
      " []\n",
      "Children Units:\n",
      " {'TokenScoringGAU': 'token_scorer', 'DualPathGAU': 'dual_path', 'LatentAttentionGAU': 'latent_attention'}\n",
      "New Arguments:\n",
      " {}\n",
      "Called Children:\n",
      " {'token_scorer', 'latent_attention', 'dual_path'}\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import astor\n",
    "\n",
    "\n",
    "class ImportChecker(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self.found_gaubase_import = False\n",
    "\n",
    "    def visit_ImportFrom(self, node):\n",
    "        # Check if 'from model_discovery.model.utils.modules import GAUBase' exists\n",
    "        if node.module == 'model_discovery.model.utils.modules' and any(alias.name == 'GAUBase' for alias in node.names):\n",
    "            self.found_gaubase_import = True\n",
    "        return self.generic_visit(node)\n",
    "\n",
    "\n",
    "class ClassRenamer(ast.NodeTransformer):\n",
    "    def __init__(self, unit_name):\n",
    "        self.unit_name = unit_name\n",
    "        self.gau_class_found = False\n",
    "        self.gaubase_classes = []\n",
    "        self.errors = []\n",
    "\n",
    "    def visit_ClassDef(self, node):\n",
    "        # Extract the base class names\n",
    "        base_names = [base.id if isinstance(base, ast.Name) else base.attr if isinstance(base, ast.Attribute) else None for base in node.bases]\n",
    "\n",
    "        # Check for classes inheriting from GAUBase\n",
    "        if any(base == \"GAUBase\" for base in base_names):\n",
    "            self.gaubase_classes.append(node)\n",
    "\n",
    "        # Rename the class named 'GAU' to unit_name\n",
    "        if node.name == \"GAU\" or (len(self.gaubase_classes) == 1 and not self.gau_class_found):\n",
    "            node.name = self.unit_name\n",
    "            self.gau_class_found = True\n",
    "\n",
    "        return self.generic_visit(node)\n",
    "\n",
    "\n",
    "class AttributeChecker(ast.NodeVisitor):\n",
    "    def __init__(self, unit_name):\n",
    "        self.unit_name = unit_name\n",
    "        self.children_units = {} # key: class unit_name, value: object name\n",
    "        self.created_children = set()\n",
    "        self.errors = []\n",
    "        self.required_args = [\"embed_dim\", \"device\", \"dtype\", \"kwargs\"]\n",
    "        self.new_args = {}\n",
    "        self.found_init = False\n",
    "        self.found__forward = False\n",
    "        self.inside_gau_class = False\n",
    "\n",
    "    def visit_ClassDef(self, node):\n",
    "        if node.name == self.unit_name:\n",
    "            self.inside_gau_class = True  # Start processing only when inside GAU class\n",
    "            self.generic_visit(node)\n",
    "            self.inside_gau_class = False  # Reset after processing GAU class\n",
    "        else:\n",
    "            # Skip other classes\n",
    "            self.inside_gau_class = False\n",
    "\n",
    "    def visit_FunctionDef(self, node):\n",
    "        if not self.inside_gau_class:\n",
    "            return node\n",
    "        # Only process the __init__ method\n",
    "        if node.name == \"__init__\":\n",
    "            self.found_init = True\n",
    "\n",
    "            # Extract argument names\n",
    "            arg_names = [arg.arg for arg in node.args.args]\n",
    "            \n",
    "            # Check for required arguments in __init__\n",
    "            missing_args = [arg for arg in self.required_args if arg not in arg_names]\n",
    "            if missing_args:\n",
    "                for arg in missing_args:\n",
    "                    new_arg = ast.arg(arg=arg, annotation=None)\n",
    "                    node.args.args.append(new_arg)\n",
    "                    # print(f\"Added missing argument {arg} to __init__ method of {self.unit_name}\")\n",
    "\n",
    "            # ensure kwargs is **kwargs \n",
    "            for kw in node.args.args:\n",
    "                if kw.arg == \"kwargs\":\n",
    "                    node.args.args.remove(kw)\n",
    "                    break\n",
    "            node.args.kwarg = ast.arg(arg=\"kwargs\", annotation=None)\n",
    "\n",
    "            # Check for new args and default values in __init__\n",
    "            for arg in node.args.args:\n",
    "                if arg.arg not in self.required_args and arg.arg != \"self\":\n",
    "                    self.new_args[arg.arg] = arg.annotation \n",
    "            \n",
    "            for stmt in node.body:\n",
    "                if isinstance(stmt, ast.AnnAssign):\n",
    "                    # Look for annotated assignments with GAUBase\n",
    "                    if isinstance(stmt.annotation, ast.Name) and stmt.annotation.id == \"GAUBase\":\n",
    "                        if isinstance(stmt.target, ast.Attribute) and isinstance(stmt.target.value, ast.Name) and stmt.target.value.id == \"self\":\n",
    "                            self.created_children.add(stmt.target.attr)\n",
    "                        # Process the value (which is a constructor call) to check arguments\n",
    "                        if isinstance(stmt.value, ast.Call) and isinstance(stmt.value.func, ast.Name):\n",
    "                            unit_name = stmt.value.func.id\n",
    "                            # Verify and add missing arguments\n",
    "                            existing_arg_names = {kw.arg for kw in stmt.value.keywords if kw.arg is not None}\n",
    "                            missing_args = [arg for arg in self.required_args if arg not in existing_arg_names]\n",
    "                            if missing_args:\n",
    "                                for arg in missing_args:\n",
    "                                    if arg == \"kwargs\":\n",
    "                                        # Handle **kwargs\n",
    "                                        stmt.value.keywords.append(ast.keyword(arg=None, value=ast.Name(id=\"kwargs\", ctx=ast.Load())))\n",
    "                                    else:\n",
    "                                        new_kw = ast.keyword(arg=arg, value=ast.Name(id=arg, ctx=ast.Load()))\n",
    "                                        stmt.value.keywords.append(new_kw)\n",
    "                            self.children_units[unit_name] = stmt.target.attr\n",
    "\n",
    "        elif node.name == \"_forward\":\n",
    "            self.found__forward = True\n",
    "        elif node.name=='forward':\n",
    "            self.errors.append(\"Error: The forward method in GAUBase should not be overridden.\")\n",
    "\n",
    "        return self.generic_visit(node)\n",
    "\n",
    "\n",
    "class ForwardChecker(ast.NodeVisitor):\n",
    "    def __init__(self, unit_name, created_children):\n",
    "        self.unit_name = unit_name\n",
    "        self.created_children = created_children\n",
    "        self.warnings = []\n",
    "        self.inside_gau_class = False\n",
    "        self.called_children = set()\n",
    "\n",
    "    def visit_ClassDef(self, node):\n",
    "        if node.name == self.unit_name:\n",
    "            self.inside_gau_class = True  # Start processing only when inside GAU class\n",
    "            self.generic_visit(node)\n",
    "            self.inside_gau_class = False  # Reset after processing GAU class\n",
    "        else:\n",
    "            # Skip other classes\n",
    "            self.inside_gau_class = False\n",
    "\n",
    "    def visit_FunctionDef(self, node):\n",
    "        if not self.inside_gau_class:\n",
    "            return node\n",
    "        \n",
    "        if node.name == \"_forward\":\n",
    "            # Traverse the body of the _forward function\n",
    "            for stmt in node.body:\n",
    "                if isinstance(stmt, ast.Assign):\n",
    "                    # Check if the right-hand side of the assignment is a function call\n",
    "                    if isinstance(stmt.value, ast.Call):\n",
    "                        # Check if the function call is an attribute of `self` (e.g., `self.token_scorer`)\n",
    "                        if isinstance(stmt.value.func, ast.Attribute) and isinstance(stmt.value.func.value, ast.Name):\n",
    "                            if stmt.value.func.value.id == \"self\":\n",
    "                                self.called_children.add(stmt.value.func.attr)  # Add the attribute name\n",
    "\n",
    "            # Check for any children that were not called in _forward\n",
    "            missing_calls = self.created_children - self.called_children\n",
    "            if missing_calls:\n",
    "                self.warnings.append(f\"Error: The following GAUBase children defined in __init__ are not called in _forward: {missing_calls}\")\n",
    "\n",
    "        return self.generic_visit(node)\n",
    "\n",
    "\n",
    "class ModuleProcessor(ast.NodeTransformer):\n",
    "    def __init__(self, found_gaubase_import, gaubase_classes, unit_name, gau_class_found):\n",
    "        self.found_gaubase_import = found_gaubase_import\n",
    "        self.gaubase_classes = gaubase_classes\n",
    "        self.unit_name = unit_name\n",
    "        self.gau_class_found = gau_class_found\n",
    "        self.errors = []\n",
    "\n",
    "    def visit_Module(self, node):\n",
    "        # Add import if not found\n",
    "        if not self.found_gaubase_import:\n",
    "            gaubase_import = ast.ImportFrom(module='model_discovery.model.utils.modules', names=[ast.alias(name='GAUBase', asname=None)], level=0)\n",
    "            node.body.insert(0, gaubase_import)\n",
    "\n",
    "        # Handle renaming and removing other classes that inherit from GAUBase\n",
    "        if not self.gau_class_found and len(self.gaubase_classes) == 1:\n",
    "            gau_class_node = self.gaubase_classes[0]\n",
    "            gau_class_node.name = self.unit_name\n",
    "            self.gau_class_found = True\n",
    "        elif len(self.gaubase_classes) > 1:\n",
    "            matching_class = None\n",
    "            for cls in self.gaubase_classes:\n",
    "                if cls.name == self.unit_name:\n",
    "                    matching_class = cls\n",
    "                    break\n",
    "            if matching_class:\n",
    "                matching_class.name = self.unit_name\n",
    "            else:\n",
    "                self.errors.append(f\"Error: Multiple classes inheriting from GAUBase found, but none match the provided unit_name '{self.unit_name}'.\")\n",
    "\n",
    "        # Remove other classes that inherit from GAUBase (other than the renamed class)\n",
    "        node.body = [cls for cls in node.body if not (isinstance(cls, ast.ClassDef) and \"GAUBase\" in [base.id if isinstance(base, ast.Name) else base.attr if isinstance(base, ast.Attribute) else None for base in cls.bases] and cls.name != self.unit_name)]\n",
    "\n",
    "        return self.generic_visit(node)\n",
    "\n",
    "\n",
    "def check_and_reformat_gau_code(source_code, unit_name):\n",
    "    # Step 1: Parse the source code into an AST\n",
    "    tree = ast.parse(source_code)\n",
    "    errors = []\n",
    "    warnings = []\n",
    "\n",
    "    # Step 2: Run an import checker to determine if GAUBase import exists\n",
    "    import_checker = ImportChecker()\n",
    "    import_checker.visit(tree)\n",
    "\n",
    "    # Step 3: Run the first pass to rename classes and gather class-related information\n",
    "    class_renamer = ClassRenamer(unit_name)\n",
    "    class_renamer.visit(tree)\n",
    "\n",
    "    # Step 4: Run the second pass to check the __init__ method for annotated attributes\n",
    "    attribute_checker = AttributeChecker(unit_name)\n",
    "    attribute_checker.visit(tree)\n",
    "    if not attribute_checker.found_init:\n",
    "        errors.append(\"Error: No __init__ method found in the GAU.\")\n",
    "    if not attribute_checker.found__forward:\n",
    "        errors.append(\"Error: No _forward method found in the GAU.\")\n",
    "\n",
    "    # Step 5: Run the third pass to check the _forward method for all created children\n",
    "    forward_checker = ForwardChecker(unit_name, attribute_checker.created_children)\n",
    "    forward_checker.visit(tree)\n",
    "\n",
    "    # Step 6: Process the module (e.g., imports and removing classes)\n",
    "    module_processor = ModuleProcessor(import_checker.found_gaubase_import, class_renamer.gaubase_classes, unit_name, class_renamer.gau_class_found)\n",
    "    module_processor.visit(tree)\n",
    "\n",
    "    reformatted_code = astor.to_source(tree)\n",
    "    \n",
    "    errors += class_renamer.errors + attribute_checker.errors + module_processor.errors\n",
    "    warnings += forward_checker.warnings\n",
    "    return reformatted_code, attribute_checker.children_units, attribute_checker.new_args, forward_checker.called_children, errors, warnings\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "source_code = \"\"\"\n",
    "# gau.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model_discovery.model.utils.modules import GAUBase\n",
    "\n",
    "# Placeholder classes for future implementation\n",
    "class MemoryAccessUnit(nn.Module):\n",
    "    def __init__(self, embed_dim, memory_size, device=None, dtype=None):\n",
    "        super().__init__(embed_dim)\n",
    "\n",
    "    def _forward(self, X, **Z):\n",
    "        return X, {}\n",
    "\n",
    "class DownsamplingUnit(nn.Module):\n",
    "    def __init__(self, embed_dim, downsample_factor, device=None, dtype=None):\n",
    "        super().__init__(embed_dim)\n",
    "\n",
    "    def _forward(self, X, **Z):\n",
    "        return X, {}\n",
    "\n",
    "class XAEU(GAUBase):  # This class will be renamed to the unit_name\n",
    "    def __init__(self, embed_dim: int, device=None, dtype=None):\n",
    "        super().__init__(embed_dim)\n",
    "        self.unit: GAUBase = MemoryAccessUnit(embed_dim=embed_dim, device=device)\n",
    "\n",
    "    def _forward(self, X, **Z):\n",
    "        return X, Z\n",
    "\"\"\"\n",
    "\n",
    "unit_name = \"XAU\"  # Provide the unit_name to rename GAU class\n",
    "reformatted_code, children_units, new_args, called, errors, warnings = check_and_reformat_gau_code(code, unit_name)\n",
    "print(\"Reformatted Code:\\n\" + reformatted_code)\n",
    "print(\"Errors:\\n\", errors)\n",
    "print(\"Warnings:\\n\", warnings)\n",
    "print(\"Children Units:\\n\", children_units)\n",
    "print(\"New Arguments:\\n\", new_args)\n",
    "print(\"Called Children:\\n\", called)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# gau.py\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "\n",
      "from model_discovery.model.utils.modules import GAUBase\n",
      "\n",
      "# Placeholder imports for future GAUs\n",
      "# from gau import RandomizedAttentionUnit, HierarchicalCompositionUnit\n",
      "\n",
      "class HRAB(GAUBase):\n",
      " \"\"\"Hierarchical Randomized Attention Block Unit\n",
      " Input: X: (batch, seqlen, embed_dim), Z: {dict of all current intermediate variables}\n",
      " Output: Y: (batch, seqlen, embed_dim), Z_: Optional, {dict of *new* intermediate variables to update the current Z}\n",
      " Constraints: Causal, differentiable, parameter number, complexity, parallelizable\n",
      " \"\"\"\n",
      " def __init__(self, embed_dim: int, device=None, dtype=None, **kwargs):\n",
      " factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
      " super().__init__(embed_dim)\n",
      " \n",
      " # Initialize the Randomized Attention Unit\n",
      " self.randomized_attention: GAUBase = RandomizedAttentionUnit(embed_dim, **factory_kwargs, **kwargs)\n",
      " \n",
      " # Initialize the Hierarchical Composition Unit\n",
      " self.hierarchical_composition: GAUBase = HierarchicalCompositionUnit(embed_dim, **factory_kwargs, **kwargs)\n",
      "\n",
      " def _forward(self, X, **Z):\n",
      " # Apply randomized attention to capture local dependencies\n",
      " Y, Z = self.randomized_attention(X, **Z)\n",
      " \n",
      " # Apply hierarchical composition to capture global dependencies\n",
      " Y, Z = self.hierarchical_composition(Y, **Z)\n",
      " \n",
      " return Y, Z\n",
      "\n",
      "# Placeholder classes for future implementation\n",
      "class RandomizedAttentionUnit(GAUBase):\n",
      " def __init__(self, embed_dim: int, device=None, dtype=None, **kwargs):\n",
      " super().__init__(embed_dim)\n",
      " # Implementation will be added later\n",
      "\n",
      " def _forward(self, X, **Z):\n",
      " # Placeholder forward method\n",
      " return X, {}\n",
      "\n",
      "class HierarchicalCompositionUnit(GAUBase):\n",
      " def __init__(self, embed_dim: int, device=None, dtype=None, **kwargs):\n",
      " super().__init__(embed_dim)\n",
      " # Implementation will be added later\n",
      "\n",
      " def _forward(self, X, **Z):\n",
      " # Placeholder forward method\n",
      " return X, {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
